<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ESWA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eswa">ESWA - 1189</h2>
<ul>
<li><details>
<summary>
(2026). A transferable deep learning framework to propagate extreme water levels from sparse tide-gauges across spatial domains. <em>ESWA</em>, <em>299</em>, 130222. (<a href='https://doi.org/10.1016/j.eswa.2025.130222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of extreme water level (EWL) dynamics resulting from cyclone-induced events is critical for mitigating coastal flood hazards, yet existing approaches remain constrained by computationally expensive hydrodynamic models. While recent deep learning (DL) models can achieve high accuracy and reduced computational cost, they often fail to capture delayed hydrodynamic responses across large water bodies and/or generalize EWL dynamics across distinct spatial domains. In this study, we present a transferable DL framework designed to propagate EWLs in estuaries and bays using sparse tide-gauges as water level sources. The framework evaluates the model’s performance of the proposed Attention-based Gated Graph Convolution Network (AbGGCN) against a U-Net model with a convolutional long short-term memory network (ConvLSTM) and a conventional GGCN. These models embed sparse tide-gauges in the model domain and utilize convolutional or graph diffusion operators that learn how localized EWL signals spread across space and time, with the AbGGCN model incorporating a custom temporal attention mechanism. We demonstrate that the AbGGCN model outperforms both the U-Net ConvLSTM and GGCN models with accuracies comparable to those from physics-based model simulations (e.g., Mean Kling-Gupta Efficiency: 0.71 vs. 0.50 and 0.46, and Mean Bias: +0.04 m vs. + 0.14 and + 0.12 m, respectively, for Hurricane Beryl, 2024). Moreover, AbGGCN exhibits strong model transferability when trained in Galveston Bay, TX and tested in Chesapeake Bay, VA-MD without additional retraining. Our findings suggest that spatiotemporal graph-based architectures are scalable, efficient, and generalizable alternatives for real-time EWL forecasting, with broad applicability to diverse estuarine and coastal systems.},
  archive      = {J_ESWA},
  author       = {Samuel Daramola and David F. Muñoz and Md Shadman Sakib and Hana Thurman and George Allen},
  doi          = {10.1016/j.eswa.2025.130222},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130222},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transferable deep learning framework to propagate extreme water levels from sparse tide-gauges across spatial domains},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stackelberg game optimization method for virtual power plant and electric vehicle considering coupled green certificates and spot markets. <em>ESWA</em>, <em>299</em>, 130202. (<a href='https://doi.org/10.1016/j.eswa.2025.130202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the global energy sector shifts toward cleaner and more sustainable sources, integrating renewable energy into existing power systems has become a critical objective. This transition is further accelerated by the large-scale deployment of electric vehicles (EVs), which presents both opportunities and challenges for grid management and stability. The variability of renewable energy output, coupled with the increasing demand from EV charging, calls for innovative solutions in energy trading and system optimization. Against the backdrop of large-scale EV deployment and the increasing share of renewable energy, this paper proposes a VPP-EV trading model that incorporates the coupling of the green certificate and spot markets. Additionally, an ultra-short-term wind and solar output forecasting method based on the TCN-GRU-Attention hybrid model is introduced. Furthermore, by integrating utility functions and conditional value at risk, the study quantifies EV user satisfaction and the impact of uncertainties in EV charging and discharging on VPP profitability. A Stackelberg game-based optimization method for VPP-EV interaction is also proposed, using price signals to guide EV charging and discharging behaviors and determine the optimal guidance strategy. Finally, a case study in the Beijing-Tianjin-Hebei region of China is conducted. The results indicate that the proposed method achieves 97.2% and 98.1% accuracy in wind and solar forecasting, reduces the peak–valley difference by 32.32%, and lowers average user costs by 18.44–25.10% compared to benchmark scenarios. Overall, this optimization model and trading mechanism offer valuable theoretical guidance for integrating EVs into electricity markets, supporting the energy sector’s transformation and upgrade.},
  archive      = {J_ESWA},
  author       = {Zhenyu Zhao and Qianxin Ma and Chang Wei and Ruyue Han},
  doi          = {10.1016/j.eswa.2025.130202},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130202},
  shortjournal = {Expert Syst. Appl.},
  title        = {Stackelberg game optimization method for virtual power plant and electric vehicle considering coupled green certificates and spot markets},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A 3D existing railway alignment recreation method based on particle swarm optimization and mesh adaptive direct search. <em>ESWA</em>, <em>299</em>, 130199. (<a href='https://doi.org/10.1016/j.eswa.2025.130199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term operation, existing railway alignments often deviate from their original design, which may pose safety risks during train operation. Therefore, it is necessary to recreate the alignment. Most current recreation methods focus on either the horizontal or vertical alignments separately. However, these two components are closely interrelated, while both are mutually constrained during the design process. Independent recreation of either the horizontal or vertical alignment makes it difficult to minimize the total 3D deviations from the measured points to the recreated alignment. To address this issue, this study develops a 3D recreation model for existing railway alignments, which fully accounts for the coupling relations between horizontal and vertical alignments. A PSO-MADS hybrid optimization algorithm is then proposed to solve this model. By designing a 3D adjustable range for the alignment solutions, the optimization efficiency is further improved. Finally, the proposed method is applied to a real-world case study. The results demonstrate the effectiveness of the proposed method in generating a better 3D recreation solution, compared with both human designers and a conventional Swing iteration method.},
  archive      = {J_ESWA},
  author       = {Yang Ran and Wei Li and Xinjie Wan and Hao Pu and Paul Schonfeld and Cheng Lu and Zhenya Zhang and Lihui Peng},
  doi          = {10.1016/j.eswa.2025.130199},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130199},
  shortjournal = {Expert Syst. Appl.},
  title        = {A 3D existing railway alignment recreation method based on particle swarm optimization and mesh adaptive direct search},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). STFF-IFD: A novel multi-channel intelligent fault diagnosis based on data-driven spatio-temporal feature fusion. <em>ESWA</em>, <em>299</em>, 130181. (<a href='https://doi.org/10.1016/j.eswa.2025.130181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in sensor and information fusion technologies have substantially expedited the development of intelligent fault diagnosis techniques. During the process of extracting fault features for equipment health monitoring, traditional time-domain and frequency-domain features are restricted by their limited characterization capabilities, and single-dimensional features find it difficult to precisely capture complex fault patterns. Nevertheless, the combination of time–frequency domain features and clustering analysis has demonstrated potential in surmounting these limitations and improving the accuracy of fault detection. This paper proposes a spatiotemporal feature fusion based intelligent fault diagnosis (STFF-IFD) approach, which utilizes a multi-level fusion strategy to analyze three-directional vibration signals. At the data layer, the symmetrized dot pattern algorithm is utilized to thoroughly integrate three-dimensional vibration signals, thus extracting invariant feature parameters that are robust to diverse sources. At the feature layer, a convolutional autoencoder is employed to learn the hierarchical representations of three-dimensional vibration signals and explore latent spatiotemporal features. At the decision layer, spatiotemporal features are fused with invariant point features through a decision fusion mechanism to realize intelligent identification of fault types. Dual-platform experiments were conducted to validate the results. The findings indicate that the STFF-IFD method exhibits superior performance in terms of fault diagnosis accuracy and environmental adaptability. This model offers an innovative research perspective and a technical solution path for fault diagnosis based on multi-level information fusion. It not only aligns with the development trends of data-driven and intelligent diagnosis but also further improves the comprehensive theoretical and methodological system of intelligent fault diagnosis.},
  archive      = {J_ESWA},
  author       = {Dengyun Sun and Zong Meng and Jingbo Liu and Haoze Chen and Fengjie Fan},
  doi          = {10.1016/j.eswa.2025.130181},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130181},
  shortjournal = {Expert Syst. Appl.},
  title        = {STFF-IFD: A novel multi-channel intelligent fault diagnosis based on data-driven spatio-temporal feature fusion},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). R2D-EQ: A two-stage workflow for risk reasoning and decision-making in earthquake emergency scenarios. <em>ESWA</em>, <em>299</em>, 130178. (<a href='https://doi.org/10.1016/j.eswa.2025.130178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective decision-making is crucial in earthquake emergency response, where rapid and well-informed actions are vital to saving lives and minimizing losses. However, current methods often struggle to rapidly acquire and effectively analyze localized historical data under specific disaster scenarios, achieve real-time risk identification, and seamlessly connect these insights to emergency decision-making. This study proposes R2D-EQ, a two-stage workflow designed to enhance risk reasoning and decision-making in earthquake emergencies. The framework integrates real-time web intelligence, event evolutionary graph construction, and retrieval-augmented generation (RAG) to dynamically uncover risk propagation chains and generate context-specific response recommendations. By combining symbolic reasoning with neural generation, R2D-EQ offers an interpretable, adaptive, and scalable solution for complex disaster management scenarios. System evaluations show that the framework achieves strong performance in risk perception, risk reasoning, and response generation. Notably, causal risk chain modeling enhances interpretability, while LightRAG-based decision generation improves precision and domain-level professionalism. Despite these advances, the framework faces limitations, including high computational costs, challenges in managing event generalization, limited geographic and contextual coverage in the knowledge base, and difficulties in detecting unknown risks. Future work will focus on incorporating multimodal data sources, embedding geospatial computation tools as agent-accessible modules, and developing multi-agent collaboration mechanisms, aiming to strengthen the system’s adaptive and cooperative potential in next-generation disaster management.},
  archive      = {J_ESWA},
  author       = {Liwei Yao and Fu Ren and Qingyun Du},
  doi          = {10.1016/j.eswa.2025.130178},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130178},
  shortjournal = {Expert Syst. Appl.},
  title        = {R2D-EQ: A two-stage workflow for risk reasoning and decision-making in earthquake emergency scenarios},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-weaver query in sparse temporal knowledge graphs leveraging complex space embedding and adjacent timestamp relations. <em>ESWA</em>, <em>299</em>, 130177. (<a href='https://doi.org/10.1016/j.eswa.2025.130177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In temporal knowledge graph querying, effectively integrating both semantic and temporal information is essential, as it enables accurate search and dynamic event prediction by capturing how relationships between entities evolve over time. However, T emporal K nowledge G raphs ( TKGs ) often suffer from semantic and temporal sparsity, in which incomplete temporal information and the uneven distribution of facts lead to great challenges in capturing the correlation between entities. To tackle these challenges, this paper proposes a T ime- W eaver Q uery ( TWQ ) model in S parse T emporal K nowledge G raph ( STKG ) leveraging complex space embedding and exploitation of adjacent time relations. TWQ reconstructs entity, relation, and timestamp embeddings with eight complex-domain matrices, integrating temporal and semantic features via complex arithmetic. To model implicit interdependencies between entities, TWQ incorporates a temporal relationship synthesis module to dynamically aggregate relational patterns across current and adjacent timestamps, facilitating adaptive temporal dependency resolution and multi-scale contextual inference. Furthermore, the framework integrates an intermediate node identification mechanism to decompose multi-hop queries into interpretable hierarchical subqueries. Experiments on real-world datasets demonstrate that the proposed method mitigates sparsity-related issues and enhances the accuracy and scalability of STKG queries.},
  archive      = {J_ESWA},
  author       = {Yang Gao and Luyi Bai and Ruiming Shi and Huayin Jiang},
  doi          = {10.1016/j.eswa.2025.130177},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130177},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-weaver query in sparse temporal knowledge graphs leveraging complex space embedding and adjacent timestamp relations},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RLEM-net: Reinforcement learning enhanced multimodal segmentation for camellia oleifera diseases based on semantic and visual features. <em>ESWA</em>, <em>299</em>, 130176. (<a href='https://doi.org/10.1016/j.eswa.2025.130176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important woody oil crop, Camellia oleifera requires effective disease and pest control to ensure yield and quality. Deep learning-based segmentation of Camellia oleifera diseases plays a crucial role in promoting the sustainable development of tea-oil industry. Although existing studies have achieved significant progress in the segmentation and classification of Camellia oleifera diseases, several key challenges remain unresolved: (1) some lesions share chromatic similarities with complex backgrounds; (2) lesion boundaries frequently exhibit low contrast; and (3) the small size of lesions compromises segmentation accuracy. To overcome these limitations, we proposed RLEM-Net, a dual-modal segmentation model for Camellia oleifera diseases that integrates image and textual information. By incorporating a text branch for multimodal feature extraction, RLEM-Net enhances segmentation performance, achieving a 1.29% improvement in mean Intersection over Union (mIoU). the proposed Reinforcement Learning Weight Adjuster (RLWA) effectively differentiates between background and small-scale lesions, contributing an additional 2.47% improvement in mIoU. we evaluated the degree of erosion of the lesions and calculated the proportion of the lesions on the leaves. Furthermore, to address blurred boundaries, we introduce a Channel-Space Polarization Attention mechanism, which yields a 1.79% gain in mIoU. With all innovations integrated, the model achieves a substantial mIoU increase of 4.85%. Additionally, guided by forestry experts, we compiled a novel dataset with pixel-level annotations and complementary textual descriptions for Camellia oleifera diseases. This dataset provides a robust foundation for future research on disease segmentation in natural environments.},
  archive      = {J_ESWA},
  author       = {Hao Zhou and Lin Li and Shaofeng Peng and Sheng Xu and Ziyang Shi and Bin Xie and Yuting Peng and Benhan Zhao},
  doi          = {10.1016/j.eswa.2025.130176},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130176},
  shortjournal = {Expert Syst. Appl.},
  title        = {RLEM-net: Reinforcement learning enhanced multimodal segmentation for camellia oleifera diseases based on semantic and visual features},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language models as virtual experts? evaluating AHP-based criteria weighting performance for solar power plant site selection. <em>ESWA</em>, <em>299</em>, 130171. (<a href='https://doi.org/10.1016/j.eswa.2025.130171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Criteria Decision Making (MCDM) methods integrated with Geographic Information Systems (GIS) are essential for spatial planning, particularly in renewable energy development. The Analytic Hierarchy Process (AHP) traditionally relies on expert elicitation for criteria weighting, which can be costly, time-consuming, and inconsistent. This study develops a framework to evaluate Large Language Models (LLMs) as virtual experts for spatial MCDM, addressing the need for accessible and reliable decision-support alternatives in urban and environmental systems. We empirically compared six contemporary LLMs with a panel of ten regional domain experts in determining AHP criteria weights for solar power plant site selection. The framework tests multiple prompting strategies, assesses architectural performance, examines stability across iterations, and identifies biases. Fourteen spatially explicit criteria were used, spanning resource potential, topography, environmental constraints, and infrastructure connectivity. Optimally configured LLMs achieve strong correlations with expert consensus (r = 0.838), approaching typical inter-expert agreement levels, though systematic biases in specific criterion categories reveal important limitations in expert simulation. Expert Panel Role-Based prompting outperformed Chain-of-Thought and Minimal Context methods. Stability analysis revealed significant reliability differences across architectures, while systematic biases included underestimation of topographical factors and overemphasis on infrastructure connectivity. The framework provides empirical performance benchmarks and identifies model-specific optimization needs and bias correction protocols. This research establishes a controlled testbed for exploring AI decision-making patterns rather than replacing expert processes in high-stakes energy infrastructure decisions.},
  archive      = {J_ESWA},
  author       = {Abdulkadir Memduhoğlu and Nir Fulman and Nizar Polat and Tacettin Ataş},
  doi          = {10.1016/j.eswa.2025.130171},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130171},
  shortjournal = {Expert Syst. Appl.},
  title        = {Large language models as virtual experts? evaluating AHP-based criteria weighting performance for solar power plant site selection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UKANCNet: Multi-scale feature fusion with UKAN enhancement for micro wind turbine blade defect segmentation. <em>ESWA</em>, <em>299</em>, 130170. (<a href='https://doi.org/10.1016/j.eswa.2025.130170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro windmills, characterized by rapid installation and low wind-speed startup capabilities, are particularly suited for low-wind regions, providing reliable off-grid power. However, ensuring their operational stability remains challenging, necessitating efficient blade defect detection. Traditional encoder-decoder networks often suffer from information loss, a limitation addressed by multi-scale feature fusion. To further enhance defect localization, an advanced U-shaped Kolmogorov-Arnold network (UKAN) variant UKAN cross-scale network (UKANCNet) is designed for windmill blade defect identification. The key contributions can be summarized as follows: firstly, we introduce a fine-to-coarse feature integration method, which supersedes the conventional decoder with a hierarchical feature fusion mechanism to minimize information loss. Secondly, an attention mechanism is employed to suppress background noise while accentuating defect regions. Finally, an optimized loss function is used to enable automatic hyperparameter tuning and reduce computational overhead. Experimental results show that UKANCNet outperforms existing methods in various key indicators, notably reaching a remarkable 89.5% mean intersection over union (mIoU), and presents an efficient and precise solution for defect segmentation in micro and small wind turbine blades, significantly improving detection accuracy. By ensuring operational reliability, this work contributes to the stable performance of wind power systems and advances the intelligent development of renewable energy. Code is available at the following website: https://github.com/jiajia65/UKANCNet .},
  archive      = {J_ESWA},
  author       = {Sijia Li and Jizheng Yi and Xiaoyao Li and Xiangyu Shen and Lijiang Chen and Ze Jin},
  doi          = {10.1016/j.eswa.2025.130170},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130170},
  shortjournal = {Expert Syst. Appl.},
  title        = {UKANCNet: Multi-scale feature fusion with UKAN enhancement for micro wind turbine blade defect segmentation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). What are the eigen visual features for penetration state recognition?. <em>ESWA</em>, <em>299</em>, 130169. (<a href='https://doi.org/10.1016/j.eswa.2025.130169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based penetration state recognition serves as a critical basis for online feedback control of welding quality. To address challenges such as visual interference, dynamic variations, and subtle visual differences between marginally distinct penetration states, this study focuses on identifying eigen visual features corresponding to different penetration states, aiming to enhance the accuracy of vision-based penetration state recognition. First, 44 spatial, value, and frequency domain features were extracted from molten pool images using the Segment Anything Model 2(SAM 2) and preprocessing techniques. Second, an eigen feature mining method based on Shapley Additive Explanations (SHAP) was proposed and applied to three classification models: XGBoost, RandomForest, and LightGBM. Finally, the applicability of the proposed eigen visual feature extraction methods, the robustness of the eigen visual features, and the coupling relationship between the eigen visual features and the welding process mechanism were thoroughly validated. Results showed that SHAP outperforms sequential forward selection (SFS) in stability across models, with consistent rankings of high-contribution features. Under four performance metrics, eigen visual feature-based models outperformed those non-eigen feature-based model by 0.25% to 2.75%. Moreover, the eigen visual features exhibited strong robustness: under cross-model settings, the standard deviation of their classification accuracy was only about 25% of that observed with non-eigen features. Remarkably, by using just 13% of the original feature dimensionality, the eigen feature set preserved 99.2% to 99.8% of the full feature set’s classification accuracy under noise-free conditions, and maintained 97.6% to 99.4% of its performance even at the highest noise level.},
  archive      = {J_ESWA},
  author       = {Yaojin Jiang and Tianyuan Liu and Jinsong Bao},
  doi          = {10.1016/j.eswa.2025.130169},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130169},
  shortjournal = {Expert Syst. Appl.},
  title        = {What are the eigen visual features for penetration state recognition?},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A frequency loss function based dynamic convolutional transformer model with data denoising for short-term wind speed forecasting. <em>ESWA</em>, <em>299</em>, 130166. (<a href='https://doi.org/10.1016/j.eswa.2025.130166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient wind speed forecasting is essential for power grid management in balancing supply and demand, and support cost-effective transition to renewable energy. This study develops a novel wind power forecasting system designed to reduce deployment training computational time and support periodic updates in practical applications. The system first applies Stagewise Orthogonal Matching Pursuit (StOMP) to suppress noise in the raw wind speed sequences and performs correlation-based feature selection to determine the most informative historical inputs. Subsequently, DCFDT FDD , the forecasting model is constructed, in which multi-layer Dynamic Convolution (DC) modules are employed for multi-scale feature fusion, and a frequency debiased Transformer is introduced to directly learn multiple frequency components of wind speed sequences through frequency-domain modeling and patching operations, without the need for prior signal decomposition. Additionally, a Frequency-Domain Decorrelation (FDD) loss function is incorporated to mitigate the inherent autocorrelation of label sequences in Transformer. Experiments conducted on three real-world wind speed datasets demonstrate that the proposed system delivers both accurate and efficient predictions, reducing training computational time by 36.20 %, 34.24 % and 41.46 % compared with state-of-the-art decomposition-based hybrid methods, while maintaining accuracy within 0.54 m/s RMSE. These results indicate that the developed system offers a practical solution for wind farm applications considering engineering time.},
  archive      = {J_ESWA},
  author       = {Bingzhe Fu and Wei Wang and Yihuan Li and Guorui Ren and Kang Li},
  doi          = {10.1016/j.eswa.2025.130166},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130166},
  shortjournal = {Expert Syst. Appl.},
  title        = {A frequency loss function based dynamic convolutional transformer model with data denoising for short-term wind speed forecasting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffuStory: Improving text diffusion models for creative story generation with contrastive learning and decoder-decoder transformers. <em>ESWA</em>, <em>299</em>, 130154. (<a href='https://doi.org/10.1016/j.eswa.2025.130154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural story generation (NSG) is an advanced task in natural language processing (NLP). Its major challenges lie in the significant information gap between short prompts and long narrative outputs. Most recent NSG models rely on explicit plot planning to enhance consistency or employ the conditional variational autoencoder (CVAE) to improve word diversity. However, these models lack creativity and struggle to be applied in real-world scenarios. This study proposes a two-stage NSG model, DiffuStory, comprising a memory module and an expression module. In the first stage, the memory module leverages a text diffusion model to learn an implicit plot representation (IPR). We incorporate a novel token-level contrastive learning (TLCL) objective to calibrate the anisotropic representation space, mitigating the drift effect of diffusion models on open-ended language generation. In the second stage, the expression module with decoder-decoder Transformer architecture captures long-range dependencies within the IPR and performs autoregressive decoding to generate coherent story text. At the same time, we introduce an optimal transport knowledge distillation (OTKD) approach that guides the decoding process with pre-trained models and supports cross-tokenizer knowledge transfer. Following a multidimensional evaluation framework, including automatic, large language model (LLM)-based, and human evaluations, we validate the proposed DiffuStory on two widely used English NSG datasets (ROCStories and WikiPlots) and a newly curated Chinese NSG dataset (CHGStories). Experimental results reveal a significant bias when NSG models are evaluated solely using automatic metrics. DiffuStory achieves competitive performance on LLM-based metrics across three datasets and effectively addresses the limitations of text diffusion models under human evaluation. Moreover, the ablation study demonstrates the effectiveness of each component in DiffuStory. In the case study, human evaluations further confirm that the learned IPR can serve as an implicit intermediate representation that bridges the information gap and fosters creativity in NSG, resulting in higher human satisfaction.},
  archive      = {J_ESWA},
  author       = {Zhenyu Li and Kaijie Xu and Yian Liang and Yuechuan Wang and Zongfeng Zou},
  doi          = {10.1016/j.eswa.2025.130154},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130154},
  shortjournal = {Expert Syst. Appl.},
  title        = {DiffuStory: Improving text diffusion models for creative story generation with contrastive learning and decoder-decoder transformers},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy naive bayes with gaze-behavior-aware attention for accurate intention inference. <em>ESWA</em>, <em>299</em>, 130152. (<a href='https://doi.org/10.1016/j.eswa.2025.130152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate intention inference is a critical prerequisite for effective human-robot interaction. However, existing gaze-based inference methods overlook the continuity of gaze attention and incur gaze information loss during inference, thereby limiting their inference accuracy. Our goal is to devise a general method for quantifying continuous gaze attention and to develop a companion framework that fully exploits intention relevant gaze information to infer intentions. Specifically, gaze-behavior-aware attention refers to the object-centred gaze attention computed based on two complementary gaze behaviors, gaze duration and gaze sequence, in a continuous quantification through fuzzy inference. It then fully leverages intention-relevant gaze information, namely gaze duration, gaze sequence, and continuous gaze attention together with gaze object-occurrence frequencies in the Fuzzy Naive Bayes framework to infer intentions. These information is utilized to adjust fuzzy priors and likelihoods, enabling joint intention inference, which interprets the complex relationships among gaze behavior, continuous gaze attention, and intentions. Its fuzzy priors and likelihoods accommodate the uncertainty and incompleteness typical of real-world gaze data. Evaluated on our ADLIP Gaze dataset, which comprises 102 participants spanning diverse age groups, the proposed method achieves an inference accuracy of 95.59±1.92 % and also attains the highest reported accuracy on the publicly available benchmark. The proposed framework has the potential application in assistive robots, especially for older individuals or individuals with motor decline. The proposed framework has potential applications in assistive robotics, particularly for daily-living object manipulation, by enabling robots to perceive and exploit human gaze attention for accurate intention inference.},
  archive      = {J_ESWA},
  author       = {Zihang Yin and Shiqian Wu and Zhonghua Wan and Bo Yang and Sos S. Agaian and Xiao Wei Sun},
  doi          = {10.1016/j.eswa.2025.130152},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130152},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fuzzy naive bayes with gaze-behavior-aware attention for accurate intention inference},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid residual dengue outbreak prediction network with optimal climatic parameter and its micro-level selection. <em>ESWA</em>, <em>299</em>, 130151. (<a href='https://doi.org/10.1016/j.eswa.2025.130151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dengue is a worldwide health-affecting disease. Unorganized urbanization raises the complexity of dengue transformation due to the density of the population, access to water, and human mobility. Climate changes have a high likelihood of impacting the control of mosquito growth. Thus, to resolve this, a new hybrid model on the basis of deep learning for dengue outbreak prediction is implemented. The relevant databases are used to collect raw data in this proposed model. From this collected information, the relevant features are optimally selected with aid of Statistical Adaptive Hippopotamus Optimization (St-AHO) that renders multi-objective functions with constraints like mutual information gain, entropy, and relief score. Optimally selected features are fed to Hybrid Residual Networks (HRNet), which are formed by both Bidirectional- Gated Recurrent Unit (Bi-GRU) and Convolutional-Long Short Term Memory (Conv-LSTM) for predicting the dengue outbreak. The predictive ability of proposed model is enhanced by optimally selecting the climate parameters and their micro-levels using the St-AHO to control the mosquito-spread. The proposed model can reduce dengue outbreaks by controlling the spread of mosquitoes. Finally, experimental assessments are done among several conventional predictive models and algorithms using different performance metrics to ensure the reliability of the proposed predictive model.},
  archive      = {J_ESWA},
  author       = {Gopala Varma Kosuri and M. Chandra Naik and R.N.V. Jagan Mohan},
  doi          = {10.1016/j.eswa.2025.130151},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130151},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid residual dengue outbreak prediction network with optimal climatic parameter and its micro-level selection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-supervised privacy-preserving graph classification framework enhanced by graph contrastive learning. <em>ESWA</em>, <em>299</em>, 130149. (<a href='https://doi.org/10.1016/j.eswa.2025.130149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Graph Neural Networks (GNNs) have demonstrated impressive performance across various domains, their high interconnectivity makes them inherently vulnerable to privacy leakage. Traditional Differential Privacy (DP) methods—such as Differentially Private Stochastic Gradient Descent (DPSGD) and Private Aggregation of Teacher Ensembles (PATE)—either fail to provide sufficient protection in graph settings or require impractical assumptions, such as strictly disjoint data partitions and large volumes of labeled data. To address these challenges, we propose a semi-supervised privacy-preserving graph classification framework that integrates the differentially private k -nearest neighbor (DP-kNN) mechanism with contrastive pre-training. Unlike prior approaches, We design a DP-kNN mechanism that securely transfers private labels to public graphs by aggregating and perturbing nearest-neighbor labels, without requiring multiple teacher models or strictly disjoint data splits. To further improve the quality and robustness of the pseudo-labels generated by DP-kNN, we introduce a graph contrastive learning pre-training stage, which establishes a noise-resistant feature foundation for the graph data, thereby mitigating the impact of differential privacy noise during the label transfer process. Finally, pseudo-labeled public graphs are used for fine-tuning, yielding high utility with strong privacy guarantees. We further conduct a rigorous privacy analysis under the Rényi Differential Privacy (RDP) framework, incorporating privacy amplification via subsampling. Extensive experiments on eight benchmark graph datasets demonstrate that our approach achieves competitive classification performance under strict privacy budgets, offering a scalable and practical solution for privacy-aware graph learning.},
  archive      = {J_ESWA},
  author       = {Yong Li and Xiao Song and Songsong Liu and Kaiqi Gong},
  doi          = {10.1016/j.eswa.2025.130149},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130149},
  shortjournal = {Expert Syst. Appl.},
  title        = {A semi-supervised privacy-preserving graph classification framework enhanced by graph contrastive learning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-level visual-textual alignment transformer for multimodal aspect-based sentiment analysis. <em>ESWA</em>, <em>299</em>, 130148. (<a href='https://doi.org/10.1016/j.eswa.2025.130148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Aspect-Based Sentiment Analysis (MABSA) aims to identify aspectual terms in sentences by employing both images and text while also forecasting the sentiment polarity of these aspect terms. Present MABSA methods mainly focus on the fusion of text and images, but less research has been done on the image noise problem. Moreover, irrelevant context is easily interfered with when processing text, especially words that are semantically or morphologically similar to aspectual words. In addition, existing models are deficient in handling representational consistency between textual and visual modalities. This paper presents a Multi-level Visual-textual Alignment Transformer (MVAT) for MABSA. The model comprises a Text Sentiment Differential Amplifier, a Multi-Granularity Fusion Optimizer module, and a Visual-Textual Alignment module. In the Text Sentiment Differential Amplifier module, we can more accurately distinguish the sentiment polarity of different entities by using a Differential Transformer that incorporates GCN. In the Multi-Granularity Fusion Optimizer module, we establish a fine-grained correspondence between the local features of the image and the token of the text, which is used to optimize the multi-granularity fusion. In the Visual-textual Alignment module, we dynamically attenuate the noise in the image using dynamic multimodal gates, which adaptively modify the contribution ratio between text and image according to the confidence level of the text. Furthermore, we also use a Transformer incorporating a CNN to mitigate the effect of noise in the image on the model. We performed comprehensive experiments on two publicly accessible datasets. State-of-the-art (SOTA) outcomes are achieved using the MVAT model, which performs noticeably better than the baseline model.},
  archive      = {J_ESWA},
  author       = {Hongxin Li and Bin Gao and Linlin Li and Yutong Li and Shutian Liu and Zhengjun Liu},
  doi          = {10.1016/j.eswa.2025.130148},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130148},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-level visual-textual alignment transformer for multimodal aspect-based sentiment analysis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-model denoising and spearman-based negative sample filling for implicit feedback recommendation. <em>ESWA</em>, <em>299</em>, 130143. (<a href='https://doi.org/10.1016/j.eswa.2025.130143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become critical in alleviating information overload, with implicit feedback learning emerging as a dominant approach due to its capacity to capture detailed user behaviors and the simplicity of data collection. However, implicit feedback data is often noisy and biased. Although existing denoising methods have proven effective, they often exacerbate data sparsity by discarding samples or struggling to generalize across different datasets. To address these challenges, we propose a novel implicit feedback recommendation model called the Cross-Model Denoising and Spearman-Based Negative Sample Filling. This model performs data denoising and sample filling by leveraging the collaboration between a primary and an auxiliary model, integrating Kullback-Leibler (KL) divergence and the Spearman rank correlation coefficient. Specifically, noisy samples tend to produce larger prediction discrepancies across models. To capture this effect, we use KL divergence to quantify cross-model prediction consistency, enabling the identification and removal of noisy positive and negative samples while mitigating the bias of single-model judgments. Unlike conventional approaches that rely solely on loss values, which fail to separate noise from informative but hard-to-learn instances, KL divergence effectively reflects discrepancies in predictive distributions under different levels of overfitting, thereby providing a more robust basis for denoising. To mitigate the data sparsity introduced by denoising, we further utilize Spearman rank correlation to select reliable noisy negative samples with higher ranking consistency and refill them into the training set. This not only compensates for data loss but also leverages latent weak signals, enabling the model to better capture users’ implicit interests. Experimental results demonstrate that the proposed model consistently outperforms existing recommendation methods across multiple datasets, enhancing recommendation accuracy.},
  archive      = {J_ESWA},
  author       = {Zhiqiang Zhang and Jiayi Zhao and Jiangzhou Deng and Jianmei Ye and Leo Yu Zhang and Yong Wang and Kobiljon Kh. Khushvakhtzoda},
  doi          = {10.1016/j.eswa.2025.130143},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130143},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-model denoising and spearman-based negative sample filling for implicit feedback recommendation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). K-shape clustering and STL decomposition with transformer fusion RF user power consumption forecasting model. <em>ESWA</em>, <em>299</em>, 130142. (<a href='https://doi.org/10.1016/j.eswa.2025.130142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous progress of society, the scale of electricity consumption has shown a rapid growth trend, resulting in an exponential increase in energy demand. Hence, this paper addresses the issue of user load data processing, where K-means has a limited impact on load curve clustering, by introducing a new load cluster decomposition hybrid model, called FKSTL. The proposed model combines K-shape clustering and STL with an isolated forest. Additionally, it presents the concept of ensemble learning, utilizes the STL algorithm to enhance the K-shape clustering unit, and subsequently divides clusters into seasonal, trend, and random items. This architecture enables the extraction of multidimensional curves from time series data, thereby improving data mining capabilities. Furthermore, the model introduces an isolated forest to identify outliers and obtain more accurate time series data. The results demonstrate that the prediction error of the developed FKSTL model is lower, and the prediction precision and accuracy are high. Thus, to solve the problem of power load forecasting, a Transformer is applied for short-term load forecasting, and a stacked random forest load forecasting model based on mixed dual attention is proposed. This upgraded model, MDATSRF, employs the dual attention method, which combines internal and external patches, to address the limitation of Transformers, which do not consider the entire picture, and obtains both global and local context information. At the same time, the random forest model in Stacking is introduced to perform nonlinear fusion of the output of each branch, and the final load prediction result is obtained by stacking random forests. The experimental results show that the proposed MDATSRF load forecasting model has higher accuracy and robustness.},
  archive      = {J_ESWA},
  author       = {Fengjun Shang and Qianye Liu},
  doi          = {10.1016/j.eswa.2025.130142},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130142},
  shortjournal = {Expert Syst. Appl.},
  title        = {K-shape clustering and STL decomposition with transformer fusion RF user power consumption forecasting model},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-powered UAV remote sensing for drought stress phenotyping: Automated chlorophyll estimation in individual plants using deep learning and instance segmentation. <em>ESWA</em>, <em>299</em>, 130141. (<a href='https://doi.org/10.1016/j.eswa.2025.130141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate, high-throughput and non-destructive estimation of chlorophyll content in plants under drought stress is critical for precision agriculture and forestry. This study presented an intelligent framework integrating unmanned aerial vehicle (UAV)-based imaging, advanced artificial intelligence (AI)-powered instance segmentation, and machine learning to achieve high-throughput chlorophyll measurement in individual poplar trees. Leveraging UAV-acquired RGB and multispectral images, we first employed an optimized YOLOv10s model for robust tree crown detection. The detected regions were then refined using the Segment Anything Model (SAM), achieving precise instance segmentation (IoU = 91 %) even in complex weedy backgrounds. For chlorophyll estimation, we developed a deep neural network (DNN) that integrated multispectral vegetation indices, RGB-derived color/texture features, and environmental variables (temporal and weather data). The relative chlorophyll content was obtained using a SPAD chlorophyll meter. The DNN outperformed the other three models considered (Random Forest, Support Vector Machine, and Extreme Gradient Boosting), yielding an R 2 of 0.75, RMSE of 1.51, and MAE of 1.21, with environmental variables enhancing prediction accuracy by 3–11 %. Further application of the framework revealed cultivar-specific chlorophyll dynamics under drought, demonstrating its utility for stress phenotyping. This work advances intelligent systems for plant monitoring by synergizing UAV remote sensing, cutting-edge AI segmentation, and interpretable machine learning, offering scalable solutions for precision forestry and agricultural automation.},
  archive      = {J_ESWA},
  author       = {Zhuhao Shen and Huichun Zhang and Liming Bian and Lei Zhou and Qifei Tian and Yufeng Ge},
  doi          = {10.1016/j.eswa.2025.130141},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130141},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-powered UAV remote sensing for drought stress phenotyping: Automated chlorophyll estimation in individual plants using deep learning and instance segmentation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised learning-enhanced surrogate-assisted evolutionary search based on a pareto infill criterion for geological energy production optimization. <em>ESWA</em>, <em>299</em>, 130137. (<a href='https://doi.org/10.1016/j.eswa.2025.130137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of geological energy production optimization is to maximize the efficient extraction of oil, gas, or geothermal energy from subsurface reservoirs while minimizing cost. Although data-driven surrogate models serve as effective alternatives to high-fidelity simulations, their reliability is constrained by the substantial cost of acquiring large numbers of labeled samples. This presents a critical trade-off, as allocating a large computational budget to surrogate construction limits the subsequent search for globally optimal development schemes. To address this challenge, a novel algorithm named semi-supervised learning enhanced surrogate-assisted evolutionary search based on a pareto infill criterion (SLESA-PI) is proposed in this paper. The framework incorporates a semi-supervised co-training strategy that leverages diverse, distributionally aligned unlabeled samples to enhance the generalization of two heterogeneous surrogate models with limited labeled data. To reliably select high-quality unlabeled samples, a novel trend-based error metric is introduced as a more suitable alternative to traditional accuracy indicators. Furthermore, the evolutionary search is guided by a dual-objective Pareto infill criterion, which not only balances exploration and exploitation but also enriches the unlabeled sample pool with high-potential candidates. The performance of SLESA-PI is evaluated on eight benchmark functions (30–100 dimensions) and two real-world geological energy production cases, and compared against six other surrogate-assisted algorithms. Experimental results confirm the effectiveness and practical utility of SLESA-PI.},
  archive      = {J_ESWA},
  author       = {Jia-Lin Wang and Li-Ming Zhang and Kai Zhang and Jian Wang and Pi-Yang Liu and Xia Yan},
  doi          = {10.1016/j.eswa.2025.130137},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130137},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semi-supervised learning-enhanced surrogate-assisted evolutionary search based on a pareto infill criterion for geological energy production optimization},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Classifying mixed-defect from single-defect training in imbalanced wafer maps via diffusion and attention. <em>ESWA</em>, <em>299</em>, 130127. (<a href='https://doi.org/10.1016/j.eswa.2025.130127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wafer bin map (WBM) classification in semiconductor manufacturing is crucial for identifying the root causes of defects and improving production efficiency. As process complexity increases, mixed-defect instances become more frequent in WBMs, highlighting the need for robust classification methods that can identify multiple defect origins. However, in real-world scenarios, single-defect WBMs are often class imbalanced, and mixed-defect WBMs lack labels due to high annotation costs, making classification particularly challenging. Therefore, we propose the first method that is capable of robustly classifying both single- and mixed-defect WBMs using only class-imbalanced single-defect training data. Our approach leverages a generalized zero-shot learning framework that classifies both seen and unseen classes by exploiting semantic information and employs a diffusion model as a generative classifier. The proposed method consists of two key components. First, a class-mixing diffusion model is designed to enhance the generation quality of underrepresented mixed and tail classes by learning from potential class combinations. Second, the classification performance achieved for seen classes is improved by using the prompt-wise attention score similarity to compare the generation processes for the training and test samples. Experiments conducted on the MixedWM38 dataset, which is commonly used in WBM classification research, demonstrate that our method achieves superior generalization performance with less overfitting to the training data and realizes significantly improved classification accuracy owing to its enhanced generation quality.},
  archive      = {J_ESWA},
  author       = {Daeyeol Yang and Jaeyeon Jang and Chang Ouk Kim},
  doi          = {10.1016/j.eswa.2025.130127},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130127},
  shortjournal = {Expert Syst. Appl.},
  title        = {Classifying mixed-defect from single-defect training in imbalanced wafer maps via diffusion and attention},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Electricity load and price forecasting in spain: A hybrid deep learning framework leveraging temporal and seasonal dynamics. <em>ESWA</em>, <em>299</em>, 130123. (<a href='https://doi.org/10.1016/j.eswa.2025.130123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of electricity load and price is critical for energy management, market stability, and the integration of renewable resources. Yet, strong volatility, seasonal fluctuations, and nonlinear dependencies in market signals limit the effectiveness of traditional statistical and classical machine learning approaches. To address these challenges, we develop a hybrid deep learning framework that integrates long short-term memory (LSTM), convolutional neural networks (CNN), gated recurrent units (GRU), and temporal-context hybrids to capture both short-term fluctuations and long-range seasonal dependencies. Exogenous drivers such as weather conditions, calendar effects, and fuel prices are incorporated to better reflect nonlinear price dynamics. Using Spanish electricity market data from 2015 to 2018, the models are benchmarked against conventional methods. Results show that the proposed LSTM achieved the lowest error for load forecasting (Root Mean Squared Error “RMSE” ≈ 3914 MWh; Mean Absolute Percentage Error “MAPE” ≈ 10.7%), while the hybrid Convolutional Contact Time “CONV-CT” model significantly outperformed alternatives for price forecasting (RMSE ≈ 6.4 €/MWh; MAPE ≈ 7.2%), yielding improvements of more than 15% over baseline deep learning models. These findings demonstrate that combining temporal learning with hybrid architectures enhances robustness under seasonal variations and price spikes. The framework provides a feature-rich and validated solution that advances electricity forecasting and delivers actionable insights for grid operators, market participants, and policy makers.},
  archive      = {J_ESWA},
  author       = {Ahmed Adil Nafea and Omer A. Alawi and Ziaul Haq Doost and M.M. AlAni and Ahmad Bilal Ahmadullah and Ravinesh C. Deo and Zaher Mundher Yaseen},
  doi          = {10.1016/j.eswa.2025.130123},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130123},
  shortjournal = {Expert Syst. Appl.},
  title        = {Electricity load and price forecasting in spain: A hybrid deep learning framework leveraging temporal and seasonal dynamics},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing intrusion detection in IoT: CNN integration with K-means for efficient and balanced classification. <em>ESWA</em>, <em>299</em>, 130122. (<a href='https://doi.org/10.1016/j.eswa.2025.130122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fact that the Internet of Things (IoT) is rapidly spreading and is everywhere, helps to increase speed and enlarge the amount of data moving around on earth on a planetary scale. The growing number of connected units leads to the excess of the flow of traffic through the networks, and an ecosystem of dense and inter-networked digital environments rises. Nevertheless, this astronomical growth of network traffic is accompanied by a parallel surge in the possibility to have cyber attacks. Therefore, intrusion detection systems (IDSs) are increasingly needed to confront these attacks. In this paper, we propose a detection model based on a deep learning method called convolutional neural network (CNN). To train this model, two datasets are used, Canadian Institute for Cybersecurity Intrusion Detection System 2017 (CICIDS2017) and Telemetry and Network data for the Internet of Things (ToN-IoT). These datasets first go through a size reduction step, which aims to reduce the size of the training set to speed up the learning process, avoid the overlearning problem, and also solve the class-imbalanced problem. The method used in this stage is the k-means algorithm. The results obtained in this work demonstrate the effectiveness of our approach, which can achieve an accuracy of 99.69 %, 99.96 %, and 99.97 % for CICIDS2017, ToN-IoT Windows 10, and ToN-IoT Windows 7 respectively.},
  archive      = {J_ESWA},
  author       = {Sarra Cherfi and Ammar Boulaiche and Ali Lemouari and Abdelhafid Abouaissa},
  doi          = {10.1016/j.eswa.2025.130122},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130122},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing intrusion detection in IoT: CNN integration with K-means for efficient and balanced classification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning-based control optimization for glass bottle forming. <em>ESWA</em>, <em>299</em>, 130120. (<a href='https://doi.org/10.1016/j.eswa.2025.130120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In glass bottle manufacturing, precise control of forming machines is critical for ensuring quality and minimizing defects. This study presents a deep learning-based control algorithm designed to optimize the forming process in real production environments. Using real operational data from active manufacturing plants, our neural network predicts the effects of parameter changes based on the current production setup. Through a specifically designed inversion mechanism, the algorithm identifies the optimal machine settings required to achieve the desired glass gob characteristics. Experimental results on historical datasets from multiple production lines show that the proposed method yields promising outcomes, suggesting potential for enhanced process stability, reduced waste, and improved product consistency. These results highlight the potential of deep learning to process control in glass manufacturing.},
  archive      = {J_ESWA},
  author       = {Mattia Pujatti and Andrea Di Luca and Nicola Peghini and Federico Monegaglia and Marco Cristoforetti},
  doi          = {10.1016/j.eswa.2025.130120},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130120},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep learning-based control optimization for glass bottle forming},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving electric vehicle routing problem with recharging and battery swapping using a collaborative decision attention network. <em>ESWA</em>, <em>299</em>, 130116. (<a href='https://doi.org/10.1016/j.eswa.2025.130116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for electric vehicles (EVs) in logistics and transportation, long charging times and limited driving range have emerged as significant challenges. Battery swapping offers a faster alternative to conventional charging, reducing downtime but introducing additional costs. This study investigates the electric vehicle routing problem with recharging and battery swapping (EVRP-RBS), which requires balancing range constraints with cost-efficiency. To address this, we propose a collaborative decision attention network (CDAN) based on deep reinforcement learning (DRL). CDAN jointly optimizes routing and charging strategies by training an encoder-decoder structured policy network. The EVRP-RBS is formulated as a two-action Markov decision process. The encoder extracts features from customer nodes, charging stations, and the depot, embedding them separately into a high-dimensional space. A self-attention mechanism is employed to capture the internode relationships, producing a global representation for downstream decision-making tasks. To effectively coordinate route planning and energy replenishment, we introduce a dual-attention decoder, which integrates two specialized attention modules—one for routing decisions and another for charging or battery swapping decisions. This architecture enables efficient integration of routing and charging considerations, significantly enhancing solution quality. Extensive experiments demonstrate that CDAN achieves competitive performance compared to both traditional and DRL-based baselines while exhibiting strong generalizability. Notably, the charging decision module plays a critical role in improving the overall solution quality.},
  archive      = {J_ESWA},
  author       = {Qi-chao Sun and Jun-qing Li and Xiao-long Chen and Zhong-zhi Yang and Ya-nan Wang and Zhao-sheng Du and Li Wei},
  doi          = {10.1016/j.eswa.2025.130116},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130116},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving electric vehicle routing problem with recharging and battery swapping using a collaborative decision attention network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PassREfinder-FL: Privacy-preserving credential stuffing risk prediction via graph-based federated learning for representing password reuse between websites. <em>ESWA</em>, <em>299</em>, 130111. (<a href='https://doi.org/10.1016/j.eswa.2025.130111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credential stuffing attacks have caused significant harm to online users who frequently reuse passwords across multiple websites. While prior research has attempted to detect users with reused passwords or identify malicious login attempts, existing methods often compromise usability by restricting password creation or website access, and their reliance on complex account-sharing mechanisms hinders real-world deployment. To address these limitations, we propose PassREfinder-FL , a novel framework that predicts credential stuffing risks across websites. We introduce the concept of password reuse relations—defined as the likelihood of users reusing passwords between websites—and represent them as edges in a website graph. Using graph neural networks (GNNs), we perform a link prediction task to assess credential reuse risk between sites. Our approach scales to a large number of arbitrary websites by incorporating public website information and linking newly observed websites as nodes in the graph. To preserve user privacy, we extend PassREfinder-FL with a federated learning (FL) approach that eliminates the need to share user sensitive information across administrators. Evaluation on a real-world dataset of 360 million breached accounts from 22,378 websites shows that PassREfinder-FL achieves an F1-score of 0.9153 in the FL setting. We further validate that our FL-based GNN achieves a 4–11 % performance improvement over other state-of-the-art GNN models through an ablation study. Finally, we demonstrate that the predicted results can be used to quantify password reuse likelihood as actionable risk scores. Our implementation is available at https://github.com/jaehanwork/PassREfinder-FL .},
  archive      = {J_ESWA},
  author       = {Jaehan Kim and Minkyoo Song and Minjae Seo and Youngjin Jin and Seungwon Shin and Jinwoo Kim},
  doi          = {10.1016/j.eswa.2025.130111},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130111},
  shortjournal = {Expert Syst. Appl.},
  title        = {PassREfinder-FL: Privacy-preserving credential stuffing risk prediction via graph-based federated learning for representing password reuse between websites},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fraud detection based on GNNs with local augmentation and adaptive relation aggregation. <em>ESWA</em>, <em>299</em>, 130110. (<a href='https://doi.org/10.1016/j.eswa.2025.130110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection based on Graph Neural Networks (GNNs) relies on aggregating information from the local neighborhoods, but this mechanism is vulnerable to two adversarial tactics: feature camouflage where fraudsters manipulate node attributes to mimic benign users, and relation camouflage where they establish connections with benign entities to dilute suspicious signals. These camouflage strategies compromise GNNs’ discriminative capability by exploiting the neighborhood aggregation mechanism itself. To address this vulnerability, we propose a fraud detection method based on GNNs with Local Augmentation and Adaptive Relation Aggregation (GNN-LAARA). GNN-LAARA integrates three synergistic components: a conditional variational autoencoder (CVAE) that generates discriminative node representations to expose camouflaged patterns, a reinforcement learning-based neighbor selector that dynamically filters noisy connections, and a multi-relational attention aggregator that adaptively fuses heterogeneous relationships. The effectiveness of GNN-LAARA is validated by two real-world fraud detection datasets. Experimental evaluation on two real-world fraud detection datasets demonstrates that GNN-LAARA achieves significant performance improvements, with up to 2.24% enhancement in AUC over state-of-the-art methods. Ablation studies further confirm the individual contributions of each module to the overall detection capability.},
  archive      = {J_ESWA},
  author       = {Zhou Mengzhe and Chen Jindong and Zhang Wen and Yan Zhihua},
  doi          = {10.1016/j.eswa.2025.130110},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130110},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fraud detection based on GNNs with local augmentation and adaptive relation aggregation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional low-rank three-way tensor autoregressive time series predictor. <em>ESWA</em>, <em>299</em>, 130104. (<a href='https://doi.org/10.1016/j.eswa.2025.130104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, tensor time-series forecasting has gained increasing attention, whose core requirement is how to perform dimensionality reduction. In this paper, we establish a least square optimization model by combining tensor singular value decomposition (t-SVD) with autoregression (AR) to forecast third-order tensor time-series, which has great benefit in computational complexity and dimensionality reduction. We divide such an optimization problem using fast Fourier transformation and t-SVD into four decoupled subproblems, whose variables include regressive coefficient, f-diagonal tensor, left and right orthogonal tensors, and propose an efficient forecasting algorithm via alternating minimization strategy, called Low-rank Tensor Autoregressive Predictor (LOTAP), in which each subproblem has a closed-form solution. Numerical experiments indicate that, compared to Tucker-decomposition-based algorithms, LOTAP achieves a speed improvement ranging from 2 to 6 times while maintaining accurate forecasting performance in all four baseline tasks. In addition, this algorithm is applicable to a wider range of tensor forecasting tasks because of its more effective dimensionality reduction ability.},
  archive      = {J_ESWA},
  author       = {Haoning Wang and Liping Zhang},
  doi          = {10.1016/j.eswa.2025.130104},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130104},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional low-rank three-way tensor autoregressive time series predictor},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Guided and knowledgeable multi-agent debate for fact verification. <em>ESWA</em>, <em>299</em>, 130103. (<a href='https://doi.org/10.1016/j.eswa.2025.130103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid dissemination of misinformation through social media and open-access platforms has seriously affected public and personal lives and raised data security concerns. Fact verification plays a pivotal role in curbing the spread of such information. While Large Language Models have shown strong capabilities in reasoning and generation, their inherent issues—such as hallucination and bias—can lead to unreliable and logically inconsistent outputs, making them less trustworthy in fact verification tasks. To address these limitations, we propose GKMAD (Guided and Knowledgeable Multi-Agent Debate), a multi-agent fact verification framework designed to enhance reliability by incorporating structured guidance and external knowledge. Specifically, GKMAD incorporates four key mechanisms: (1) a Guided Debate Mechanism that introduces structured prompts to steer agent debates in a targeted and coherent manner; (2) a Knowledgeable Debate Mechanism that enables agents to dynamically incorporate external knowledge to enhance the informativeness and knowledge coverage of the debate; (3) an Advanced Advice Mechanism that generates structured advice from debate outcomes to guide final verification; and (4) a Knowledgeable Verification Mechanism that combines retrieved evidence and debate insights for comprehensive decision-making. Experimental results the FOLK benchmark datasets—constructed from representative subsets of HoVER, FEVEROUS, and SciFact-Open—across seven fact verification tasks demonstrate that GKMAD consistently outperforms state-of-the-art baselines in terms of Macro-F1, confirming the effectiveness of guidance and knowledge integration in mitigating LLM unreliability in fact verification.},
  archive      = {J_ESWA},
  author       = {Xiaochen Ma and Guozheng Rao and Lina Xu and Xin Wang and Zaiming Fan and Zhe Zhang},
  doi          = {10.1016/j.eswa.2025.130103},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130103},
  shortjournal = {Expert Syst. Appl.},
  title        = {Guided and knowledgeable multi-agent debate for fact verification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced brain tumor classification in multi modal images: Leveraging self-calculated missing modality compensation transformer with NetB7++. <em>ESWA</em>, <em>299</em>, 130102. (<a href='https://doi.org/10.1016/j.eswa.2025.130102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor classification is a critical task in medical imaging and is essential for accurately identifying tumor types for effective diagnosis and treatment planning. However, existing classification approaches face significant challenges, including variability in tumor size, shape, size, location, etc., and often experience issues like overfitting, class imbalance, and lack of interpretability in classification models. To address these challenges, this work proposes a Self-calculated Missing Modality Compensation Transformer with EfficientNetB7++ (SMMCTE) model. Specifically, SMMCTE incorporates L2 regularization with a dynamic dropout scheduler for robust data preprocessing, the Self-calculated Missing Modality Compensation Transformer (SCMMCT) with self-calculated convolutional and cross-modal fusion blocks for precise tumor detection and segmentation, Smart Learning to transfer segmentation-learned features for classification, and the EfficientNetB7++ that has a conformer block for improved classification accuracy. The collective utilization of these techniques provides multiple benefits, including mitigating overfitting through dynamic dropout scheduling, handling class imbalance by leveraging feature transfer in Smart Learning, and enhancing interpretability and robustness with SCMMCT and EfficientNetB7++. Moreover, the SMMCTE method was evaluated using the BraTS 2020 and BraTS 2021 datasets. For the BraTS 2020 dataset, the method achieved Hausdorff distances of 1.99 ± 06 %, sensitivity of 99.4 %, specificity of 99.2 %, accuracy of 99.6 %, and Dice scores of 98 ± 0.4 %. In BraTS 2021, the method reached Hausdorff distances of 2.12 ± 06 %, sensitivity of 99.1 %, specificity of 98.9 %, accuracy of 99.3 %, and Dice scores of 98 ± 0.7. These results demonstrate that the proposed method outperforms existing state-of-the-art techniques.},
  archive      = {J_ESWA},
  author       = {Narmada Kari and Sanjay Kumar Singh and Roshan M. Bodile},
  doi          = {10.1016/j.eswa.2025.130102},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130102},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced brain tumor classification in multi modal images: Leveraging self-calculated missing modality compensation transformer with NetB7++},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Recommender system for secure mobile application based on permission pairs using explainable artificial intelligence. <em>ESWA</em>, <em>299</em>, 130101. (<a href='https://doi.org/10.1016/j.eswa.2025.130101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the privacy and security of users is crucial when recommending mobile applications (apps), as these apps often access sensitive personal information. This paper addresses security concerns arising from app permissions, emphasising that while individual permissions appear benign, certain combinations of these may lead to malicious behavior. We design a recommender system that assesses apps by focusing on the permission pairs rather than individual permissions, extending the current literature to identify potential security risks among permission combinations. We present a formal mathematical formulation for the problem of secure-app recommendation. We identify the significant permission pairs to classify apps as benign or malicious using a Light Gradient-Boosting model and assign risk levels using XAI techniques. We introduce a risk scoring function based on permission pairs, and it is used to recommend the top r low-risk benign apps. This study is the first to assess the risk score of mobile apps that considers permission pairs. We validated our model by evaluating it with two available datasets and one curated dataset, totaling 6,881 mobile apps released from 2012 to 2022. The classification performance of our model demonstrated superior accuracy (92.2%), precision (93.12%), and F1 score (85.42%) compared to standard classification models and state-of-the-art methods. Furthermore, the secure apps recommended by our approach received higher ratings and popularity on the Google Play Store compared to the recommendations given by the other methods.},
  archive      = {J_ESWA},
  author       = {S. Tejaswi and V.N. Sastry and S. Durga Bhavani},
  doi          = {10.1016/j.eswa.2025.130101},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130101},
  shortjournal = {Expert Syst. Appl.},
  title        = {Recommender system for secure mobile application based on permission pairs using explainable artificial intelligence},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DEG-NER: Dynamic graph-enhanced diffusion model for named entity recognition. <em>ESWA</em>, <em>299</em>, 130094. (<a href='https://doi.org/10.1016/j.eswa.2025.130094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Name entity recognition (NER) significantly facilitates research on downstream NLP tasks. However, existing methods often struggle with modeling complex inter-entity dependencies. This paper proposes a GNN-enhanced diffusion model for NER. GED-NER leverages a BERT encoder for initial contextual representation and constructs a dynamic semantic graph via sliding windows. Subsequently, Graph Neural Networks (GNNs) are employed to capture global dependencies, and these are integrated through a weighted fusion process with sentence-level encoding. A diffusion model progressively reconstructs entity boundaries for final predictions. Experiments show state-of-the-art F1-scores of 88.72 %, 82.53 %, 87.65 %, 94.46 %, 96.12 % and 88.67 % on ACE04, GENIA, ACE05, CoNLL03, MRSA and OntoNotes datasets.},
  archive      = {J_ESWA},
  author       = {Lin Cao and Zhongxue Jia and Benkui Zhang and Huanyu Bian and Fan Zhang and Kangning Du and Yanan Guo},
  doi          = {10.1016/j.eswa.2025.130094},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130094},
  shortjournal = {Expert Syst. Appl.},
  title        = {DEG-NER: Dynamic graph-enhanced diffusion model for named entity recognition},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MLENet: Multi-level efficient network based on single-scale feature extraction for human keypoint estimation. <em>ESWA</em>, <em>299</em>, 130092. (<a href='https://doi.org/10.1016/j.eswa.2025.130092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current methods use multi-scale feature fusion to improve human keypoint estimation accuracy. However, such methods are often computationally inefficient. To address this, we propose a Multi-Level Efficient Network (MLENet) that maintains single-scale features throughout the network and comprises three modules: Local Feature Extraction (LFE), Spatial Feature Extraction (SFE), and Global Feature Extraction (GFE). The objectives of this study are to improve keypoint estimation accuracy, maintain computational efficiency, and investigate the effect of combining these three modules. The LFE captures low-level features from the input image using convolutional blocks and incorporates Channel Squeeze Attention and Spatial Squeeze Attention to enhance overall performance. The GFE employs self-attention to capture global dependencies in high-level features and leverage position-wise information to improve Transformer robustness. In contrast, the SFE extracts middle-level features by separating feature channels into several identical spaces and applying multiple convolutions to obtain mixed features. By integrating low-middle-high multi-level feature extraction, MLENet facilitates complementary feature learning throughout the network. Extensive experiments confirm that MLENet outperforms most current state-of-the-art methods on COCO and MPII datasets while being more efficient than mainstream multi-scale fusion architectures, showing that the combination of the proposed three modules effectively enhances keypoint localization performance. The source code will be publicly available at: https://github.com/wangdong0556/MLENet .},
  archive      = {J_ESWA},
  author       = {Dong Wang and Youcheng Cai and Yiming Tang and Wenjun Xie and Xiaoping Liu},
  doi          = {10.1016/j.eswa.2025.130092},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130092},
  shortjournal = {Expert Syst. Appl.},
  title        = {MLENet: Multi-level efficient network based on single-scale feature extraction for human keypoint estimation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Consciousness-ECG transformer for conscious state estimation system with real-time monitoring. <em>ESWA</em>, <em>299</em>, 130091. (<a href='https://doi.org/10.1016/j.eswa.2025.130091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conscious state estimation is important in various medical settings, including sleep staging and anesthesia management, to ensure patient safety and optimize health outcomes. Traditional methods predominantly utilize electroencephalography (EEG), which faces challenges such as high sensitivity to noise and the requirement for controlled environments. In this study, we propose the consciousness-ECG transformer that leverages electrocardiography (ECG) signals for non-invasive and reliable conscious state estimation. Our approach employs a transformer with decoupled query attention to effectively capture heart rate variability features that distinguish between conscious and unconscious states. We implemented the conscious state estimation system with real-time monitoring and validated our system on datasets involving sleep staging and anesthesia level monitoring during surgeries. Experimental results demonstrate that our model outperforms baseline models, achieving accuracies of 0.877 on sleep staging and 0.880 on anesthesia level monitoring. Moreover, our model achieves the highest area under curve values of 0.786 and 0.895 on sleep staging and anesthesia level monitoring, respectively. The proposed system offers a practical and robust alternative to EEG-based methods, particularly suited for dynamic clinical environments. Our results highlight the potential of ECG-based consciousness monitoring to enhance patient safety and advance our understanding of conscious states.},
  archive      = {J_ESWA},
  author       = {Young-Seok Kweon and Gi-Hwan Shin and Ji-Yong Kim and Bokyeong Ryu and Seong-Whan Lee},
  doi          = {10.1016/j.eswa.2025.130091},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130091},
  shortjournal = {Expert Syst. Appl.},
  title        = {Consciousness-ECG transformer for conscious state estimation system with real-time monitoring},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSEP: Dual-stage generative model with sequence-oriented labeling and element-to-tuple prompting improves aspect sentiment triplet extraction. <em>ESWA</em>, <em>299</em>, 130088. (<a href='https://doi.org/10.1016/j.eswa.2025.130088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative methods have made significant progress in the Aspect Sentiment Triplet Extraction (ASTE) task and have attracted widespread attention. However, existing studies typically adopt a single-stage generation strategy and do not fully explore the potential of step-by-step generation. In this paper, we propose the DGSEP (Dual-stage generative model with sequence-oriented labeling and element-to-tuple prompting improves aspect sentiment triplet extraction) framework to address this gap. The DGSEP framework adopts a dual-stage process. In the first step, we independently predict each individual element (i.e., aspect, sentiment, and opinion terms) as candidates for the subsequent step. In the second step, these candidates are mapped and ultimately refined into relevant aspect-sentiment triplets. To further enhance the performance of the DGSEP framework, we introduce two innovative strategies, namely DGSEP ( S 1 ) and DGSEP ( S 2 ), which not only significantly improve data augmentation effects but also incorporate different prompt templates. Additionally, we propose a label-oriented sequence label generation fusion module (LSGF), which aims to fuse T5-based and label-oriented sequence labels to improve the ability of the generation model to handle complex structures. Through comprehensive analysis on various benchmarks, we demonstrate that DGSEP achieves state-of-the-art results in nearly all cases.},
  archive      = {J_ESWA},
  author       = {Yujun Chen and Mingwei Tang and Shangyi Du and Kun Yang and Yanxi Zheng and Mingfeng Zhao},
  doi          = {10.1016/j.eswa.2025.130088},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130088},
  shortjournal = {Expert Syst. Appl.},
  title        = {DGSEP: Dual-stage generative model with sequence-oriented labeling and element-to-tuple prompting improves aspect sentiment triplet extraction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language foundation model for leaf disease identification. <em>ESWA</em>, <em>299</em>, 130084. (<a href='https://doi.org/10.1016/j.eswa.2025.130084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaf disease identification plays a pivotal role in smart agriculture. However, many existing studies still struggle to integrate image and textual modalities to compensate for each other’s limitations. Furthermore, many of these approaches rely on pretraining with constrained datasets such as ImageNet, which lack domain-specific information. The research proposes SCOLD (Soft-target COntrastive learning for Leaf Disease identification), a context-aware vision-language foundation model tailored to domain-specific tasks in smart agriculture. SCOLD is developed using a diverse corpus of plant leaf images and corresponding symptom descriptions, comprising over 186,000 image-captions pairs aligned with 97 unique concepts. Through task-agnostic pretraining, SCOLD leverages contextual soft targets to mitigate overconfidence in contrastive learning by smoothing labels, thereby improving model generalization and robustness on fine-grained classification tasks. Experimental results demonstrate that SCOLD outperforms existing Vision-language models (VLMs) such as LLaVA 1.5, Qwen-VL 2.5, OpenAI-CLIP-L, BioCLIP, and SigLIP2 across several benchmarks, including zero-shot and few-shot classification, image-text retrieval, and image classification, while maintaining a competitive parameter footprint. Ablation studies further highlight SCOLD’s effectiveness in contrast to its counterparts. The proposed approach significantly advances the agricultural vision-language foundation model, offering strong performance with minimal or no supervised fine-tuning. This work lays a solid groundwork for future research on models trained with long-form and simplified contexts, tasks involving class ambiguity, and multi-modal systems for intelligent plant disease diagnostics. The code for this study is available at https://huggingface.co/enalis/scold .},
  archive      = {J_ESWA},
  author       = {Khang Nguyen Quoc and Lan Le Thi Thu and Luyl-Da Quach},
  doi          = {10.1016/j.eswa.2025.130084},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130084},
  shortjournal = {Expert Syst. Appl.},
  title        = {A vision-language foundation model for leaf disease identification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An overview of multi-attribute auctions: Bibliometrics, methodologies, applications and future directions. <em>ESWA</em>, <em>299</em>, 130083. (<a href='https://doi.org/10.1016/j.eswa.2025.130083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute auctions are efficient and popular transaction mechanisms that consider price attribute and non-price attributes such as quality, quantity and delivery time to support bids. The incorporation of multiple attributes allows multi-attribute auctions to adapt the complex markets better and meet diverse requirements of both bidders and auctioneers. Multi-attribute auctions have been applied to solve practical problems such as items procurement, resources allocation and suppliers selection. Aiming to exhibit the research status and identify challenges in multi-attribute auctions, this work gives an overview of multi-attribute auctions based on 410 papers published during 1991–2024 and screened from the Web of Science Core Collection database. A bibliometric analysis is provided to pinpoint the hotspots of multi-attribute auctions. Classifications of multi-attribute auctions are presented to clarify the meaning of different auction formats. Multi-attribute auction approaches are summarized from four perspectives containing decision making, game theory, behavioral economics and experimental analysis. The main application areas including industrial engineering, electronic commerce, information technology, energy management and environment management of multi-attribute auctions are recalled. The current research status and future research directions are highlighted. It is hoped that our work can provide enlightenment for scholars in the domain of multi-attribute auctions.},
  archive      = {J_ESWA},
  author       = {Yuhang Cai and Huchang Liao},
  doi          = {10.1016/j.eswa.2025.130083},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130083},
  shortjournal = {Expert Syst. Appl.},
  title        = {An overview of multi-attribute auctions: Bibliometrics, methodologies, applications and future directions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic feature fusion guiding and multimodal large language model refining for medical image report generation. <em>ESWA</em>, <em>299</em>, 130082. (<a href='https://doi.org/10.1016/j.eswa.2025.130082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image report generation refers to the automatic generation of text descriptions that correspond to specific medical images. In recent years, the increasing demand for medical imaging from both patients and healthcare institutions has significantly increased radiologists’ workloads. Concurrently, shortages in medical resources and diagnostic capabilities have raised the risks of diagnostic delays and misinterpretations in medical imaging. To alleviate the burden on medical professionals and ensure accurate diagnoses, the task of automated medical report generation has attracted a growing number of researchers. In this context, systems based on deep learning methods combined with general Large Language Models (LLMs) have been developed. However, existing methods face limitations in effectively integrating visual and textual data and they ignore the fact that the contributions of different modalities to diagnostic results vary across cases. Additionally, these approaches fail to address the lack of specialized medical knowledge when applying general LLMs. This paper introduces the Dynamic Feature Fusion Guiding and Multimodal Large Language Model Refining (DFFG-MLLMR) framework, which addresses these limitations through two key components:(1) The DFFG module dynamically adjusts the contributions of visual and textual features based on their diagnostic relevance, ensuring optimal feature utilization for report generation; (2) The MLLMR module integrates visual retrieval methods with fine-tuned LLMs to generate comprehensive and accurate medical reports. Our method achieves quantitatively superior results to other baseline methods on both benchmark datasets. On the IU-Xray dataset, DFFG-MLLMR achieves BLEU-4 of 0.191 and CIDEr of 0.574, exceeding the best conventional approach Token-Mixer. On the MIMIC-CXR dataset, our method achieves BLEU-4 of 0.132 and CIDEr of 0.289, improving upon Token-Mixer by 0.008 and 0.126. Experiments on public datasets demonstrate the superiority of DFFG-MLLMR, showing significant improvements in cross-modal feature fusion performance and enhanced diagnostic quality in automated reports. Furthermore, ablation studies confirm that the DFFG and MLLMR modules contribute complementary improvements, collectively enhancing the accuracy and clinical reliability of reports. The code can be obtained at https://github.com/BearLiX/DFFG-MLLMR .},
  archive      = {J_ESWA},
  author       = {Pu Han and Xiong Li and Shenqi Jing and Jianxiang Wei},
  doi          = {10.1016/j.eswa.2025.130082},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130082},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic feature fusion guiding and multimodal large language model refining for medical image report generation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An effective hypergraph influence blocking maximization strategy via neighbor approximate influence estimation. <em>ESWA</em>, <em>299</em>, 130081. (<a href='https://doi.org/10.1016/j.eswa.2025.130081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid development of society and the continuous advancement of network technology, various types of information can spread through networks. To prevent the spread of negative information, most existing studies focus on selecting positive nodes as a strategy to counter it. However, higher-order relationships are widespread and significant in real life, but these approaches often overlook this. Therefore, this paper first introduces the hypergraph influence blocking maximization (HIBM) problem, defines the hypergraph competitive independent cascade (HCIC) diffusion model, and proves that the problem has the properties of monotonicity and submodularity. To address this problem, we propose an effective negative information blocking algorithm, named as HNAIE. The algorithm starts with a neighbor approximate influence blocking estimation method to reduce the computational complexity of evaluating the blocking capacity of target nodes against negative information. It then uses this method to calculate the blocking gain of each inactive node and the node with the highest blocking gain is added to the positive seed set. Finally, extensive experiments conducted on eight real world hypergraph datasets show that our algorithm’s performance in blocking the spread of negative information is comparable to that of the CELF-Greedy algorithm, and its running time is significantly reduced by server orders of magnitude. Furthermore, compared to several other baseline algorithms, our algorithm achieves a performance improvement of up to 5% in blocking negative influence. These findings strongly demonstrate the superiority of our proposed algorithm in efficiently blocking the spread of negative information.},
  archive      = {J_ESWA},
  author       = {Hai-Feng Zhang and Guang-Hui Xiong and Bing-Bing Xiang and Xian-Jie Zhang},
  doi          = {10.1016/j.eswa.2025.130081},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130081},
  shortjournal = {Expert Syst. Appl.},
  title        = {An effective hypergraph influence blocking maximization strategy via neighbor approximate influence estimation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WDAE-GAN: A hybrid dual autoencoder and generative adversarial framework with wavelet denoising for credit card fraud detection. <em>ESWA</em>, <em>299</em>, 130078. (<a href='https://doi.org/10.1016/j.eswa.2025.130078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud detection remains a critical challenge due to the severe class imbalance in real-world transaction datasets, where fraudulent cases represent only a minute fraction of total records. This study proposes WDAE-GAN, a hybrid detection framework that combines a Wasserstein Generative Adversarial Network (WGAN), dual autoencoders, wavelet-based denoising, and CatBoost classification. In this approach, the WGAN generates realistic synthetic fraud samples to augment the minority class, while dual autoencoders learn distinct latent representations from normal and fraud-augmented data. The concatenated latent features are refined through wavelet denoising before final classification by CatBoost, enhancing feature quality and reducing noise. Experimental results on two benchmark datasets—the European Credit Card Fraud Detection dataset and the IEEE-CIS Fraud Detection dataset—demonstrate that WDAE-GAN achieves near-perfect detection performance. On the European dataset, the model achieved a recall of 0.9999, precision of 0.9999, F1-score of 0.9999, AUC of 1.0000, and AUPRC of 0.9994. On the IEEE-CIS dataset, WDAE-GAN obtained a recall of 0.9994, precision of 0.9994, F1-score of 0.9994, AUC of 1.0000, and AUPRC of 0.9999. These results show that the proposed model not only delivers exceptional detection accuracy but also performs competitively against state-of-the-art methods, effectively identifying rare fraud instances while maintaining an extremely low false-positive rate. This confirms WDAE-GAN’s robustness and scalability for real-world financial fraud detection applications.},
  archive      = {J_ESWA},
  author       = {Masoud RezvaniNejad and Ali Sabzali Yameqani},
  doi          = {10.1016/j.eswa.2025.130078},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130078},
  shortjournal = {Expert Syst. Appl.},
  title        = {WDAE-GAN: A hybrid dual autoencoder and generative adversarial framework with wavelet denoising for credit card fraud detection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical attention-driven multimodal local to global learning framework for enhanced drug-target interaction prediction. <em>ESWA</em>, <em>299</em>, 130076. (<a href='https://doi.org/10.1016/j.eswa.2025.130076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of drug-target interactions (DTIs) can effectively prompt drug development and lower expenses. However, existing DTI prediction methods based on multimodal and deep learning have limitations in effectively extracting local and global information from drugs and targets, as well as cross-modal and cross-entity fusion. Therefore, this study presents a Hierarchical Attention-Driven Multimodal Local to Global Learning Framework (HADLGL-DTI) for drug-target interaction prediction. The framework incorporates three novel modules: a hybrid drug representation learning module, a multi-scale target encoding module, and a hierarchical attention-driven multimodal fusion module. In the drug representation module, we integrate atomic and chemical bond features to model drug molecular graphs. Simultaneously, a CNN-LSTM (Convolutional Neural Network-Long Short Term Memory) architecture is introduced to capture both local and long-range dependencies within SMILES sequences. In the target representation module, we present a multi-scale target encoding module to jointly encode and fuse target sequences and their k-mer sequences across multiple scales, enabling the model to extract target features from local to global levels effectively. Furthermore, we design a hierarchical attention-driven multimodal fusion method to capture the inter-modal and inter-entity interactions between drugs and targets. A comprehensive evaluation of HADLGL-DTI and state-of-the-art (SOTA) models is conducted on representative public datasets, and the experimental results show that this proposed HADLGL-DTI outperforms the SOTAs in predicting drug-target interactions, which achieves an overall performance improvement of a maximum improvement of 44.6 % . Moreover, to better simulate real-world scenarios, we have extended cold drug scenarios, imbalanced datasets, and case studies for further experimental verification. The results show our model’s promising ability to predict targets for novel drugs. This model also provides a practical tool to accelerate the drug development pipeline.},
  archive      = {J_ESWA},
  author       = {Hui Chen and Mengyuan Jin and Miguel Baptista Nunes and Fang Hu and Yin Zhang},
  doi          = {10.1016/j.eswa.2025.130076},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130076},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hierarchical attention-driven multimodal local to global learning framework for enhanced drug-target interaction prediction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive study of UK climate change policies based on complex systems modeling: Evidence from 2001 to 2020. <em>ESWA</em>, <em>299</em>, 130073. (<a href='https://doi.org/10.1016/j.eswa.2025.130073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The United Kingdom is a highly industrialized and economically developed country, with greenhouse gas (GHGs) emissions historically well above the global average, thereby significantly contributing to global climate change. Over the past two decades, the UK government has introduced a range of measures to mitigate emissions, such as enacting legislation and employing market-based mechanisms. Between 2001 and 2020, the number of climate policies issued by the government and think tanks increased by 73 and 171 times, respectively, accompanied by a 43% reduction in GHGs and a 44% reduction in CO 2 emissions. Although prior research has identified a negative correlation between policy quantity and emissions, the relative importance of specific policy themes remains unclear. In this study, we employed the Latent Dirichlet Allocation (LDA) model to identify key thematic topics within UK climate policies published from 2001 to 2020. Subsequently, Partial Least Squares (PLS) regression was applied to quantify the contribution of each policy theme to reductions in GHGs emissions. Our quantitative results show that policies emphasizing themes such as “climate”, “carbon”, “greenhouse”, “gas”, and “low” accounted for 73.3% of the total emission reduction. Furthermore, we modeled the policy system as a complex network to assess structural interactions. These findings provide actionable insights for policymakers seeking to design more effective climate strategies.},
  archive      = {J_ESWA},
  author       = {Weiyi Jiang and Yihang Hong and Chun Xia Yang},
  doi          = {10.1016/j.eswa.2025.130073},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130073},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comprehensive study of UK climate change policies based on complex systems modeling: Evidence from 2001 to 2020},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GATOC: Learning temporal abstraction with the option transition graph attention mechanism. <em>ESWA</em>, <em>299</em>, 130071. (<a href='https://doi.org/10.1016/j.eswa.2025.130071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical reinforcement learning methods aim to learn temporal abstraction to uncover the hierarchical structure of tasks, which supports agents in making decisions on variable time scales. Existing option-based methods can discover temporal abstraction in an end-to-end manner by learning the components of options; however, their performance in complex tasks is hindered by a limited initial number of options and inefficient update frequencies. In order to enhance the diversity of options and the utilization of samples, this paper approaches the learning and utilization of options from a graph-based perspective: the historical information regarding option transitions from SMDPs is incorporated into the decision-making process in the form of a graph. We propose the Graph Attention Option Critic (GATOC) framework, which consists of a skill aggregation module and a fusion scheduling module. Both modules employ the graph attention mechanism; the former merges the relevant options, while the latter determines when to terminate an option for subsequent skill selection. We conducted experimental validation on challenging robotic simulation tasks, and the results indicate that GATOC outperforms previous option-based methods in both single-task and task transfer settings.},
  archive      = {J_ESWA},
  author       = {He Diao and Shan Zhong and Jian Chen and Jingkui Zhang and Jiacheng He and Ping Zhang and Gang Wang and Zhenyu Feng and Bei Peng},
  doi          = {10.1016/j.eswa.2025.130071},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130071},
  shortjournal = {Expert Syst. Appl.},
  title        = {GATOC: Learning temporal abstraction with the option transition graph attention mechanism},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SALARec: Dual-alignment contrastive learning with preference-aware adversarial augmentation for sequential recommendation. <em>ESWA</em>, <em>299</em>, 130070. (<a href='https://doi.org/10.1016/j.eswa.2025.130070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation plays a critical role in modern recommender systems, but its performance is often hindered by sparse user interactions and limited informative signals. To alleviate this, contrastive learning (CL) has recently gained attention as a powerful tool for enhancing representation learning by aligning user behavior sequences from different augmented views. However, existing CL-based methods typically align only the final-layer representations of two views, overlooking the layer-wise representation evolution throughout the encoder. Moreover, common augmentation strategies such as masking or reordering can disrupt the intrinsic sequential structure and distort the original semantics. To address these issues, we propose Self-Alignment and Layer-Aware Recommendation (SALARec), a general CL framework for sequential recommendation. SALARec is built on a novel dual alignment strategy that simultaneously enforces consistency across augmented views at each layer and across adjacent layers within the same view. Specifically, we introduce two complementary contrastive tasks: (1) a layer-wise cross-view contrastive task, leveraging a preference-aware adversarial noise augmentation strategy to generate semantically meaningful perturbations and improve view robustness; and (2) an intra-view cross-layer contrastive task, which performs self-alignment between adjacent layers to promote progressive semantic consistency. Extensive experiments on benchmark datasets demonstrate that SALARec consistently outperforms state-of-the-art methods, demonstrating its effectiveness and robustness in learning high-quality sequence representations for recommendation tasks in sparse and real-world scenarios.},
  archive      = {J_ESWA},
  author       = {Peizheng Wang and Wanna Cui},
  doi          = {10.1016/j.eswa.2025.130070},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130070},
  shortjournal = {Expert Syst. Appl.},
  title        = {SALARec: Dual-alignment contrastive learning with preference-aware adversarial augmentation for sequential recommendation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bridging the safety-specific language model gap: Domain-adaptive pretraining of transformer-based models across several industrial sectors for occupational safety applications. <em>ESWA</em>, <em>299</em>, 130068. (<a href='https://doi.org/10.1016/j.eswa.2025.130068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupational safety remains a persistent global challenge despite advancements in regulatory frameworks and safety technologies. Unstructured incident narratives, such as accident reports and safety logs, offer valuable context for understanding workplace hazards but are underutilized due to the gap in the safety-specific language models. This study addresses that gap by adapting pretrained transformer-based models (BERT and ALBERT) to the occupational safety domain through Domain-Adaptive Pretraining (DAPT). We construct a large-scale, multi-source corpus comprising over 2.4 million documents spanning several industrial sectors, including mining, construction, transportation, and chemical processing, augmented with safety-related academic abstracts to preserve general linguistic understanding and mitigate catastrophic forgetting. Using this corpus, we develop two domain-adapted models, safetyBERT and safetyALBERT, through continual pretraining on the masked language modeling objective. Intrinsic evaluation using pseudo-perplexity (PPPL) demonstrates substantial improvements, with safetyBERT and safetyALBERT achieving 76.9% and 90.3% reductions in PPPL, respectively, over their general-domain counterparts. Extrinsic evaluation on the Mine Safety and Health Administration (MSHA) injury dataset across three classification tasks (accident type, mining equipment, and degree of injury) demonstrated consistent performance improvements, with both models outperforming diverse baseline models including general-purpose models (BERT, ALBERT, DistilBERT, RoBERTa), domain-specific scientific model (SciBERT), and large language model (Llama 3.1-8B), with safetyALBERT achieving competitive results despite its parameter-efficient design.. To further assess generalization in low-resource settings, these models were evaluated on the small-scale Alaska insurance claim dataset from mining industry across two classification tasks − claim type and injured body part. Both safetyBERT and safetyALBERT maintained strong performance under this constraint, demonstrating the value of domain adaptation for data-constrained environments. Additionally, multi-task classification on the MSHA dataset using safety domain models showed improved generalization and more balanced performance across underrepresented classes. These findings confirm that DAPT effectively enhances language understanding in safety–critical domains while enabling scalable, resource-efficient deployment. This work lays the foundation for integrating domain-adapted natural language processing (NLP) systems into occupational health and safety management frameworks.},
  archive      = {J_ESWA},
  author       = {Abid Ali Khan Danish and Snehamoy Chatterjee},
  doi          = {10.1016/j.eswa.2025.130068},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130068},
  shortjournal = {Expert Syst. Appl.},
  title        = {Bridging the safety-specific language model gap: Domain-adaptive pretraining of transformer-based models across several industrial sectors for occupational safety applications},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H-HRGAN: Knowledge graph-driven representation for missing value imputation. <em>ESWA</em>, <em>299</em>, 130067. (<a href='https://doi.org/10.1016/j.eswa.2025.130067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data presents a major challenge in real-world applications, as traditional imputation methods like one-hot encoding and statistical heuristics have difficulty capturing the complex semantic relationships and dependencies among discrete features. To address this, we introduce the Heterogeneous-Homogeneous Relational Graph Attention Network (H-HRGAN), a new framework designed for efficiently imputing missing values in structured data. H-HRGAN models structured data as nodes and relations, effectively capturing rich semantic and co-occurrence patterns. It uses a hierarchical graph structure to model both heterogeneous attribute-value relationships and homogeneous dependency patterns, enabling strong feature interactions. By incorporating a relational subgraph learning mechanism within a Graph Neural Network (GNN), H-HRGAN performs context-aware feature aggregation through multi-level reasoning. Additionally, a multi-scale dynamic convolution with channel attention is used to capture complex entity-relation interactions, improving the accuracy of missing value predictions. Extensive experiments on various real-world datasets show that H-HRGAN significantly surpasses state-of-the-art imputation and knowledge graph completion (KGC) methods, achieving higher accuracy and robustness, especially in scenarios with high missingness rates and complex dependencies.},
  archive      = {J_ESWA},
  author       = {Hanlin Deng and Guohui Zhou and Yong Deng and Wei He and Yanling Cui and Hailong Zhu},
  doi          = {10.1016/j.eswa.2025.130067},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130067},
  shortjournal = {Expert Syst. Appl.},
  title        = {H-HRGAN: Knowledge graph-driven representation for missing value imputation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FreLinear: Spectral-aware design and acceleration for efficient graph neural networks. <em>ESWA</em>, <em>299</em>, 130066. (<a href='https://doi.org/10.1016/j.eswa.2025.130066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) excel in modeling graph-structured data but often face significant computational costs and fail to capture high-frequency components critical for fine-grained local variations. We propose FreLinear, a novel framework that integrates spectral-domain analysis with an efficient linear-attention mechanism. By avoiding the quadratic complexity inherent in traditional Transformer architectures, FreLinear leverages Fourier-based spectral features to enhance sensitivity to local structures while achieving near-linear computational complexity. Extensive experiments across diverse benchmark datasets demonstrate that FreLinear consistently surpasses state-of-the-art GNNs, delivering superior accuracy with significantly reduced computational overhead. On eight public datasets such as arxiv and Citeseer, the running time was shortened by 1 to 3 times with an increase in the number of parameters. At the same time, on the node classification task, the performance was improved by an average of 1.4 percentage points compared to the previous best work in these eight datasets. The code for the method proposed in our paper is publicly available on https://github.com/SWLee777/Frelinear .},
  archive      = {J_ESWA},
  author       = {Xuefeng Li and Zhengyuan Wang and Chensu Zhao and Xiaqiong Fan and Xinxin Zhang and Honglin Xie},
  doi          = {10.1016/j.eswa.2025.130066},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130066},
  shortjournal = {Expert Syst. Appl.},
  title        = {FreLinear: Spectral-aware design and acceleration for efficient graph neural networks},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AHDPC: Adaptively hyperbolic density peak clustering. <em>ESWA</em>, <em>299</em>, 130065. (<a href='https://doi.org/10.1016/j.eswa.2025.130065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-uniformly distributed datasets are common in real-world, and density peak clustering (DPC) methods are used on these datasets due to their superior clustering performance. However, existing DPC relies on linearly growing Euclidean distance, causing misleading similarity between points from different clusters and limiting the improvement of accuracy. To overcome this limitation, this study introduces an adaptive hyperbolic density peak clustering algorithm (AHDPC) by extending DPC into hyperbolic space. First, linear Euclidean distance is replaced with exponentially growing hyperbolic distance to enhance density difference between different points. Then, to overcome the misclassification of points at the junction of high-density and low-density regions and errors from extreme hyperbolic distance, a novel adaptive weighting strategy is proposed, it dynamically adjusts hyperbolic distance by building the trace of the global covariance matrix, the Euclidean norm, the maximum pairwise distance, and point-to-center deviation. Finally, an adaptively cutoff distance method based on a segmented search strategy is developed to eliminate manual tuning, and an exponential density function replaces the gaussian kernel to improve computational efficiency. AHDPC not only overcomes the deficiencies of Euclidean space but also mitigates the restrictive aspects of hyperbolic space. Extensive experiments on synthetic and real datasets, the olivetti faces dataset, and medical image datasets demonstrate that AHDPC outperforms state-of-the-art methods in clustering accuracy. Results also show that AHDPC produces more discriminative decision graph for identifying cluster centers and enhances the accuracy of categorisation of non-center points. The advantages of its robustness and adaptive weight in improving the clustering performance are also confirmed.},
  archive      = {J_ESWA},
  author       = {Jinglong Wang and Yu Zhang and Changju Liu and Jiangtao Xu},
  doi          = {10.1016/j.eswa.2025.130065},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130065},
  shortjournal = {Expert Syst. Appl.},
  title        = {AHDPC: Adaptively hyperbolic density peak clustering},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSA mamba: A model for advanced medical image classification. <em>ESWA</em>, <em>299</em>, 130064. (<a href='https://doi.org/10.1016/j.eswa.2025.130064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image classification faces two persistent challenges: the difficulty of traditional models in simultaneously capturing both local details and global context, leading to insufficient extraction of key diagnostic features; and the high computational complexity of self-attention mechanisms, which hinders real-time diagnostic applications. To address these limitations, we propose DSA Mamba, a novel lightweight architecture featuring a Dual Mamba Block for parallel multi-scale feature extraction and a Self-Cross-Channel Attention (SCCA) module for superior feature fusion. Our model demonstrates significant and quantifiable performance gains over established methods. Specifically, it achieves 93.15 % accuracy on the FETAL_PLANES_DB dataset, surpassing the prominent Swin-Transformer (90.34 %) by 2.81 %. On the MedMNIST 2D benchmark, it demonstrates state-of-the-art performance, including 99.2 % accuracy on the PathMNIST subset. With a compact parameter count of 30 million,our model is comparable to Swin-Transformer (28M), notably more compact than Spatial Mamba (43M) and nearly 3x smaller than ViT (86M), DSA Mamba offers significant advantages in computational efficiency and training convergence speed compared to larger transformer-based architectures, making it highly suitable for real-world clinical applications. The code is available at https://github.com/First-Ronin/DSA-Mamba .},
  archive      = {J_ESWA},
  author       = {Zhiwen Wang and Haoyu Yin and Jilin Yu and Mengsi Gong and Qi Chen and Qiaoqiao Chen and Zhenlin He and Danying Wang},
  doi          = {10.1016/j.eswa.2025.130064},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130064},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSA mamba: A model for advanced medical image classification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal quantum-inspired network for emotion recognition. <em>ESWA</em>, <em>299</em>, 130063. (<a href='https://doi.org/10.1016/j.eswa.2025.130063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion Recognition in Conversations (ERC) is a prominent research topic in Natural Language Processing (NLP). Most current approaches rely on deep black-box models, which lack sufficient interpretability. To this end, some work inspired by quantum theory has been proposed, trying to explore new solutions with the help of uncertainty modeling. However, these methods fail to fully integrate useful information within conversations, and overlook many effective classical mechanisms when employing quantum probabilistic modeling. In this paper, we propose a multimodal quantum-inspired network (MQN) to tackle these challenges from the perspectives of feature embedding and information fusion. We design a conversation-oriented feature embedding (CFE) method to effectively encode useful information in conversations and establish global interaction through phase embedding. Additionally, we introduce a joint information fusion (JIF) method that incorporates attention and gating mechanisms to enhance intra-modal feature representation and inter-modal interactions in multimodal fusion. Experimental results on two benchmark ERC datasets demonstrate that our model outperforms other quantum-inspired models and achieves performance comparable to state-of-the-art methods, providing a novel perspective for conversation emotion recognition.},
  archive      = {J_ESWA},
  author       = {Zimeng Xiao and Jia Liao and Jinjing Shi and Shichao Zhang and Xuelong Li},
  doi          = {10.1016/j.eswa.2025.130063},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130063},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal quantum-inspired network for emotion recognition},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Digital twin-based anomaly detection under concept drift: A comparison between iterative batch learning and incremental learning approaches. <em>ESWA</em>, <em>299</em>, 130062. (<a href='https://doi.org/10.1016/j.eswa.2025.130062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Twins enable continuous monitoring of manufacturing systems and support data-driven anomaly detection. This paper investigates three approaches within a Digital Twin framework: (i) a statistical baseline method based on predefined thresholds, (ii) iterative batch learning using Isolation Forests, periodically retrained with operator feedback, and (iii) incremental learning with Half-Space Trees that update models in real time. A simulated assembly line subject to conveyor perturbations was used to generate datasets representing normal operations, mean shifts, and variance changes. Results indicate that thresholding performs well in simple scenarios but produces numerous false positives under complex drift conditions. Batch learning achieves stable performance with retraining but struggles with abrupt changes and requires operator input. Incremental learning adapts more effectively to evolving conditions with low latency, although its performance depends on careful parameter tuning and may occasionally miss anomalies.},
  archive      = {J_ESWA},
  author       = {Farah Abdoune and Maroua Nouiri and Olivier Cardin},
  doi          = {10.1016/j.eswa.2025.130062},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130062},
  shortjournal = {Expert Syst. Appl.},
  title        = {Digital twin-based anomaly detection under concept drift: A comparison between iterative batch learning and incremental learning approaches},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic link prediction in construction innovation networks: An integrated framework of topological and content attributes. <em>ESWA</em>, <em>299</em>, 130061. (<a href='https://doi.org/10.1016/j.eswa.2025.130061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the evolution of collaborative relationships in construction innovation organizations is crucial for optimizing subsequent innovation decisions and developing inter-organizational collaboration strategies. Regrettably, prior research has accorded limited attention to link prediction within construction innovation collaborative networks. Consequently, this study introduces a novel link prediction approach that forecasts inter-node connectivity relationships by integrating topological structure characteristics and node content attributes of these networks. The proposed metrics leverage primary and secondary measures based on temporal events to assess the influence of nodes and their neighbors on the prediction outcomes. Through a comprehensive set of experiments, the study systematically assessed the performance of the proposed metrics across diverse link prediction scenarios. The results indicate that the proposed metric consistently outperforms several well-established baseline methods, yielding highly encouraging outcomes. This research not only enriches the theoretical underpinnings of network link prediction and construction innovations but also provides valuable insights into the evolution of collaborative relationships and the identification of potential partners within innovation organizations.},
  archive      = {J_ESWA},
  author       = {Yajiao Chen and Qinghua He and Xiaoyan Chen and Likai Zheng},
  doi          = {10.1016/j.eswa.2025.130061},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130061},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic link prediction in construction innovation networks: An integrated framework of topological and content attributes},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EMOCSO: An efficient multi-objective competitive swarm optimizer for large-scale optimization. <em>ESWA</em>, <em>299</em>, 130060. (<a href='https://doi.org/10.1016/j.eswa.2025.130060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-objective optimization problems (LSMOPs) are crucial in real-world applications where balancing conflicting objectives is essential for decision-making. To overcome this limitation, we propose an efficient Multi-objective Competitive Swarm Optimizer (EMOCSO). The algorithm introduces three key innovations: (1) an Archive-driven Winner Learning Strategy that uses elite solutions to guide the search, (2) a Dual-layer Differential Neutral Update Mechanism to enhance diversity by adaptively updating “neutral” individuals (solutions with similar fitness), and (3) a Selective Spiral Archive Update Strategy to refine solutions through spiral-based local search. Comprehensive experiments on the LSMOP benchmark show that EMOCSO outperforms five state-of-the-art algorithms, demonstrating superior convergence and diversity in high-dimensional optimization scenarios. Moreover, in the application of active power allocation for regional photovoltaic clusters driven by meteorological data, EMOCSO effectively balances multiple objectives such as following dispatch instructions, stabilizing power output, and controlling uncertainty, providing operable solutions for actual power grid dispatching and verifying its engineering practical value.},
  archive      = {J_ESWA},
  author       = {Wuxin Li and Jie Yang and Huiduo Wang and Yanhong Wang},
  doi          = {10.1016/j.eswa.2025.130060},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130060},
  shortjournal = {Expert Syst. Appl.},
  title        = {EMOCSO: An efficient multi-objective competitive swarm optimizer for large-scale optimization},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BandCondiNet: Parallel transformers-based conditional popular music generation with multi-view features. <em>ESWA</em>, <em>299</em>, 130059. (<a href='https://doi.org/10.1016/j.eswa.2025.130059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional music generation offers significant advantages in terms of user convenience and control, presenting great potential in AI-generated content research. However, building conditional generative systems for multitrack popular songs presents three primary challenges: insufficient fidelity of input conditions, poor structural modeling, and inadequate inter-track harmony learning in generative models. To address these issues, we propose BandCondiNet, a conditional model based on parallel Transformers, designed to process the multiple music sequences and generate high-quality multitrack samples. Specifically, we propose multi-view features across time and instruments as high-fidelity conditions. Moreover, we propose two specialized modules for BandCondiNet: Structure Enhanced Attention (SEA) to strengthen the musical structure, and Cross-Track Transformer (CTT) to enhance inter-track harmony. We conducted both objective and subjective evaluations on two popular music datasets with different sequence lengths. Objective results on the shorter dataset show that BandCondiNet outperforms other conditional models in 9 out of 10 metrics related to fidelity and inference speed , with the exception of Chord Accuracy. On the longer dataset, BandCondiNet surpasses all conditional models across all 10 metrics. Subjective evaluations across four criteria reveal that BandCondiNet trained on the shorter dataset performs best in Richness and performs comparably to state-of-the-art models in the other three criteria, while significantly outperforming them across all criteria when trained on the longer dataset. To further expand the application scope of BandCondiNet, future work should focus on developing an advanced conditional model capable of adapting to more user-friendly input conditions and supporting flexible instrumentation.},
  archive      = {J_ESWA},
  author       = {Jing Luo and Xinyu Yang and Dorien Herremans},
  doi          = {10.1016/j.eswa.2025.130059},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130059},
  shortjournal = {Expert Syst. Appl.},
  title        = {BandCondiNet: Parallel transformers-based conditional popular music generation with multi-view features},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AMST-net: An adaptive multi-scale transformer dual encoder network for skin lesion segmentation. <em>ESWA</em>, <em>299</em>, 130058. (<a href='https://doi.org/10.1016/j.eswa.2025.130058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer has become a prevalent and concerning disease affecting modern populations. Although dermoscopy is a standard approach for screening skin cancer, the subsequent analysis and diagnosis process is notably time-consuming and requires specialized expertise. With the advancements in deep learning models, many of them have also succeeded in medical segmentation tasks. However, some challenges still hinder the development of automatic skin lesion segmentation. For example, in most dermatoscopic images, the skin lesion’s color, texture, shape, size, and position vary randomly. This paper proposes a novel network called AMST-Net, which adopts a dual encoder structure to address the challenges. One encoder branch utilizes a lightweight multi-scale Transformer Encoder, generating four layers of coarse and fine features with different resolutions, while the other encoder uses a typical CNN architecture. Unlike previous methods that fuse a single layer of Transformer information, our approach hierarchically aggregates the four different resolution features into the CNN downsampling process. This adaptive multilayer Transformer structure not only increases the network’s global perceptual field but also improves the accuracy of segmentation boundary details. Additionally, we propose the CMSP-ECA module, a cascaded multi-scale pooling module-based efficient channel attention mechanism. This module enhances channel attention by extracting representative features and effectively restores boundary details and local information. Furthermore, an efficient global context fusion module is proposed to maintain the integrity of small segmented regions, significantly improving the network’s robustness in handling objects of various sizes and scales, and further enhancing segmentation accuracy. Extensive experiments conducted on three public skin lesion segmentation dataset,including ISIC2017,ISIC2018,and PH2 datasets, achieving an IoU value of 75.79 % , 81.48 % ,and 87.42 % respectively, outperforming state-of-the-art approaches in both visual comparisons and quantitative evaluations. Ablation studies validate the effectiveness of our AMST-Net. Our approach presents a novel and effective solution for skin lesion segmentation with potential clinical and medical imaging.},
  archive      = {J_ESWA},
  author       = {Ba Gao and Lina Yang and Yunguang Guan and Haoyan Yang and Changxin Liu and Yifeng Tan},
  doi          = {10.1016/j.eswa.2025.130058},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130058},
  shortjournal = {Expert Syst. Appl.},
  title        = {AMST-net: An adaptive multi-scale transformer dual encoder network for skin lesion segmentation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An online multi-agent path finding algorithm for large-scale puzzle-based conveyor system. <em>ESWA</em>, <em>299</em>, 130057. (<a href='https://doi.org/10.1016/j.eswa.2025.130057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Puzzle-based Conveyor System (PCS) is a modular logistics platform that relies on efficient path planning to maintain high throughput and operational efficiency. In this paper, we model agent routing on PCS as an online Multi-Agent Path Finding (MAPF) problem, which requires real-time, collision-free paths for agents. In PCS-based online MAPF, agents continuously enter the platform and disappear upon reaching their goals. Existing approaches are often unsuitable for large-scale online MAPF, while typical online MAPF solutions struggle to meet real-time requirements. To address these challenges, we propose OMA (Online MAPF Algorithm), an algorithm designed to find suboptimal solutions for snapshot-based planning in large-scale PCS in limited computation time. We first introduce the windowed space utilization optimization strategy to enhance solution quality, followed by Agent-based Grouping and Windowed Planning with Priority Cache methods to improve computational efficiency. Experimental results show that OMA outperforms mainstream MAPF methods, achieving up to 26 % higher throughput and 20 % faster computation times, offering an effective and scalable solution for online MAPF on PCS platforms.},
  archive      = {J_ESWA},
  author       = {Mingrui Yin and Hao Zhang and Chenxin Cai and Jie Liu},
  doi          = {10.1016/j.eswa.2025.130057},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130057},
  shortjournal = {Expert Syst. Appl.},
  title        = {An online multi-agent path finding algorithm for large-scale puzzle-based conveyor system},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FFEvent: Fast fourier-based knowledge transfer for event cameras. <em>ESWA</em>, <em>299</em>, 130055. (<a href='https://doi.org/10.1016/j.eswa.2025.130055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras, as an emerging imaging technology, offer distinct advantages over traditional RGB cameras, including reduced energy consumption and higher frame rates. However, the limited quantity of available event data presents a significant challenge, hindering their broader development. To address this challenge, we propose a modality-adaptive framework, FFEvent, for RGB-to-event knowledge transfer. By introducing domain adaptation, FFEvent enables event data to effectively leverage pre-trained RGB models and achieve competitive performance with minimal parameter tuning. Specifically, we introduce a bidirectional reverse state space model (BiR-SSM) within the FFEvent architecture. Unlike traditional bidirectional scanning, BiR-SSM introduces a shared-weight design that simultaneously models forward and reverse dependencies while significantly reducing computational overhead. Additionally, we design a fast fourier sparse convolution block (FFSConv), which combines frequency-domain global modeling with local spatial sparse convolution to efficiently capture the inherent sparsity of event data. Extensive experiments on event classification, object detection, and video deblurring demonstrate that FFEvent achieves state-of-the-art results across eight benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Yuhui Lin and Jiahao Zhang and Siyue Yu and Jimin Xiao and Jiaxuan Lu},
  doi          = {10.1016/j.eswa.2025.130055},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130055},
  shortjournal = {Expert Syst. Appl.},
  title        = {FFEvent: Fast fourier-based knowledge transfer for event cameras},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MFS-fusion: Mamba-integrated deep multi-modal image fusion framework with multi-scale fourier enhancement and spatial calibration. <em>ESWA</em>, <em>299</em>, 130054. (<a href='https://doi.org/10.1016/j.eswa.2025.130054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal image fusion (MMIF) significantly enhances visual quality and improves the accuracy of medical diagnoses by combining complementary information from multiple modalities. By integrating the strengths of various modalities, the unique characteristics of each can be leveraged to enhance image detail, contrast ratio, and overall visual quality in complex environments. However, current methodologies face substantial challenges in preserving image fidelity and achieving cross-modal coherence. Traditional spatial-domain approaches struggle with reconciling local structures and global frequency information, while cross-scale misalignment often leads to detail loss and inconsistencies across modalities. To address these challenges, we propose an innovative fusion framework, MFS-Fusion. The core of our design is two novel modules: a Multi-Scale Fourier Enhancement Module (MS-FEM) that innovatively models long-range interdependencies in the frequency domain to achieve global coherence, and a Cross-Scale Spatial Refinement Module (CS-SRM) that ensures precise feature alignment and edge preservation. Extensive experiments on several fusion tasks, including infrared-visible image fusion (IVIF) and medical image fusion (MIF), demonstrate that our method outperforms existing approaches in terms of detail retention, structural integrity, and information fidelity, effectively overcoming the challenges of cross-modal misalignment and detail loss. Furthermore, the fused images generated by MFS-Fusion significantly enhance the performance of downstream tasks, such as object detection and semantic segmentation. The code is publicly available at https://github.com/CrisT777-JN/MFS-Fusion .},
  archive      = {J_ESWA},
  author       = {Tao Chen and Chuang Wang and Yuanpeng Zhang and Kaijian Xia and Pengjiang Qian},
  doi          = {10.1016/j.eswa.2025.130054},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130054},
  shortjournal = {Expert Syst. Appl.},
  title        = {MFS-fusion: Mamba-integrated deep multi-modal image fusion framework with multi-scale fourier enhancement and spatial calibration},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Negative samples filter of contrastive learning for time series classification. <em>ESWA</em>, <em>299</em>, 130052. (<a href='https://doi.org/10.1016/j.eswa.2025.130052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an unsupervised learning method, contrastive learning has achieved remarkable success in the field of computer vision. However, issues such as false negative samples and hard negative samples can significantly impair its effectiveness. Addressing these issues is therefore crucial for improving contrastive learning. While current research on handling these challenges mainly focuses on image data, there is limited exploration of contrastive learning for time series data. In this paper, we propose a negative samples filter in the embedding space to investigate the impact of hard negative samples on time series contrastive learning. We conducted extensive experiments on six different time series datasets to examine the effect of the negative samples filter on classification performance, both in unsupervised and supervised settings. The results demonstrate that in the unsupervised case, some of the most difficult samples can degrade classification performance, while in the supervised case, more difficult samples are beneficial for classification. Furthermore, we applied our filter function to other contrastive learning baselines for time series, achieving superior results compared to previous baselines, and outperforming other baselines that address false negative and hard negative samples.},
  archive      = {J_ESWA},
  author       = {Yinlong Li and Licheng Pan and Hu Xu and Xinggao Liu},
  doi          = {10.1016/j.eswa.2025.130052},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130052},
  shortjournal = {Expert Syst. Appl.},
  title        = {Negative samples filter of contrastive learning for time series classification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Right-of-way based multi-agent deep reinforcement learning for collaborative decision-making at unsignalized intersection. <em>ESWA</em>, <em>299</em>, 130051. (<a href='https://doi.org/10.1016/j.eswa.2025.130051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent transportation, the vehicle-road cooperative system (VRCS) provides a new way for connected autonomous vehicles (CAVs) to achieve reliable cooperative driving at road intersection. In this paper, we orient to the mixed traffic scenario where CAVs and human-driven vehicles (HDVs) coexist, and propose a centralized right-of-way based decision-making framework under VRCS to address the challenge on safe-efficient traffic of CAVs at unsignalized intersection. We model the multi-vehicle driving problem at unsignalized intersection as multi-agent deep reinforcement learning (MADRL) problem, in which CAVs cooperatively learn policy to accommodate HDVs and safely enhance traffic efficiency. We develop a highly scalable MADRL algorithm for dynamic traffic flows, with the design of synergistic state spaces generic to different intentional CAVs based on conflict relationships. Parameter sharing is employed to achieve multi-intelligent agent policy scaling, while local reward mechanism is utilized to promote cooperation of agents. In addition, we design a right-of-way cooperator (RWC) for the proposed MADRL algorithm, which greatly reduces conflicts among vehicles and improves the training effect. Through comprehensive traffic simulation experiments with SUMO, the results show that the proposed approach improves traffic efficiency by at least 14.20 % and achieves zero collision rate compared to several current state-of-the-art approaches.},
  archive      = {J_ESWA},
  author       = {Ji Feng and Xiaofang Yuan and Zhe Li and Xiangcheng Pan and Kexin Liu},
  doi          = {10.1016/j.eswa.2025.130051},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130051},
  shortjournal = {Expert Syst. Appl.},
  title        = {Right-of-way based multi-agent deep reinforcement learning for collaborative decision-making at unsignalized intersection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-user game-based system for planning modular construction activities. <em>ESWA</em>, <em>299</em>, 130050. (<a href='https://doi.org/10.1016/j.eswa.2025.130050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain (SC) planning in modular construction (MC) can be challenging because it requires interconnected and complex activities among various teams and across different project stages. Recently, game engines have been increasingly used to resolve these challenges, as they create realistic virtual environments and simulations of possible scenarios before actual project implementation. However, game engine applications have been restricted to single-user and centralized models, limiting real-time collaboration among MC teams. Within a Design Science Research methodology, this study proposes an intelligent game-based modular planning (GAMMOD) system, supported by multi-user functions, which is flexible in terms of access, allowing for either non-immersive or immersive mode, depending on the available hardware tools, for collaborative planning of the MC-SC. The GAMMOD system integrates a blockchain protocol for data security in the non-immersive mode, while the immersive mode relies on user credentials authorization. The GAMMOD system considers both numerical key performance indicators, such as sustainability, cost, and time, as well as practical ones, including road dimensions, module clearance, and possible clashes. Two distinct case studies, representing different MC types, are presented to illustrate the features of the GAMMOD system. The evaluation tests of the GAMMOD system conducted by 14 MC experts have shown a general consensus on its functionality, with 80% to 100% of the participants agreeing or strongly agreeing on the GAMMOD system’s performance. Additionally, the GAMMOD system demonstrated a usability score of 75.7, surpassing the established threshold of 70. The GAMMOD system is expected to help MC stakeholders make informed, collaborative decisions and develop a shared understanding of decision feasibility, potential conflicts, and constraints before the commencement of the MC project.},
  archive      = {J_ESWA},
  author       = {Mohamed Assaf and Sena Assaf and Xinming Li and Mohamed Al-Hussein},
  doi          = {10.1016/j.eswa.2025.130050},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130050},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-user game-based system for planning modular construction activities},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MonoGuard: Towards infrastructure-aware oversized vehicle detection via dynamic 3D metrology with monocular surveillance cameras. <em>ESWA</em>, <em>299</em>, 130049. (<a href='https://doi.org/10.1016/j.eswa.2025.130049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversized vehicles pose a significant threat to public safety and urban infrastructure, leading to catastrophic bridge failures and traffic disruptions worldwide. However, existing detection systems often lack the automation, real-time capability, and cost-effectiveness required for widespread deployment. To address this gap, this study introduces MonoGuard, a deep learning-enhanced framework for real-time oversized vehicle detection (OSVD). By leveraging ubiquitous monocular surveillance cameras, Monoguard is designed to guard against infrastructure damage and enhance traffic safety. Monoguard integrates three key innovations: a semi-automatic calibration workflow using Segment Anything Model 2 (SAM2) and multi-frame fusion for robust vanishing point estimation; the lightweight Context-Guided Attention Segmentation-You Only Look Once (CGAS-YOLO) model for efficient vehicle segmentation; and a rule-based adaptive 3D bounding box pipeline that dynamically adjusts to camera-object geometry. Extensive evaluations across 36 UAV-simulated scenarios demonstrate MonoGuard’s high performance. It achieves a remarkable height estimation accuracy rate of 96.98% for cars and 95.50% for trucks, while maintaining a real-time throughput of 46.5 FPS on an RTX 4080 Laptop. By repurposing existing surveillance infrastructure, MonoGuard provides a scalable and economical solution for smart cities, enabling early warnings to prevent collisions, protect infrastructure, and safeguard lives and property.},
  archive      = {J_ESWA},
  author       = {Yi You and Jiachang Gu and Zida Chen and Gang Wu and Kang Gao},
  doi          = {10.1016/j.eswa.2025.130049},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130049},
  shortjournal = {Expert Syst. Appl.},
  title        = {MonoGuard: Towards infrastructure-aware oversized vehicle detection via dynamic 3D metrology with monocular surveillance cameras},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UAPFinger: One-to-many deep neural network fingerprinting via universal adversarial perturbations. <em>ESWA</em>, <em>299</em>, 130048. (<a href='https://doi.org/10.1016/j.eswa.2025.130048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and implementation of deep neural networks (DNNs) typically require substantial resources. To protect the intellectual property of these models, researchers have developed model fingerprinting techniques to tag and identify DNNs. However, existing model fingerprinting methods are designed for individual models, protecting specific models by constructing tailored query sets. These approaches cannot safeguard multiple models simultaneously, and leakage of the query set can lead to performance degradation. To address these challenges, we propose a one-to-many model fingerprinting method called UAPFinger. This method leverages the effectiveness of universal adversarial perturbations (UAPs) in the cross-model to design a general query set that does not depend on specific models. Then, it inputs the query set into the suspicious model and determines the model’s identity by comparing its misguidance rate and the degree of label shift. UAPFinger can protect multiple models simultaneously through a universal query set, effectively reducing the complexity involved in safeguarding multiple DNN models, and leakage of the universal query set does not lead to performance degradation. We conduct experiments on the CIFAR-10 and TinyImageNet datasets. The results demonstrate that UAPFinger can effectively perform one-to-many model protection and exhibits robustness against model modification attacks.},
  archive      = {J_ESWA},
  author       = {Zekai Wang and Deyang Wu and Jie Wang and Xianquan Zhang and Zhenjun Tang},
  doi          = {10.1016/j.eswa.2025.130048},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130048},
  shortjournal = {Expert Syst. Appl.},
  title        = {UAPFinger: One-to-many deep neural network fingerprinting via universal adversarial perturbations},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Low-light image enhancement integrated semantic aware guidance. <em>ESWA</em>, <em>299</em>, 130045. (<a href='https://doi.org/10.1016/j.eswa.2025.130045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simply increasing brightness is not an optimal solution for low-light image enhancement, as excessive adjustment often leads to overexposure, amplified noise, and color distortion. To address this issue, we propose a dual-branch semantic-aware guided enhancement network. One branch focuses on natural brightness adjustment, while the other conducts coarse semantic segmentation to guide region-specific enhancement. Indoor scenes are segmented into foreground and background, whereas outdoor scenes are divided into sky, foreground, and ground, with each region enhanced using tailored strategies. The backbone employs lightweight inverted residual convolutional blocks with attention mechanisms, and spatial-positional encoding is incorporated to inject absolute positional cues, thereby improving the understanding of image structures and spatial relationships. Extensive experiments on both the Outdoor-Synthetic dataset (synthesized from CamVid and Cityscapes) and the Indoor-LLRGDB_Real low-light dataset demonstrate that our method consistently surpasses state-of-the-art approaches in both qualitative and quantitative evaluations, achieving 33.448/0.977/0.141 (PSNR/SSIM/LPIPS) on Outdoor-Synthetic dataset and 17.939/0.993/0.259 on Indoor-LLRGDB_Real dataset. Furthermore, no-reference image quality assessments confirm the naturalness and realism of the enhanced results. Our code and corresponding database can be obtained at https://github.com/zhangjunchang2023/LLIE-SAG .},
  archive      = {J_ESWA},
  author       = {Junchang Zhang and Yucai Shi and Hong Chen and Qing Wang and Hai Huang},
  doi          = {10.1016/j.eswa.2025.130045},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130045},
  shortjournal = {Expert Syst. Appl.},
  title        = {Low-light image enhancement integrated semantic aware guidance},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lab-DN: Dual-branch lightweight network for lab color space shadow removal. <em>ESWA</em>, <em>299</em>, 130044. (<a href='https://doi.org/10.1016/j.eswa.2025.130044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the limitations of current over-parameterized shadow removal models and proposes a novel dual-branch lightweight deep neural network for processing shadow images in the Lab color space. The proposed network, called “Lab-DN”, is motivated by three key observations. Firstly, the Lab color space effectively separates luminance information and color properties, which have not been fully utilized by existing networks. Secondly, the sequential stacking of convolutional layers fails to leverage features from different receptive fields. Finally, non-shadow regions contain important prior knowledge for mitigating the significant color differences between shadow and non-shadow regions. Therefore, we design our Lab-DN with a dual-branch structure, consisting of “L” and “ab” branches, where shadow-related luminance information is processed in the L branch, while the ab branch retains chrominance properties. Moreover, each branch comprises several Multi-receptive-fields Information Fusion modules (MIF), Shadow Boundary-aware Attention modules, and convolutional filters. Each MIF module includes multiple parallelized dilated convolutions with varying dilation rates to receive different receptive fields and operate with distinct network widths, thereby reducing model computational costs. In addition, a Laplacian-filter-based Channel Attention module is incorporated to aggregate features from different receptive fields and achieve better shadow removal performance. Extensive experiments on the ISTD, ISTD+, and SRD datasets demonstrate that our Lab-DN achieves +0.22/+0.18/+0.76 PSNR improvements-in ISTD improving from 36.95 dB to 37.17 dB compared to EMDN. Our model has only 0.93 M parameters and requires approximately one-tenth the computational cost.},
  archive      = {J_ESWA},
  author       = {Haocheng Chu and Hong Yang and Fei Chao and Xiang Chang and Changjing Shang and Qiang Shen},
  doi          = {10.1016/j.eswa.2025.130044},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130044},
  shortjournal = {Expert Syst. Appl.},
  title        = {Lab-DN: Dual-branch lightweight network for lab color space shadow removal},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrysFormer++: Dual-phase refinement learning for transparent object depth estimation. <em>ESWA</em>, <em>299</em>, 130043. (<a href='https://doi.org/10.1016/j.eswa.2025.130043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparent object depth estimation is a critical yet challenging task in robotic perception, particularly in grasping applications for industrial automation and human-robot interaction. Due to the high transmittance of visible light in transparent materials, depth sensors often suffer from severe depth measurement errors, leading to inaccuracies in grasp planning and object manipulation. To address this issue, we propose a Mamba-Transformer hybrid encoding framework (CrysFormer++) for robust depth estimation of transparent objects. The model integrates VMamba to efficiently model global long-range dependencies and leverages Swin Transformer to capture fine-grained local features. In addition, we have developed a self-supervised confidence learning framework that generates pixel-wise reliability maps through photometric consistency constraints, and realizes adaptive fusion of raw depth measurements and network predictions via physics-informed spatial weighting. Meanwhile, we have designed a novel loss function to enhance the accuracy and robustness of depth prediction. Extensive experiments conducted on the TransCG and ClearGrasp datasets validate that CrysFormer++ achieves superior performance compared to existing state-of-the-art approaches, in terms of both visual quality and quantitative metrics. The results validate the effectiveness of CrysFormer++ in handling complex backgrounds, providing a high-precision depth perception solution for robotic grasping of transparent objects.},
  archive      = {J_ESWA},
  author       = {Xiaomei Zhang and Min Deng and Jiwei Hu and Xiao Huang and Qiwen Jin},
  doi          = {10.1016/j.eswa.2025.130043},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130043},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrysFormer++: Dual-phase refinement learning for transparent object depth estimation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep class-weighted and class-shared dictionary learning for image classification. <em>ESWA</em>, <em>299</em>, 130042. (<a href='https://doi.org/10.1016/j.eswa.2025.130042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep dictionary learning has shown promising performance in various image classification tasks. However, different images containing different objects usually contain both class-specific features and those shared across different classes. Distinguishing these two types of features through learning the class-specific and shared dictionaries can improve the discriminative ability of sparse coding, leading to further improved classification performance, which is still an active but less explored area of research. In this paper, we propose deep class-weighted and class-shared dictionary learning (DCWSDL), which can combine the advantages of deep dictionary learning, shared dictionary learning as well as the geometry of data. Our DCWSDL is able to learn both dictionaries with class-shared features and those with class-specific features at different levels, which allows it to acquire more abstract dictionaries. To enhance the effectiveness of sparse coding for class-specific dictionaries, we adapt the well-known Fisher intra- and inter-class discrimination constraint terms from Fisher Discrimination Dictionary Learning by introducing weighting factors based on the locality information of the samples. Those constraints are applied to multiple layers for learning more discriminative sample representations. Experimental results derived from several benchmark image datasets have shown that DCWSDL outperforms the recent state-of-the-art algorithms that we considered. The source codes are available at: https://github.com/qinghe-D/DCWSDL .},
  archive      = {J_ESWA},
  author       = {Jianping Gou and Xin He and Lan Du and Weiyong Zhang and Weihua Ou},
  doi          = {10.1016/j.eswa.2025.130042},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130042},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep class-weighted and class-shared dictionary learning for image classification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction of iron ore inventory at ports: A decomposition-integration hybrid approach incorporating key influencing factors. <em>ESWA</em>, <em>299</em>, 130041. (<a href='https://doi.org/10.1016/j.eswa.2025.130041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate prediction of iron ore inventory at ports is necessary for analyzing market trends, optimizing operational strategies, and avoiding supply chain risks. Considering that the iron ore inventory is complex and influenced by various factors, this study offers a novel decomposition-integration hybrid model to fully capture the underlying patterns in inventory data and improve prediction accuracy. First, three significant components are extracted from the raw inventory sequence to represent high-, mid-, and low-frequency features using CEEMDAN decomposition and sample entropy reconstruction. Then, after investigating the potential influencing factors and diverse characteristics of each frequency sequence, we individually develop the prediction models by incorporating different influencing factors. Finally, the individual models’ outputs are integrated to achieve the final prediction, fully capturing the impact of key influencing factors on the iron ore inventory data at ports. Empirical results based on the data from Qingdao Port illustrate that the established hybrid forecasting model yields ideal accuracy, with at least a 2.11% reduction in RMSE and a minimum 1.73% reduction in MAE compared with nine models, verifying its effectiveness in forecasting iron ore inventory at ports.},
  archive      = {J_ESWA},
  author       = {Hongyue Guo and Qianying Yang and Yating Yu and Lidong Wang and Peng Jia and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.130041},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130041},
  shortjournal = {Expert Syst. Appl.},
  title        = {Prediction of iron ore inventory at ports: A decomposition-integration hybrid approach incorporating key influencing factors},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable image transmission by boosting multiple weak semantic communications. <em>ESWA</em>, <em>299</em>, 130040. (<a href='https://doi.org/10.1016/j.eswa.2025.130040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to achieve a reliable transmission in scenarios with severe interference and channel fading remains a challenge. Meanwhile, semantic communications have become a promising technique that transmits semantic features rather than original data. This paper proposes a novel, reliable image transmission by boosting multipath semantic-oriented communications. The novelty of the proposed multiple path semantic communications (MP-SCS) lies in its ability to fuse multiple weak semantic transmissions through a feature pyramid cascaded (FPC) and multiple channel aggregation blocks, thereby reducing the impact of channel fading and improving decoding quality. Based on MP-SCS, three MP-SCS-assisted frameworks, namely S-CoMP, S-LBMP, and S-ARQ, are further proposed to cope with the existing wireless systems and tackle unreliable transmission environments. The simulation results demonstrate that the MP-SCS outperforms conventional multiple-path-based communications, especially with very low SINR or lengthy communication distances. Specifically, S-CoMP obtains a similar image reconstruction quality to conventional JP-CoMP with no hardware requirements. S-LBMP obtains the same transmission quality as traditional SCS with lower transmission power. S-ARQ enhances the transmission quality and reduces the number of retransmissions. We further implement the S-ARQ in the USRP testbed, and the experimental results exhibit a consistent trend with the simulation.},
  archive      = {J_ESWA},
  author       = {Jie Jia and Yidi Chou and Jian Chen and Yansha Deng and Xingwei Wang},
  doi          = {10.1016/j.eswa.2025.130040},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130040},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reliable image transmission by boosting multiple weak semantic communications},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid cooperative coevolution approach for robust medical supply chain logistics scheduling during an emerging epidemic. <em>ESWA</em>, <em>299</em>, 130039. (<a href='https://doi.org/10.1016/j.eswa.2025.130039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adequate medical supplies and prompt disposal of medical waste are crucial to effectively controlling an emerging epidemic. However, logistics scheduling within the medical supply chain can be severely impacted during such outbreaks. To optimize the distribution of medical supplies and the collection of resulting medical waste, we propose a hybrid cooperative coevolution approach for robust medical supply chain logistics scheduling during an emerging epidemic. First, we develop a hierarchical medical supply chain model in which various types of medical supplies flow from top to bottom. The susceptible-exposed-infected-vigilant epidemic model is also integrated into this model to predict the demand for medical supplies under conditions of uncertainty. Second, we hybridize a cooperative coevolution algorithm with an ant colony system algorithm to optimize the distribution of medical supplies and the collection of the resulting medical waste, respectively, while considering both operational cost and robustness. Finally, extensive experiments based on Monte Carlo simulations validate the effectiveness and efficiency of the proposed approach. The results indicate that the divide-and-conquer strategy employed by the cooperative coevolution algorithm can mitigate the impact of uncertainty while improving scalability.},
  archive      = {J_ESWA},
  author       = {Wen-Jin Qiu and Wei-Neng Chen and Xuan-Li Shi and Jun Zhang},
  doi          = {10.1016/j.eswa.2025.130039},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130039},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid cooperative coevolution approach for robust medical supply chain logistics scheduling during an emerging epidemic},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advancing sustainable material handling in construction warehouses using web 4.0 technologies through disc intuitionistic CRADIS-based decision analytics. <em>ESWA</em>, <em>299</em>, 130037. (<a href='https://doi.org/10.1016/j.eswa.2025.130037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction sector is responsible for over a third of global energy consumption and greenhouse gas emissions. Despite its powerful economic performance, the construction industry confronts numerous challenges. The use of Web 4.0 technologies in construction material handling has become a way of solving safety issues and increasing the efficiency of operations. Nevertheless, due to several competing requirements, strong levels of uncertainty, and overall fuzziness in the choice and application of these technologies, sophisticated multi-criteria decision-making techniques are required. This paper suggests a new approach to decision-making that combines the compromise ranking of alternatives form distance to ideal solution (CRADIS) approach with disc intuitionistic fuzzy sets. The introduced decision analytics provides additional flexibility and accuracy when assessing Web 4.0 adoption in material handling. This study is original in that the CRADIS method has never been applied in disc intuitionistic fuzzy settings so far, filling a vacuum spot in the management of decision uncertainty. The actual application is done on a real-world-aspiring dataset. The results indicate that the model can be effectively applied to provide steady and trusted rankings and can therefore provide a flavor to the builders and researchers who intend to foster sustainable use of materials in construction houses through the warehouse. This study establishes a framework for estimating motivations for Web 4.0 technology implementation in building material handling. It highlights the identification as well as evaluation of potential advantages and weaknesses of various advanced technological solutions, while providing a comprehensive analysis of their long-term implications.},
  archive      = {J_ESWA},
  author       = {Hafiz Muhammad Athar Farid and Vladimir Simic and Shahzaib Ashraf and Svetlana Dabic-Miletic and Wania Iqbal and Dragan Pamucar},
  doi          = {10.1016/j.eswa.2025.130037},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130037},
  shortjournal = {Expert Syst. Appl.},
  title        = {Advancing sustainable material handling in construction warehouses using web 4.0 technologies through disc intuitionistic CRADIS-based decision analytics},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term traffic flow prediction based on deep learning approach with inter-day and intra-day strategies. <em>ESWA</em>, <em>299</em>, 130036. (<a href='https://doi.org/10.1016/j.eswa.2025.130036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is becoming increasingly important for preventing traffic congestion. The powerful predictive abilities of deep learning models have significantly improved the outcomes of short-term traffic flow forecasting. Inter-day features can be used to forecast long-term traffic flow, while intra-day features can be used to forecast short-term traffic flow. This study explores the impact of different data preprocessing methods on traffic flow datasets, as well as the differences in feature extraction effectiveness of deep learning models regarding inter-day and intra-day characteristics of the data. This study uses denoising methods such as EMD, EEMD, CEEMDAN, Fourier Transform, and Wavelet Transform to make the datasets more stable and easier for deep learning and statistical models to learn, and compares the prediction results using models such as ARIMA, GRU, LSTM, Bi-LSTM, and CNN-LSTM. This research finds that data denoising effectively reduces errors during model training, and with Fourier transform offering better denoising performance. Furthermore, extracting and combining inter-day and intra-day features in appropriate proportions outperformed other models that either did not use relevant features or relied on single features. The CNN-LSTM model showed superior predictive performance with minimal errors, with a traffic flow prediction error rate below 5%.},
  archive      = {J_ESWA},
  author       = {Hsiu-Sen Chiang and Keng-Hsi Lin and Hsun Lin and Mu-Yen Chen},
  doi          = {10.1016/j.eswa.2025.130036},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130036},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term traffic flow prediction based on deep learning approach with inter-day and intra-day strategies},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MGRNN for dynamic constrained quadratic programming with verification and applications. <em>ESWA</em>, <em>299</em>, 130034. (<a href='https://doi.org/10.1016/j.eswa.2025.130034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Constrained Quadratic Programming (DCQP) is at the core of problems such as portfolio optimization and robot control. However, for this dynamic problem, the Gradient Recurrent Neural Network (GRNN) suffers lag errors and the Zeroing Neural Network (ZNN) requires costly matrix inversion and derivative information. Therefore, this paper proposes a Modified Gradient Recurrent Neural Network (MGRNN) to address these limitations. Its core adaptive mechanism that retains the simplicity of explicit dynamic structure while eliminating dependencies on matrix inversion and derivative computation, thereby resolving lag errors. Moreover, theoretical analyses demonstrate that the MGRNN achieves finite-time convergence and exhibits robust performance. Besides, performance analysis validates that the MGRNN outperforms traditional GRNN by significantly reducing residuals in solving the DCQP problem. Moreover, noise tolerance experiments reveal that the MGRNN also delivers the smallest residuals and the fastest convergence among all compared models under bounded noise, confirming its superior robustness. Furthermore, its efficacy and practicality are verified through current computation in dynamic circuits with temperature-dependent resistors, as well as through applications to portfolio optimization and manipulator control. Consequently, these results collectively highlight the effectiveness and practicality of MGRNN in addressing dynamic optimization tasks, providing a robust and computationally lightweight solution for real-time applications.},
  archive      = {J_ESWA},
  author       = {Songjie Huang and Guancheng Wang and Xiuchun Xiao},
  doi          = {10.1016/j.eswa.2025.130034},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130034},
  shortjournal = {Expert Syst. Appl.},
  title        = {MGRNN for dynamic constrained quadratic programming with verification and applications},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-series forecasting via topological information supervised framework with efficient topological feature learning. <em>ESWA</em>, <em>299</em>, 130032. (<a href='https://doi.org/10.1016/j.eswa.2025.130032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological Data Analysis (TDA) has emerged as a powerful tool for extracting meaningful features from complex data structures, driving advancements in neuroscience, biology, machine learning, and financial modeling. However, its integration with time-series forecasting remains underexplored due to three key challenges: limited use of temporal dependencies in topological features, computational bottlenecks in persistent homology, and the deterministic nature of TDA pipelines that restrict generalized learning. To address these issues, we propose the Topological Information Supervised (TIS) Prediction framework, which employs neural networks and Conditional Generative Adversarial Networks (CGANs) to generate synthetic topological features that preserve distributional properties while reducing computation time. A novel training strategy incorporating a topological consistency loss further enhances predictive accuracy. We evaluate TIS across recurrent and Transformer-based models, showing that integrating topological information yields consistent performance improvements across diverse architectures and forecasting horizons. While the magnitude of gains varies, tending to be more modest for recent architectures, the results highlight TIS as a lightweight, complementary inductive bias that augments existing models beyond architectural refinements. This work advances TDA-based time-series prediction and opens new directions for embedding topological insights into deep learning frameworks.},
  archive      = {J_ESWA},
  author       = {Zixin Lin and Nur Fariha Syaqina Zulkepli and Mohd Shareduwan Mohd Kasihmuddin and R.U. Gobithaasan},
  doi          = {10.1016/j.eswa.2025.130032},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130032},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-series forecasting via topological information supervised framework with efficient topological feature learning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An enhanced hybrid deep neural network method for adjusted industrial time series prediction with variable operating states. <em>ESWA</em>, <em>299</em>, 130029. (<a href='https://doi.org/10.1016/j.eswa.2025.130029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial production, dynamic nature of working conditions and reliance on manual judgment introduces significant hurdles for accurate prediction models. Despite commendable performance of contemporary Deep Learning techniques in time series prediction (TSP), they frequently overlook crucial impact of human intervention. Moreover, the subjective nature of operational condition labeling and the scarcity of comprehensive experimental datasets further hinder the efficacy of predictive systems. This work proposes an E nhanced H ybrid D eep N eural N etwork (EH-DNN) framework to tackle these issues. It achieves robust classification and prediction of working conditions by integrating the multi-dimensional features of set values and observation time series. The data preprocessing phase encompasses feature extraction and feature fusion, ensuring the model acquires the essential information intrinsic to the production process. A novel two-step prediction methodology is employed during the training phase, incorporating pre-classification to enhance TSP, achieving an accuracy of 94%. EH-DNN mirrors intricate dynamics of industrial production and aligns seamlessly with real-world application scenarios, demonstrating substantial practical utility. By integrating this methodology, the industrial sector can anticipate a significant leap in automation levels and production efficiency, bridging the gap between theoretical models and practical implementation.},
  archive      = {J_ESWA},
  author       = {Meifang Zhang and Jing Bi and Haitao Yuan and Ziqi Wang and Jia Zhang and Rajkumar Buyya},
  doi          = {10.1016/j.eswa.2025.130029},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130029},
  shortjournal = {Expert Syst. Appl.},
  title        = {An enhanced hybrid deep neural network method for adjusted industrial time series prediction with variable operating states},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stock price trend forecasting based on multi-channel complementary network with CEEMDAN decomposition and transformer residual prediction. <em>ESWA</em>, <em>299</em>, 130028. (<a href='https://doi.org/10.1016/j.eswa.2025.130028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting stock market movement provides important investment signals, but the presence of a large amount of noise in financial time series (FTS) data poses significant challenges to prediction accuracy. This paper proposes a novel multi-channel complementary network with data decomposition and a fusion strategy to effectively improve the prediction accuracy and robustness of stock price movement. The model first applies the algorithm of Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) to decompose the historical stock data sequence into a set of Intrinsic Mode Functions (IMFs), representing different frequency components of the original FTS data. Then, each IMF combined with six key indicators (i.e., open price, high price, low price, trading volume, price-earnings ratio and price-to-book ratio) are processed by an independent long short-term memory (LSTM) module to make a parallel prediction. To further enhance the forecasting accuracy, a transformer-based residual term prediction model is incorporated, serving as the complementary branch to the LSTM modules. Subsequently, the outputs from all network branches are fused together to obtain the final prediction result. A set of numerical experiments on different stock index datasets are conducted to verify the superiority of the proposed model in terms of average forecasting accuracy compared with other benchmark models. In addition, the effectiveness of different sub-modules in the proposed framework is proved by the ablation experiments.},
  archive      = {J_ESWA},
  author       = {Yuanji Shen and Jun Dai and Mingxian Wang and Gonzalo R. Arce},
  doi          = {10.1016/j.eswa.2025.130028},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130028},
  shortjournal = {Expert Syst. Appl.},
  title        = {Stock price trend forecasting based on multi-channel complementary network with CEEMDAN decomposition and transformer residual prediction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite label diffusion enhanced cross domain data synthesis for matching siamese network-based diesel engine fault diagnosis under varying conditions. <em>ESWA</em>, <em>299</em>, 130027. (<a href='https://doi.org/10.1016/j.eswa.2025.130027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep diagnosis model is limited by the few-shot problem caused by the scarcity of fault data in the actual industry. Data generation networks can solve this problem at the data level. However, the complex multi-source impulse coupling characteristics of diesel engine vibration signals pose serious challenges to the generation network. In this paper, an innovative “decoupling-generation-reconstruction” strategy is proposed to improve the quality of the generated signal at a more detailed and local level. Firstly, the diesel engine cycle signal is decomposed into several single-impulse signals based on the working phase parameters of the valve. Then, a composite label diffusion generation adversarial network (CLDGAN) is constructed, and multiple composite labels are used to guide the generation of various types of single-impulse signals. Secondly, based on the working condition information and fault information, the single impulse signal is reconstructed into the completed periodic signal. Finally, a condition matching siamese network (CMSN) is constructed to realize cross-domain few-shot fault diagnosis. Compared with the current advanced methods, the results show that the diversity and differentiation of the single impulse signals generated under the guidance of compound label information are higher. The performance of the proposed cross-domain few-shot diagnosis method is superior to the existing advanced methods. It shows good application potential in practice.},
  archive      = {J_ESWA},
  author       = {Anzheng Huang and Hangfeng Mo and Likai Ye and Fengchun Liu and Xiangxin Kong and Zhinong Jiang and Zhiwei Mao},
  doi          = {10.1016/j.eswa.2025.130027},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130027},
  shortjournal = {Expert Syst. Appl.},
  title        = {Composite label diffusion enhanced cross domain data synthesis for matching siamese network-based diesel engine fault diagnosis under varying conditions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transparent fault diagnosis for magnetic control circuit breakers: A ViT-based unsupervised approach. <em>ESWA</em>, <em>299</em>, 130026. (<a href='https://doi.org/10.1016/j.eswa.2025.130026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional fault diagnosis method of circuit breakers is always hindered by the scarcity of labeled fault data and the lack of transparency in model decision-making, thereby compromising its practical applicability. To address these challenges, this study proposes an unsupervised fault diagnosis framework for magnetic control circuit breakers, integrating a Vision Transformer (ViT) autoencoder, HDBSCAN clustering, and explainable AI (XAI) techniques. Acoustic and vibration signals are fused into mixed-feature Mel-spectrograms, enabling the ViT autoencoder to detect anomalies through reconstruction errors by learning normal-state distributions. HDBSCAN clusters latent features and attention scores to generate pseudo-labels, which are mapped to fault types using attention attribution and Integrated Gradients heatmaps, guided by expert knowledge. A classifier achieves 100% accuracy in fault detection and diagnosis. Experimental validation demonstrates the framework’s robustness and transparency, providing an effective solution for intelligent fault diagnosis in industrial settings. © 2017 Elsevier Inc. All rights reserved.},
  archive      = {J_ESWA},
  author       = {Kunquan Chen and Haoqing Wang and Fengchao Wang and Haiming Gao and Yiran Xia and Shude Zhao and Yakui Liu},
  doi          = {10.1016/j.eswa.2025.130026},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130026},
  shortjournal = {Expert Syst. Appl.},
  title        = {Transparent fault diagnosis for magnetic control circuit breakers: A ViT-based unsupervised approach},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal legendre multiwavelet frequency band-based an improved adaptive denoising algorithm for mechanical fault diagnosis under complex conditions. <em>ESWA</em>, <em>299</em>, 130025. (<a href='https://doi.org/10.1016/j.eswa.2025.130025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional fault diagnosis methods face significant challenges in real-world engineering scenarios, including heavy background noise, wrong labels, and limited fault samples. To address these challenges, this paper proposes an improved adaptive denoising algorithm combining Legendre multiwavelet with genetic algorithm (IAD-LWGA). This novel method devises a modified threshold estimation algorithm on each LW frequency band optimized by GA, resulting in effectively suppressing noise while preserving fault-related features. The efficacy of the proposed approach is first validated on a real-world air conditioner external unit dataset. Subsequently, the extracted optimal feature combinations are directly transferred to PHM 2009 gearbox compound fault diagnosis dataset, demonstrating strong cross-domain generalization ability with minimal requirement for domain-specific expertise. Extensive experiments show that the proposed approach consistently outperforms state-of-the-art models, attaining 100 % accuracy for both datasets under normal conditions, while reaching 100 %, 94.75 %, 93.57 % accuracies with –10 dB noise, label noise ratio 0.05, faulty samples 10 for Dataset 1, and achieving 99.83 %, 95.33 %, 90.80 % accuracies with 6 dB noise, label noise ratio 0.05, limited faulty samples 10 for Dataset 2, respectively. This work presents a practical and effective strategy for fault diagnosis in complex industrial environments, enhancing predictive maintenance capabilities of expert and intelligent systems.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Zheng and Zejiang Yu and Lei Chen and Zijian Lei and Zhixia Feng},
  doi          = {10.1016/j.eswa.2025.130025},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130025},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal legendre multiwavelet frequency band-based an improved adaptive denoising algorithm for mechanical fault diagnosis under complex conditions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-level fuzzy decision support framework for asset maintenance criticality: Corrosion risk assessment in piping systems. <em>ESWA</em>, <em>299</em>, 130024. (<a href='https://doi.org/10.1016/j.eswa.2025.130024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current decision support frameworks in asset management lack robust approaches for assessing criticality in complex offshore systems, particularly regarding component relationships and corrosion risks. This study develops an innovative framework using Design Science paradigm, integrating Hierarchical Fuzzy Inference Systems (HFIS), Best-Worst Method (BWM), and fuzzy VIKOR (FVIKOR) for comprehensive asset criticality assessment. The methodology combines expert knowledge through semi-structured interviews with fuzzy rule-based modelling and hybrid multi-criteria analysis, incorporating adaptable importance weighting whilst evaluating relationships between operational units at multiple organisational levels. Applied to 2,975 components across four FPSO operational sections, the framework demonstrated superior discrimination in criticality classification, with empirical validation showing 75 % expert consensus and near-zero inconsistency indices (0.0168–0.0428). Benchmarking against Fuzzy TOPSIS demonstrated FVIKOR’s computational superiority: 99.89 % faster execution and 74 % reduced expert cognitive burden through hierarchical rule reduction. Ranking correlation analysis revealed criterion-specific methodological concordance: Severity and Occurrence demonstrated consistent moderate correlation (Spearman ρ = 0.332), whilst Detection exhibited reduced agreement (ρ = 0.303) under perturbation scenarios, confirming methodologically distinct but complementary prioritisation strategies. FVIKOR’s compromise-based optimisation provides contextually appropriate solutions for offshore maintenance decision-making, with systematic perturbation analysis (γ∈{0.8,1.0,1.2}) confirming ranking stability across failure parameters. Key contributions include novel multi-level evaluation approach, quantitative validation of hierarchical criteria weights, and integration of corrosion-specific risk factors. The framework provides oil and gas operators evidence-based asset prioritisation for maintenance planning, balancing severity, occurrence, and detection dimensions through computationally efficient compromise solutions optimal for risk-critical contexts.},
  archive      = {J_ESWA},
  author       = {Bruna Kaiser and Rodrigo Goyannes Gusmão Caiado and Marina Polonia Rios and Yiselis Rodriguez Vignon and Luiz Felipe Scavarda and Eduardo Thadeu Corseuil},
  doi          = {10.1016/j.eswa.2025.130024},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130024},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-level fuzzy decision support framework for asset maintenance criticality: Corrosion risk assessment in piping systems},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cascade-TCN-BiLSTM: Accurate prediction of long-term transmission error curves in multi-stage transmission system. <em>ESWA</em>, <em>299</em>, 130023. (<a href='https://doi.org/10.1016/j.eswa.2025.130023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting long-term transmission error trends in multi-stage transmission systems is essential for ensuring high motion accuracy in mechanical systems. Effectively modeling the nonlinear propagation and inter-stage coupling of errors to enhance predictive capabilities remains a significant challenge. This research introduces a cascaded deep learning framework, termed Cascade-Temporal Convolutional Network-Bidirectional Long Short-Term Memory, designed to estimate long-term transmission error curves across planetary and harmonic stages. By building a three-stage cascade aligned with intrinsic errors of the planetary reducer, inter-stage assembly errors at the planetary–harmonic interface, and operational errors of the harmonic reducer, we establish a one-to-one mapping between network modules and the corresponding error sources, thereby ensuring physical interpretability. The model incorporates both static assembly features and short-term dynamic input signals. A stage-specific cascaded configuration is embedded into a comprehensive sequence-to-sequence structure, consisting of an encoder-decoder network. Each encoder and decoder component consists of stacked temporal convolutional networks and bidirectional long short-term memory layers, followed by a multi-head attention module designed. Experimental results indicate that the proposed model consistently achieves low mean squared error and mean absolute error, typically below 0.22 and 0.33, respectively. The coefficient of determination exceeds 0.97 in most cases, demonstrating that the model significantly outperforms both traditional machine learning methods and baseline deep learning architectures. Ablation studies further confirm the critical contributions of the unified architecture, temporal modeling, and attention mechanism to the model’s performance. In addition to multi-stage transmissions, the method applies to series elastic actuators, surgical and industrial robot joints, and rotating machinery.},
  archive      = {J_ESWA},
  author       = {Xiao Wang and Hao Gong and Jianhua Liu and Ruixiang Wang and Zhongtian Lu},
  doi          = {10.1016/j.eswa.2025.130023},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130023},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cascade-TCN-BiLSTM: Accurate prediction of long-term transmission error curves in multi-stage transmission system},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HierFLMC: Efficient hierarchical federated learning based on soft clustering model compression. <em>ESWA</em>, <em>299</em>, 130022. (<a href='https://doi.org/10.1016/j.eswa.2025.130022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is an advanced distributed machine learning paradigm that enables clients to collaboratively train a shared neural network model using local datasets, transmitting model parameters instead of raw data. However, in many FL systems, the frequent exchange of model parameters between clients and remote cloud servers leads to significant communication overhead. As the model size increases, existing FL methods incur substantial communication costs. To address this bottleneck, this paper proposes a novel hierarchical federated learning model compression scheme (HierFLMC). This scheme integrates model compression techniques within a hierarchical framework, significantly enhancing communication efficiency between edge devices and cloud servers. In addition, an innovative preliminary soft clustering model update compression algorithm (SCMUC) is proposed. The SCMUC algorithm utilizes the K-means method for initial clustering, effectively reducing the computational complexity associated with traditional soft clustering methods. We validate the proposed scheme using the CIFAR-10 and FEMNIST datasets, demonstrating a 2 % improvement in model accuracy and an 11 % reduction in communication time compared to MUCSC. Experimental results indicate that this approach not only achieves a favorable compression rate but also substantially improves communication efficiency.},
  archive      = {J_ESWA},
  author       = {Yifan Liu and Hongmei Ma and Donglin Pan and Yi Liu and Wenlei Chai and Zhenpeng Liu},
  doi          = {10.1016/j.eswa.2025.130022},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130022},
  shortjournal = {Expert Syst. Appl.},
  title        = {HierFLMC: Efficient hierarchical federated learning based on soft clustering model compression},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive corner detection algorithm using auto-correlation directional gradient matrix. <em>ESWA</em>, <em>299</em>, 130021. (<a href='https://doi.org/10.1016/j.eswa.2025.130021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an enhanced corner detection algorithm based on the auto-correlation directional gradient matrix, aims at addressing two key issues of the Harris algorithm: the need for multiple thresholds and the lack of intelligent threshold setting. Initially, a set of novel directional differential operators were constructed to calculate the partial derivatives of the original image, followed by the application of a Gaussian low-pass filter to the derivative image. This process enhanced the intensity of corner features and significantly reduced the probability of pseudo-corner detection at image edges. Next, the Feature Corner Image (FCI) was constructed by evaluating the determinant of the auto-correlation directional gradient matrix for each pixel. An adaptive segmentation threshold for the FCI was then determined using the OTSU algorithm, allowing for the identification of pre-screened corners. Building on this, a modified non-maximum suppression method was employed to accurately extract true corner points from the pre-screened corner dataset. Comparison experiments with Harris, Shi-Tomasi, FAST, SOGGDD, ECFRNet, and Pcorner algorithms, as well as R2D2, D2-net, SuperPoint, and SIFT detectors, revealed several key findings. Firstly, the proposed algorithm more effectively highlights corner features, and the optimal threshold is automatically computed. Additionally, it successfully extracts a larger number of accurate corners with precise localization, achieving the highest corner detection accuracy among the tested algorithms. Furthermore, the algorithm demonstrates strong robustness and some degree of noise resistance.},
  archive      = {J_ESWA},
  author       = {Xiaolian Deng and Jiao Deng},
  doi          = {10.1016/j.eswa.2025.130021},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130021},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive corner detection algorithm using auto-correlation directional gradient matrix},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A prototype-based framework for open-set heterogeneous federated face recognition. <em>ESWA</em>, <em>299</em>, 130020. (<a href='https://doi.org/10.1016/j.eswa.2025.130020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning enables privacy-preserving face recognition by keeping raw images on users’ devices, addressing challenges of non-IID identity distributions and heterogeneous model architectures. To tackle these, we propose FedPFR, a prototype-based, architecture-agnostic framework for open-set Heterogeneous Federated Face Recognition (HtFFR). Each client computes identity prototypes-mean feature embeddings of local classes-that are uploaded to the server and redistributed without averaging, while local models are trained with a hybrid loss combining CosFace and a novel prototype-anchor contrastive (PAC) loss. This design preserves semantic integrity by reducing the distance between local embeddings and their global prototypes and enlarging inter-class separation. We provide a mathematical convergence analysis proving that FedPFR converges to a stationary point under appropriate learning conditions. Extensive experiments on the IJB-C benchmark with 20 heterogeneous clients show that FedPFR achieves strong verification performance, with 23.39 % TAR at FAR=1e-6, outperforming local-only training (21.70 %) and prior heterogeneous FL baselines. Furthermore, our cost analysis quantifies the computation, communication, and storage overhead, confirming the framework’s scalability and practicality. Ablation studies and clustering analyses further demonstrate that FedPFR produces compact and discriminative embeddings, highlighting its robustness as a resource-efficient solution for real-world open-set federated face recognition.},
  archive      = {J_ESWA},
  author       = {Taeyong Kim and Jungyun Kim and Andrew Beng Jin Teoh},
  doi          = {10.1016/j.eswa.2025.130020},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130020},
  shortjournal = {Expert Syst. Appl.},
  title        = {A prototype-based framework for open-set heterogeneous federated face recognition},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predicting TSV depth using laser drilling by simulation model and neural network. <em>ESWA</em>, <em>299</em>, 130018. (<a href='https://doi.org/10.1016/j.eswa.2025.130018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor manufacturing, accurately predicting the ablated depth is a challenge for Through-Silicon-Via (TSV) formation using laser drilling. This study presents an innovative hybrid architecture that integrates ablation and vaporization models with a Physics Informed Recurrent Neural Network (PIRNN). The ablation model surrogates a time-consuming thermal simulation model to supply the baseline depths on various drilling conditions. The machine vision-based vaporization model is developed to extract plasma features captured and analyzed in vaporization. Then, PIRNN utilizes the baseline depths derived from the ablation model while adjusting the predicted depth according to actual plasma images. PIRNN presents the optimal model of various recurrent neural networks for depth prediction based on depth growth in drilling. The proposed architecture significantly reduces the time required for modeling compared to traditional and purely data-driven AI models while enhancing prediction accuracy. The mean absolute percentage error of PIRNN is below 2%, showcasing its excellent performance. Furthermore, experimental results demonstrate that the architecture achieves higher prediction precision when handling complex workpieces and material characteristics of TSV, outperforming physical or data-driven models.},
  archive      = {J_ESWA},
  author       = {Chun-Wei Hsu and Haw-Ching Yang and Yu-Lung Lo},
  doi          = {10.1016/j.eswa.2025.130018},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130018},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predicting TSV depth using laser drilling by simulation model and neural network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimizing the spread of misinformation using random influence subgraph sampling. <em>ESWA</em>, <em>299</em>, 130017. (<a href='https://doi.org/10.1016/j.eswa.2025.130017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current algorithms for minimizing misinformation spread in mobile communication systems encounter two main challenges: (i) the spread of misinformation within an influence game framework and (ii) the key node identification process overlooks the effect of graph traversal. To overcome these issues, we propose a minimization scheme for misinformation spread. First, we designed a competitive information dissemination model called the Independent Cascade with Beacon model (IC-B), which is an independent cascade propagation model based on influence game theory, when multiple information entities reach users concurrently, IC-B demonstrates superior propagation advantages compared to traditional SI and IC models. Next, we introduce Random Influence Subgraph Sampling (RISS) to identify key nodes that amplify positive information diffusion, we validate our approach across diverse real-world networks, experimental results show that at the end of the information process, the number of positive information nodes in a network exceeded 10 times the number of misinformation nodes, this result significantly outperforming traditional strategies (Degree/Betweenness/Closeness/Eigenvector Centrality). This demonstrates substantial practical significance for misinformation mitigation efforts.},
  archive      = {J_ESWA},
  author       = {Xinxin Zhang and Zhenyu Xu and Xuefeng Li},
  doi          = {10.1016/j.eswa.2025.130017},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130017},
  shortjournal = {Expert Syst. Appl.},
  title        = {Minimizing the spread of misinformation using random influence subgraph sampling},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective load distribution in strip hot rolling with multiple roller profiles based on RPK-net and a distributed TDADE algorithm. <em>ESWA</em>, <em>299</em>, 130016. (<a href='https://doi.org/10.1016/j.eswa.2025.130016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling load distribution, as one of the core tasks in the hot strip rolling process, is a key factor affecting the forming size and performance of the strip steel. The existing load distribution optimization methods rarely consider the coupling relationship between multiple objectives such as width, thickness, and energy consumption, and the optimization solution speed is slow, making it difficult to meet the needs of continuous rolling production. To this end, this paper first analyzes the coupling relationship between multiple objectives and establishes a three-layer structure multi-objective load allocation optimization model. Secondly, eight types of rolling process knowledge are extracted, and a neural network multi-metric prediction model (RPK-Net) embedded with rolling process knowledge is established. Then, a distributed strategy is designed based on a two direction adaptive differential evolution algorithm (D-TDADE) for optimizing rolling load allocation. Finally, data are collected from the actual hot rolling production line for method validation, and the results show that the multi-metric prediction accuracy of RPK-Net on the six rolling passes is 0.9865, with a prediction performance improvement of 2.09 %; the roller reduction optimized by the D-TDADE algorithm meets the requirements of the multi-objective process specification and improves the optimization efficiency by 24.54 %. This demonstrates the effectiveness and practical application value of the proposed method.},
  archive      = {J_ESWA},
  author       = {Yanjiu Zhong and Qiang Zhang and Shuai Chen and Keke Li and Daye Yang and Linghui Hu},
  doi          = {10.1016/j.eswa.2025.130016},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130016},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective load distribution in strip hot rolling with multiple roller profiles based on RPK-net and a distributed TDADE algorithm},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An block-diagonal elastic weight consolidation-attention mechanism LSTM enabled lifelong learning approach for lifetime prediction of insulated gate bipolar transistor. <em>ESWA</em>, <em>299</em>, 130015. (<a href='https://doi.org/10.1016/j.eswa.2025.130015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IGBT is widely used in fields such as electric vehicles, traction systems, and frequency converters. During operation, power loss causes the junction temperature to rise and fluctuate, thereby accelerating device aging and ultimately leading to failure. Accurately predicting the lifetime of IGBT is crucial for ensuring the safety of power electronic systems. Currently, neural network models have relatively high accuracy in predicting the lifetime of Insulated Gate Bipolar Transistor (IGBT) at constant junction temperature, but their prediction accuracy often significantly decreases when the junction temperature changes significantly. Therefore, this paper first proposes a Block-Diagonal Elastic Weight Consolidation-Attention Mechanism Long Short-Term Memory (BDEWC-AMLSTM) enabled lifelong learning approach, which is used to achieve continuous learning and accurate prediction of the IGBT lifetime under different temperature conditions. Firstly, an AMLSTM model is constructed, which utilizes LSTM neural networks to identify and extract temporal features from lifetime data, while enhancing the model’s focus on key features through an Attention Mechanism, thereby improving lifetime prediction accuracy. Secondly, after the model completes training for the current task, Block-Diagonal Elastic Weight Consolidation is introduced to evaluate the importance of model parameters for the current task, and a regularization penalty term is added to the loss function to constrain the update speed and range of key parameters when learning new tasks. Finally, the BDEWC-AMLSTM approach can continue learning new and different tasks after completing training for the current task, maintaining long-term memory of previously learned tasks and forming a lifelong learning framework, thereby expanding the model’s capability to handle different junction temperature conditions. Research shows that the proposed BDEWC-AMLSTM enabled lifelong learning approach maintains low prediction errors in all four IGBT lifetime prediction tasks under different junction temperature conditions, with its RMSE reduced by 24.8% compared to the best results from Transformer, Bi-LSTM, CNN-LSTM, GRU, and WOA-ELM models. Through lifelong learning, the proposed approach effectively solves the problem of insufficient lifetime prediction accuracy of current models when IGBT operate under different junction temperature conditions, providing core support for the power electronics industry to evolve towards high reliability, low cost, and intelligence.},
  archive      = {J_ESWA},
  author       = {Tao Li and Enyu Wang and Xingping Liu and Rongjun Ding and Yunqing Hu},
  doi          = {10.1016/j.eswa.2025.130015},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130015},
  shortjournal = {Expert Syst. Appl.},
  title        = {An block-diagonal elastic weight consolidation-attention mechanism LSTM enabled lifelong learning approach for lifetime prediction of insulated gate bipolar transistor},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic sensing system for noise monitoring and source identification using transfer learning. <em>ESWA</em>, <em>299</em>, 130014. (<a href='https://doi.org/10.1016/j.eswa.2025.130014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing noise pollution in urban areas underscores the need for an autonomous system to monitor and control noise. Beyond detecting noise levels, identifying noise sources further improves noise management. This work presents a scalable IoT-based sensing platform for smart environment applications. The system integrates low-cost devices for acoustic measurement, edge devices to enable noise source identification, a back-end infrastructure crucial for efficient acoustic data and device management, and a web-based application facilitating noise data visualization. Our study explores three feature extraction techniques and eight Convolutional Neural Network (CNN)-based pre-trained models for noise classification on the resource-constrained Raspberry Pi platform and compares their performance. Leveraging pre-trained models helps speed up the model development process. UrbanSound8k, ESC-50 datasets, and audio data collected with our low-cost microphone are used for model development and validation. The evaluation results show that our hierarchical model, utilizing the Mel Spectrogram feature extraction method and a MobileNet model, achieves the highest accuracy of 90.18 %. Furthermore, we deploy the system and assess its performance. Our system can reliably transmit audio data with an average delay of 0.37 s, and the Raspberry Pi can perform feature extraction and classification within an average of 2.5 s. Hence, our solution offers a comprehensive and cost-effective solution to enhance noise management and control.},
  archive      = {J_ESWA},
  author       = {Dolvara Gunatilaka and Wudhichart Sawangphol and Thanakorn Charoenritthitham and Thanawat Kanjanapoo and Teerapat Burasotikul and Kittikawin Pongprasit},
  doi          = {10.1016/j.eswa.2025.130014},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130014},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic sensing system for noise monitoring and source identification using transfer learning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive framework for human - AI collaborative decision making in intelligent retail environments. <em>ESWA</em>, <em>299</em>, 130013. (<a href='https://doi.org/10.1016/j.eswa.2025.130013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) approaches have been more and more adopted in the retail industry in the past years, ranging from demand forecasting, dynamic pricing, inventory optimization to personalization of recommendations and promotions. However, conventional AI-centric decision platforms are often limited in interpretability, unable to manage data heterogeneity across channels, real-time adaptability and lack of domain knowledge from human expertise. Intelligent retailing is one application field that this paper would propose a human-AI cooperative decision-making system in order to combine the benefits of human expertise and machine learning. This system should be developed on: (i) modular architecture that includes a reinforcement learning (RL) core, fuzzy logic reasoning engine, human feedback interface, bias detection module; (ii) explainable AI (XAI) methods to output the rationale of the model, and also have human operators for (iii) human-in-the-loop correction and (iv) bias mitigation and fairness checks, and (v) a hybrid multi-store evaluation mechanism. Experiment: we compare our framework against baselines such as traditional rule-based systems, pure RL models and the more recent hybrid human-AI methods. Experiments are based on six months of transaction and inventory data from three separate mid-size retail stores (> 500,000 transactions, ∼2,000 SKUs), with results showing an increase of 15 percent in revenue and 10–12 percent reduction in stock-outs, and an average increase of around 18 percent in staff satisfaction indices, and with decision latency below 200 ms. The advantage can be shown by paired t-tests (ANOVA, p = 0.05). Ablation experiments demonstrate the importance of each of the modules (e.g., XAI transparency, fuzzy logic smoothing, bias detector). The qualitative interview data with store managers on the explanations and override controls provide a basis for trust.},
  archive      = {J_ESWA},
  author       = {Sunaina Sridhar and Praveen Baskar and Josh Grimes and Ashwin Sampathkumar},
  doi          = {10.1016/j.eswa.2025.130013},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130013},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comprehensive framework for human - AI collaborative decision making in intelligent retail environments},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TCSTNet: A text-driven color style transfer network for low-light image enhancement. <em>ESWA</em>, <em>299</em>, 130012. (<a href='https://doi.org/10.1016/j.eswa.2025.130012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light image enhancement (LLIE) plays a crucial role in enabling downstream computer vision tasks and has attracted substantial research interest. Nevertheless, LLIE remains a highly ill-posed problem due to the complex and ambiguous mapping between low-light and well-exposed images, which usually involves noise removal, detail restoration, and color correction. Moreover, prior studies have largely overlooked an important fact that users have diverse requirements for lighting and color adjustments, and they often prefer to articulate these preferences through natural language. Therefore, this paper introduces TCSTNet, a user-friendly text-driven color style transfer network specifically designed for low-light image enhancement. TCSTNet first models a color distribution flow transformation from low-light to well-exposed images via rectified flow theory. It then integrates a super resolution module combining U-Net and residual convolutional neural networks to extract color details from the original image. To enhance perceptual quality, we introduce a VGG-based style loss function coupled with the encoding loss of rectified flow to guide the style transfer towards photorealistic outputs. For semantic-aware stylization, we incorporate the LISA image segmentation model for high-level mask generation, ultimately enabling localized style transfer. Additionally, we construct a multi-exposure gradient (MEG) dataset which captures aligned scenes under varying exposure conditions and serves as a valuable benchmark for LLIE research. Extensive experiments demonstrate that TCSTNet outperforms state-of-the-art methods on the MEG, LOL and LOL-V2 datasets. Ablation studies further validate the contribution of each module in achieving high-quality and semantically coherent enhancements. Our MEG dataset is available at https://huggingface.co/datasets/RainS/MEG-Multi-Exposure-Gradient-dataset/tree/main},
  archive      = {J_ESWA},
  author       = {Tianyi Zeng and Tianyi Wang and Miao Zhang and Jun Yin and Zimo Zeng and Feiyang Zhang and Yangyang Wang and Junfeng Jiao and Yuantao Wang and Yangfan He and Junbo Tan and Christian Claudel and Xueqian Wang},
  doi          = {10.1016/j.eswa.2025.130012},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130012},
  shortjournal = {Expert Syst. Appl.},
  title        = {TCSTNet: A text-driven color style transfer network for low-light image enhancement},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid diagnosis method for rail service status based on the analysis of wheel–rail dynamics behavior with a PDVRD model. <em>ESWA</em>, <em>299</em>, 130011. (<a href='https://doi.org/10.1016/j.eswa.2025.130011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of wheel–rail dynamics behaviour provides a quantifiable method to assess the service performance of heavy haul railway rails. However, traditional vehicle–rail dynamics (VRD) models rely on global statistical track irregularity data, which limits their accuracy and practicality, especially when evaluating minor local rail surface damages. To address this issue, this paper proposes a prior data-driven VRD model (PDVRD), that integrates visual detection and dynamic analysis to evaluate rails’ performance. First, rail surface conditions are detected using an R-P image attention fusion network (RP-AFN), based on multisource information such as images, rail profiles, and geometric parameters. Then, in accordance with the analysis of the damage characteristics, the surface damages are mapped using corresponding local excitation functions. And then these data are automatically positioned and superimposed on the measured track irregularities. Subsequently, employing the superimposed excitations as input, the PDVRD model is developed and used to make simulations, the results of which are compared with those obtained with the traditional VRD model. Finally, the correlation between simulated and measured vibrations is analyzed globally and in localized damaged areas. Results show that the PDVRD model’s simulation aligns well with actual vibration responses both globally and locally, while the traditional VRD model shows significant discrepancies in local areas. The comparison results validate the effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Nengpu Yang and Miao Zhou and Wenkun Wang and Xi Chen and Yuan Cao},
  doi          = {10.1016/j.eswa.2025.130011},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130011},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid diagnosis method for rail service status based on the analysis of wheel–rail dynamics behavior with a PDVRD model},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards enhancing prototypes driven by graph convolutional network for domain adaptation. <em>ESWA</em>, <em>299</em>, 130010. (<a href='https://doi.org/10.1016/j.eswa.2025.130010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) is essential for transferring knowledge across domains with differing distributions, yet challenges like domain shifts and scarce labeled data limit performance. Prototype-based methods show promise on the DA task. This work introduces a prototype-based method, termed enhanced prototypical network (EnPro), for unsupervised domain adaptation (UDA) and semi-supervised domain adaptation (SSDA) settings with consistent architecture and training. We provide a theoretical analysis dividing the DA mapping space into consensus, vicinal , and vulnerable spaces. This improves classification by expanding the consensus and vicinal spaces while reducing the vulnerable space. To achieve this, we use a graph convolutional network (GCN) to increase labeled target samples through reliable pseudo-labels and enhanced prototypes. Experiments on UDA and SSDA benchmark datasets demonstrate state-of-the-art performance.},
  archive      = {J_ESWA},
  author       = {Ba Hung Ngo and Tae Jong Choi and Sung In Cho},
  doi          = {10.1016/j.eswa.2025.130010},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130010},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards enhancing prototypes driven by graph convolutional network for domain adaptation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Achieving dynamic controllability for simple temporal networks with uncertainty and sensing timepoints. <em>ESWA</em>, <em>299</em>, 130009. (<a href='https://doi.org/10.1016/j.eswa.2025.130009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of advanced sensors, executors in real-world planning domains can acquire information about temporal uncertainty through sensing activities, enabling the resolution of previously intractable planning problems. This development underscores the necessity of finding more dynamically controllable plans by leveraging sensing activities that reduce temporal uncertainty, thereby enhancing the solvability of planning problems under uncertainty. This paper addresses the problem of transforming weakly controllable temporal plans into dynamically controllable ones by inserting a minimal set of sensing activities. We propose Simple Temporal Network with Uncertainty and Sensing Timepoints (STNUST), an extension of the traditional Simple Temporal Network with Uncertainty (STNU) model that explicitly incorporates sensing activities. To support this model, we develop ST-BOSA, a novel algorithm composed of four interdependent modules for constraint propagation, redundancy elimination, sensing timepoint selection, and insertion. Extensive experiments on Mars rover-inspired scenarios and randomly generated networks demonstrate that the proposed approach effectively achieves dynamic controllability for networks while minimizing the number of inserted sensing timepoints. This framework shows promise for integration into planning systems in sensor-rich domains such as space exploration. Future work includes improving scalability and extending support to multi-agent settings.},
  archive      = {J_ESWA},
  author       = {Xianzhang Cheng and Chao Qi and Hongwei Wang and Yuhui Gao},
  doi          = {10.1016/j.eswa.2025.130009},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130009},
  shortjournal = {Expert Syst. Appl.},
  title        = {Achieving dynamic controllability for simple temporal networks with uncertainty and sensing timepoints},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Double-layer Q-learning guided NSGA-II for integrated production scheduling and inventory decision considering multi-product orders. <em>ESWA</em>, <em>299</em>, 130008. (<a href='https://doi.org/10.1016/j.eswa.2025.130008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality spare parts production and supply are critical for establishing sustained competitive advantages. However, limited manufacturing resources and tight delivery deadlines challenge enterprises in balancing delivery reliability and inventory capital occupation. The widespread existence of multi-product spare parts orders, characterized by interdependent delivery constraints, further complicates production resource allocation and operational coordination. To address these issues, this study treats production and inventory as dual sources for order fulfillment and investigates the integrated production scheduling and inventory decision optimization problem considering multi-product orders (IPSID-MPO), aiming to simultaneously minimize total inventory capital occupation and total order delay penalty. We propose a novel double-layer Q-learning-guided non-dominated sorting genetic algorithm-II (DQ-NSGA), incorporating key innovations: (i) a decoding strategy that considers product delivery constraints, (ii) a hybrid initialization mechanism integrating four problem-specific heuristics, (iii) knowledge-driven local search strategies, and (iv) a self-adaptive adjustment mechanism via double-layer Q-learning. The outer layer dynamically tunes crossover/mutation probabilities based on population evolution, while the inner layer guides individual-specific search strategies. Comprehensive experiments on 180 benchmark instances demonstrate DQ-NSGA’s superiority over mainstream comparative algorithms. Comparisons with common simplified models that consider single-product orders demonstrates the necessity of incorporating multi-product orders in production and inventory decision-making. Furthermore, compared to Make-to-Stock and Make-to-Order paradigms, the proposed IPSID-MPO model not only reduces inventory carrying costs by 28.7% but also effectively enhances the flexibility of the manufacturing system.},
  archive      = {J_ESWA},
  author       = {Juan Zhou and Qianwang Deng and Yinwen Ma and Rui Pan and Jingxing Zhang and Mao Tan},
  doi          = {10.1016/j.eswa.2025.130008},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130008},
  shortjournal = {Expert Syst. Appl.},
  title        = {Double-layer Q-learning guided NSGA-II for integrated production scheduling and inventory decision considering multi-product orders},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balanced multi-objective evolution algorithm for unmanned systems project scheduling with preventive maintenance and order grouping constraints. <em>ESWA</em>, <em>299</em>, 130006. (<a href='https://doi.org/10.1016/j.eswa.2025.130006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing deployment of unmanned systems in multi-platform operations, intelligent scheduling has become increasingly critical. These systems are typically organized into distributed mission clusters, executing sequences of mission-critical operations under resource and operational constraints. Inspired by the structural similarity between unmanned systems coordination and manufacturing workflows, this paper reformulates the scheduling problem of unmanned missions as a distributed permutation flowshop scheduling problem. Two domain-specific factors are incorporated into the model: preventive maintenance and order grouping, with the objective of minimizing total tardiness and makespan. To address this problem, a balanced multi-objective evolution algorithm (BMOEA) is proposed. Initially, two improved heuristic algorithms based on NEH2 are used to balance the quality and diversity of initial solutions. Then, four target-specific operators and two crossover operators are designed to improve the search efficiency of the algorithm. Next, three criteria are developed to balance local and global search: a classification-based operator selection criterion, which dynamically adjusts the search direction of operators to optimize local search; a non-periodic evaluation criterion based on Kernel Density Estimation and a non-dominated solution threshold criterion, which accurately determines the timing for switching to global search. These criteria balance exploration and exploitation, allowing the algorithm to optimize both convergence speed and population diversity, expand the feasible domain, and steadily approach the Pareto front. Finally, the experimental results reveal that BMOEA delivers superior performance compared to the most advanced algorithms available.},
  archive      = {J_ESWA},
  author       = {Xin Zhou and Guodong Ling and Jiayi Yu and Tian Zhou and Rui Wang},
  doi          = {10.1016/j.eswa.2025.130006},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130006},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balanced multi-objective evolution algorithm for unmanned systems project scheduling with preventive maintenance and order grouping constraints},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-graph regularized non-negative tucker decomposition and its semi-supervised extension for image clustering. <em>ESWA</em>, <em>299</em>, 130005. (<a href='https://doi.org/10.1016/j.eswa.2025.130005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative Tucker decomposition (NTD) is a popular technique for extracting a low-dimensional representation of tensor data, but NTD is unsupervised. As an important means of presenting geometric information of data space, graph has been frequently employed. Many graph-based NTD approaches have been proposed. However, these approaches rely on a single representation of data space when leveraging graphs, which overlooks some graphs derived from other representations of data space. To address this limitation, we propose a multi-graph regularized NTD (MGNTD) method by constructing a multi-graph regularization into NTD. MGNTD can extract a low-dimensional space where multi-graph structures of data space are preserved. We further extend MGNTD to a semi-supervised version called multi-graph regularized semi-supervised NTD (MGSNTD) by incorporating a small amount of label information into MGNTD. MGSNTD can find an excellent low-dimensional representation by propagating label information and preserving geometrical structures contained in multiple graphs of data space. Efficient algorithms to solve the MGNTD and MGSNTD methods are presented, and the corresponding convergence is also analyzed. Extensive experiments on five real-world data sets are conducted to demonstrate the effectiveness and superiority of these two proposed methods.},
  archive      = {J_ESWA},
  author       = {Wenjing Jing and Linzhang Lu and Qilong Liu and Zhen Chen},
  doi          = {10.1016/j.eswa.2025.130005},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130005},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-graph regularized non-negative tucker decomposition and its semi-supervised extension for image clustering},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating BiLSTM and CNN for predicting user mobility from geotagged social media posts. <em>ESWA</em>, <em>299</em>, 130004. (<a href='https://doi.org/10.1016/j.eswa.2025.130004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems for social media platforms face significant challenges in accurately capturing user preferences from unstructured geotagged data. This research introduces a hybrid recommendation system leveraging Convolutional neural networks (CNNs) paired with Bidirectional Long Short-Term Memory (BiLSTM) networks to improve the prediction of user mobility and preferences. The proposed model calculates user similarity by analyzing opinions and preferences extracted from social media posts, combining CNN strength in feature extraction with BiLSTM ability to capture users dependencies. By incorporating demographic data, the system addresses the cold-start issue and improves recommendation accuracy by utilizing contextual information. Experimental results using datasets from Yelp and Flickr demonstrate significant advancements in RMSE, F-Score, MAP, and NDCG metrics. These findings highlight the effectiveness of the CNN-BiLSTM hybrid approach in generating personalized, sentiment-aware, and contextually rich recommendations on social media platforms.},
  archive      = {J_ESWA},
  author       = {Zhao Yu and Zohre Moradi},
  doi          = {10.1016/j.eswa.2025.130004},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130004},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrating BiLSTM and CNN for predicting user mobility from geotagged social media posts},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards smarter warehouse perception: Integrating adaptive tile segmentation in warehousing object detection pipelines. <em>ESWA</em>, <em>299</em>, 130003. (<a href='https://doi.org/10.1016/j.eswa.2025.130003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional object detection methods struggle in complex logistics and warehousing environments due to their inability to effectively identify regions of interest while handling extreme occlusion, high object density, and significant scale variations with static. Existing region proposal approaches (anchor-based, anchor-free, and deep learning-based) require meticulous hyperparameter tuning, struggle with small or overlapping objects, have difficulties with different lighting conditions or suffer from poor localization in cluttered scenes. We introduce Adaptive Tiles , a novel preprocessing algorithm that dynamically identifies potential object regions prior to detection, thereby addressing these limitations. The core mechanism involves a three-step process: (1) zero-shot segmentation for adaptable, object-agnostic mask generation, (2) filter heuristics to refine masks into robust region proposals, and (3) bounding box combination for merging proposals into optimal detection zones. By shifting from static region identification methods to a dynamic, segmentation-driven proposal mechanism, Adaptive Tiles significantly enhances the efficiency and accuracy of object detectors, as demonstrated by its integration into the DMZoomNet framework and evaluation on the challenging LOCO dataset.},
  archive      = {J_ESWA},
  author       = {Carlos Clavero and Miguel A. Patricio and Jesús García and José M. Molina},
  doi          = {10.1016/j.eswa.2025.130003},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130003},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards smarter warehouse perception: Integrating adaptive tile segmentation in warehousing object detection pipelines},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Activation-driven discrepancy as evidence for generalized neural interpretability. <em>ESWA</em>, <em>299</em>, 130001. (<a href='https://doi.org/10.1016/j.eswa.2025.130001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Architectural and operational variances among Deep Neural Networks (DNNs) limit the universal applicability of existing activation-based explainability methods. In this paper, we propose a model-agnostic framework for interpreting network decisions by clarifying the gap between the transferred activations and those of the original model. Notably, even when given an empty input, a model can produce a plausible prediction based solely on the activation information retained from the original prediction. Our motivation starts from this phenomenon, assuming that an incomplete prediction contains a rough representation of neural information that is approximate to the original model’s prediction, yet missing key details. Conversely, clarifying the distributional gap between these activation differences could help identify crucial factors influencing model predictions. To address this, we introduce Activation Presence Transfer (APT), a method that transfers neuron activation information to a cloned model, preserving the nature of the original model’s prediction when given a blank image. Next, we propose the Residual Attribution Map (RAM), which quantifies distributional discrepancies across layers and generates integrated attribution maps using both weights and gradients. In a verified experimental setup, we conduct comparative analyses against existing methods on various CNN and Transformer models to validate its model-agnostic nature. The experimental results demonstrate superior performance compared to existing approaches that are specifically tailored to particular model types.},
  archive      = {J_ESWA},
  author       = {Ho Kyung Shin and Woo-Jeoung Nam},
  doi          = {10.1016/j.eswa.2025.130001},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130001},
  shortjournal = {Expert Syst. Appl.},
  title        = {Activation-driven discrepancy as evidence for generalized neural interpretability},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An enhanced PSO algorithm for integrated irregular flight recovery with heterogeneity and multi-runway considerations. <em>ESWA</em>, <em>299</em>, 130000. (<a href='https://doi.org/10.1016/j.eswa.2025.130000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe disruptions such as airport closures pose significant challenges to the stability and efficiency of air transportation networks. Most existing recovery studies are based on the assumption of flight homogeneity, failing to reflect the real-world differences in resource allocation and priority levels, while also overlooking the operational characteristics of multi-runway airports. To address these limitations, this paper develops an integrated optimization model that accounts for flight heterogeneity, multi-runway attributes, and aircraft-crew resource recovery constraints. Given the model’s nonlinear, strongly coupled, and highly constrained nature, we propose a novel enhanced Convergence-Diversity Particle Swarm Optimization algorithm, termed CDPSO. This algorithm incorporates a dual-population evolutionary framework with innovative evolutionary mechanisms and a feasible-solution probing strategy, significantly improving both solution quality and efficiency. Furthermore, a series of infeasibility-repair mechanisms are designed to ensure solution feasibility. Experimental validation using real-world cases of varying scales demonstrates that the proposed method outperforms seven peer algorithms in recovery effectiveness and adaptability. The results also confirm the significance of incorporating flight heterogeneity into the model for effectively reducing recovery costs.},
  archive      = {J_ESWA},
  author       = {Huifen Zhong and Chen Guo and Lijing Tan and Otilia Manta and Gabriel Xiaoguang Yue and Ben Niu},
  doi          = {10.1016/j.eswa.2025.130000},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {130000},
  shortjournal = {Expert Syst. Appl.},
  title        = {An enhanced PSO algorithm for integrated irregular flight recovery with heterogeneity and multi-runway considerations},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mind-pinyin speller: A non-invasive brain-computer interface for efficient chinese character input using EEG-based imagined handwriting. <em>ESWA</em>, <em>299</em>, 129999. (<a href='https://doi.org/10.1016/j.eswa.2025.129999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each year, millions of individuals lose their ability to move and communicate because of illnesses or accidents, creating an urgent need for innovative solutions that can restore language communication. While invasive brain-computer interfaces (BCIs) have demonstrated high speed and reliability in helping individuals regain communication abilities, their high costs and surgical risks make them impractical for temporary conditions. Non-invasive BCIs offer a more affordable and accessible alternative, but they suffer from challenges such as lower decoding accuracy, slower speed, dependence on passive typing paradigms, and potential long-term health risks, including epilepsy. Furthermore, existing research has primarily focused on phonetic languages like English, leaving a critical gap for logographic languages like Chinese, which serves over one-sixth of the global population. This study introduces the Mind-Pinyin Speller, an innovative active-mode Chinese spelling system that decodes electroencephalogram (EEG) signals to identify the imagined writing of 23 consonants and 23 vowels. We have improved the CSP feature extraction strategy by employing a pairwise extraction method and have introduced a novel CNN-fuzzy-attention network (CFAN) that integrates a fuzzy layer into the CNN-transformer structure. Our system achieves an average output accuracy of 75.7 % for both vowels and consonants, with an information transfer rate (ITR) of 160 bits/min, doubling the 80 bits/min typically observed in existing BCI spelling systems. Users can produce a vowels and consonants in less than three seconds, enabling an estimated generation of up to ten Chinese characters per minute. By directly tackling the linguistic complexity of Chinese and leveraging active imagination for spelling, the Mind-Pinyin Speller delivers a high-speed solution tailored for individuals with speech and motor impairments. This breakthrough not only meets the unique needs of Chinese speakers but also paves the way for future innovations in BCI applications for logographic languages.},
  archive      = {J_ESWA},
  author       = {Lingyu Wu and Tzyy-Ping Jung and Xiaojian Li and Yanhong Zhou and Xianglong Wan and Wenlong Jiao and Xueguang Xie and Dingna Duan and Tiange Liu and Hao Yu and Danyang Li and Xiaoling Li and Zhenzhen Wu and Jing Wang and Haiqing Song and Dong Wen},
  doi          = {10.1016/j.eswa.2025.129999},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129999},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mind-pinyin speller: A non-invasive brain-computer interface for efficient chinese character input using EEG-based imagined handwriting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BAFNet: Deep contour-aware features for colorectal polyps segmentation. <em>ESWA</em>, <em>299</em>, 129998. (<a href='https://doi.org/10.1016/j.eswa.2025.129998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature channel selection has proven to be an effective strategy for establishing a top-down neural attention mechanism that refines and enhances semantic features for central representation. The quality of the semantic segmentation results for colorectal polyps is significantly influenced by both the encoder and decoder, with the encoder playing a pivotal inductive role in guiding the decoder’s final output. To improve the semantic accuracy of colorectal polyp segmentation in medical image-processing tasks, we introduce a boundary-aware feature fusion neural network (BAFNet). BAFNet incorporates two novel approaches. First, a gating branch was designed to construct an inhibition mechanism that selects high-quality contour features. This branch integrates a gating module with four convolutional-Batch Normalization (conv-BN) blocks. Second, to further construct prominent semantic features, we propose and incorporate the multi-scale feature aggregation module (MFAM) and dynamic global attention module (DGAM) as a robust feature constructor, parsing the semantics as a foreground representation. When tested on the CVC-ColonDB, ETIS, and EndoScene benchmark datasets, the proposed method achieved DICE scores of 0.808, 0.808, and 0.914; IoU scores of 0.722, 0.732, and 0.863; and F-measure scores of 0.782, 0.774, and 0.905, respectively, demonstrating a balanced and robust performance in colorectal polyp segmentation. Our neural network, with 5.98 million parameters and 3.59 GFLOPs, significantly outperforms ASCNet, MSNet, TransFuse, C 2 F-Net, and PraNet. These results demonstrate that the proposed algorithm is highly suitable for colorectal polyp segmentation applications and provides a robust solution for advancing medical image processing technology.},
  archive      = {J_ESWA},
  author       = {Dibin Zhou and Ni Chen and Yueping Zhu and Xueyan Zhang and Innocent Nyalala and Jiayu Zhang and Junfeng Gao},
  doi          = {10.1016/j.eswa.2025.129998},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129998},
  shortjournal = {Expert Syst. Appl.},
  title        = {BAFNet: Deep contour-aware features for colorectal polyps segmentation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Human-computer interaction design and evaluation of a virtual reality-based comprehensive training system for vascular interventional surgery. <em>ESWA</em>, <em>299</em>, 129997. (<a href='https://doi.org/10.1016/j.eswa.2025.129997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vascular interventional surgery represents a highly effective approach to treating cardiovascular diseases, requiring physicians to demonstrate exceptional hand-eye coordination and proficiency in manipulating interventional tools with precision, highlighting the need for thorough professional training. Nevertheless, conventional training approaches for vascular interventional surgery are expensive and involve radiation risks, failing to meet the contemporary educational requirements of the medical field. This study has introduced a comprehensive training system for vascular interventional surgery that simulates real surgical conditions, offering a safe platform for physicians to engage in repetitive training sessions. From the perspective of human–computer interaction design, the system constructs a “module–event” dual-driven interaction framework that covers the entire vascular intervention process. The interaction logic is designed strictly in accordance with the actual surgical procedures executed by clinical experts, so as to ensure the realism and usability of the training process. Additionally, by integrating levels of detail (LOD) techniques, the system enhances graphic rendering efficiency, ensuring smooth system operation. In terms of interface design, the study utilizes emotional design theory to enhance users’ intuitive experiences and operational logic, thereby improving the system’s acceptability and educational effectiveness. To quantitatively evaluate user experience, this research gathered feedback through the user experience questionnaire (UEQ) and eye-tracking experiments. Results indicate that the system outperformed UEQ benchmark data in terms of attractiveness, clarity, and novelty, showcasing exceptional overall performance. Furthermore, the study employed real-time data analyzer (Profiler) in Unity3D to conduct performance analysis of all interactive content within the training system. The results revealed that the average frames per second (FPS) during interactive training sessions peaked at 97.2, with average response times per frame at each stage remaining under 15.4 ms. This achievement demonstrates a high level of performance in the realm of virtual reality application development.},
  archive      = {J_ESWA},
  author       = {Pan Li and Xiaowei Hu and Boxuan Xu and Xinxin Zhang and Fangting Ding and Cunman Liang},
  doi          = {10.1016/j.eswa.2025.129997},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129997},
  shortjournal = {Expert Syst. Appl.},
  title        = {Human-computer interaction design and evaluation of a virtual reality-based comprehensive training system for vascular interventional surgery},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalizing inverse data envelopment analysis through directional distance function. <em>ESWA</em>, <em>299</em>, 129996. (<a href='https://doi.org/10.1016/j.eswa.2025.129996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional inverse data envelopment analysis (DEA) models focus on either input-oriented or output-oriented scenarios. However, in many real-world problems, it is desirable to adjust both inputs and outputs. In this paper, we introduce directional distance function inverse DEA models that consider input and output perturbations simultaneously. Our method determines the ideal input–output combination for DMUs by considering both the intended outputs and the available additional inputs, in contrast to traditional inverse DEA models. To find the optimal combination of inputs and outputs for the DMU being evaluated, we use a mixed-oriented perturbation that preserves the efficiency scores of all DMUs. To illustrate the concept and logic of the proposed models, we provide a numerical example. Furthermore, we demonstrate the strength, expediency, and suitability of our models through a real-world application in the context of a supermarket chain.},
  archive      = {J_ESWA},
  author       = {Mojtaba Ghiyasi and Ali Emrouznejad and Gholam R. Amin},
  doi          = {10.1016/j.eswa.2025.129996},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129996},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generalizing inverse data envelopment analysis through directional distance function},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient column generation approach for crew re-scheduling and recovery in urban rail transit systems under emergency conditions. <em>ESWA</em>, <em>299</em>, 129993. (<a href='https://doi.org/10.1016/j.eswa.2025.129993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crew Re-Scheduling Problem is a significant challenge in urban rail transit systems, particularly when addressing service disruptions and restoring operational order. When crew members unexpectedly sign off due to emergencies (e.g., illness), the train assigned to their operation task may be stranded in one running direction. This can subsequently cause obstructions for trains following in the same direction, thereby impacting normal operations. To address this issue, we first propose introducing a closed-loop scheduling mode, which involves rearranging the finite crew members across both running directions to sustain operations during emergency periods. Subsequently, a Crew Re-Scheduling and Recovery (CRSRP) model is developed to response the depart-time changes of trains. To solve the model, a generic framework of column generation (CG) embedded labeling algorithm is re-engineered to meet re-scheduling time requirements and permit changes in running directions at disrupted stations, which could be adopted in different emergency phases. It is important to note that after fireman crews are supplemented, all crew members resume normal operations, but emergency tasks must still be prioritized. A greedy algorithm is devised to manage assignments during the recovery phase. Finally, a real-life case study from Beijing is presented to assess the effectiveness of the proposed method. The model demonstrates the capability to respond swiftly within 30 min post-accident and control the generation time of individual tasks within 1 min. Additionally, the fluctuation range of crew members’ scheduling time has been reduced to [4, 21] minutes. This evidence underscores the model’s efficacy in restoring operational order under emergency conditions.},
  archive      = {J_ESWA},
  author       = {Mengjiao Zhao and Songpo Yang and Xin Yang and Jianjun Wu},
  doi          = {10.1016/j.eswa.2025.129993},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129993},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient column generation approach for crew re-scheduling and recovery in urban rail transit systems under emergency conditions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dependence assessment method based on quantum model of mass function in human reliability analysis. <em>ESWA</em>, <em>299</em>, 129992. (<a href='https://doi.org/10.1016/j.eswa.2025.129992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human reliability analysis (HRA) has garnered widespread attention in high-reliability-demand fields such as the nuclear industry. The dependence assessment among human failure events (HFEs) constitutes a crucial component of HRA research, as it enhances the accuracy of HRA outcomes and contributes to reducing human error probabilities. This paper proposes a novel method based on the quantum model of mass function (QMMF) to address dependence assessment in HRA under uncertain dynamic scenarios. Firstly, dependence influencing factors are identified and their basic belief assignments (BBAs) are constructed based on expert evaluations. Then, a time correction model is developed to generate time-corrected BBAs, upon which the QMMF is applied to reconstruct dynamic factor BBAs. Finally, the conditional human error probability (CHEP) is calculated through the fusion of reconstructed dynamic factor BBAs and static factor BBAs. The proposed method, grounded in quantum evidence theory, assigns the physical meaning of “time” to the “phase angle” variable, enabling flexible expression of evidence evolution over time while maintaining solid theoretical foundations and compatibility. Additionally, the method allows adjustment of temporal correction intensity for dynamic factors by modifying the weight distribution in time-corrected BBAs. Case study results demonstrate that the proposed method can yield more accurate and rational outcomes.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xuying Huang and Xiaolei Pan and Debiao Meng},
  doi          = {10.1016/j.eswa.2025.129992},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129992},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dependence assessment method based on quantum model of mass function in human reliability analysis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-module framework for enhanced day-ahead photovoltaic power forecasting considering input heterogeneity. <em>ESWA</em>, <em>299</em>, 129991. (<a href='https://doi.org/10.1016/j.eswa.2025.129991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate day-ahead photovoltaic (PV) power forecasting is crucial for safe, stable renewable energy integration, sustainable energy transition, and informed decision-making in the energy sector. However, existing methods often struggle to exploit historical data periodicity fully, align with Numerical Weather Prediction (NWP) data, leverage surrounding site information, or account for heterogeneous input, limiting practical applicability. This paper proposes SD-FGF-EC, a novel multi-module framework integrating signal decomposition (SD), feature grouping and fusion (FGF), and error compensation (EC) for enhanced day-ahead PV power forecasting. Specifically, the SD module, utilizing Seasonal-Trend decomposition using Loess (STL), captures temporal patterns of historical data. The FGF mechanism categorizes and fuses heterogeneous inputs (including historical data, NWP data, and surrounding site information) through an orchestrated ensemble within a parallel Bi-directional Long Short-Term Memory (Bi-LSTM) neural network, enabling seamless alignment and utilization of diverse data sources. Moreover, it embeds a ridge regression-based method for missing value imputation and Light Gradient Boosting Machine (LightGBM) for EC, further enhancing performance. Evaluated on nine China's southeast coastal PV sites, SD-FGF-EC outperforms 12 baseline schemes and five state-of-the-art (SOTA) models. Compared to a standard Bi-LSTM neural network, SD-FGF-EC achieves average reductions of 45.64% in Mean Absolute Error (MAE), 43.29% in Root Mean Squared Error (RMSE), and 54.44% in coefficient of determination (R 2 ), along with average improvements of 6.36% in Correct Rate (CR) and 7.29% in Qualification Rate (QR). Overall, SD-FGF-EC introduces a novel paradigm for day-ahead photovoltaic power forecasting.},
  archive      = {J_ESWA},
  author       = {Lei Fang and Bin He and Chenggong Zhang},
  doi          = {10.1016/j.eswa.2025.129991},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129991},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-module framework for enhanced day-ahead photovoltaic power forecasting considering input heterogeneity},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid learning framework integrating fisher linear discriminant and localized support vector machines. <em>ESWA</em>, <em>299</em>, 129990. (<a href='https://doi.org/10.1016/j.eswa.2025.129990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid learning strategy, termed FLD-based Localized SVMs (FL-SVMs), for accelerating Support Vector Machine (SVM) classification. Departing from existing approaches focused on reducing support vectors, FL-SVMs integrates localized SVMs (L-SVMs) with Fisher Linear Discriminant (FLD). The strategy first employs FLD to capture global dataset structural information and partition the data into non-overlapping subsets. Subsequently, L-SVMs are applied to each subset to determine optimal hyperplanes. Theoretical analysis establishes the consistency of FL-SVMs. To address the reliance on manual hyperparameter selection in FLD for subset partitioning, an enhanced self-adaptive version (SFL-SVMs) is introduced. Experimental evaluations on benchmark datasets demonstrate that classifiers based on FL-SVMs and SFL-SVMs achieve both lower misclassification rates and significantly reduced training times compared to alternative methods.},
  archive      = {J_ESWA},
  author       = {Jingjing Zeng and Yimo Qin and Bin Zou and Jie Xu and Peipei Dong},
  doi          = {10.1016/j.eswa.2025.129990},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129990},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid learning framework integrating fisher linear discriminant and localized support vector machines},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EGFE-net: An edge-guided and feature elimination network for small object detection. <em>ESWA</em>, <em>299</em>, 129989. (<a href='https://doi.org/10.1016/j.eswa.2025.129989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small objects typically contain relatively little feature information, and small object detection is vulnerable to interference from the features of medium and large objects. To obtain sufficient feature information for small objects during small object detection, we propose a novel network framework named the Edge-Guided and Feature Elimination Network (EGFE-Net) to ensure that rich spatial and semantic information is extracted from small objects and reduce interference from medium and large objects. Our EGFE-Net includes two main parts: (1) a feature extraction block using a collaborative enhanced dual-backbone network; (2) a feature processing block consisting of a feature pyramid module, an edge guidance module and a feature elimination module. Our main idea is first to use the dual-backbone network to enhance the expression of small object features. Then, the edge guidance module and feature elimination module are applied to an additional high-resolution feature layer of the feature pyramid to direct the model to pay more attention to small objects during the training process. Experimental results show that, compared with the two baseline networks RetinaNet and YOLOv8 on the MS COCO dataset, our method improves the detection accuracy of small objects by 2.9 % and 8.0 % respectively, achieving state-of-the-art results. Additionally, an Adaptive Feature Attention (AFA) module is explored as an extension to improve model generality, achieving consistent improvements on both the MS COCO and Pascal VOC datasets.},
  archive      = {J_ESWA},
  author       = {Xuesong Liu and Baolin Liu},
  doi          = {10.1016/j.eswa.2025.129989},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129989},
  shortjournal = {Expert Syst. Appl.},
  title        = {EGFE-net: An edge-guided and feature elimination network for small object detection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Building adaptative and transparent cyber agents with local language models. <em>ESWA</em>, <em>299</em>, 129987. (<a href='https://doi.org/10.1016/j.eswa.2025.129987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous intelligent agents offer a transformative approach to cyber defense by operating independently in complex and dynamic environments. While much research has focused on defensive systems, offensive agents are equally important for testing system resilience and improving defenses through realistic adversarial interaction. Recent advances demonstrate that large language models can automate penetration testing effectively, rivaling traditional reinforcement learning methods, but their reliance on cloud-based services introduces significant concerns around privacy and reproducibility. Smaller language models provide a promising alternative for local deployment in environments with limited resources or strict confidentiality requirements. Although these models have limitations, such as smaller context windows and a higher tendency to generate incorrect information, their performance can be enhanced through domain-specific fine-tuning techniques like supervised fine-tuning and direct preference optimization. In this study, we fine-tune a seven-billion-parameter version of the Zephyr model to create an autonomous penetration testing agent called Hackphyr, which is integrated into a cognitive architecture for autonomous decision-making. We evaluate Hackphyr in a simulated network security environment designed for ethical cybersecurity research and aligned with real-world attack tactics. In extensive evaluations, Hackphyr achieved win rates above 85 % in simpler scenarios without defenders and 23–50 % in more complex scenarios. The Hackphyr-based agent outperformed all baseline agents, and it was consistently approaching the performance of the most capable commercial models, even in unfamiliar scenarios. Beyond its penetration testing performance, Hackphyr exhibits structured strategic behavior aligned with realistic attack stages such as reconnaissance, privilege escalation, lateral movement, and data exfiltration. These findings highlight the potential of locally deployed small language models to support effective and transparent offensive operations in cybersecurity.},
  archive      = {J_ESWA},
  author       = {Maria Rigaki and Carlos A. Catania and Sebastian García},
  doi          = {10.1016/j.eswa.2025.129987},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129987},
  shortjournal = {Expert Syst. Appl.},
  title        = {Building adaptative and transparent cyber agents with local language models},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Universal source-free domain adaptation method with feature decomposition for machinery fault diagnosis. <em>ESWA</em>, <em>299</em>, 129986. (<a href='https://doi.org/10.1016/j.eswa.2025.129986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of domain adaptation algorithms has significantly accelerated the deployment of intelligent diagnostic technologies. However, existing domain adaptation methods predominantly focus on closed-set fault diagnosis and rarely address data privacy concerns, limiting their applicability in industrial settings. To this end, a universal source-free domain adaptation method is proposed. Initially, a source model is pre-trained using labeled source data. This pre-trained model then processes the target data to decompose the target features into common class components and unknown class components, while simultaneously generating target prototypes and source anchors. Subsequently, the distribution of the unknown class components is estimated using a Gaussian mixture model with two components. Finally, a confidence estimation strategy is developed to derive instance-level decision boundaries by evaluating the distance between target prototypes and source anchors, thereby completing the classification task. Experimental results on gearbox and rolling bearing datasets demonstrate that our approach excels in handling fault diagnosis under varying conditions while ensuring data privacy.},
  archive      = {J_ESWA},
  author       = {Ruixin Wang and Zhenghong Wu and Jiangfeng Fu and Han Zhang and Haidong Shao},
  doi          = {10.1016/j.eswa.2025.129986},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129986},
  shortjournal = {Expert Syst. Appl.},
  title        = {Universal source-free domain adaptation method with feature decomposition for machinery fault diagnosis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCTrack: Multi-cue spatio-temporal object tracking. <em>ESWA</em>, <em>299</em>, 129984. (<a href='https://doi.org/10.1016/j.eswa.2025.129984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents MCTrack, a multi-cue spatio-temporal object tracking method designed to fully exploit the multi-dimensional spatio-temporal information of the object in video sequences, thereby enhancing the tracker’s robustness in complex scenes. Unlike previous approaches that collapse appearance and temporal cues into a single latent, this study explicitly disentangles the object representation into three complementary yet distinct cues: the initial cue capturing a clean appearance prior and structural shape, the dynamic cue modeling short-term appearance drift and rapid local changes, and the historical cue aggregates temporal features from consecutive frames to construct a motion memory of the object. By directly incorporating multi-cue information into the encoding stage, temporal information is able to directly optimize low-level feature representations and cross-cue interactions, thereby providing early guidance for spatial encoding. For the historical cue, a Historical Context Aggregation Module designed to aggregate the object’s historical information within a certain temporal range. Additionally, the proposed Tracking Head Guided by Spatio-Temporal Decoding generates a historical query from the historical cue and enhances the object region features through weighted fusion with the search region feature. In this process, the historical cue serves as a bridge between spatio-temporal encoding and tracking head, introducing contextual information into the tracking head while simultaneously reflecting its discriminative demands onto the regions and channels emphasized during encoding. Furthermore, a confidence prediction module based on temporal attention of historical cue is proposed for multi-cue online updating. Extensive evaluations on multiple benchmarks demonstrate that MCTrack achieves state-of-the-art performance, particularly on the one-shot tracking benchmark GOT-10k, achieving the AO of 79.4 %, which is a 3.5 % improvement over baseline DropTrack.},
  archive      = {J_ESWA},
  author       = {Jianbo Song and Hong Zhang and Hanyang Liu and Yachun Feng and Yang Han and Yifan Yang},
  doi          = {10.1016/j.eswa.2025.129984},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129984},
  shortjournal = {Expert Syst. Appl.},
  title        = {MCTrack: Multi-cue spatio-temporal object tracking},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unlocking gait semantics: A multimodal lifelong gait recognition framework with decoupled features and attribute-driven mixture of experts. <em>ESWA</em>, <em>299</em>, 129983. (<a href='https://doi.org/10.1016/j.eswa.2025.129983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition, as a critical biometric technology, continues to face challenges under existing paradigms, including error accumulation from upstream tasks and insufficient semantic understanding. Moreover, real-world deployment demands the capability to continuously learn new identities and variations without succumbing to catastrophic forgetting. To address these issues, we propose SemGait, a novel multimodal lifelong gait recognition framework that integrates structured semantic descriptions with visual information. Specifically, we introduce the Gait Semantic Description Framework (GSDF), which converts low-level kinematic features from 2D skeleton sequences into rich, interpretable natural language descriptions, thereby bridging the gap in textual semantics within gait analysis. To harness the complementary advantages of multimodal inputs, SemGait adopts a multi-stage feature learning pipeline comprising Specific and Shared Feature Decoupling (SSFD) to disentangle modality-specific and shared representations; Gait Attribute Knowledge Encoder (GAKE) to capture fine-grained attribute-level semantics; and Attribute-Driven Mixture of Experts (ADMoE) to enable discriminative fusion of visual, textual, and attribute features. To facilitate effective lifelong learning, we further propose Lifelong Gait Learning Strategies (LGLS), which include the Attribute-Anchored Forgetting Suppression (AFS) mechanism for preserving prior knowledge and the Adaptive Knowledge Transfer (AKT) mechanism for enhancing generalization to new domains. Extensive experiments on four public benchmark datasets demonstrate that SemGait consistently surpasses state-of-the-art methods in both within-domain and cross-domain gait recognition. Furthermore, in lifelong learning scenarios, it exhibits superior robustness against catastrophic forgetting while maintaining strong adaptability to new conditions, highlighting the effectiveness of the proposed multimodal and lifelong learning strategies.},
  archive      = {J_ESWA},
  author       = {Hao Xi and Peng Lu and Kai Ren and Yongqiang Li and Jinhao Fan and Chuanping Hu},
  doi          = {10.1016/j.eswa.2025.129983},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129983},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unlocking gait semantics: A multimodal lifelong gait recognition framework with decoupled features and attribute-driven mixture of experts},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). YOLO-DLA: A YOLO-based unified framework for multi-scale document layout analysis. <em>ESWA</em>, <em>299</em>, 129981. (<a href='https://doi.org/10.1016/j.eswa.2025.129981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document layout analysis (DLA) serves as a cornerstone of modern information systems, enabling efficient data extraction and structured knowledge organization. However, processing multi-scale layout documents has remained a bottleneck in the development of universal DLA frameworks. To address this limitation, we introduce the first multi-scale DLA dataset and propose a novel YOLO-based detection framework. Specifically: (1) To address the lack of fine-grained layout annotations in existing datasets, we construct AcadLayout , a specialized dataset for scientific documents with 13 layout element types (e.g., multi-level headings, formula, figure caption). (2) To address the challenges of multi-scale feature extraction, particularly for micro-scale elements, we innovatively incorporate the KWConv dynamic convolution method. (3) To achieve robust feature fusion across scales, we propose the PRDM-neck module, which uniquely integrates axial attention with multi-scale context aggregation. (4) To address scale imbalance in scientific documents, we propose a scale-aware curriculum learning strategy that progressively trains models from macro- to micro-scale elements (macro → medium → micro), effectively balancing detection performance across all scales.},
  archive      = {J_ESWA},
  author       = {Haoyan Qi and Xinyang Meng and Zhijuan Du},
  doi          = {10.1016/j.eswa.2025.129981},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129981},
  shortjournal = {Expert Syst. Appl.},
  title        = {YOLO-DLA: A YOLO-based unified framework for multi-scale document layout analysis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time bipartite flocking of perturbed networked UAV systems: A distributed optimization approach. <em>ESWA</em>, <em>299</em>, 129979. (<a href='https://doi.org/10.1016/j.eswa.2025.129979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flocking, inspired by the collective dynamics observed in biological swarms, exemplifies the emergence of self-organization and swarm intelligence through local agent interactions. Motivated by these principles, this paper investigates the fixed-time bipartite flocking control problem for networked unmanned aerial vehicle (UAV) systems under external disturbances from the perspective of distributed optimization. The proposed solution addresses key concerns in multi-agent coordination, including the emergence rate of flocking behavior, robustness against uncertainties, and performance optimization. A hierarchical distributed optimal control framework is developed, consisting of a distributed optimization layer and a trajectory tracking layer. Theoretically, the proposed control scheme ensures (i) convergence to the global optimum of the distributed optimization problem within a fixed time, and (ii) fixed-time emergence of bipartite flocking behavior characterized by subgroup cohesion and velocity alignment. The stability of the closed-loop system is rigorously established via a Lyapunov-based analysis method, which also guarantees robustness against dynamic disturbances. In addition, explicit upper bounds on the settling time for both layers are derived, allowing the trade-off between convergence speed and control effort to be tuned through parameter selection. Finally, numerical simulations together with real-world experiments are presented to validate the effectiveness and practical feasibility of the proposed fixed-time bipartite flocking control scheme.},
  archive      = {J_ESWA},
  author       = {Weihao Li and Mengji Shi and Lei Shi and Boxian Lin},
  doi          = {10.1016/j.eswa.2025.129979},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129979},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fixed-time bipartite flocking of perturbed networked UAV systems: A distributed optimization approach},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking depth: Depth estimation from sparse events with spiking neural networks. <em>ESWA</em>, <em>299</em>, 129977. (<a href='https://doi.org/10.1016/j.eswa.2025.129977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras provide remarkable temporal resolution, wide dynamic range, and low power consumption, making them ideal for depth estimation in high-contrast and dynamic environments. While spiking neural networks (SNNs) are naturally suited to process event data, their performance in depth estimation tasks has not consistently surpassed those of traditional artificial neural networks (ANNs) because of the former’s lack of effective mechanisms for handling the sparse nature of event data. Herein, we propose Spiking Depth, a novel end-to-end SNN framework designed to overcome the limitations of current ANN models and achieve superior depth estimation from sparse event data. In particular, Spiking Depth introduces three key innovations: an event encoding module based on a spiking-driven fusion block (SDFB), enhanced skip connections incorporating both SDFB and an adaptive spiking convolutional block attention module, and the event depth loss that optimizes depth estimation by addressing the sparse and dynamic nature of event data. Spiking Depth outperforms current state-of-the-art SNN and ANN models on two event-based datasets: the Multi Vehicle Stereo Event Camera (MVSEC) dataset, which is a real-world dataset, and a synthetic dataset. On the MVSEC dataset, our model achieves mean depth error values of 11.8 cm, 18.0 cm, and 12.5 cm for Splits 1, 2, and 3, respectively, setting a new benchmark for event-based depth estimation with significantly lower power consumption.},
  archive      = {J_ESWA},
  author       = {Dongze Liu and Yimeng Fan and Wenrui Lu and Changsong Liu and Wei Zhang},
  doi          = {10.1016/j.eswa.2025.129977},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129977},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spiking depth: Depth estimation from sparse events with spiking neural networks},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-aware contrastive learning for graph classification. <em>ESWA</em>, <em>299</em>, 129976. (<a href='https://doi.org/10.1016/j.eswa.2025.129976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the performance of vanilla graph-level contrastive learning is limited by traditional data augmentation strategies and size imbalance. First, adding noise in the embedding space for data augmentation may cause the graph-level representation to exceed the class decision boundary and alter its original semantic information. Second, transferring information from head graphs to tail graphs to alleviate size imbalance without distinguishing the semantic information of the graphs may lead to suboptimal model performance. To address these issues, we propose a semantic-aware graph-level contrastive learning method named SAGCL. Specifically, SAGCL achieves controllable data augmentation by adjusting the closeness between class center features and augmented features, preserving the inherent structure and semantic information of the graph. Meanwhile, the intra-cluster variance is used as a regularization term to maintain the uniformity of the feature distribution. In addition, SAGCL employs a confidence-weighted approach to obtain the semantic prototypes of head graphs and tail graphs within each cluster. Then, the rich semantic information from the head graphs is transferred to the tail graphs, effectively enhancing the model’s ability to distinguish tail graphs. Experiments on graph classification tasks on eight imbalanced datasets demonstrate that SAGCL outperforms existing state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Chengcheng Xu and Tong Han and Tianfeng Wang and Xiao Han and Zhisong Pan},
  doi          = {10.1016/j.eswa.2025.129976},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129976},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semantic-aware contrastive learning for graph classification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-encoded neural network via multi-scale tree-structured graph representation for assessing cardiovascular hemodynamics. <em>ESWA</em>, <em>299</em>, 129975. (<a href='https://doi.org/10.1016/j.eswa.2025.129975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hemodynamic assessment is crucial for understanding cardiovascular disease mechanisms and accurate diagnosis. Deep learning with prior physical knowledge holds promise for hemodynamic modelling. However, existing approaches struggle to assess hemodynamics across various cardiovascular systems due to geometric heterogeneity and imbalance learning from competing physical constraints. We propose a multi-scale tree-structured physics-encoded graph neural network for hemodynamic assessment across various cardiovascular systems. We introduce a multi-scale tree-structured graph representation (MTGR) that hierarchically decomposes vascular systems. This enables adaptive geometric modelling while maintaining physiological consistency. Building on MTGR, we propose a physics-encoded computational decoupling paradigm: (1) intra-segment hemodynamic computation within continuous vessel regions and (2) inter-segment hemodynamic coupling at bifurcation nodes. This decoupling paradigm efficiently combines knowledge of morphology and physics. With physics-encoded framework, we achieve the network training with label-free data. Experimental results on coronary and pulmonary arteries validate our framework’s superior generalization across diverse vascular topologies while preserving clinically interpretable physics. The excellent accuracy in predicting functionally significant stenosis demonstrates that this novel methodology has the potential to contribute to the development of innovative diagnostic and treatment strategies in the field of cardiovascular medicine.},
  archive      = {J_ESWA},
  author       = {Anbang Wang and Xiaofei Xue and Zhifan Gao and Zhihui Zhang and Dan Deng and Xiujian Liu},
  doi          = {10.1016/j.eswa.2025.129975},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129975},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-encoded neural network via multi-scale tree-structured graph representation for assessing cardiovascular hemodynamics},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Breast mass classification in 3D ABUS based on laplace-beltrami spectra and dual path CNN. <em>ESWA</em>, <em>299</em>, 129973. (<a href='https://doi.org/10.1016/j.eswa.2025.129973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most common cancer among women and remains a leading cause of cancer-related mortality worldwide. Accurately classifying breast masses as benign or malignant is crucial for guiding treatment and reducing unnecessary interventions. In this paper, we propose a hybrid deep learning-based classification framework for automated three-dimensional breast ultrasound (3D ABUS) images. The system integrates three classification paths: Support Vector Machine (SVM), Extremely Randomized Trees (Extra Trees), and a novel deep neural network. The SVM and Extra Trees classifiers utilize handcrafted features, including radiomic descriptors and Laplace-Beltrami eigenvalues. In these models, to reduce dimensionality of the Laplace-Beltrami features and prevent overfitting, Isomap is employed for nonlinear dimensionality reduction. The proposed neural network processes a 3D patch around the mass and the corresponding mask through two parallel paths, utilizing convolutional and max-pooling layers. The extracted features from both branches are concatenated with the complete Laplace-Beltrami feature vector before being classified by fully connected layers. To combine the outputs of all three base models, we employ a histogram-based gradient-boosting stacking classifier. This meta -classifier learns nonlinear dependencies between classifiers and enhances the overall performance. Experimental evaluation was conducted on the public TDSC-ABUS dataset, comprising 200 annotated breast volumes. The training/validation set includes 75 malignant and 55 benign cases, while the test set contains 40 malignant and 30 benign cases. On the test set, the proposed system achieves 84.29% accuracy, 93.50% AUC, 97.50% sensitivity, and 87.64% F1-score. Compared to the best competing method, it improves accuracy by 8.58% and AUC by 4.58%.},
  archive      = {J_ESWA},
  author       = {Sepideh Barekatrezaei and Ali Naderiparizi and Ehsan Kozegar and Javad Ghofrani and Mohsen Soryani},
  doi          = {10.1016/j.eswa.2025.129973},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129973},
  shortjournal = {Expert Syst. Appl.},
  title        = {Breast mass classification in 3D ABUS based on laplace-beltrami spectra and dual path CNN},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IJTyper: An effective type inference framework for incomplete java codes by integrating constraint- and statistics-based methods. <em>ESWA</em>, <em>299</em>, 129972. (<a href='https://doi.org/10.1016/j.eswa.2025.129972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring the types of APIs used in incomplete codes (also referred to as code snippets), e.g., those on Q&A forums, is a prerequisite step required to work with the codes. Existing type inference methods proposed for incomplete Java codes can be primarily categorized as constraint-based or statistics-based. The former relies on a pre-built API knowledge base (KB) and the type constraints in code snippets, which imposes higher requirements on code syntax and thus suffers from low recall due to the syntactic limitation. The latter overcomes the syntactic limitation by learning statistical regularities from a code corpus, however it rarely employs the type constraints in code snippets, which may lead to low precision. In this paper, we propose an effective type inference framework, called iJTyper, for incomplete Java codes by integrating the complementary advantages of constraint- and statistics-based methods. For a code snippet, iJTyper first applies a constraint-based method and augments the code context with the inferred API types. Then, it applies a statistics-based method to the augmented code snippet. The types predicted for APIs are further used to improve the constraint-based method by reducing its pre-built KB. iJTyper iteratively executes both methods and performs the code context augmentation and KB reduction mechanisms until a termination condition is satisfied. The final inference results are produced by combining the results of both methods. We implemented a version of iJTyper by integrating two state-of-the-art methods, SnR and MLMTyper, and evaluated iJTyper on two open-source datasets. Results show that 1) iJTyper achieves the highest average precision/recall 1 of 97.3 % and 92.5 % on both datasets; 2) iJTyper improves the average recall of SnR and MLMTyper by at least 7.3 % and 27.4 %, respectively; and 3) iJTyper improves the average precision/recall of the recently popular language model, ChatGPT, by 3.2 % and 0.5 % on both datasets.},
  archive      = {J_ESWA},
  author       = {Zhixiang Chen and Anji Li and Neng Zhang and Jianguo Chen and Yuan Huang and Zibin Zheng},
  doi          = {10.1016/j.eswa.2025.129972},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129972},
  shortjournal = {Expert Syst. Appl.},
  title        = {IJTyper: An effective type inference framework for incomplete java codes by integrating constraint- and statistics-based methods},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing job offer packages in a two-sided matching with bounded rationality: A two-stage stochastic approach. <em>ESWA</em>, <em>299</em>, 129971. (<a href='https://doi.org/10.1016/j.eswa.2025.129971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel selection is a two-sided market where companies compete for qualified candidates by designing job-offer packages. However, there is a gap in understanding how to optimize these packages considering candidate preferences and associated costs, while decision-makers exhibit bounded rationality due to limited information or cognitive constraints. This study addresses this gap by proposing a matching framework that accounts for bounded rationality based on the Quantal Response Equilibrium (QRE), in which both sides are not perfect optimizers and face uncertainty in the other side’s actions. Maximum Likelihood Estimation (MLE) and analysis of real hiring data confirm that decision-makers exhibit bounded rationality and tend to behave more rationally as the selection process progresses. Finally, a two-stage stochastic optimization approach using Particle Swarm Optimization (PSO) to determine the optimal job offer package for the organization, taking into account its human resource policies and candidate competencies, is presented. The evaluation of the results and a sensitivity analysis are conducted under rational and bounded rational modes. This approach offers valuable insights for organizations to optimize their hiring processes and attract top talent.},
  archive      = {J_ESWA},
  author       = {Saeed Najafi-Zangeneh and Naser Shams-Gharneh},
  doi          = {10.1016/j.eswa.2025.129971},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129971},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing job offer packages in a two-sided matching with bounded rationality: A two-stage stochastic approach},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SFLES: Shuffled differentially private federated learning with early-stopping strategy. <em>ESWA</em>, <em>299</em>, 129970. (<a href='https://doi.org/10.1016/j.eswa.2025.129970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) allows multiple clients to collaboratively train a global model without sharing raw data, yet it remains susceptible to privacy attacks. The recently proposed shuffle model of differential privacy (DP) offers a promising solution by leveraging privacy amplification to achieve strong local privacy guarantees while maintaining high utility. However, existing approaches based on this model rely on conventional Gaussian or Laplace mechanisms, which introduce unbounded noise and risk significant data distortion. Furthermore, these methods typically exhibit inefficient privacy budget allocation and suffer from excessive communication overhead and computational costs imposed by fixed training rounds, ultimately degrading performance. To address these limitations, we present SFLES, a novel shuffled differentially private FL framework designed to robustly prevent privacy leakage while optimizing model utility. In particular, SFLES employs Top- k sparsification to compress local model updates and integrates an adaptive, layer-wise bounded noise mechanism based on a symmetric piecewise distribution for fine-grained noise injection. To enhance efficiency, we propose a novel directional similarity-aware aggregation strategy, which prioritizes updates with consistent directional trends, accelerating convergence under DP constraints. Additionally, SFLES incorporates a dynamic early-stopping strategy that tracks update conflict rates and global accuracy trends, dynamically terminating training upon convergence detection and reallocating residual privacy budgets to subsequent rounds for improved utility. Extensive evaluations on MNIST, Fashion-MNIST, and CIFAR-10 demonstrate that SFLES surpasses state-of-the-art alternatives in balancing privacy-utility trade-offs, convergence speed, and communication efficiency.},
  archive      = {J_ESWA},
  author       = {Yanhui Li and Chen Huang and Yuxin Zhao and Xinjie Du and Junqing Huang and Ye Yuan},
  doi          = {10.1016/j.eswa.2025.129970},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129970},
  shortjournal = {Expert Syst. Appl.},
  title        = {SFLES: Shuffled differentially private federated learning with early-stopping strategy},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traditional chinese medicine toxicity prediction by heterogeneous network. <em>ESWA</em>, <em>299</em>, 129969. (<a href='https://doi.org/10.1016/j.eswa.2025.129969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clinical usage of Traditional Chinese Medicines (TCMs) gains increasing international attention for their distinct therapeutic effects. Precisely understanding the herb (TCM) toxicity, and identifying toxic and effective herb ingredients are crucial for their safe use. Traditional wet-lab based pipelines for assessing herb toxicity are complex and time-consuming. Given the large volume toxicity data of ingredients, building computational models for efficient ingredient-based toxicity prediction and evaluation is promising, but often fails to effectively predict the toxicity of herbs, due to the complexity herbs and toxic mechanisms. To address these challenges, we propose a heterogeneous network based approach (HerbToxNet) for predicting herb toxicity. HerbToxNet first constructs a heterogeneous network composed with herbs, ingredients and molecular targets, and leverages a heterogeneous graph attention network to learn the representation of herbs. Meanwhile, it performs contrastive learning with dynamic coefficient to refine the representation by pulling close the herbs with shared toxic labels, while pushing away the others. Next, it uses Multilayer Perceptron (MLP) on the herb representation to predict the toxic labels of this herb, and further introduces a weighted label fusion strategy that uses toxic labels of similar herbs to augment the predicted labels of this herb. HerbToxNet outperforms competitive methods and finds out novel potential toxicities, with 96 % toxicity labels confirmed for canonical herbs. It can mine related toxic ingredients and targets in an interpretable way, and dissect the molecular mechanism of herb toxicity with authenticity.},
  archive      = {J_ESWA},
  author       = {Yongzheng Zhu and Yunbo Miao and Rong Sun and Zhongmin Yan and Guoxian Yu},
  doi          = {10.1016/j.eswa.2025.129969},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129969},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traditional chinese medicine toxicity prediction by heterogeneous network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A “parallel” combined transformer-CNN model using secondary decomposition for crude oil forecasting. <em>ESWA</em>, <em>299</em>, 129968. (<a href='https://doi.org/10.1016/j.eswa.2025.129968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to better apply the advantages of deep learning models in crude oil price prediction, this paper proposes a novel deep learning combined model. It has a “decomposition and construction, dual-model parallel feature and extraction fully connected fusion” architecture, which combines the Transformer model with self-attention mechanism, the convolutional neural network (CNN) with local feature extraction in “parallel” and a fully connected neural network (FCN) to realize feature fusion. Firstly, the original price sequence is decomposed into multiple intrinsic mode functions through variational mode decomposition (VMD), and then the component with the highest Lempel-Ziv complexity (LZC) is processed by the empirical mode decomposition (EMD). Furthermore, model each component obtained from two decomposition using the Transformer-CNN model separately to obtain their predicted values. Finally, the final prediction results are derived from a linear combination of the predicted values of all components. Empirical analysis has demonstrated that the proposed model has better performance than benchmark models, and a series of tests have demonstrated its robustness. In conclusion, it represents a collaborative mechanism of decomposition as the foundation, dual models performing their respective duties, and fusion amplifying advantages. The application of this model in this paper significantly improves the forecasting accuracy of crude oil prices, which is helpful for investors and managers to grasp the trend of oil price changes and make response strategies.},
  archive      = {J_ESWA},
  author       = {Zhifeng Dai and Huali Huang and Qinnan Jiang and Yaling Chen},
  doi          = {10.1016/j.eswa.2025.129968},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129968},
  shortjournal = {Expert Syst. Appl.},
  title        = {A “parallel” combined transformer-CNN model using secondary decomposition for crude oil forecasting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiscale self-attention convolution and adaptive fusion for enhanced multimodal medical image fusion. <em>ESWA</em>, <em>299</em>, 129967. (<a href='https://doi.org/10.1016/j.eswa.2025.129967'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image fusion (MMIF) is a critical component of the larger system state inference (SSI) problem, which seeks to extract comprehensive clinical information from complementary data streams. While current fusion techniques have limitations in global modeling and computational efficiency, we present a new Multiscale Self-attention Convolution and Adaptive Fusion (MSAFusion) network. Our work combines traditional state inference principles with deep learning by implementing: (1) an ACmix module to extract local and global features synergistically; (2) a multiscale architecture for comprehensive representation; and (3) a Squeeze Fusion Calibration (SFC) block to dynamically recalibrate feature contributions, similar to adaptive expert opinion integration. Extensive experiments on benchmark multimodal dataset show that MSAFusion outperforms current advanced techniques in both qualitative and quantitative performance metrics. Furthermore, we apply MSAFusion to emerging challenges in biomedical imaging applications, and the results demonstrate its robustness and generalizability.},
  archive      = {J_ESWA},
  author       = {Rui He and Yang Xu and You Zheng and Zhiming Zhou and Chaoyang Zhou and Wenlong Song and Jiayi Yu and Dajing Guo},
  doi          = {10.1016/j.eswa.2025.129967},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129967},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multiscale self-attention convolution and adaptive fusion for enhanced multimodal medical image fusion},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intrusion detection system for shipping communication networks based on federated distillation learning. <em>ESWA</em>, <em>299</em>, 129966. (<a href='https://doi.org/10.1016/j.eswa.2025.129966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of IoT into maritime shipping communication networks introduces challenges for distributed intrusion detection, especially when ships are sailing across regions, changes in network environments, and attack patterns lead to non-independent and identically distributed (Non-IID) data issues. In this work, we propose a federated distillation learning-based intrusion detection method (FDL) to enhance detection efficiency while preserving data privacy. The core of this framework lies in two levels, the former being a CNN-LSTM-based student model that balances accuracy and edge-device deployment needs. A local knowledge distillation mechanism, employing dynamic temperature adjustment and soft-label supervision, improves the student model’s learning capability. As a latter, the parameter space distillation aggregation algorithm (PSKD-Agg) intelligently fuses historical model parameters and aligns knowledge distributions from different clients, alleviating parameter oscillations caused by non-independent and identically distributed (Non-IID) data, thereby improving the stability and convergence of the global model. Experiments on the NSL-KDD and real maritime datasets show macro-averaged accuracies of 88.73 % and 91.98 %, Significantly improve FedAvg by 1.81 % and 1.06 %, respectively, surpassing the latest maritime intrusion detection methods FedBatch by 1.19 % and 1.41 %. Model stability is also enhanced, with the standard deviation in the last 10 rounds reduced to 0.08 %, compared with 0.27 % for FedAvg and 0.53 % for FedBatch, demonstrating that FDL achieves the lowest volatility among the three methods, offering a robust solution for maritime network security and privacy, and paving the way for future research on heterogeneous device adaptation and multimodal data fusion.},
  archive      = {J_ESWA},
  author       = {Zhimin Feng and Dezhi Han and Jiatao Li and Shuxin Shi and Kuan-Ching Li},
  doi          = {10.1016/j.eswa.2025.129966},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129966},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intrusion detection system for shipping communication networks based on federated distillation learning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). VPS-APF-RRT*: A variable probability sampling RRT* intelligent algorithm combined with APF for autonomous vehicles path planning. <em>ESWA</em>, <em>299</em>, 129965. (<a href='https://doi.org/10.1016/j.eswa.2025.129965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of autonomous driving technologies, path planning has received widespread attention due to its great potential to improve safety. The Rapid- exploring Random Tree star(RRT*) algorithm is commonly utilized in path planning for its good adaptability and scalability. However, the algorithm still suffers from drawbacks such as high path cost and slow convergence speed, which are caused by its large search space. In order to overcome these problems, a variable probability sampling RRT* algorithm combined with the artificial potential field(APF) method(VPS-APF-RRT*) for path planning is proposed. First, a variable probability goal-bias sampling method is proposed to improve the global search capability and path search efficiency. Second, a steering constraint-based method is proposed to optimize the selection of nearest nodes. Again, an improved APF is introduced into the RRT* algorithm framework to further improve the obstacle avoidance capability of the algorithm. Fourth, an optimization approach with node connection constraints is proposed to decrease the formation of unneeded nodes, hence speeding up the convergence of the algorithm. Finally, the VPS-APF-RRT* algorithm is compared with the RRT*, G-RRT*, and APF-IRRT* algorithms, and the suggested approach is highly optimized in terms of path quality and convergence speed, according to testing data.},
  archive      = {J_ESWA},
  author       = {Fanzhan Tao and Zhaowei Ding and Zhikai Wang and Baofeng Ji},
  doi          = {10.1016/j.eswa.2025.129965},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129965},
  shortjournal = {Expert Syst. Appl.},
  title        = {VPS-APF-RRT*: A variable probability sampling RRT* intelligent algorithm combined with APF for autonomous vehicles path planning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-robust and sector-aware representation learning for natural gas demand forecasting. <em>ESWA</em>, <em>299</em>, 129964. (<a href='https://doi.org/10.1016/j.eswa.2025.129964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With natural gas becoming a key component of energy systems, precise demand forecasting is crucial for supporting efficient planning and resource management. However, existing methods face two key challenges: substantial noise in industrial datasets and heterogeneous consumption patterns across sectors. Data noise caused by sensor errors, irregular reporting, and logging inconsistencies obscures underlying consumption trends. Simultaneously, sector-specific variations in demand make it challenging to develop a unified forecasting model capable of capturing diverse consumption behaviors. To address these challenges, we propose a novel data forecasting framework that integrates contrastive learning with targeted noise filtering to enhance data representation and prediction robustness. The noise filtering module incorporates a denoising task that enables the model to learn to suppress noise and improve representation reliability. Meanwhile, the contrastive learning mechanism leverages sector-specific information to capture both shared patterns and sectoral usage behaviors. We further introduce a false negative removal strategy to refine sample selection, reducing representation bias and enhancing generalization. Our approach is validated on a large-scale dataset from the ENN Group, covering over 10,000 industrial, commercial, and welfare-related customers across multiple regions. Experimental results demonstrate that our model consistently outperforms a range of state-of-the-art forecasting baselines across both short- and long-term horizons, achieving notably better accuracy and robustness in real-world scenarios. This work demonstrates the potential of noise-robust and sector-aware representation learning for advancing natural gas demand forecasting in real-world applications.},
  archive      = {J_ESWA},
  author       = {Xinxing Zhou and Jiaqi Ye and Shubao Zhao and Ming Jin and Zhaoxiang Hou and Chengyi Yang and Zengxiang Li and Yanlong Wen and Xiaojie Yuan},
  doi          = {10.1016/j.eswa.2025.129964},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129964},
  shortjournal = {Expert Syst. Appl.},
  title        = {Noise-robust and sector-aware representation learning for natural gas demand forecasting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CCF-former: A transformer with cross-channel feature aggregation and frozen backbone for fault prediction. <em>ESWA</em>, <em>299</em>, 129963. (<a href='https://doi.org/10.1016/j.eswa.2025.129963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected system faults may cause significant economic losses, service disruption, and safety risks in failure-prone interconnected systems, including industrial and distributed computing infrastructures. Therefore, accurate and timely fault prediction is essential for ensuring system reliability and maintaining continuous service availability. In this paper, we propose CCF-Former, a Transformer-based fault prediction framework that combines C ross- C hannel feature aggregation and a F rozen pretrained backbone to predict failures in such interconnected systems. The proposed framework exhibits excellent fault prediction performance, maintaining both high precision and robustness. The framework combines three main components: (1) a Cross-Channel Feature Aggregation Module (CCFAM) that captures long-range dependencies and subtle fault patterns by aggregating and redistributing informative representations across input features; (2) a Frozen Pre-trained Transformer Module (FPTM) that captures temporal patterns using rich pre-trained representations, significantly reducing resource consumption and avoiding repeated fine-tuning; and (3) a Failure Inference Module (FIM) that produces reliable fault judgements through reconstruction-based scoring and adaptive thresholding. Extensive experiments on multiple public benchmarks, including server monitoring and spacecraft telemetry datasets, demonstrate that CCF-Former consistently outperforms state-of-the-art baselines, achieving a top F1-score of 87.94 %. The proposed framework offers a robust and effective solution for fault prediction in complex interconnected systems. Our code is publicly available at https://github.com/Yolandalt/CCF-Former .},
  archive      = {J_ESWA},
  author       = {Ting Li and Huanlin Huang and Kai Yang and Jing Wen},
  doi          = {10.1016/j.eswa.2025.129963},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129963},
  shortjournal = {Expert Syst. Appl.},
  title        = {CCF-former: A transformer with cross-channel feature aggregation and frozen backbone for fault prediction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). INN-RAE: Reversible adversarial examples based on invertible neural networks for facial protection. <em>ESWA</em>, <em>299</em>, 129962. (<a href='https://doi.org/10.1016/j.eswa.2025.129962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible adversarial examples can effectively prevent data from being accessed and recognized by unauthorized deep neural network models, but existing methods struggle to balance the visual quality and attack effectiveness of the generated adversarial examples. This paper proposes a method for generating reversible adversarial examples based on invertible neural networks (INN-RAE), achieving an effective unification of high attack success rate and high visual stealthiness. Specifically, during the forward propagation phase of the invertible neural network, both the clean sample and a noise matrix are input simultaneously, and adversarial examples are generated by fine-tuning the noise matrix. When restoring the adversarial examples, the same invertible neural network can be used to achieve high-quality restoration and remove the attack noise, thereby realizing end-to-end reversible adversarial example generation and restoration. Compared with existing reversible adversarial example generation algorithms, INN-RAE achieves state-of-the-art levels of attack success rate on multiple face datasets and face recognition models, while also achieving better visual stealthiness and restoration effects.},
  archive      = {J_ESWA},
  author       = {Zeyu Zhao and Ke Xu and Laijin Meng and Tanfeng Sun and Xinghao Jiang},
  doi          = {10.1016/j.eswa.2025.129962},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129962},
  shortjournal = {Expert Syst. Appl.},
  title        = {INN-RAE: Reversible adversarial examples based on invertible neural networks for facial protection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph structure enhancement with local cluster guidance for discrete spectral clustering. <em>ESWA</em>, <em>299</em>, 129961. (<a href='https://doi.org/10.1016/j.eswa.2025.129961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering (SC), as the most popular graph clustering algorithm, is widely used in data mining due to its ability to effectively capture complex cluster structures. However, most graph-based clustering methods overlook the integration of prior information, which, although challenging to acquire in unsupervised scenarios, has the potential to enhance clustering accuracy by aligning results more closely with the ground truth. Moreover, existing SC methods usually require an additional discretization step to generate a discrete label matrix, leading to information loss. To overcome these challenges, a unified self-supervised graph clustering model called Graph Structure Enhancement with Local Cluster Guidance for Discrete Spectral Clustering (LCG-DSC) is proposed. In particular, the proposed method is characterized by the following advancements: 1) an innovative self-supervised term is used to extend the loss function of spectral clustering; 2) a novel optimization method, which alternately iterates singular value decomposition and coordinate ascent, is employed to combine spectral embedding analysis and label matrix learning into a unified framework, avoiding the information loss. Furthermore, a theoretical analysis is provided to show the roles of the self-supervised term and the extensibility of the proposed algorithm. Experimental clustering results demonstrate that LCG-DSC exhibits good effectiveness on both synthetic and real-world datasets.},
  archive      = {J_ESWA},
  author       = {Xiaojun Yang and Bin Li and Jingjing Xue and Yi Fang and Jian Yang and Feiping Nie},
  doi          = {10.1016/j.eswa.2025.129961},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129961},
  shortjournal = {Expert Syst. Appl.},
  title        = {Graph structure enhancement with local cluster guidance for discrete spectral clustering},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A collaborative reasoning framework for large language models in long-context Q&A. <em>ESWA</em>, <em>299</em>, 129960. (<a href='https://doi.org/10.1016/j.eswa.2025.129960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) often struggle with the Lost in the Middle phenomenon in long-context question answering (Q&A). Existing solutions, such as modifying attention mechanisms or positional encodings, typically require retraining, which demands substantial computational resources. Other strategies, including long-term memory mechanisms and context processing, heavily rely on auxiliary components and fail to fundamentally enhance the LLM’s reasoning capabilities. To bridge this gap, this paper proposes a novel collaborative reasoning framework. Initially, the framework uses a retrieval-augmented generation (RAG) approach to generate a candidate answer from sentences relevant to the input question. Subsequently, a training-free Shadow-LLM is designed to supplement local sentence-level information from the long-context during the reasoning process to produce another candidate answer. Finally, a one-out-of-two selection strategy chooses the final answer based on the two candidates. Experiments on three long-context Q&A datasets and three backbone LLMs show that our method raises the F1 score over the baselines by 2% to 18%. Notably, we find that activating only the 0th decoder layer of the LLM is sufficient for Shadow-LLM to operate at optimal performance, enabling efficient deployment without retraining. The code is available at link .},
  archive      = {J_ESWA},
  author       = {Jiacheng Yao and Guoxiu He and Xin Xu},
  doi          = {10.1016/j.eswa.2025.129960},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129960},
  shortjournal = {Expert Syst. Appl.},
  title        = {A collaborative reasoning framework for large language models in long-context Q&A},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring mechanisms of integrating global perception prediction for connected vehicles with lane-specific reinforcement learning-based variable speed limits. <em>ESWA</em>, <em>299</em>, 129958. (<a href='https://doi.org/10.1016/j.eswa.2025.129958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable Speed Limit (VSL) is widely recognized as an effective traffic control method for alleviating congestion in freeway weaving areas. Previous control strategies that rely on fixed detectors often experience limitations in state feature engineering, which can only obtain partial environment data and limited information categories. In contrast, Connected Vehicles (CVs) can serve as moving detectors by dynamically perceiving the traffic conditions and estimating the global state of the traffic. By utilizing the global state perception and future traffic flow prediction, this paper proposes the BiLSTM-D3QN-DVSL strategy, which integrates Bidirectional Long Short-Term Memory Networks (BiLSTM) and Dueling Double Deep Q-Network (D3QN) in a lane-specific Differentiated VSL (DVSL) system. A freeway scenario in California is selected in training simulations, along with the car-following model parameter calibrations. Results indicate that the proposed model integrating global perception and prediction capabilities significantly improves efficiency and sustainability across different CV penetration rates compared to variable baselines. Notably, at a low CV penetration rate of 20%, the model can increase net traffic outflow by 64.86% and reduce total vehicle waiting time by 59.01%. As the CV penetration rate increases, the model’s regulatory effectiveness is further optimized, leading to significant reductions in traffic congestion, fuel consumption, and carbon emissions. By further exploring the mechanism of the strategy, the spatiotemporal prediction capability is also found to compensate for the limitations of local perception, facilitating forward-looking decision-making capabilities. Also, the lane-level strategy indicates the homogenization of traffic flow through inter-lane coordination, enhancing global precision and efficiency. This study presents a novel solution for VSL control in a CV environment by minimizing dependence on fixed detectors, demonstrating substantial practical value.},
  archive      = {J_ESWA},
  author       = {Li Song and Shijie Li and Guojun Chen and Xin Zhao and Nengchao Lyu and Wei (David) Fan},
  doi          = {10.1016/j.eswa.2025.129958},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129958},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring mechanisms of integrating global perception prediction for connected vehicles with lane-specific reinforcement learning-based variable speed limits},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EXP-GNN: Towards expressive propagation function design for graph neural network-based knowledge graph completion. <em>ESWA</em>, <em>299</em>, 129957. (<a href='https://doi.org/10.1016/j.eswa.2025.129957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The message-passing process in a graph neural network (GNN)-based knowledge graph completion (KGC) model consists of two key components: propagation path design (PPD) and propagation function design (PFD). Existing GNN-based KGC methods mainly focus on studying the PPD component while lacking in-depth insights into PFD. In this paper, we investigate the expressive power of PFD from both theoretical and empirical perspectives. Specifically, we first generalize the theoretical injectivity principle for highly expressive GNN propagation functions from single-relational graphs to multi-relational ones. Based on this generalization, we theoretically find that existing expressive propagation function designs for GNNs can be directly extended to GNN-based KGC tasks and that a more expressive GNN inherently results in a more expressive GNN-based KGC model. Then, we develop a design space for the PFD component, involving not only injective propagation functions but also many non-injective ones to facilitate a systematic empirical analysis. Finally, we propose a GNN-based KGC framework, EXP-GNN, where we validate our theoretical findings and systematically evaluate the developed design space. The evaluation results offer some interesting empirical findings, from which we derive a practical design principle to help inspire more powerful GNN-based KGC models: a stronger neighborhood feature extraction capability in the propagation functions makes the resulting GNN-based KGC models theoretically and practically more powerful.},
  archive      = {J_ESWA},
  author       = {Kaiqi Gong and Xiao Song and Songsong Liu and Yong Li},
  doi          = {10.1016/j.eswa.2025.129957},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129957},
  shortjournal = {Expert Syst. Appl.},
  title        = {EXP-GNN: Towards expressive propagation function design for graph neural network-based knowledge graph completion},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective redundancy allocation integrating interval uncertainty and hesitant fuzzy aggregation with a non-dominated sorting genetic algorithm. <em>ESWA</em>, <em>299</em>, 129956. (<a href='https://doi.org/10.1016/j.eswa.2025.129956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of optimizing reliability redundancy allocation in engineering systems under uncertainty. The objective is to develop a robust multi-objective framework that accounts for both aleatory and epistemic uncertainty in system parameters. Reliability values are modeled as interval numbers to capture inherent variability, while cost, weight, and volume are evaluated using hesitant fuzzy sets to incorporate expert opinion and subjective assessment. A modified Non-Dominated Sorting Genetic Algorithm II (NSGA-II) is employed to identify trade-off solutions across reliability, cost, and weight objectives. The methodology is validated through four benchmark problems with varying decision space complexity. Results show that the proposed approach consistently achieves well-distributed Pareto fronts and outperforms alternative methods such as MOEA/D and hesitant fuzzy MOPSO in terms of reliability-cost efficiency. These findings demonstrate the effectiveness and practical relevance of integrating interval modeling and hesitant fuzzy aggregation in reliability-based design optimization.},
  archive      = {J_ESWA},
  author       = {B. Maneckshaw and G.S. Mahapatra and Kash Barker},
  doi          = {10.1016/j.eswa.2025.129956},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129956},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective redundancy allocation integrating interval uncertainty and hesitant fuzzy aggregation with a non-dominated sorting genetic algorithm},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attribute-guided aesthetic assessment for artistic images based on multimodal hybrid network. <em>ESWA</em>, <em>299</em>, 129954. (<a href='https://doi.org/10.1016/j.eswa.2025.129954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artistic Image Aesthetic Assessment (AIAA) aims to predict the aesthetic quality of artistic images, which is considered a challenging topic due to the inherent abstractness and complexity of artistic perception. Current approaches typically depend on singular visual features, overlooking that human evaluation of artistic images involves multiple perceptual attributes, such as color, composition, and creativity, which leads to suboptimal performance. To solve this problem, we propose an Attribute-guided Multimodal Hybrid Network (AMH-Net) for artistic image aesthetic assessment. With the powerful image understanding and language generation capabilities of the multimodal large language model, multi-attribute descriptions for artistic images are generated across seven complementary dimensions, including technical quality, color, theme, historical context, composition, emotion, and creativity. Furthermore, we propose a multimodal hybrid network that extracts visual features via ResNet-50 and encodes attribute descriptions using a transformer-based text encoder. A self-attention mechanism refines the textual features to model inter-attribute dependencies, and the two modalities are fused through bilinear pooling for fine-grained aesthetic prediction. Extensive experiments conducted on five public AIAA datasets validate the superiority of the proposed AMH-Net over the state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xiaoping Xu and Siye Huang and Wenbo Li and Feng Wang},
  doi          = {10.1016/j.eswa.2025.129954},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129954},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attribute-guided aesthetic assessment for artistic images based on multimodal hybrid network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Co-evolutionary multi-objective optimization enhanced by reinforcement learning decision support in distributed group scheduling. <em>ESWA</em>, <em>299</em>, 129953. (<a href='https://doi.org/10.1016/j.eswa.2025.129953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amid increasing demands for sustainable and flexible production, this paper addresses the multi-objective distributed blocking flow shop group scheduling problem, formally denoted as DF m g r o u p , s d st , b l o c k i n g ( C max , T E C ) . To address it, this paper proposes a Q-learning-assisted collaborative multi-objective evolutionary algorithm QACMOEA . Specifically, a sequence-based mathematical model is formulated and validated via Gurobi. To boost search quality, a multi-feature fusion strategy leverages group processing time, average setup time, and skewness. A Q-learning-based mechanism dynamically selects local search strategies by maximizing cumulative rewards across Pareto-derived states. A hybrid convergence-diversity selection combined with a metrical-driven reference update maintains elite solutions and diversity, preventing premature convergence and adapting to varied scenarios. Additionally, a dynamic machine speed adjustment with hierarchical evaluation expands the Pareto front, balancing economic and ecological goals. Extensive computational experiments and comparative analyses on 405 test instances demonstrate that the proposed QACMOEA outperforms existing state-of-the-art algorithms in terms of solution quality, convergence stability, and scalability for this complex multi-objective scheduling problem.},
  archive      = {J_ESWA},
  author       = {Zhen Li and Yuting Wang and Yuyan Han and Leilei Meng and Kaizhou Gao and Qingda Chen},
  doi          = {10.1016/j.eswa.2025.129953},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129953},
  shortjournal = {Expert Syst. Appl.},
  title        = {Co-evolutionary multi-objective optimization enhanced by reinforcement learning decision support in distributed group scheduling},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DC-SLAM: Dual-category dynamic feature suppression for RGB-D VSLAM. <em>ESWA</em>, <em>299</em>, 129952. (<a href='https://doi.org/10.1016/j.eswa.2025.129952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Simultaneous Localization and Mapping (SLAM) systems assume static environments, and their localization accuracy degrades significantly when encountering dynamic objects. Although dynamic SLAM based on semantic information can handle simple dynamic objects, it fails to address the impact of pseudo-dynamic objects and unrecognized dynamic objects on pose estimation. To address these issues, we propose a DC-SLAM system, comprehensively eliminating two types of dynamic features while preserving valid static features. The system implements a dual-category mechanism: for active dynamic features, it combines a dynamic object detection network with dense optical flow for detection and removal, preventing excessive elimination of static features; for passive dynamic features, the system first determines their attributes using multi-view geometry, then clusters all feature points based on depth information and object detection categories, and finally optimizes dynamic properties through Mahalanobis distance analysis of outlier similarity. This approach compensates for the limitations of multi-view geometry, enabling more effective suppression of passively dynamic objects. Additionally, an octree mapping module is developed to assist mobile robots in scene understanding for practical applications. Extensive experiments on the TUM dataset, Bonn dataset, and real-world dynamic scenes verify DC-SLAM’s effectiveness. The results demonstrate significant improvements, compared with ORB-SLAM2, DC-SLAM reducing Absolute Trajectory Error (ATE) by 98.86 % and Relative Pose Error (RPE) by 97.28 %, while enabling the reliable construction of octree maps to enhance spatial understanding.},
  archive      = {J_ESWA},
  author       = {Shuping Ye and Benlian Xu and Yong Yang and Xu Zhou and Mingli Lu and Jian Shi and Zhicheng Yang},
  doi          = {10.1016/j.eswa.2025.129952},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129952},
  shortjournal = {Expert Syst. Appl.},
  title        = {DC-SLAM: Dual-category dynamic feature suppression for RGB-D VSLAM},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ALDA-UNet: Missing target segmentation based on active learning and deformation filling attention. <em>ESWA</em>, <em>299</em>, 129951. (<a href='https://doi.org/10.1016/j.eswa.2025.129951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comprehensive visual and quantitative analysis of the left ventricle is crucial for the diagnosis and treatment of cardiovascular diseases. As a widely adopted clinical diagnostic tool, echocardiography enables accurate evaluation of cardiac structure and function, playing a vital role in cardiovascular disease assessment. However, during echocardiogram acquisition, factors including scanning angle, myocardial movement, and specific diseases can cause the left ventricular myocardium to extend beyond the fan-shaped scanning area. To address the challenge of accurate myocardial segmentation in such situations, we propose ALDA-UNet, an automatic segmentation method based on the UNet architecture. ALDA-UNet stands out by integrating an active learning strategy and deformable attention, allowing it to segment the complete myocardial contour in echocardiogram views with incomplete myocardial scans. In this study, the image annotation results from multiple experts are employed as the gold standard for evaluating the automatic segmentation performance. The experimental results further reveal that ALDA-UNet can not only accurately quantify the degree of myocardial defects but also precisely segment the contours of defective myocardium, enhancing its clinical and research significance in cardiovascular diseases.},
  archive      = {J_ESWA},
  author       = {Shuhuan Wang and Yuanyuan Cui and Shuangqingyue Zhang and Difei Li and Ya Zhang and Ze Li and Zhijian Qi and He Ma and Shuang Liu},
  doi          = {10.1016/j.eswa.2025.129951},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129951},
  shortjournal = {Expert Syst. Appl.},
  title        = {ALDA-UNet: Missing target segmentation based on active learning and deformation filling attention},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Color image encryption scheme based on 5D fractional-order complex chaotic system and eight-base DNA cubes. <em>ESWA</em>, <em>299</em>, 129950. (<a href='https://doi.org/10.1016/j.eswa.2025.129950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, the secure transmission of color images has become an urgent problem. In order to overcome this problem, this paper proposes a high-security color image encryption algorithm. First, a five-dimensional fractional-order complex chaotic system is designed, and its dynamics are comprehensively analyzed from the perspectives of Lyapunov exponent spectrum, bifurcation diagram, and phase diagram. The results prove that the system has good chaotic characteristics. Second, a dynamic Arnold scrambling algorithm is designed, which dynamically generates scrambling parameters by calculating the pixel values of each channel of an image. Then, combined the eight-base DNA coding scheme with a three-dimensional cube structure, a space rotation-based scrambling method and a diffusion method integrating DNA mutation and crossover operations were designed under chaotic sequence control, thereby enhancing the nonlinearity and security of the encryption system. Finally, simulation experiments and security analysis indicate that the proposed color image encryption scheme provides high security and strong key sensitivity. It effectively scrambles pixel distributions, demonstrating robustness against statistical, noise, and cropping attacks, while maintaining efficient computational performance. These results demonstrate its effectiveness for secure digital image transmission.},
  archive      = {J_ESWA},
  author       = {Liming Wu and Zijian Tian and Wei Chen},
  doi          = {10.1016/j.eswa.2025.129950},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129950},
  shortjournal = {Expert Syst. Appl.},
  title        = {Color image encryption scheme based on 5D fractional-order complex chaotic system and eight-base DNA cubes},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGFed: Transferability-guided federated learning for unseen client adaptation. <em>ESWA</em>, <em>299</em>, 129949. (<a href='https://doi.org/10.1016/j.eswa.2025.129949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning allows multiple clients to collaboratively train a shared model by aggregating local model parameters while preserving data privacy. However, models trained via federated learning often suffer from significant performance degradation on unseen clients. Although existing methods have introduced multi-source domain adaptation techniques, they still face challenges such as negative transfer caused by substantial differences between source and target domains, and difficulty in model adaptation due to the lack of labeled data in the target domain. To address these challenges, we innovatively propose Transferability-Guided Federated Learning for Unseen Client Adaptation (TGFed). By dynamically evaluating the transferability of source domain models, TGFed selects models with data distributions more similar to target clients for aggregation, effectively mitigating the impact of negative transfer. Additionally, to address the lack of labeled data in unseen clients, a mean teacher learning module is proposed, which generates pseudo-labels to guide the training of student models, enabling efficient local model adaptation on unseen clients. Experiments on six datasets across two medical image segmentation tasks show significant performance improvements over SOTA methods, proving its practical effectiveness.},
  archive      = {J_ESWA},
  author       = {Ke Niu and Jiuyun Cai and Wenjuan Tai and Yijie Pan and Kaize Shi},
  doi          = {10.1016/j.eswa.2025.129949},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129949},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGFed: Transferability-guided federated learning for unseen client adaptation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advancing broad learning through structured feature generation. <em>ESWA</em>, <em>299</em>, 129948. (<a href='https://doi.org/10.1016/j.eswa.2025.129948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks achieve strong performance in big data scenarios, while requiring extensive iterative parameter optimization, making them inefficient and suboptimal in scarce data scenarios. Broad Learning System (BLS) has gained popularity as an efficient, effective, and incremental learning model. BLS relies on independent and identically distributed random feature generation. Although efficient, the literature has shown that this approach can lead to suboptimal and redundant representations. This paper introduces Structured BLS (SBLS), a novel reinterpretation of BLS components. SBLS enhances latent features by incorporating a structured random basis, which provides a beneficial inductive bias that promotes neuronal specialization to learn specific patterns in the data while reducing the redundancy issue of the classic BLS. Experimental results in various classification and regression datasets demonstrate that SBLS outperforms BLS in terms of performance, robustness to noise, and interpretability, while remaining efficient and easy to deploy. Our findings emphasize the need for focused feature generation through random weights in neural networks and reservoir computing. In fact, we are transitioning from a chaotic to a controlled exploration of patterns. Moreover, we illustrate how our approach can incorporate task-specific knowledge into neuron behavior by design. SBLS has practical implications for real-world applications that involve data scarcity. By refining the way randomness is exploited in neural networks, our work challenges the conventional wisdom that improved performance requires deeper architectures or complex optimization strategies. Instead, we show that intelligent feature generation can unlock significant gains at minimal additional cost. 1},
  archive      = {J_ESWA},
  author       = {Mario Mallea and Ángela Nebot and Francisco Mugica},
  doi          = {10.1016/j.eswa.2025.129948},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129948},
  shortjournal = {Expert Syst. Appl.},
  title        = {Advancing broad learning through structured feature generation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-objective prediction of garment pressure and body contouring efficacy in shapewear: A hybrid GA-BP framework for sizing systems. <em>ESWA</em>, <em>299</em>, 129946. (<a href='https://doi.org/10.1016/j.eswa.2025.129946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate shapewear sizing is essential to maximize wearer comfort and achieve effective body-contouring outcomes, yet remains challenging due to the complex, nonlinear relationship between anthropometric data, garment pressure distribution, and subjective comfort perception. This study presents a novel application of a hybrid intelligent model that integrates backpropagation (BP) neural networks with genetic algorithm (GA) optimization to enhance the precision of size recommendations. The GA-BP framework specifically tackles the limitations of conventional sizing methods by simultaneously optimizing initial weights, activation thresholds, and network topology, effectively escaping local minima and enhancing generalization for dual-objective prediction of garment pressure and contouring efficacy . Experimental results demonstrate superior predictive performance, achieving coefficients of determination (R 2 ) of 0.9896 (training) and 0.9854 (testing), significantly outperforming standard BP networks (0.837). Crucially, the model predicts key ergonomic indicators (e.g., localized pressure values) correlated with comfort, validated through controlled user trials. To bridge research and practice, an intelligent decision support system (DSS) was developed, featuring a C#-based GUI and MATLAB backend. This system processes anthropometric data to provide personalized sizing recommendations through an intuitive user interface. The findings confirm the effectiveness of GA-BP optimization in garment sizing and propose a user-centric decision support framework that harmonizes garment pressure with ergonomic comfort in shapewear selection.},
  archive      = {J_ESWA},
  author       = {Zhu Wenhui and Wang Fenfen and Wang Gehui and Wang Yongrong},
  doi          = {10.1016/j.eswa.2025.129946},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129946},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-objective prediction of garment pressure and body contouring efficacy in shapewear: A hybrid GA-BP framework for sizing systems},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A heterogeneous agent reinforcement learning approach with curriculum learning for variable speed limit control. <em>ESWA</em>, <em>299</em>, 129945. (<a href='https://doi.org/10.1016/j.eswa.2025.129945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of existing Variable Speed Limit (VSL) studies employ rule-based control strategies, which often fail to accommodate diverse road characteristics and lack responsiveness to sudden congestion. These limitations are further compounded by computational inefficiencies, hindering real-time decision-making in large-scale or complex traffic environments. To address these issues, this study proposes a VSL strategy based on Heterogeneous Agent Reinforcement Learning with Curriculum Learning (HARLCL). Specifically, a top-level agent classifies road segments using the Mini-Batch K-means algorithm, thereby capturing the heterogeneity of each segment. The lower-level agents operate with class-specific observation spaces and action spaces, each agent observes and acts its feature set tailored to its segment class while sharing the same reward design and learning architecture. Subsequently, lower-level agents adaptively adjust both the position and length of each controlled segment according to classification results and real-time traffic conditions. Through a reward-driven mechanism, these agents continually refine their control precision. Moreover, curriculum learning is introduced during the multi-agent training process, effectively accelerating convergence and mitigating computational burdens typically encountered in large-scale reinforcement learning. Experiments were conducted in three task scenarios–typical fixed bottlenecks, random task bottlenecks, and multiple bottlenecks using realistic road data. The results indicate that training time decreased by 43.18 % and 47.35 %; in the SUMO microscopic simulation, total travel time was 312.25 veh·h, 43.05 % lower than NoVSL, and safe braking distances also decreased, indicating improved safety and more stable traffic flow. Compared with conventional feedback control and deep reinforcement learning approaches, the HARLCL-based strategy demonstrates substantial advantages in training efficiency and control precision, offering a promising avenue for practical VSL implementation.},
  archive      = {J_ESWA},
  author       = {Zhaoqing Li and Silai Chen and Guosheng Xiao and Yangsheng Jiang and Zhihong Yao and Puxin Yang},
  doi          = {10.1016/j.eswa.2025.129945},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129945},
  shortjournal = {Expert Syst. Appl.},
  title        = {A heterogeneous agent reinforcement learning approach with curriculum learning for variable speed limit control},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diffinformer: Diffusion informer model for long sequence time-series forecasting. <em>ESWA</em>, <em>299</em>, 129944. (<a href='https://doi.org/10.1016/j.eswa.2025.129944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long sequence time-series forecasting (LSTF) is a significant research area with wide-ranging applications in energy, transportation, meteorology, and finance. Current methods primarily rely on statistical machine learning and deep neural network techniques to model historical time series for long-term forecasting. In recent years, Transformer-based models have demonstrated outstanding performance in forecasting, but their high computational costs limit their application. The Informer model addresses issues of high computational complexity and the management of long sequence inputs and outputs. However, existing models still face prediction bottlenecks under limited computational resources. The powerful generative capability of diffusion models can significantly enhance time series forecasting. We propose the Diffinformer model, which utilizes generative models for forecasting. Specifically, it combines conditional diffusion models with the ProbSparse self-attention distilling mechanism of Informer and incorporates the output of the diffusion model into the decoder to capture distant dependencies of observations from the perspective of dynamic systems. Comprehensive experimental results across five large-scale datasets demonstrate that Diffinformer improves predictive accuracy and outperforms corresponding baselines, offering a novel solution to the LSTF problem.},
  archive      = {J_ESWA},
  author       = {Jiacheng Li and Wei Chen and Yican Liu and Junmei Yang and Zhiheng Zhou and Delu Zeng},
  doi          = {10.1016/j.eswa.2025.129944},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129944},
  shortjournal = {Expert Syst. Appl.},
  title        = {Diffinformer: Diffusion informer model for long sequence time-series forecasting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimization of task scheduling and resource allocation for autonomous vehicle testing in vehicle-road-cloud collaborative systems. <em>ESWA</em>, <em>299</em>, 129943. (<a href='https://doi.org/10.1016/j.eswa.2025.129943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient closed site testing is crucial for ensuring the safety and enhancing the performance of autonomous vehicles. To improve testing efficiency in complex testing scenarios, this paper proposes a vehicle-road-cloud collaborative framework for autonomous vehicle testing that integrates task scheduling and resource allocation. First, we construct an integrated testing scenario based on 5G communication networks. Test tasks are prioritized according to their time sensitivity, enabling differences in delay tolerance and processing priorities. Second, Genetic-Enhanced Deep Deterministic Policy Gradient (Genetic-Enhanced DDPG) Scheduler is proposed. Genetic Algorithm (GA) are used to generate initial task scheduling strategies which are stored in the experience replay buffer of DDPG. This process leverages the diversity and redundancy of the GA population, thereby enhancing stability and accelerating convergence in DDPG. Third, dynamic load balancing mechanism for real-time task allocation is implemented to further improve system resource utilization. Finally, we conduct a series of numerical experiments to compare the proposed method with existing delay minimization schemes under various traffic conditions. Evaluation metrics include task completion time and energy consumption, enabling a balanced assessment of execution efficiency and resource utilization. The results show that the proposed task scheduling and resource allocation method significantly reduces task completion time by 33.43 % with a success rate of 98.4 %, lower energy consumption by approximately 15.2 %. More importantly, it achieves a server resource utilization rate of 93.6 %, ensuring high-quality service delivery by maximizing resource efficiency and meeting real-time execution demands. It demonstrate that the proposed method is especially well-suited for Vehicular Edge Computing environments, which require stringent low-latency performance.},
  archive      = {J_ESWA},
  author       = {Lan Yang and Meng Yuan and Yang Liu and Xiaobo Qu and Zhiqiang Hu and Zhe Zhang and Xiangmo Zhao and Shan Fang},
  doi          = {10.1016/j.eswa.2025.129943},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129943},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimization of task scheduling and resource allocation for autonomous vehicle testing in vehicle-road-cloud collaborative systems},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). StructCare: Dynamic graph structure learning for enhancing context-aware healthcare. <em>ESWA</em>, <em>299</em>, 129942. (<a href='https://doi.org/10.1016/j.eswa.2025.129942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of intelligent healthcare systems has generated large-scale electronic health records (EHRs). This data provides a foundation for advancing machine learning in healthcare, particularly for pivotal tasks like disease prediction and medication recommendation. Despite the growing focus on modeling relationships within EHR, most existing methods treat medical events as connected by static relationships, where associations are defined by co-occurrence or fixed correlations. However, such approaches overlook dynamic relationships that reflect how a patient’s health status and treatment evolve over time. Therefore, we propose StructCare, a clustering-based graph structure learning framework that explicitly models these dynamic relationships by integrating lab test results with medical events. Specifically, StructCare leverages large language models to construct relationships among medical events and generate personalized patient graphs from visit records. It then employs temporal networks to capture evolving health trends from monitoring-level events and dynamically updates the graph structure at each visit, generating richer patient representations, thereby improving the accuracy of disease prediction and medication recommendation. Extensive experiments on two real-world datasets and across two tasks show that StructCare consistently outperforms state-of-the-art methods. Specifically, it achieves an average improvement of approximately 2.1 % in F1-score and 2.8 % in Jaccard for disease prediction, and 2.3 % in F1-score and 4.0 % in Jaccard for medication recommendation, highlighting its effectiveness in capturing dynamic, context-aware relationships.},
  archive      = {J_ESWA},
  author       = {Qizheng Sun and Xiang Li and Chuankun Duan and Chen Li and Shunpan Liang},
  doi          = {10.1016/j.eswa.2025.129942},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129942},
  shortjournal = {Expert Syst. Appl.},
  title        = {StructCare: Dynamic graph structure learning for enhancing context-aware healthcare},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generating vascular network structures from real data. <em>ESWA</em>, <em>299</em>, 129941. (<a href='https://doi.org/10.1016/j.eswa.2025.129941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood vessels are essential components of the mammalian circulatory system, responsible for delivering nutrients and oxygen to tissue cells. Studying the structural properties of these complex vascular networks is of great importance given their role in several diseases. Despite recent advances in understanding the biological mechanisms underlying vascular growth and the vast number of computational models that use those mechanisms to simulate vascular development, researchers have not yet tackled the generation of synthetic vascular structures using deep learning implementations that are trained with existing datasets. This work aims to address these challenges by introducing a novel computational approach to generate three-dimensional vascular networks. By using an encoder-decoder architecture, we treat these networks as complex spatial graphs in a three-dimensional space, learning sequential moves to create new nodes and edges that mimic real vascular structures. Without replicating the real-truth network, our method can generate new vascular networks with structural characteristics identical to those of existing real data, such as branching pattern, vessel lengths, network density, and degree distribution. The parameters of the model can be adjusted to regulate and fine-tune the morphology of the generated networks. The achieved results not only demonstrate the potential of our approach in accurately modelling vascular structure but also open new avenues for exploring data-driven models in tissue engineering and to complement imaging data collected in clinical and research contexts.},
  archive      = {J_ESWA},
  author       = {João Braz Simões and Rui D.M. Travasso and Tiago Baptista and Ernesto Costa},
  doi          = {10.1016/j.eswa.2025.129941},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129941},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generating vascular network structures from real data},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Operating performance assessment and fault diagnosis of electro-hydraulic servo valves using trans-SN-CGAN with gaussian and non-gaussian information fusion. <em>ESWA</em>, <em>299</em>, 129940. (<a href='https://doi.org/10.1016/j.eswa.2025.129940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electro-hydraulic servo valve (EHSV) is a critical component in hydraulic systems, particularly in high-precision applications such as aircraft braking systems. Traditional operational performance assessment (OPA) and fault diagnosis (FD) methods often struggle to capture the complex spatiotemporal relationships and non-Gaussian characteristics inherent in EHSV data, especially when dealing with imbalanced datasets. To address these challenges, this paper presents a Transformer-based spectral normalization conditional generative adversarial network (Trans-SN-CGAN) for monitoring the EHSV. Trans-SN-CGAN integrates both Gaussian and non-Gaussian information through kernel principal component analysis (KPCA) and kernel independent component analysis (KICA). It further transforms time-series data into 2D images using Gramian angular fields (GAF), preserving essential spatiotemporal features. Additionally, spectral normalization (SN) is incorporated into the conditional generative adversarial network (CGAN) to enhance training stability and generate high-quality synthetic data samples. The Transformer architecture is utilized to enhance the model’s capacity to extract discriminative feature representations by capturing long-range dependencies in sequential data. Experimental results demonstrate exceptional performance, with OPA accuracy of 97.6 % and FD accuracy of 97.2 %, showcasing the framework’s robustness and reliability for improving EHSV efficiency and dependability.},
  archive      = {J_ESWA},
  author       = {Hanwen Zhang and Wenxiao Yin and Chuanfang Zhang and Qiang Min and Ruihua Jiao and Kaixiang Peng},
  doi          = {10.1016/j.eswa.2025.129940},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129940},
  shortjournal = {Expert Syst. Appl.},
  title        = {Operating performance assessment and fault diagnosis of electro-hydraulic servo valves using trans-SN-CGAN with gaussian and non-gaussian information fusion},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-enhanced structured dataset building for generating meaningful knowledge relationships and diversified questions. <em>ESWA</em>, <em>299</em>, 129939. (<a href='https://doi.org/10.1016/j.eswa.2025.129939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of generative AI, meaningful datasets to effectively retrain Large Language Models (LLMs) for specific domain knowledge have gained widespread recognition across various domains, particularly using datasets with high-level structured relationships of knowledge components (KC). In addition, diversified questions with different difficulty levels and cognitive development levels for specific domain knowledge are highly demanded for evaluation and training purposes. To fulfill these needs, this study proposes a hybrid system utilizing prompt engineering techniques to address several challenges, including the lack of defined structured knowledge components, the limitation of questions to single relationships between knowledge components, and the lack of diversity in question difficulty levels and cognitive development levels. To address these challenges, we leveraged the capabilities of Tree of Thought prompting (ToT) and Retrieval Augmented Generation (RAG) to propose a system called Smart Knowledge with questions and answers (SKQA), which can be applied across various courses. SKQA is designed to automatically generate structured KCs with multiple relationships and create diverse question-answer datasets by leveraging these structured KCs. To illustrate the capabilities of SKQA, the course Fundamentals of Database Systems (FDS) is adopted as an example to demonstrate how our proposed system generates seven structured knowledge component groups with multiple relationships, which is significantly better than other related datasets. Moreover, SKQA generates more than 1000 pairs of questions and answers at varying levels of difficulty and cognitive development. The qualitative and quantitative evaluation results demonstrate that our system has strong potential in generating structured knowledge components and high-quality, diverse question-answer pairs based on the relationships among KCs. While we highlight its application in the Fundamentals of Database Systems course, SKQA is broadly applicable to various subjects and domains (e.g., Operating Systems), showcasing its general utility and adaptability. The code and data are available at https://github.com/vietnq262/SmartSKQA .},
  archive      = {J_ESWA},
  author       = {Wu-Yuin Hwang and Quoc-Viet Nguyen and Min-Te Sun},
  doi          = {10.1016/j.eswa.2025.129939},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129939},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-enhanced structured dataset building for generating meaningful knowledge relationships and diversified questions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AirMamba: A deep learning framework for long-term PM2.5 forecasting integrating multi-scale correlations and time-frequency dynamics. <em>ESWA</em>, <em>299</em>, 129937. (<a href='https://doi.org/10.1016/j.eswa.2025.129937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing approaches for long-term forecasting of PM 2.5 typically focus either on time-domain or frequency-domain features in isolation, neglecting their complementary interactions. This limitation restricts their capacity to effectively capture long-term trends. Moreover, the absence of explicit modeling of multi-scale correlations among influencing factors under complex environmental conditions may undermine both the stability and accuracy of model predictions. To overcome these limitations, we introduce AirMamba, a novel deep learning framework designed to enhance long-term PM 2.5 forecasting by integrating multi-scale correlation analysis with time-frequency interactions. Specifically, a multi-scale inter-variable correlations extractor module is developed to capture the complex interdependencies among variables across diverse temporal scales. The framework leverages the Maximum Overlap Discrete Wavelet Transform (MODWT) to decompose time series data into multi-scale high-frequency and low-frequency components, thereby facilitating a comprehensive time-frequency analysis. An enhanced bidirectional Mamba structure is then employed to model both long- and short-term dependencies within the time series, informed by the identified time-frequency interactions. Extensive experiments demonstrate that the proposed method achieves superior forecasting performance compared to existing mainstream models.},
  archive      = {J_ESWA},
  author       = {Jie Lian and Xiao Wang and Sirong Huang and Dong Wang and Qin Zhao},
  doi          = {10.1016/j.eswa.2025.129937},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129937},
  shortjournal = {Expert Syst. Appl.},
  title        = {AirMamba: A deep learning framework for long-term PM2.5 forecasting integrating multi-scale correlations and time-frequency dynamics},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prompting across perception and recognition: A unified CLIP-based visual-text prompt framework for zero-shot anomaly detection. <em>ESWA</em>, <em>299</em>, 129936. (<a href='https://doi.org/10.1016/j.eswa.2025.129936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection aims to model the distribution characteristics of normal data and identify samples that significantly deviate from this distribution. It has been widely applied in real-world scenarios such as industrial defect detection and medical image analysis. Given the limited availability of anomalous samples, zero-shot anomaly detection (ZSAD) has attracted increasing research interest. ZSAD focuses on training models with source-domain data to detect previously unseen anomalies without requiring target-domain samples. Although recent CLIP-based ZSAD approaches have shown promise by leveraging textual prompts or auxiliary data, they still encounter challenges such as substantial performance gaps between image-level and pixel-level tasks and unstable generalization capabilities. To address these limitations, this paper proposes PPR-CLIP, a CLIP-based anomaly detection framework that establishes a unified vision-language feature alignment mechanism by integrating prior knowledge with real-time adaptability. The proposed method effectively exploits latent semantic information from auxiliary data and incorporates textual prompts at both the front-end perception and back-end recognition stages, enabling consistent and deeply integrated prompt guidance. Extensive experiments on 13 industrial and medical image datasets demonstrate that PPR-CLIP achieves superior performance in both anomaly localization and classification tasks, confirming the effectiveness and generalizability of the proposed cross-modal fusion and unified prompt mechanism in the context of ZSAD.},
  archive      = {J_ESWA},
  author       = {Jiahao Lai and Zehao Wu and Lingxi Peng and Haohuai Liu},
  doi          = {10.1016/j.eswa.2025.129936},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129936},
  shortjournal = {Expert Syst. Appl.},
  title        = {Prompting across perception and recognition: A unified CLIP-based visual-text prompt framework for zero-shot anomaly detection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orientation-aware detection system for real-time monitoring of cracks in steel structures. <em>ESWA</em>, <em>299</em>, 129932. (<a href='https://doi.org/10.1016/j.eswa.2025.129932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection plays a crucial role in steel structure health monitoring. However, conventional methods primarily rely on horizontal bounding box (HBB) detection to locate cracks, which lack orientation information and are susceptible to noise and false positives, thus hindering accurate and real-time performance. To address these limitations, this study proposes an orientation-aware detection system designed to more accurately assess the condition of steel cracks. Specifically, a parallel adaptive perceptual (PAP) attention module, an information interaction perception (I2P) head, and an orientation-shape guided (OSG) loss function are designed to enhance the performance of steel crack detection. Extensive experiments on both a custom-built steel structure crack dataset and public benchmarks demonstrate that our framework achieves a significant mAP improvement of 4.3 %-10.0 % compared to Yolov11s-obb and Yolov12s-obb. Furthermore, our model exhibits reduced computational cost relative to the baseline while achieving state-of-the-art (SOTA) performance.},
  archive      = {J_ESWA},
  author       = {Hongru Xiao and Bin Yang and Yantao Yu and Jiale Han and Zhen Lian and Songning Lai},
  doi          = {10.1016/j.eswa.2025.129932},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129932},
  shortjournal = {Expert Syst. Appl.},
  title        = {Orientation-aware detection system for real-time monitoring of cracks in steel structures},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rootex 2.0: Multi-head deep learning and graph-based analysis for automated barley root phenotyping. <em>ESWA</em>, <em>299</em>, 129930. (<a href='https://doi.org/10.1016/j.eswa.2025.129930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding plant root architecture under diverse environmental conditions is crucial for improving crop resilience and ensuring global food security. We present a fully automated method for segmenting barley root systems from high-resolution images and detecting keypoints such as tips and sources with high precision. At the core of our approach is DeepRoot-3H , a novel multi-head deep network built upon the DeepLabv3+ backbone, designed to jointly handle root segmentation and keypoint detection within a unified architecture. This integrated design enhances both the consistency and robustness of the outputs. A dedicated post-processing stage further refines keypoint localization, effectively handling challenges such as dense root clusters and variability in image quality. The resulting predictions are then structured into a graph representation, on which a path-walking algorithm identifies biologically meaningful connections between tips and sources. This enables the generation of RSML files and the extraction of critical morphological traits. To evaluate the system, we employ IoU and Dice scores for segmentation quality, alongside Euclidean and weighted distance metrics for tip and source detection. We also assess the biological consistency of the extracted traits—such as total root length, tortuosity, covered area, and outer angles—through correlation and discrepancy measures. Experimental results on a challenging benchmark dataset demonstrate significant improvements over existing techniques, confirming the effectiveness and reliability of our method for high-fidelity root system analysis.},
  archive      = {J_ESWA},
  author       = {Maichol Dadi and Annalisa Franco and Alessandra Lumini},
  doi          = {10.1016/j.eswa.2025.129930},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129930},
  shortjournal = {Expert Syst. Appl.},
  title        = {Rootex 2.0: Multi-head deep learning and graph-based analysis for automated barley root phenotyping},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MACR-afford: Weakly supervised multimodal affordance grounding via multi-branch attention enhancement and CoT multi-stage reasoning. <em>ESWA</em>, <em>299</em>, 129929. (<a href='https://doi.org/10.1016/j.eswa.2025.129929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal affordance grounding plays a crucial role in enabling computer systems to understand and recognize the functions and potential uses of objects. Affordance grounding involves not only identifying the shape and appearance of objects, but also understanding how they interact with the environment and users. However, current research faces challenges in accurately localizing affordance regions and addressing previously unseen scenarios. To address these challenges, we propose a weakly supervised multimodal affordance grounding framework, termed MACR-Afford, which combines a Multi-Branch Attention Enhancement module and a multi-stage Chain-of-Thought reasoning module. Under the guidance of a large language model, MACR-Afford improves the ability of intelligent agents to recognize and utilize objects in complex environments. First, we introduce a Multi-Branch Attention Enhancement (MBAE) module to improve the complementarity among object features. By enhancing cross-branch attention and extracting complementary discriminative features, MBAE enables more accurate localization of affordance regions. Subsequently, we introduce a Chain-of-Thought multi-stage reasoning module to generates general affordance knowledge units, which are used to guide the model in localizing affordance-relevant regions. Comprehensive experiments demonstrate that MACR-Afford consistently achieves superior performance in both seen and unseen scenarios, surpassing state-of-the-art baselines across multiple evaluation metrics. The code is publicly available at: https://github.com/HuiHui-Robot/MACR-Afford .},
  archive      = {J_ESWA},
  author       = {Peiliang Wu and Fengtao Sun and Yifan Liu and Shanyi Zhang and Shiyu Wang and Xiaohu Zhou and Wenbai Chen},
  doi          = {10.1016/j.eswa.2025.129929},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129929},
  shortjournal = {Expert Syst. Appl.},
  title        = {MACR-afford: Weakly supervised multimodal affordance grounding via multi-branch attention enhancement and CoT multi-stage reasoning},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A matrix-assisted surrogate particle swarm optimization algorithm for multi-objective deployment of solar insecticidal lamps. <em>ESWA</em>, <em>299</em>, 129926. (<a href='https://doi.org/10.1016/j.eswa.2025.129926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar Insecticidal Lamps (SILs) are a green and efficient pest control method in modern agriculture, but their deployment must balance coverage efficiency, cost, and uniformity, especially in irregular and partitioned farmland. To address this challenge, this paper formulates the Solar Insecticidal Lamp Deployment Problem (SILDP) as a multi-objective optimization problem and proposes a Matrix-based Assisted Surrogate-Aided Multi-Objective Particle Swarm Optimization (MASA-MOPSO) algorithm. This method incorporates matrix computation to fully exploit the parallel computing capabilities of modern platforms. The Spatially-aware Crowding Distance (SCD) calculation is adopted to update the external archive and select leader particles, enhancing the diversity and uniformity of the solution set. During the particle swarm evolution process, a surrogate-guided mechanism is introduced to reduce the computational burden of the objective functions and assist in exploring potentially high-quality regions, thereby enhancing local search capabilities. Meanwhile, a new calculation method for smoothed coverage probability is introduced to address the hard-threshold issues in traditional coverage probability metrics. This improvement allows the incorporation of gradient information to adaptively adjust particle step sizes, thereby accelerating convergence and enhancing optimization accuracy. Experiments in complex farmland environments show that MASA-MOPSO significantly outperforms eight advanced algorithms in terms of deployment cost, coverage, overlap, variability, and runtime, demonstrating its strong effectiveness in solving the SILDP.},
  archive      = {J_ESWA},
  author       = {Wenjie Liu and Donglin Zhu and Changjun Zhou and Shi Cheng and Lianbo Ma and Taiyong Li},
  doi          = {10.1016/j.eswa.2025.129926},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129926},
  shortjournal = {Expert Syst. Appl.},
  title        = {A matrix-assisted surrogate particle swarm optimization algorithm for multi-objective deployment of solar insecticidal lamps},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PHGAT: Persistent homology-enhanced graph attention network for IIoT anomaly detection. <em>ESWA</em>, <em>299</em>, 129923. (<a href='https://doi.org/10.1016/j.eswa.2025.129923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational safety and efficiency of modern Industrial Internet of Things (IIoT) systems, which generate massive volumes of high-dimensional multivariate time series data, hinge on the early detection of anomalies. However, existing graph-based methods often struggle with the structural instability of dynamically learned graphs and are blind to higher-order, multi-component system dependencies. This paper introduces the Persistent Homology-enhanced Graph Attention Network (PHGAT). This novel framework addresses these critical limitations by pioneering a co-learning paradigm that structurally regularizes dynamic graph learning through topological invariants. Unlike prior works that apply persistent homology to static graphs or as a simple feature augmentation step, PHGAT introduces a principled framework where pH-derived topological features provide global structural constraints, forcing the model to learn meaningful and robust sensor relationships from noisy time-series data. The framework integrates three key innovations: (1) an adaptive graph construction mechanism that dynamically learns sensor relationships by fusing spatio-temporal correlations to model evolving system dynamics; (2) a hierarchical graph attention architecture with cross-scale mechanisms to capture multi-resolution temporal dependencies; and (3) a learnable topological vectorization component that leverages persistent homology to extract robust structural invariants, enhancing model resilience. Extensive experiments on four public IIoT benchmarks–SWaT, SMD, WADI, and SMAP–demonstrate that PHGAT consistently outperforms state-of-the-art methods by a significant margin. Notably, PHGAT achieves an F1-score of 0.976 on SWaT, improving upon the best-performing baseline by 2.24 %, which validates the efficacy of topological regularization in dynamic graph learning for IIoT anomaly detection.},
  archive      = {J_ESWA},
  author       = {Lulu Wang and Yuhua Sun and Xuchong Liu and Chengqing Li},
  doi          = {10.1016/j.eswa.2025.129923},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129923},
  shortjournal = {Expert Syst. Appl.},
  title        = {PHGAT: Persistent homology-enhanced graph attention network for IIoT anomaly detection},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid FAIR and XGBoost framework for cyber-risk intelligence and expected loss prediction. <em>ESWA</em>, <em>299</em>, 129920. (<a href='https://doi.org/10.1016/j.eswa.2025.129920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a hybrid framework integrating the Factor Analysis of Information Risk (FAIR) model with XGBoost and SHAP explainablity for cyber risk intelligence. We extend traditional FAIR methodology by developing a composite Risk Exposure Score (RES) that unifies frequency, vulnerability, control maturity, loss severity, and operational downtime into a standardised metric for risk stratification and machine learning analysis. Our novel NIST CSF-based control maturity quantification provides objective measures of security effectiveness using technology (40%), process (35%), and people (25%) weightings derived from empirical correlation analysis. Testing on 3000 simulated cyber incident scenarios reveals threshold effects, with Expected Annual Loss exhibiting exponential growth beyond RES values of 0.4. SHAP analysis identifies Primary Loss and Technology Score as the most influential EAL predictors, demonstrating that control maturity effectiveness diminishes significantly in high-exposure environments. We deployed a Streamlit-based dashboard operationalising the framework for risk analysts, cyber insurers, and governance professionals. The system processes threat intelligence data, generates probabilistic risk scenarios, and provides real-time risk calculations through an interactive interface. This research contributes the first deployable integration of FAIR quantitative modelling with explainable ML, addressing the research-to-practice gap in cyber-risk quantification while supporting regulatory compliance requirements under NIS2 and SEC cybersecurity disclosure mandates.},
  archive      = {J_ESWA},
  author       = {Chioma Ngozi Nwafor and Obumneme Nwafor and Sanjukta Brahma and Madhusudan Acharyya},
  doi          = {10.1016/j.eswa.2025.129920},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129920},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid FAIR and XGBoost framework for cyber-risk intelligence and expected loss prediction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FLIT: Federated ledger and intelligence for trust-bootstrapping in the internet of medical things. <em>ESWA</em>, <em>299</em>, 129916. (<a href='https://doi.org/10.1016/j.eswa.2025.129916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the Internet of Medical Things (IoMT) has transformed how healthcare data is collected and analyzed to improve patient health through real-time monitoring and personalized treatment. However, there is a significant concern over data security, privacy, and trust among healthcare providers. To address these challenges, we present a federated ledger and intelligence framework named FLIT to provide secure and privacy-preserving data sharing across multiple healthcare stakeholders. The proposed method combines blockchain technology with federated learning (FL) to protect sensitive patient information. Herein, patient data is never shared in raw form and is encrypted and distributed among trusted stakeholders so that individual data points remain confidential and tamper-proof. Besides, access control is enforced using smart contracts that automatically grant or deny permissions based on predefined conditions. To enhance clinical decision-making, FL allows hospitals and healthcare providers to collaboratively train machine learning models without exchanging actual patient data. These models are then used to generate recommendations for patients’ treatment plans, which can be shared across the network. We also implemented and tested the FLIT using smart contracts deployed on Ethereum environments and FL models trained on real-world healthcare datasets. Our experiment results evaluated several metrics, such as local and global model accuracy, training loss, trust score, and cost of smart contract operations across multiple Ethereum Virtual Machines. The proposed work achieves high model performance and preserves privacy by validating its robustness in real-world healthcare scenarios.},
  archive      = {J_ESWA},
  author       = {Debashis Das and Sourav Banerjee and Debashis De},
  doi          = {10.1016/j.eswa.2025.129916},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129916},
  shortjournal = {Expert Syst. Appl.},
  title        = {FLIT: Federated ledger and intelligence for trust-bootstrapping in the internet of medical things},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradient-aligned physics-informed neural network for performance analysis of permanent magnet eddy current device under complex operating conditions. <em>ESWA</em>, <em>299</em>, 129915. (<a href='https://doi.org/10.1016/j.eswa.2025.129915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The permanent magnet drive (PMD) is a non-contact mechanical power transmission device that demonstrates broad application prospects in industrial fields due to its exceptional torque control performance and structural reliability. However, with the increasing demand for real-time condition monitoring and the advancement of high-power-density PMD design, achieving efficient and accurate performance analysis has become a critical challenge. Artificial intelligence-driven digital twin approaches offer a novel perspective to address this issue, among which Physics-Informed Neural Networks (PINNs) exhibit significant potential by integrating data with physical knowledge. Nevertheless, under complex operating conditions, the skin effect of electromagnetic fields and the scale variation of solution domains in PMD severely limit the prediction accuracy and physical consistency of PINNs. To address the aforementioned challenges, this paper proposes a Gradient-Aligned Physics-Informed Neural Network (GA-PINN) method for performance analysis of PMD under complex conditions. GA-PINN incorporates electromagnetic governing equations and boundary conditions into the loss function to guide the model training process. By identifying and aligning the gradient information of the loss terms, it dynamically balances the model’s constraint capacity across multi-scale solution domains. Additionally, a dynamic sampling strategy is introduced, which reconstructs the distribution probability of collocation points by identifying the gradient characteristics of the solution function, thereby addressing the mismatch in the global distribution of collocation points caused by localized high residuals. Through experimental validation across multiple operating conditions and structural parameters, GA-PINN achieves efficient and accurate performance analysis of PMD in complex scenarios, providing a reliable theoretical basis for its performance monitoring and optimization design. Dataset link: https://github.com/wongsihan/GA-PINN .},
  archive      = {J_ESWA},
  author       = {Sihan Wang and Kai Wang and Peng Zeng and Yaguo Lei and Zhiping Wang and Bo Zhang},
  doi          = {10.1016/j.eswa.2025.129915},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129915},
  shortjournal = {Expert Syst. Appl.},
  title        = {Gradient-aligned physics-informed neural network for performance analysis of permanent magnet eddy current device under complex operating conditions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Link prediction in social networks and E-commerce: A comprehensive review and bibliometric analysis. <em>ESWA</em>, <em>299</em>, 129914. (<a href='https://doi.org/10.1016/j.eswa.2025.129914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This comprehensive review thoroughly examines the dynamic field of link prediction in social networks, focusing specifically on its applications in e-commerce through integrated bibliometric analysis and narrative review. The study analyzes research developments from 2005 to 2024, revealing significant growth characterized by a 22.46% annual increase in research output. Our analysis of 690 documents from 358 distinct sources demonstrates a clear methodological evolution from traditional statistical approaches to advanced machine learning techniques, particularly graph neural networks and deep learning models. The study comprehensively examines link prediction algorithms diverse applications in e-commerce, encompassing personalized recommendations, influencer identification, strategic collaborations, and fraud detection. Through systematic investigation, we identify significant regional disparities in research production, with China (902 publications) and the USA (483 publications) emerging as dominant contributors, while noting limited international collaboration (21.45 % cross-border co-authorship). The field demonstrates strong interdisciplinary characteristics, with substantial contributions from computer science, mathematics, and engineering, alongside growing engagement from social sciences and business studies. Key challenges include data sparsity, scalability issues, the cold-start problem, and the need for interpretable models. Our findings highlight crucial research opportunities in developing dynamic network models, exploring ethical artificial intelligence applications, enhancing cross-platform prediction capabilities, and integrating large language models. This review provides valuable insights for researchers, practitioners, and policymakers, emphasizing the importance of balancing technological innovation with ethical considerations in the evolving landscape of social networks and e-commerce.},
  archive      = {J_ESWA},
  author       = {Gehad Abdullah Amran and Xianneng Li and Ali A. Al-Bakhrani},
  doi          = {10.1016/j.eswa.2025.129914},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129914},
  shortjournal = {Expert Syst. Appl.},
  title        = {Link prediction in social networks and E-commerce: A comprehensive review and bibliometric analysis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bank financing or e-commerce platform financing: Green supply chain financing strategies with blockchain integration. <em>ESWA</em>, <em>299</em>, 129912. (<a href='https://doi.org/10.1016/j.eswa.2025.129912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amid rapid technological advancements, blockchain’s ability to prevent supply chain greenwashing and its high cost characteristics have made green products utilizing blockchain technology more appealing to consumers. The question of whether green supply chains should secure financing to adopt blockchain technology has become increasingly urgent. We developed a green supply chain model involving a manufacturer investing in green technology innovation and an e-commerce platform (EP) with sufficient funds to provide blockchain technology. We employed a Stackelberg game model to examine and compare the operational strategies of six different scenarios involving both bank financing and EP financing, with and without the adoption of blockchain technology. Various parameters were considered in our analysis, including the cost of green technological innovation, the cost of adopting blockchain technology, and consumer preferences, to uncover their impacts on the decisions and profits of supply chain members. Additionally, we set different interest rates for bank financing and EP financing, while also accounting for financing approval costs. Our findings indicate that with the adoption of blockchain technology, an increase in consumer preference for green products leads to higher product greenness and sales quantity. However, in scenarios with blockchain, the product greenness and sales quantity may not necessarily exceed those without blockchain. We discovered that there is no universally optimal operational choice within a blockchain-based green supply chain. Under certain conditions, manufacturers should forgo the introduction of blockchain technology, as this would result in higher profits for supply chain members. However, when cost of adopting blockchain technology and financing interest rate fall below a certain threshold, the blockchain + bank financing scenario becomes more advantageous for manufacturers. In other words, under specific conditions, the supply chain can achieve a win–win situation through the combination of “blockchain + financing”.},
  archive      = {J_ESWA},
  author       = {Yuting Zhang and Honghong Kou},
  doi          = {10.1016/j.eswa.2025.129912},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129912},
  shortjournal = {Expert Syst. Appl.},
  title        = {Bank financing or e-commerce platform financing: Green supply chain financing strategies with blockchain integration},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Effective hybrid branch-and-cut algorithm for the inventory routing problem with open vehicle routing constraints. <em>ESWA</em>, <em>299</em>, 129905. (<a href='https://doi.org/10.1016/j.eswa.2025.129905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers a kind of inventory routing problem, which jointly optimizes the open vehicle routing decision and the inventory replenishment in a real-world distribution scenario. That is, the considered problem is an integrated optimization problem with two coupled subproblems (IOP_TCSP), i.e., the open vehicle routing problem (OVRP) and the inventory replenishment problem. The criterion is to minimize the total logistics and inventory costs under multiple periods. The IOP_TCSP is modelled as a mixed integer programming problem, and then a hybrid branch-and-cut algorithm combining novel Lagrangian heuristic approach and valid inequalities (HB&C_NLHAVI) is devised to deal with it. Test results on 72 instances with different scales demonstrate that the devised HB&C is more effective than the commercial solver Gurobi. Specifically, the HB&C can obviously reduce optimality gaps for many instances within the similar or less running time, and it can reduce the optimality gaps by 12–24% within only 60–70% of Gurobi’s running time for almost all large-scale instances.},
  archive      = {J_ESWA},
  author       = {Nai-Kang Yu and Bin Qian and Rong Hu and Jian-Bo Yang},
  doi          = {10.1016/j.eswa.2025.129905},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129905},
  shortjournal = {Expert Syst. Appl.},
  title        = {Effective hybrid branch-and-cut algorithm for the inventory routing problem with open vehicle routing constraints},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RS-GCL: Randomized SVD-based graph-enhanced contrastive learning for recommendation. <em>ESWA</em>, <em>299</em>, 129902. (<a href='https://doi.org/10.1016/j.eswa.2025.129902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, contrastive learning has attracted considerable attention in the recommendation domain owing to its ability to extract valuable supervisory signals from large-scale unsupervised data. However, existing graph augmentation-based contrastive learning strategies often compromise the structural integrity of the original graph views to enhance model robustness. This trade-off can lead to the loss of global information, ultimately degrading overall model performance. Moreover, during the aggregation process in graph neural networks (GNNs), indiscriminate information merging across layers may result in the loss of fine-grained details. To address these issues, we propose a novel algorithm: Randomized singular value decomposition (SVD)-based Graph-enhanced Contrastive Learning for Recommendation (RS-GCL). In particular, RS-GCL leverages randomized SVD to generate two fully connected contrastive views that retain global collaborative signals. The first view is constructed using a smaller q value, reducing the original graph to a low-dimensional embedded representation that captures essential user preference information. The second view uses a larger q value to obtain a more accurate approximation, thereby preserving finer structural details of the original graph. In addition, we introduce a set of layer-wise aggregation coefficients to mitigate the oversmoothing problem commonly encountered in GNNs. Extensive experiments on multiple benchmark datasets demonstrate that RS-GCL significantly outperforms existing state-of-the-art recommendation models. Further analysis reveals its strong robustness in addressing challenges such as data sparsity and popularity bias, underscoring its effectiveness in real-world recommendation scenarios. The code for RS-GCL is publicly available at: https://github.com/3endurance/RS-GCL .},
  archive      = {J_ESWA},
  author       = {Jing Sun and Xingchen Peng and Ganghui Li and Fangmei Chen},
  doi          = {10.1016/j.eswa.2025.129902},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129902},
  shortjournal = {Expert Syst. Appl.},
  title        = {RS-GCL: Randomized SVD-based graph-enhanced contrastive learning for recommendation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A structure carved building mesh simplification. <em>ESWA</em>, <em>299</em>, 129896. (<a href='https://doi.org/10.1016/j.eswa.2025.129896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional building models are extensively utilized in domains such as smart cities and environmental assessments. However, the complex geometric structures and topological relationships of building models present significant challenges for applications such as rendering and spatial analysis. Existing methods rely on local geometry-based simplification approaches while underutilizing structural information, making it difficult to preserve both geometric structure fidelity and topological validity. This paper first proposes a novel approach to simplify man-made building meshes through structure carving. Initially, the spatial relationships of planar primitives are analyzed to construct an attribute-connected graph. The graph is then decomposed, and structures are extracted based on various connected relationships. Finally, the visual hull algorithm is employed to generate the visual mesh, which is subsequently simplified into a low-poly mesh through structure carving and mesh simplification. Structure carving introduces a novel framework comprising structure selection, structure primitives generation, and iterative carving, driven by depth loss. Experiments on various building models show that our method generates lightweight meshes that are watertight, accurate, and exhibit high geometric similarity, outperforming other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Zepeng Hou and Fan Zhang and Wenxuan Liu and Yunlong Gao and Xuan Wang and Xianfeng Huang},
  doi          = {10.1016/j.eswa.2025.129896},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129896},
  shortjournal = {Expert Syst. Appl.},
  title        = {A structure carved building mesh simplification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fusing context and path with efficient negative sampling and retrieval for inductive link prediction. <em>ESWA</em>, <em>299</em>, 129894. (<a href='https://doi.org/10.1016/j.eswa.2025.129894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive link prediction in knowledge graphs is critical for artificial intelligence, natural language processing, and graph reasoning, as it aims to infer missing triples with unseen entities. Existing path-based methods with pre-trained language models improve accuracy and interpretability but are hindered by noisy negative samples, sparse reasoning paths, and limited semantic coverage. We propose CPNR ( C ontext and P ath with efficient N egative sampling and R etrieval), which introduces semantic-aware negative sampling to generate informative negatives, incorporates multi-hop context to mitigate path sparsity, and leverages large language model-generated entity descriptions by merging short and long descriptions into sentences encoded with a Sentence Transformer for final scoring and prediction. Two variants are developed: CPNR_R (random sampling) and CPNR_S (semantic-aware sampling). Experiments on transductive, inductive, and few-shot settings show that CPNR_S achieves state-of-the-art results, surpassing prior methods by 22.26 % and improving over CPNR_R by 32.32 %, while CPNR_R itself still exceeds strong baselines by 1.21 %.},
  archive      = {J_ESWA},
  author       = {Xinyu Liang and Guannan Si and Linnan Lu and Mingshen Li and Fengyu Zhou},
  doi          = {10.1016/j.eswa.2025.129894},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129894},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fusing context and path with efficient negative sampling and retrieval for inductive link prediction},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). R&D direction and equity financing strategy selection for key component suppliers. <em>ESWA</em>, <em>299</em>, 129893. (<a href='https://doi.org/10.1016/j.eswa.2025.129893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reducing marginal production cost and enhancing product quality are two potential directions for the research and development (R&D) of key component suppliers. However, R&D needs substantial capital. Equity financing is one of the main methods to mitigate the financing pressure of conducting R&D. This study considers two types of equity financing: internal equity financing and external equity financing. We develop a game model comprising a capital-constrained key component supplier and a capital- abundant manufacturer to capture different equity financing strategies and R&D directions, and investigate supply chain members’ selection decisions regarding equity financing strategies and R&D directions and the interplay between the two decisions. The results show that the R&D direction and equity financing strategy have a significant impact on the relationship between the R&D level and pricing/equity transfer ratio decision. However, the R&D direction does not affect the supplier’s choice of equity financing strategy. Specifically, no matter the R&D direction is to reduce marginal production cost or to improve product quality, the supplier will always choose internal equity financing; while the manufacturer will opt for external equity financing. When the price sensitivity coefficient is large, both the supplier and the manufacturer can achieve a win–win situation in terms of R&D direction. Interestingly, when the supplier’s R&D level are equal under different R&D directions, regardless of whether internal or external equity financing strategies are used, the cost-reduction R&D direction is optimal for both the supplier and the manufacturer when the price sensitivity coefficient is high. However, when the supplier’s R&D level differ under different R&D directions, various equity financing strategies will influence the technology R&D direction choices of supply chain members. Additionally, our analysis indicates that internal equity financing yields a higher equity transfer ratio in comparison to external equity financing.},
  archive      = {J_ESWA},
  author       = {Xueping Zhen and Xiaoyu Tang and Dan Shi and Jiangjing Liu and Xinran Li},
  doi          = {10.1016/j.eswa.2025.129893},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129893},
  shortjournal = {Expert Syst. Appl.},
  title        = {R&D direction and equity financing strategy selection for key component suppliers},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DC-RRG: Diagnosis-centered cascaded radiology report generation. <em>ESWA</em>, <em>299</em>, 129884. (<a href='https://doi.org/10.1016/j.eswa.2025.129884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation (RRG) aims to automatically generate clinical reports from chest Xray images, offering potential benefits in aiding diagnosis and reducing clinician workload. However, this task remains challenging due to the need for generating diagnostically accurate and comprehensive reports. Previous methods neglect explicit and fine-grained diagnosis guidance, which is critical for addressing these challenges. To this end, we introduce a novel Diagnosis Centered method for Radiology Report Generation (DC-RRG), explicitly incorporating diagnostic observations to guide report generation. Specifically, our method utilizes a cascaded inference framework, initially using a large language model to generate diagnoses, which subsequently guide the generation of comprehensive reports. We design multi-modal prompts ( i.e. , textual instructions, visual features, and medical knowledge features) to extend the Multi-Modal Large Language Model (MLLM) to generate accurate and comprehensive diagnostic reports. Additionally, we also develop a progressive training strategy that aligns modalities in two stages: first using reports for coarse clinical priors, then using diagnoses for fine-grained details. Extensive experiments on MIMIC-CXR and IU-Xray datasets demonstrate that DC-RRG surpasses all previous methods and achieves new state-of-the-art results.},
  archive      = {J_ESWA},
  author       = {Zihao Lin and Zinan Hong and Zijian Zhou and Miaojing Shi and Jin-Gang Yu and Jingping Yun and Shuangping Huang},
  doi          = {10.1016/j.eswa.2025.129884},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129884},
  shortjournal = {Expert Syst. Appl.},
  title        = {DC-RRG: Diagnosis-centered cascaded radiology report generation},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AdaptiveStreamFL: A bayesian-enhanced multi-scale federated learning framework for dynamic data streams with uncertainty quantification. <em>ESWA</em>, <em>299</em>, 129882. (<a href='https://doi.org/10.1016/j.eswa.2025.129882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) in streaming data environments presents significant challenges, including concept drift, parameter instability, and client heterogeneity, which collectively hinder robust and adaptive model learning. To address these issues, we propose AdaptiveStreamFL, a framework designed to enhance adaptability in federated streaming scenarios. The method incorporates adaptive parameter selection guided by information-theoretic principles, prototype-based representation learning with dynamic adjustment, and Bayesian inference with explicit uncertainty modeling. These mechanisms are intended to improve adaptability to evolving data streams while maintaining efficiency and privacy within the FL paradigm. Experimental evaluations on several real-world datasets indicate that AdaptiveStreamFL achieves stable performance and demonstrates resilience under dynamic and heterogeneous conditions. Overall, the framework provides a theoretically grounded and practically feasible approach to advancing federated learning in streaming environments.},
  archive      = {J_ESWA},
  author       = {Tai Xiong and Chi Zhang and Miao Rong and Dunwei Gong and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129882},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129882},
  shortjournal = {Expert Syst. Appl.},
  title        = {AdaptiveStreamFL: A bayesian-enhanced multi-scale federated learning framework for dynamic data streams with uncertainty quantification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep low-rank tensor embedded network for hyperspectral image super-resolution. <em>ESWA</em>, <em>299</em>, 129864. (<a href='https://doi.org/10.1016/j.eswa.2025.129864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent efforts have witnessed significant progress in deep-learning-based hyperspectral image super-resolution (HSISR). However, most existing methods focus solely on spatial or spectral exploration, while lacks enough consideration of the intrinsic correlation between these aspects. This oversight limits the potential for collaborative optimization, leading to suboptimal feature representations of HSI. Moreover, they mainly engaged in super-resolve the pixel-wise spatial details, neglecting the vital spectral consistency. To mitigate these issues, this paper proposed LRTENet, a novel deep low-rank tensor embedding network for HSISR, which effectively bridges the optimization gap between spatial and spectral features with well-defined low-rank tensor decomposition. Specially, we introduce a low-rank embedding module (LREM) to extract low-rank dependencies across multiple directions facilitating a holistic mapping by adaptively integrating these tensors. This enables our model to generate discriminative spatial-spectral representations for accurate reconstruction. Furthermore, to better preserve the spectral consistency, we incorporate LREM after upsample operation to progressively refine and correct spectral distortion. Extensive experiments demonstrate that LRTENet achieves superior spatial reconstruction and spectral preservation performance, outperforming state-of-the-art methods on various benchmarks, including Chikusei, CAVE, and Pavia.},
  archive      = {J_ESWA},
  author       = {Qiang Zhang and Xianpeng Zhang and Yi Xiao and Hongjie Xie},
  doi          = {10.1016/j.eswa.2025.129864},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129864},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep low-rank tensor embedded network for hyperspectral image super-resolution},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive personalized large-scale group decision-making model based on psychobehavior in comprehensive trust network. <em>ESWA</em>, <em>299</em>, 129863. (<a href='https://doi.org/10.1016/j.eswa.2025.129863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus decision-making methods for large-scale group decision-making problems in trust networks have become an important research direction of decision science. An adaptive personalized feedback mechanism based on self-confidence-certainty and psychological discrepancy in the consensus reaching process is proposed for the large-scale group decision-making problem under social trust network. Firstly, a comprehensive trust network is constructed based on trust familiarity and trust similarity. Secondly, the subgroup weights are calculated based on internal cohesion and external cohesion, and the social network DeGroot model is extended by considering the self-confidence-certainty and personalization factors. Thirdly, based on the self-confidence-certainty and psychological discrepancy measurement, adaptive personalized feedback mechanism is used to classify experts into four classes considering experts’ willingness and psychological behaviors. Finally, the method is validated by the problem of ‘east data, west computing’ project selection.},
  archive      = {J_ESWA},
  author       = {Wei Yang and Yizhuo Wang},
  doi          = {10.1016/j.eswa.2025.129863},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129863},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive personalized large-scale group decision-making model based on psychobehavior in comprehensive trust network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ACA-net: Adaptive cloud-aware network for remote sensing image thick cloud removal. <em>ESWA</em>, <em>299</em>, 129859. (<a href='https://doi.org/10.1016/j.eswa.2025.129859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequent appearance of clouds, particularly thick clouds, in optical Remote Sensing (RS) images significantly restricts the continued use of RS images. The current multi-temporal cloud removal models have two drawbacks when the cloud occlusion ratio varies substantially across the temporals. The first is the static processing for temporals with varying cloud occlusion ratios, and the second is the lack of a dynamic adaptive mechanism for adjusting the prompt intensity acrosstemporals. A novel dynamic deep-learning model with a two-stage coarse-to-fine network framework (ACA-Net) is proposed to overcome these drawbacks, which incorporates three main modules to accomplish adaptive processing: (1) a Self-Attention Adaptive K module, which dynamically adjusts the proportion of attention maps according to cloud occlusion ratios, balancing effectiveness and efficiency, (2) an Adaptive High-Low Frequency module, which selectively emphasizes frequency components to improve detail recovery and structural consistency, and (3) an Adaptive Temporal Prompt module, which adaptively modulates prompt intensity across temporals to enhance cross-temporal information fusion. Extensive experiments on our cloud removal datasets demonstrate that ACA-Net significantly outperforms five typical cloud removal modules in both quantitative and qualitative metrics. Importantly, ACA-Net maintains strong cloud removal performance even when cloud occlusion ratios vary greatly across the three temporal inputs. Compared with the latest DiffCR model, ACA-Net achieves a 34.2 % PSNR improvement and a 13.0 % SSIM improvement, while requiring 89.4 % fewer parameters. These results highlight ACA-Net’s effectiveness and efficiency in thick cloud removal. The source code of ACA-Net model can be accessed at https://github.com/BaopuHou/ACA-Net .},
  archive      = {J_ESWA},
  author       = {Baopu Hou and Yaowei Li and Xin Dang and Jinguang Wang and Quankai Zhao and Hongjia Qu and Yuting Yang and Xiaoxuan Chen and Bo Jiang},
  doi          = {10.1016/j.eswa.2025.129859},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129859},
  shortjournal = {Expert Syst. Appl.},
  title        = {ACA-net: Adaptive cloud-aware network for remote sensing image thick cloud removal},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-fruit leaf disease detection and severity assessment using catch fish optimized deep learning model. <em>ESWA</em>, <em>299</em>, 129838. (<a href='https://doi.org/10.1016/j.eswa.2025.129838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate disease detection in fruit leaves is crucial for preserving crop health and enhancing agricultural productivity. Fruits hold significant economic value and nutritional importance, but their vulnerability to diseases severely impacts both yield and quality. This research proposes a novel Multi-level Attention DenseNet-based Deep Convolutional Neural Network (MADDCNN) model to improve fruit disease detection. The model addresses challenges such as varying lighting conditions, complex backgrounds, and overlapping symptoms, which hinder detection accuracy in existing systems. By incorporating the Catch Fish Optimization (CFO) technique, MADDCNN enhances multi-fruit classification accuracy and optimizes parameter tuning for better performance. To further enhance the detection process, the model employs the Hybrid Runge Kutta DeepLabV3+ (HRKD) method for segmenting disease-affected areas, enabling more precise identification and isolation of infected regions. This segmentation step significantly boosts classification accuracy and reliability in agricultural environments. The novelty of this research lies in the integration of MADDCNN with CFO and HRKD, enabling severity classification, adaptive optimization, and precise segmentation under varying agricultural conditions. The MADDCNN model outperforms other methods in key metrics, achieving 98.34% accuracy, 97.85% precision, 97.91% recall, and 98.12% F1 score. Furthermore, it demonstrates computational efficiency, processing each image in just 1.5 s. Overall, the MADDCNN approach offers a sustainable, efficient solution for detecting fruit diseases, addressing the challenges of varying conditions and complex symptoms, and contributing to enhanced agricultural practices.},
  archive      = {J_ESWA},
  author       = {Junaid Farooq War and Farida Khursheed},
  doi          = {10.1016/j.eswa.2025.129838},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129838},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-fruit leaf disease detection and severity assessment using catch fish optimized deep learning model},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Toxicity in online platforms and AI systems: A survey of needs, challenges, mitigations, and future directions. <em>ESWA</em>, <em>299</em>, 129832. (<a href='https://doi.org/10.1016/j.eswa.2025.129832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of digital communication systems and the designs of online platforms have inadvertently facilitated the subconscious propagation of toxic behavior. Giving rise to reactive responses to toxic behavior. Toxicity in online content and Artificial Intelligence Systems has become a serious challenge to individual and collective well-being around the world. It is more detrimental to society than we realize. Toxicity, expressed in language, image, and video, can be interpreted in various ways depending on the context of usage. Therefore, a comprehensive taxonomy is crucial to detect and mitigate toxicity in online content, Artificial Intelligence systems, and/or Large Language Models in a proactive manner. A comprehensive understanding of toxicity is likely to facilitate the design of practical solutions for toxicity detection and mitigation. The classification in published literature has focused on only a limited number of aspects of this very complex issue, with a pattern of reactive strategies in response to toxicity. This survey attempts to generate a comprehensive taxonomy of toxicity from various perspectives. It presents a holistic approach to explain the toxicity by understanding the context and environment that society is facing in the Artificial Intelligence era. This survey summarizes the toxicity-related datasets and research on toxicity detection and mitigation for Large Language Models, social media platforms, and other online platforms, detailing their attributes in textual mode, focused on the English language. Finally, we suggest the research gaps in toxicity mitigation based on datasets, mitigation strategies, Large Language Models, adaptability, explainability, and evaluation.},
  archive      = {J_ESWA},
  author       = {Smita Khapre and Melkamu Abay Mersha and Hassan Shakil and Jonali Baruah and Jugal Kalita},
  doi          = {10.1016/j.eswa.2025.129832},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129832},
  shortjournal = {Expert Syst. Appl.},
  title        = {Toxicity in online platforms and AI systems: A survey of needs, challenges, mitigations, and future directions},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reasoning or not? a comprehensive evaluation of reasoning LLMs for dialogue summarization. <em>ESWA</em>, <em>299</em>, 129831. (<a href='https://doi.org/10.1016/j.eswa.2025.129831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid progress in reasoning Large Language Models, their efficacy in dialogue summarization remains a critical, underexplored area, as this task requires a delicate balance of abstraction, faithfulness, and conciseness. To address this gap, we present the first large-scale, systematic evaluation of leading reasoning LLMs against their direct non-reasoning counterparts. Our rigorous framework covers three core paradigms of generic, role-oriented, and query-oriented summarization, and is tested on four diverse benchmark datasets spanning multiple languages and contexts. Our multi-perspective evaluation consistently demonstrates that, rather than conferring an advantage, the explicit reasoning processes in current models often hinder summarization quality. We find that reasoning models systematically produce longer, less faithful summaries that exhibit higher novelty but lower source coverage, deviating significantly from human summarization styles. Moving beyond performance metrics, we provide a deep diagnostic of the root causes for these failures through a novel, human-annotated error analysis. We identify a critical trade-off where one class of models suffers from structural inefficiency, characterized by verbose and redundant reasoning, while another, though more concise, is prone to multifaceted errors involving logical and factual fallacies. These findings reveal a fundamental conflict between the verbose, step-by-step nature of current reasoning architectures and the high-level abstraction required for summarization, offering crucial insights for designing future models that can effectively bridge logical deduction with concise synthesis.},
  archive      = {J_ESWA},
  author       = {Keyan Jin and Yapeng Wang and Leonel Santos and Tao Fang and Xu Yang and Sio Kei Im and Hugo Gonçalo Oliveira},
  doi          = {10.1016/j.eswa.2025.129831},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129831},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reasoning or not? a comprehensive evaluation of reasoning LLMs for dialogue summarization},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multivariate integration of time series with ML for corn price forecasting in colombia. <em>ESWA</em>, <em>299</em>, 129822. (<a href='https://doi.org/10.1016/j.eswa.2025.129822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volatility of corn prices poses a significant challenge for both producers and policymakers. This study proposes a hybrid model that combines Extreme Gradient Boosting (XGBoost) and Light Gradient Boosting Machine (LightGBM), optimized through Particle Swarm Optimization with Cuckoo Search (PSO-CS), for accurate corn price forecasting. The approach integrates multivariate time series data, including local prices from the Atlántico market and international futures prices from the Chicago Board of Trade (CBOT). Empirical Mode Decomposition (EMD) is applied to enhance signal clarity and improve model performance. Model performance is assessed through sensitivity analysis and statistical comparison using the Diebold-Mariano (DM) test. The results demonstrate that the proposed ensemble outperforms both individual models and neural network combinations, achieving a Mean Absolute Percentage Error (MAPE) of 2.06},
  archive      = {J_ESWA},
  author       = {Adelaida Ojeda Beltran and Mario E. Suaza-Medina and F. Javier Zarazaga-Soria and Emiro De-La-Hoz-Franco and José Escorcia-Gutierrez},
  doi          = {10.1016/j.eswa.2025.129822},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129822},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multivariate integration of time series with ML for corn price forecasting in colombia},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Point cloud quality assessment using the perceptual clustering weighted graph (PCW-graph) and attention fusion network. <em>ESWA</em>, <em>299</em>, 129817. (<a href='https://doi.org/10.1016/j.eswa.2025.129817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for evaluating 3D content in real-world applications where reference models are unavailable. Existing NR-PCQA methods often fail to capture structural and perceptual relationships, leading to inconsistent quality predictions. To address this issue, we propose a Perceptual Clustering Weighted Graph (PCW-Graph) that models point cloud distortions through a structured learning process. Our approach follows three main steps: (1) Perceptual Feature Extraction - Color, curvature, and saliency features are computed to capture geometric and visual distortions. (2) Graph-Based Representation - Perceptual clusters form nodes, and weighted edges encode feature similarities, ensuring spatial and structural consistency. (3) Adaptive Quality Prediction - A Graph Attention Fusion Network (GAF) dynamically refines feature importance and estimates quality scores via regression to improve correlation with human perception. We evaluate the proposed method on three benchmark datasets: WPC, SJTU PCQA, and ICIP2020. It achieves high Pearson (PLCC ≥ 0.93 ) and Spearman (SRCC ≥ 0.91 ) correlation coefficients. These results show better alignment with human perceptual scores than alternative NR-PCQA methods. The approach also reduces Root Mean Square Error (RMSE) by up to 15 %. This confirms its effectiveness and robustness for blind point cloud quality assessment.},
  archive      = {J_ESWA},
  author       = {Abdelouahed Laazoufi and Mohammed El Hassouni and Hocine Cherifi},
  doi          = {10.1016/j.eswa.2025.129817},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129817},
  shortjournal = {Expert Syst. Appl.},
  title        = {Point cloud quality assessment using the perceptual clustering weighted graph (PCW-graph) and attention fusion network},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transfer learning-based sparse-reward meta-Q-learning algorithm for active SLAM. <em>ESWA</em>, <em>299</em>, 129799. (<a href='https://doi.org/10.1016/j.eswa.2025.129799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a widely researched topic, especially in complex unknown environments where dynamic changes and sensor drift introduce significant uncertainties. This paper proposes a transfer-learning-based prioritized experience replay meta-Q-learning algorithm. To solve the sparse reward problem caused by dynamic changes and sensor drift in complex unknown environments, a path planning algorithm based on sparse-reward meta-Q-learning is proposed. In the adaptive stage, the learned advantage function and transfer learning is introduced to improve the decision-making capability and generalisation of the algorithm, ensuring stable performance under uncertain conditions. To address the issues of low sample efficiency in the reinforcement learning experience replay buffer, sampling weights are designed, and bias estimation is used to maximise performance on new tasks in meta-learning. This approximated the policy to the optimal action decisions and further shortened the training time. Experimental results demonstrate that, compared to state-of-the-art meta-reinforcement learning algorithms, the proposed algorithm exhibits stronger robustness against uncertainties. It effectively avoids obstacles and successfully accomplishes localization and mapping tasks in dynamic and noisy environments, validating its reliability under uncertain conditions. We provide code at: https://github.com/XinLiu98/Transfer-Learning-based-sparse-reward-meta-Q-learning-Algorithm-for-Active-SLAM.git},
  archive      = {J_ESWA},
  author       = {Xin Liu and Shuhuan Wen and Zhengzheng Guo and Huaping Liu},
  doi          = {10.1016/j.eswa.2025.129799},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129799},
  shortjournal = {Expert Syst. Appl.},
  title        = {Transfer learning-based sparse-reward meta-Q-learning algorithm for active SLAM},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). End-to-end motion detection via multi-scale spatial-temporal feature fusion for dual-view 3D macaque behavior quantification. <em>ESWA</em>, <em>299</em>, 129765. (<a href='https://doi.org/10.1016/j.eswa.2025.129765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying 3D macaque behavior, particularly position and action, is crucial for neural mechanism research and drug safety evaluation. Existing methods face challenges in precisely and efficiently analyzing macaque behavior within the constrained and obstructed environments of typical cage housing. This paper introduces Multi-scale Spatial-Temporal Feature-fusion Network (MSTFN), an end-to-end model to detect macaque motion in complex environments through an efficient feature extraction and fusion mechanism. Specifically, a frame-wise spatial extractor and a spatial-temporal fusion unit are utilized in MSTFN. Frame-wise spatial extractor captures spatial features, including position and pose information, from individual frames within multi-frame input. Spatial-temporal fusion unit integrates these spatial features temporally, refining the representation over time and obtaining the motion information. Furthermore, a Dual-view Motion-aware Approach (DMA) that combines the MSTFN with a fast 3D fitting algorithm is proposed for efficient 3D macaque behavior quantification. To evaluate the performance, we collected long-term daytime data from multiple macaques in standard cage environments and constructed a dual-view macaque behavior dataset that comprises over 150,000 bounding boxes and 70,000 action labels. The results show that MSTFN achieved 99.5 % mean average precision in position detection and 97.2 % accuracy in actions classification with over 60 % fewer parameters than existing multi-network baselines in primate behavior quantification. Additionally, DMA successfully captures the behavioral pattern differences between two different age groups. These findings highlight the potential of the proposed method to quantify 3D macaque behavior in complex environments, providing a practical tool for life science research.},
  archive      = {J_ESWA},
  author       = {Zhiyuan Chen and Zongli Jiang and Qiang Guan and Xibo Ma},
  doi          = {10.1016/j.eswa.2025.129765},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129765},
  shortjournal = {Expert Syst. Appl.},
  title        = {End-to-end motion detection via multi-scale spatial-temporal feature fusion for dual-view 3D macaque behavior quantification},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SG-DTAM: Joint staged generation and dynamic time alignment for missing and unaligned modalities in sentiment analysis. <em>ESWA</em>, <em>299</em>, 129750. (<a href='https://doi.org/10.1016/j.eswa.2025.129750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) aims to infer users’ emotional states by integrating information from multiple modalities, such as language, audio, and visual data. However, real-world multimodal data often presents two critical challenges: missing modalities and unaligned multimodal sequences. Missing sources can lead to information loss, while temporal misalignment introduces inconsistencies-both of which significantly degrade analytical accuracy. While a plethora of existing approaches effectively address each challenge in isolation, few can tackle both simultaneously without resorting to complex architectures or incurring substantial computational costs. To overcome these limitations, we propose SG-DTAM, a novel framework that combines staged generation with multi-head dynamic temporal alignment. In the first stage, conditional mutual information is employed to guide a hierarchical series of cross modal attention modules that sequentially reconstruct each missing modality. In the following alignment stage, a set of attention heads with adaptive weighting reconciles temporal discrepancies across all modalities without any reliance on external synchronization labels. Throughout the process, we innovatively introduce a dual supervision objective that combines an InfoNCE based contrastive loss and a reconstruction loss ensures both precise modality synthesis and the development of resilient feature representations. We evaluate SG-DTAM on four benchmark MSA datasets-CMU-MOSI, CMU-MOSEI, IEMOCAP, and MELD. Experimental results demonstrate that our framework achieves competitive or state-of-the-art performance with relatively few learnable parameters. Notably, SG-DTAM exhibits robust performance in scenarios involving both missing and misaligned modalities, underscoring its effectiveness in real-world multimodal sentiment analysis tasks.},
  archive      = {J_ESWA},
  author       = {Deling Huang and Ran Gao and Geng Zhang and Jian Yu},
  doi          = {10.1016/j.eswa.2025.129750},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129750},
  shortjournal = {Expert Syst. Appl.},
  title        = {SG-DTAM: Joint staged generation and dynamic time alignment for missing and unaligned modalities in sentiment analysis},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). STKG-TP: Depression recognition via spatial-temporal knowledge graph and trajectory-semantic cross-fusion with EEG signals. <em>ESWA</em>, <em>299</em>, 129744. (<a href='https://doi.org/10.1016/j.eswa.2025.129744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG signals carry important neurocognitive information for depression recognition. However, existing EEG-based depression recognition research faces challenges in addressing semantic interpretability and improving model robustness. Consequently, in this paper, to overcome these challenges, we propose STKG-TP, a novel depression recognition model that integrates Spatiotemporal Knowledge Graphs (STKG) with trajectory-semantic cross-fusion. Specifically, we design an STKG module to learn brain region activation patterns associated with different depressive states and construct a spatiotemporal knowledge graph to enhance the model’s generalization and robustness. In addition, we introduce a Trajectory Prompting module that transforms EEG signal trajectories into a structured semantic library, enabling neurocognitive interpretability at the semantic level. Extensive experimental evaluations on three publicly available EEG datasets demonstrate the superior performance of STKG-TP in addressing these challenges. Compared with existing state-of-the-art depression recognition models, STKG-TP improves Accuracy by 1.13 %, 0.61 %, and 1.29 %, and Kappa score by 3.14 %, 1.88 %, and 2.75 %, respectively. The STKG-TP code is publicly available at: https://github.com/xuxuanya-love/STKG-TP .},
  archive      = {J_ESWA},
  author       = {Chen Huang and Huijie Liu and Jiannong Cao and Yan Zhang and Chao Yang and Jianhua Song and Zhifei Li and Xiaoyong Yan},
  doi          = {10.1016/j.eswa.2025.129744},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129744},
  shortjournal = {Expert Syst. Appl.},
  title        = {STKG-TP: Depression recognition via spatial-temporal knowledge graph and trajectory-semantic cross-fusion with EEG signals},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BNFW: Boundary and noise detection clustering for data with fuzzy boundaries and weak connectivity. <em>ESWA</em>, <em>299</em>, 129714. (<a href='https://doi.org/10.1016/j.eswa.2025.129714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a widely used data analysis technique to identify data elements as the same pattern based on the similarity of their features. Nowadays, many advanced algorithms based on densities and graphs have been proposed. However, heterogeneous densities, boundary ambiguities, and noise in the data seriously affect their effectiveness. To overcome these problems, this study proposes a novel boundary and noise detection clustering method using local distribution difference (BNFW). It identifies noise, boundary, and core data based on data distribution differences. Clustering by a small number of core data with clear boundaries, prevents cross-cluster connections, separates weakly connected clusters, and improves clustering efficiency. We demonstrate the effectiveness of BNFW through experiments on challenging synthetic datasets to detect clusters with different complex structures, detecting clusters from real UCI database datasets, and identifying cell types from single-cell RNA sequencing (scRNA-seq) with various data types. Ultimately, BNFW achieved excellent results on both ACC and Purity indicators to prove its superiority.},
  archive      = {J_ESWA},
  author       = {Tianshuo Li and Rui Pu and Fei Wang and Zhijiang Chen and Dongming Tang and Lijun Yang},
  doi          = {10.1016/j.eswa.2025.129714},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129714},
  shortjournal = {Expert Syst. Appl.},
  title        = {BNFW: Boundary and noise detection clustering for data with fuzzy boundaries and weak connectivity},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Era splitting - Invariant learning for decision trees. <em>ESWA</em>, <em>299</em>, 129687. (<a href='https://doi.org/10.1016/j.eswa.2025.129687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-life machine learning problems exhibit distributional shifts in the data from one time to another or from one place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental , or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, namely, gradient boosting decision trees (GBDT). The new splitting criteria use era-wise information associated with the data to grow tree-based models that are optimal across all disjoint eras in the data, instead of optimal over the entire data set pooled together, which is the default setting. In this paper, two new splitting criteria are defined and analyzed theoretically. Effectiveness is tested on four experiments, ranging from simple, synthetic to complex, real-world applications. In particular we cast the OOD domain-adaptation problem in the context of financial markets, where the new models out-perform state-of-the-art GBDT models on the Numerai data set. The new criteria are incorporated into the Scikit-Learn code base and made freely available online.},
  archive      = {J_ESWA},
  author       = {Timothy Delise},
  doi          = {10.1016/j.eswa.2025.129687},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129687},
  shortjournal = {Expert Syst. Appl.},
  title        = {Era splitting - Invariant learning for decision trees},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language network for stored-grain pest counting. <em>ESWA</em>, <em>299</em>, 129482. (<a href='https://doi.org/10.1016/j.eswa.2025.129482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infestations of stored-grain pest are estimated to cause approximately 3 % of global grain losses. Accurately estimating the number of these pests is crucial for ensuring the safety of grain storage and enabling effective management. However, most existing methods are limited to a single visual modality and rely heavily on manual annotations, making it difficult to achieve accurate counting in dense scenes. To explore the potential of multi-modal information in stored-grain pest analysis, this study introduces a multi-modal learning paradigm into this domain and proposes a multi-modal network for stored-grain pest counting. Our approach firstly leverages task-specific prompts and a modified image encoder to enhance counting performance. Then, a mean-interval counting strategy is applied to retain the discreteness of the counting values. Finally, a novel Location- Aware Cross-Entropy (LACE) loss function to achieve more accurate pest density estimation. We evaluate our experiments based on Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Experimental results on our various pests dataset demonstrate that our method achieves the optimal performance, with the mean absolute error (MAE) and root mean square error (RMSE) as low as 1.88 and 3.34, respectively. Compared with the state of the art counting methods, these two values are reduced by 1.12 and 1.23 points, respectively.},
  archive      = {J_ESWA},
  author       = {Jiahui Sun and Rui Li and Chengjun Xie and Peng Chen and Jie Zhang and Jianming Du and Hongbo Chen and Runsheng Qi and Long Chen},
  doi          = {10.1016/j.eswa.2025.129482},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129482},
  shortjournal = {Expert Syst. Appl.},
  title        = {A vision-language network for stored-grain pest counting},
  volume       = {299},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid deep learning rainfall-runoff forecasting model incorporating spatiotemporal information from multi-source data. <em>ESWA</em>, <em>298</em>, 129974. (<a href='https://doi.org/10.1016/j.eswa.2025.129974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely applied in runoff forecasting, focusing primarily on temporal features but neglecting the influence of spatial heterogeneity. Capturing complex spatiotemporal atmosphere–land–hydrology interactions by deep learning remains challenging in rainfall–runoff forecasting. This study proposes a hybrid deep learning framework, Runoff Forecasting Model Integrating Spatiotemporal Features (RFMISF), which leverages the complementary strengths of multiple deep learning architectures to construct five modules, thereby fusing multi-source data. Specifically, the framework integrates the Convolutional Neural Networks for extracting spatial features of underlying surface, the LSTM for capturing temporal dependencies in rainfall and runoff, and the Convolutional LSTM (ConvLSTM) for learning spatiotemporal features of meteorological inputs. Two case studies of daily runoff forecasting have been deviced for the BHT and SBY hydrological stations with distinct hydrological regimes. At the BHT, the RFMISF reduced RMSE by 31.53% and MAE by 33.39% compared to the Xinanjiang baseline; at the SBY, the RFMISF improved NSE by 13.6% and decreased MAE by 27.39%. Ablation experiments of excluding station rainfall, underlying surface, and meteorological data are further conducted to underline the importance of multi-source data. At the BHT, the experiments led to RMSE increases of 9.29%, 4.69%, and 5.59% during flood season, respectively. At the SBY, the experiments resulted in reductions of NSE by 15.08%, 4.46%, and 12.94%. Additionally, model performance varies with rainfall intensity, indicating the differentiated contributions of multi-source data in complex runoff responses. Although reanalysis data enhance spatial representativeness, their systematic errors require careful treatment. Overall, this study introduces a novel, robust framework for enhancing runoff prediction and improving water resource management in hydrologically complex environments.},
  archive      = {J_ESWA},
  author       = {Wan Liu and Li Mo and Xiaodong Li and Wenjing Xiao and Haodong Huang and Yongchuan Zhang},
  doi          = {10.1016/j.eswa.2025.129974},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129974},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid deep learning rainfall-runoff forecasting model incorporating spatiotemporal information from multi-source data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An offline-online collaborative optimization framework for the energy-efficient distributed hybrid flow shop scheduling problem with blocking constraints in electric anode carbon rod manufacturing system. <em>ESWA</em>, <em>298</em>, 129955. (<a href='https://doi.org/10.1016/j.eswa.2025.129955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scheduling problem in the assembly workshop of carbon anodes for aluminum production is investigated within the distributed green manufacturing context. This scheduling problem is modeled as an Energy-Efficient Distributed Hybrid Flow Shop Scheduling Problem with Blocking Constraints (EEDHFSP-BC), with optimization objectives that include the minimization of both the makespan and the total energy consumption. To address this complex multi-objective optimization problem, an offline-online collaborative optimization framework (QLINSGA-II) integrating Q-Learning and an improved non-dominated sorting genetic algorithm (INSGA-II) is proposed. A two-phase offline-online scheduling strategy is adopted. First, a dedicated encoding scheme is designed according to the problem characteristics, and a hybrid initialization strategy is introduced during the offline learning phase. Meanwhile, three crossover and mutation operators integrating task assignment coordination and processing sequence allocation are developed to enhance global search capability. Second, a high-quality Pareto solution set is generated by INSGA-II, and Q-Learning is employed to learn from this solution set in the offline phase, thereby achieving intelligent guidance of the population evolution direction. Finally, trained agents are utilized in the online phase to dynamically adjust scheduling for newly arriving jobs. After the search process, a state evaluation mechanism is incorporated to dynamically guide the search by assessing the proportion of non-dominated solutions in the population, effectively improving the distribution and convergence of the Pareto solution set. Experimental results demonstrate that QLINSGA-II outperforms existing mainstream multi-objective optimization algorithms in terms of diversity, convergence speed, and solution coverage rate, providing an efficient and reliable solution for green workshop scheduling in the aluminum industry.},
  archive      = {J_ESWA},
  author       = {Fuqing Zhao and Shangpeng Wang and Weiyuan Wang and Tianpeng Xu and NingNing Zhu},
  doi          = {10.1016/j.eswa.2025.129955},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129955},
  shortjournal = {Expert Syst. Appl.},
  title        = {An offline-online collaborative optimization framework for the energy-efficient distributed hybrid flow shop scheduling problem with blocking constraints in electric anode carbon rod manufacturing system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GRAG-ProSafe QAS: Graph retrieval-augmented generation for process production safety intelligent question and answer system. <em>ESWA</em>, <em>298</em>, 129947. (<a href='https://doi.org/10.1016/j.eswa.2025.129947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the frequent occurrence of safety accidents in process industries and the inadequacy of traditional safety management approaches in coping with complex risk scenarios, this study proposed an intelligent question answering system based on graph retrieval-augmented generation, named GRAG-ProSafe QAS. The system adopted a four-stage framework to extract structured knowledge from accident reports using Large Language Models and constructed a dynamic knowledge graph. This graph is utilized to support multi-hop retrieval and chain-of-thought reasoning strategies, thereby enhancing the trustworthiness of the generated responses. Taking 198 accident reports from the iron and steel industry as the dataset, the experiments demonstrated that the model achieved efficient structured knowledge extraction, and the constructed knowledge graph covers 1637 nodes with 2285 edges, which can provide semantic support for multi-hop causal reasoning. Ablation experiments validated the effectiveness of each core module in the system such as structured graph retrieval. In the multi-turn question answering scenario focused on explosion accidents, the system achieved strong overall performance, with a Faithfulness Score of 0.8684, Answer Relevancy of 0.8241, and Factual Correctness of 0.8050. The developed GRAG-ProSafe QAS realized the integration of knowledge extraction, graph construction and intelligent QA, which provides a feasible path for the intelligent management and control of safety risks in the process industry.},
  archive      = {J_ESWA},
  author       = {Jianrong Zhang and Wei Zhang and Qingwen Wei and Huayu Zhong and Yu Miao},
  doi          = {10.1016/j.eswa.2025.129947},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129947},
  shortjournal = {Expert Syst. Appl.},
  title        = {GRAG-ProSafe QAS: Graph retrieval-augmented generation for process production safety intelligent question and answer system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unseen class feature regeneration adversarial learning method for time-varying cross-domain fault diagnosis. <em>ESWA</em>, <em>298</em>, 129938. (<a href='https://doi.org/10.1016/j.eswa.2025.129938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying working conditions are common in industrial applications, the fault diagnosis under time-varying working conditions is of great significance. However, collecting enough fault data of all categories in engineering scenarios is impossible; unseen category fault recognition would cause severe performance decreases, the fault misjudgment could result in serious accidents. Therefore, a towards unseen class feature regeneration adversarial learning (UCFR) method is proposed for time-varying cross-domain fault diagnosis, which can effectively transfer knowledge from the seen faults of the source domain to the unseen faults of the target domain. Specifically, the fault attribute description is developed based on the sparse coding to describe the fault visually. The fault attribute and fault feature are leveraged into the designed feature regeneration module to generate and refine the fault feature of the unseen class faults. Moreover, an adaptive margin center loss and a fault attribute consistency loss are used to train the feature regeneration module to mine the category and attribute-related representation. Finally, the discriminative features are further refined by the feature transformation module to improve the diagnosis performance of unseen faults. Extensive experiments illustrate the significant performance of the proposed framework; the fault diagnosis accuracy of the unseen class is improved by at least 10 %.},
  archive      = {J_ESWA},
  author       = {Li Wang and Yiping Gao and Liang Gao and Xinyu Li},
  doi          = {10.1016/j.eswa.2025.129938},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129938},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unseen class feature regeneration adversarial learning method for time-varying cross-domain fault diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Relevance-based adaptive differential private spiking neural networks. <em>ESWA</em>, <em>298</em>, 129934. (<a href='https://doi.org/10.1016/j.eswa.2025.129934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) have achieved widespread attention recently due to biological plausibility and ultra-low energy consumption. However, the training process of SNNs can potentially cause data privacy leaks. Attackers can use models to infer sensitive features of data, therefore, protecting sensitive information in training data is crucial. Differential Privacy (DP) is an effective method for protecting data privacy from attacks. The existing differential private SNN models are not satisfactory due to adding the same amount of noise to gradient parameters, which affects the trade-off between model utility and privacy protection. To address these issues, a Relevance-based Adaptive Differential Private SNN (RADP-SNN) framework is proposed, which dynamically perturbs gradients based on the relevance between input features and model outputs. It adjusts the Gaussian noise added to the gradients according to each neuron’s relevance to the model outputs. Additionally, based on the interpretability of the Layer-wise Relevance Propagation (LRP) algorithm, an SNNLRP algorithm is designed, which uses surrogate gradients to approximate the backpropagation of spiking neurons. It integrates the spikes and membrane potential information across time steps in SNNs. Then, the impact of Leaky-Integrated and Fire and Integrated and Fire neuron models on privacy protection is explored. Results show that the proposed framework can maintain high model performance while providing effective privacy assurance. RADP-SNN has broad potential applications in image, robot control, and scenarios requiring time series data processing.},
  archive      = {J_ESWA},
  author       = {Junxiu Liu and Xiwen Luo and Qiang Fu and Yuling Luo and Sheng Qin and Xue Ouyang},
  doi          = {10.1016/j.eswa.2025.129934},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129934},
  shortjournal = {Expert Syst. Appl.},
  title        = {Relevance-based adaptive differential private spiking neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EDPDet: Efficient dense pedestrian detectors with multi-scale feature extraction, enhancement and aggregation. <em>ESWA</em>, <em>298</em>, 129933. (<a href='https://doi.org/10.1016/j.eswa.2025.129933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is one of the key tasks in the field of computer vision. However, in dense scenes, pedestrians may be confused with the background or obstructed to varying degrees, and factors such as shooting distance can affect the scale of pedestrians in images, increasing the difficulty of pedestrian detection tasks. To address these issues, we propose the efficient dense person detectors called EDPDet. On the one hand, we propose the Multi-scale Contour Feature Enhancement Module (MCFEM) with multi-scale feature extraction and contour feature enhancement, which can improve the network’s ability to perceive pedestrian objects at different scales and distinguish pedestrians from complex backgrounds. On the other hand, we propose the Efficient Cross-scale Path Aggregation Network (ECPAN) that realizes the integration of semantic information and spatial information among different feature layers of the network. Furthermore, we implemented the end-to-end deployment of the detectors using the non-maximum suppression-free (NMS-free) training strategy. Finally, we construct three detectors of different sizes, EDPDet-N, EDPDet-S and EDPDet-L. Our method achieves 91.4% and 92.5% AP on the CrowdHuman and WiderPerson datasets, respectively, demonstrating superior performance.},
  archive      = {J_ESWA},
  author       = {Yangxi Yu and Wentao Lyu and Qing Guo and Zhijiang Deng and Weiqiang Xu},
  doi          = {10.1016/j.eswa.2025.129933},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129933},
  shortjournal = {Expert Syst. Appl.},
  title        = {EDPDet: Efficient dense pedestrian detectors with multi-scale feature extraction, enhancement and aggregation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SketchFormer3D: Generating 3D shapes from sketches with implicit SDF priors via diffusion models. <em>ESWA</em>, <em>298</em>, 129931. (<a href='https://doi.org/10.1016/j.eswa.2025.129931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an intuitive and highly efficient means of conveying information, sketches are widely used in three-dimensional design and modeling tasks. However, due to the highly abstract and visually sparse nature of sketches, directly reconstructing structurally clear and topologically sound 3D models from single-view sketches remains a significant challenge. Existing approaches often overlook the cross-modal semantic associations between sketches and 3D geometry and fail to effectively utilize prior knowledge of three-dimensional spatial geometry, resulting in deficiencies in the structural coherence and topological validity of the generated 3D models. To address these issues, we propose a 3D reconstruction method based on a Signed Distance Function (SDF) diffusion model, aiming to enhance the stability and accuracy of model generation through implicit geometric priors and cross-modal semantic information. Specifically, we first employ an SDF-based implicit neural network to construct high-quality geometric representations and capture spatial priors of target shapes; this component is then incorporated as a fixed module into the diffusion process, guiding the network to gradually recover accurate 3D structures from noise under sketch conditions. Meanwhile, we design a sketch-aware semantic encoding module and a cross-modal attention mechanism to deeply integrate sketch images with geometric priors, thereby strengthening the model’s ability to represent structural consistency and local details. Experimental results demonstrate that our method outperforms existing approaches across multiple sketch-based modeling datasets. In terms of quantitative metrics, compared to the latest method Doodle Your 3D, our Chamfer Distance (CD) decreases from 9.41 × 10 − 3 to 6.53 × 10 − 3 , the Earth Mover’s Distance (EMD) decreases from 10.68 × 10 − 2 to 7.59 × 10 − 2 , and the Voxel-IoU increases from 46.19 × 10 − 2 to 48.72 × 10 − 2 . These improvements further validate that our approach is capable of stably generating 3D mesh models that are both structurally coherent and geometrically precise.},
  archive      = {J_ESWA},
  author       = {Yang Ding and Huamin Yang and Cheng Han and Chao Zhang and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129931},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129931},
  shortjournal = {Expert Syst. Appl.},
  title        = {SketchFormer3D: Generating 3D shapes from sketches with implicit SDF priors via diffusion models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network. <em>ESWA</em>, <em>298</em>, 129928. (<a href='https://doi.org/10.1016/j.eswa.2025.129928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust developed by workers towards robotic systems is critical to the successful implementation of human-robot collaboration (HRC) in construction, directly influencing operational efficiency and safety outcomes. To accurately evaluate trust risks within HRC scenarios, this study proposes an integrated method combining an improved Cloud Model (CM) with Bayesian Networks (BNs) for dynamic trust risk analysis. Initially, key factors influencing trust risks in HRC were identified through literature review and expert elicitation. The improved CM was then employed to capture inherent uncertainties and fuzziness in trust state definitions, facilitating the discretization of continuous expert evaluations into appropriate risk states. Subsequently, the BN was developed to perform forward reasoning, sensitivity analysis, and backward diagnosis, enabling proactive trust risk prediction, critical factor identification, and targeted interventions. The primary contributions of this research include: (a) identifying 11 trust factors from human, organizational, and robotic perspectives, offering a comprehensive basis for analyzing HRC trust risk in construction; (b) employing an optimized cloud entropy approach to accurately capture fuzziness and randomness in expert evaluations, thereby producing robust prior probabilities; and (c) developing a hybrid CBN framework to assess HRC trust risk in construction, demonstrating superior performance in risk perception, analysis, and control. Overall, this study provides valuable insights into safer and more effective HRC through dynamic evaluation of trust risk.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Mingyu Zhang and Heng Li and Yinong Hu and Jie Ma and Waleed Umer and Xin Fang},
  doi          = {10.1016/j.eswa.2025.129928},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129928},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated emotional design generation for NEV wheel hubs: Integrating StyleGAN2-ADA and WOA-SVR within kansei engineering. <em>ESWA</em>, <em>298</em>, 129927. (<a href='https://doi.org/10.1016/j.eswa.2025.129927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheel hub design is significant in the New Energy Vehicle’s (NEV) aesthetics and user emotional connection. However, the existing design process faces two main challenges: traditional concept methods suffer from efficiency bottlenecks, and designers’ subjective judgments make it difficult to capture users’ emotional preferences. Recently, Generative Adversarial Networks (GANs) have been introduced to industrial design. However, conventional GAN-based methods typically require large-scale datasets to achieve high-quality design generation, which limits their applicability in vertical product domains where data are scarce. To overcome these challenges, this paper proposes an emotional design generation approach for NEV wheel hubs by combining StyleGAN2 with Adaptive Discriminator Augmentation (StyleGAN2-ADA) and Whale Optimisation Algorithm-Support Vector Regression (WOA-SVR). First, the StyleGAN2-ADA is trained on a limited NEV wheel hub dataset to achieve automated design generation. Second, Ward hierarchical clustering dentifies representative samples, while morphological analysis deconstructs design features. Subsequently, Factor Analysis (FA) categorises Kansei words to extract principal emotions. After collecting users’ emotional ratings of wheel hubs, WOA-SVR constructs a “design features-emotional needs” mapping model. Finally, the generated images are used to validate the implementation of the generation and prediction models. The case study demonstrates that the proposed method not only generates diverse design alternatives aligned with users’ emotional preferences but also provides reliable predictions of their emotional responses, thereby systematically improving the NEV wheel hub design process while preserving its emotional impact.},
  archive      = {J_ESWA},
  author       = {Yi Wang and Meiyu Zhou and Zhengyu Wang and Weilin Cai and Xin Sun and Huijuan Zhu},
  doi          = {10.1016/j.eswa.2025.129927},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129927},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated emotional design generation for NEV wheel hubs: Integrating StyleGAN2-ADA and WOA-SVR within kansei engineering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffAD: Diffusion augmentation for influenza virus antigenic distance prediction. <em>ESWA</em>, <em>298</em>, 129925. (<a href='https://doi.org/10.1016/j.eswa.2025.129925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous monitoring of the antigenic phenotypes of circulating influenza viruses is essential for both vaccine evaluation and development. However, traditional serology-based methods for antigenicity assessment, such as hemagglutination inhibition assays, are inherently low-throughput and labor-intensive. As a result, the available antigenicity data remain sparse and limited, posing a significant challenge to the development of accurate and scalable computational models. To address this, we have curated a influenza antigenicity dataset from authoritative sources and propose DiffAD, a novel diffusion-based data augmentation framework for antigenic distance prediction to enhance data availability and model performance. DiffAD introduces a forward noising process and a timestep-aware reverse denoising network incorporating pre-normalized residual blocks to enable precise noise estimation across diffusion steps. This design facilitates the generation of biologically plausible HA feature vectors that introduce meaningful variability and augment existing datasets. These augmented data are then used to enhance the accuracy of antigenic distance estimation between viral strains. Experimental results on four influenza subtypes (H1N1, H3N2, B/Victoria, and B/Yamagata), using two widely adopted antigenic distance metrics. Experimental results show that DiffAD significantly outperforms existing methods, reducing the MAE to 0.6402 and 0.6795, and increasing the R 2 to 0.7412 and 0.6969 on the H1N1 and H3N2 datasets, respectively, using the SLT-based distance metric. Furthermore, visualization analysis reveals that the low-dimensional embeddings of virus strains exhibit clear clustering patterns, and the synthetic strains generated by DiffAD closely align with original antigenic clusters. These findings demonstrate that DiffAD not only improves prediction performance but also learns biologically meaningful characteristics of viral strains.},
  archive      = {J_ESWA},
  author       = {Qingbo Liu and Yuanling Xia and Yanbu Guo and Weihua Li},
  doi          = {10.1016/j.eswa.2025.129925},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129925},
  shortjournal = {Expert Syst. Appl.},
  title        = {DiffAD: Diffusion augmentation for influenza virus antigenic distance prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning to select cutting planes in mixed integer linear programming solving. <em>ESWA</em>, <em>298</em>, 129924. (<a href='https://doi.org/10.1016/j.eswa.2025.129924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes (cuts) are crucial for solving Mixed Integer Linear Programming (MILP) problems. Advanced MILP solvers typically rely on manually designed heuristic algorithms for cut selection, which require extensive expert knowledge and cannot be generalized to MILP problems with varying instance sizes across different domains. Therefore, learning-based methods for cut selection are considered a promising direction. State-of-the-art learning-based methods formulate cut selection as a sequence-to-sequence problem, easily handled by sequence models. However, the existing sequence models need help with the following issues: (1) the model only captures cut information while neglecting the Linear Programming (LP) relaxation; (2) the sequence model utilizes positional information of the input sequence, which may influence cut selection. To address these challenges, we design a novel model HGTSM for better cut selection. We encode MILP problem state as a heterogeneous tripartite graph, utilizing heterogeneous graph networks to fully capture the underlying structure of MILP problems. Simultaneously, we propose a novel sequence model whose architecture is tailored to handle inputs in different orders. Experimental results demonstrate that our model outperforms heuristic methods and learning-based baselines on multiple challenging MILP datasets. The code of HGTSM can be found at https://github.com/aqi007/Learn2Cut-HGTSM.},
  archive      = {J_ESWA},
  author       = {Xuefeng Zhang and Liangyu Chen and Zhengfeng Yang and Zhenbing Zeng},
  doi          = {10.1016/j.eswa.2025.129924},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129924},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning to select cutting planes in mixed integer linear programming solving},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view. <em>ESWA</em>, <em>298</em>, 129922. (<a href='https://doi.org/10.1016/j.eswa.2025.129922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent quality problems with medical devices and the associated recall present potential health risks to users, bringing extra costs and disturbances to the supply chain. Classical medical device recall strategy neglects the significance of the failure detection process in the premarket phase, increasing the medical device recall risks. This research first established the theoretical foundation for the medical device recall reasons detection problem by reconstructing the medical device recall strategy from the supply chain risk and resilience view and reinforced the importance of failure detection and quality inspection work in the premarket stage. Moreover, existing medical device failure reason prediction research was limited in practicality and scalability. To address this problem, we developed a machine learning-based medical device recall initiator prediction system framework to conduct proactive failure detection based on the industrial case. By redesigning in dataset, clustering method and input feature selection, an accuracy rate of 88.85% is achieved, which indicates the potential of the proposed framework in assisting manufacturers with asset predictive failure detection for reducing recall. A comparative analysis of prediction performance between our framework and the most similar research that utilized the same prediction algorithms was presented. The comparison results showed that our distinctive design in the dataset, clustering method, and key input features chosen are valid and efficient. Before redesigning the prediction algorithms that require higher technical investment, our elaborate research design in selecting the dataset, cluster method, and key input features can be the antecedents of better prediction performance for manufacturers. The proposed predictive framework obtains higher accuracy, scalability, practicality, with accessibility.},
  archive      = {J_ESWA},
  author       = {Yang Hu and Davy Monticolo and Pezhman Ghadimi},
  doi          = {10.1016/j.eswa.2025.129922},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129922},
  shortjournal = {Expert Syst. Appl.},
  title        = {A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predicting last-mile delivery route deviations using machine learning. <em>ESWA</em>, <em>298</em>, 129921. (<a href='https://doi.org/10.1016/j.eswa.2025.129921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Route planning in last-mile delivery is a complex task with many challenges, directly impacting delivery efficiency and costs. Drivers often deviate from optimized planned routes based on their knowledge. Using the properties of machine learning, this study aims to determine whether machine learning techniques can effectively predict deviations by drivers from planned routes and quantify the extent of such deviations. We propose to predict route deviations by analyzing a logistics company’s historical data of planned and actual routes using deep neural networks, with the dataset made publicly available. Our methodology incorporates both regression and classification models. The regression model estimates the degree of deviation, while the classification model aims to predict whether the deviation from a planned route will exceed a given threshold, based on different deviation metrics. As the input, we leverage the sequential structure of the route with route properties and drivers information. The computational experiments explore extending the given input to the models and testing various state-of-art neural network architectures. Our results demonstrate strong performance on both tasks, with our models achieving 9 − 19 % improvements in regression metrics and 3 − 15 % improvements in classification metrics compared to specified benchmarks, with statistical tests confirming the significance of these improvements.},
  archive      = {J_ESWA},
  author       = {Anna Konovalenko and Lars Magnus Hvattum and Kim Aleksander Hammer Iversen},
  doi          = {10.1016/j.eswa.2025.129921},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129921},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predicting last-mile delivery route deviations using machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PDHG: An ethereum phishing detection approach via heterogeneous graph transformer. <em>ESWA</em>, <em>298</em>, 129919. (<a href='https://doi.org/10.1016/j.eswa.2025.129919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing scams have emerged as a significant threat within the Ethereum ecosystem. Cutting-edge Ethereum phishing scams detection techniques mostly treat accounts in Ethereum as homogeneous nodes in transaction graphs. Existing detection approaches model Ethereum transaction records as homogeneous transaction graphs and use graph representation learning for account classification. However, those approaches often overlook the heterogeneity between accounts and transactions, making it difficult to capture the diversity of interactions and features among accounts. In this paper, a heterogeneous graph transformer (HGT)-based phishing account identification approach called PDHG is proposed. Specifically, PDHG models the transaction network between accounts as a heterogeneous graph based on different attributes of Ethereum accounts, allowing for a more comprehensive description of the structure and behavioral patterns of the transaction network. To enhance the explainability, PDHG leverages PDHGexplainer as the explainer for the detection results. We compare PDHG with other existing detection models. The experimental results demonstrate that PDHG achieves an AUC score of 96.04 % and a recall score of 89.87 %, surpassing the state-of-the-art approaches.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Yihan Mi and Yanan Zhang and Jialin Zhang},
  doi          = {10.1016/j.eswa.2025.129919},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129919},
  shortjournal = {Expert Syst. Appl.},
  title        = {PDHG: An ethereum phishing detection approach via heterogeneous graph transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-graph fusion guided robust adaptive learning for subspace clustering. <em>ESWA</em>, <em>298</em>, 129918. (<a href='https://doi.org/10.1016/j.eswa.2025.129918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering is an advanced technique that identifies clusters embedded within a union of low-dimensional subspaces of the original data space, thereby revealing its intrinsic structure. Spectral clustering-based methods have gained significant attention in computer vision, image processing and pattern recognition due to their promising performance. However, existing approaches, which typically rely on self-representation for representation coefficient learning, often lack robustness and struggle to comprehensively characterize complex data structures. Traditional reconstruction loss based on the Frobenius or ℓ 1 norm are susceptible to noise and outliers. Furthermore, many methods underutilize inherent data characteristics for capturing local geometric structures and adapting to intricate data relationships. To address these limitations, this paper proposes a novel subspace clustering approach, named Multi-graph Fusion Guided Robust Adaptive Learning (MFGRAL), which integrates robust adaptive representation and multi-graph fusion within a unified framework. Specifically, a non-convex logarithmic loss function is adopted to enhance robustness against noise and outliers. To better preserve local manifold structures, a multi-graph fusion strategy is developed to guide the adaptive graph learning process. This facilitates the learning of more discriminative low-dimensional embeddings and enhances the capacity to capture complex neighborhood relationships. An effective and efficient optimization algorithm based on Alternating Direction Method of Multipliers (ADMM) is developed to solve the proposed model. Extensive experimental results on several benchmark datasets demonstrate the effectiveness of the proposed MFGRAL and its superiority over state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Jianyu Miao and Xiaochan Zhang and Chao Fan and Tiejun Yang and Yingjie Tian and Yong Shi and Mingliang Xu},
  doi          = {10.1016/j.eswa.2025.129918},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129918},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-graph fusion guided robust adaptive learning for subspace clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing storage efficiency for cloud-based vehicle data based on advanced lossless compression algorithm. <em>ESWA</em>, <em>298</em>, 129917. (<a href='https://doi.org/10.1016/j.eswa.2025.129917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based vehicle data is being produced in various forms at an unparalleled speed, which requires efficient compression mechanisms to better store, transmit and process such data. In this article, we devise a novel, hybrid, adaptation-enabled framework, RTLAE, built on a neural network (NN) predictor and an adaptive arithmetic coding (AC) encoder, which enables outstanding lossless compression performance on non-stationary (unanticipated contextual changes) or randomly mixed vehicle datasets without requiring any domain-specific prior knowledge (lacking optimal hyperparameter settings). This framework integrates a tailor-made redundancy reduction filter, a temporal convolutional network, a long short-term memory network, and a multi-order adaptive arithmetic encoder to preprocess data sequences, generate accurate estimations, and learn optimal character encoding. Validation results on real-life datasets indicate that the proposed framework has achieved quite superior results on various datasets, with an average performance improvement of about 26%, 46%, 27%, and 12% over AC, Gzip, block-sorting compression algorithm, and DeepZip, respectively, and with a runtime cost that is slightly better than other NN-based compressors. This work emphasizes the potential of NNs and combinatorial modeling to improve general-purpose compressors, and highlights the research prospect of resource utilization of big data platforms based on vehicle-cloud collaborative interconnection.},
  archive      = {J_ESWA},
  author       = {Zheng Yifan and Cao Rui and Liu Chaohui and Liu Qixing and Luo Zixuan and Yang Dong and Zhang Kun and Zhou Sida and Yang Shichun},
  doi          = {10.1016/j.eswa.2025.129917},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129917},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing storage efficiency for cloud-based vehicle data based on advanced lossless compression algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex forecasting and investment strategy optimization via chain-of-thought of large language models. <em>ESWA</em>, <em>298</em>, 129913. (<a href='https://doi.org/10.1016/j.eswa.2025.129913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper pioneers the application of chain-of-thought (CoT) prompting in large language models (LLMs) for financial forecasting and portfolio optimization. Leveraging anonymized financial statements from 608 Chinese A-share listed companies (2010–2023), we benchmark ChatGPT 4.0 against human analysts in earnings direction prediction. The CoT-enhanced model achieved superior accuracy (64.35% vs. 58.37%) and generated a 17.14% alpha with a Sharpe ratio of 1.5959 in backtests, demonstrating LLMs’ capacity to automate financial reasoning while reducing reliance on specialized expertise. Our findings bridge AI and quantitative finance by validating LLMs’ cross-domain adaptability using purely numerical data, offering practical implications for AI-driven investment decision systems.},
  archive      = {J_ESWA},
  author       = {Meiqun Yin and Mengzhu Guo},
  doi          = {10.1016/j.eswa.2025.129913},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129913},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex forecasting and investment strategy optimization via chain-of-thought of large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). KMHBO: A knowledge-guided multi-niche hybrid breeding optimization algorithm for high-dimensional multimodal feature selection. <em>ESWA</em>, <em>298</em>, 129911. (<a href='https://doi.org/10.1016/j.eswa.2025.129911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal feature selection aims to identify multiple feature subsets with similar discriminative capabilities, providing diverse and interchangeable solutions for intelligent decision-making. However, most existing multimodal feature selection methods based on metaheuristic algorithms are designed for low or medium dimensional data, and their search efficiency significantly degrades in high-dimensional spaces. To address this challenge, we propose a knowledge-guided multi-niche hybrid breeding optimization algorithm (KMHBO) with dual dynamic grouping, which enhances both solution diversity and overall search performance. KMHBO introduces a two-level dynamic grouping mechanism: at the outer level, a dual similarity-guided niche partitioning strategy adaptively adjusts the size and distribution of each niche to improve the global exploration; at the inner level, the population is divided into three subpopulations based on historical evolutionary behaviors, namely the maintainer, the restorer, and the sterile. Each subpopulation is assigned specific search tasks to strengthen the local exploitation and increase structural diversity among solutions. Additionally, a mutation mechanism based on feature selection frequency is introduced to promote information exchange between niches, while an improved external archive updating mechanism ensures the preservation of diverse equivalent solutions. Extensive experiments on ten high-dimensional benchmark datasets demonstrate that KMHBO significantly outperforms state-of-the-art methods in terms of classification accuracy. Notably, KMHBO achieves 100% classification accuracy on the ALLAML and GLI_85 datasets and identifies nearly 50 structurally distinct yet functionally equivalent feature subsets under a fixed archive size, showcasing its superior performance and strong potential in high-dimensional multimodal feature selection tasks.},
  archive      = {J_ESWA},
  author       = {Zhiwei Ye and Ying Zeng and Ting Cai and Jun Shen and Wen Zhou and Qiyi He and Mengqing Mei and Yi Cen},
  doi          = {10.1016/j.eswa.2025.129911},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129911},
  shortjournal = {Expert Syst. Appl.},
  title        = {KMHBO: A knowledge-guided multi-niche hybrid breeding optimization algorithm for high-dimensional multimodal feature selection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A fault-tolerant task offloading framework via large-scale multi-objective evolutionary optimization and game-based decision mechanism. <em>ESWA</em>, <em>298</em>, 129910. (<a href='https://doi.org/10.1016/j.eswa.2025.129910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-access edge computing (MEC) optimization is challenging due to high-dimensional decision spaces, conflicting objectives, nonstationary conditions, and failure-prone infrastructure. This paper presents an adaptive Mahalanobis distance-based large-scale multi-objective evolutionary algorithm with knowledge transfer and a two-layer encoding ( ALC-LSMOEA-KT ). The task-offloading model optimizes latency, energy, load balance, and failure risk under communication and computation constraints. A two-layer sparse encoding separates variable activation from value search, and a phase-aware evolution with Mahalanobis-guided covariance adaptation exploits inter-variable correlations while preserving diversity. A Stackelberg-based fault-tolerant migration module reassigns disrupted tasks to sustain robustness. Experiments on scalable multi-objective optimization Problems(SMOP)/large-scale multi-objective optimization problem(LSMOP) benchmarks and a realistic MEC simulator with dynamic arrivals, bandwidth variation, and injected failures show consistent gains in inverted generational distance (IGD), solution diversity, and robustness. The results indicate a scalable and reliable approach to MEC optimization under high dimensionality and uncertainty.},
  archive      = {J_ESWA},
  author       = {Tingting Dong and Jinbu Wen and Fei Xue and Yuge Geng and Xingjuan Cai},
  doi          = {10.1016/j.eswa.2025.129910},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129910},
  shortjournal = {Expert Syst. Appl.},
  title        = {A fault-tolerant task offloading framework via large-scale multi-objective evolutionary optimization and game-based decision mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MEDTSAN: A mechanism-enabled deep transferable subdomain adaptation network for rolling bearing fault diagnosis without labeled data. <em>ESWA</em>, <em>298</em>, 129908. (<a href='https://doi.org/10.1016/j.eswa.2025.129908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis methods are utilized extensively in rolling bearings. However, in practical scenarios, the scarcity of high-quality labeled data leads to poor generalization ability and limits their application. In this paper, a novel subdomain-adaptive rolling bearing fault diagnosis method, mechanism-enabled deep transferable subdomain adaptation network (MEDTSAN), is proposed to combine the dynamic model with the subdomain adaptation method to identify fault classes without labeled measurement data accurately. First, the six-degree-of-freedom (6-DOF) dynamic model is developed based on the bearing failure mechanisms to generate abundant labeled simulation data for the source domain, contrasting with the employment of unlabeled measured data in the target domain. Then, a union subdomain contrastive learning (USCL) method is introduced to establish discriminative subdomain decision boundaries by considering the transferability of target data. Finally, a multi-view subdomain alignment (MVSA) strategy is designed to achieve target-to-source and target-to-target subdomain alignments, reducing the difficulty of subdomain adaptation and suppress negative transfer. Experiments indicate that the proposed method performs better than existing methods in cross-domain diagnostic tasks from simulation to measured data, providing an effective solution to the scarcity of high-quality labeled data.},
  archive      = {J_ESWA},
  author       = {Zihao Li and Baoping Tang and Lei Deng and Peng Zhu and Qikang Li},
  doi          = {10.1016/j.eswa.2025.129908},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129908},
  shortjournal = {Expert Syst. Appl.},
  title        = {MEDTSAN: A mechanism-enabled deep transferable subdomain adaptation network for rolling bearing fault diagnosis without labeled data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs. <em>ESWA</em>, <em>298</em>, 129907. (<a href='https://doi.org/10.1016/j.eswa.2025.129907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of glaucoma progression is crucial to managing patients, permitting individualized care plans and treatment. It is a challenging task requiring the assessment of structural changes to the optic nerve head and functional changes based on visual field testing. Artificial intelligence, especially deep learning techniques, has shown promising results in many applications, including glaucoma diagnosis. This paper proposes a two-stage computational learning pipeline for detecting glaucoma progression using only fundus photographs. In the first stage, a deep learning model takes a time series of fundus photographs as input and outputs a vector of predictions where each element represents the overall rate of change in visual field (VF) sensitivity values for a sector (region) of the optic nerve head (ONH). We implemented two deep learning models—ResNet50 and InceptionResNetV2—for this stage. In the second stage, a binary classifier (weighted logistic regression) takes the predicted vector as input to detect progression. We also propose a novel method for constructing annotated datasets from temporal sequences of clinical fundus photographs and corresponding VF data suitable for machine learning. Each dataset element comprises a temporal sequence of photographs together with a vector-valued label. The label is derived by computing the pointwise linear regression of VF sensitivity values at each VF test location, mapping these locations to eight ONH sectors, and assigning the overall rate of change in each sector to one of the elements of the vector. We used a retrospective clinical dataset with 82 patients collected at multiple timepoints over five years in our experiments. The InceptionResNetV2-based implementation yielded the best performance, achieving detection accuracies of 97.28 ± 1.10 % for unseen test data (i.e., each dataset element is unseen but originates from the same set of patients appearing in the training dataset), and 87.50 ± 0.70 % for test data from unseen patients (training and testing patients are entirely different). The testing throughput was 11.60 ms per patient. These results demonstrate the efficacy of the proposed method for detecting glaucoma progression from fundus photographs.},
  archive      = {J_ESWA},
  author       = {Md.Reduanul Haque and Andrew Mehnert and William Huxley Morgan and Graham Mann and Ferdous Sohel},
  doi          = {10.1016/j.eswa.2025.129907},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129907},
  shortjournal = {Expert Syst. Appl.},
  title        = {A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Symmetric difference consistent semi-supervised brain stroke lesion segmentation with uncertainty guidance. <em>ESWA</em>, <em>298</em>, 129900. (<a href='https://doi.org/10.1016/j.eswa.2025.129900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sudden onset of stroke is a leading cause of death and disability worldwide. Automatic segmentation of stroke lesions is crucial for the timely formulation of clinical treatment strategies. However, the extensive variations in size, shape, and intensity of stroke lesions present significant challenges for precise segmentation, particularly in the absence of a large set of meticulously annotated data for model training. In this paper, we propose a symmetric difference consistent semi-supervised learning method (SDC-SSL) to leverage readily available unlabeled data for stroke lesion segmentation. We first design a symmetric difference network (SD-Net) that incorporates anatomical symmetry priors, with two key modules: difference awareness extraction (DAE) and symmetric feature fusion (SFF), to accurately segment diverse lesions. Specifically, DAE extracts more discriminative features by exploring multi-scale bilateral differences, while SFF adaptively integrates symmetric features enriched with salient pathological information. To excavate meaningful representations from unlabeled data, SD-Net is then embedded into a novel dual-level consistency mean teacher framework, where uncertainty estimation progressively guides the student in acquiring reliable knowledge from the teacher. In addition to pixel-level consistency regularization, we introduce a difference-aware attention consistency loss at feature level to capture robust semantic information. Finally, we specifically develop pseudo-labels driven symmetric contrastive learning to amplify bilateral differences caused by stroke lesions, further enhancing semi-supervised segmentation. Experimental results show that our SDC-SSL consistently outperforms state-of-the-art semi-supervised methods and achieves performance comparable to fully-supervised approaches with only 20% of labeled data, highlighting its potential clinical value in reducing reliance on extensive data annotation.},
  archive      = {J_ESWA},
  author       = {Yongliang Zhang and Wei Wang and Lei Li and Qi Wu and Haoquan Sun and Ao Li and Minghui Wang and Feng Gao},
  doi          = {10.1016/j.eswa.2025.129900},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129900},
  shortjournal = {Expert Syst. Appl.},
  title        = {Symmetric difference consistent semi-supervised brain stroke lesion segmentation with uncertainty guidance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming. <em>ESWA</em>, <em>298</em>, 129899. (<a href='https://doi.org/10.1016/j.eswa.2025.129899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free-bending (FB) technology enables the efficient processing of spatially complex-shaped tubes. Springback causes variations in curvature and torsion of the tube axis during the FB process. The mapping relationship of bent tube curvature and torsion from ideal to actual values can be abstracted as nonlinear physical operators. This paper first proposes a novel six-axis FB processing method that can control geometric features of tube transition segments. Then, an operator learning-based springback behavior prediction (OL-SBP) framework is presented, which includes an OL module and an SBP module. A feature-information-enhanced deep operator network (FIE-DeepONet) is integrated into the first module to learn tube springback operators. The curvature and torsion predicted by the OL module are then fed into the SBP module to calculate the overall shape of the springback axis. This paper also introduces a set of similarity evaluation indicators that are independent of the curve’s spatial attitude. Planar and spatial bent tubes are selected as case studies. Results show that the framework yields more accurate predictions compared to the analytical model. The framework also exhibits excellent generalization performance. Once FIE-DeepONet has learned the springback operators, it can accurately predict the springback curvature and torsion, even for tube shapes not present during training.},
  archive      = {J_ESWA},
  author       = {Yongzhe Xiang and Zili Wang and Shuyou Zhang and Le Wang and Caicheng Wang and Yaochen Lin and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129899},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129899},
  shortjournal = {Expert Syst. Appl.},
  title        = {Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-label chest X-ray image classification agorithm based on multi-scale and attribute-aware semantic graph. <em>ESWA</em>, <em>298</em>, 129898. (<a href='https://doi.org/10.1016/j.eswa.2025.129898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label Chest X-Ray classification is crucial for intelligent diagnosis, yet existing algorithms usually ignore lesion-scale heterogeneity and attribute-conditioned label dependencies, limiting their clinical generalizability. To address these issues, this paper proposes MSASG, a multi-label Chest X-Ray image classification algorithm based on Multi-Scale and Attribute-aware Semantic Graph which enhances discriminative power and semantic consistency. Firstly, a Multi-scale Feature Partitioning and Reconstruction method is proposed to capture lesion patterns at different scales. Secondly, a Label-guided Multi-scale Semantic Alignment method is proposed to improve visual-semantic alignment by integrating label embeddings into feature extraction and using a Transformer to model high-order cross-modal dependencies. Finally, an Attribute-aware Graph Convolutional Network method is proposed to construct attribute-specific label co-occurrence matrices and dynamically select relevant structures during inference, enabling personalized characterization of label dependencies. Experiments on ChestX-ray14 and CheXpert show that MSASG outperforms state-of-the-art methods in recognizing complex lesion co-occurrence and adapting to heterogeneous populations.},
  archive      = {J_ESWA},
  author       = {Qian Wang and Zhijuan Wu and Jiyu Gao and Hongnian Yu and Yongqiang Cheng},
  doi          = {10.1016/j.eswa.2025.129898},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129898},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-label chest X-ray image classification agorithm based on multi-scale and attribute-aware semantic graph},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABE-mamba: Few-shot medical image segmentation via adversarial bidirectional enhanced mamba. <em>ESWA</em>, <em>298</em>, 129897. (<a href='https://doi.org/10.1016/j.eswa.2025.129897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Few-Shot Medical Image Segmentation (FSMIS) methods primarily focus on mining information from support image to guide query image segmentation, while insufficiently exploring the contextual information within the query image itself. Due to significant anatomical variability and differences in imaging conditions, the targets in support and query images may exhibit substantial discrepancies, even within the same class. Consequently, inadequate utilization of query context limits the model’s ability to adapt to intra-class variations, reducing its generalization capability. To address this issue, inspired by Mamba’s capacity for context modeling with linear complexity, we propose ABE-Mamba, a novel query-focused FSMIS framework. ABE-Mamba enhances the model’s adaptability to intra-class variations by effectively mining the query image’s contextual information, and introduces an adversarial training mechanism to improve high-order consistency between the predicted mask and the ground truth. Firstly, a Bidirectional Enhanced Mamba module is introduced into the generator to fully mine the rich semantics in query images by facilitating bidirectional enhancement of both local and global context. Secondly, a cross 2D Selective Scan (cross-SS2D) block is designed and incorporated into the discriminator to improve its capability in distinguishing subtle differences between real and generated masks, thereby enhancing the alignment between predicted masks and ground truths. Thirdly, a pyramid structure is integrated into the generator to facilitate multi-scale feature extraction, thereby improving robustness to objects of varying sizes. Extensive experiments on four widely used datasets (Syn-CT, CHAOS-MRI, Card-MRI, and P-MRI) demonstrate that ABE-Mamba achieves competitive performance.},
  archive      = {J_ESWA},
  author       = {Bingjie Guo and Wenhui Huang and Xiaoyan Wang},
  doi          = {10.1016/j.eswa.2025.129897},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129897},
  shortjournal = {Expert Syst. Appl.},
  title        = {ABE-mamba: Few-shot medical image segmentation via adversarial bidirectional enhanced mamba},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FSTrack: Visual tracking with feature fusion and adaptive selection. <em>ESWA</em>, <em>298</em>, 129895. (<a href='https://doi.org/10.1016/j.eswa.2025.129895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking represents a critical research domain within computer vision, with significant applications spanning security surveillance, autonomous navigation, and other fields. Throughout the tracking process, distractors and target appearance variations frequently arise, rendering sole reliance on initial templates unreliable. Therefore, the effective integration of spatiotemporal information and search region features plays a crucial role in achieving robust long-term single-object tracking. However, most existing methods indiscriminately incorporate all historical features as spatiotemporal context, potentially introducing irrelevant or redundant information that undermines tracking reliability. To address this limitation while more effectively exploiting backbone features, we propose FSTrack, which leverages feature fusion to enhance search features and adaptively selects features to strengthen spatiotemporal features. First, we integrate multi-level backbone features through feature fusion and enhance feature resolution, thereby fully exploiting the multi-scale features of the backbone networks. Second, we introduce an adaptive feature selection mechanism that dynamically identifies and emphasizes discriminative historical features, enhancing the robustness of spatiotemporal modeling under diverse tracking scenarios. Third, we propose a globally contextual prediction head that overcomes the limitation of the limited receptive field inherent in conventional CNN-based heads and further improving the overall performance. Extensive experiments demonstrate the superiority of FSTrack. On mainstream benchmark datasets such as GOT-10k, TrackingNet, and LaSOT, our approach outperforms mainstream models using both the same and higher resolution inputs in terms of speed and accuracy, achieving state-of-the-art results on tracking benchmarks.},
  archive      = {J_ESWA},
  author       = {Jian Shi and Yang Yu and Bin Hui and Junze Shi and Haibo Luo},
  doi          = {10.1016/j.eswa.2025.129895},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129895},
  shortjournal = {Expert Syst. Appl.},
  title        = {FSTrack: Visual tracking with feature fusion and adaptive selection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exact reliability of cold chain networks with multi-state travel time and transport capacity. <em>ESWA</em>, <em>298</em>, 129892. (<a href='https://doi.org/10.1016/j.eswa.2025.129892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-pandemic lifestyle changes have increased reliance on e-commerce, boosting the logistics sector. One of the most highly regarded industries is cold chain logistics, especially for vaccines and refrigerated foods. In cold chain networks, transport routes have varying capacities based on customer orders, and travel times fluctuate due to traffic and weather. Thus, this study focuses on evaluating network reliability, i.e., the probability to meet given demands within the specified time threshold, of cold chain networks considering the two multi-state factors: travel time and transport capacity. To account for practical situations, a multi-state cold chain network (MCCN) is constructed with retailers, third-party logistics companies, and suppliers as nodes, and transportation routes as arcs. The concept of minimal path is used to determine the transport flow that complies with the time threshold and to determine the transport capacity vectors that satisfy the demands. An algorithm is proposed to resolve different characteristics of time thresholds and demand requirements for efficient assessment. Network reliability is successfully calculated, as shown in the case and sensitivity analysis. This allows managers to grasp the performance of MCCN and make informed decisions based on the achieved network reliability.},
  archive      = {J_ESWA},
  author       = {Thi-Phuong Nguyen and Chin-Lung Huang and Louis Cheng-Lu Yeng and Yi-Kuei Lin},
  doi          = {10.1016/j.eswa.2025.129892},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129892},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exact reliability of cold chain networks with multi-state travel time and transport capacity},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-tensor collaborative facilitation for multi-view clustering. <em>ESWA</em>, <em>298</em>, 129883. (<a href='https://doi.org/10.1016/j.eswa.2025.129883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view clustering methods, tensor is often used to capture higher-order information among multi-view data and characterize the feature space structure of the original data. In this paper, we propose the D ual- T ensor C ollaborative F acilitation for M ulti- V iew C lustering approach. DTCF-MVC collaboratively facilitates the multi-view representation tensor through the original data projection tensor, and then finally obtains the multi-view optimal representation through rank-based adaptive weighted fusion. Secondly we design new solutions for tensor rank and tensor sparsity respectively. Therefore, we design a new tensor projection norm to handle the projection tensor. In addition, since there may be large differences between multi-view features, we design a new Weighted Arctangent Coupled tensor nuclear norm. This enables weighted arctangent coupling of singular values of different sizes in the tensor-singular value decomposition, which adequately approximates the true rank of the singular value matrix generated by the representation tensor in the frequency domain decomposition. The superiority of the proposed method is demonstrated by extensive experiments on different datasets.},
  archive      = {J_ESWA},
  author       = {Jie Zhang and Xiaoqian Zhang and Yongyi Yang and Jinghao Li and Zhenwen Ren and Rong Tang and Dong Wang},
  doi          = {10.1016/j.eswa.2025.129883},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129883},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-tensor collaborative facilitation for multi-view clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PFL-TEnet: Personalized federated learning for wind power forecasting via time-series embedding and hypernetwork modeling. <em>ESWA</em>, <em>298</em>, 129881. (<a href='https://doi.org/10.1016/j.eswa.2025.129881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As wind power occupies an increasingly important position in the global energy structure, improving its power prediction accuracy has become the key to guarantee the stable operation of the power system and the efficient consumption of new energy. However, wind energy is driven by complex nonlinear meteorological factors, exhibiting significant time series dependency and heterogeneity among wind farms, while also facing practical requirements for data privacy protection. These factors present numerous challenges for personalized modeling across multiple wind farms. To address these challenges, this paper proposes a personalized federated learning model, PFL-TEnet, which utilizes time-series embedding network to extract critical temporal features and dynamically generates personalized model parameters through hypernetwork. Under the premise of protecting data privacy, this model balances personalized adaptability and generalization capability. Experimental results demonstrate that the proposed method significantly outperforms existing mainstream methods on multiple real wind farm datasets and demonstrates notable advantages in prediction accuracy and personalized performance.},
  archive      = {J_ESWA},
  author       = {Yi Li and Chenguang Zhang and Yan Zhang and Jianming Hu},
  doi          = {10.1016/j.eswa.2025.129881},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129881},
  shortjournal = {Expert Syst. Appl.},
  title        = {PFL-TEnet: Personalized federated learning for wind power forecasting via time-series embedding and hypernetwork modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge-guided semi-supervised 6D pose estimation with cross-domain alignment for robotic grasping. <em>ESWA</em>, <em>298</em>, 129880. (<a href='https://doi.org/10.1016/j.eswa.2025.129880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately estimating 6D poses of objects is crucial for robotic grasping, and existing pose estimation methods generally require large amount of labeled data from same domain, which is difficult for real-world cases. Although some feature transfer methods have been proposed, the gap between source and target scenes still exists. To solve these limitations, we construct a virtual environment with scanned object models and further propose a novel edge-guided semi-supervised 6D pose estimation approach for robotic grasping, where labeled virtual images and unlabeled real images are required, substantially reducing reliance on annotated real data. The designed edge guidance module is able to highlight fine-grained edges of objects and weaken their surface textures, effectively mitigating negative transfer. In addition, a simple yet effective domain mixture mechanism is introduced to align pose-specific features of virtual and real domains from implicit and explicit perspectives, facilitating smoother feature alignment transitions. Comparative experiments are extensively conducted on two pairs of datasets, and the results indicate that the proposed method outperforms other approaches and transfer strategies by 4.1 % and 7.2 %, respectively. The real-world pose estimation and robotic grasping experiments also prove its effectiveness in diverse scenarios.},
  archive      = {J_ESWA},
  author       = {Lu Chen and Jiajie Wen and Yan Gao and Jing Yang and Chao Zhang and Shan An and Peng Wu},
  doi          = {10.1016/j.eswa.2025.129880},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129880},
  shortjournal = {Expert Syst. Appl.},
  title        = {Edge-guided semi-supervised 6D pose estimation with cross-domain alignment for robotic grasping},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-source multi-label feature selection with missing features. <em>ESWA</em>, <em>298</em>, 129879. (<a href='https://doi.org/10.1016/j.eswa.2025.129879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature dimensionality reduction on Multi-Source Multi-Label (MSML) data is a critical and challenging task. Because practical situations always produce massive MSML data, but they usually contain more missing feature values in the high-dimensional feature space and present severely skewed label distributions in the multi-label space, which aggravate the difficulties in the tackling of high-dimensional feature selection on MSML data. However, much attention in feature selection has been directed either toward multi-label data or multi-source data, while little attention is focused on MSML data, not to mention those containing missing features. Motivated by this, we present a new feature selection method for MSML data with missing features, called MMFSMF. Specifically, to overcome the issue of feature missing, we first supplement the feature matrix by constructing a feature correlation matrix during the modeling process of multi-label learning. At the meanwhile, we utilize a multi-label oversampling mechanism to address the persistent problem of label skewness in multi-label data. Secondly, in terms of the above processing, we introduce a refined infinite feature selection algorithm to perform feature dimensionality reduction in each multi-label data source, considering both label correlations and label-specific features. Thirdly, to address feature redundancy among multiple data sources, we apply a new inter-source feature fusion method. Finally, experiments conducted on nine synthetic MSML datasets with missing features demonstrate that MMFSMF achieves superior performances compared to all competing ones.},
  archive      = {J_ESWA},
  author       = {Yabo Shi and Peipei Li and Xiulan Yuan and You Wu and Haiping Wang},
  doi          = {10.1016/j.eswa.2025.129879},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129879},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-source multi-label feature selection with missing features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual attention-guided fractional-order system for collision perception in complex dynamic scenes. <em>ESWA</em>, <em>298</em>, 129877. (<a href='https://doi.org/10.1016/j.eswa.2025.129877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately perceiving collision threats in dynamic environments is a significant challenge for intelligent mobile machines. Insects, through millions of years of evolution, have developed a robust and efficient visual system for collision perception. This system hinges on a special class of neurons called Lobula Giant Movement Detectors (LGMDs), known for their exceptional sensitivity to looming motion. However, existing LGMD-based collision perception systems, which often rely on fixed system thresholds, struggle with interference from dynamic visual scenes. This paper presents a collision perception system enhanced with a selective visual attention neural mechanism. The system is designed to autonomously adapt to complex dynamic environments by selectively focusing on crucial information pertinent to collision detection, thereby improving its perceptual accuracy. In the proposed system, the attention module and the attentional shift module are integrated into an LGMD visual neural network, which is built on fractional-order neurodynamics. Through their collaborative interaction, these components effectively process visual motion information for accurate collision perception. We define a novel method for calculating attention distribution, which assigns varying levels of attention strength to different regions of the receptive field based on their relevance to collision detection. Furthermore, the attentional shift module incorporates a rarity factor to determine how attention is redistributed, enabling the system to better adapt to complex and ever-changing scenarios. When tested in dynamic and challenging environments, the attention-guided fractional-order LGMD visual system demonstrates superior performance.},
  archive      = {J_ESWA},
  author       = {Yusi Wang and Haiyang Li and Yi Zheng and Chao Yuan and Jigen Peng},
  doi          = {10.1016/j.eswa.2025.129877},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129877},
  shortjournal = {Expert Syst. Appl.},
  title        = {Visual attention-guided fractional-order system for collision perception in complex dynamic scenes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades. <em>ESWA</em>, <em>298</em>, 129876. (<a href='https://doi.org/10.1016/j.eswa.2025.129876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot machining, offering a more flexible and reconfigurable approach compared to fixed-base robots, has therefore become a promising solution for efficiently machining large and complex wind turbine blades. In this context, determining proper machining placements and allocating machining trajectories are two pivotal factors in the mobile robotic automation grinding of wind turbine blades, directly affecting machining efficiency and quality. However, the highly nonlinear performance distribution of the robot in the task space, combined with the complexity of the machining surface, presents significant challenges. To address these challenges, this paper presents a general optimization model of this problem with the objectives of completion time and robot manipulability, considering singularity avoidance and collision avoidance. Based on this model, an improved non-dominated sorting genetic algorithm integrated with reinforcement learning and dual population co-evolution (RL-NSGA-DP) is developed. In RL-NSGA-DP, each solution is coded using a novel two-layer metavariable encoding scheme, and a tailored dominated-recessive crossover operator is designed. Moreover, a dual-population collaborative search strategy employing different operators and an adaptive switching environmental selection mechanism based on reinforcement learning are implemented to ensure the convergence and maintain population diversity. Comparative experiments on test instances and a practical case study demonstrate that RL-NSGA-DP outperforms five well-known multi-objective evolutionary algorithms, and effectively addresses robot placement and trajectory allocation problem in mobile robotic machining systems.},
  archive      = {J_ESWA},
  author       = {Yi Hua and Xuewu Wang},
  doi          = {10.1016/j.eswa.2025.129876},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129876},
  shortjournal = {Expert Syst. Appl.},
  title        = {An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive GNSS-5G hybrid positioning based on time offset optimization estimation and multi-rate measurement fusion. <em>ESWA</em>, <em>298</em>, 129875. (<a href='https://doi.org/10.1016/j.eswa.2025.129875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion positioning of the Global Navigation Satellite System and Fifth-Generation Mobile Communication Network is a key direction for breaking through the performance bottleneck of a single system. However, it faces two core challenges: inconsistent spatiotemporal benchmarks and multi-rate measurement fusion. To address these issues, this paper proposes a joint time offset estimation and phased fusion strategy: An adaptive time-varying offset model is established, and an adaptive relative time offset estimation algorithm based on pseudo-measurements is designed. The high-precision time benchmark provided by GNSS is used to realize the indirect estimation of the 5G absolute time offset, solving the problem of offset accumulation in dynamic scenarios. A two-stage filtering framework is proposed, which processes the coordinate conversion error of 5G polar coordinate measurements through a modified unbiased converted measurement Kalman filter, combines with a Kalman filter to estimate the target state, and constructs a time offset pseudo-measurement based on velocity estimation for efficient solutions. A phased multi-rate fusion strategy is designed: At GNSS sampling moments, adaptive weighted fusion is used to correct the accumulated errors of 5G high-frequency data; at non-GNSS moments, 5G high-frequency measurements and motion state equation predictions are used to maintain tracking accuracy for high-dynamic targets. Simulation results show that the proposed algorithm significantly outperforms eight mainstream algorithms such as SPP, EKF, and UKF in positioning accuracy, with a total average error of 1.66 m and a total root mean square error of 2.02 m. Moreover, the error distribution is more concentrated and stability is stronger, which can effectively adapt to the needs of high-dynamic scenarios and provide reliable solutions for GNSS-5G hybrid positioning.},
  archive      = {J_ESWA},
  author       = {Huiyu Chen and Yu Lu and Yao Xing and Xu Zhang and Jiongqi Wang},
  doi          = {10.1016/j.eswa.2025.129875},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129875},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive GNSS-5G hybrid positioning based on time offset optimization estimation and multi-rate measurement fusion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RAFN: A risk-aware feature network for identifying risk factors in supply chain finance. <em>ESWA</em>, <em>298</em>, 129874. (<a href='https://doi.org/10.1016/j.eswa.2025.129874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As supply chain finance businesses expand, traditional risk assessment systems, which rely heavily on manual processes and static rule-based frameworks, are increasingly unable to keep up with the complexity and dynamism of modern risk patterns. This often leads to delayed responses and inefficiencies in risk management. To address key challenges such as difficulties in integrating heterogeneous data, low detection rates for hidden risks, and limited ability to capture dynamic risk patterns, this paper introduces a novel Risk-Aware Feature Network (RAFN) driven by an adaptive attention mechanism. The RAFN model is designed with a dual-channel architecture to process numerical and categorical data separately, employs gated linear units to dynamically merge heterogeneous data streams, and incorporates a multi-head attention mechanism with dynamic coefficients to focus on risk-sensitive features adaptively. Experiments conducted on both public and proprietary datasets show that RAFN outperforms mainstream algorithms, achieving a 1.73%-5.81% improvement in accuracy, recall, and F1-score, while maintaining a strong balance between specificity and recall. Furthermore, this study proposes a closed-loop risk management framework based on RAFN, which integrates “smart contract triggering, off-chain model evaluation, and on-chain consensus validation.” This approach offers an efficient technical solution to break down data silos and enhance the precision of risk identification in supply chain finance, paving the way for more effective and reliable risk control systems.},
  archive      = {J_ESWA},
  author       = {Yang Zhang and Yating Zhao and Wenjuan Lian and Bin Jia},
  doi          = {10.1016/j.eswa.2025.129874},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129874},
  shortjournal = {Expert Syst. Appl.},
  title        = {RAFN: A risk-aware feature network for identifying risk factors in supply chain finance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Task-free continual generative modelling via dynamic teacher-student framework. <em>ESWA</em>, <em>298</em>, 129873. (<a href='https://doi.org/10.1016/j.eswa.2025.129873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continually learning and acquiring new concepts from a dynamically changing environment is an important requirement for an artificial intelligence system. However, most existing deep learning methods fail to achieve this goal and suffer from significant performance degeneration under continual learning. We propose a new unsupervised continual learning framework combining Long- and Short-Term Memory management for training deep learning generative models. The former memory system employs a dynamic expansion model (Teacher), while the latter uses a fixed-capacity memory buffer to store the update-to-date information. A novel Teacher model expansion approach, called the Knowledge Incremental Assimilation Mechanism (KIAM) is proposed. KIAM evaluates the probabilistic distance between the already accumulated information and that from the Short Term Memory (STM). The proposed KIAM adaptively expands the Teacher’s capacity and promotes knowledge diversity among the Teacher’s experts. As Teacher experts, we consider generative deep learning models such as : the Variational Autocencoder (VAE), the Generative Adversarial Network (GAN) or the Denoising Diffusion Probabilistic Model (DDPM). We also extend the KIAM-based model to a Teacher-Student framework in which we use a data-free Knowledge Distillation (KD) process to train a VAE-based Student without using any task information. The results on Task Free Continual Learning (TFCL) benchmarks show that the proposed approach outperforms other models.},
  archive      = {J_ESWA},
  author       = {Fei Ye and Adrian G. Bors},
  doi          = {10.1016/j.eswa.2025.129873},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129873},
  shortjournal = {Expert Syst. Appl.},
  title        = {Task-free continual generative modelling via dynamic teacher-student framework},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trend-aware structure relearning framework for water quality prediction with coupled noise governance. <em>ESWA</em>, <em>298</em>, 129872. (<a href='https://doi.org/10.1016/j.eswa.2025.129872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban river water quality monitoring is an essential initiative for promoting sustainable and green societal development. Water quality prediction, by effectively modeling the spatiotemporal dependencies between different monitoring sites, holds significant practical value for sites where historical data is difficult to obtain. However, despite progress in spatiotemporal (ST) dependency modeling methods, existing models face challenges in accurately capturing the complex ST dependencies of water quality changes due to the coupled effects of numerical and structural noise. To address this, we propose TaSRef, a T rend- a ware S tructure Re learning F ramework for water quality prediction with coupled noise governance. Specifically, we first separate structural noise and relearn the water topology by analyzing the trend features and relationships of neighboring historical water quality data. Then, based on the relearned topologies and the original noisy data, we thoroughly extract spatiotemporal features to isolate numerical noise. Finally, we achieve robust prediction of water quality in complex environments by aligning and aggregating the trend and ST features of corresponding nodes. Validation on three real datasets shows that the proposed TaSRef framework significantly outperforms baseline models in terms of R 2 , MAE, and RMSE. Through case visualization, results further indicate that TaSRef effectively infers the actual connectivity of river systems and demonstrates strong adaptability in handling coupled noises, thereby validating the robustness and effectiveness of TaSRef for accurate water quality prediction in complex environments.},
  archive      = {J_ESWA},
  author       = {Shuo Tong and Yuyang Xu and Jianming Sun and Fuzhen Zhuang and Jian Wu and Guangdi Chen and Haochao Ying},
  doi          = {10.1016/j.eswa.2025.129872},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129872},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trend-aware structure relearning framework for water quality prediction with coupled noise governance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance. <em>ESWA</em>, <em>298</em>, 129871. (<a href='https://doi.org/10.1016/j.eswa.2025.129871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic hip exoskeletons hold enormous potential to enhance human locomotion. However, the rigid structures and predefined control laws limit their compliance and adaptability during dynamic human-robot interactions. Here, a novel parallel elastic hip exoskeleton is developed for human locomotion assistance. The exoskeleton utilizes a remote cable actuation system to improve compliance and incorporates a parallel elastic mechanism at the hip wearable components to enhance actuator energy efficiency by generating a compensatory torque. For exoskeleton control, a speed-adaptive torque control strategy is implemented to modulate the assistance torque in real time, based on the user’s gait phase and hip movement frequency estimated by adaptive oscillators. The system was tested on seven healthy subjects, and preliminary results indicate that the parallel elastic element achieves a 40.2 % reduction in peak motor torque through energy conversion. The controller exhibits excellent torque tracking performance and effectively extracts human gait features across walking speeds with hip frequency correlation ( R 2 = 0.89). Furthermore, the hip exoskeleton significantly reduced users’ peak hip moments and muscle activity while preserving natural kinematics. The parallel elastic hip exoskeleton demonstrates strong adaptive assistive capabilities and is expected to enhance locomotion in real-world applications.},
  archive      = {J_ESWA},
  author       = {Jing Zhang and Aibin Zhu and Bingsheng Bao and Xinyu Wu and Chunli Zheng and Meng Li and Jing Wang and Yu Zhang and Xue Wu and Xiao Li},
  doi          = {10.1016/j.eswa.2025.129871},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129871},
  shortjournal = {Expert Syst. Appl.},
  title        = {Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine. <em>ESWA</em>, <em>298</em>, 129870. (<a href='https://doi.org/10.1016/j.eswa.2025.129870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed rail (HSR) short-term passenger flow forecasting is of great significance for dynamically adjusting operation plans and optimizing transportation resource allocation. For this reason, this paper proposes an innovative complete ensemble empirical mode decomposition with adaptive noise integrated with multivariate and bidirectional support vector machine (CEEMDAN-MBSVM) method with four key steps. First, we analyze the correlations between multiple origin–destination (OD) passenger flows and select strongly correlated ODs incorporated with their opposite OD for joint bidirectional forecasting. Second, we decompose the original passenger flow time series by using period division technique of CEEMDAN, which yield multiple intrinsic mode functions (IMFs) and a residual trend term (RES). Then we apply MBSVM to predict the IMFs of each OD and use trend extrapolation to forecast the RES. Finally, we reconstruct the predicted IMFs and RES to obtain the final bidirectional HSR OD daily passenger flows. Subsequently, we conduct a comprehensive validation exercise and significance testing, using real data from Beijing-Shanghai HSR Line, against seven prediction methods. In particular, for five selected ODs, benchmarking against EEMD-MSVM method, the best performer among the six existing models, our model reduces the minimum mean absolute percentage error (MAPE) by 1.30 % to 4.97 % and benchmarking against ARIMA model, the worst performer among the six existing models, our model reduces the MAPE by 11.57 % to 22.72 %. This research has clearly demonstrated the value of leveraging bidirectional OD data on improving short-term passenger flow forecasting.},
  archive      = {J_ESWA},
  author       = {Xueyi Guan and Michael Z.F. Li and Jin Qin and Chengna Wang},
  doi          = {10.1016/j.eswa.2025.129870},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129870},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transfer learning based standard-essential patent prediction with prior transfer direction learning. <em>ESWA</em>, <em>298</em>, 129869. (<a href='https://doi.org/10.1016/j.eswa.2025.129869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard-Essential Patent Prediction (SEPP) holds strategic significance for technological development and international market competition. Traditional SEPP models learned from Standard-Essential Patents (SEPs) with country-specific distribution differences result in different prediction accuracy. Therefore, we propose two propositions: (1) Can transfer learning be leveraged to improve prediction performance of lower-accuracy countries. (2) Can different transfer directions achieve different transfer learning performances. To address these, we propose a transfer learning based SEPP ewith prior transfer direction learning (TLSEPP-PTDL) model. The model uses a mixed transfer learning method, achieving an average accuracy of 92.03 % on four datasets, surpassing the state-of-the-art (SOTA) by 2.03 % and improving precision, recall, and F1-score by 4.25 %, 0.33 %, and 2.25 %, respectively. Moreover, we conduct experiments across countries with different patent volume, standardization rate, and standardization speed, resulting in positive transfer when transfer learning uses source domains with (1) high volume, high rate, and high speed; (2) high volume, low rate, and high speed; (3) low volume, high rate, and high speed.},
  archive      = {J_ESWA},
  author       = {Weidong Liu and Xiaoyu Fan and Kai Wang and Hongjun Sun and Keqin Gan and Cuicui Jiang and Fangyuan Lei},
  doi          = {10.1016/j.eswa.2025.129869},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129869},
  shortjournal = {Expert Syst. Appl.},
  title        = {Transfer learning based standard-essential patent prediction with prior transfer direction learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MetaPlanner: A decentralized metaheuristic-driven framework for spatio-temporal trajectory planning of agent swarms in dynamic environments. <em>ESWA</em>, <em>298</em>, 129868. (<a href='https://doi.org/10.1016/j.eswa.2025.129868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents MetaPlanner, a decentralized metaheuristic-driven framework for joint spatio-temporal trajectory planning of multi-agent swarms in dynamic environments. MetaPlanner generates piecewise polynomial spline trajectories by directly optimizing parameterized spatio-temporal control points, innovatively unifies optimization across static and dynamic obstacles, inter-agent collisions, and dynamic constraints, while also supporting dynamic target tracking and precise time-of-arrival control. For swarm coordination, MetaPlanner introduces an efficient decentralized conflict resolution strategy based on a conflict graph and approximate minimum vertex cover. Extensive simulations, including coordinated navigation of up to 100 agents in complex 3D dynamic environments, precise time-of-arrival tasks, dynamic target tracking, and large-scale robustness tests (MetaPlanner-ABC achieved zero collisions in 40,000 experiments), validate the framework’s high levels of safety, coordination, efficiency, and scalability. MetaPlanner’s code and experimental environments will be open-sourced on GitHub at https://github.com/Bziyue/MetaPlanner to foster further research and applications in multi-agent trajectory planning.},
  archive      = {J_ESWA},
  author       = {Yaxin Li and Deping Zhang and Yu Wang},
  doi          = {10.1016/j.eswa.2025.129868},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129868},
  shortjournal = {Expert Syst. Appl.},
  title        = {MetaPlanner: A decentralized metaheuristic-driven framework for spatio-temporal trajectory planning of agent swarms in dynamic environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IMPACT-net: An integrated multi-scale and computation-efficient timely network for surface defect detection in industrial embedded systems. <em>ESWA</em>, <em>298</em>, 129867. (<a href='https://doi.org/10.1016/j.eswa.2025.129867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated defect detection is crucial in industrial production, with typical scenarios in steel, automotive, and new energy manufacturing. Although deep learning-based defect detection methods have achieved significant progress, challenges such as limited detection accuracy for low-contrast defects and difficulties in efficient inference still persist. To address these challenges, this paper proposes an integrated multi-scale and computation-efficient timely network (IMPACT-Net) for surface defect detection. Firstly, a Precision-Enhanced Feature Pyramid Network (PE-FPN) is designed to improve the detection performance for low-contrast and fine defects by enhancing multi-scale feature fusion. Secondly, an Adaptive Normalized Wasserstein Distance Loss (ANWD-Loss) is proposed to optimize bounding box localization accuracy and enhance robustness. Finally, by employing Progressive Block-Freezing Architecture Search (PBF-AS) and a ZYNQ-based acceleration platform, computational complexity is significantly reduced, and efficient inference is achieved under low-power conditions. Experimental results show that the proposed IMPACT-Net achieves an mAP50 of 78.9 % on the NEU-DET dataset with 2.3 ms inference time and 71.4 % mAP50 on the GC10-DET dataset with 2.5 ms inference time, demonstrating a good balance between detection accuracy and real-time performance that is well suited for resource-constrained embedded industrial environments.},
  archive      = {J_ESWA},
  author       = {Ruiqi Wu and Yong Zhang and Rukai Lan and Lei Zhou},
  doi          = {10.1016/j.eswa.2025.129867},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129867},
  shortjournal = {Expert Syst. Appl.},
  title        = {IMPACT-net: An integrated multi-scale and computation-efficient timely network for surface defect detection in industrial embedded systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Frequency-decomposed attention joint optimization network for image compressive sensing. <em>ESWA</em>, <em>298</em>, 129866. (<a href='https://doi.org/10.1016/j.eswa.2025.129866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network approaches for image compressive sensing (ICS) have garnered significant attention due to their high efficiency and fidelity in image reconstruction. Reconstructing complex image textures from highly compressed measurements has been a longstanding goal of ICS, yet existing methods often struggle to varying degrees with the restoration of low-frequency (LF) textures and high-frequency (HF) details, which potentially limits the quality of the reconstructed image. In this paper, we propose a Frequency-decomposed Attention Joint Optimization Network (FAJO-Net) for ICS, which is capable of enhancing the attention to LF and HF components of images. Specifically, we introduce a frequency-decomposed sparse prior and coupling fidelity constraints, and incorporate a tri-optimization network framework for full, low, and high-frequency (FLH) features, where each component is optimized using an optimization-unfolded multi-scale network (OM-Net), inclusive of Principal Component Augmented Gradient Descent Module (PCAGDM) and U-shaped Proximal Mapping Module (UPMM). The PCAGDM optimizes the FLH features efficiently by supplementing the optimization of the minimum dimension principal component augmented features while optimizing the principal component features. The UPMM is able to perform multi-scale proximal mapping for all FLH features. Finally, we design a Frequency-decomposed Interaction Attention Module (FIAM) to enhance the fusion of FLH features, particularly the HF and LF components related to the full-frequency features, while reducing the impact of unnecessary features introduced by frequency decomposition. Extensive experiments demonstrate that our proposed FAJO-Net surpasses the state-of-the-art ICS networks in terms of image fidelity and visual effect, and validates that the proposed FAJO-Net framework can help enhance the image reconstruction capabilities of the vast majority of existing ICS networks, further unlocking the potential for high-fidelity restoration in ICS. Code is available at https://github.com/giant-pandada/FAJO-Net .},
  archive      = {J_ESWA},
  author       = {Zhifu Tian and Tao Hu and Di Wu and Shu Wang and Tingli Li and Ming Zhang},
  doi          = {10.1016/j.eswa.2025.129866},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129866},
  shortjournal = {Expert Syst. Appl.},
  title        = {Frequency-decomposed attention joint optimization network for image compressive sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CARNet: Cross-attention guided feature reconstruction for RGB-T object detection. <em>ESWA</em>, <em>298</em>, 129865. (<a href='https://doi.org/10.1016/j.eswa.2025.129865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-T object detection leverages the complementary advantages of visible and infrared images in describing the same scene, providing a robust solution for all-weather intelligent perception systems. However, existing methods still suffer from insufficient feature fusion due to inherent differences between the two modalities. To address this issue, we propose CARNet, a cross-attention guided feature reconstruction framework for RGB-T object detection. The core innovation lies in the introduction of a novel cross-attention guided feature reconstruction (CAR) module, which establishes a new paradigm of feature decomposition-interaction-reconstruction for multispectral feature interaction: the feature decomposition unit (FDU) separates strong/weak features based on group normalization weights, the inter-modality iterative cross-attention (Inter-ICA) module enables information interaction from strong to weak features, and the feature reconstruction unit (FRU) reconstructs the modality. This interaction strategy effectively retains modality-specific information while avoiding feature aliasing. Additionally, a channel attention fusion (CAF) module is introduced to optimize the integration of dual-modality features through adaptive weight allocation. Extensive experiments on the KAIST, M3FD and VEDAI public datasets show that CARNet significantly outperforms existing state-of-the-art methods, achieving precise and stable detection of objects in complex scenarios.},
  archive      = {J_ESWA},
  author       = {Sirui Wang and Guiling Sun and Liang Dong and Bowen Zheng},
  doi          = {10.1016/j.eswa.2025.129865},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129865},
  shortjournal = {Expert Syst. Appl.},
  title        = {CARNet: Cross-attention guided feature reconstruction for RGB-T object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identification of critical nodes by fusing propagation probabilities and entropy in binary networks. <em>ESWA</em>, <em>298</em>, 129861. (<a href='https://doi.org/10.1016/j.eswa.2025.129861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of critical nodes is crucial for effectively allocating resources and prioritizing tasks in complex networks, which significantly enhances the stability and the efficiency of networks in real-world environments. Generally, existing studies primarily focus on extracting multiple different influential factors from network topology, but they have to face accuracy limitations due to high computational complexity, overlapping influence ranges, and information loss. Inspired by information entropy, in this paper, we explore to identify critical node in complex networks from the perspective of inter-node propagation probabilities. We introduce an innovative critical node ranking algorithm, named MNIE (Mixed Node Information Entropy). MNIE initially segments the node influence within the network topology by distinguishing between global and local effects so as to integrate a more comprehensive topological features set. Then, we refine the connection probability calculation and integrate the features derived from the network structural topology with the probabilities of information transmission (infection rates) among the nodes. Experimental results on 9 real-world networks and 4 synthetic datasets indicate that MNIE enhances the identification of critical nodes and accomplishes better than state-of-the-art methods on monotonicity and accuracy.},
  archive      = {J_ESWA},
  author       = {Lintao Zhang and Jianing Zhang and Rong Yan and Guoqin Yu},
  doi          = {10.1016/j.eswa.2025.129861},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129861},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identification of critical nodes by fusing propagation probabilities and entropy in binary networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks. <em>ESWA</em>, <em>298</em>, 129860. (<a href='https://doi.org/10.1016/j.eswa.2025.129860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery Swapping Stations (BSSs) are emerging as critical components in smart power systems, offering rapid energy refueling, grid load balancing, and improved battery lifecycle management for electric vehicles (EVs). However, the economic operation and cyber-physical security of BSSs remain underexplored, particularly in microgrids that integrate distributed generation (DG) and face increasing vulnerability to cyber-attacks. This paper presents a novel, adaptive energy management framework that optimally schedules the charge and discharge cycles of BSSs under uncertain EV user behavior and potential cyber-physical disruptions. A key innovation lies in modeling two types of cyber-attacks—power disruption and control hijacking—and embedding their technical and economic impacts directly into the optimization process. To solve this multi-objective problem, a Hybrid multi-objective Differential Evolution–Particle Swarm Optimization (HMDE-PSO) algorithm is proposed, which efficiently balances cost minimization, system reliability, and resilience. The framework is validated using the IEEE 69-bus distribution system, demonstrating substantial improvements: over 40% reduction in power losses, enhanced voltage stability, and lower operational costs compared to conventional methods. This work distinguishes itself by integrating cyber-defense considerations with real-time energy scheduling, providing a comprehensive and resilient solution for future BSS-integrated microgrids.},
  archive      = {J_ESWA},
  author       = {Mehdi Ahmadi Jirdehi and Hamdi Abdi and Hazhir Dousti},
  doi          = {10.1016/j.eswa.2025.129860},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129860},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-enhanced 3D residual networks for knee abnormality classification. <em>ESWA</em>, <em>298</em>, 129858. (<a href='https://doi.org/10.1016/j.eswa.2025.129858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning technologies, particularly through Convolutional Neural Networks (CNNs), has substantially enriched medical image analysis. This study focuses on improving knee MRI diagnostics by comparing 2D and 3D CNN architectures using the MRNet and SKM-TEA datasets. Initially, modified 2D CNNs, such as ResNet50, were applied for plane-specific and integrated multi-plane analyses. Plane-specific models captured detailed anatomical features, while integrated approaches synthesized information across multiple planes, improving diagnostic capability but lacking full volumetric data utilization. To address these limitations, a novel 3D CNN architecture enhanced with residual attention blocks was developed, leveraging volumetric MRI data. These blocks integrate spatial attention and Squeeze-and-Excitation (SE) mechanisms, optimizing feature focus for accurate diagnostics. This approach improved both model precision and interpretability, which are crucial for clinical applications. Experimental evaluation on the MRNet dataset demonstrated that the proposed 3D CNN outperformed 2D models, achieving 83.58 % accuracy for abnormalities. On the SKM-TEA dataset, the model classified Meniscal Tear (71.36 %), Ligament Tear (79.84 %), Cartilage Lesion (84.28 %), and Effusion (76.74 %), demonstrating robustness in complex pathology detection. Gradient-weighted Class Activation Mapping (Grad-CAM) further enhanced interpretability by highlighting critical diagnostic regions. These findings emphasize the effectiveness of attention-guided 3D CNNs in knee abnormality classification. Future work will explore broader applications in medical imaging, refining the model’s generalizability across diverse clinical datasets.},
  archive      = {J_ESWA},
  author       = {Mohamad M.A. Ashames and Semih Ergin and Omer N. Gerek and H. Serhan Yavuz},
  doi          = {10.1016/j.eswa.2025.129858},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129858},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-enhanced 3D residual networks for knee abnormality classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement. <em>ESWA</em>, <em>298</em>, 129857. (<a href='https://doi.org/10.1016/j.eswa.2025.129857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts are integral to blockchain ecosystems, yet their security remains a critical concern due to the prevalence of exploitable vulnerabilities. Existing conventional and deep learning-based vulnerability detection methods often struggle to capture the fine-grained semantics and heterogeneous structural dependencies essential for accurate analysis. We propose and implement SmartScope , a novel technique for smart contract vulnerability detection that leverages heterogeneous graph embedding with local semantic enhancement. Specifically, SmartScope constructs a semantically rich contract graph that depicts control-flow, data-flow, and fallback relations among critical code elements. To guide the graph learning process, we empirically assign various importance coefficients to vulnerability-relevant subgraphs, thereby enhancing the detection model’s focus on semantically critical regions. The heterogeneous graph transformer is then employed to generate context-aware node representations, which are then passed to an MLP-based detector for vulnerability classification. To the best of our knowledge, this is the first method that structurally encodes domain knowledge into the heterogeneous graph learning for achieving effective smart contract analysis. Experimental results demonstrate that SmartScope outperforms 10 representative conventional and deep learning-based baselines on over 5K smart contracts. The evaluation spans multiple vulnerability types, including reentrancy, timestamp dependence, and infinite loops, highlighting the effectiveness and robustness of our work.},
  archive      = {J_ESWA},
  author       = {Zhaoyi Meng and Zexin Zhang and Wansen Wang and Jie Cui and Hong Zhong},
  doi          = {10.1016/j.eswa.2025.129857},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129857},
  shortjournal = {Expert Syst. Appl.},
  title        = {SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation. <em>ESWA</em>, <em>298</em>, 129856. (<a href='https://doi.org/10.1016/j.eswa.2025.129856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air Quality Index (AQI) prediction is crucial for environmental management and public health. However, most existing studies focus on single site modeling, neglecting the complex spatial correlations of meteorological factors and air pollutants. Therefore, a multi-scale spatio-temporal prediction model, 3DIGAT-CBAM-BiLSTM, is proposed to fully capture the spatio-temporal evolution characteristics of AQI. To reduce the interference of redundant information, the Maximum Information Coefficient and Dynamic Time Series Trend Correlation Method are employed to select the neighboring sites and influencing factors that are highly correlated with the AQI of the target site. The original air quality data is decomposed and reconstructed into high-frequency, low-frequency, and trend-term subsequences using Multivariate Variational Mode Decomposition and Sample Entropy to enhance prediction accuracy. To forecast the three-dimensional spatial tensors of these reconstructed subsequences based on time steps, monitoring sites, and influencing factors, we propose the 3DIGAT-CBAM-BiLSTM model. The spatial dependencies between sites are effectively captured by the Improved Graph Attention Network, which constructs a graph adjacency matrix based on MIC and geographic distance. Meanwhile, the Convolutional Block Attention Mechanism enhances the focus on important sites and features by combining channel and spatial attention. Furthermore, the Bidirectional Long Short-Term Memory network extracts global temporal patterns. The experimental results on the Beijing dataset show that the proposed model achieves a relative reduction of 8.53 % in RMSE and 5.83 % in MAE compared with the optimal baseline model, demonstrating clear performance improvements and offering a novel approach for modeling complex spatio-temporal data.},
  archive      = {J_ESWA},
  author       = {Liangqiong Zhu and Liren Chen and Huayou Chen},
  doi          = {10.1016/j.eswa.2025.129856},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129856},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module. <em>ESWA</em>, <em>298</em>, 129855. (<a href='https://doi.org/10.1016/j.eswa.2025.129855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG)-based emotion identification enables accurate emotional interaction in brain-computer fusion by decoding brain signals, thereby enhancing the intelligence of human-computer collaboration. Data augmentation (DA) techniques offer a promising solution to the challenge of data scarcity in emotion identification. However, traditional DA methods often overlook the physiological mechanisms underlying EEG data, limiting their effectiveness and constraining the performance of emotion classification. To address this, a DA model based on human nerve conduction mechanisms (NCMs), named the gustatory-emotion coupling model and multiblock attention module (GECM-MBAM), is proposed to improve the performance of emotion identification. First, the 1/ f characteristics and synchronization of brain responses are reproduced in the GECM output when stimulated by EEG. The bionic performance of the model in EEG processing is validated, demonstrating brain-like perception of EEG signals via the GECM. Second, the MBAM is designed based on the characteristics of the GECM output, facilitating data augmentation of emotion-related EEG. Comparative experiments demonstrate that GECM-MBAM remarkably outperforms multiple existing DA models in recognition accuracy ( p < 0.05), confirming its effectiveness and superiority in EEG data augmentation. Finally, when compared with state-of-the-art algorithms and in ablation studies, GECM-MBAM demonstrates superior performance in emotion recognition. Specifically, GECM-MBAM attains accuracies of 96.91 % and 94.52 %, recalls of 96.23 % and 93.86 %, and kappa coefficients of 95.45 % and 94.29 % on the SEED and SEED-IV datasets, respectively. In conclusion, the performance of emotion identification is improved using the GECM-MBAM, offering a novel bionic processing approach for affective computing.},
  archive      = {J_ESWA},
  author       = {Wenbo Zheng and Yong Peng and Ancai Zhang and Quan Yuan},
  doi          = {10.1016/j.eswa.2025.129855},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129855},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unifying structural proximity and equivalence for enhanced dynamic network embedding. <em>ESWA</em>, <em>298</em>, 129854. (<a href='https://doi.org/10.1016/j.eswa.2025.129854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network embedding methods transform nodes in a dynamic network into low-dimensional vectors while preserving network characteristics, facilitating tasks such as node classification and community detection. Several embedding methods have been proposed to capture structural proximity among nodes in a network, where densely connected communities are preserved, while others have been proposed to preserve structural equivalence among nodes, capturing their structural roles regardless of their relative distance in the network. However, most existing methods that aim to preserve both network characteristics mainly focus on static networks and those designed for dynamic networks do not explicitly account for inter-snapshot structural properties. This paper proposes a novel unifying dynamic network embedding method that simultaneously preserves both structural proximity and equivalence while considering inter-snapshot structural relationships in a dynamic network. Specifically, to define structural equivalence in a dynamic network, we use temporal subgraphs, known as dynamic graphlets, to capture how a node’s neighborhood structure evolves over time. We then introduce a temporal-structural random walk to flexibly sample time-respecting sequences of nodes, considering both their temporal proximity and similarity in evolving structures. The proposed method is evaluated using five real-world networks on node classification where it outperforms benchmark methods, showing its effectiveness and flexibility in capturing various aspects of a network.},
  archive      = {J_ESWA},
  author       = {Suchanuch Piriyasatit and Chaohao Yuan and Ercan Engin Kuruoglu},
  doi          = {10.1016/j.eswa.2025.129854},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129854},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unifying structural proximity and equivalence for enhanced dynamic network embedding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised. <em>ESWA</em>, <em>298</em>, 129853. (<a href='https://doi.org/10.1016/j.eswa.2025.129853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of blockchain technology, the increasing number of cyber frauds has caused huge economic losses, prompting more and more researchers to focus on how to effectively detect criminal activities in the blockchain transaction environment. Currently, graph neural network (GNN)-based methods have made significant progress in the field of blockchain illegal transaction detection due to their advantages in extracting graph structure features. However, existing illegal transaction pattern detection methods usually rely on historical labeled data. In the blockchain transaction environment, transaction data changes over time, and it is often difficult to obtain transaction labels. As a result, the performance of these methods is often unsatisfactory when faced with newly distributed transaction data. To address this challenge, this paper proposes a dynamic graph neural network based on co-association of semi-supervised (CoSemiGNN) for more efficiently identifying illegal transactions in blockchain environments under conditions of dynamically changing transaction data. The model combines semi-supervised learning with a dynamic graph neural network, enabling it to effectively identify novel illegal transaction patterns from unlabeled data and adapt to the evolving blockchain network environment. Specifically, CoSemiGNN captures features of novel transactions by integrating semi supervised learning results. It utilizes co-occurrence relations of edges and co-occurrence feature aggregation of nodes to skillfully integrate semi-supervised methods into feature extraction of transaction graphs, enabling the model to extract novel illegal transaction patterns from unlabeled data. In addition, the model utilizes self attention recurrent neural networks (RNNs) to capture temporal information in transactions, ensuring the dynamics of CoSemiGNN. Finally, we theoretically analyze the model, and experiments on a real Bitcoin transaction dataset demonstrate that CoSemiGNN outperforms existing methods by as much as 30 % in terms of F1 scores for detecting illegal transactions when the transaction data undergoes distributional migration. This research compensates the problem that existing methods ignore the distributional changes of blockchain transaction data, and provides a new perspective and an effective solution for blockchain illegal transaction detection.},
  archive      = {J_ESWA},
  author       = {Yulong Wang and Qingxiao Zheng and Xuedong Li and Lingfeng Wang and Ling Lin},
  doi          = {10.1016/j.eswa.2025.129853},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129853},
  shortjournal = {Expert Syst. Appl.},
  title        = {CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy prototype transfer learning for non-overlapping cross-domain recommendation. <em>ESWA</em>, <em>298</em>, 129852. (<a href='https://doi.org/10.1016/j.eswa.2025.129852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation (CDR) offers an efficient and effective solution to mitigate data sparsity in recommender systems. Existing research primarily focuses on exploring knowledge transfer based on overlapping entities or auxiliary contents between domains. However, there is little research on the real non-overlapping cross-domain recommendation (NCDR) problems, even though it poses a more general and applicable prospect. The core challenge of NCDR lies in the difficulty of finding the correct and useful knowledge transfer bridge between domains without relying on the explicit overlapping identities. Utilizing the inherent similarity and fuzzy characteristics of users and items in the latent feature space, this paper investigates a Fuzzy Prototype Transfer (FPT) learning method for the NCDR problem. FPT jointly optimizes prototypes and individual features for both users and items in target domain under the guidance of source features. An end-to-end learnable fuzzy clustering module based on maximum entropy regularization is proposed to learn both user and item fuzzy clustering assignments and fuzzy fusion prototypes. Lastly, by constructing an asymmetric dual-prototype fuzzy transfer module, similar user and item features across domains are found and aligned effectively. Extensive experiments demonstrate FPT’s superior performance over the state-of-the-art methods while maintaining lower inference and memory costs than those of the baselines.},
  archive      = {J_ESWA},
  author       = {Ruxia Liang and Qinglin Huang and Xiaoxuan Shen},
  doi          = {10.1016/j.eswa.2025.129852},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129852},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fuzzy prototype transfer learning for non-overlapping cross-domain recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-based exploration and analysis of real-time and historical blockchain data. <em>ESWA</em>, <em>298</em>, 129851. (<a href='https://doi.org/10.1016/j.eswa.2025.129851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has revolutionized digital transactions and decentralized applications through its transparent and immutable ledger system, with platforms like Ethereum processing millions of transactions daily. However, as blockchain networks grow, traditional blockchain explorers show limitations when providing intuitive access to this vast data landscape, particularly when handling complex analytical queries, interpreting transaction patterns, and serving users without technical expertise. In this paper, we address these limitations by proposing an intelligent blockchain explorer that combines a Large Language Model (LLM)-powered agent for real-time blockchain interactions with a schema-aware SQL agent for historical data analysis. For real-time interactions, a dedicated blockchain agent connects to live networks through external APIs and specialized tools to process queries about current transactions and network states. When analyzing historical data patterns, we use an approach in which a Retrieval-Augmented Generation (RAG) system enhances the SQL agent’s understanding of the blockchain database schema and structure. This SQL agent subsequently translates natural language queries into SQL commands for efficient data retrieval from our periodically synchronized blockchain database. A query processor, powered by an LLM, intelligently routes user queries between these components based on temporal and contextual requirements, which enables both immediate blockchain state analysis and complex historical data querying. We evaluate our system on diverse blockchain queries, including complex analytical scenarios and multi-step operations. The experimental results demonstrate the effectiveness of our schema-aware SQL agent in accurate query translation and the overall system’s capability in handling both real-time and historical blockchain data exploration tasks.},
  archive      = {J_ESWA},
  author       = {S. Gebreab and A. Musamih and K. Salah and R. Jayaraman},
  doi          = {10.1016/j.eswa.2025.129851},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129851},
  shortjournal = {Expert Syst. Appl.},
  title        = {LLM-based exploration and analysis of real-time and historical blockchain data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion. <em>ESWA</em>, <em>298</em>, 129850. (<a href='https://doi.org/10.1016/j.eswa.2025.129850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis of online public opinion plays a vital role in understanding emotional dynamics on social media. However, most existing approaches focus on overall sentiment within text, often neglecting fine-grained sentiment information. This limitation restricts the depth of insights obtainable for public opinion monitoring. Aspect-based sentiment analysis (ABSA) addresses this issue by identifying sentiment toward specific aspects. Despite its advantages, current ABSA methods struggle to effectively integrate syntactic and sequential features, leading to incomplete contextual understanding. Additionally, noisy dependency trees introduce irrelevant syntactic features, which mislead sentiment classification and degrade accuracy. To address these challenges, we propose RL-DFN, a reinforcement learning-driven dual-view feature fusion network that enhances the robustness of ABSA models. RL-DFN consists of a dual-view feature fusion network and an actor-critic reinforcement learning module. The dual-view feature fusion network employs a graph attention network (GAT) to extract syntactic features and a transformer to capture sequential features. These complementary features are then fused through a bilinear affine transformation (Biaffine) module which captures fine-grained and bidirectional correlations between syntactic and sequential representations, enabling more expressive cross-view interactions. Simultaneously, an actor-critic reinforcement learning module dynamically refines the dependency tree representations by identifying key dependency types and filtering out noise, ensuring the reliability of syntactic features used in fusion. Extensive experiments on five widely used benchmark datasets demonstrate that RL-DFN significantly outperforms existing models, validating the effectiveness of our approach.},
  archive      = {J_ESWA},
  author       = {Ziheng Li and Kui Zhao},
  doi          = {10.1016/j.eswa.2025.129850},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129850},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode. <em>ESWA</em>, <em>298</em>, 129849. (<a href='https://doi.org/10.1016/j.eswa.2025.129849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing global demand for perishable agricultural products necessitates advancements in cold chain logistics. Cross-docking, known for its efficiency, is particularly well-suited for the transfer and distribution of such goods. However, truck scheduling at cold chain cross-dock terminals (CDTs) presents unique challenges, including product perishability, stringent time windows, and temperature-controlled environments. This work investigates a truck scheduling problem within a cold chain CDT, explicitly addressing uncertainties in refrigerated product damage (affecting supply) and repackaging times. A two-stage stochastic programming model is developed to capture these uncertainties. To solve this model, a scenario reduction approach employing K-means++ and K-medoids clustering is used, followed by Sample Average Approximation. Small-scale instances are solved optimally using CPLEX. For larger instances, a novel hybrid heuristic algorithm, combining the global search capabilities of Genetic Algorithms with the local search capabilities of Adaptive Large Neighborhood Search and Simulated Annealing, is proposed. Numerical experiments demonstrate the effectiveness of this algorithm, and sensitivity analysis provides valuable managerial insights.},
  archive      = {J_ESWA},
  author       = {Feifeng Zheng and Yuzhi Yi and Ming Liu and Huaxin Qiu},
  doi          = {10.1016/j.eswa.2025.129849},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129849},
  shortjournal = {Expert Syst. Appl.},
  title        = {Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem. <em>ESWA</em>, <em>298</em>, 129848. (<a href='https://doi.org/10.1016/j.eswa.2025.129848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a new variant of the Electric Vehicle Routing Problem (EVRP), termed the Clustered Electric Vehicle Routing Problem (CluEVRP). In CluEVRP, all customers are pre-divided into clusters, and each charging station is either located within a cluster or independent of any cluster. Each electric vehicle must complete service for all customers within the current cluster before proceeding to the next cluster or returning to the depot. Electric vehicles can charge at any available charging station while serving a cluster, but incur a penalty cost upon entering each cluster. The objective is to minimize the total logistics cost, comprising vehicle startup costs, cluster entry penalty costs, and energy consumption costs. To solve CluEVRP, a two-stage hybrid heuristic combining a Genetic Algorithm (GA) and Variable Neighborhood Descent (VND) is proposed (HGA-VND), where GA ensures population diversity and VND enhances local search capability. To evaluate the algorithm’s performance, 75 test instances are adapted from classic Clustered Vehicle Routing Problem (CluVRP) dataset, incorporating electric vehicle characteristics. Computational results demonstrate that HGA-VND consistently obtains high-quality solutions within reasonable time for both CluVRP and CluEVRP instances, exhibiting good performance. Furthermore, sensitivity analysis indicates that moderately increasing vehicle capacity, optimizing battery configuration, and adopting lightweight designs can significantly reduce total operating costs. This study extends traditional EVRP research by introducing clustered customer distribution, enriching solutions for routing problems in practical logistics networks, particularly for “milk run” models in industrial parks, and providing significant managerial insights.},
  archive      = {J_ESWA},
  author       = {Yuheng Jin and Xiaoguang Bao and Zhaocai Wang},
  doi          = {10.1016/j.eswa.2025.129848},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129848},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prior feature efficient diffusion model for 3D MRI image super-resolution improving brain connectomics analysis. <em>ESWA</em>, <em>298</em>, 129847. (<a href='https://doi.org/10.1016/j.eswa.2025.129847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is a non-invasive imaging technique used to study the internal structure and function of the human body, especially vital in the frontier exploration of brain science. However, due to hardware limitations and relatively thicker slices, the spatial resolution of MRI image is insufficient to meet the demands of clinical applications. Deep learning-based Super Resolution (SR) methods improve MRI image quality but often result in poor visual quality and over-smoothing. Diffusion-based SR methods can produce complex and perceptually appealing details, but require numerous diffusion steps. Besides, current SR model evaluations rely predominantly on quantitative metrics and visual inspection, yet remain disconnected from clinical integration. To alleviate above problems, this paper presents the Prior Feature Efficient Diffusion Model (PFEDiff) for 3D MRI image SR. To improve the generation efficiency, PFEDiff utilizes Resolution Disparity Maps (RDMs) as the target for the SR task. By incorporating rich prior features from low-resolution MRI through the Prior Information Embedding Module (PIEM), PFEDiff achieves precise SR and strong generalization capabilities. In addition, the designed residual attention noise predictor enables advanced noise prediction, thereby improving the overall performance of the model. The MRI images SR experimental results demonstrate that PFEDiff outperforms SOTA methods, and compared to baseline diffusion models, PFEDiff achieves more than 10 times faster sampling speed. To connect the quantitative metrics and clinical application, we apply PFEDiff to Brain Connectomics Analysis. The results of the brain connectomics experiment confirm the clinical application potential of the proposed method. Our code is publicly available at https://github.com/Rein592977/PFEDiff .},
  archive      = {J_ESWA},
  author       = {Renpeng Yao and Jinglong Du and Wenzong Peng and Hongbi Li and Jingbo Zhang and Du Lei and Yuanyuan Jia},
  doi          = {10.1016/j.eswa.2025.129847},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129847},
  shortjournal = {Expert Syst. Appl.},
  title        = {Prior feature efficient diffusion model for 3D MRI image super-resolution improving brain connectomics analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Group-guided prompt learning for vision-language models. <em>ESWA</em>, <em>298</em>, 129846. (<a href='https://doi.org/10.1016/j.eswa.2025.129846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has become one of the mainstream approaches for enabling Vision-Language Models (VLMs) to effectively adapt to downstream tasks. Recent approaches enhanced the generalization of models by integrating prior knowledge from large language models (LLMs). However, these approaches overlook the potential value of group knowledge derived from semantic correlations across different classes, which may limit the performance of the model in the face of complex downstream tasks. To overcome this challenge, we propose Group-guided Prompt Learning (GGPL) , which integrates group knowledge into the original text prompts through LLMs. Specifically, GGPL uses LLMs to group all classes and integrates the group knowledge into the original text prompts to construct the final text prompts. Furthermore, we introduce a novel Group Knowledge Alignment (GKA) module, which aligns the learnable prompt features with the pre-trained features that contain group knowledge, preventing the learnable prompt features from feature shift during the training process and thus reducing overfitting. Experimental results across 11 public datasets demonstrate that the proposed GGPL method achieves significant improvement on various prompt learning approaches, while numerous ablation experiments also demonstrate the effectiveness of the each component of our GGPL method.},
  archive      = {J_ESWA},
  author       = {Yufei Zheng and Shengsheng Wang and Yansheng Gao},
  doi          = {10.1016/j.eswa.2025.129846},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129846},
  shortjournal = {Expert Syst. Appl.},
  title        = {Group-guided prompt learning for vision-language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MTMP: Multimodal targeted molecule generation model with protein features. <em>ESWA</em>, <em>298</em>, 129845. (<a href='https://doi.org/10.1016/j.eswa.2025.129845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular generation is a fundamental task in computational chemistry and drug discovery, aiming to design molecular structures with specific properties through algorithmic approaches. Traditional molecular generation models predominantly rely on SMILES representations or molecular topological graphs, limiting their ability to comprehensively capture molecular characteristics. To address this limitation, we propose MTMP, a generative model that bridges molecular structure and sequence. It uses a graph neural network to encode topological features and a GRU decoder to generate SMILES strings. This integration enhances the joint modeling of chemical properties and structure. Furthermore, MTMP incorporates a pre-trained language model trained on large-scale protein sequence data to extract target protein features, enabling a direct and more precise encoding of protein-specific information. This facilitates the generation of molecules with enhanced binding affinity to specific protein targets. To further improve molecular design efficacy, the model was pre-trained on the ZINC molecular database and subsequently fine-tuned via transfer learning using a curated dataset of ligand molecules with known activity against specific target proteins. Experimental evaluations demonstrate that MTMP achieves competitive performance compared to state-of-the-art molecular generation methods. The model produces structurally valid and diverse molecules with favorable physicochemical properties and strong drug-likeness. Notably, it generates novel compounds with high docking scores against target proteins, underscoring its potential for de novo drug design and targeted molecular discovery.},
  archive      = {J_ESWA},
  author       = {Dingming Liang and Runfu Yu and Xiaofeng Wang and Kaiyu Dong and Yunjing Zhang and Huicong Liang and Ximing Xu and Tao Song and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129845},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129845},
  shortjournal = {Expert Syst. Appl.},
  title        = {MTMP: Multimodal targeted molecule generation model with protein features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments. <em>ESWA</em>, <em>298</em>, 129844. (<a href='https://doi.org/10.1016/j.eswa.2025.129844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to generate a composite image that simultaneously preserves thermal radiation information from infrared images and the rich texture details of visible images. However, existing studies have overlooked the adverse effects of scene degradation in visible images on the fusion process, leading to suboptimal fusion outcomes. To address the challenges posed by scene degradation in image fusion tasks, this paper proposes an image fusion network with degradation correction capability named the Enhancing Mixture-of-Experts model with Prior knowledge for infrared and visible image fusion (EMPFusion), which pioneers the automated execution of multiple degradation restoration tasks during the fusion process. First, we develop a diffusion model for degradation removal to generate high-quality pseudo-labels of visible images, thereby providing supervisory signals for training the fusion network. Second, to overcome the significant challenges in feature extraction caused by complex and diverse degradation scenarios, we design a Degradation removal backbone based on Prior knowledge and the Mixture-of-Experts (DPM) module. This architecture removes degradation with low loss and moderate computational overhead by integrating domain-specific prior knowledge and the Mixture-of-Experts framework. Furthermore, to mitigate semantic loss under extreme environmental conditions, we propose a Semantic Deconstruction and Segmentation (SDS) module based on image-text foundation models, enhancing semantic consistency throughout the fusion process. Extensive experiments demonstrate that EMPFusion excels in infrared-visible fusion tasks within complex degraded scenes. Across the LLVIP, M3FD, RoadScene, and MSRS datasets, EMPFusion achieves state-of-the-art (SOTA) performance on multiple evaluation metrics, showcasing exceptional degradation robustness and visual-semantic information preservation capabilities. By unifying adaptive degradation correction with fusion, this research addresses fusion distortion caused by degraded multimodal data in harsh environments, significantly enhancing applicability and robustness in downstream tasks such as autonomous driving and security monitoring.},
  archive      = {J_ESWA},
  author       = {Gang Li and Chengrun Jiang and Jiachen Li and Jin Wan and Mingle Zhou and Delong Han},
  doi          = {10.1016/j.eswa.2025.129844},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129844},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning. <em>ESWA</em>, <em>298</em>, 129843. (<a href='https://doi.org/10.1016/j.eswa.2025.129843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scenario building change detection (BCD) plays a crucial role in scientific decision-making for urban development, natural disasters, and war scenarios. Nevertheless, current research confronts several challenges: (1) In deep learning (DL) methods, convolutional neural networks (CNN) fail to capture global information, and transformer has high computational overhead. (2) The clear distinction and collaborative suppression of scene-level and data-level pseudo-changes remain unresolved. (3) Multi-scenario BCD remains under-explored. To address these challenges, this study proposes a dual pseudo-change suppression framework for multi-scenario BCD. The framework includes the novel C 2 Mamba DL model (CNN collaborates with Mamba) and the consistency enhancement learning strategy (CELS). Among them, the C 2 Mamba merges the local feature extraction capability of CNN with the efficient global modeling capability of Mamba. It further integrates the proposed progressive context information aggregation module (PCIA) and the multi-scale differential feature enhancement module (MDFE). These two modules enable the model to effectively distinguish building changes among various ground targets, thereby suppressing the scene-level pseudo-changes. The CELS first performs data augmentation on the post-temporal images, including weather (clouds, rain, and overcast) and sensor differences. Subsequently, a novel difference-focused loss function is designed to ensure the accurate alignment of the change features between the original and enhanced image pairs, thereby suppressing the data-level pseudo-changes. In experiments, the BCD performance of urban development, natural disasters, and war scenarios is evaluated using WHU-CD, xBD, and WraBCD datasets, respectively. Compared to the second-best methods, the proposed method achieves F1-score improvements of 1.36%, 2.69%, and 1.65%, and IoU improvements of 2.49%, 3.21%, and 2.32%, respectively. Additionally, numerous ablation experiments are conducted to validate the validity of the proposed method. And the robustness of the proposed method is verified through zero-shot generalization and few-shot testing.},
  archive      = {J_ESWA},
  author       = {Wei Li and Guorui Ma and Haiming Zhang and Peng Chen and Di Wang and Rong Chen},
  doi          = {10.1016/j.eswa.2025.129843},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129843},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Software defect prediction based on graph code semantics. <em>ESWA</em>, <em>298</em>, 129842. (<a href='https://doi.org/10.1016/j.eswa.2025.129842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software systems become larger and more complicated, researchers are focusing more on how to effectively determine whether a program is flawed. Convolutional neural networks (CNNs) have been employed by several researchers in recent years to extract latent semantic information based on Abstract Syntax Trees (AST). However, the small granularity of code information in AST makes it easy to focus on local information and difficult to capture global semantic information. Further, ASTs lack control flow and data flow edges to fully utilize the code’s contextual semantic information. In this paper, we obtain the Control Flow Graph (CFG) and Program Dependence Graph (PDG) of a program through the improved TinyPDG. The Continuous Bag-of-Words (CBOW) model is utilized to train the corpus of CFG and PDG. Additionally, an improved PNIAT layer that combines multi-head attention and BiLSTM is employed to obtain method-level semantic feature vectors. Subsequently, methods based on weighted summation and linear fully connected are respectively proposed to aggregate method-level semantic feature vectors into file-level semantic feature vectors. The joint features are then constructed in combination with the hand-labeled features. Finally, after balancing the data using the SMOTETomek method, 11 machine learning models are used as classifiers for defect prediction. The experimental findings demonstrate that, compared to current software defect prediction techniques, the PDG using a weighted summation-based approach in the QDA model (W-PDG-QDA) presented in this research is the best, and improves AUC, F1, and accuracy scores by 0.723 % -21.72 %, 5.18 % -55.25 % and 1.99 % -25.16 %.},
  archive      = {J_ESWA},
  author       = {Hongwei Tao and Tao Wang and Zhenhao Geng and Xiaoxu Niu and Qiaoling Cao},
  doi          = {10.1016/j.eswa.2025.129842},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129842},
  shortjournal = {Expert Syst. Appl.},
  title        = {Software defect prediction based on graph code semantics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). G-GraphTST: Spatiotemporal learning for multivariate long-term photovoltaic power forecasting. <em>ESWA</em>, <em>298</em>, 129841. (<a href='https://doi.org/10.1016/j.eswa.2025.129841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clean energy systems, the importance of photovoltaic power forecast (PVPF) has become increasingly prominent. In China, the proactive management and control of distributed photovoltaic systems in rural areas have gained policy priority, aiming optimize the integration of photovoltaic energy through multi-node long-term PVPF. However, existing studies face significant challenges in effectively modeling spatiotemporal correlations at different perceptual levels and frequently overlook the interactive learning between spatial and temporal dependencies. To address these limitations, we propose a Global-Embedding Graph-Encoder Time Series Transformer (G-GraphTST 1 ) for solar power forecasting, which features an interactive learning framework comprising spatial and temporal modules to downsample solar data and capture spatiotemporal correlations from multi-level perceptual perspectives. Temporally, the framework compresses high-dimensional raw time-series data into more semantically meaningful 1D local feature representations and introduces learnable global embeddings that interact with all patch embeddings via the self-attention mechanism in the Transformer encoder to capture the periodicity and trends of photovoltaic systems. Spatially, it employs a learnable graph constructor that uses the spatiotemporal heterogeneity of photovoltaic power data in the current batch as query conditions to dynamically reveal the transient power correlations and dependencies between power stations in the photovoltaic network in real time. Extensive experiments on solar datasets and multiple other benchmark datasets demonstrate that GraphTST outperforms existing mainstream methods in performance and exhibits strong generalizability, providing critical support for optimizing smart grid scheduling and managing large-scale photovoltaic power plants.},
  archive      = {J_ESWA},
  author       = {Wentao Zheng and Weixing Qian and Pengyu Liu and Rongzhe Wu and Mingjia Chen and Houchen Zhou},
  doi          = {10.1016/j.eswa.2025.129841},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129841},
  shortjournal = {Expert Syst. Appl.},
  title        = {G-GraphTST: Spatiotemporal learning for multivariate long-term photovoltaic power forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantifying expressive power in knowledge graph embeddings: An entropy-based metric framework. <em>ESWA</em>, <em>298</em>, 129840. (<a href='https://doi.org/10.1016/j.eswa.2025.129840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) is a mainstream technique for the knowledge completion (KGC) task and has attracted significant attention. However, there is a lack of a quantitative evaluation framework to measure the expressive power of KGE models, which is important for model selection and design in downstream applications. Specifically, existing metrics inadequately assess the expressive power of these models because they focus solely on learning outcomes rather than on the embeddings or datasets themselves, which have a significant influence on performance. To address this gap, we propose a novel framework, the Dense Feature Model (DFM), grounded in information theory, to enhance our understanding of KGE. This framework offers three key insights regarding embedding-based KGC (eKGC) approaches: (1) the expressive power of an eKGC model can be quantified using entropy, enabling straightforward model comparison based on a value computed solely from the numbers of entities and relations; (2) the DFM metrics indicate how far an eKGC model is from its theoretical limitations and how much potential improvement remains, as demonstrated by propositions proven in this work; and (3) as a significant byproduct, the framework elucidates why and how a model balances expressive power and computational cost. Furthermore, the framework may be transferable to other relational data processing domains.},
  archive      = {J_ESWA},
  author       = {Panfeng Chen and Hui Li and Qi Wang and Xin Zhou and Xibin Wang},
  doi          = {10.1016/j.eswa.2025.129840},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129840},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantifying expressive power in knowledge graph embeddings: An entropy-based metric framework},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Legend-KINN: A legendre polynomial-based Kolmogorov–Arnold-informed neural network for efficient PDE solving. <em>ESWA</em>, <em>298</em>, 129839. (<a href='https://doi.org/10.1016/j.eswa.2025.129839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have become a widely used method in scientific machine learning for solving partial differential equation (PDE) problems. However, existing PINN methods, while adhering to physical constraints during the convergence process, often suffer from a lack of interpretability in the nonlinear mapping between inputs and outputs during forward propagation. Additionally, fixed activation functions and soft constraint mechanisms result in poor training stability and high computational costs. To address these challenges, we propose a Legendre Polynomial-Based Kolmogorov–Arnold-Informed Neural Network (Legend-KINN), which explicitly enhances physical consistency through Legendre orthogonal polynomials and optimizes the backpropagation path using pseudo-time stepping methods to improve training stability. The use of Legendre polynomials improves the physical interpretability of the model while maintaining strict adherence to physical constraints. Experimental results demonstrate that Legend-KINN outperforms standard Multi-Layer Perceptron (MLPs) and Kolmogorov–Arnold Network (KAN) in terms of both accuracy and computational efficiency, achieving faster convergence with fewer parameters across 25 datasets from three classical computational fluid dynamics cases. Code is available at: https://github.com/zhang-zhuo001/Legend-KINN},
  archive      = {J_ESWA},
  author       = {Zhuo Zhang and Xiong Xiong and Sen Zhang and Wei Wang and Yanxu Zhong and Canqun Yang and Xi Yang},
  doi          = {10.1016/j.eswa.2025.129839},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129839},
  shortjournal = {Expert Syst. Appl.},
  title        = {Legend-KINN: A legendre polynomial-based Kolmogorov–Arnold-informed neural network for efficient PDE solving},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel grey possibility clustering method based on inverse perspective and its applications. <em>ESWA</em>, <em>298</em>, 129837. (<a href='https://doi.org/10.1016/j.eswa.2025.129837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The center-point mixed possibility functions (CMPFs), which are determined by the decision makers qualitatively, are the most important element to obtain the effective clustering results in a grey clustering model. However, different decision makers provide different CMPFs which may lead to inconsistent or contradictory clustering results. In response to this problem, this article proposes an inverse grey possibility clustering model which can determine the CMPFs based on the part of the given final results. This novel matrix-based method can derive all of the required CMPFs which satisfy the partially known clustering results. More specifically, four theorems are put forward to analyze the four different cases, which are single index single object (SISO), single index multiple objects (SIMO), multiple indices single object (MISO) and multiple indices multiple objects (MIMO), respectively, to derive the required CMPFs of a given clustering result using algebraic expressions. For the purpose of developing the matrix representations for the MISO and MIMO situations, a new unified expression of the CMPFs to replace their existing segmented function expression is proposed. Finally, in order to demonstrate how it can be used in practice, the proposed method is applied for evaluating the effects of the reduction of pollution and carbon emissions and determining aerospace equipment component suppliers with different types of data. Compared to the forward GPC models, the proposed IGPC model has higher accuracy.},
  archive      = {J_ESWA},
  author       = {Junjie Wang and Xun Li and Yaoguo Dang and Zhongju Shang and Li Ye and Sifeng Liu},
  doi          = {10.1016/j.eswa.2025.129837},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129837},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel grey possibility clustering method based on inverse perspective and its applications},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing semantic and structural decoding for fMRI-to-image reconstruction. <em>ESWA</em>, <em>298</em>, 129836. (<a href='https://doi.org/10.1016/j.eswa.2025.129836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing visual images from fMRI signals is an enticing task that opens new horizons in understanding the intricate workings of human cognition. Most existing methods benefit from the diffusion model to decode high-level semantic information from fMRI signals, achieving promising semantic reconstruction. However, such a solution ignores low-level structure information, e.g. , object location and color, leading to an uncompleted visual reconstruction. In this work, we present a novel fMRI-to-image approach to reconstruct high-quality images by balancing semantic and structural decoding in the diffusion model. Specifically, we first utilize the CLIP model and an MLP module to extract sufficient semantic information and structural details, respectively. Then we design a S emantic and S tructural A wareness B alanced module ( SSAB ) to predict the weight of structural information for the current denoising step, thus generating high-quality images by gradually integrating semantic and structural information during image reconstruction. Experimental results demonstrate that the proposed SSAB model is effective with only a few extra parameters, it achieves state-of-the-art performance in comprehensively evaluating both semantic and structural metrics. All code is available on https://github.com/Venchy-he/SSAB .},
  archive      = {J_ESWA},
  author       = {Wanqi He and Jin Wang and Hui Li and Hanyang Chi and Bingfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129836},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129836},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing semantic and structural decoding for fMRI-to-image reconstruction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis. <em>ESWA</em>, <em>298</em>, 129835. (<a href='https://doi.org/10.1016/j.eswa.2025.129835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-frequency (t-f) signal processing techniques are particularly advantageous for induction motor (IM) fault diagnosis under dynamic and variable industrial operating conditions. Broken rotor bar (BRB) faults remain among the most challenging to detect because of their proximity to the fundamental frequency and significantly lower amplitude in comparison. Additionally, traditional approaches often result in false positives or negatives in scenarios involving load variation, power quality issues, and inverter-fed operations. To address these issues, this work proposes a comprehensive and objective methodology to evaluate eight Cohen-Class Bilinear Distributions (CCBD) to diagnose BRB. CCBDs offer high-resolution t-f representations, a crucial advantage for fault identification. However, their use is limited by cross-terms, nonlinear artifacts inherent to bilinear processing. To overcome this limitation, convolutional neural networks (CNNs) are applied to automatically classify t-f images and identify the CCBD methods that effectively minimize the cross-terms while preserving fault signature harmonics. This strategy also avoids subjective and time-consuming visual inspections. In addition, this work proposes a novel CNN architecture with an attention module (CNN-Attention), designed to enhance performance in this context. The evaluation considers challenging conditions, including 1) line-fed and 2) inverter-fed operation, 3) voltage unbalance, and 4) load oscillations, applied to a 2 HP, 60 Hz motor. Generalization capability is validated with data collected from a different laboratory, using an independent 1 HP, 50 Hz motor and five different inverter models. Experimental results show that combining CNN-Attention with CCBDs enables highly accurate and fast classification, achieving approximately 96% accuracy even when trained and tested on distinct laboratory datasets, demonstrating the effectiveness and adaptability of the proposed method.},
  archive      = {J_ESWA},
  author       = {Avyner L.O. Vitor and Alessandro Goedtel and Wesley A. Souza and Marcelo F. Castoldi and Daniel Morinigo-Sotelo and Oscar Duque-Perez},
  doi          = {10.1016/j.eswa.2025.129835},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129835},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven spatio-temporal driving risk field mechanism for path planning. <em>ESWA</em>, <em>298</em>, 129834. (<a href='https://doi.org/10.1016/j.eswa.2025.129834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing the future risk posed by surrounding human-driven vehicles is crucial for enhancing the safety of autonomous vehicles. Existing risk field methods build spatiotemporal risk fields using mathematical models with fixed parameters, making them struggle to capture dynamic human driving behaviors such as frequent acceleration, deceleration or lane changes, and are prone to overlooking rare but critical sudden events, which leads to unstable risk assessments in complex long-term scenarios. To address the aforementioned issues, a data-driven spatio-temporal risk field framework is proposed, which builds on a Bidirectional Deep Ultra-Gated Recurrent Unit (BDUGRU) to capture the high-dimensional spatio-temporal features of nearby vehicles and precisely predict vehicle distribution patterns over extended horizons. The introduced approach manages to yield a more accurate risk field and significantly improves long-term risk assessment in complex traffic environments. Furthermore, to validate the model’s practicality in engineering, we integrated Rapidly-exploring Random Tree with spatiotemporal data-driven risk field (SRF-RRT) and conducted path-planning simulations for autonomous vehicles using real-world traffic data. The results demonstrate that the proposed model excels in both prediction accuracy and reliability, and effectively reduces the measurement error based on collision time (TTC), offering strong applicability and providing a novel theoretical foundation and technological route for path planning in intelligent connected vehicles (ICVs).},
  archive      = {J_ESWA},
  author       = {Zhuoer Wang and Baohan Shi and Jianping Zhang and Xiaowen Zhu and Jian Zhou and Bingrong Xu and Bijun Li},
  doi          = {10.1016/j.eswa.2025.129834},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129834},
  shortjournal = {Expert Syst. Appl.},
  title        = {A data-driven spatio-temporal driving risk field mechanism for path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds. <em>ESWA</em>, <em>298</em>, 129833. (<a href='https://doi.org/10.1016/j.eswa.2025.129833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid detection and assessment of potholes are critical for ensuring road traffic safety. However, point cloud-based techniques relying on surveying vehicles or drones are often expensive and may be limited by roadside obstruction or narrow roadways. This study proposes a novel approach for assessing road potholes using point cloud data collected by smartphone LiDAR. The method integrates the Point Pothole-Specialized Segmentation Network (PointPSSN), a lightweight point cloud segmentation model designed to achieve high accuracy with low parameter complexity and rapid inference, together with scale-adjustable voxelization for assessment. The PointPSSN model incorporates a Geometric Feature Encoder module to capture the geometric attributes of potholes by extracting local geometric features. Neighbor Finder module identifies and aggregates neighboring points that provide more significant information. Experiments were conducted using a smartphone LiDAR device within a 7.28 km 2 area of Wuchang District, Wuhan, China, encompassing diverse road conditions. A dataset of 1040 potholes was constructed for model training and evaluation. The results demonstrate that the PointPSSN model achieves a segmentation accuracy of 97.336 %, precision of 91.322 %, recall of 79.888 %, an F1-score of 85.223 %, and an intersection-over-union (IoU) of 74.251 %. Notably, the accuracy, F1-score, and IoU surpass the performance of state-of-the-art models by 0.233 %, 1.336 %, and 2.006 %, respectively. In terms of efficiency, PointPSSN requires only one-seventh of the FLOPs and one-fifteenth of the parameters of state-of-the-art models, while achieving an 18.37 % faster inference speed. Furthermore, the average relative errors in depth and volume assessment using voxelization methods are 9.08 % and 9.04 %, respectively.},
  archive      = {J_ESWA},
  author       = {Tingrui Zhang and Xuequan Zhang and Zichuan Yang and Yumin Chen and Li Song and Weichen Zhang},
  doi          = {10.1016/j.eswa.2025.129833},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129833},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PAD: Popularity-aware debiasing for high-value item recommendation. <em>ESWA</em>, <em>298</em>, 129830. (<a href='https://doi.org/10.1016/j.eswa.2025.129830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems play a crucial role in our daily lives. However, in the context of high-value item recommendation, they face significant challenges. Due to the high price of these items, user purchase histories are often extremely sparse, making it difficult for recommender systems to accurately capture user preferences. Consequently, they tend to over-rely on popularity information. Moreover, the high-value item market exhibits a pronounced imbalanced distribution, where most user interactions focus on popular items. As a result, traditional recommender systems tend to prioritize these items while rarely recommending less popular ones, leading to low recommendation coverage. To address this challenge, we propose a P opularity- A ware D ebiasing (PAD) model, which improves recommendation coverage in high-value item scenarios without compromising accuracy. First, we employ soft prompts to guide a pre-trained language model (PLM) in enriching user representations. By incorporating semantic knowledge from the PLM, our model captures more comprehensive user preferences, ensuring recommendation accuracy while mitigating the model’s dependence on popularity signals. Building upon this, we apply popularity-aware debiasing to reduce overfitting and enhance coverage. PAD prevents the recommendation model from indiscriminately recommending the most popular items to all users, encouraging it to explore a wider range of items in its recommendations. Experiments conducted on industrial and public datasets demonstrate that our method mitigates popularity bias, significantly improving item recommendation coverage while maintaining accuracy.},
  archive      = {J_ESWA},
  author       = {Yuchen Zheng and Dongming Zhao and Xiangrui Cai and Yanlong Wen and Xiaojie Yuan},
  doi          = {10.1016/j.eswa.2025.129830},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129830},
  shortjournal = {Expert Syst. Appl.},
  title        = {PAD: Popularity-aware debiasing for high-value item recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection. <em>ESWA</em>, <em>298</em>, 129829. (<a href='https://doi.org/10.1016/j.eswa.2025.129829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-resolution remote sensing change detection (CD) is a critical task in various applications, including urban monitoring, environmental changes, and disaster management, where images captured at different times often possess varying spatial resolutions. Current methods typically address this by resampling low-resolution (LR) images to high-resolution (HR) formats, but such image-level strategies lead to significant artifacts and misalignment in the change map. These imperfections not only reduce detection accuracy but also lead to misleading or false change identifications, resulting in incorrect or incomplete conclusions in time-sensitive applications, such as land-use change detection or disaster monitoring. To address these challenges, we propose the Hierarchical Window Aggregate Network(HWA-Net), a novel framework that directly operates on cross-resolution image pairs without preprocessing, aiming to accurately aggregate cross-resolution representations for robust CD. HWA-Net initially employed window-based feature extraction to produce scale-independent representations, subsequently transferring these features to layered decoding. This process effectively enhances detection accuracy across diverse resolutions. Our approach establishes new state-of-the-art results on three synthesized datasets and one real-world cross-resolution change detection dataset.},
  archive      = {J_ESWA},
  author       = {Hualin Yang and Boran Ren and Zhijun Yang and Jing Xiong and Xiying Li and Calvin Yu-Chian Chen},
  doi          = {10.1016/j.eswa.2025.129829},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129829},
  shortjournal = {Expert Syst. Appl.},
  title        = {HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). KAN-MoDTI: Drug target interaction prediction based on kolmogorov-arnold network and multimodal feature fusion. <em>ESWA</em>, <em>298</em>, 129828. (<a href='https://doi.org/10.1016/j.eswa.2025.129828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-target interaction (DTI) prediction is a crucial task in computational drug discovery and repurposing, as it accelerates candidate identification while reducing development costs. Despite the advancements in deep learning, existing methods still face challenges in effectively modeling multi-modal data, fusing heterogeneous features, and capturing complex nonlinear relationships. We propose KAN-MoDTI to tackle these challenges by integrating Kolmogorov-Arnold Networks (KAN) with multimodal feature fusion and adaptive gating mechanisms, effectively combining heterogeneous drug and target representations to better capture the complex interactions between them. In the feature encoding stage, we use a dual-branch approach: For drugs, we combine SMILES sequence embeddings with structural representations from a KAN-based graph encoder. For targets, we integrate N-gram sequence embeddings with biochemical descriptor features. In the feature fusion stage, we introduce the FeatureFusionKAN module, which uses a gating mechanism to assign adaptive weights and KAN to perform the integration of heterogeneous modal features. KAN is also utilized in the final prediction layer to enhance the model’s ability to accurately predict complex drug-target interactions. Comprehensive experiments on datasets such as DrugBank, BindingDB, and Human show that KAN-MoDTI consistently outperforms or matches recent state-of-the-art baselines across metrics like AUROC and AUPRC.The source code implementation can be found at: https://github.com/jiahaoxin/KAN-MoDTI .},
  archive      = {J_ESWA},
  author       = {Hui Liu and Haoxin Jia and Wenze Li and Wei Li and Yuting Yuan},
  doi          = {10.1016/j.eswa.2025.129828},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129828},
  shortjournal = {Expert Syst. Appl.},
  title        = {KAN-MoDTI: Drug target interaction prediction based on kolmogorov-arnold network and multimodal feature fusion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GRDGNN: A directed graph neural network framework for multi-relational inference of gene regulatory networks. <em>ESWA</em>, <em>298</em>, 129827. (<a href='https://doi.org/10.1016/j.eswa.2025.129827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring gene regulatory networks (GRNs) from gene expression data is a central challenge in systems biology. Graph neural networks (GNNs) offer a promising approach due to their ability to process graph-structured data. However, existing GNN methods for GRN inference often treat the problem as binary classification, limiting their ability to capture comprehensive regulatory relationships. This paper introduces two learning algorithms that utilize an end-to-end gene regulatory directed graph neural network (GRDGNN) schema for efficient inference of causal relationships in large-scale networks. These algorithms incorporate a directed graph neural network (DGNN) and a graph multi-classification task to identify explicit interactions between transcription factors (TFs) and target genes. The proposed approach consists of four key steps: (1) constructing a directed initial network using regression Pearson correlation and mutual information analysis, (2) extracting subgraphs of observed TF-gene pairs and applying a DGNN for information aggregation, (3) projecting the aggregated information into a low-dimensional space using graph pooling to generate graph representations of TF-gene pairs, and (4) classifying subgraphs using a multilayer perceptron (MLP) for link prediction and inference of explicit regulatory relationships. Evaluation of the DREAM5 microarray and scRNA-seq datasets demonstrates that our transductive and inductive learning methods can accurately and effectively infer explicit regulatory relationships compared to benchmark methods. These results demonstrate that the proposed GRDGNN schema exhibits strong generalization across species, data types, and modalities in cross-species, cross-data type, and cross-modality learning.},
  archive      = {J_ESWA},
  author       = {Wanhong Zhang and Zhenyu Guo},
  doi          = {10.1016/j.eswa.2025.129827},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129827},
  shortjournal = {Expert Syst. Appl.},
  title        = {GRDGNN: A directed graph neural network framework for multi-relational inference of gene regulatory networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy. <em>ESWA</em>, <em>298</em>, 129826. (<a href='https://doi.org/10.1016/j.eswa.2025.129826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate photovoltaic (PV) power prediction under complex meteorological conditions remains challenging, particularly given the pronounced seasonal variations that obscure generation patterns. This study presents a novel ultra-short-term prediction framework integrating meteorological volatility analysis with seasonal characteristic modeling. We developed a specialized multi-channel Gram angular summation field (MGASF) transformation matrix to holistically capture meteorological fluctuations, subsequently leveraging denoising diffusion probabilistic model (DDPM) for strategic augmentation of under-represented weather scenarios to enhance similar-day identification. Our hybrid architecture combines multi-channel vision Transformer (VIT) with bidirectional long and short-term memory (BILSTM) networks to synergistically analyze temporal dependencies and spatial patterns in PV similarity recognition. Furthermore, we engineered a seasonal-adaptive prediction system through an improved variable-weight Smooth L1 loss function, establishing an optimized seasonal alignment mechanism that achieves high-precision prediction across varying meteorological conditions with minimal computational overhead. Through rigorous validation using operational data from a utility-scale photovoltaic cluster in Western Inner Mongolia, the proposed method achieved consistent accuracy improvements: 3.02 % reduction in N RMSE , 1.65 % decrease in N MAE , and 2.19 % enhancement in R 2 compared to baseline approaches in PV cluster. These statistically significant enhancements demonstrate our framework’s capability to mitigate seasonal impacts while maintaining prediction reliability in complex meteorological environments.},
  archive      = {J_ESWA},
  author       = {Mao Yang and Yue Jiang and Yunfeng Guo and Jianfeng Che and Wei He and Kang Wu},
  doi          = {10.1016/j.eswa.2025.129826},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129826},
  shortjournal = {Expert Syst. Appl.},
  title        = {Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Segmentation, fusion, and representation: A novel approach to multi-label classification for long texts. <em>ESWA</em>, <em>298</em>, 129825. (<a href='https://doi.org/10.1016/j.eswa.2025.129825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification (MLTC) is a vital task in natural language processing (NLP), often requiring high-quality text representations generated by pre-trained language models (PLMs). However, the inherent input length constraints of PLMs limit their capacity to handle long texts effectively. To address this challenge, we propose an innovative framework for multi-label long text classification. Our approach incorporates a dynamic text segmentation algorithm that optimally partitions long texts, thereby mitigating the input length limitations of PLMs. Additionally, we enhance both text and label representations by integrating external knowledge, modeling label co-occurrence relationships, and employing attention mechanisms. Extensive experiments conducted on diverse MLTC datasets demonstrate the superior performance of our method and uncover intricate relationships between texts and their associated labels. The code is available at https://github.com/Coder-Jeffrey/SKFRL},
  archive      = {J_ESWA},
  author       = {Xin Wang and Junfeng Xiao and Wang Zhang and Tao Deng and Qian Wang},
  doi          = {10.1016/j.eswa.2025.129825},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129825},
  shortjournal = {Expert Syst. Appl.},
  title        = {Segmentation, fusion, and representation: A novel approach to multi-label classification for long texts},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced multi-scale TCN ensemble for component chain prediction using evolutionary algorithms. <em>ESWA</em>, <em>298</em>, 129824. (<a href='https://doi.org/10.1016/j.eswa.2025.129824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In software engineering, component-based development has gained significant traction due to its ability to enhance efficiency and reusability, especially as the complexity of software projects increases. A core aspect of this paradigm is component chain prediction, which intelligently infers subsequent components based on historical usage sequences, effectively reducing redundant development efforts. To overcome limitations in existing methods regarding temporal feature capture and hyperparameter optimization, we propose an Evolution algorithm-enhanced Temporal Convolutional Network ensemble model (E-TCN). This approach integrates the convolutional structure of TCN with the sequential processing capabilities of GRU and employs a dynamic threshold mechanism to improve temporal feature capture and generalization performance. Additionally, we construct a hybrid evolutionary search framework, combining the strengths of four optimization algorithms—Artificial Bee Colony (ABC), Ant Colony Optimization (ACO), Black Widow Optimization Algorithm (BWOA), and Grasshopper Optimization Algorithm (GOA)—for efficient parameter space exploration. Experimental results on real-world development datasets demonstrate a 5.9 % improvement in F1 score compared to conventional TCN models, underscoring the efficacy and practical applicability of the proposed approach in component chain prediction.},
  archive      = {J_ESWA},
  author       = {Wen Qin and Peiyang Wei and Tong Peng and Hongping Shu and Zhuoning Zhao},
  doi          = {10.1016/j.eswa.2025.129824},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129824},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced multi-scale TCN ensemble for component chain prediction using evolutionary algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings. <em>ESWA</em>, <em>298</em>, 129823. (<a href='https://doi.org/10.1016/j.eswa.2025.129823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) is a critical task in high-dimensional data processing, aiming to identify the most discriminative subset of features to improve model performance and reduce computational complexity. In recent years, multi-objective evolutionary algorithms have been widely applied to FS problems due to their ability to simultaneously optimize multiple objectives (i.e., classification accuracy and subset size for an FS problem). However, when dealing with large-scale multi-objective FS problems, existing algorithms often suffer from the vast search space and limited search capability, which makes them prone to local optima. To address these challenges, this paper proposes a two-stage evolutionary algorithm guided by dual feature weightings, named TSEA/DFW. In the first stage, an evolutionary search is performed under the guidance of the filter-based feature weighting strategy. The key features are then identified based on the population distribution and optimal solutions, thereby shrinking the search space. In the second stage, a refined search is conducted in the shrunken feature space to boost search efficiency and solution quality. To this end, a novel weighting strategy named Pareto-based hierarchical feature weighting is proposed, which captures the variation in feature performance across different non-dominated levels, reinforces the contribution of high-quality solutions, and preserves useful information from suboptimal solutions. Additionally, a novel offspring reproduction procedure guided by stage-specific feature weights is designed to further enhance search capability. Experimental results on 13 real-world datasets show that the proposed TSEA/DFW performs best on 10 datasets in terms of HV metric and on 11 datasets in terms of IGD, demonstrating the significant superiority of TSEA/DFW over seven state-of-the-art feature selection methods. The performance improvements stem from the two-stage evolutionary framework guided by dual feature weighting, which enables the early identification of important features, thereby effectively reducing the search space and enhancing search efficiency. In addition, further analysis demonstrates that the proposed TSEA/DFW has strong generality across diverse classifiers, and the developed two-stage evolutionary framework in TSEA/DFW is a general powerful framework that can integrate any mainstream FS algorithm into its second stage, exhibiting robust applicability and scalability.},
  archive      = {J_ESWA},
  author       = {Gaohui Li and Zefeng Chen and Yuren Zhou and Zhengxin Huang and Xiaoyun Xia},
  doi          = {10.1016/j.eswa.2025.129823},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129823},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-temporal ensemble for few-shot action recognition. <em>ESWA</em>, <em>298</em>, 129821. (<a href='https://doi.org/10.1016/j.eswa.2025.129821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Action Recognition (FSAR) aims to recognize novel action classes with only a few labeled samples. Due to the scarcity of labeled data, FSAR models suffer from high variance and low confidence. To address this issue, this paper first introduces ensemble learning into the field of FSAR, leveraging the diversity among multiple temporal action representations to generate base models. Specifically, we propose a Multi-Temporal Ensemble (MTE) method for FSAR. By combining sub-sequences of video frames of various lengths (i.e., tuples), MTE creates multiple sets of action representations and generates base models based on these representations. All base models share a single embedding network to learn frame-level features. The proposed method adaptively captures temporal relations with different lengths and speeds while avoiding the computational cost of training multiple deep neural networks. Furthermore, we introduce a Short-term Temporal Modeling Module (STMM) that uses self-attention to highlight frames with high variation, enhancing short-term temporal representation at the frame level. The proposed method has been validated on four benchmark datasets. Extensive experimental results demonstrate that MTE outperforms 26 state-of-the-art FSAR methods. The source code is available at https://github.com/CharmainCahill/MTE.git .},
  archive      = {J_ESWA},
  author       = {Zhen Jiang and Jianlong Sun and Haodong Liu and Haizhen Guan},
  doi          = {10.1016/j.eswa.2025.129821},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129821},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-temporal ensemble for few-shot action recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation. <em>ESWA</em>, <em>298</em>, 129820. (<a href='https://doi.org/10.1016/j.eswa.2025.129820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure-based drug design (SBDD) focuses on developing 3D ligand molecules that bind with high affinity to specific protein targets, which requires the accurate capture of the complex interactions between proteins and ligands. Although existing diffusion models have demonstrated potential in molecular generation tasks, they typically consider only a single stage of the generation process. This limitation prevents them from integrating the multi-stage protein-ligand interaction information from both forward and reverse processes, which may negatively impact the binding affinity of the generated molecules. To address this problem, MSIDiff ( M ulti- S tage I nteraction-Aware Diff usion Model), a multi-stage interaction-aware diffusion model for protein-specific molecule generation, is proposed. MSIDiff leverages the pre-trained model MSINet to extract authentic protein-ligand interaction information during the initial diffusion stage and incorporates this information into the reverse process to ensure that the generated molecules accurately interact with target proteins. Through a scoring mechanism, MSIDiff filters key nodes to extract crucial protein-ligand interaction data and employs a GRU-based cross-layer interaction update module to recursively integrate information across different denoising stages, facilitating effective cross-layer information transmission. Experimental results on the CrossDocked2020 dataset show that MSIDiff can generate molecules with more realistic 3D structures and higher binding affinity to protein targets, achieving an Avg. Vina Score of up to -6.36, while maintaining appropriate molecular properties.Our code and data are available at: https://github.com/zhangyaoxiang/MSIDiff .},
  archive      = {J_ESWA},
  author       = {Yaoxiang Zhang and Junteng Ma and Ze Zhang and Zhaoyang Dong and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129820},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129820},
  shortjournal = {Expert Syst. Appl.},
  title        = {MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github. <em>ESWA</em>, <em>298</em>, 129819. (<a href='https://doi.org/10.1016/j.eswa.2025.129819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across numerous application scenarios in Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated exceptional capabilities in text comprehension and generation. These models exhibit significant potential across various interdisciplinary fields. However, their effectiveness is somewhat constrained by the unique characteristics of the open-source ecosystem. Developing an LLM with generalization capabilities across datasets and tasks, specifically tailored for the open-source ecosystem, is an urgent research need. To address this challenge, this paper introduces open-source atomic tasks, which are defined as intermediate tasks essential for solving complex objectives. These tasks are designed through strategies such as simplification, reversal, decomposition, and composition, enabling models to gradually acquire domain knowledge and understand task interdependencies. By integrating public resources with open-source atomic tasks, we construct OSE-Instruct–an instruction dataset for the open-source ecosystem. We first unify open-source atomic tasks within an instruction-tuning paradigm that reflects real-world developer behavior, and develop OSATG-GPT at various parameter scales by fine-tuning the BLOOMZ backbone model on OSE-Instruct. This enables the model to learn fine-grained developer actions and the underlying task dependencies. Extensive experiments validate the effectiveness of OSATG-GPT compared to other advanced LLMs with larger parameter scales, and highlight its advantages over GPT-4 in specific and complex open-source collaboration tasks.},
  archive      = {J_ESWA},
  author       = {Fanyu Han and Li Ma and Fenglin Bi and Yantong Wang and Mingdong You and Wei Wang and Jiaheng Peng and Xiaoya Xia},
  doi          = {10.1016/j.eswa.2025.129819},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129819},
  shortjournal = {Expert Syst. Appl.},
  title        = {OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Markov-based continuous learning with diversion of data distribution direction for streaming data in limited memory. <em>ESWA</em>, <em>298</em>, 129818. (<a href='https://doi.org/10.1016/j.eswa.2025.129818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional online classifiers often require accumulating past data, leading to uncontrollable memory usage and learning times. The ideal solution is a Markov-based continuous learning approach, where a model updates using only its current state and new data. While one-pass learning with hyper-ellipsoids aligns with this principle, a critical weakness persists: classification ambiguity for data points within the overlap region where ellipsoids from different classes intersect. To solve this, this paper proposes the Diversion of Data Distribution Direction (D 4 ), a new method that implements this Markov-based approach while specifically targeting the ambiguity problem. D 4 introduces two novel mechanisms: a new adaptive width adjustment to prevent over-adjusted ellipsoid boundaries and a distribution diversion technique that resolves ambiguity by projecting data into an optimally selected subspace. The proposed D 4 method was evaluated against seven state-of-the-art online classifiers across nine benchmark datasets, having 2011 to 567,498 samples. It achieved the highest accuracy and macro F1-score on six datasets while proving to be the most computationally efficient and generating the most compact models.},
  archive      = {J_ESWA},
  author       = {Peemapat Wongsriphisant and Kitiporn Plaimas and Chidchanok Lursinsap},
  doi          = {10.1016/j.eswa.2025.129818},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129818},
  shortjournal = {Expert Syst. Appl.},
  title        = {Markov-based continuous learning with diversion of data distribution direction for streaming data in limited memory},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting knowledge graph communities to fine-tune large language models. <em>ESWA</em>, <em>298</em>, 129816. (<a href='https://doi.org/10.1016/j.eswa.2025.129816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the introduction of GPT-2, Large Language Models (LLMs) have proven to be able to handle various tasks with impressive performance. However, they sometimes generate incorrect output or even hallucinations. To overcome this problem, many researchers have investigated the possibility of integrating external factual knowledge, such as that encoded in Knowledge Graphs (KGs), into LLMs. Although there are many approaches in the existing literature that integrate KGs and LLMs in different ways, few of them use KGs to fine-tune LLMs, and none of them systematically use KG substructures. In this paper, we propose CoFine (Community-Based Fine-Tuner), an approach to fine-tune an LLM using the communities of a KG. CoFine works as follows: it first divides the KG into communities, each of which contains a homogeneous portion of the knowledge expressed by the KG. It then uses these communities to fine-tune the LLM. This way of proceeding allows LLM fine-tuning to focus on specific homogeneous information contained in the KG expressed by each community. CoFine allows the LLM to achieve a very high accuracy in knowledge completion tasks. This is evidenced by comparisons between CoFine and a baseline LLM fine-tuning approach, which showed that our approach achieves better results for all metrics considered with several KG.},
  archive      = {J_ESWA},
  author       = {Alessia Amelio and Christopher Buratti and Michele Marchetti and Davide Traini and Domenico Ursino and Luca Virgili},
  doi          = {10.1016/j.eswa.2025.129816},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129816},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting knowledge graph communities to fine-tune large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale fusion graph convolutional networks. <em>ESWA</em>, <em>298</em>, 129815. (<a href='https://doi.org/10.1016/j.eswa.2025.129815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph analysis methods, as important tools for mining complex information, have made remarkable progress driven by graph neural networks (GNNs). However, existing approaches still face challenges in handling complex topological structures and multi-dimensional node features, making it difficult to fully capture deep-level feature and structural information. When analyzing attribute networks, a key challenge is how to effectively integrate node attribute features with graph topological structure information. To address this issue, this paper proposes a multi-scale fusion graph convolutional network (MSF-GCN) method. This method combines shallow and deep convolution strategies while adaptively fusing information across three parallel channels — the original topological structure, a feature-derived graph, and a deep-combination channel that captures shared depth information between them. An autoencoder is employed to reconstruct the adjacency matrix, enhancing the representation capability of the network. Additionally, an attention mechanism is introduced to dynamically assign weights to attribute and structural features at different scales, optimizing node representation. Experimental results demonstrate that, in node classification tasks across multiple benchmark datasets, MSF-GCN achieves outstanding performance, strongly validating the effectiveness and robustness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhi Kong and Jie Ren and Lifu Wang and Ge Guo},
  doi          = {10.1016/j.eswa.2025.129815},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129815},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scale fusion graph convolutional networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integration path coverage testing of the changing driver code guided by knowledge graph. <em>ESWA</em>, <em>298</em>, 129814. (<a href='https://doi.org/10.1016/j.eswa.2025.129814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device driver code often includes several hardware driver codes. Changes to hardware driver code may thus introduce security risks to device operation. Fortunately, integration target paths are formed by multiple unit functions. These paths reflect the global execution logic of a device’s driver code. Test cases generated for these paths can detect how changing driver code affects the device’s overall operation. Therefore, this paper proposes an approach to integration path coverage testing of the changing driver code guided by knowledge graph. The proposed approach is used to generate test cases covering integration target paths that include changing driver code, queried from the knowledge graph. In the proposed approach, we first statically analyze a device’s hardware driver code, and extract defined entities and their relationships to construct a knowledge graph. From the constructed knowledge graph, we mine entities associated with the changing hardware driver code, which serve as integration target paths. The generation model of test cases is established, which is solved by an intelligent optimization algorithm, thereby generating test cases covering integration target paths. The proposed approach is applied to several open-source driver codes, and compared with several other approaches. Experiments show that the accuracy of both the knowledge graph and the integration target paths has reached 100 %. In addition, the efficiency and effectiveness of test case generation using proposed approach have improved by 19.08 % to 24.54 % and 9 % to 23 %, respectively.},
  archive      = {J_ESWA},
  author       = {Baicai Sun and Miao Rong and Gaige Wang and Dunwei Gong},
  doi          = {10.1016/j.eswa.2025.129814},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129814},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integration path coverage testing of the changing driver code guided by knowledge graph},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution. <em>ESWA</em>, <em>298</em>, 129813. (<a href='https://doi.org/10.1016/j.eswa.2025.129813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial inspection and component alignment tasks, template matching requires efficient estimation of a target’s position and geometric state (rotation and scaling) under complex backgrounds to support precise downstream operations. Traditional methods rely on exhaustive enumeration of angles and scales, leading to low efficiency under compound transformations. Meanwhile, most deep learning-based approaches only estimate similarity scores without explicitly modeling geometric pose, making them inadequate for real-world deployment. To overcome these limitations, we propose a lightweight end-to-end framework that reformulates template matching as joint localization and geometric regression, outputting the center coordinates, rotation angle, and independent horizontal and vertical scales. A Template-Aware Dynamic Convolution Module (TDCM) dynamically injects template features at inference to guide generalizable matching. The compact network integrates depthwise separable convolutions and pixel shuffle for efficient matching. To enable geometric-annotation-free training, we introduce a rotation-shear-based augmentation strategy with structure-aware pseudo labels. A lightweight refinement module further improves angle and scale precision via local optimization. Experiments show our 3.07M model achieves high precision and ∼ 14 ms inference under compound transformations. It also demonstrates strong robustness in small-template and multi-object scenarios, making it highly suitable for deployment in real-time industrial applications. The code is available at: https://github.com/ZhouJ6610/PoseMatch-TDCM .},
  archive      = {J_ESWA},
  author       = {Ke Jia and Ji Zhou and Hanxin Li and Zhigan Zhou and Haojie Chu and Xiaojie Li},
  doi          = {10.1016/j.eswa.2025.129813},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129813},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GraphShield: Advanced dynamic graph-based malware detection using graph neural networks. <em>ESWA</em>, <em>298</em>, 129812. (<a href='https://doi.org/10.1016/j.eswa.2025.129812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising complexity of modern malware-such as polymorphic, fileless, and sandbox-aware variants-has severely diminished the reliability of conventional detection techniques. Models based on sequential data frequently miss intricate behavioral patterns and long-range dependencies, resulting in poor accuracy and limited adaptability to new threats. This paper introduces GraphShield, a graph-centric behavioral detection framework that identifies malware with high precision by analyzing dynamic API call sequences. GraphShield converts raw API calls into temporal graphs, applies semantic vectorization, and leverages attention mechanisms to extract both localized activity and extended behavioral correlations, directly addressing the weaknesses of earlier systems. We design and assess multiple Graph Neural Network (GNN) variants, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Isomorphism Networks (GINs), and Transformer-based architectures combining convolutional, recurrent, and autoencoding layers. These models capture structural and temporal traits of execution traces using both classification-only and combined classification-reconstruction strategies. To enhance transparency, we incorporate GNN interpretation tools that isolate key API call subgraphs and critical decision pathways, making detection outcomes explainable for analysts. GraphShield is trained on 300,000 balanced instances and tested on a separate 200,000-sample holdout set, achieving over 58 % improvement in accuracy over advanced sequence-driven deep learning models while maintaining a false positive rate under 1 %. Key features include BERT-based API call grouping for reducing dimensionality and a Markov-inspired graph stabilization method for managing graphs of variable length. Our top models attain a 99.5 % F1-score on the test set. GraphShield aligns recent graph learning techniques with operational cybersecurity needs, delivering accurate detection and clear, interpretable results.},
  archive      = {J_ESWA},
  author       = {Eslam Amer and Shaker El-Sappagh and Tamer Abuhamad and Bander Ali Saleh Al-Rimy and Alaa Mohasseb},
  doi          = {10.1016/j.eswa.2025.129812},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129812},
  shortjournal = {Expert Syst. Appl.},
  title        = {GraphShield: Advanced dynamic graph-based malware detection using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network. <em>ESWA</em>, <em>298</em>, 129811. (<a href='https://doi.org/10.1016/j.eswa.2025.129811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft skin is prone to surface damage, such as cracks and dents, during long-term service or manufacturing processes. These defects not only threaten structural integrity but may also pose potential safety hazards. The industrial sector continually explores more efficient and precise detection methods to address this issue. Therefore, this paper proposes a skin defect detection method based on a lightweight and flexible residual separation convolutional network to improve detection accuracy and efficiency. Therefore, this paper proposes a skin defect detection method based on a lightweight flexible residual separable convolution network to improve detection accuracy and efficiency. First, a lightweight flexible residual separable convolution module (LFRCM) is designed, which effectively integrates multi-modal features by combining multi-scale receptive fields with an adaptive channel attention mechanism; at the same time, a lightweight backbone network based on PP-LCNet is constructed, employing a collaborative optimization strategy of depthwise separable convolutions and the h-swish activation function to significantly enhance inference speed while maintaining detection accuracy; finally, the MPDIoU metric criterion is introduced, which effectively improves target localization accuracy by implementing a center point offset penalty mechanism. Experiments on the self-built professional dataset SD-DET and the public dataset GC10-DET show that the model achieves mAP@0.5 of 99.5% and 86.2%, respectively, demonstrating significant advantages over mainstream detection models. Systematic ablation experiments confirm the synergistic effect of various innovative modules. Finally, verification experiments are conducted on the AIRCRAFT skin defect dataset, achieving an mAP@0.5 of 30.7%. Quantitative analysis and comparative experiments verify that LFRSCNet can achieve detection accuracy breakthroughs while maintaining low parameter counts and computational costs. Its balanced accuracy-efficiency characteristics provide an efficient and reliable solution for surface defect detection in industrial scenarios.},
  archive      = {J_ESWA},
  author       = {Zhenyu Lu and Jue Wang and Jiteng Zhu and Yuwen Sun},
  doi          = {10.1016/j.eswa.2025.129811},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129811},
  shortjournal = {Expert Syst. Appl.},
  title        = {LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem. <em>ESWA</em>, <em>298</em>, 129810. (<a href='https://doi.org/10.1016/j.eswa.2025.129810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban-rural bus transit services encounter a dilemma between the necessity for enhanced services and the challenge of low profitability due to scant travel demand. Combining freight transportation with passenger services can enhance the efficiency and profitability of buses in both urban and rural areas, while also reducing environmental impacts. A case in point is the integration of freight deliveries into rural bus networks in China. Concurrently, with the advancement of autonomous delivery robot (ADR) technology, there is a growing deployment of ADRs for last-mile delivery purposes. In this paper, we have studied a new collaborative passenger and freight transportation problem involving buses and ADRs, namely, the bus and ADR collaborative delivery problem (BACDP). In this scenario, a bus route transports several ADRs, which carry multiple parcels, to distribution regions for door-to-door delivery, each ADR boards a bus to reach the sub-region and then boards another bus to return to the distribution center. We have proposed a mathematical model for BACDP, which can be decomposed into a master problem and a sub-problem. and the condition that the optimal solution to the master problem is also the optimal solution to the original problem has been proved. To tackle the BACDP effectively, we designed a novel three-stage iterative method, guided by adaptive late acceptance hill-climbing heuristics (ALAHH). Specifically, at the first stage, the k-means++ and Hamiltonian graph-guided algorithms are used to cluster customers; at the second stage, the variable neighborhood search plans the ADRs’ routes; at the third stage, we utilize the solver to address subproblems, and the evaluation and invocation mechanism is proposed to achieve the efficient utilization of solvers. Extensive experiments have been conducted on synthetic instances of varying scales to investigate the efficiency of ALAHH. The experimental results demonstrate that the objective values and the computation time are significantly lower than those of SA and LAHC, and our algorithm has achieved the best solutions for 16 problems to date. Additionally, the impacts of two key parameters and mechanisms have been analyzed, and further validation of the robustness of the algorithm parameters and the effectiveness of the mechanisms.},
  archive      = {J_ESWA},
  author       = {Lijun Pan and Changshi Liu and Yifan Zhang and Shun Li},
  doi          = {10.1016/j.eswa.2025.129810},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129810},
  shortjournal = {Expert Syst. Appl.},
  title        = {The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Future-aware user intent modeling with knowledge distillation for sequential recommendation. <em>ESWA</em>, <em>298</em>, 129809. (<a href='https://doi.org/10.1016/j.eswa.2025.129809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of recommender systems, leveraging users’ future interactions to capture the evolution of preferences in sequential behaviors has become a key focus in Sequential Recommendation (SR). Although current approaches have made notable progress, several important challenges persist: 1) An excessive dependence on historical interactions limits the ability to effectively model the evolution of user preferences. 2) There is a lack of mechanisms to capture the dynamic transition path between historical and future behaviors. 3) Existing denoising techniques often fail to fully consider the semantic information in behavior denoising. To address these issues, we propose an SR framework—Future Distillation Recommendation (FDistRec), which introduces the following strategies: To tackle Limitation 1, we incorporate future interaction data to help alleviate the constraints posed by relying on past behaviors. To address Limitation 2, we adopt a distillation framework along with the Causal Mixture-of-Experts (CMoE) module, effectively capturing the evolution and shift path in user interests. To overcome Limitation 3, we present a Masked Denoising Variational Auto Encoder (MDVAE) model that applies semantic-aware masking to perturb user behaviors, facilitating generative preference modeling and noise-aware interest recovery. Experiments on five real-world datasets demonstrate the superior performance of FDistRec compared to the SOTA baselines on SR.},
  archive      = {J_ESWA},
  author       = {Xinhua Wang and Xiaodi Liu and Wensheng Sun and GuiyuanJiang and Feng Yuan and Lei Guo},
  doi          = {10.1016/j.eswa.2025.129809},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129809},
  shortjournal = {Expert Syst. Appl.},
  title        = {Future-aware user intent modeling with knowledge distillation for sequential recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments. <em>ESWA</em>, <em>298</em>, 129808. (<a href='https://doi.org/10.1016/j.eswa.2025.129808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning for a mobile robot operating in complex hazardous environments often requires simultaneous optimization of multiple objectives, such as minimal path length, low energy consumption, and safe passing under cumulative hazard dosage (CHD) constraint. Available methods, involving deterministic algorithms and meta -heuristic algorithms, have drawbacks in solving this problem to meet these simultaneous requirements. A flexible jump point search strategy (FlexJPS) is proposed to address the problem. In the scheme, jump points are divided into two categories, dominant waypoints (DWPs) and linkage jump points (LJPs). Each DWP is flexibly assigned to one limited zone and all the limited zones are distributed in a spaced form in the grid-based environment. The LJPs are generated in a limited short range by the modified jump point search rule. The DWPs followed by LJPs are evaluated by a designed multi-operator differential evolution algorithm to achieve the optimal solution meeting the safe passing constraint. Various experiments are carried out to validate the performance of the proposed scheme with comparisons to feasible famous counterparts. Statistical results and achieved planning success rates from the experiments under stringent CHD constraint indicate superior performance of the proposed method. It is concluded that the proposed method contributes a high-efficacy multi-objective path planning method for a mobile robot operating in complex environments with CHD constraint.},
  archive      = {J_ESWA},
  author       = {Xiankun Lin and Xiaoting Peng and Linsen Liang},
  doi          = {10.1016/j.eswa.2025.129808},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129808},
  shortjournal = {Expert Syst. Appl.},
  title        = {Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory. <em>ESWA</em>, <em>298</em>, 129807. (<a href='https://doi.org/10.1016/j.eswa.2025.129807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a disorder caused by abnormal discharges of cerebral neurons, affecting 50 million people worldwide. Most existing research on seizure prediction remains at the scalp level. To explore and harness the potential of information flow among cortical regions as well as the intrinsic brain networks and functional mechanisms for seizure prediction, this study proposes a novel multi-domain feature fusion seizure prediction framework based on Electroencephalography (EEG) source estimation and graph theory. Specifically, dSPM source estimation and singular value decomposition (SVD) are first applied to extract 44 subcortical regions defined by the “HCPMMP1_combined” atlas. Brain networks are then constructed using coherence (COH) and phase lag index (PLI), from which specific network topological features based on graph theory are calculated. These features are further extended to higher-order brain networks to enhance connectivity modeling. We also build a multi-domain feature hybrid (MFH) prediction model that adopts a multi-branch structure. One branch employs hypergraph convolution attention along with time–frequency node features derived from continuous wavelet transform (CWT) to capture high-order spatial correlations; another branch inputs the temporal signals from cortical brain regions and combines the hybrid Mamba2-Transformer expert (HMT) model with a frequency-domain dot-product channel attention network (FDCA). By fusing these branches, the model demonstrates satisfactory results across multiple age-groups in the epilepsy EEG dataset of Gansu Province Central Hospital, as well as in the CHB − MIT dataset. This framework highlights the potential of integrating source estimation, hypergraph analysis, and multi-domain feature learning for personalized seizure prediction.},
  archive      = {J_ESWA},
  author       = {Bingyang Ji and Wenwen Chang and Guanghui Yan and Dandan Li and Rong Yin and Xuan Liu and Yaxuan Wei},
  doi          = {10.1016/j.eswa.2025.129807},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129807},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering. <em>ESWA</em>, <em>298</em>, 129806. (<a href='https://doi.org/10.1016/j.eswa.2025.129806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot commonsense question answering (QA) task is to evaluate the general reasoning ability of the language model without training on the specific datasets. The existing zero-shot framework transforms triples within the commonsense knowledge graphs (KGs) into QA-format samples, serving as a pre-training data source to integrate commonsense knowledge into the language model. However, this approach still faces the following challenges: 1) The model trained from synthetic QA generated from triples lacks the multi-hop commonsense knowledge required for handling complex QA problems. 2) Ambiguity caused by confusing commonsense knowledge within synthetic QA, making it challenging for models to discern semantically similar entities. To address the above problem, we propose a novel M ulti-hop C ommonsense K nowledge I njection Framework (MCKI). Specifically, we draw inspiration from human complex reasoning thinking and further propose a synthetic multi-hop commonsense QA generation method. Meanwhile, we introduce negative samples with high confusion in synthetic QA, and then use contrastive learning to improve the model’s ability to distinguish similar commonsense knowledge. Extensive experiments on five commonsense question answering benchmarks demonstrate that our framework achieves state-of-the-art performance, surpassing existing methods, including large language models like GPT3.5 and ChatGPT.},
  archive      = {J_ESWA},
  author       = {Xin Guan and Jiuxin Cao and Biwei Cao and Qingqing Gao and Bo Liu},
  doi          = {10.1016/j.eswa.2025.129806},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129806},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis. <em>ESWA</em>, <em>298</em>, 129805. (<a href='https://doi.org/10.1016/j.eswa.2025.129805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis integrates linguistic, audio, and visual modalities for predicting human emotional states. However, current algorithms encounter three challenges: limitations in adjacency matrix modeling, noise interference and modality imbalances in cross-modal attention, and inefficient cross-modal feature alignment. To address these, we propose the C ross-modal R ecombination via G raph- A ttention C ollaborative Optimization (CR-GAC) by unifying graph and sequence learning in a collaborative framework. Specifically, we first design the modality-adaptive M ultimodal G raph C onstruction (MGC) to tackle the first challenge. For the linguistic modality, a local sparse graph based on a K-Nearest Neighbors-Radial Basis Function kernel is designed to preserve fine-grained semantics; for the audio and visual modalities, a low-rank representation method combined with nuclear norm regularization is designed to capture latent cross-sample structures via singular value decomposition, while suppressing noise interference. Modalities that have been processed are then input into graph attention networks to achieve higher-order feature aggregation. Next, we construct the L anguage-guided H ierarchical C ross-modal I nteraction (LHCI) to tackle the second challenge, which leverages bidirectional cross-modal attention and multi-level Transformer blocks to hierarchically enhance feature representations. Subsequently, the H igh-level M ultimodal F eature C ontainer (HMFC) iteratively accumulates multi-grained semantics, providing a high-level feature pool for fusion. Finally, the dynamic matching-based H igh-level F eature R ecombination (HFR) is designed to tackle the third challenge, which uses the linguistic feature as an anchor to achieve semantically controllable explicit alignment and flexible implicit alignment by matching the most relevant features. Experimental results show our model achieves state-of-the-art performance on CMU-MOSI and CMU-MOSEI datasets, and demonstrates generalization capability on CH-SIMS dataset.},
  archive      = {J_ESWA},
  author       = {Haoran Chen and Jiapeng Liu and Zuhe Li and Yushan Pan and Hongwei Tao and Huaiguang Wu and Yunyang Wang and Chenguang Yang},
  doi          = {10.1016/j.eswa.2025.129805},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129805},
  shortjournal = {Expert Syst. Appl.},
  title        = {CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm. <em>ESWA</em>, <em>298</em>, 129804. (<a href='https://doi.org/10.1016/j.eswa.2025.129804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the design of a sustainable hub-and-spoke logistics network that integrates intermodal transportation between the hubs, hub failures, time dependency, and environmental parameters. Accordingly, we propose a novel mixed-integer linear programming (MILP) model and a hybrid artificial bee colony-based algorithm (HABCb) to minimize transportation costs and emissions in robust network configurations. The model is the first to simultaneously integrate intermodality, sustainability metrics, and hub disruption scenarios within a single framework. Computational experiments using real-life data from Turkey demonstrate that the proposed HABCb approach outperforms both genetic algorithm (GA) and artificial bee colony (ABC) algorithm. On medium-sized problem sets, it achieves average cost reductions of 7% compared to GA and 10% compared to ABC algorithm, while on large-sized problems the reductions are 10% and 15%, respectively. Furthermore, the HABCb approach provides faster convergence and higher-quality solutions for larger problem sizes. The findings highlight the practical and theoretical insights of incorporating sustainability, intermodality, and robustness into hub-and-spoke network design.},
  archive      = {J_ESWA},
  author       = {Burcu Tokbay Erkek and Salih Himmetoğlu and Yılmaz Delice and Emel Kızılkaya Aydoğan},
  doi          = {10.1016/j.eswa.2025.129804},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129804},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels. <em>ESWA</em>, <em>298</em>, 129803. (<a href='https://doi.org/10.1016/j.eswa.2025.129803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networked physical systems (NPSs) are widely applied in modern engineering practices characterized by intensive domain knowledge and imperfect observational data. Meanwhile, collaborative performance assessment provides strong support for them to operate safely and stably over a long period of time. For a specific NPS and its corresponding online and centralized collaborative performance assessment system, the existence of interference and noise in the real-world channel that is rather nonideal inevitably obstructs the smooth progress of the assessment. To this end, in this paper, a symbolic systematic solution is proposed resorting to an improved version of the belief rule base with continuous inputs (BRB-CI). First, the extrapolation module is enhanced by integrating a matched filtering-based link. Second, the existing robustness analysis for systems based on the fundamental belief rule base is extended to systems based on the BRB-CI. Third, the optimization module is ameliorated by designing a multimetric-balanced pattern of the grey wolf optimizer with interpretability reinforcement. Ultimately, by choosing an instance of NPSs in the field of aerospace with continuous time dynamics, pertinent empirical studies are carried out to substantiate the good engineering practicability of our proposal. Note that this paper is the first piece inquiring into belief rule-based systems such a class of expert systems for online and centralized cooperative performance assessment of NPSs with continuous time dynamics such an application, with considerable attention paid to the nonideality of real-world channels.},
  archive      = {J_ESWA},
  author       = {Haoran Zhang and Lining Xing and Jian Wu and Ruohan Yang and Zhichao Feng},
  doi          = {10.1016/j.eswa.2025.129803},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129803},
  shortjournal = {Expert Syst. Appl.},
  title        = {A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). E2D-GS: Event-enhanced deblurring gaussian splatting. <em>ESWA</em>, <em>298</em>, 129802. (<a href='https://doi.org/10.1016/j.eswa.2025.129802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, implicit neural representations and explicit 3D Gaussian Splatting(3DGS) have demonstrated substantial advancements in the domain of novel view synthesis. Nevertheless, the efficacy of these approaches is predominantly contingent upon the availability of well-defined, clear imagery and precise camera pose information. Consequently, they exhibit a pronounced susceptibility to motion blur, which impedes the rendering of sharp images. Event cameras, which measure intensity changes with microsecond temporal precision, possess an inherent robustness to motion-induced blur. This characteristic offers new avenues for 3D reconstruction in challenging scenarios characterized by high-speed motion or low-light conditions. This paper introduces E2D-GS, a novel algorithm for deblurring and reconstruction based on event cameras and 3D Gaussian Splatting. To enhance reconstruction accuracy, our proposed framework leverages event streams to physically model the formation process of motion blur. This is achieved by optimizing the discrepancy between synthesized data and the observed blurry images, while simultaneously recovering the camera’s motion trajectory. Additionally, to enhance robustness in real-world scenarios, this paper proposes a differential consistency module. This module effectively mitigates noise within the event data and regularizes the optimization of Gaussian parameters, thereby improving reconstruction quality under non-ideal conditions. Comprehensive experimental evaluations on both simulated and real-world benchmarks validate the proposed method’s capability to reconstruct latent sharp imagery via the learned 3DGS representations, and further demonstrate its capacity for stable reconstruction under adverse scenarios. The results show that our approach surpasses the performance of previous works.},
  archive      = {J_ESWA},
  author       = {Lifeng Lin and Shuangjie Yuan and Lu Yang},
  doi          = {10.1016/j.eswa.2025.129802},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129802},
  shortjournal = {Expert Syst. Appl.},
  title        = {E2D-GS: Event-enhanced deblurring gaussian splatting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated universal information extraction for chinese legal texts. <em>ESWA</em>, <em>298</em>, 129801. (<a href='https://doi.org/10.1016/j.eswa.2025.129801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing knowledge graphs in legal domains requires simultaneous extraction of entities and relations. To reduce repeated modeling in traditional approaches, we adopt the Universal Information Extraction (UIE) model as a foundation and propose an enhanced variant named Adaptive Gated Universal Information Extraction (AGUIE). This study develops a new decoder based on the Adaptive Focusing Gated Attention Unit (AFGAU). This unit enhances the standard Gated Attention Unit (GAU) by integrating two key components—learnable dynamic convolution and reset/update gating mechanisms. Moreover, the study employs a cross-pointer structure as the output layer to better identify information boundaries. To support this study, we construct a domain specific dataset for extracting key information from legal judgment documents. Systematic comparative analysis and ablation studies demonstrate that AGUIE achieves significant performance gains over baseline UIE, with an F1 score of 85.56% on our legal judgment documents dataset. Additionally, we evaluate the model’s generalization on public datasets such as ACE04, ACE05, and CoNLL04, covering both entity recognition and relation extraction tasks. Experimental results indicate that AGUIE demonstrates competitive results with recent studies on ACE04-Ent and CoNLL04, outperforms them on the ACE05 dataset, achieving F1 scores of 87.19% on ACE05-Ent and 79.29% on ACE05-Rel. In conclusion, AGUIE is a reliable and effective solution for universal information extraction in both legal and general domains.},
  archive      = {J_ESWA},
  author       = {Yabo Liu and Yatong Zhou and Kuo-Ping Lin},
  doi          = {10.1016/j.eswa.2025.129801},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129801},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated universal information extraction for chinese legal texts},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiomics knowledge-driven deep learning framework for breast cancer ultrasound video diagnosis. <em>ESWA</em>, <em>298</em>, 129800. (<a href='https://doi.org/10.1016/j.eswa.2025.129800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and accurate diagnosis of breast cancer is essential. However, the absence of expert knowledge guidance often hampers the performance and clinical applicability of existing automated cancer diagnostic models. Radiomics indicators serve as important references for physicians during clinical diagnosis; nevertheless, limited research has incorporated such domain knowledge into deep learning frameworks. Therefore, we propose a radiomics knowledge-driven deep learning framework for breast cancer diagnosis based on dual-amplitude contrast-enhanced ultrasound (CEUS) videos. The framework employs a three-branch video classification network augmented by a three-step knowledge guidance process. This process begins with radiomics knowledge extraction, deriving both numerical and categorical features from the video data. Quantitative knowledge fusion then integrates these numerical features using numerical bin encoding and the spatio-temporal causal module. Finally, qualitative knowledge fusion incorporates categorical features via label embedding and the multi-label calibrated loss, aligning model outputs with categorical features. Extensive experiments on triple-class cancer classification demonstrate superior performance, achieving an AUC of 94.50 % ± 1.50 % and an accuracy of 83.88 % ± 1.94 %, while providing symptom analysis results as clinical decision support. Furthermore, our framework achieves consistent performance gains when applied to other deep learning models, highlighting its broad applicability and potential for advancing medical diagnosis. Code is available at https://github.com/tobenan/radiomics .},
  archive      = {J_ESWA},
  author       = {Dinghao Guo and Zheng Xue and Dali Chen and Chunyu Lu and Jun Fu and Jizhong Yuan and Ying Huang},
  doi          = {10.1016/j.eswa.2025.129800},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129800},
  shortjournal = {Expert Syst. Appl.},
  title        = {Radiomics knowledge-driven deep learning framework for breast cancer ultrasound video diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation. <em>ESWA</em>, <em>298</em>, 129794. (<a href='https://doi.org/10.1016/j.eswa.2025.129794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific novelty constitutes a fundamental catalyst for both disciplinary innovation and interdisciplinary progress. Nevertheless, prevailing approaches to novelty assessment predominantly emphasize a single analytical dimension–either the semantic content of the focal paper or its cited references. Content-based methodologies frequently fail to incorporate the foundational knowledge cited by the target publication, whereas reference-based strategies tend to disregard the intrinsic conceptual contributions of the focal work itself. To address this limitation, the present study introduces a hybrid graph and large language model approach to jointly capture and integrate knowledge embedded in both the focal paper and its cited literature. The proposed method, which integrates knowledge recombination and propagation, is structured into four primary stages. First, prompt-based extraction techniques using general LLMs are applied to extract knowledge. Second, a Reference Knowledge Combination Network (RKCN) is constructed to model the knowledge referenced by the focal paper. Third, the RKCN is initialized with representations generated by SciDeBERTa(CS), and a graph attention network is employed to propagate knowledge across the network. Finally, the novelty of the focal paper is quantified by aggregating the novelty scores of all internal knowledge combinations based on the propagated representations. Experimental evaluation in the domain of artificial intelligence (AI) demonstrates that the proposed method significantly outperforms existing baseline approaches in quantifying scientific novelty. Additional ablation studies further validate the contribution of the knowledge propagation module. A case study illustrates the interpretability of our approach, and a cross-field validation in Biomedical Engineering (BME) domain highlights its robustness and cross-domain generalizability. A multi-dimensional comparative analysis between award-winning and non-award papers further reveals that the former generally incorporate a larger volume of knowledge and exhibit greater diversity in knowledge combinations. Moreover, while both groups encompass knowledge combinations spanning a wide range of novelty, award-winning papers display a stronger concentration at higher novelty levels, in contrast to the more uniform distribution observed in non-award papers. Data, code, and more detailed results are publicly available at: https://github.com/haihua0913/graphLLM4ScientificNovelty .},
  archive      = {J_ESWA},
  author       = {Zhongyi Wang and Zeren Wang and Guangzhao Zhang and Jiangping Chen and Markus Luczak-Roesch and Haihua Chen},
  doi          = {10.1016/j.eswa.2025.129794},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129794},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-based approaches for rumor detection in social networks: A systematic review. <em>ESWA</em>, <em>298</em>, 129786. (<a href='https://doi.org/10.1016/j.eswa.2025.129786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased public anxiety and fear, disrupted decision-making, social instability, and other significant societal challenges are the results of the rapid spread of rumors on social media platforms. The unique characteristics of these platforms contribute to the rapid spread of both verified and unverified information. These pressing issues highlight the need to develop advanced technologies for early detection and prevention of rumors. This paper presents a systematic review of graph-based approaches for rumor detection in social networks, analyzing 53 studies published between 2018 and 2025. The selected studies are comprehensively reviewed with a focus on graph models and the integration of propagation structure, social, temporal, and content features, which enhances detection accuracy. This review critically evaluates the effectiveness of various methods, highlighting their strengths, limitations, and key challenges. The key contributions of this paper include: (i) an in-depth analysis of current graph-based rumor detection approaches (ii) a categorization of graph models and feature extraction strategies, (iii) the identification of major challenges and research gaps, and (iv) recommendations for future research to develop scalable, robust, and accurate early rumor detection systems. The findings of this study provide valuable insights for researchers aiming to advance the state-of-the-art in fighting misinformation on social networks.},
  archive      = {J_ESWA},
  author       = {Fatima Al-Thulaia and Seyyed Alireza Hashemi Golpayegani},
  doi          = {10.1016/j.eswa.2025.129786},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129786},
  shortjournal = {Expert Syst. Appl.},
  title        = {Graph-based approaches for rumor detection in social networks: A systematic review},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems. <em>ESWA</em>, <em>298</em>, 129785. (<a href='https://doi.org/10.1016/j.eswa.2025.129785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed parameter systems are prevalent in various industrial processes and attract significant attention. However, these systems exhibit complex spatiotemporal coupling characteristics, and effectively determining the fuzzy rules of the antecedent set is crucial for improving modeling performance. Traditional clustering methods typically rely on empirical heuristics and are unable to adapt to dynamic system characteristics under changing environments. In high-dimensional and nonlinear scenarios, the number of fuzzy rule combinations grows exponentially, significantly increasing computational complexity. Therefore, an online spatiotemporal three-dimensional fuzzy modeling method based on knowledge-driven differential evolution automatic clustering and extreme learning machine (3D-OSADE-ELM) is proposed for the complex nonlinear distributed parameter system. First, an automatic clustering mechanism based on differential evolution and extreme learning machine initializes the fuzzy rules within the three-dimensional fuzzy system. Subsequently, a knowledge-driven archiving mechanism dynamically updates the fuzzy rules of the antecedent set during the online incremental learning phase. Finally, the spatial basis function is obtained by learning the output weight of the online extreme learning machine. The validation experiments conducted on the rapid thermal chemical vapor deposition reactor system and the nonisothermal packed-bed system demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Gang Zhou and Xianxia Zhang and Bing Wang},
  doi          = {10.1016/j.eswa.2025.129785},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129785},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies. <em>ESWA</em>, <em>298</em>, 129784. (<a href='https://doi.org/10.1016/j.eswa.2025.129784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of retinal diseases is vital to preventing partial or permanent blindness. However, the diagnostic process is often impeded by the complexity of interrelated lesions and the challenge of incomplete or missing pathology labels, which require specialized expertise in ophthalmic diagnosis. To address these limitations, we propose CG-Tran, a novel multi-label classification model that leverages partially known pathology information to diagnose retinal diseases. This approach integrates a pathology graph neural network with graph-based feature extraction to handle partially known pathologies, enabling more accurate multi-label classification of retinal diseases. To model the intricate interrelationships among ocular diseases, CG-Tran employs BERT-GNN to learn label interactions and construct a comprehensive fundus pathology graph. Additionally, an enhanced attention mechanism incorporates known pathology label features, bridging the gap between incomplete pathology information and fundus image data. These innovations collectively empower the model to overcome the challenges of missing or incomplete pathology labels. The model’s performance is rigorously evaluated on the Multilabel Retinal Disease (MuReD) dataset. Results demonstrate that CG-Tran significantly improves diagnostic accuracy, especially as more pathology labels become available. Under conditions with 0% and 75% partially known labels, CG-Tran achieves mean average precision (mAP) scores of 69.9% and 72.1%, respectively—outperforming the baseline model by 1.0% and 1.9%. This innovative architecture excels in multi-label classification tasks, particularly in recognizing and distinguishing complex and interrelated retinal lesions with partially known pathology. It offers a promising solution for early detection and accurate diagnosis of retinal diseases, addressing critical limitations in existing diagnostic methods.},
  archive      = {J_ESWA},
  author       = {Jia Sheng Yang and Zihao Ning and Xu Xiao and Rui Zhong and Chenbo Xia and Ya Ding},
  doi          = {10.1016/j.eswa.2025.129784},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129784},
  shortjournal = {Expert Syst. Appl.},
  title        = {CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-balanced MSE for machinery imbalanced degradation trend prediction. <em>ESWA</em>, <em>298</em>, 129783. (<a href='https://doi.org/10.1016/j.eswa.2025.129783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate degradation trend prediction (DTP) is crucial for optimizing equipment operation and maintenance. With the rapid development of artificial intelligence, many data-driven methods have been applied to machinery degradation trend prediction. In practice, most machineries are in the early stages of degradation, with only a few reaching the final stages, leading to a temporal imbalanced data distribution. Current research on imbalanced distributions mainly focuses on classification tasks. However, DTP involves multiple time-dependent continuous targets, making classification-based methods unsuitable. To address this issue, the degradation trend prediction task is reformulated as a multi-task problem and a novel time-balanced Mean Square Error (TBMSE) loss function is proposed. In each prediction task, the Gaussian Mixture Model (GMM) is used to fit the training label distribution. Additionally, the cumulative information noise for each prediction task is modeled using GMM, and an end-to-end network structure is designed to learn the GMM parameters. Experiments are conducted on the IMS bearing dataset and the turboprop engine dataset, demonstrating that the TBMSE loss effectively mitigates the issue of temporal imbalanced distribution in degradation trend prediction.},
  archive      = {J_ESWA},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Tian-Ding Zhang and Yu-Wei Wang},
  doi          = {10.1016/j.eswa.2025.129783},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129783},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-balanced MSE for machinery imbalanced degradation trend prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images. <em>ESWA</em>, <em>298</em>, 129782. (<a href='https://doi.org/10.1016/j.eswa.2025.129782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing low-light image enhancement (LIE) methods rely on expensive paired low-light and normal-light datasets, while unsupervised approaches depend on handcrafted priors to design networks or select similar normal-light images as pseudo-references, limiting their generalization and robustness. To address these challenges, we propose a novel differentiable histogram-guided unsupervised Retinex enhancement (DHURE) method, which leverages the distribution of illumination histograms in real-world scenarios to achieve high-fidelity color preservation and refined brightness distribution across diverse extremely low-light images. DHURE avoids reliance on scene-specific features and effectively captures both fine-grained details and overall brightness information. Specifically, our method consists of two key components: 1) The lightweight architecture of DHURE is composed of Retinex decomposition and illumination enhancement. We perform Retinex decomposition on paired low-light images (PRD) and design the Illumination Histogram-guided Enhancement (IHE) module. Both modules employ lightweight architectures. 2) To fully exploit the adaptive priors inherent in paired low-light images, we introduce a self-supervised reflectance map loss that aligns with the Retinex basis loss. Based on the illumination distribution of real-world normal-light images, we define two unsupervised illumination histogram losses, enabling more generalized and robust enhancement. Extensive and diverse experiments demonstrate that our method achieves competitive performance compared to existing unsupervised LIE approaches, showing superior results on most evaluation metrics. The source code is available at https://github.com/yoonyin/DHURE-main .},
  archive      = {J_ESWA},
  author       = {Liyuan Yin and Pingping Liu and Tongshun Zhang and Hongwei Zhao and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129782},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129782},
  shortjournal = {Expert Syst. Appl.},
  title        = {Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments. <em>ESWA</em>, <em>298</em>, 129781. (<a href='https://doi.org/10.1016/j.eswa.2025.129781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) methodologies have achieved notable advancements across diverse domains. Despite these successes, the susceptibility of neural networks to perturbed data and the ubiquity of external attacks in real-world settings, such as sensor noise, pose challenges for MARL approaches. The pivotal issue revolves around the effective transfer of policies learned in idealized simulation environments to the complexities inherent in real-world scenarios. More precisely, when agents are unable to obtain any accurate observations of the external environment throughout the entire policy learning process, the MARL methods cannot learn effective policies. In addressing this issue, we propose a methodology wherein noisy observations from neighboring agents are utilized, with an agent’s own noisy observations serving as surrogate ground truth. This approach facilitates the learning of effective policies by MARL methods in environments characterized by pervasive noise. We design a denoising representation network to filter out the principal state information from environment data characterized by noise to mitigate the adverse effects of noise on the process of policy learning. Then, we integrate the denoising representation network with classic MARL methodologies to learn effective policies within environments characterized by pervasive noise. A series of exhaustive experimental results demonstrate the efficacy of our approach in attenuating the impact of external attacks on the optimization parameters of neural networks during the policy-learning process. Moreover, our methodology exhibits compatibility with classic MARL methods, allowing for the learning of effective policies.},
  archive      = {J_ESWA},
  author       = {Kaiyu Wang and Bohao Qu and Menglin Zhang and Xianchang Wang and Ximing Li},
  doi          = {10.1016/j.eswa.2025.129781},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129781},
  shortjournal = {Expert Syst. Appl.},
  title        = {SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing. <em>ESWA</em>, <em>298</em>, 129780. (<a href='https://doi.org/10.1016/j.eswa.2025.129780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle mobility trajectories, especially fine-grained trajectories, provide valuable insights for understanding urban dynamics and play a crucial role in intelligent transportation systems and urban planning. Obtaining fine-grained vehicle trajectories can be realized by trajectory recovery, but traditional efforts suffer from defects such as poor privacy protection and low recovery accuracy. To address these issues, we propose a new scenario of trajectory recovery based on roadside unit (RSU) sensing. However, this scenario introduces a significant challenge: recovering high-precision trajectories from the incomplete and unevenly distributed sensing data. To tackle this, we design RSUTrajRec , a multi-granularity trajectory recovery framework that comprises a graph neural network-based module for road information prediction, a Transformer-based module for multi-granularity recovery, and an RSU deployment planning module. Extensive real-world dataset evaluations reveal that RSUTrajRec has a significant advantage in recovering missing vehicle trajectories outside the RSU coverage area. In addition, evaluations also verify that the performance of the trajectory recovery task can be effectively improved by optimizing the RSU deployment plan.},
  archive      = {J_ESWA},
  author       = {Xianjing Wu and Xutao Chu and Jianyu Wang and Shengjie Zhao},
  doi          = {10.1016/j.eswa.2025.129780},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129780},
  shortjournal = {Expert Syst. Appl.},
  title        = {RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generating realistic pruning solutions for automated grape vine pruning using graph neural networks. <em>ESWA</em>, <em>298</em>, 129778. (<a href='https://doi.org/10.1016/j.eswa.2025.129778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our prior work we showed that graph neural networks (GNNs) can be trained to generate pruning solutions that could direct robotic pruning robots to perform automated cane pruning of wine grape vines. That study introduced the feasibility of the technology but also showed that there were many open questions and issues with the research results that needed to be addressed. In this study we address some of these questions. For example, we answer the question of how would a model like this perform on real vine architectures compared with pruning solutions from real experienced pruners. Our most notable contributions include moving away from a per-cane classification model that attempts to define a single perfect pruning solution, to a model that ranks multiple good solutions and picks the best one. We addressed a key limitation of the previous training data by moving away from synthetic vine architectures to realistic ones recorded from real vines and using pruning solutions collected by expert pruners as our ground-truth. Our primary goal was to show that learning by example using a GNN-based model was a viable approach to automated pruning, even when compared with experienced pruners. We showed robust performance from our model by training on a dataset of 90 pruning solutions generated by expert pruners in the 2022 season, and testing our performance on 117 pruning solutions from an independent set of pruners from the 2021 season. The model was able to correctly score all the pruning solutions from the 2021 dataset as good to very good and none of the expert solutions were classified as poor .},
  archive      = {J_ESWA},
  author       = {Jaco Fourie and Jeffrey Hsiao and Oliver Batchelor and Kevin Langbroek and Henry Williams and Richard Green and Armin Werner},
  doi          = {10.1016/j.eswa.2025.129778},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129778},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generating realistic pruning solutions for automated grape vine pruning using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration. <em>ESWA</em>, <em>298</em>, 129776. (<a href='https://doi.org/10.1016/j.eswa.2025.129776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container terminal operations frequently encounter disruptions, including delays, extended handling times, and unscheduled vessel arrivals, all of which necessitate intelligent rescheduling strategies to maintain operational efficiency. This study investigates the integrated problem of disruption-responsive berth allocation and quay crane (QC) scheduling, explicitly considering vessel gathering status and incorporating inter-terminal shifting (ITS) and reassignment to terminals different from its originally designated one (RT) as adaptive response strategies to mitigate these disruptions. A rescheduling model is developed to minimize associated costs. To efficiently solve large-scale problems, an adaptive large neighborhood search (ALNS)-based heuristic is proposed. The effectiveness of the proposed scheme is validated through comparative experiments involving three alternative schemes, highlighting its superior performance. Furthermore, algorithm comparison experiments are conducted to verify the robustness of parameter settings. Computational results demonstrate that the proposed model and algorithm achieve high efficiency and solution quality. Additionally, sensitivity analysis reveals that neglecting vessel gathering status leads to substantial cost increases, particularly in large-scale operations. The integration of ITS and RT proves to be an effective strategy for mitigating disruptions, enhancing scheduling flexibility, and improving operational performance.},
  archive      = {J_ESWA},
  author       = {Hongxing Zheng and Zhaoyang Wang and Lingxiao Wu},
  doi          = {10.1016/j.eswa.2025.129776},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129776},
  shortjournal = {Expert Syst. Appl.},
  title        = {Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mining spatiotemporal dominant co-location patterns. <em>ESWA</em>, <em>298</em>, 129775. (<a href='https://doi.org/10.1016/j.eswa.2025.129775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial co-location pattern mining is an important branch of spatial data mining, which can identify spatial features that prevalently occur in proximity. Based on spatial co-location patterns, the research of dominant relationships mining within co-location patterns further considers the influence relationship among features. However, relying solely on spatial data to analyze the positions and distribution of features for mining dominant relationships is insufficient and may lead to incorrect patterns. To address this limitation, this paper introduces the temporal factor into the research of dominant relationships mining and proposes the spatiotemporal dominant co-location pattern mining (STDCPM). At first, we define the concepts of spatiotemporal dominant relationship from both temporal and spatial dimensions, and then propose the spatiotemporal dominant participation index to assess the prevalence of spatiotemporal dominant co-location patterns. Furthermore, we design two algorithms, the spatiotemporal dominant co-location pattern mining algorithm with level-by-level search and its improved version, i.e., the spatiotemporal dominant co-location pattern mining approach based on dual pruning and refining set (STDCPM-DPR), to ensure efficient mining in spatiotemporal datasets. The time complexity, correctness, and completeness of proposed algorithms are discussed. Extensive experiments on real-world datasets demonstrate the effectiveness of STDCPM and the efficiency of STDCPM-DPR algorithm.},
  archive      = {J_ESWA},
  author       = {Jiangchuan Mei and Peizhong Yang and Hongmei Chen and Lizhen Wang},
  doi          = {10.1016/j.eswa.2025.129775},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129775},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mining spatiotemporal dominant co-location patterns},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification. <em>ESWA</em>, <em>298</em>, 129774. (<a href='https://doi.org/10.1016/j.eswa.2025.129774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking and quantifying fish activity are vital for evaluating their health status and adaptability to the environment. However, most current research on fish tracking and activity quantification suffers from the limitation of being two-dimensional, losing crucial vertical or horizontal information. To facilitate tracking and quantitative analysis of fish activity in three-dimensional (3D) space, a cross-scale content-adaptive network-based 3D multi-object tracking method for fish is proposed, through which fish movements are quantified accordingly. Firstly, a cross-scale content-adaptive fusion network is proposed to accurately determine the fish positions from top-down and side views, thereby mitigating the issue of scale variation across different perspectives. Secondly, a hierarchical tracking method is implemented to obtain the 3D trajectories of the fish, addressing the challenge of cross-view identity matching. Finally, activity parameters in 3D space, including the activity quantity and trajectory length for individual fish, as well as the dispersion and cohesion for the fish group, are calculated. The proposed method was validated, achieving a Multi-Object Tracking Accuracy (MOTA) of 97.68% and an Identification F1 Score (IDF1) of 97.93%. For activity quantification, the Mean Absolute Error (MAE) was found to be 0.088 (unit weight·(cm/s) 2 ), and the Root Mean Square Error (RMSE) was 0.1064 (unit weight·(cm/s) 2 ). These results affirm the method’s adaption of fish features across scales for 3D tracking and activity analysis. With its efficient performance, our method presents as an instrument for activities such as fish behavior monitoring, selective breeding, and environmental assessment.},
  archive      = {J_ESWA},
  author       = {Yiran Liu and Dingshuo Liu and Mingrui Kong and Beibei Li and Qingling Duan},
  doi          = {10.1016/j.eswa.2025.129774},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129774},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. <em>ESWA</em>, <em>298</em>, 129773. (<a href='https://doi.org/10.1016/j.eswa.2025.129773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection (MSD) has become an important research topic for understanding sentiments on social media, while various recent MSD approaches extract high-level semantic knowledge from images to improve performance. However, some key semantic information, such as emotions expressed in images, is still neglected, limiting reliable sentiment understanding. To address this issue, we propose an adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. We first design an adaptive processing pipeline to extract emotion-aware visual semantics as an auxiliary modality to enhance multimodal feature representations. Enabled by two attention mechanisms, bidirectional cross-modal attention and graph attention, interactions between modalities are analysed to improve MSD performance. Extensive experiments are conducted on two public multimodal sarcasm detection datasets, MMSD and MMSD 2.0, comprising approximately 19,000 tweet samples. Our proposed approach achieves consistent improvements in both sarcasm detection accuracy and F1-score compared to strong baseline models such as DIP and KnowleNet. Built upon a ViT-based architecture, the fine-tuned model offers competitive performance with lower computational overhead, highlighting its potential for practical deployment.},
  archive      = {J_ESWA},
  author       = {Jing Dong and Yu Sui and Qiang Zhang and Hui Fang and Gerald Schaefer and Rui Liu and Pengfei Yi and Xiaoyong Fang},
  doi          = {10.1016/j.eswa.2025.129773},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129773},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossFPN: Efficient cross-scale feature pyramid network for real-time low-altitude aerial target detection. <em>ESWA</em>, <em>298</em>, 129772. (<a href='https://doi.org/10.1016/j.eswa.2025.129772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-altitude aerial target detection presents significant challenges in object detection due to the rapid development of Unmanned Aerial Vehicles (UAVs). Despite the recent advances in feature pyramid networks, the accuracy and efficiency of real-time low-altitude aerial target detection remain suboptimal, which is caused by the tiny proportion, the similar patterns, the complex background textures, and the deficient resolution of the target area of interest. This study proposes the innovative Cross-Scale Feature Pyramid Network (CrossFPN) to address the key gap in real-time low-altitude aerial target detection. Benefiting from the core components Deep Cross-Scale Fuser Module (DCFM) and Shallow Cross-Scale Fuser Module (SCFM), the CrossFPN efficiently fuses the semantic and spatial features across levels through a unique propagating route and preserves the high-resolution information that is crucial to small aerial targets. Differing from the conventional feature extraction process, the simultaneous fusion mode and the feature reutilization reduce the computational overhead of the model and ensure real-time performance, uncovering novel insights into cross-scale fusion. Furthermore, the Adaptive Partial Channel Mixer (APCM) is implemented to process the fused features and extract the discriminative features of the low-altitude aerial targets. Publicly available datasets and self-built extended datasets were employed for hybrid training to enhance the robustness and scalability of the model. Extensive experiments on various datasets have demonstrated that CrossFPN performs superior to state-of-the-art feature pyramid networks in detection accuracy and model complexity by a notable margin.},
  archive      = {J_ESWA},
  author       = {Liyan Cai and Qingfang Zheng and Yaowei Wang and Xuefei Xiong and Yong Xu},
  doi          = {10.1016/j.eswa.2025.129772},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129772},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossFPN: Efficient cross-scale feature pyramid network for real-time low-altitude aerial target detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FoRKER: Focused reasoner with knowledge editing and self-reflection. <em>ESWA</em>, <em>298</em>, 129771. (<a href='https://doi.org/10.1016/j.eswa.2025.129771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop question answering (MHQA) is a complex question answering (QA) benchmark that requires agents to integrate information from diverse sources and utilize cross-referencing reasoning to answer intricate questions. Existing MHQA-handling frameworks typically employ a retrieve-read paradigm. However, these efforts rooted in the retrieve-read paradigm are still constrained by: 1) unstable document retrieval performance , 2) weak knowledge refinement capabilities , and 3) the absence of a reflection mechanism for error awareness . To address these limitations, we propose FoRKER ( Fo cused R easoner with K nowledge E diting and Self- R eflection), which is a plug-and-play framework. Specifically, we develop a novel progressive focusing mechanism to pinpoint highly relevant document resources and introduce knowledge editing techniques to further eliminate noise interference within textual information. Additionally, we design a novel prompting method, named Chain-of-Evidence (CoE), which is designed to augment the reasoning capabilities of FoRKER . Notably, the integration of Self-Reflection technology further endows FoRKER with the ability to learn and improve from its mistakes. Extensive experiments on widely-used datasets demonstrate that FoRKER achieves new state-of-the-art results in information retrieval and reading comprehension, while also exhibiting effective generalization. Exhilaratingly, on the MusiqueQA dataset, FoRKER demonstrates a 20 % improvement in Answering scores compared to the advanced competitors.},
  archive      = {J_ESWA},
  author       = {Chunbai Zhang and Haoyang Li and Chao Wang and Yang Zhou and Yan Peng},
  doi          = {10.1016/j.eswa.2025.129771},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129771},
  shortjournal = {Expert Syst. Appl.},
  title        = {FoRKER: Focused reasoner with knowledge editing and self-reflection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Training-free pedestrian trajectory prediction via segmentation-guided path planning. <em>ESWA</em>, <em>298</em>, 129770. (<a href='https://doi.org/10.1016/j.eswa.2025.129770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction is a critical research topic for industrial applications and has been significantly advanced by deep learning. Despite decades of progress, current approaches still face two major challenges. First, the scarcity of data limits the generalization capability of deep learning models. Second, the absence of interpretability hinders real-world applications. To address these challenges, recent research has leveraged the knowledge of large language models (LLMs) to alleviate data sparsity and introduced novel knowledge-based methods to enhance interpretability. Nevertheless, transferring LLMs is excessively cumbersome, and the black-box nature of deep learning continues to obstruct interpretability. In our work, we propose a training-free transfer paradigm named Segmentation-Guided Path Planning (SGPP). Rather than directly transferring pretrained LLMs, SGPP introduces a more tailored and efficient transfer strategy by employing a promptable segmentation model. The segmentation model explicitly extracts walkable regions from the scenario, which serve as constraints in the planning space, thereby reformulating trajectory prediction as a more tractable white-box path-planning problem. Within this framework, our method offers a more effective solution to the two prevailing challenges. Compared with the latest training-free methods, our approach achieves superior performance and demonstrates strong generalization across diverse real-world scenarios, highlighting its suitability for industrial applications.},
  archive      = {J_ESWA},
  author       = {Dongchen Li and Zhimao Lin and Jinglu Hu},
  doi          = {10.1016/j.eswa.2025.129770},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129770},
  shortjournal = {Expert Syst. Appl.},
  title        = {Training-free pedestrian trajectory prediction via segmentation-guided path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions. <em>ESWA</em>, <em>298</em>, 129769. (<a href='https://doi.org/10.1016/j.eswa.2025.129769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the effectiveness of digital literacy interventions often relies on raw score comparisons or hard classifications, which may obscure nuanced changes in conceptual understanding and provide limited interpretability. Traditional approaches fail to capture the probabilistic and fuzzy nature of learning progression and do not support transparent analysis of how learners transition across conceptual clusters over time. This study proposes an explainable evaluation framework that integrates fuzzy clustering with a fuzzy transition matrix to model the redistribution of aggregated membership values between pretest and posttest conceptual clusters. The framework applies Fuzzy C-Means (FCM) to derive soft cluster memberships and constructs a transition matrix that represents probabilistic learning progression in a linguistically interpretable form. Unlike conventional methods, this approach enables the analysis of gradual transitions across levels of proficiency rather than binary outcomes. The model was applied to real-world educational data from control and experimental classes, the latter of which received a social media-based instructional intervention. Results indicate that the control class exhibited downward or stagnant patterns, particularly among high-performing learners, while the experimental class showed more coherent upward cluster transitions among low- and moderate-level learners. By enabling interpretable modeling of pre–post cluster transition patterns, the proposed framework contributes to the advancement of explainable machine learning in education. It also highlights the potential of social computing platforms to foster scalable, data-driven digital literacy development.},
  archive      = {J_ESWA},
  author       = {Rustam and Diana Noor Anggraini and Koredianto Usman and Loveleen Gaur},
  doi          = {10.1016/j.eswa.2025.129769},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129769},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting. <em>ESWA</em>, <em>298</em>, 129768. (<a href='https://doi.org/10.1016/j.eswa.2025.129768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively modeling the relations between variables in multivariate time series is of utmost importance for accomplishing accurate predictions. In real-world scenarios, in addition to sequential correlations, the evolution of relations between variables also exhibits nonadjacent correlations at different scales. However, existing methods primarily focus on constructing dynamic graph structures at each time step using temporal features extracted by continuous temporal models, which cannot capture above latent dependencies. In this study, we introduce the Dynamic Graph Structure Correction (DGC) model, leveraging a multi-scale framework with dilated convolution. To take full advantage of nonadjacent correlations in the evolution of relations between variables, we adaptively select history-related graph structures to correct initial graph structure constructed by Gate Recurrent Units. In addition, we design a time-decay-based attention mechanism to address the influence of time intervals between history-related and current time steps. Finally, the evolved graph structures are fed into graph neural networks to handle the multi-scale and complex structural relations. Our proposed model achieves superior performance compared to state-of-the-art methods in multivariate time series forecasting, as evidenced by the evaluation results on four widely used benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Dandan He and Yueyang Wang and Chaoli Lou and Gang Tan and Qingyu Xiong and Guodong Sa},
  doi          = {10.1016/j.eswa.2025.129768},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129768},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimized homomorphic linear computation in privacy-preserving CNN inference. <em>ESWA</em>, <em>298</em>, 129767. (<a href='https://doi.org/10.1016/j.eswa.2025.129767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning as a Service (MLaaS) provides robust solutions for deploying deep learning inference in cloud environments. However, it also raises serious privacy concerns regarding user data and proprietary model parameters. Numerous hybrid cryptographic protocols that integrate homomorphic encryption (HE) and garbled circuits (GC) have been proposed to enable secure inference with low latency. In these protocols, the homomorphic evaluation of linear operations remains the primary performance bottleneck and warrants further optimization. In this work, we propose novel optimizations for HE-based linear computations within the hybrid cryptographic framework for secure neural network inference. Specifically, we devise two efficient strategies for homomorphic matrix-vector multiplication and convolution. For matrix-vector multiplication, we introduce a grouped diagonal extraction technique that encodes the weight matrix more compactly and enables configurable ciphertext rotation reuse, while for homomorphic convolution, we present a group-wise combine-and-merge evaluation method. Both methods significantly reduce the number of required ciphertext rotations. Our approach achieves up to a 3.9 × speedup in matrix-vector multiplication and a 2.9 × improvement in convolution over state-of-the-art (SOTA) solutions. The HE-GC hybrid secure convolutional neural networks (CNN) inference framework incorporating these enhancements yields speedups of 2.5 × on widely used ResNets deep learning architectures.},
  archive      = {J_ESWA},
  author       = {Chenglong Li and Xirong Ma and Xiuhao Wang and Fanyu Kong and Yunting Tao and Chunpeng Ge},
  doi          = {10.1016/j.eswa.2025.129767},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129767},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimized homomorphic linear computation in privacy-preserving CNN inference},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved convolutional neural networks for the bullwhip effect in supply chains. <em>ESWA</em>, <em>298</em>, 129764. (<a href='https://doi.org/10.1016/j.eswa.2025.129764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bullwhip Effect (BWE) introduces significant challenges to production systems by amplifying demand and order oscillations. One of the most effective methods for predicting and modeling complex systems is Convolutional Neural Networks (CNNs). However, certain phenomena, such as the BWE in supply chains (SC), are difficult to predict and identify directly. The primary challenge for Machine Learning (ML) algorithms in this context lies in the training phase: the raw demand and order data are fed into the network, yet the desired training outcome is the oscillatory behavior of these data from the perspective of the BWE. Consequently, conventional max pooling, average pooling operators, kernels, and weighted linear combinations of data are insufficient for capturing this type of learning. To address this issue, in this paper, a novel structure containing new pooling operators and kernels of CNNs is proposed to tailor the unique characteristics of the BWE. Specifically: a ) Considering the temporal propagation nature of the BWE, new filters and pooling operators were designed to enable CNNs to predict the BWE accurately. b ) A tensor structure was also proposed for the time signal of demand as inputs of the CNNs to facilitate the analysis of all factors influencing the occurrence of the BWE. c ) To capture the magnitude of the BWE among features, a novel combination of filters and pooling operators was proposed, enabling the CNNs to account for hidden but yet significant feature effects during training. The benefits of the proposed approach lie in its versatility, and it can be applied to train CNNs to model structured fluctuations like the BWE in various dynamic systems.},
  archive      = {J_ESWA},
  author       = {Sajjad Aslani Khiavi and Farzad Hashemzadeh},
  doi          = {10.1016/j.eswa.2025.129764},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129764},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved convolutional neural networks for the bullwhip effect in supply chains},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident. <em>ESWA</em>, <em>298</em>, 129763. (<a href='https://doi.org/10.1016/j.eswa.2025.129763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a dominant mode of maritime transportation with unique risk characteristics, container shipping requires accurate and applicable risk assessment. However, conventional risk matrices oversimplify complex interactions, while pure data-driven models lack operational utility. To address this, a hybrid method for container ship risk assessment is proposed. This method integrates CatBoost-based predictive method, FAHP-grid search optimized risk matrix, and GIS-supported risk mapping. A comprehensive study of maritime casualties and piracy accidents is conducted, utilizing historical incident data sets collected from the Global Integrated Shipping Information System (GISIS). The global maritime accident risk of container ships is then evaluated and mapped. The sensitivity analysis confirms the robustness of the method under varying linguistic distance parameters, while expert weights have a moderate impact on the assessment results. Finally, the effectiveness of the proposed method is validated through comparative analyses on predictive performance, risk discrimination capability, and risk assessment accuracy. CatBoost algorithm outperforms XGBoost, LightGBM, and Random Forest algorithms in predictive metrics. The designed risk matrix shows strong discriminatory ability for container ship risk levels. In historical accident data validation, the proposed method also achieves higher accuracy than combinations involving XGBoost, LightGBM, or Random Forest with the designed risk matrix.},
  archive      = {J_ESWA},
  author       = {Yuqing Xiao and Shilian Han and Xinwang Liu},
  doi          = {10.1016/j.eswa.2025.129763},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129763},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129761. (<a href='https://doi.org/10.1016/j.eswa.2025.129761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems involve the optimization of multiple objective functions and the satisfaction of different constraints, which poses a challenge for algorithms to achieve a good balance between convergence and diversity. However, indiscriminately enhancing diversity can hinder convergence, while solely focusing on convergence may impair the exploration of the objective space, especially when the current stage is not well-defined. To address this issue, we propose a three-stage multi-task framework for constrained multi-objective optimization with dynamically switchable stages. This framework introduces two auxiliary tasks: one that operates during the exploration and transition stages to accelerate convergence towards the boundary of the infeasible regions and assist the population in crossing it, and another that operates in the final convergence stage to guide the population towards the constrained Pareto front. Moreover, a stage detection method is proposed, which evaluates the current stage to determine the appropriate evolutionary direction for the population, thus enabling dynamic stage transitions. In addition, a neural network-assisted search operator is designed for the auxiliary task during the transition stage, which learns the optimal offspring generation process. This operator enhances the ability of the auxiliary population to cross the infeasible regions. Finally, the performance of the proposed algorithm is superior and competitive on three test suites and six real-world engineering problems compared to seven state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Qianlong Dang and Xinkang Hong and Xianpeng Sun},
  doi          = {10.1016/j.eswa.2025.129761},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129761},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids. <em>ESWA</em>, <em>298</em>, 129760. (<a href='https://doi.org/10.1016/j.eswa.2025.129760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of smart grids is progressively extending toward Integrated Energy Systems (IES) that couple electricity with gas, heating, and cooling. Due to the unsteady-state physical characteristics inherent in the transmission of gas, heat, and cooling resources, IES scheduling must not only balance multiple typical objectives but also account for the dynamic coupling of heterogeneous physical domains. To address these challenges, this paper formulates a Many-objective Optimization Model for Coupled Multi-Energy Flows (MaOCMFM) with partial differential equations (PDEs) in IES, which captures the dynamic physical behaviors of electricity, gas, heat, and cooling subsystems. Building upon this model, we propose a Probabilistic Contributing Many-objective Evolutionary Algorithm enhanced by a Physics-Informed Neural Network surrogate model (PC-MaOEA-PINN). Cubic B-spline functions are employed to achieve a continuous representation of the decision variables, while multi-physics constraints are embedded into the loss function of the surrogate model. This design enables efficient approximation of the objective function with a limited number of samples and facilitates focused exploration in critical evolutionary regions, thereby accelerating population convergence. The effectiveness of the proposed model and algorithm is validated on 9 typical scheduling days across four simulated IES scenarios.},
  archive      = {J_ESWA},
  author       = {Jingbo Zhang and Xingjuan Cai and Zhihua Cui and Jinjun Chen},
  doi          = {10.1016/j.eswa.2025.129760},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129760},
  shortjournal = {Expert Syst. Appl.},
  title        = {A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An emergency scheduling method based on AutoML for space maneuver objective tracking. <em>ESWA</em>, <em>298</em>, 129759. (<a href='https://doi.org/10.1016/j.eswa.2025.129759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large-scale constellations has led to a dramatic increase in the number of Resident Space Objectives (RSOs), significantly intensifying the complexity of Space Situational Awareness (SSA). Furthermore, the maneuver behaviors of non-cooperative RSOs pose potential threats to space safety, making the real-time monitoring of their post-maneuver orbital becomes more critical. In particular, the maneuvering characteristics of large-scale constellation satellites impose more stringent demands on the timeliness and adaptability of existing scheduling algorithms for observation resources. To address the emergency scheduling demands of heterogeneous ground-based observation resources, this paper proposes an Emergency Task Three-phase Scheduling Framework (ETTSF) based on Automated Machine Learning (AutoML) and auction algorithm. The framework collaboratively optimizes resource allocation through three phases: resource matching, task scheduling, and rescheduling. First, AutoML combined with an auction algorithm predicts and assigns emergency tasks to the most appropriate resources, reducing solution space complexity, simultaneously, the auction algorithm’s corrected results are fed back to AutoML for model fine-tuning. Second, a heuristic algorithm with dynamic neighborhood structures efficiently inserts emergency tasks into the routine observation plan. Finally, affected routine tasks are rescheduled to minimize the operational impact. Simulation results demonstrate that compared to baselines-Real-Time Dynamic Scheduling (RTDS) and Improved Adaptive Large Neighborhood Search (IALNS)-ETTSF achieves a 2.82% improvement in Completion Rate of Emergency RSOs (CRER) and a 27.83% reduction in Impact Rate (IR) on routine tasks. Ablation experiments further validate the effectiveness of the resource matching and rescheduling phases.},
  archive      = {J_ESWA},
  author       = {Xi Long and Jinrun Chen and Leping Yang and Huan Huang},
  doi          = {10.1016/j.eswa.2025.129759},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129759},
  shortjournal = {Expert Syst. Appl.},
  title        = {An emergency scheduling method based on AutoML for space maneuver objective tracking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting point-language models with dual-prompts for 3D anomaly detection. <em>ESWA</em>, <em>298</em>, 129758. (<a href='https://doi.org/10.1016/j.eswa.2025.129758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) in 3D point clouds is crucial in a wide range of industrial applications, especially in various forms of precision manufacturing. Considering the industrial demand for reliable 3D AD, several methods have been developed. However, most of these approaches typically require training separate models for each category, which is memory-intensive and lacks flexibility. In this paper, we propose a novel P oint- L anguage model with dual-prompts for 3D AN omaly d E tection (PLANE). The approach leverages multi-modal prompts to extend the strong generalization capabilities of pre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD, achieving impressive detection performance across multiple categories using a single model. Specifically, we propose a dual-prompt learning method, incorporating both text and point cloud prompts. The method utilizes a dynamic prompt creator module (DPCM) to produce instance-specific dynamic prompts, which are then integrated with class-specific static prompts for each modality, effectively driving the PLMs. Additionally, based on the characteristics of point cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to improve the model’s detection capabilities in the unsupervised setting. Experimental results demonstrate that the proposed method, which is under the multi-class-one-model paradigm, achieves a +8.7 %/+7.0 % gain on anomaly detection and localization performance as compared to the state-of-the-art one-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains +4.3 %/+0.3 % gain for the Real3D-AD dataset. Code will be available upon publication.},
  archive      = {J_ESWA},
  author       = {Jiaxiang Wang and Haote Xu and Xiaolu Chen and Haodi Xu and Yue Huang and Xinghao Ding and Xiaotong Tu},
  doi          = {10.1016/j.eswa.2025.129758},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129758},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting point-language models with dual-prompts for 3D anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective. <em>ESWA</em>, <em>298</em>, 129757. (<a href='https://doi.org/10.1016/j.eswa.2025.129757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver vigilance is a critical cognitive factor in ensuring the safety of intelligent driving systems. With advances in physiological and behavioral sensing technologies, multimodal data have become an essential source for modeling drivers’ cognitive states. However, vigilance, as an implicit cognitive state, is difficult to model accurately using a single modality. Efficient fusion of multiple modalities and structured information interaction remains a core challenge in this task. Existing approaches often rely on strategies such as feature concatenation and attention mechanisms, which lack explicit structural constraints. As a result, heterogeneous modality features are fused in an uncontrolled and entangled manner, making the interaction process opaque and difficult to interpret. To address these issues, we propose the Path-Aware Routing System (PARS), which formulates multimodal fusion as a feature routing task. In PARS, intra-modal enhancement and cross-modal interaction are abstracted into independent semantic channels, and a confidence-aware mechanism is introduced to enable dynamically weighted fusion. PARS explicitly constructs a path space, allowing features to be selectively routed and integrated along semantical pathways, thereby enhancing the model’s discriminative power and robustness. We conduct extensive experiments on a public dataset and a self-constructed driving simulation dataset. The results demonstrate that PARS significantly outperforms existing multimodal fusion methods in the task of driver vigilance estimation, achieving superior performance in terms of accuracy, interpretability, and generalization. These findings highlight the broad potential of PARS in intelligent driving applications. Our code and models are available at: https://github.com/SunYu-Gavin/PARS .},
  archive      = {J_ESWA},
  author       = {Yu Sun and Shiwu Li and Yiming Bie and Linhong Wang and Tongtong Jin and Mengzhu Guo and Zhifa Yang},
  doi          = {10.1016/j.eswa.2025.129757},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129757},
  shortjournal = {Expert Syst. Appl.},
  title        = {Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Homophone-aware offensive language detection via semantic-phonetic collaboration. <em>ESWA</em>, <em>298</em>, 129756. (<a href='https://doi.org/10.1016/j.eswa.2025.129756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of implicit and obfuscated expressions poses significant challenges to offensive language detection in Chinese online platforms. In particular, users often exploit homophone substitutions to bypass keyword-based moderation, making traditional detection systems inadequate. This study addresses the problem of detecting offensive content masked through homophonic substitutions, which retain aggressive intent while altering character representations. Existing methods fall into two main categories: (1) semantic-only models, which struggle with phonetic manipulations due to their reliance on text features alone, and (2) auxiliary-enhanced models, which incorporate phonetic or syntactic signals but lack deep integration between modalities. To overcome these limitations, we propose a lightweight dual-branch model that separately encodes textual semantics and pinyin phonetics under a multi-view learning framework. A Dual-Branch Interactive Training strategy is introduced to enable dynamic cross-modal alignment via contrastive objectives, allowing each modality to mutually refine the other and enhance robustness to adversarial inputs. We conduct experiments on two benchmark datasets, COLD and SWSR, both of which are augmented with varying levels of homophone noise to simulate real-world evasion strategies. The proposed model outperforms all baseline models, achieving an average F1-score improvement of 6.3 % under high-noise conditions, while reducing inference latency and memory usage by more than 60 %, demonstrating both effectiveness and efficiency for real-time deployment. We will release the source code for further use by the community https://github.com/hjhhlc/DBIT .},
  archive      = {J_ESWA},
  author       = {Jiahao Hu and Shanliang Pan},
  doi          = {10.1016/j.eswa.2025.129756},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129756},
  shortjournal = {Expert Syst. Appl.},
  title        = {Homophone-aware offensive language detection via semantic-phonetic collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing traffic signal control through model-based reinforcement learning and policy reuse. <em>ESWA</em>, <em>298</em>, 129755. (<a href='https://doi.org/10.1016/j.eswa.2025.129755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and conditions of the road network used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies, and environment models using predefined source-domain traffic scenarios. The environmental model predicts state transitions, facilitating the comparison of environmental characteristics. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.},
  archive      = {J_ESWA},
  author       = {Yihong Li and Chengwei Zhang and Furui Zhan and Wanting Liu and Kailing Zhou and Longji Zheng},
  doi          = {10.1016/j.eswa.2025.129755},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129755},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing traffic signal control through model-based reinforcement learning and policy reuse},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer. <em>ESWA</em>, <em>298</em>, 129754. (<a href='https://doi.org/10.1016/j.eswa.2025.129754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Performance Computing (HPC) systems increasingly require intelligent, scalable anomaly detection to ensure operational reliability. However, conventional centralized approaches often struggle with data privacy constraints, poor generalization across heterogeneous nodes, and limited scalability. This study presents the first real-world application of federated transfer learning (FTL) for anomaly detection in a production-grade Tier-0 supercomputer. By combining federated learning with transfer learning, the proposed framework enables decentralized model training and personalized adaptation to unseen nodes, without accessing raw data. We validate the approach using two large-scale telemetry datasets collected from 100 nodes of the Marconi100 supercomputer, evaluating its effectiveness across supervised, semi-supervised, and unsupervised learning paradigms. Results show that FTL consistently improves anomaly detection performance on nodes that did not participate in federated training, with F1-score gains reaching up to 0.50. These improvements demonstrate the framework’s ability to generalize across non-identically distributed data and maintain detection accuracy under real-world conditions. This work establishes FTL as a scalable, privacy-preserving solution for fault detection in HPC environments. Its practical deployment on production hardware confirms its readiness for real-time monitoring applications in large-scale, heterogeneous computing systems.},
  archive      = {J_ESWA},
  author       = {Emmen Farooq and Michela Milano and Andrea Borghesi},
  doi          = {10.1016/j.eswa.2025.129754},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129754},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Security script arrangement based on enhanced BERT for cooperative defense in networked control systems. <em>ESWA</em>, <em>298</em>, 129753. (<a href='https://doi.org/10.1016/j.eswa.2025.129753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the mutual collaboration and in-depth integration among multiple defense technologies through information sharing, the cooperative defense in networked control systems has emerged as a feasible solution to counter increasingly diversified cyber threats under the unique security characteristics and requirements of industrial environments. However, one of the chief challenges is how to automatically and intelligently develop effective cooperative working strategies when an attack occurs. Leveraging the advantages of large-scale AI (Artificial Intelligence) models, this paper defines a new concept named “security script”, and proposes a security script arrangement approach based on enhanced BERT to achieve fine-grained cooperative defense in networked control systems. Furthermore, this approach introduces intrusion detection and industrial firewall as two practical examples, and can automatically arrange effective security scripts to enable the dynamic interaction of two defense technologies. Additionally, to improve efficiency, the encoder structure adjusting and AdamW optimizing are further presented to enhance the traditional BERT. Experimental results clearly demonstrate that: for one thing, these two optimization ways can make greater achievements in reducing unnecessary time consumption and enhancing accuracy of security script arrangement; for another, compared with other typical BERT and large-scale AI models, the proposed approach can exhibit more favorable performance advantages in achieving cooperative defense based on security script arrangement. In particular, through its successful application and verification in one real-world manufacturing control system, our approach may bring a potential opportunity or direction for further research and improvement of AI-based cooperative defense.},
  archive      = {J_ESWA},
  author       = {Ming Wan and Xueqing Liu and Shengbao An and Aiping Tan and Xi Jin and Chuan Sheng},
  doi          = {10.1016/j.eswa.2025.129753},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129753},
  shortjournal = {Expert Syst. Appl.},
  title        = {Security script arrangement based on enhanced BERT for cooperative defense in networked control systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anatomically-robust and feature-unbiased domain generalization for medical segmentation. <em>ESWA</em>, <em>298</em>, 129752. (<a href='https://doi.org/10.1016/j.eswa.2025.129752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-source domain generalization (SSDG) in medical image segmentation is severely hindered by limited single-source data and inter-domain biases. Existing methods often focus on appearance bias, neglecting crucial organ shape bias arising from differing acquisition protocols or patient populations and feature bias arising from learned confounding context by network. Therefore, we develop an anatomically-robust and feature-unbiased (ARFU) framework. Specifically, to generate morphologically sound and stylistically diverse training data, ARFU synergistically employs shape regularization-guided augmentation (SRG) and anatomical prior-guided augmentation (APG). The SRG leverages intrinsic structural information from low-frequency as a regularization to guide global appearance transformations while preventing anatomical distortion. APG learns a universal organ shape distribution from the variety of training masks, while simultaneously using organ-specific appearance augmentation to enforce an appearance-agnostic anatomical discrimination. To ensure that the network focuses on discriminative and domain-invariant representations of anatomical features, the feature unbiased learning (FUL) module is designed. FUL perturbs feature distributions by treating intra-batch variance as pixel-wise uncertainty to reduce the model’s reliance on domain-specific cues, and then dynamically filters in the frequency domain to adaptively suppress domain-specific noise and irrelevant background patterns. Extensive experiments on abdominal cross-modality and cardiac cross-sequence segmentation tasks demonstrate that our ARFU framework achieves superior generalization performance compared to state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Bijuan Ren and Yanfeng Li and Jia Sun and Houjin Chen and Luyifu Chen},
  doi          = {10.1016/j.eswa.2025.129752},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129752},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anatomically-robust and feature-unbiased domain generalization for medical segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering. <em>ESWA</em>, <em>298</em>, 129751. (<a href='https://doi.org/10.1016/j.eswa.2025.129751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in single-cell sequencing technologies have enabled researchers to better identify cells based on gene-level information. Cell clustering is a key task in single-cell analysis and plays an important role in distinguishing cell types. However, due to the high dimensionality and sparsity of scRNA-seq data, single-cell clustering remains a major challenge. Although many methods based on deep learning and machine learning have been developed for single-cell clustering, they often fail to capture the deep topological structure between cells, which limits clustering precision. In addition, most existing clustering approaches cannot effectively construct suitable sample pairs to optimize clustering models. To address these issues, we propose a topology-aware deep contrastive clustering model for single-cell data, named scSCDT. First, scSCDT employs a ZINB-based autoencoder to simultaneously learn cell embeddings and topological information, effectively handling the challenges posed by the high-dimensional and sparse nature of the data. Then, we introduce a dual clustering-guided loss to supervise the clustering task, combining a probabilistic soft assignment strategy and a hard pseudo-labeling strategy for optimization. Finally, based on the topological structure in the low-dimensional embedding space, we construct negative pairs within a single view and design a self-contrastive learning method to further improve clustering performance. We conduct extensive experiments on ten real scRNA-seq datasets and evaluate performance using four clustering metrics. The results indicate that scSCDT achieves strong clustering performance across multiple datasets, thereby facilitating more accurate cell type identification in single-cell transcriptomic analysis.},
  archive      = {J_ESWA},
  author       = {Zhongyang Zhou and Bin Tang and Feiyu Chen and Wei Wang and Shangshang Zhao and Nanjun Yu},
  doi          = {10.1016/j.eswa.2025.129751},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129751},
  shortjournal = {Expert Syst. Appl.},
  title        = {ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography. <em>ESWA</em>, <em>298</em>, 129749. (<a href='https://doi.org/10.1016/j.eswa.2025.129749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic (PA) imaging is a powerful non-invasive medical imaging technique that combines the high contrast of optical imaging with the deep tissue penetration of ultrasound, offering both structural and functional insights into tissues and organs. Organ-level analysis of photoacoustic tomography (PAT) images enables quantification of specific morphological and functional parameters, making accurate organ segmentation a critical step in PA image-based analysis. However, the limited availability of large-scale annotated datasets remains a major challenge. To address this, we employ cross-modality data augmentation by generating synthetic PA images from MRI scans. To further reduce manual annotation efforts, we propose a weakly supervised learning (WSL) framework that leverages scribble annotations. Since many deep learning models struggle to capture global context from sparse labels, we introduce a novel architecture that combines traditional convolutional neural networks (CNNs) with Visual Mamba, integrating both local and global feature extraction capabilities. This hybrid design improves segmentation performance in weakly supervised settings. We validate our method on a simulated PA abdominal dataset and real in vivo mouse abdominal PAT data, demonstrating notable improvements in segmentation accuracy and robustness.},
  archive      = {J_ESWA},
  author       = {Meng Zhou and Ziyin Ren and Qinlin Tan and Xin Du and Hengrong Lan and Fei Gao and Raymond Kai-Yu Tong},
  doi          = {10.1016/j.eswa.2025.129749},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129749},
  shortjournal = {Expert Syst. Appl.},
  title        = {Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D modeling from a single sketch with multifaceted semantic understanding. <em>ESWA</em>, <em>298</em>, 129748. (<a href='https://doi.org/10.1016/j.eswa.2025.129748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3D shape generation from a single sketch. Prior works rely on directly extracted visual features of sketches as guidance for the generation process. However, the sparse visual cues and abstract nature of sketches, which are inherited in the guiding features, lead to semantic ambiguity and geometry incompleteness in the generated shapes, compromising accuracy. To address this, we propose MSU-3D, a diffusion-based framework for sketch-to-3D generation, leveraging Multifaceted Semantic Understanding to explicitly analyze the construction information of sketches from multiple facets before providing fine-grained guidance over 3D shape generation. Specifically, we decompose sketches through three interpretative facets (semantics, depth, and normal), introducing reasoning of three representations to capture 3D features from distinct perspectives: local components, basic 3D geometry, and 3D surface details. One step further, we propose a multifaceted perception module. It aggregates multifaceted feature representations and leverages local component features as a two-pronged guiding representation to jointly guide the perception of basic shapes and surface details. To ensure fine-grained control, the hierarchical perception strategy adaptively injects varying granularity of perception features at different stages of the 3D generation. Extensive experiments and comparisons with state-of-the-art methods on various complex posture datasets validate the effectiveness of our framework in mitigating semantic ambiguity and geometry incompleteness in 3D generation.},
  archive      = {J_ESWA},
  author       = {Yuxiao Zhang and Jin Wang and Yang Zhou and Senyun Jia and Zhi Zheng and Dongliang Zhang and Guodong Lu},
  doi          = {10.1016/j.eswa.2025.129748},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129748},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D modeling from a single sketch with multifaceted semantic understanding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample. <em>ESWA</em>, <em>298</em>, 129747. (<a href='https://doi.org/10.1016/j.eswa.2025.129747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shimmering Image Enhancement and Defogging (SIED) are two important aspects of image recovery. However, most methods are often fail to consider image context information, overexposure of image and the intrinsic correlation between SIED without enough sample. Furthermore, current methods may lead to the amplification of external color interference during image recovery, and can’t fine-tune the model with new samples. Firstly, we propose an Adjustable Multiscale Attention Codec Network (AMACNet) architecture. AMACNet includes variable restorative coder decoder and group channel attention to fuse multi-level contextual and channel information of images, respectively. These components are designed as plug-and-play modules. Secondly, a Continuous Learning with Small Sample (CLS) training method is presented. It utilizes few samples based on a front-and-back stage receding structure. The method synergizes the tasks of SIED, allowing the network to perform both tasks without incresing the number of parameters. It also enables the network to adapt to new tasks with a small number of unpaired samples. Finally, a color adjustment module for image post-processing is designed. The post-processing method is used to balance the impact of color illumination on the inherent color of materials. Extensive experiments demonstrate that training AMACNet by CLS allow the final image recovery results to exceed the GT in terms of ENIQA, FES, PIQE, and other unparameterized metrics.},
  archive      = {J_ESWA},
  author       = {Fenglin Yao and Zhengxiang Liu},
  doi          = {10.1016/j.eswa.2025.129747},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129747},
  shortjournal = {Expert Syst. Appl.},
  title        = {Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning domain-invariant representation for generalizable iris segmentation. <em>ESWA</em>, <em>298</em>, 129746. (<a href='https://doi.org/10.1016/j.eswa.2025.129746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain iris segmentation (CDIS) seeks to transfer knowledge from a labeled source dataset to an unlabeled target dataset. Existing CNN-based iris segmentation methods commonly assume that training and application stages share the same data distribution and modality setting, thus their performance may decline substantially on open-domain iris datasets unseen before. Furthermore, the process of annotating pixel-wise labels is labor-intensive and time-consuming, resulting in limited applicability of these methods in realistic scenarios. Therefore, we propose a generic domain adaptation iris segmentation framework ( DAIrisSeg ), which can be flexibly incorporated into existing methods. First, a domain-sensitive feature whitening strategy is proposed to effectively mitigate the domain-specific styles while preserving the domain-invariant content, thereby improving the model’s generalizability to unknown domain distribution. We then utilize the prototype estimation and the context-similarity learning adapter to produce reliable segmentation labels. In addition, DAIrisSeg incorporates prior constraints of the iris to further refine the segmentation results. Extensive experiments on three iris datasets demonstrate that the proposed method has shown consistent improvements over state-of-the-art (SOTA) methods.},
  archive      = {J_ESWA},
  author       = {Dawei Lin and Meng Yuan and Ying Chen and Xiaodong Zhu and Yuanning Liu},
  doi          = {10.1016/j.eswa.2025.129746},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129746},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning domain-invariant representation for generalizable iris segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings. <em>ESWA</em>, <em>298</em>, 129745. (<a href='https://doi.org/10.1016/j.eswa.2025.129745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial multimodal anomaly detection is confronted with three pivotal challenges: cross-modal feature drift, noise sensitivity, and modality imbalance. To address these issues, we propose Cycle-Consistent Cross-Modal Feature Mapping (Cycle-CFM), an unsupervised framework that integrates cycle-consistent cross-modal mapping with channel-attention-guided adaptive loss weighting. Cycle-CFM establishes bidirectional feature alignment between RGB and 3D modalities via reversible cycle mappings, yielding consistent representations robust to vibration and depth noise. To further mitigate dynamic interferences such as illumination variations, we introduce a joint optimization strategy that combines cross-consistency and cycle-consistency losses. Experimental results on our self-constructed SteelDefect-3D-AD dataset demonstrate that Cycle-CFM achieves an AUPRO@1 % of 0.371, outperforming state-of-the-art methods by 17–45 %. It also attains a pixel-level AUROC (P-AUROC) of 0.991 and an image-level AUROC (I-AUROC) of 0.998. On the public MVTec 3D-AD benchmark, Cycle-CFM reaches a mean P-AUROC of 0.960 and improves accuracy by 37.5 % for elongated anomalies. With a runtime of 11.03 FPS and 469.52 MB of parameters, the model highlights both its effectiveness and deployability for real-time industrial inspection.},
  archive      = {J_ESWA},
  author       = {Yikang Shi and Xin Zhan and Yaqian Li and Zhongqiang Wu and Wenming Zhang and Haibin Li},
  doi          = {10.1016/j.eswa.2025.129745},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129745},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data. <em>ESWA</em>, <em>298</em>, 129743. (<a href='https://doi.org/10.1016/j.eswa.2025.129743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon mitigation policies and emission trading systems have heightened the need to monitor and predict the carbon emission intensity (CEI) of coal-fired power plants. Leveraging big data and machine learning (ML) technologies, this study trains predictive models of CEI using operational parameters, load rate, and coal-quality data from three Chinese power plants. The performance of Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM), and Artificial Neural Network (ANN) was evaluated, and the challenge of limited data in individual plants was mitigated through instance-based transfer learning (ITL) and graft learning (GL) technologies. The results indicate that while traditional ML models struggle with poor data quality and limited samples, transfer learning between different plants will improve predictive accuracy substantially, and GL delivers the greatest gains. Among the most influential features, air supply temperature and load rate critically impact CEI and therefore should be carefully managed to achieve emission reductions. Nevertheless, the effectiveness of transfer learning depends on source data quality and model choice, and the proposed operational strategies require further validation before practical adoption. Our findings offer a robust framework for enhancing the predictive accuracy of plant CEI under data-scarce conditions and inform effective strategies for promoting a low-carbon transition in the energy sector.},
  archive      = {J_ESWA},
  author       = {Xiaodong Jin and Lingzhen Zhang and Fangyi Li and Wu Xie and Dawei Ma and Yan Wu},
  doi          = {10.1016/j.eswa.2025.129743},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129743},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis. <em>ESWA</em>, <em>298</em>, 129742. (<a href='https://doi.org/10.1016/j.eswa.2025.129742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis is crucial for ensuring the safety and reliability of modern industrial systems. However, the performance of deep learning models often significantly degrades due to the domain shift between training and testing data. Domain Adaptation (DA) methods, particularly bi-classifier adversarial networks, have proven effective in transferring knowledge from a labeled source domain to an unlabeled target domain. However, existing approaches often pay insufficient attention to target sample prediction accuracy, resulting in reduced feature discriminability and generalization. Additionally, due to the absence of labeled target data, most approaches rely on pseudo-labels, which are often noisy and unreliable, especially in the early stages of training. To address these issues, this paper proposes a novel uncertainty-guided denoising bi-classifier adversarial domain adaptation network (UGDBAN) for cross-domain fault diagnosis. Specifically, a feature generator based on Transformer layers is designed to capture long-range dependencies and local features. To mitigate the impact of noisy pseudo-labels, an uncertainty-based denoising pseudo-labeling mechanism is introduced to enhance the discriminability of features by redefining pseudo-labels and dynamically selecting high-confidence samples as clean samples. Building upon this denoised pseudo-label set, a Dirichlet uncertainty estimation-based class prototype alignment strategy is proposed to align domain features at the class level by selecting low-uncertainty samples representative of each class as prototypes. Extensive experiments demonstrate the effectiveness of UGDBAN, and comparative results with mainstream methods highlight its superiority.},
  archive      = {J_ESWA},
  author       = {Zheng Li and Lei Geng and Yanbei Liu and Feng Rong and Ming Ma and Jun Tong and Zhitao Xiao},
  doi          = {10.1016/j.eswa.2025.129742},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129742},
  shortjournal = {Expert Syst. Appl.},
  title        = {Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partially view-aligned clustering via data recoupling and elastic bi-consistency learning. <em>ESWA</em>, <em>298</em>, 129741. (<a href='https://doi.org/10.1016/j.eswa.2025.129741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-view data often suffer from partial view alignment issues, yet most existing multi-view clustering (MVC) methods assume that the data are fully aligned, which is rarely the case in real-world scenarios. This misalignment leads to False Negative Pairs (FNPs), disrupting the learning process. While some methods address partial alignment, they often neglect intra-view consistency and multi-scale inter-view relationships, limiting their ability to capture both global and local structural dependencies. Additionally, the prevalent use of Mean Squared Error (MSE) as a reconstruction loss is suboptimal for discrete data, potentially causing severe performance degradation. To overcome these limitations, we propose Partially View-aligned Clustering via Data Recoupling and Elastic Bi-consistency Learning (PVC-DREBL). Our method integrates two key components: (1) a Data Recouple Module, which realigns the data to mitigate the effects of FNPs while leveraging an exponential contrastive loss to enhance learning stability and prevent overfitting; (2) an Elastic Bi-consistency Learning Module, designed to reconstruct diverse data types robustly while enforcing intra-view and multi-scale inter-view consistency. Extensive experiments on six benchmark datasets demonstrate that PVC-DREBL significantly outperforms existing methods, highlighting its effectiveness in handling partially view-aligned clustering tasks.},
  archive      = {J_ESWA},
  author       = {Wenzhe Liu and Jiongcheng Zhu and Jingbo Tan and Huibing Wang and Yong Zhang},
  doi          = {10.1016/j.eswa.2025.129741},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129741},
  shortjournal = {Expert Syst. Appl.},
  title        = {Partially view-aligned clustering via data recoupling and elastic bi-consistency learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots. <em>ESWA</em>, <em>298</em>, 129736. (<a href='https://doi.org/10.1016/j.eswa.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of elderly mobile robot technology, the training efficiency and path planning of robots have become key issues in research. Current mobile robot training faces challenges such as local optima and slow convergence speeds. To address these issues, this paper proposes a hierarchical path planning method based on deep reinforcement learning (H-DDQN). This method first introduces a global path planning module, which uses a density function to select high-value key points. In areas with dense obstacles, these key points provide the robot with effective global path guidance, enabling it to avoid getting stuck in a local optimum due to reliance solely on local information. In the local path planning module, we introduce a spatial attention mechanism based on global information, which weights global path points to enable the robot to focus on critical areas, thereby enhancing local decision-making capabilities and addressing dynamic obstacles on the basis of global optimality. Finally, this paper designs a new comprehensive reward function that combines path guidance from global key points with goal-oriented dense rewards, avoiding excessive unnecessary exploration and providing timely feedback to accelerate the model’s convergence speed. Experimental results show that compared to other existing algorithms, the H-DDQN algorithm converges more quickly during training and generates shorter and more efficient paths. In dynamic obstacle environments, the algorithm also demonstrates strong adaptability, combining global and local capabilities to achieve superior performance.},
  archive      = {J_ESWA},
  author       = {Jilin Zhang and Jia Qiao and Ke Huang and Menghua Zhang},
  doi          = {10.1016/j.eswa.2025.129736},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129736},
  shortjournal = {Expert Syst. Appl.},
  title        = {An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS. <em>ESWA</em>, <em>298</em>, 129735. (<a href='https://doi.org/10.1016/j.eswa.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable Energy Sources (RESs) help decarbonize power systems, but selecting among them is a challenging decision problem due to multiple, often conflicting, technical, economic, environmental, and health-related criteria. Consequently, numerous studies in the literature have attempted to address this decision-making issue using objective, subjective, and fuzzy decision-making procedures. However, there are still unaddressed research gaps in the literature, particularly regarding the explicit modeling of expert hesitation and ambiguity in real-world RES selection cases. The current study develops a decision-making model based on Step-wise Weight Assessment Ratio Analysis (SWARA) and Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) methods integrated with Interval-Valued q-Rung Orthopair Fuzzy Sets (IV-q-ROFSs) to fill these gaps. Unlike previous studies that have predominantly applied conventional fuzzy MCDM techniques, our model introduces the first integration of IV-q-ROFS into RES selection. This novelty enables a more accurate representation of expert hesitation and uncertainty. The study is applied to a real industrial case in Turkey, where six RES alternatives are evaluated across 43 criteria by five senior experts under the supervision of a three-member professionals’ board. Furthermore, the structured robustness check and systematic literature mapping ensure that the proposed approach is methodologically robust and practically relevant for policymakers and energy planners. The application results of the developed model demonstrate that the estimated energy production potential of the RES and the effects of carcinogens generated from utilizing these energy sources are the critical factors influencing the selection of the most appropriate RESs. Solar energy ranked first among the alternatives. The applicability and validity of the developed model are examined by a comprehensive robustness check consisting of tests of sensitivity, comparison, and resilience to the rank reversal problem. Overall, the study provides (i) a novel methodological framework integrating IV-q-ROFS with SWARA and TOPSIS, (ii) empirical evidence from a comprehensive real-world RES selection case, and (iii) policy-relevant insights into the drivers of renewable energy adoption.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Ahmet Aytekin and Selçuk Korucuk and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129735},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129735},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation. <em>ESWA</em>, <em>298</em>, 129733. (<a href='https://doi.org/10.1016/j.eswa.2025.129733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling language models have revolutionized widespread NLP tasks, yet little investigation has been conducted to assess the ability of Large Language Models (LLMs) to explore low-resource relation triplet extraction. This paper investigates essential methodologies, k -shot demonstration of in-context learning, and many-shot instruction tuning for few-shot and zero-shot relation triplet extraction using FlanT5, supported by exhaustive experiments. To enhance low-resource setting performance, we further propose different types of demonstration examples and task-related instructions for data generation. Specifically, we leverage LLMs to construct a structured prompt template for generating synthetic training data based on structured text and efficiently explore the boundary issues of examples in both instruction tuning and in-context learning, assessing their impact on model performance. To address the challenge of extracting multiple relation triplets from a single sentence, we design a novel Multiple Triplet Search (MTS) algorithm. Furthermore, we find that in-context learning can match the performance of previous prompt learning methods. Additionally, integrating synthetic data with the LLM can improve existing solutions in low-resource scenarios, achieving new state-of-the-art results. Experiments conducted on six relation extraction datasets demonstrate the efficacy of the proposed model for the zero-shot and few-shot RTE tasks. Our source code is publicly available at https://github.com/Phevos75/LLMRTE.},
  archive      = {J_ESWA},
  author       = {Qian Guo and Yi Guo and Jin Zhao},
  doi          = {10.1016/j.eswa.2025.129733},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129733},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection. <em>ESWA</em>, <em>298</em>, 129725. (<a href='https://doi.org/10.1016/j.eswa.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) image analysis faces the dual challenges of complex background interference and limited onboard computational resources, particularly when processing extreme scale variations across multiple viewpoints. Existing approaches typically enhance detection accuracy by increasing model complexity, but this often leads to parameter proliferation that exceeds the deployment limits of airborne platforms. To address this fundamental contradiction, we propose LDATA-Net (Lightweight Dynamic Aggregation Task-Aligned Network), which pioneers a “Dynamic Feature Adaptation” design paradigm aimed at achieving synergistic optimization between parameter efficiency and detection accuracy. This framework systematically realizes end-to-end dynamic adaptive capabilities through three core components that operate collaboratively across feature extraction, fusion, and detection stages: (1) Dynamic Multi-Branch Depthwise Block (DMBD-Block), whose core innovation is our proposed novel operator DIDWConv, which adaptively adjusts receptive fields according to input features to capture targets of extreme scales and orientations; (2) Lightweight Dynamic Aggregation Network (LDANet), which effectively preserves critical spatial contextual information through hierarchical fusion architecture and dynamic weighting mechanisms; (3) Dynamic Adaptive Head (DA-Head), which effectively mitigates task conflicts through geometric and semantic dynamic feature alignment. LDATA-Net achieves 35.4 %, 77.9 %, and 51.2 % AP 50 on VisDrone2019, DOTA1.0, and AI-TODv2 datasets respectively with only 2.8M parameters, establishing a new paradigm for designing memory-efficient yet high-performance detection systems, particularly for resource-constrained heterogeneous computing aviation platforms.},
  archive      = {J_ESWA},
  author       = {Shuming Lin and Sang Feng and Junnan Tan},
  doi          = {10.1016/j.eswa.2025.129725},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129725},
  shortjournal = {Expert Syst. Appl.},
  title        = {LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved actor-critic architecture with PPO for the traveling salesman problem. <em>ESWA</em>, <em>298</em>, 129723. (<a href='https://doi.org/10.1016/j.eswa.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is a classic NP-hard problem in combinatorial optimization with extensive practical applications. In this paper, we present an improved Actor-Critic architecture incorporating Proximal Policy Optimization (PPO) to effectively solve TSP. We introduce adaptive temperature scheduling, comprehensive state representation, and layer normalization to enhance learning stability. Experimental results demonstrate our Improved Actor-Critic approach achieves significant improvements ranging from 8.7 % to 55.9 % for different problem sizes compared to established reinforcement learning baselines including Q-Learning, SARSA, Double Q-Learning, Actor-Critic with Experience Replay (ACER), and Trust Region Policy Optimization (TRPO), with particularly strong performance on smaller instances between 20 to 100 cities. When testing on standard TSPLIB benchmarks, our method shows consistent advantages of 12 % to 33 % compared to classical approaches While tabular methods become computationally infeasible beyond 250 cities due to memory constraints, our approach maintains high solution quality for problems up to 1432 cities on our experimental setup (Intel® Core™i9-10900X CPU @ 3.70GHz × 20 with four NVIDIA Quadro RTX 5000 GPUs). Our ablation studies confirm the importance of each component in our proposed architecture, in which the improved state representation provides the most significant contribution to our model performance. This research significantly advances reinforcement learning approaches to combinatorial optimization, with practical implications for logistics, telecommunications, and manufacturing. The developed source code is available at: https://github.com/LetuQingge/TSP_Environment .},
  archive      = {J_ESWA},
  author       = {Hailemicael Lulseged Yimer and Pei Yang and Letu Qingge},
  doi          = {10.1016/j.eswa.2025.129723},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129723},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved actor-critic architecture with PPO for the traveling salesman problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application. <em>ESWA</em>, <em>298</em>, 129718. (<a href='https://doi.org/10.1016/j.eswa.2025.129718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization issue of the semi-Markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks is addressed, in which the dual-scale hybrid attacks mean that hybrid attacks can be encountered in different time scales transmission channels. Based on mismatched membership functions, a new ϵ -dependent combined synchronization controller is proposed to ensure the synchronization of the master semi-Markov jump two-time-scale fuzzy neural networks and the slave ones while it is capable of resisting independent dual-scale hybrid attacks. Through the development of a Lyapunov function incorporating the singular perturbation parameter ϵ , stability conditions and a computational approach for determining the synchronization controller gain are derived for semi-Markov jump two-time-scale fuzzy neural networks. Finally, some simulations and two encryption and decryption processes are used to show the effectiveness of obtained results.},
  archive      = {J_ESWA},
  author       = {Feng Li and Ya-Nan Wang and Lei Su and Sangmoon Lee},
  doi          = {10.1016/j.eswa.2025.129718},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129718},
  shortjournal = {Expert Syst. Appl.},
  title        = {Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery. <em>ESWA</em>, <em>298</em>, 129710. (<a href='https://doi.org/10.1016/j.eswa.2025.129710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unmanned aerial vehicle (UAV) and remote sensing technologies have propelled UAV object detection to the forefront of computer vision research. Despite significant progress in deep learning-based detection algorithms, critical challenges persist in small object detection, including high-frequency information loss, inadequate multiscale feature representation, etc. To address these limitations, this paper proposes Freq-DETR, a frequency-aware real-time transformer detection framework leveraging frequency domain analysis to enhance edge detail preservation and global contextual modeling through three novel innovations. First, the frequency-enhanced convolution module (FECM) synergistically integrates spatial and frequency features via dual-branch processing; Second, the decoupled intra-feature scale interaction module (DSC-Clo block) facilitates the integration of high-frequency local and low-frequency global information; Finally, the attention-guided selective feature pyramid network (AGS-FPN) employs context-aware attention for high-level screening feature fusion. Extensive evaluations on the VisDrone2019 benchmark demonstrate that Freq-DETR outperforms the baseline RT-DETR by 4.9 % m a p @ 50 gain while maintaining computational efficiency. There are also remarkable improvements on both UAVDT and HIT-UAV datasets. Ablation investigations and visual interpretability analyses further confirm the complementary benefits of its frequency-domain components and the framework’s robustness in complex aerial scenarios.},
  archive      = {J_ESWA},
  author       = {Jiayi Chen and Ningzhong Liu and Han Sun and Yu Wang},
  doi          = {10.1016/j.eswa.2025.129710},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129710},
  shortjournal = {Expert Syst. Appl.},
  title        = {Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expensive multiobjective immune algorithm using a novel differential evolution in objective space. <em>ESWA</em>, <em>298</em>, 129708. (<a href='https://doi.org/10.1016/j.eswa.2025.129708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating offspring solutions with strong convergence and diversity is critical when solving expensive multiobjective optimization problems due to the limited number of objective function evaluations. However, existing algorithms produce offspring solutions in the decision space, causing significant uncertainty in obtaining offspring with strong convergence and diversity. To address this issue, we devise a novel differential evolution based on the objective space rather than the decision space, called Differential Objective Evolution (DOE). Specifically, DOE generates objective values with strong convergence and diversity and then maps these values to the decision space to achieve high-quality offspring. Furthermore, we utilize a multiobjective immune algorithm to produce high-quality samples for effectively training the mapping in DOE. When compared with eleven recently proposed algorithms on 105 expensive multiobjective optimization problems, the experiments demonstrate the superiority of our algorithm and the contributions of DOE in both population convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Yuchao Su and Wu Lin and Daxin Zhu and Anhui Tan and Ka-Chun Wong and Qiuzhen Lin},
  doi          = {10.1016/j.eswa.2025.129708},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129708},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expensive multiobjective immune algorithm using a novel differential evolution in objective space},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning. <em>ESWA</em>, <em>298</em>, 129698. (<a href='https://doi.org/10.1016/j.eswa.2025.129698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems with complex and dynamic constraints pose significant challenges for evolutionary algorithms, as the constraints reshape the solution space and create conflicts between feasibility maintenance and global exploration. To address this issue, this study proposes TSC-PSODE, a two-stage evolutionary algorithm based on a hybrid penalty strategy. The algorithm employs an external penalty in the early stage to preserve population diversity and enhance exploration, while an internal penalty in the later stage accelerates convergence toward high-quality feasible solutions. In addition, a cooperative strategy combining differential evolution operators strengthens robustness and helps the population escape local optima. Experimental evaluations on the CEC2017 benchmark suite (the IEEE Congress on Evolutionary Computation 2017 benchmark) and multi-Unmanned Aerial Vehicle path planning tasks demonstrate that TSC-PSODE consistently outperforms state-of-the-art algorithms. The results confirm that the proposed method not only provides an effective mechanism for constraint handling, but also achieves a favorable balance between exploration and exploitation by maintaining diversity and accelerating convergence. In practical terms, TSC-PSODE is capable of generating safe and feasible flight paths for multiple UAVs in complex environments, highlighting its adaptability and competitiveness for real-world applications.},
  archive      = {J_ESWA},
  author       = {Eryang Guo and Yuelin Gao and Chenyang Hu},
  doi          = {10.1016/j.eswa.2025.129698},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129698},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated recommender system with data valuation for E-commerce platform. <em>ESWA</em>, <em>298</em>, 129695. (<a href='https://doi.org/10.1016/j.eswa.2025.129695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is gaining prominence in machine learning as privacy concerns grow. This paradigm allows each client (e.g., an individual online store) to train a recommendation model locally while sharing only model updates, without exposing the raw interaction logs to a central server, thereby preserving privacy in a decentralized environment. Nonetheless, despite the abundance of publicly available datasets that could substantially enrich local training, most existing FL-based recommender systems continue to rely only on private client data, leaving this potential largely unexplored. To this end, we consider a realistic scenario wherein a large shopping platform collaborates with multiple small online stores to build a global recommender system. The platform possesses global data, such as shareable user and item lists, while each store holds a portion of interaction data privately (or locally). Although integrating global data can help mitigate the limitations of sparse and biased clients’ local data, it also introduces additional challenges: simply combining all global interactions can amplify noise and irrelevant patterns, degrading personalization and increasing computational costs. To address these challenges, we propose, which selectively augments each client’s local graph with semantically aligned samples from the global dataset. employs: (i) a pre-trained graph encoder to extract global structural features, (ii) a local valid predictor to assess the client-specific relevance, and (iii) a reinforcement-learning-based probability estimator to filter and sample only the most pertinent global interactions. improves performance by up to 34.86% on recognized benchmarks in FL environments.},
  archive      = {J_ESWA},
  author       = {Jongwon Park and Minku Kang and Wooseok Sim and Soyoung Lee and Hogun Park},
  doi          = {10.1016/j.eswa.2025.129695},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129695},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated recommender system with data valuation for E-commerce platform},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG emotion recognition through a domain-adversarial multi-feature fusion network. <em>ESWA</em>, <em>298</em>, 129694. (<a href='https://doi.org/10.1016/j.eswa.2025.129694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of EEG signals linked to emotions is crucial for neuroscience and human-computer interaction. However, variability in EEG emotion recognition among individuals results in inconsistent feature distributions and limited generalization across subjects. To enhance the robustness of the model, we propose a deep learning approach integrating a domain adversarial migration network with an attention mechanism. Initially, a feature extractor with a hierarchical architecture (low-medium-high levels) is employed to capture multi-scale EEG features, which are then normalized for age and encoded for genderand education before being aligned with EEG features through spatio-temporal replication. Subsequently, global distribution alignment is achieved using multi-kernel maximum mean difference (MK-MMD), subdomain adversarial alignment is accomplished with a gradient inversion layer (GRL), and decision boundary clarity is enhanced through joint emotion classification loss. The generalization capability and effectiveness of the model are validated using the DEAP and DREAMER datasets, offering insights for cross-subject emotion recognition research and applications.},
  archive      = {J_ESWA},
  author       = {Weitong Sun and Yuping Su and Yumei Zhang and Xiaojun Wu},
  doi          = {10.1016/j.eswa.2025.129694},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129694},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG emotion recognition through a domain-adversarial multi-feature fusion network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFHD: Dual-granularity fusion network using historical drugs for drug recommendation. <em>ESWA</em>, <em>298</em>, 129693. (<a href='https://doi.org/10.1016/j.eswa.2025.129693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug recommendation is a task in clinical medicine aimed at suggesting a set of safe and effective medications based on a patient’s electronic health records. Current approaches either rely on diagnoses and procedures documented in electronic health records to recommend drug combinations or focus on enhancing drug recommendation safety by considering drug-drug interactions. However, these approaches often overlook the significance of historical medication information in drug recommendation despite its strong correlation with current diagnostic and prescription recommendation. Therefore, we propose a Dual-granularity Fusion Network using Historical Drugs. Specifically, at the time-series modeling level, recurrent neural networks are used to extract time-series features from historical drug data to construct coarse-grained drug characterizations. At the molecular structure modeling level, a graph neural network is used to build a relationship map between drug molecular structures and drug substructures to capture the fine-grained interactions within drug molecules. In addition, we designed a historical drug molecule awareness module to capture historical drug information during drug molecule modeling so as to identify the drugs that really help to cure patients. To effectively integrate dual-granularity information, we design a dual-granularity fusion module to realize the synergistic learning of temporal and structural features. To ensure drug safety, we introduce the DDI loss function to adaptively adjust the loss weights based on the drug interaction risk results, taking into account the optimization goals of efficacy and safety. Our source code is available at https://github.com/AK-321/DFHD .},
  archive      = {J_ESWA},
  author       = {Kang An and Ming-Yu Lu and Yan-Kai Tian and Yi-Jia Zhang},
  doi          = {10.1016/j.eswa.2025.129693},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129693},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFHD: Dual-granularity fusion network using historical drugs for drug recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129690. (<a href='https://doi.org/10.1016/j.eswa.2025.129690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For hyperspectral cross-scene classification (HSIC) tasks, the model is trained on the source domains (SDs) and applied directly to the unseen target domains (TDs). For this domain generalization (DG) challenge, a significant issue is the contradiction between the overparameterized model and the limited training domain, which results in the absorption of spurious correlations from environmental features. To alleviate this contradiction, this study proposes a domain extension generator with a feature decoupling network (FDNet). The generator initially decouples the SD into reflectance and shading components, treating them as causal and environmental features, respectively. Considering possible causal residues in environmental features, the shading components are shuffled by style to eliminate undesired correlations. Then, the reflectance and sparsified shading are reconstructed for extension, enriching the training diversity without environmental interference. In addition, to enhance the stability of class-level causal representation, a supervised aggregation strategy is designed to minimize the intra-class distance of the reflectance domain, and supervised contrastive learning is employed to enhance the class-domain semantic consistency information. Comparative analysis with advanced domain generalization and adaptation approaches on three HSI datasets validates the superiority in accuracy and Kappa coefficient metrics of the proposed method.},
  archive      = {J_ESWA},
  author       = {Hanqing Zhao and Lianlei Lin and Zongwei Zhang and Sheng Gao and Junkai Wang},
  doi          = {10.1016/j.eswa.2025.129690},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129690},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards intelligent online cross-selling. <em>ESWA</em>, <em>298</em>, 129686. (<a href='https://doi.org/10.1016/j.eswa.2025.129686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of online cross-selling for fashion demands a large number of qualified outfit compositions. This paper targets practical and intelligent online cross-selling by providing a more accurate fashion compatibility model and a reliable evaluation protocol for evaluating the fashion compatibility model. Firstly, a Hierarchical Outfit Network (HON) is proposed to leverage multi-layer relations among attributes, items, and outfits. The awareness of multiple relations hidden in various outfits enables the HON to outperform all state-of-the-art methods on fill-in-the-blank (FITB) accuracy and compatibility Area Under Curve (AUC) on the Maryland and Type-aware test sets. Meanwhile, a new evaluation protocol is introduced to assess the fashion compatibility model more objectively and accurately, namely, Aesthetic 100 (A100). A100 possess three desirable characteristics: 1) Completeness . All types of standards in the fashion aesthetic system are covered through two tests, namely LAT (Liberalism Aesthetic Test) and AAT (Academicism Aesthetic Test); 2. Reliability . It is an agnostic protocol and consistent with major indicators. It provides an objective and fair assessment for model comparison. 3. Explainability . A100 assesses the model on more fine-grained dimensions, e.g. , Color, Material, and Balance demonstrating its superiority in identifying essential characteristics of fashion aesthetics. Experimental results demonstrate the progress of A100 in the aspects of Reliability and Explainability. The evaluation results on A100 also show the generalization ability of HON from both quantitative and qualitative perspectives. Finally, solutions for multiple applications in fashion retailing are proposed to show how HON can be utilized to help online cross-selling.},
  archive      = {J_ESWA},
  author       = {Kaicheng Pang and Xingxing Zou and Zowie Broach and Waikeung Wong},
  doi          = {10.1016/j.eswa.2025.129686},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129686},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards intelligent online cross-selling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MECA: Modular editing via customized expert networks and adaptors in large language models. <em>ESWA</em>, <em>298</em>, 129675. (<a href='https://doi.org/10.1016/j.eswa.2025.129675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Updating language models with new information through targeted edits without resorting to expensive full model retraining remains a critical challenge, particularly when aiming to preserve pre-existing capabilities. In this work, we introduce M odular E diting via C ustomized expert networks and A daptors) (MECA), a unified framework that selectively integrates new knowledge into language models. MECA employs a module-level deferral router to evaluate whether incoming queries fall within the scope of existing edit requests. Queries are then dynamically routed to either customized editing experts or key-value adaptors. This modular strategy ensures that updates are localized, thereby mitigating risks of unintended alterations on unrelated outputs. We validate our approach on sequential editing tasks using Llama2-7B, Llama2-13B and Falcon 11B, benchmarked across two diverse datasets ZsRE and Hallucination. Experimental results show that MECA consistently outperforms several state-of-the-art knowledge editing techniques, achieving improved integration of new information while preserving the model’s original performance. Our analysis further demonstrates that the deferral routing mechanism for selecting modules effectively balances editing precision with overall model stability.},
  archive      = {J_ESWA},
  author       = {Roseline Nyange and Shanbao Qiao and Seung Hoon Na},
  doi          = {10.1016/j.eswa.2025.129675},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129675},
  shortjournal = {Expert Syst. Appl.},
  title        = {MECA: Modular editing via customized expert networks and adaptors in large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm. <em>ESWA</em>, <em>298</em>, 129673. (<a href='https://doi.org/10.1016/j.eswa.2025.129673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical power systems (CPPSs) are the deep integration of advanced information and other technologies applied to the grid to achieve fundamental changes in the power industry. Thus, it is very significant to enhance the robustness of the power communication system in order to ensure security. For instance, when an interdependent CPPSs is under attack, the failure can diffuse along interconnect topology to the whole system, even causing a system crash. Recall that most of the existing models are one-to-one coupling structures. Drawing close to reality, we develop a modified memetic algorithm to reconstruct CPPSs with multiple-to-multiple interlinks, called MA-Multiple, which is dedicated to improving the robustness of CPPSs. To improve the accuracy of the optimal solution of the MA-Multiple, we devise a crossover operator (CO) based on the null model to increase population diversity. Further improving the suitability of algorithms on CPPSs, we propose a new Kirchhoff centrality (KIC) based on the approximation of the inverse matrix to measure network connectivity and design a local search operator (LSO). In the experiment, we comprehensively compare the MA-Multiple with four closely relevant methods in different scenarios. The results imply that MA-Multiple performs better in enhancing network robustness and resisting attacks.},
  archive      = {J_ESWA},
  author       = {Wei Lin and Li Xu and Yuexin Zhang and Jie Li},
  doi          = {10.1016/j.eswa.2025.129673},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129673},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective portfolio optimization for stock return prediction using machine learning. <em>ESWA</em>, <em>298</em>, 129672. (<a href='https://doi.org/10.1016/j.eswa.2025.129672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach that integrates stock return prediction with the mean–variance (MV) model to enhance the performance of the original model. Firstly, stock returns are predicted using machine learning algorithms, including Robust Linear Regression (OLS-H), Random Forest (RF), and Long Short-Term Memory Networks (LSTM), to select a pre-screened stock pool composed of stocks with high predicted returns. Secondly, a linear weighting method combines the predictions above with the MV model, constructing the Mean-Variance-Forecast Error (MVF) model and determining the investment proportions for the pre-selected stocks. Finally, empirical research is conducted using the components of the CSI 300 Index as sample data. The results indicate that the RF + MVF model outperforms other models and the CSI 300 Index in return and risk metrics. At the same time, a sensitivity analysis of relevant parameters further confirms that considering return uncertainty is beneficial for improving the out-of-sample performance of the MV model.},
  archive      = {J_ESWA},
  author       = {Meiyu Huang and Shili Dang and Miraj Ahmed Bhuiyan},
  doi          = {10.1016/j.eswa.2025.129672},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129672},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective portfolio optimization for stock return prediction using machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN. <em>ESWA</em>, <em>298</em>, 129670. (<a href='https://doi.org/10.1016/j.eswa.2025.129670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are comprised of autonomous nodes, where the physical devices and other equipment are embedded for monitoring the environment. Yet, it consumes larger energy consumption while it fails to provide the optimal routing path. The data aggregation in WSN is accomplished by several classification approaches, but the delay and utilization of the resource are high. So, it is necessary to solve the challenges by implementing the developed model for the energy efficient routing in WSN. A distributed data mining scheme is developed based on a deep learning approach to provide greater energy efficiency and optimal load balancing in WSN. The distributed data mining is performed to distribute the appropriate data to the sensor nodes. This data distribution highly reduces the overhead at the fusion center. The data are categorized via Fused Deep Structural Network (FDSNet), where the Attention-based Dilated Deep Temporal Context Networks (DTCN) are fused with a Deep Shallow Network. The necessary data are distributed to the sensor nodes. The optimal routing is carried out based on optimal path selection using Stability Bound-based Energy Valley Optimizer (SBEVO). The optimal routing is done via the multi-objective functions such as “energy consumption, PDR, delay, and shortest path”. The energy-efficient data transmission is accomplished with the help of developed distributed data mining with a routing scheme. The developed energy-efficient optimal routing in WSN is compared to conventional routing approaches with several performance metrics to show energy efficiency. While comparing with existing methods, the developed model attains the value of 0.95% with regards of accuracy, precision, and F1-score. These findings of the developed model show accurate performance with an efficient routing mechanism in WSN.},
  archive      = {J_ESWA},
  author       = {Kiran Goud Palakuri and Manjeet Singh},
  doi          = {10.1016/j.eswa.2025.129670},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129670},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Curriculum learning for a hybrid approach for aspect-based sentiment analysis. <em>ESWA</em>, <em>298</em>, 129669. (<a href='https://doi.org/10.1016/j.eswa.2025.129669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, the amount of unstructured online review data has grown exponentially. Many people express their opinions about different aspects of goods and services on the Web. Aspect-Based Sentiment Analysis (ABSA) automatically extracts the sentiments with respect to aspects given in a sentence. We improve the training procedure of the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis with deep contextual word embeddings and hierarchical attention (HAABSA++). In this method, a domain sentiment ontology is used as a main classifier, and if it is not conclusive, a neural network is employed as a back-up. We extend the training of the neural network by incrementally adding more difficult instances, also known as curriculum learning. Restaurant reviews obtained from the SemEval-2015 and SemEval-2016 datasets are used to evaluate the effect of implementing curriculum learning. Using baby steps curriculum learning and a specific curriculum strategy, the accuracy of HAABSA++ is improved from 86.3 % to 87.5 %.},
  archive      = {J_ESWA},
  author       = {Nana Lange and Flavius Frasincar and Maria Mihaela Truşcǎ},
  doi          = {10.1016/j.eswa.2025.129669},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129669},
  shortjournal = {Expert Syst. Appl.},
  title        = {Curriculum learning for a hybrid approach for aspect-based sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation. <em>ESWA</em>, <em>298</em>, 129659. (<a href='https://doi.org/10.1016/j.eswa.2025.129659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge sources of large language models (LLMs) encompass both parametric internal knowledge and external contextual information. However, conflicts between these two sources can significantly impair model performance. Existing methods typically assume a priori correctness of either the context or the parametric knowledge, lacking dynamic coordination mechanisms and being limited to single-context scenarios. To address this issue, this work proposes a lightweight and training-free decoding method, M ulti- C ontext A daptive D ecoding ( MCAD-EUC ), which dynamically measures the effectiveness of both knowledge through E ntropy based U ncertainty C alibration. It does not concern itself with whether the knowledge is false or true, the internal or the external, but balancing them according to their contributions to correctly answering the question. Particularly, MCAD-EUC is naturally multi-contextual. It can dynamically amplify the distribution of golden context while mitigating the influence of noisy context, thereby optimizing the final logits for predicting the next token during the decoding process. To comprehensively evaluate the model performance in multi-context scenarios, this work constructs MCQA, a multi-context question answering dataset that includes golden context, irrelevant context, and six categories of misleading context (crowd, logic, temporal, authority, emotional, numeric), simulating the diversity of noise in real-world settings. Extensive experiments on four LLMs and four MCQA datasets demonstrate that MCAD-EUC achieves an average accuracy improvement of 3.17 % over the best-performing baseline methods. Further sensitivity analysis confirms that the entropy-based adaptive weighting mechanism consistently outperforms all fixed-weight settings. Our dataset and code will be publicly available.},
  archive      = {J_ESWA},
  author       = {Yimin Ou and Yifan Wang and Ping Jian and Tianhe Zhang and Xing Pei},
  doi          = {10.1016/j.eswa.2025.129659},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129659},
  shortjournal = {Expert Syst. Appl.},
  title        = {MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trust in recommender systems: A survey. <em>ESWA</em>, <em>298</em>, 129653. (<a href='https://doi.org/10.1016/j.eswa.2025.129653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-based recommender systems incorporate interpersonal trust relationships into the recommendation process, operating on the principle that users are more likely to accept suggestions from people they trust. Empirical studies have shown that trust-aware approaches often deliver more accurate recommendations than their trust-unaware counterparts. In this comprehensive, up-to-date survey, we analyze a variety of trust-based recommendation methods, categorize different trust inference techniques, and examine how trust is integrated into recommendation algorithms. We then organize the investigated approaches according to a clear taxonomy, explore their underlying concepts, and highlight the key challenges and open issues that remain in the field.},
  archive      = {J_ESWA},
  author       = {Imane Akdim and Loubna Mekouar and Youssef Iraqi},
  doi          = {10.1016/j.eswa.2025.129653},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129653},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trust in recommender systems: A survey},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers. <em>ESWA</em>, <em>298</em>, 129652. (<a href='https://doi.org/10.1016/j.eswa.2025.129652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a cost-effective, low-computation system for composite Human Activity Recognition (HAR) that leverages knowledge-distilled neural networks on a Microcontroller Unit (MCU) to minimize reliance on cloud processing. A key contribution of this work is the investigation of plantar pressure sensor data within a knowledge distillation framework, addressing a notable gap in the existing literature. The proposed solution centers around the ESP32-S3 DevKit C1, equipped with a dual-core 240 MHz Tensilica chip, 320 KiB of usable Static Random Access Memory (SRAM), and built-in Wi-Fi and Bluetooth. Significantly, both the teacher and the student models surpass existing state-of-the-art methods, achieving F1-scores of 99.33 %, 98.36 %, and 97.68 % respectively, in classifying a comprehensive set of 21 activities (15 composite and 6 simple). The distilled student models demonstrate remarkable efficiency, with execution times of 1.83 and 0.64 s, memory footprints of only 62 KB and 82 KB, and flash memory usage of approximately 209 KB and 127 KB, while maintaining low power consumption of 210 mW and 215 mW, respectively. Furthermore, we have developed an end-to-end prototype that integrates the ESP32-S3 with a WitMotion Inertial Measurement Unit (IMU) sensor. This system autonomously manages data acquisition, feature extraction, and inference in under 7 s with a total power consumption of approximately 295 mW.},
  archive      = {J_ESWA},
  author       = {Athar Noor Mohammad Rafee and John Clear and Jannatun Noor},
  doi          = {10.1016/j.eswa.2025.129652},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129652},
  shortjournal = {Expert Syst. Appl.},
  title        = {Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GE-adapter: A general and efficient adapter for enhanced video editing with pretrained text-to-image diffusion models. <em>ESWA</em>, <em>298</em>, 129649. (<a href='https://doi.org/10.1016/j.eswa.2025.129649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in text-to-image (T2I) generation using diffusion models have enabled cost-effective video-editing applications by leveraging pre-trained models, eliminating the need for resource-intensive training. However, the frame-independence of T2I generation often results in poor temporal consistency. Existing methods address this issue through temporal layer fine-tuning or inference-based temporal propagation, but these approaches suffer from high training costs or limited temporal coherence. To address these challenges, we propose a General and Efficient Adapter (GE-Adapter) that integrates temporal-spatial and semantic consistency with Baliteral DDIM inversion. This framework introduces three key components: (1) Frame-based Temporal Consistency Blocks (FTC Blocks) to capture frame-specific features and enforce smooth inter-frame transitions via temporally-aware loss functions; (2) Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateral filters to enhance spatial coherence by reducing noise and artifacts; and (3) Token-based Semantic Consistency Module (TSC Module) to maintain semantic alignment using shared prompt tokens and frame-specific tokens. Our method significantly improves perceptual quality, text-image alignment, and temporal coherence, as demonstrated on the MSR-VTT dataset. Additionally, it achieves enhanced fidelity and frame-to-frame coherence, offering a practical solution for T2V editing. The project page is https://github.com/codepassionor/T2I_Adapter .},
  archive      = {J_ESWA},
  author       = {Yangfan He and Sida Li and Kun Li and Jianhui Wang and Binxu Li and Tianyu Shi and Yi Xin and Keqin Li and Jun Yin and Miao Zhang and Xueqian Wang},
  doi          = {10.1016/j.eswa.2025.129649},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129649},
  shortjournal = {Expert Syst. Appl.},
  title        = {GE-adapter: A general and efficient adapter for enhanced video editing with pretrained text-to-image diffusion models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification. <em>ESWA</em>, <em>298</em>, 129647. (<a href='https://doi.org/10.1016/j.eswa.2025.129647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot one-class classification (FS-OCC) is a challenging classification problem that involves learning from a very limited number of training samples, all from a single class. Recently, several data description methods have been proposed to address the FS-OCC problem. Unlike conventional one-class classification problems, the few-shot setting requires the model to generalize to novel tasks with previously unseen positive classes. Most existing methods learn decision boundaries in the feature space without explicitly modeling the underlying data distributions, which limits the generalization ability of the learned representations. To address this issue, we propose Bayesian Rule-based Adaptive Hypersphere Data Description (BayesAHDD), a probabilistic framework that represents data with multivariate Gaussian distributions and performs classification according to the Bayes decision rule. Based on the assumption that negative samples are more dispersed in the feature space, BayesAHDD models the negative class by scaling the positive class variance vector element-wise using a learnable vector. To address the challenges of exploding gradients and numerical overflow, we impose a lower bound on the positive class variance vector and introduce a trainable parameter that integrates the class prior probability ratio with the normalization constants of the Gaussian class-conditional densities. Experimental results on both benchmark and domain-specific datasets show that BayesAHDD consistently outperforms existing baselines and state-of-the-art FS-OCC methods. Moreover, quantitative analysis demonstrates that the learned feature representations exhibit superior discriminative ability compared to those produced by previous approaches.},
  archive      = {J_ESWA},
  author       = {Yuchen Ren and Xiabi Liu and Yan Pei and Yunlong Li and Yongxia Wei},
  doi          = {10.1016/j.eswa.2025.129647},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129647},
  shortjournal = {Expert Syst. Appl.},
  title        = {BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making. <em>ESWA</em>, <em>298</em>, 129646. (<a href='https://doi.org/10.1016/j.eswa.2025.129646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an indispensable component of 5G and even the future 6G networks, the Space-Air-Ground Integrated Network (SAGIN) is envisioned to provide ubiquitous network connectivity and services by integrating satellite, aerial, and terrestrial networks. However, due to the frequent network selection of in-vehicle terminals, the user’s Quality of Service (QoS) can significantly deteriorate. To address this issue, a network selection algorithm based on terminal location prediction has been proposed. Firstly, we enhanced the Particle Swarm Optimization (PSO) algorithm to optimize the hyper-parameters of the Long Short-Term Memory (LSTM) network, thereby improving the accuracy of terminal location prediction. After constructing the network sets of the current terminal position and the predicted position, respectively, we designed a network selection judgment mechanism with a dynamically adjustable switching threshold based on Fuzzy Logic and K-Means theory. Finally, through the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) algorithm, we have achieved robust network selection in fast-moving scenarios. The simulation results show that the proposed algorithm can adaptively adjust the switching threshold and provide precise positions. Compared to existing algorithms, it can significantly reduce the number of candidate networks and the number of selections, thereby reducing the computational load and increasing the throughput of users.},
  archive      = {J_ESWA},
  author       = {Jianli Xie and Weicheng Pan and Lei Wu and Zishan Wu},
  doi          = {10.1016/j.eswa.2025.129646},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129646},
  shortjournal = {Expert Syst. Appl.},
  title        = {A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems. <em>ESWA</em>, <em>298</em>, 129645. (<a href='https://doi.org/10.1016/j.eswa.2025.129645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective anomaly detection heavily relies on accurately modeling the normal behavior of the industrial cyber-physical systems (ICPSs). Current popular data-driven black-box methods’ performance depends on the quantity and quality of data from the ICPS, rather than integrating with the intrinsic characteristics of the system, such as mass conservation and structural dependencies of industrial processes. The data used to train these models often fails to cover all operating conditions of ICPSs, resulting in a distributional mismatch between training and testing data. This limitation significantly reduces the generalization capability of trained data-driven models for detecting anomalies under unseen and unknown operational conditions. Meanwhile, constructing well-generalized behavior models using white-box mechanism models (MM)–which represent the internal behavior of controllers and physical processes using first-principles equations or physical laws, such as conservation principles and kinetic dynamics–is not always feasible in real-world industrial applications. To address this issue, this paper presents a novel anomaly detection approach employing a domain knowledge-embedded hybrid graph neural network (HGNN) that integrates control, physical, and structural characteristics of ICPSs into a data-driven modeling framework. It establishes a domain knowledge-based MM to predict the behavior of controllers and physical processes, and utilizes a HGNN model with embedded state topology and spatial distribution knowledge to compensate for the predictive error of MM, forming a hybrid model called mechanism-embedded HGNN (MEHGNN). This model can detect anomalies in unknown operational conditions by analyzing the predictive error of MEHGNN. In the experiments, MEHGNN raises the detection accuracy of GNNs from 36.6 %–82.4 % to 79.4 %–96.3 % under distribution shift scenarios, achieving the best detection performance among all compared methods.},
  archive      = {J_ESWA},
  author       = {Xin Du and Chunjie Zhou and Yu-Chu Tian and Bo Xu},
  doi          = {10.1016/j.eswa.2025.129645},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129645},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging. <em>ESWA</em>, <em>298</em>, 129638. (<a href='https://doi.org/10.1016/j.eswa.2025.129638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise identification of Alzheimer’s disease (AD) holds a crucial position in patient healthcare, particularly in the early stages. This early detection is essential, as it allows patients to understand the severity of the disease and take preventive measures before irreversible brain damage occurs. Although recent studies have harnessed machine learning techniques for Computer-Aided Diagnosis (CAD) of AD, many of these research efforts have encountered limitations in diagnostic performance. In this research, a novel AD detection system using Magnetic Resonance Imaging (MRI) is developed to identify subtle brain changes at an early stage through deep learning strategies. The goal is to reduce the risk for individuals facing challenges such as aging and brain-related diseases. The MRI images were obtained from the internet. The detection phase begins by receiving the MRI images. A Vision Transformer-based 3D Adaptive Residual DenseNet combined with a Gated Recurrent Unit (VARD-GRU) architecture is employed for effective AD identification. Here, the model parameters are optimized using the proposed Fitness-based Walrus Optimization Algorithm (FWOA). The AD detection system’s performance is evaluated against several existing frameworks using validation metrics to assess its effectiveness. The accuracy of the developed FWOA-VARD-GRU model is 94.11%. The results demonstrate that the FWOA-VARD-GRU model significantly enhances diagnostic accuracy, outperforming comparable methods. The model’s effectiveness confirms its strong capability in detecting early-stage AD. This system offers a promising approach to reduce risks for individuals affected by aging and neurological conditions by enabling timely and accurate detection.},
  archive      = {J_ESWA},
  author       = {Dr. A. Hemlathadhevi and Indumathy Paranthaman and Moorthy Agoramoorthy and Dr. Hari Kumar Palani},
  doi          = {10.1016/j.eswa.2025.129638},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129638},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto optimization of two-agent scheduling on parallel batch machines. <em>ESWA</em>, <em>298</em>, 129637. (<a href='https://doi.org/10.1016/j.eswa.2025.129637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a Pareto optimization problem of scheduling jobs of two competing agents on parallel batch machines. The jobs have equal processing times and non-identical job sizes. The objective is to find Pareto optimality and the corresponding schedules for minimizing both agents’ makespans. We analyze and identify an approximate Pareto region with a guarantee of 2-approximate Pareto optimal. We propose an integrated algorithm to find the approximate Pareto optimal points. Our computational study shows that the proposed algorithm outperforms the widely used non-dominated sorting genetic algorithm (NSGA-II), and that the obtained approximate Pareto optimal front is very close to the Pareto optimal front.},
  archive      = {J_ESWA},
  author       = {Cui-Lin Zhang and Guo-Qiang Fan},
  doi          = {10.1016/j.eswa.2025.129637},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129637},
  shortjournal = {Expert Syst. Appl.},
  title        = {Pareto optimization of two-agent scheduling on parallel batch machines},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ill-posed regions-aware self-supervised stereo matching with left-right consistency. <em>ESWA</em>, <em>298</em>, 129634. (<a href='https://doi.org/10.1016/j.eswa.2025.129634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo matching presents a significant challenge due to the difficulty in accurately matching pixels between two images. These challenging pixels are typically found in ill-posed regions, which include areas with weak or repetitive textures, occlusions, and invisible regions. In recent years, there has been extensive research into stereo matching methods based on deep learning. However, these methods often struggle to accurately handle ill-posed regions, resulting in limited improvements in accuracy. To address this issue, this paper introduces a stereo matching model, IASSM-LRC, that is not constrained by disparity range. This model employs self-attention and cross-attention from the Transformer for dense attention computation and generates an initial disparity map. To effectively manage ill-posed regions, invalid masks are generated using left and right disparity maps. The initial disparity map is then fine-tuned through these invalid masks. IASSM-LRC is trained in an unsupervised manner. Experimental results from multiple different scenes demonstrate that the IASSM-LRC model exhibits strong disparity prediction performance. On KITTI2015, its D1-fg metric is 13.48 %, outperforming both PASM-Net’s 16.36 % and Flow2Stereo’s 14.62 %. The prediction results on the self-built calibration board dataset and Middlebury dataset show that the model has better predictive performance for both textureless and repetitive texture regions and has better generalization performance.This method can improve disparity measurement and depth measurement in binocular universal scenes.},
  archive      = {J_ESWA},
  author       = {Shengwei Yang and Yuehang Wang and Zenghui Li and Shan Zhou and Zheng Wang and Yining Hu and Lizhe Xie},
  doi          = {10.1016/j.eswa.2025.129634},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129634},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ill-posed regions-aware self-supervised stereo matching with left-right consistency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An effective new penetration test approach to detect web attacks on web applications. <em>ESWA</em>, <em>298</em>, 129623. (<a href='https://doi.org/10.1016/j.eswa.2025.129623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As web applications increasingly involve sensitive transactions such as e-commerce, online banking, and public services, they have become primary targets for cyberattacks. Therefore, web application penetration testing is vital for discovering and protecting against vulnerabilities in web-based systems. This study introduces an automated penetration testing tool that systematically applies comprehensive penetration testing methodologies to effectively identify and mitigate web application vulnerabilities. The proposed tool uses a hybrid approach that includes automated and manual testing phases for multiple attacks, including SQL Injection, Cross-Site Scripting, and Cross-Site Request Forgery. System diversity is increased, and the penetration testing process is enriched using Python scripts and APIs. The tool provides an effective mechanism for uncovering critical vulnerabilities by simulating real-world attacker behavior. Practical evaluations on various web applications demonstrate the tool’s ability to identify vulnerabilities and increase system resilience. This research will help developers and security engineers apply this automated, specialized approach to security as our digital environment becomes more connected.},
  archive      = {J_ESWA},
  author       = {Muhammed Onur Kaya and Huseyin Alperen Dagdogen and Mehmet Ozdem and Resul Das},
  doi          = {10.1016/j.eswa.2025.129623},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129623},
  shortjournal = {Expert Syst. Appl.},
  title        = {An effective new penetration test approach to detect web attacks on web applications},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GSFF-SLAM: 3D semantic gaussian splatting SLAM via feature field. <em>ESWA</em>, <em>298</em>, 129601. (<a href='https://doi.org/10.1016/j.eswa.2025.129601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic-aware 3D scene reconstruction is essential for autonomous robots to perform complex interactions. Semantic SLAM, an online approach, integrates pose tracking, geometric reconstruction, and semantic mapping into a unified framework, shows significant potential. However, existing systems, which rely on 2D ground truth priors for supervision, are often limited by the sparsity and noise of these signals in real-world environments. To address this challenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D Gaussian Splatting that leverages feature fields to achieve joint rendering of appearance, geometry, and N-dimensional semantic features. By independently optimizing feature gradients, our method supports semantic reconstruction using various forms of 2D priors, particularly sparse and noisy signals. Experimental results demonstrate that our approach outperforms previous methods in both tracking accuracy and photorealistic rendering quality. When utilizing 2D ground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation performance with 95.03 % mIoU.},
  archive      = {J_ESWA},
  author       = {Zuxing Lu and Xin Yuan and Shaowen Yang and Jingyu Liu and Changyin Sun},
  doi          = {10.1016/j.eswa.2025.129601},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129601},
  shortjournal = {Expert Syst. Appl.},
  title        = {GSFF-SLAM: 3D semantic gaussian splatting SLAM via feature field},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids. <em>ESWA</em>, <em>298</em>, 129596. (<a href='https://doi.org/10.1016/j.eswa.2025.129596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) can enhance cognitive artificial agents by improving their semantic understanding, adaptability to dynamic contexts, explainability, continuous learning, and informed, case-based decision-making. However, the development of any KG rarely follows an explicit and structured procedure to improve its consistency, modifiability, and interoperability. This ultimately restricts the utility of KGs for real-world agentic AI systems. To overcome this limitation, this paper proposes a life cycle for developing and evolving KGs in domain-specific applications, encompassing three phases to i) conceptualize the problem domain and competency questions, ii) formalize a schema using ontologies, and iii) implement the KG to foster agents’ cognition through queries and graph data science. The proposed approach is validated with a case study on context-aware automated negotiations within smart grids, where agents negotiate for energy trading while considering private and contextual circumstances. Agents may take actions with or without the aid of a KG, and can adopt one of three negotiation strategy configurations: heuristic, metaheuristic, or reinforcement learning-based. Negotiation outcomes consistently indicate that, regardless of the configuration employed, the use of a KG improves agents’ rewards by at least 1.21 % and up to 90.91 %. Results highlight that the proposed life cycle enables the integration of contextual and domain-specific data and metadata into a KG that enhances agents’ learning, while also allowing for the development and selection of relevant queries and graph data science algorithms to improve the strategic behavior of negotiation agents with cognitive abilities.},
  archive      = {J_ESWA},
  author       = {Dan E. Kröhling and Ernesto C. Martínez},
  doi          = {10.1016/j.eswa.2025.129596},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129596},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors. <em>ESWA</em>, <em>298</em>, 129593. (<a href='https://doi.org/10.1016/j.eswa.2025.129593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimization of project portfolios in corporate ecosystems by considering both strategic factors and return synergies between projects. We propose a hybrid method that combines machine learning with mathematical programming to address this enhanced form of project portfolio optimization. Unlike traditional approaches, which evaluate projects mainly based on individual risks and returns, our framework considers strategic priorities and the extra value created when projects reinforce each other. Machine learning models predict synergies, while exact optimization ensures consistent portfolio selection under resource and strategic constraints. A numerical proof-of-concept illustrates the methodology. Computational experiments show that portfolios designed with synergy and strategy in mind might achieve a significantly higher performance than portfolios that do not account for project synergies. The paper also examines computational efficiency and scalability, highlighting the approach’s potential for practical application in complex and dynamic corporate ecosystems.},
  archive      = {J_ESWA},
  author       = {Patricia Rodriguez-Garcia and Angel A. Juan and Jon A. Martin and David Lopez-Lopez and Josep M. Marco},
  doi          = {10.1016/j.eswa.2025.129593},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129593},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors. <em>ESWA</em>, <em>298</em>, 129548. (<a href='https://doi.org/10.1016/j.eswa.2025.129548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite improvements in survival rates, childhood cancer survivors in South Korea still face significant challenges in accessing the psychological and informational support they need. To address these challenges, we developed the Korean Childhood Cancer Survivor Question-Answer (KCCSQA) dataset in which contains 3876 question-answer pairs. The questions were sourced from websites, academic articles, and an online survey, where 119 childhood cancer survivors contributed 1283 questions. We used GPT-4 Turbo to generate the responses, followed by an expert evaluation by 11 specialists to ensure factual accuracy, complementarity, comprehensibility, and empathy. The overall quality of the GPT-generated responses was rated 4.98 out of 6, indicating a high level of quality. To enhance the dataset, we integrated a relational knowledge graph to mitigate hallucinations in the AI-generated answers, achieving a performance of 0.979 in hallucination detection. Additionally, a pseudo-scoring system was implemented for continuous quality assessment. The dataset’s effectiveness was evaluated through a pilot study involving 14 childhood cancer survivors, who interacted with a retrieval-based QA system using a single-turn chatbot format. The mean satisfaction rating was 4.36 on a 6-point Likert scale, and all participants expressed a willingness to use the system again.},
  archive      = {J_ESWA},
  author       = {Kyubum Hwang and Mirae Kim and Min Ah Kim and Chaerim Park and Yehwi Park and Chungyeon Lee and Jooyoung Lim and Hayoung Oh},
  doi          = {10.1016/j.eswa.2025.129548},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129548},
  shortjournal = {Expert Syst. Appl.},
  title        = {GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics. <em>ESWA</em>, <em>298</em>, 129524. (<a href='https://doi.org/10.1016/j.eswa.2025.129524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-linearity of symmetric block cryptographic algorithms, which is crucial for resisting linear and differential cryptanalysis, depends on the design of substitution boxes. This work proposes a novel scheme, named GOM, combining opposition-based learning with graph-based representation to be integrated into three population-based metaheuristics. This scheme is applied to address the 8 × 8 S-box design problem. The GOM-enhanced metaheuristics improve population diversity and convergence, achieving a non-linearity of 112. Hardware simulations indicate that GOM-based designs require similar resources to AES, while side-channel evaluations confirm their resilience against power analysis attacks. Scalability is supported by successful results on 10 × 10 and 12 × 12 S-boxes. The design of GOM, leveraging generalizable components such as opposition-based learning and graph-based representations, suggests its potential applicability to other population-based metaheuristics and optimization problems.},
  archive      = {J_ESWA},
  author       = {Francisco González and Ricardo Soto and José M. Lanza-Gutiérrez and Broderick Crawford},
  doi          = {10.1016/j.eswa.2025.129524},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129524},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Life cycle cost reliability assessment for strategic real estate decision-making. <em>ESWA</em>, <em>298</em>, 129329. (<a href='https://doi.org/10.1016/j.eswa.2025.129329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real estate projects prioritize minimizing initial development costs while often overlooking the long-term financial implications of their decisions. This short-term focus frequently leads to increased operational, maintenance, and renewal expenses, ultimately reducing overall profitability. Life Cycle Costing (LCC) provides a comprehensive approach to evaluating total project costs over time; however, its adoption remains limited due to challenges such as data constraints, uncertainty about future cost savings, and the lack of standardized performance measurement tools. To tackle these issues, this paper proposes a structured LCC reliability assessment model designed for real estate decision-makers. The model systematically identifies and analyzes key cost factors across all project phases, including construction, operation, renewal, maintenance, and end-of-life, while integrating technical, economic, environmental, and social dimensions. A structured survey was employed to quantify and prioritize these cost factors, facilitating the development of category-specific LCC models and a standardized evaluation framework. Additionally, a benchmarking scale was created to measure the reliability of input factors. Although this study emphasizes the reliability dimension, it establishes a foundation for the future integration of an optimization module to enhance decision-making and maximize life cycle cost efficiency. The proposed model has been automated to improve usability and accessibility, allowing stakeholders to make informed investment decisions that promote long-term financial sustainability in real estate development.},
  archive      = {J_ESWA},
  author       = {Elin A. Eldars and Amin A. Sorour},
  doi          = {10.1016/j.eswa.2025.129329},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129329},
  shortjournal = {Expert Syst. Appl.},
  title        = {Life cycle cost reliability assessment for strategic real estate decision-making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Resilience assessment of chinese semiconductor enterprises based on a novel grey wavelet neural differential dynamics model. <em>ESWA</em>, <em>297</em>, 129588. (<a href='https://doi.org/10.1016/j.eswa.2025.129588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of the escalating global uncertainties, such as the U.S.-China trade war, an in-depth study of enterprise adaptive strategies and resilience in response to external shocks is of significant theoretical and practical importance for enhancing the survival and development capabilities of enterprises amid global economic turmoil. First, this paper selects nine representative semiconductor enterprises in China as research subjects and evaluates their comprehensive effectiveness on a quarterly basis from 2008 to 2023. The evaluation employs the CRITIC-Grey Relational-TOPSIS method across four dimensions: profitability, adaptability, solvency, and scalability. Second, to address abrupt changes in enterprise effectiveness under uncertain environments, this paper proposes a novel Grey Wavelet Differential Neural Network Model (WNOGM) that integrates Neural Ordinary Differential Equation (NODE), Wavelet Neural Network (WNN), and grey system theory. This model is designed to fit enterprise effectiveness data and assess enterprise resilience. By effectively combining these methodologies, the model enhances its capacity to manage volatile and non-stationary data in dynamic environments, demonstrating greater adaptability and stability. Finally, the empirical analysis reveals that high-capital enterprises demonstrate greater resilience and effectively leverage indigenous substitution policies and technological advancements to recover rapidly. In contrast, mid- and low- capital enterprises exhibit varying degrees of vulnerability, highlighting the necessity to enhance their technological capabilities. These findings offer policymakers a valuable foundation for decision-making to promote sustainable growth amid uncertainty.},
  archive      = {J_ESWA},
  author       = {Qi Ding and Xinping Xiao and Xiulin Geng and Lin Luo},
  doi          = {10.1016/j.eswa.2025.129588},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129588},
  shortjournal = {Expert Syst. Appl.},
  title        = {Resilience assessment of chinese semiconductor enterprises based on a novel grey wavelet neural differential dynamics model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A discrete seasonal grey model with disturbance adjustments and dummy parameters for cyclical effects in electricity demand forecasting. <em>ESWA</em>, <em>297</em>, 129585. (<a href='https://doi.org/10.1016/j.eswa.2025.129585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to accurately anticipate electricity usage patterns is fundamental to power system reliability, yet remains challenging in data-scarce regions with pronounced seasonal variations. This study puts forward a grey model (DSDGM(1,1)), a novel approach integrating dummy variables into a discrete grey framework to explicitly capture seasonal cycles. The model derives closed-form solutions for parameter estimation and time-response functions, with proofs of unbiasedness. Validated on real-world tropical cooling load data—with hourly, daily, and weekly resolutions—the DSDGM(1,1) demonstrates key innovation in modular seasonality handling via interpretable dummy coefficients, enabling operator adjustments. Practical trials involved cooling load data from a residential building in Douala, Cameroon—a tropical region with climate-driven demand variations. The trials confirmed seamless integration into energy expert systems, particularly for peak-demand alignment. Compared to seasonal grey benchmarks (SFGM, SGM), DSDGM(1,1) reduces forecasting errors by 22–32% in MAPE and outperforms SARIMA and SVR in sparse-data scenarios while maintaining faster training times than BPNN. By bridging the gap between grey models’ efficiency and seasonal accuracy, DSDGM(1,1) offers a scalable solution for smart grids in developing economies, prioritizing interpretability and low-data adaptability.},
  archive      = {J_ESWA},
  author       = {Flavian Emmanuel Sapnken and Mohammad M. Hamed and Saralees Nadarajah and Yong Wang and Prosper Gopdjim Noumo and Jean Gaston Tamba},
  doi          = {10.1016/j.eswa.2025.129585},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129585},
  shortjournal = {Expert Syst. Appl.},
  title        = {A discrete seasonal grey model with disturbance adjustments and dummy parameters for cyclical effects in electricity demand forecasting},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated optimization approach to cell formation, cell layout, and group scheduling for dynamic cellular manufacturing system. <em>ESWA</em>, <em>297</em>, 129582. (<a href='https://doi.org/10.1016/j.eswa.2025.129582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of dynamic cellular manufacturing system (DCMS) has become a hot research field in recent years. Cell formation (CF), cell layout (CL), and group scheduling (GS) are interrelated and influence each other in designing a DCMS. However, existing research on predominantly focuses on one or two of them, which results in higher cell reconfiguration costs and diminished production efficiency. To handle this issue, this paper investigates an integrated optimization approach of CF, CL and GS for DCMS. Considering the features of the problem, a mathematical model is formulated with the total makespan and cell reconfiguration cost as the optimization objectives. Then, a multi-scale neighborhood search heuristic algorithm (MSNSH) is developed to solve it. In MSNSH, two sets of sequence pair encoding are proposed to ensure a contiguous and non-overlapping inter/intra-cell layout without additional constraints. Four machine-swap-based neighborhood searches, along with a cell-based crossover, are developed to enhance the efficiency of the local search. One adaptive cell number adjustment algorithm, accompanied by three cell-swap-based neighborhood searches, are engineered to avoid local optima and enhance the effectiveness of the optimization process. Finally, the proposed MSNSH is tested on a set of test instances with different scales. The comparative experimental results show the effectiveness and superiority of MSNSH for solving the proposed problem.},
  archive      = {J_ESWA},
  author       = {Baigang Du and Lihui Deng and Jiawen Liu and Jun Guo and Xixing Li and Lei Wang},
  doi          = {10.1016/j.eswa.2025.129582},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129582},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrated optimization approach to cell formation, cell layout, and group scheduling for dynamic cellular manufacturing system},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic self-triggered adaptive neural PI control for underactuated MASS with predefined performance. <em>ESWA</em>, <em>297</em>, 129579. (<a href='https://doi.org/10.1016/j.eswa.2025.129579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective control of underactuated Maritime Autonomous Surface Ships (MASS) is critical for maritime safety and efficiency but challenged by system uncertainties (e.g., environmental disturbances, unknown dynamics) and actuator mechanical degradation. This work addresses these dual challenges through an integrated control scheme. A coordinate transformation cascades MASS dynamics, enabling a vector-based PI control with self-adjusting gains within a PID framework. To handle uncertainties, an adaptive neural network with single-parameter learning acts as a unified approximator. Concurrently, a novel dynamic self-triggered mechanism (DSTM) is developed to minimize actuator wear by reducing unnecessary control updates. Prescribed performance control (PPC) compensates for potential degradation from intermittent DSTM signals and lack of differentiation, yielding a dynamic self-triggered adaptive neural predefined-performance PI (DST-ANPP-PI) scheme. The proposed method achieves: 1) robust uncertainty compensation via adaptation neural with single-parameter learning technique, 2) significant actuator wear reduction via DSTM, and 3) guaranteed transient and steady-state tracking performance despite triggering and lack of differentiation via the integrated PPC. Theoretical analysis proves uniformly ultimately bounded (UUB) closed-loop signals. Simulations under demanding conditions confirm the superiority of proposed scheme over alternatives in robustness, actuator preservation, and performance guarantees.},
  archive      = {J_ESWA},
  author       = {Yixin Wu and Fangliang Xiao and Yong Ma and Guibing Zhu},
  doi          = {10.1016/j.eswa.2025.129579},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129579},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic self-triggered adaptive neural PI control for underactuated MASS with predefined performance},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-domain multi-modality brain MRI arbitrary-scale super-resolution network. <em>ESWA</em>, <em>297</em>, 129575. (<a href='https://doi.org/10.1016/j.eswa.2025.129575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-contrast brain magnetic resonance imaging (MRI) super-resolution (SR) methods improve image details by utilizing complementary information from multiple contrasts. However, these methods encounter several challenges: (1) Most methods overlook feature fusion in the frequency domain, fail to simultaneously focus on different intensity regions within the dynamic range, and struggle to fuse similar features effectively. (2) Feature redistribution is inaccurate and struggles to adaptively capture global and local relationships at multiple granularities. (3) Upsampling is limited to fixed scales, failing to meet clinical demands for arbitrary scaling. To address these issues, we designed a dual-domain multi-contrast arbitrary-scale SR network with an encoder-decoder architecture. The encoder performs feature extraction and cross-contrast alignment. In the decoder, the multi-scale feature extraction block (MFEB) is designed to enhance the network’s ability to understand image content. The dual-domain fusion sparse attention block (DFSAB) focuses on varying intensity regions in the target modality, applying sparse attention in spatial and frequency domains to optimize feature fusion. The adaptive channel spatial attention block (ACSAB) facilitates interaction between global and local information to ensure accurate feature weight allocation. The upsampling branch enables arbitrary scale reconstruction while enhancing feature representation. Our proposed method achieves maximum PSNR improvements of 0.94 dB and 1.35 dB on the BraTs and IXI datasets, respectively, significantly improving brain tissue structure and boundary reconstruction, thereby aiding more accurate clinical diagnosis and decision-making.},
  archive      = {J_ESWA},
  author       = {Zhiying Yang and Xinyi Wang and Feizhong Zhou and Hanguang Xiao},
  doi          = {10.1016/j.eswa.2025.129575},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129575},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-domain multi-modality brain MRI arbitrary-scale super-resolution network},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HFE-net: A lightweight cross-layer hybrid feature enhancement network for efficient hemerocallis citrina leaf disease detection and generalization. <em>ESWA</em>, <em>297</em>, 129550. (<a href='https://doi.org/10.1016/j.eswa.2025.129550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of smart agriculture, leaf diseases have become one of the primary factors affecting crop yield and quality. As an important ornamental and edible crop, Hemerocallis citrina suffers from diverse leaf diseases characterized by complex morphology and blurred edges, making accurate detection particularly challenging. Lightweight object detection models, such as YOLOv11n, offer high inference speed but often struggle to effectively fuse high-level semantic features with low-level spatial details, leading to lesion edge feature loss and reduced detection accuracy. To address these challenges, we propose Hybrid Feature Enhancement Network (HFE-Net), a lightweight and efficient detection framework based on YOLOv11n. First, a Hybrid Feature Pyramid Network (H-FPN) with cross-layer connections is designed to enhance multi-scale feature fusion and improve fine-grained lesion localization. Second, PixelShuffle upsampling replaces conventional interpolation to better preserve lesion edges while reducing computational cost. Third, a lightweight Concatenate-to-Fusion Feature Enhancement Module (C2f-FEM) is introduced to efficiently integrate multi-scale features with fewer parameters. Experimental results on a custom Hemerocallis citrina leaf disease dataset show that HFE-Net improves mAP@50 from 88.3 % to 95.5 % and precision from 84.8 % to 93.1 % compared to YOLOv11n. Moreover, HFE-Net maintains a compact architecture and fast inference speed. Cross-framework validation on YOLOv5, YOLOv8, and YOLOv12, as well as cross-dataset tests on grape, rice, tomato, and apple leaves, further demonstrate its effective balance between detection accuracy, efficiency, and deployment feasibility in smart agriculture.},
  archive      = {J_ESWA},
  author       = {Tao Wang and Hongyi Xia and Jiao Xie and Jianian Wu and Yurong Sun and Junwan Liu},
  doi          = {10.1016/j.eswa.2025.129550},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129550},
  shortjournal = {Expert Syst. Appl.},
  title        = {HFE-net: A lightweight cross-layer hybrid feature enhancement network for efficient hemerocallis citrina leaf disease detection and generalization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive segmentation and optimization for efficient centralizer selection and placement in oilfield drilling operations. <em>ESWA</em>, <em>297</em>, 129547. (<a href='https://doi.org/10.1016/j.eswa.2025.129547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection and placement of centralizers critically affect casing centrality and construction cost. However, industrial simulators used to evaluate placement schemes are typical black-box models, which are analytically intractable and computationally expensive. Existing studies rarely address this problem from an optimization modeling perspective. This work proposes an adaptive multi-segment joint optimization framework tailored for black-box simulators, which jointly optimizes segmentation, spacing, and type selection for centralizer planning. We design a parallel bisection search algorithm (PBS) for efficient spacing optimization, an adaptive segmentation method (SAMAR), and a type selection strategy (APTS). Leveraging the local rigidity of the wellbore structure, our design approximates the problem as partially separable, which significantly reduces simulator calls. Evaluated on four real-world wells, our method satisfies eccentricity constraints while achieving substantial cost reductions. Without type selection, it reduces total cost by an average of 56 % compared to a classical baseline. With type selection included, cost is further reduced by 28 % relative to fixed-type solutions. To validate performance more broadly, we test 50 synthetic cases based on randomized constraints. Results show that our problem-specific method consistently outperforms general-purpose black-box optimizers in feasibility and efficiency. Overall, this work addresses key optimization challenges in centralizer placement and selection and presents a generalizable framework for simulation-based optimization in complex industrial systems.},
  archive      = {J_ESWA},
  author       = {Tao Ren and Yong Wang and Xin Chen and Qing Liu and Ling-Yun Wu},
  doi          = {10.1016/j.eswa.2025.129547},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129547},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive segmentation and optimization for efficient centralizer selection and placement in oilfield drilling operations},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph discriminative dynamic sampling AdaBoost for imbalanced cardiovascular disease diagnosis. <em>ESWA</em>, <em>297</em>, 129546. (<a href='https://doi.org/10.1016/j.eswa.2025.129546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the challenges arising from class imbalance within cardiovascular disease (CVD) datasets, this study proposes a novel diagnostic model: Graph Discriminative Dynamic Sampling AdaBoost (GDDSAD). This model jointly optimizes class balancing, feature extraction, and the classification process within a unified AdaBoost architecture. Initially, the weight updating mechanism leverages instance confidence to prioritize boundary-proximal instances. Subsequently, dynamic undersampling and dynamic oversampling modules are integrated during the AdaBoost iterations in order to construct a more distinct decision boundary. Ultimately, the dynamically sampled dataset is dimensionality reduced using discriminability improving Locality Preserving Projection (LPP) to provide a more discriminative low dimensional manifold input to the base learner. Experimental results demonstrate that GDDSAD achieves an average increase of 0.208 in the G-Mean and 0.111 in the AUC on 4 CVD datasets compared to AdaBoost, and outperforms mainstream Boosting variants on 6 KEEL datasets, demonstrating its ability to accurately identify diseased instances in imbalanced CVD datasets. The code related to this study is available in the GitHub repository: https://github.com/ChuantaoLi/GDDSAD .},
  archive      = {J_ESWA},
  author       = {Chuantao Li and Baoqin Chen and Sheng Li},
  doi          = {10.1016/j.eswa.2025.129546},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129546},
  shortjournal = {Expert Syst. Appl.},
  title        = {Graph discriminative dynamic sampling AdaBoost for imbalanced cardiovascular disease diagnosis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimization strategy for testing resource allocation and ICU bed capacity planning during a pandemic. <em>ESWA</em>, <em>297</em>, 129545. (<a href='https://doi.org/10.1016/j.eswa.2025.129545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global outbreak of COVID-19 has profoundly impacted daily life, prompting countries to adopt diverse epidemic prevention strategies. Critical measures, such as nucleic acid testing and the expansion of Intensive Care Unit (ICU) bed capacity, have demonstrated effectiveness in curbing the transmission of the virus and decreasing fatality rates. However, existing research has given limited attention to the integrated optimization of these two strategies. To bridge this gap, this study focuses on the integrated optimization of testing resource allocation and ICU bed capacity planning during a pandemic. We develop a novel nonlinear programming model that incorporates an epidemiological compartment framework to characterize the nonlinear dynamics inherent in the progression of COVID-19. Our model innovatively introduces time-varying adjustments to the production capacities of testing resources and the availability of ICU beds, responding to the evolving severity of the epidemic. Additionally, we introduce a new satisfaction function designed to guide policymakers in allocating resources more equitably. To address the time-sensitive nature of emergency decision-making, we employ an improved multi-verse optimization (IMVO) algorithm to derive solutions for the model. The study reveals that the allocation proportion of virus testing resources across regions remains relatively stable and is correlated with the population base and migration patterns. The allocation of ICU beds tends to favor regions with higher death rates. Furthermore, while the equitable distribution of resources may lead to a rise in infections and deaths in certain regions, it ultimately contributes to a reduction in overall infections and deaths. This, in turn, helps mitigate the broader economic and societal impact of the pandemic. Our modeling framework offers a comprehensive approach to the optimization of pandemic-related resource allocation and is not limited to the context of COVID-19 in Shanghai. This research provides policymakers with an efficient and equitable tool for decision-making during crises, contributing to improved public health outcomes and better resource management during pandemics.},
  archive      = {J_ESWA},
  author       = {Xiaoxiao Zhu and Ming Liu and Enrico Zio},
  doi          = {10.1016/j.eswa.2025.129545},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129545},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimization strategy for testing resource allocation and ICU bed capacity planning during a pandemic},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ADSRF: A deep stacked residual framework for spectrum prediction with missing data. <em>ESWA</em>, <em>297</em>, 129541. (<a href='https://doi.org/10.1016/j.eswa.2025.129541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum prediction constitutes a fundamental functionality in cognitive radio networks (CRNs) and is indispensable for accurate spectrum situation generation. Most existing spectrum prediction models operate under the assumption that spectrum data are either complete or contain only negligible missing values. However, the integrity of real-time spectrum information is often compromised due to inevitable missing data caused by various disturbances. While a common solution involves first imputing missing values and then predicting future spectrum states, this two-stage approach carries a critical drawback: the imputation process may distort essential latent features in the data, ultimately degrading prediction performance. To address the above challenge, we propose a novel temporal-spectral deep learning framework, termed the stacked residual convolutional bidirectional gated recurrent unit network (SRCBG), capable of jointly performing spectrum imputation and prediction. Particularly, the stacked residual framework is developed to estimate missing spectrum values and predict future values. Furthermore, a novel residual convolutional gated recurrent unit cell (RC-GRU) is designed to capture dynamic spectral and temporal correlations. Experiments are carried out on real-world spectrum datasets under two various missing types with the missing rate varying from 20 % to 80 % . Experimental results show that the proposed SRCBG outperforms classical state-of-the-art baselines in both imputation and prediction tasks.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Jun Hu and Dan Jiang and Zengping Chen},
  doi          = {10.1016/j.eswa.2025.129541},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129541},
  shortjournal = {Expert Syst. Appl.},
  title        = {ADSRF: A deep stacked residual framework for spectrum prediction with missing data},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An evolutionary algorithm for multimodal multi-objective traveling salesman problems. <em>ESWA</em>, <em>297</em>, 129540. (<a href='https://doi.org/10.1016/j.eswa.2025.129540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective Traveling Salesman Problem (TSP) extends the classical TSP by simultaneously optimizing multiple conflicting objectives, such as minimizing travel cost and maximizing route diversity. While existing multi-objective TSP algorithms focus on convergence and diversity in the objective space, they often overlook the multimodal nature of the problem–where structurally distinct tours may map to similar objective values. This gap leads to the loss of high-quality solutions that could offer decision-makers valuable alternatives. Therefore, it is essential to study traveling salesman problems with multimodal and multi-objective characteristics. To address this gap, this paper conducts an in-depth study of the Traveling Salesman Problem with multimodal and multi-objective characteristics (MMTSP) and proposes an algorithm called MMTSP_DS. This algorithm combines the Spearman distance with a diversity measurement criterion based on shared edges in the decision space, allowing for a more accurate assessment of the similarity between different tour solutions. Additionally, the algorithm incorporates the concept of a special crowding distance into the environmental selection process to ensure that the population maintains diversity in both the decision space and the objective space in a balanced manner. Finally, a series of experiments are conducted to systematically compare the proposed MMTSP_DS algorithm with state-of-the-art algorithms designed for multimodal multi-objective TSP. The experimental results verify that MMTSP_DS significantly improves population diversity and optimization performance, demonstrating its considerable advantages.},
  archive      = {J_ESWA},
  author       = {Caitong Yue and Jiankang Song and Mengnan Liu and Ying Bi and Weifeng Guo and Hongyu Lin and Jing Liang},
  doi          = {10.1016/j.eswa.2025.129540},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129540},
  shortjournal = {Expert Syst. Appl.},
  title        = {An evolutionary algorithm for multimodal multi-objective traveling salesman problems},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-population co-evolutionary algorithm for solving energy-efficient hybrid flow shop scheduling problem. <em>ESWA</em>, <em>297</em>, 129536. (<a href='https://doi.org/10.1016/j.eswa.2025.129536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the worsening global climate, energy-efficient hybrid flow shop scheduling, which simultaneously considers both makespan and total energy consumption (TEC), has gained significant research attention in recent years. However, existing algorithmic frameworks often face challenges in effectively balancing these two conflicting objectives. To address this, this paper introduces a multi-objective multi-population co-evolutionary algorithm (MOMPCEA) based on the interaction between these objectives. Multiple sub-populations are established, each with makespan, TEC, or their weighted sum as its optimization objective. During the self-evolution phase of each sub-population, job-based crossover operators are employed to enhance the algorithm’s global search capability, while distinct neighborhood structures and a self-adaptive mechanism are applied to the weighted sub-population to improve local search performance. Three distinct information-sharing strategies are developed to facilitate inter-population interaction during the iterative process. Furthermore, a dynamic variable neighborhood search strategy, incorporating four types of neighborhood operators, is proposed to further enhance the quality of the non-dominated solution set. The proposed MOMPCEA is benchmarked against three state-of-the-art multi-objective algorithms using C , IGD , and HV indicators. Experimental results demonstrate that MOMPCEA can achieve non-dominated solution sets with superior convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Cuiyu Wang and Youjie Yao and Wenhui Li and Xinyu Li},
  doi          = {10.1016/j.eswa.2025.129536},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129536},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-population co-evolutionary algorithm for solving energy-efficient hybrid flow shop scheduling problem},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incomplete multi-view clustering with cross-graph diversity and improved nonconvex tensor regularizer. <em>ESWA</em>, <em>297</em>, 129535. (<a href='https://doi.org/10.1016/j.eswa.2025.129535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The great process of incomplete multi-view clustering (IMVC) has been made in recent years, especially in the field of graph-based IMVC. However, the existing IMVC methods based on graph learning still have the following problems: 1. When recovering similarity graphs, most IMVC methods only focus on considering the diversity within each graph, but fail to utilize the cross-graph diversity; 2. In these methods, low-rank tensor constraint is often introduced to utilize consistency information between different views, but no more prior information such as local smoothness is utilized. To tackle these problems, we propose the incomplete multi-view clustering with cross-graph diversity and improved nonconvex tensor regularizer (IMVC/GDINTR) method. Specifically, an improved nonconvex tensor regularizer is first proposed, which not only utilizes the low-rank tensor constraint to adaptive complete the similarity graph of each view, but also explores the local smoothness prior to remove the noise of the completed similarity graph. In addition, we further explore the sparse cross-graph diversity while taking into account the intra-graph diversity to obtain the pure graphs. Then, these pure graphs can be adaptively fused into a consensus graph and we enforce that the consensus graph contains r connected components, where r is the number of clusters. Finally, we integrate all the procedures into a unified framework and use the augmented Lagrange multiplier (ALM) method for optimization. Our experimental results on some datasets are superior to some state-of-the-art IMVC methods, which proves the superiority of our framework. The code of this paper is publicly available at https://github.com/Nicy-Wu/IMVC_GDINTR .},
  archive      = {J_ESWA},
  author       = {Shanshan Wu and Gui-Fu Lu},
  doi          = {10.1016/j.eswa.2025.129535},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129535},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incomplete multi-view clustering with cross-graph diversity and improved nonconvex tensor regularizer},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-distance co-selection evolutionary algorithm for many-objective optimization. <em>ESWA</em>, <em>297</em>, 129534. (<a href='https://doi.org/10.1016/j.eswa.2025.129534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many objective optimization problems (MaOPs) face the challenge of insufficient convergence pressure to the true Pareto Front (PF) due to the exponential growth of non-dominated individuals. Particularly, the high-dimensional characterization of objectives hinders the algorithm from fully maintaining population diversity. This paper proposes a multi-distance co-selection for many-objective optimization (MDCS), which adopts a dual-distance indicator for population convergence and a dual-diversity maintenance mechanism for population diversity. The dual distance indicator is constructed based on ideal and nadir points, by which well-converged individuals are retained in the convergence archive. As for the dual diversity maintenance mechanism, it considers not only global diversity but also local diversity in the update of the diversity archive. Specifically, global diversity is maintained through reference vectors, while local diversity is measured by calculating local neighborhood density combined with parallel distances, where the size of the neighborhood is determined by information entropy-based population distribution assessment. The results on 19 test problems and 5 real-world problems demonstrate that MDCS outperforms 6 other state-of-the-art many-objective evolutionary algorithms, validating the effectiveness of MDCS in handling MaOPs.},
  archive      = {J_ESWA},
  author       = {Wei Li and Zhiting Liu and Ning Yang and Qing Xu and Ying Huang and Weize Qin},
  doi          = {10.1016/j.eswa.2025.129534},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129534},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-distance co-selection evolutionary algorithm for many-objective optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Understanding risk dynamics in digital twin integration: A causal analysis for smart infrastructure projects. <em>ESWA</em>, <em>297</em>, 129533. (<a href='https://doi.org/10.1016/j.eswa.2025.129533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative infrastructure projects are changing how cities and industries are developed by using advanced technologies to improve efficiency, sustainability, and resilience. These projects focus on managing infrastructure assets more effectively through real-time monitoring, predictive maintenance, and data-driven decisions. In this context, digital twin technology plays a key role by providing a virtual model of physical systems that updates in real time. By synchronizing real-time data with simulation models, digital twins support enhanced situational awareness, scenario testing, and performance optimization. However, implementing digital twins involves a complex process that introduces multidimensional risks, many of which are poorly understood. This study addresses the gap by identifying and analyzing key risk factors associated with digital twin adoption. A hybrid approach combines a systematic literature review, expert validation from 19 professionals, and fuzzy Decision-Making Trial and Evaluation Laboratory analysis to map and prioritize 15 critical risks across four categories: Technological, Governance/Ethical, Social, and Economic. Results indicate that economic challenges are central drivers, while data privacy and security, computational resource limitations, lack of transparency, job displacement, and high implementation costs represent significant secondary risks. Expert consultations identified practical strategies to reduce the top risks, including strong data governance, gradual (iterative) technology rollout, continuous performance monitoring, and designing systems with users in mind. These strategies directly address the most critical risks highlighted in the analysis. The structured risk framework provides actionable insights for policymakers and practitioners, supporting informed decision-making and robust risk management strategies. These findings enhance understanding of potential barriers and contribute to more sustainable and responsible deployment of digital twin technology in infrastructure and beyond.},
  archive      = {J_ESWA},
  author       = {Abdelazim Ibrahim and Ahmed Farouk Kineber and Saeed Reza Mohandes and Yini Lan and Saeed Banihashemi and Pshtiwan Shakor},
  doi          = {10.1016/j.eswa.2025.129533},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129533},
  shortjournal = {Expert Syst. Appl.},
  title        = {Understanding risk dynamics in digital twin integration: A causal analysis for smart infrastructure projects},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid deep learning-based approach for disruption detection and recovery planning in a prototype cognitive digital supply chain twin. <em>ESWA</em>, <em>297</em>, 129531. (<a href='https://doi.org/10.1016/j.eswa.2025.129531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the growing digital transformation efforts and recent global supply chain disruptions, this paper introduces an implementation of a cognitive digital supply chain twin prototype. The developed cognitive digital supply chain twin aims to enhance supply chain resilience through improved visibility, early disruption detection, and better decision-making support. The implemented data-driven cognitive digital supply chain twin has a set of embedded modules that permit disruption detection, disrupted component identification, disruption duration prediction, and time-to-recovery prediction. Furthermore, a disruption extrapolation module is developed to predict the future supply chain performance trajectory subject to the detected disruption and test candidate recovery actions. In addition, an optimization module is developed to determine an optimal set of recovery actions to be tested. Then, the cognitive digital supply chain twin can suggest the most efficient recovery action. A three-echelon supply chain model to showcase the proposed cognitive digital supply chain twin architecture. The information obtained from the cognitive digital supply chain twin helps decision-makers and supply chain practitioners make appropriate decisions based on real-time disruption detection data. Such decisions aim at minimizing adverse disruption impact on the supply chain and boost supply chain recovery.},
  archive      = {J_ESWA},
  author       = {Mahmoud Ashraf and Islam Ali and Amr Eltawil},
  doi          = {10.1016/j.eswa.2025.129531},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129531},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid deep learning-based approach for disruption detection and recovery planning in a prototype cognitive digital supply chain twin},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A biologically inspired separable learning vision model for real-time traffic object perception in dark. <em>ESWA</em>, <em>297</em>, 129529. (<a href='https://doi.org/10.1016/j.eswa.2025.129529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate object perception in low-light traffic scenes has attracted increasing attention. However, due to severe illumination degradation and the lack of reliable visual cues, existing perception models and methods struggle to quickly adapt to and accurately predict in low-light environments. Moreover, there is the absence of available large-scale benchmark specifically focused on low-light traffic scenes. To bridge this gap, we introduce a physically grounded illumination degradation method tailored to real-world low-light settings and construct Dark-traffic, the largest densely annotated dataset to date for low-light traffic scenes, supporting object detection, instance segmentation, and optical flow estimation. We further propose the Separable Learning Vision Model (SLVM), a biologically inspired framework designed to enhance perception under adverse lighting. SLVM integrates four key components: a light-adaptive pupillary mechanism for illumination-sensitive feature extraction, a feature-level separable learning strategy for efficient representation, task-specific decoupled branches for multi-task separable learning, and a spatial misalignment-aware fusion module for precise multi-feature alignment. Extensive experiments demonstrate that SLVM achieves state-of-the-art performance with reduced computational overhead. Notably, it outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1 percentage points in instance segmentation, and reduces endpoint error (EPE) of baseline by 12.37 % on Dark-traffic. On the LIS benchmark, the end-to-end trained SLVM surpasses Swin Transformer + EnlightenGAN and ConvNeXt-T + EnlightenGAN by an average of 11 percentage points across key metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage points. The Dark-traffic dataset and complete code is released at https://github.com/alanli1997/slvm .},
  archive      = {J_ESWA},
  author       = {Hulin Li and Qiliang Ren and Jun Li and Hanbing Wei and Zheng Liu and Linfang Fan},
  doi          = {10.1016/j.eswa.2025.129529},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129529},
  shortjournal = {Expert Syst. Appl.},
  title        = {A biologically inspired separable learning vision model for real-time traffic object perception in dark},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive social mobility-restructuring differential evolution for global optimization. <em>ESWA</em>, <em>297</em>, 129528. (<a href='https://doi.org/10.1016/j.eswa.2025.129528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is widely recognized as a highly effective algorithm for global optimization. As a simple yet powerful strategy, the greedy selection operator is employed in most existing DE algorithms. However, this strategy focuses solely on individual-level evolution while neglecting population-level evolution. Consequently, it fails to fully exploit the holistic information of the population during the evolutionary process, thereby limiting the performance of DE. To address the issue above, this study proposes a novel DE variant called adaptive social mobility-restructuring DE (ASMRDE). Specifically, a social generation selection mechanism (social restructuring) is proposed enabling population-level evolution to occur alongside individual-level evolution with the iteration of social generations. This dual-level evolution effectively addresses the aforementioned limitation. Additionally, an external archive is constructed to preserve historical populations eliminated during the social restructuring process. This archived information is subsequently utilized in both social restructuring and individual evolution. Furthermore, this study also develops a parameter adaptation strategy based on narrow-sense diversity and a new mutation strategy that guides individual-level evolution using historical population information. Finally, the proposed variant was thoroughly assessed by using the Congress on Evolutionary Computation (CEC) 2017, 2014 and 2013 benchmark functions, with results showing ASMRDE’s remarkably robust performance and distinct advantages for complex problems when compared to other efficient DE variants, including some winning algorithms in the CEC competition. Besides, the sensitivity of ASMRDE to parameter changes was explored, and ablation experiments and visual analyses were performed on ASMRDE, so as to demonstrate the effectiveness of the above strategies.},
  archive      = {J_ESWA},
  author       = {Yiwen Zhuo and Qiangda Yang},
  doi          = {10.1016/j.eswa.2025.129528},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129528},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive social mobility-restructuring differential evolution for global optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Query-guided predicate decoupling and prototype approximation learning for scene graph generation. <em>ESWA</em>, <em>297</em>, 129525. (<a href='https://doi.org/10.1016/j.eswa.2025.129525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene graph generation (SGG), a fundamental task in visual understanding, suffers from biased entity-relation predictions due to the long-tailed distribution problem, severely impacting downstream tasks’ comprehension of local visual details. Existing methods suffer from interference from co-occurring entity pairs in predicate prediction, compromising the decision layer’s ability to independently assess predicate information and exacerbating biased predictions. Additionally, these methods fail to fully leverage the homogeneity among similar predicate representations, leading to confusion in the decision layer and underfitting, ultimately reducing prediction accuracy. To address these issues, we propose the Query -guided predicate decoupling and Proto type approximation learning (ProtoQuery) method. On the one hand, to mitigate the influence of entity information on independent predicate decisions, we propose a decoupled learning method based on the uniqueness of predicate representations within triples to separate entity and predicate representations, ensuring that predicate decisions rely solely on independent predicate representations. On the other hand, to address confusion and insufficient learning in the decision layer caused by the diversity among representations of the same predicate category, we propose a prototype approximation learning method. This method constructs a representation memory to store predicate representations of the same category, enabling incremental training of predicate prototypes from scratch, while incorporating metric learning to enhance homogeneity among similar predicate representations. We conducted extensive experiments on various datasets, such as VG and GQA, and our method achieved state-of-the-art performance in scene graph generation across multiple datasets. The code has been posted at: https://github.com/gavin-gqzhang/ProtoQuery .},
  archive      = {J_ESWA},
  author       = {Guoqing Zhang and Shichao Kan and Yue Zhang and Yigang Cen and Wanru Xu and Yi Jin and Yidong Li},
  doi          = {10.1016/j.eswa.2025.129525},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129525},
  shortjournal = {Expert Syst. Appl.},
  title        = {Query-guided predicate decoupling and prototype approximation learning for scene graph generation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFGNet: A dual-pathway graph neural network via frequency decomposition for spatiotemporal forecasting. <em>ESWA</em>, <em>297</em>, 129518. (<a href='https://doi.org/10.1016/j.eswa.2025.129518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is essential for intelligent transportation systems. Empirical analysis reveals that traffic signals inherently exhibit a dual-frequency nature: high-frequency non-stationary perturbations caused by sudden events, and low-frequency stationary trends driven by regular commuting behaviors. Most existing models fail to explicitly separate these dynamics, resulting in poor generalization under volatile traffic conditions. In this paper, we propose DFGNet, A Dual-Pathway Graph Neural Network that integrates frequency-aware decomposition with adaptive spatiotemporal learning. We design a learnable frequency separation framework to decouple raw traffic signals into non-stationary and stationary components. These are then modeled using a dual-branch architecture: a dynamic graph convolutional network (DGCN) to capture short-term structural perturbations, and a periodic-aware gated recurrent unit (PAGRU) to learn long-term temporal patterns. A lightweight adaptive fusion module dynamically balances the two branches to improve robustness and interpretability. We evaluate DFGNet on three real-world datasets: METR-LA, PEMS-BAY, and NE-BJ. Results show that our model consistently outperforms all strong baselines, achieving up to 13.95 % relative reduction in MAE and 15.38 % relative reduction in RMSE. Extensive ablation and visualization analyses further demonstrate the effectiveness of the proposed frequency-guided spatiotemporal framework. Code is available at: https://github.com/cxt1314520/DFGNet .},
  archive      = {J_ESWA},
  author       = {Jinpeng Xu and Jing Yang and Yaqun Huang and Lip Yee Por and Xiaotong Chen and Chunna Zhao},
  doi          = {10.1016/j.eswa.2025.129518},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129518},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFGNet: A dual-pathway graph neural network via frequency decomposition for spatiotemporal forecasting},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Boundary-aware contrastive network for rotating machinery fault diagnosis under unknown long-tailed class distribution. <em>ESWA</em>, <em>297</em>, 129517. (<a href='https://doi.org/10.1016/j.eswa.2025.129517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical machinery often operates under normal condition, with various faults occurring at different probabilities, leading to a long-tailed class distribution. Meanwhile, labeled samples are typically scarce in practical monitoring dataset, resulting in numerous of unlabeled samples with an unknown long-tailed class distribution. In this context, the diagnostic model is adversely affected by the dominance of majority class and mismatched class distributions between labeled and unlabeled samples. To address the challenge, we propose a novel boundary-aware contrastive network (BACN). It incorporates prior knowledge-based imbalanced learning into contrastive learning-based framework, guiding the feature learning under the unknown long-tailed class distribution. First, by leveraging limited labels, BACN constrains class centers by employing technique of intra-class aggregation and inter-class separation. Second, class-balanced boundaries are initialized via weighting based on the effective number of samples. Third, the feature learning is implemented by contrasting designed distance vector of sample. This vector is defined by the relative position of a sample with respect to all constrained centers. Hence, unsupervised feature learning and the constraints derived from limited labels are integrated within a unified space. Experiments under our rolling bearing testbed and a benchmark dataset demonstrate the effectiveness of BACN regarding 13 different long-tailed situations.},
  archive      = {J_ESWA},
  author       = {Yu Yao and Xiaoyan Sun and Jian Feng and Yitong Xing},
  doi          = {10.1016/j.eswa.2025.129517},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129517},
  shortjournal = {Expert Syst. Appl.},
  title        = {Boundary-aware contrastive network for rotating machinery fault diagnosis under unknown long-tailed class distribution},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal collaborative framework for complex parking scenarios: Multimodal perception fusion, curvature‑continuous trajectory planning and hierarchical robust tracking control. <em>ESWA</em>, <em>297</em>, 129515. (<a href='https://doi.org/10.1016/j.eswa.2025.129515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in car ownership has led to the tightening of parking spaces, frequent parking accidents and rising operational complexity. The automatic parking system has become the core breakthrough to solve the pain points of urban traffic. Therefore, this paper proposes a multi-modal perception-planning-control collaborative framework. The accuracy of parking line recognition is 94.85 % through the cross-modal feature fusion of camera and radar. The three-dimensional semantic map of obstacles is constructed by fusing multi-source ranging data and depth feature extraction, and the maximum detection error is less than 0.65 m. Aiming at the non-holonomic constraint characteristics under the Ackerman steering model, a multi-modal path planning strategy based on an arc-line-relaxation curve is designed. The dynamic curvature compensation algorithm is used to realize the full attitude parking of vertical and horizontal parking spaces. On this basis, a hierarchical control architecture is proposed, the nonlinear model predictive control (NMPC) is used to optimize the front wheel angle in real-time, and the position-speed cascade PID is used to achieve precise speed regulation in the longitudinal direction. In the Matlab/Simulink-CarSim joint simulation, the lateral tracking error is stable at ±0.05 m, and the longitudinal speed control overshoot is less than 3 %. Real vehicle experiments show that the proposed method has a good path-tracking effect and proves its applicability to real vehicles.},
  archive      = {J_ESWA},
  author       = {Dong Guo and Zhiqin Li and Bin Zhou and Tengfei Ma and Shuai Zhang and Chao Gao and Tongqing Zhang},
  doi          = {10.1016/j.eswa.2025.129515},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129515},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal collaborative framework for complex parking scenarios: Multimodal perception fusion, curvature‑continuous trajectory planning and hierarchical robust tracking control},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel elite-preserving iterated greedy algorithm with Q-learning for cascaded flowshop joint scheduling problem. <em>ESWA</em>, <em>297</em>, 129512. (<a href='https://doi.org/10.1016/j.eswa.2025.129512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of modern manufacturing processes, the demand for multi-shop joint scheduling has become increasingly important. The cascaded flowshop joint scheduling problem (CFJSP) has gained widespread attention due to its alignment with practical production needs. However, related research on this problem remains limited. Therefore, this paper proposes an elite-preserving iterated greedy with Q-learning (EIGQ) algorithm for solving the CFJSP, with the objective of minimizing the makespan. We introduce Q-learning into the perturbation mechanisms of the two phases, enabling the algorithm to adaptively select perturbation operators based on search status and historical performance. Four neighborhood operators are designed to balance global exploration and local exploitation. In addition, a strategy combining elite preservation and dynamic population injection is proposed to enhance the exploration of the solution space. Finally, the comprehensive experiments validate the effectiveness of the key components of the EIGQ algorithm and demonstrate its significant superiority over six state-of-the-art methods based on the results of 1200 test instances.},
  archive      = {J_ESWA},
  author       = {Jie Liu and Quan-Ke Pan and Wei-Min Li and Bing-Tao Wang},
  doi          = {10.1016/j.eswa.2025.129512},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129512},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel elite-preserving iterated greedy algorithm with Q-learning for cascaded flowshop joint scheduling problem},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An intelligent diagnosis method for underwater gliders progressive anomaly based on layer-by-layer attention mechanism. <em>ESWA</em>, <em>297</em>, 129511. (<a href='https://doi.org/10.1016/j.eswa.2025.129511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progressive anomalies have a significant and incalculable impact on long-endurance platforms such as Autonomous Underwater Gliders (AUGs), and it is essential to detect and recognize them. In this paper, an unsupervised learning framework with layer-by-layer attention mechanism is constructed to analyze multi-source sequence data and develop a progressive anomaly diagnosis algorithm for AUGs. Firstly, an orthogonalized bidirectional Long Short-Term Memory (LSTM) algorithm is introduced to remove the strong correlations in feature data and achieve source decoupling. Secondly, a random mask strategy is incorporated into the encoder to enrich data features. Thirdly, prior-association and sequence-association are added to the encoder-decoder structure, and a minimax strategy is employed to amplify the association discrepancy, so as to make the anomaly features obvious. Finally, a layer-by-layer attention distribution is constructed to identify anomaly locations. The model is trained and tested using actual experimental data to verify the detection and recognition effect of the proposed algorithm. Compared with the existing unsupervised anomaly detection algorithms, the algorithm in this paper has a high detection rate, with an average value of more than 98 %, and is able to accurately complete the identification of anomaly locations, providing a strong basis for the further processing of subsequent anomalies.},
  archive      = {J_ESWA},
  author       = {Shanshan Hu and Qingwei Liang and Hancheng Huang and Cheng Yang},
  doi          = {10.1016/j.eswa.2025.129511},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129511},
  shortjournal = {Expert Syst. Appl.},
  title        = {An intelligent diagnosis method for underwater gliders progressive anomaly based on layer-by-layer attention mechanism},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). D2EF-net: A deep dual-encoder fusion-based unified network for brain tumor classification from undersampled MRI. <em>ESWA</em>, <em>297</em>, 129509. (<a href='https://doi.org/10.1016/j.eswa.2025.129509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) offers superior diagnostic quality but suffers from prolonged acquisition times, leading to patient discomfort and motion artifacts. The challenge of undersampled MRI data adversely impacts brain tumor classification accuracy. To address this, we propose D2EF-Net, a unified framework for brain tumor classification from undersampled MRI data. The model integrates MRI reconstruction and classification into a joint learning framework, preserving key diagnostic features while improving accuracy. D2EF-Net introduces three novel modules: adaptive multiscale convolution (AMC) for efficient feature extraction, residual depthwise convolution (RDC) for reduced complexity, and attention-enhanced hybrid transformer (AHT) for comprehensive feature representation. Extensive experiments on five datasets (DS-1 to DS-5) demonstrate that D2EF-Net significantly outperforms existing methods in tumor classification accuracy. Notably, it achieved average improvements of 4.66 %, 4.61 %, 14.94 %, 10.01 %, 28.53 %, 10.07 %, 10.82 %, 4.60 %, 26.01 %, and 7.97 % over baseline models. Additionally, D2EF-Net excels in fully-sampled data scenarios, further showcasing the flexibility of its joint learning mechanism. In conclusion, D2EF-Net offers a robust solution for accelerating MRI acquisition while maintaining high diagnostic accuracy, with potential applications in clinical practice.},
  archive      = {J_ESWA},
  author       = {Zhenyu Huang and Yuchao Jiang and Jizhong Duan},
  doi          = {10.1016/j.eswa.2025.129509},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129509},
  shortjournal = {Expert Syst. Appl.},
  title        = {D2EF-net: A deep dual-encoder fusion-based unified network for brain tumor classification from undersampled MRI},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RALLRec+: Retrieval augmented large language model recommendation with reasoning. <em>ESWA</em>, <em>297</em>, 129508. (<a href='https://doi.org/10.1016/j.eswa.2025.129508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have been integrated into recommender systems to enhance user behavior comprehension. The Retrieval Augmented Generation (RAG) technique is further incorporated into these systems to retrieve more relevant items and improve system performance. However, existing RAG methods have two shortcomings. (i) In the retrieval stage, they rely primarily on textual semantics and often fail to incorporate the most relevant items, thus constraining system effectiveness. (ii) In the generation stage, they lack explicit chain-of-thought reasoning, further limiting their potential. In this paper, we propose Representation learning and R easoning empowered retrieval- A ugmented L arge L anguage model Rec ommendation ( RALLRec+ ). Specifically, for the retrieval stage, we prompt LLMs to generate detailed item descriptions and perform joint representation learning, combining textual and collaborative signals extracted from the LLM and recommendation models, respectively. To account for the time-varying nature of user interests, we propose a simple yet effective reranking method to capture preference dynamics. For the generation phase, we first evaluate reasoning LLMs on recommendation tasks, uncovering valuable insights. Then we introduce knowledge-injected prompting and consistency-based merging approach to integrate reasoning LLMs with general-purpose LLMs, enhancing overall performance. Extensive experiments on three real-world datasets validate our method’s effectiveness.},
  archive      = {J_ESWA},
  author       = {Sichun Luo and Jian Xu and Xiaojie Zhang and Linrong Wang and Sicong Liu and Hanxu Hou and Linqi Song},
  doi          = {10.1016/j.eswa.2025.129508},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129508},
  shortjournal = {Expert Syst. Appl.},
  title        = {RALLRec+: Retrieval augmented large language model recommendation with reasoning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New kiwifruit quality grading methods based on image multi-feature fusion and ResTNet model. <em>ESWA</em>, <em>297</em>, 129507. (<a href='https://doi.org/10.1016/j.eswa.2025.129507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kiwifruit grading is a critical step between harvesting and market entry, ensuring quality, enhancing value, and boosting market competitiveness. This paper investigates automatic grading methods for kiwifruit using image multi-feature fusion and neural networks, focusing on the “Cuixiang” variety. To isolate kiwifruit from the background, we analyze traditional image segmentation techniques and utilize the S-component of HSV color space, the Y component of YIQ color space along with grayscale information. For appearance features, the S-component and RGB color moments are employed to represent color characteristics, while an equivalence model LBP histogram describes skin texture. Shape features are quantified by calculating the area, perimeter, major axis, minor axis, and aspect ratio. The defect area is cut by threshold segmentation method. The defect area and color moment are used to describe the defect characteristics of kiwifruit. Then, experiments on the correlation and complementarity of these four features show that the correlation between them is not high, and their complementarity is strong. We also present the importance ranking of four features for each of the six classical machine learning models such as Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), Logistic Regression (LR), Naive Bayes (NB), and K-Nearest Neighbors (KNN). Based on the ranking results of the importance of these features, a feature fusion method is designed for kiwifruit quality grading. This method can obtain the optimal feature combination for each model. The experiment shows that LR performs the best among the six models. To further enhance classification accuracy, deep learning techniques are applied for quality grading. Building on ResNet (Residual Network) and ViT (Vision Transformer), the size of both models is reduced by decreasing the number of linear layers and use the residual outputs as inputs to the ViT model. Through experimental comparison, ReLU (Rectified Linear Unit) is selected as the activation function for the new model, which we name ResTNet. The rationality of our model architecture design is also verified through comparative experiments. Then ResTNet is compared with ResNet50, ViT-B/16, and three other state-of-the-art models. The comparative experimental results show that ResTNet has the best interpretability performance, and its grading accuracy is comparable to those of three state-of-the-art models (of course, significantly better than those of ResNet50 and ViT-B/16). The computational efficiency of ResTNet is also very balanced. Finally, ResTNet’s grading accuracy (over 99 %) is significantly better than those of six traditional machine learning models, and also higher than those of related works in the past three years.},
  archive      = {J_ESWA},
  author       = {Honggang Miao and Zichun Wang and Yucheng Zhang and Xiyuan Lu and Yuhan Lou and Xin Li and Jianxiang Ma and Yi Wang and Siyu Huang and Shiwei Xu and Zhengwei Ren and Yunliu Zeng and Yan Tong},
  doi          = {10.1016/j.eswa.2025.129507},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129507},
  shortjournal = {Expert Syst. Appl.},
  title        = {New kiwifruit quality grading methods based on image multi-feature fusion and ResTNet model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enterprise risk forecasting in human resource management in cloud computing using cascaded block visual modelling, artificial hummingbird guided graph attention networks. <em>ESWA</em>, <em>297</em>, 129505. (<a href='https://doi.org/10.1016/j.eswa.2025.129505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the ever-changing economic landscape of today, sustaining organizational resilience and competitive advantage requires good enterprise risk forecasting within human resource management (HRM). Due to their inability to manage the sensitivity, volume, and complexity of HR data, traditional risk assessment techniques frequently hinder prompt and precise decision-making. This study uses Cascaded Block Visual Modelling with Artificial Hummingbird-guided Attention Networks (CBVM-AH2GACNN) to present a novel cloud-integrated neural network approach for Enterprise Risk Forecasting in order to overcome these issues. The framework employs Shape-Aware Mesh Normal Filtering (SAMNF) for robust data preprocessing, a Scale-Aware Transformer (SA2MT) for multi-scale feature extraction, and the Snow Geese Algorithm (SGA) for optimal feature selection. Data security and scalability are ensured through Fuzzy-based Elliptic Curve Cryptography (FECC) implemented on cloud infrastructure. Tested on real HR datasets, the model achieves a classification accuracy of 99.5%, reduces training time by 20%, accelerates inference by 15%, and improves storage efficiency by 98.5%. This solution provides HR professionals with real-time, adaptive risk insights, enhancing organizational decision-making and resilience in an increasingly complex risk landscape.},
  archive      = {J_ESWA},
  author       = {Allam Balaram and Rajendra Mahanandia and Parikshit N. Mahalle and D. Barani},
  doi          = {10.1016/j.eswa.2025.129505},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129505},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enterprise risk forecasting in human resource management in cloud computing using cascaded block visual modelling, artificial hummingbird guided graph attention networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bias mitigation label and aware context for debiased visual question answering. <em>ESWA</em>, <em>297</em>, 129504. (<a href='https://doi.org/10.1016/j.eswa.2025.129504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current Visual Question Answering (VQA) models rely significantly on language bias to answer questions (i.e., generating answers directly from questions without using images), which severely reduces their robustness in real-world scenarios. These models often overfit the question-answer pairs presented in the training dataset, leading to suboptimal performance when confronted with answer distributions that differ from those encountered during training. We propose a novel training strategy called Bias Mitigation Label and Aware Context (BMLAC) to alleviate the above problem. Specifically, the Bias Mitigation Label (BML) is dynamically constructed based on the degree of sample bias to adjust losses accurately across samples and ensure a more balanced total loss in VQA. In addition, the Aware Context (AC) provides the model with valid global information to assist the model in predicting answers more accurately. Finally, the model is trained through an ensemble-based approach that retains the beneficial effects of biased samples on the model while reducing their importance. Our approach is model-agnostic and supports end-to-end training. Extensive experimental results show that BMLAC provides the following benefits: (1) it improves the performance of several VQA models; (2) it achieves state-of-the-art results on the bias-sensitive VQA-CP v2 benchmark (60.91 %) without sacrificing performance on the in-distribution VQA v2 dataset (60.81 %); (3) when combined with the pre-trained LXMERT model, it further reaches 64.55 % on VQA-CP v2 and 64.21 % on VQA v2, with the smallest performance gap (0.34 %) between the two datasets among all compared methods. Ablation studies indicate that the synergy of BML (dynamic weighting), AC (global context), and ensemble training is key to performance.},
  archive      = {J_ESWA},
  author       = {Runlin Cao and Zhixin Li and Zhenjun Tang and Huifang Ma},
  doi          = {10.1016/j.eswa.2025.129504},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129504},
  shortjournal = {Expert Syst. Appl.},
  title        = {Bias mitigation label and aware context for debiased visual question answering},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). What and when to look? temporal span proposal network for video relation detection. <em>ESWA</em>, <em>297</em>, 129503. (<a href='https://doi.org/10.1016/j.eswa.2025.129503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying relations between objects is central to understanding the scene. While several works have been proposed for relation modeling in the image domain, there have been many constraints in the video domain due to challenging dynamics of spatio-temporal interactions ( e.g. , between which objects are there an interaction? when do relations start and end?). To date, two representative methods have been proposed to tackle Video Visual Relation Detection (VidVRD): segment-based and window-based. The segment-based methods lack temporal continuity on the other hand, window-based scale poorly. To tackle this limitations of typical methods, we propose a novel approach named Temporal Span Proposal Network (TSPN). TSPN tells what to look : it sparsifies relation search space by scoring relationness of object pair, i.e. , measuring how probable a relation exist. TSPN tells when to look : it simultaneously predicts start-end timestamps ( i.e. , temporal spans) and categories of the all possible relations by utilizing full video context. These two designs enable a win-win scenario: it accelerates training by 2 × or more than existing methods and achieves competitive performance on two VidVRD benchmarks (ImageNet-VidVRD and VidOR). Moreover, comprehensive ablative experiments demonstrate the effectiveness of our approach.},
  archive      = {J_ESWA},
  author       = {Sangmin Woo and Junhyug Noh and Kangil Kim},
  doi          = {10.1016/j.eswa.2025.129503},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129503},
  shortjournal = {Expert Syst. Appl.},
  title        = {What and when to look? temporal span proposal network for video relation detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A contrastive video language multimodal method for teacher action quality assessment. <em>ESWA</em>, <em>297</em>, 129501. (<a href='https://doi.org/10.1016/j.eswa.2025.129501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teacher actions can enhance the expression and appeal of classroom teaching, and appropriate actions can improve teaching effects. Therefore, the assessment of teacher actions can better norm and improve teacher’s teaching. The lack of datasets for teacher action quality assessment has seriously hindered the development of this field. To address this gap, we construct the first teacher action quality assessment dataset and propose a multi-granularity joint labeling system that combines continuous score labels and discrete grade labels, thereby enriching the expressive capacity and research space of the action quality assessment tasks. This dataset contains 9 disciplines and 4 main categories of teachers’ frequent teaching actions in the teaching process, with a total of 3738 samples, more than all current action quality assessment datasets. Furthermore, considering the specific nature of this task, this paper introduces textual prompts into action quality assessment task for the first time to learn semantic information in labels, and proposes a contrastive video-language multimodal method. By modeling the semantic consistency between action performance and target scores, the method directly guides the model to learn prediction targets and improves performance with negligible computational overhead. The experimental results prove the rationality and robustness of the constructed dataset, as well as the effectiveness of the proposed evaluation method.The dataset can be openly obtained at https://github.com/MingZier/TAQA-Dataset .},
  archive      = {J_ESWA},
  author       = {Ming Fang and Yunpeng Zhou and Qi Liu and Pengyang Wang and Jianping Ren and Xile Zhao and Shuhua Liu},
  doi          = {10.1016/j.eswa.2025.129501},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129501},
  shortjournal = {Expert Syst. Appl.},
  title        = {A contrastive video language multimodal method for teacher action quality assessment},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossLGNet: Enhanced feature extraction for magnetocardiography via local prediction and global comparison self-supervised learning. <em>ESWA</em>, <em>297</em>, 129500. (<a href='https://doi.org/10.1016/j.eswa.2025.129500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated analytical techniques for magnetocardiography (MCG) are crucial for the diagnosis and prediction of cardiovascular diseases. However, labeled data sparsity and susceptibility to interference remain significant challenges in MCG research. Moreover, the complex temporal and spatial features of MCG signals pose additional challenges for deep learning models. Learning generic and meaningful representations from MCG signals via self-supervised pre-training is an effective method to alleviate these issues. To enhance feature extraction performance of the pre-trained model, we propose a novel self-supervised learning framework named CrossLGNet. First, we generated two distinct augmented views of the MCG signals using temporal- and channel-domain augmentation and CrossLGNet was used to learn the local and global feature representations of these augmented views. The local prediction module performs the local cross-view prediction task by extracting contextual information from past and future local views, we introduced a cross-spatio-temporal attention fusion module into local prediction to facilitate the capability of the model to extract temporal and spatial features. The global comparison module learns the overall discriminative representation of the different augmented views in parallel. We comprehensively evaluated CrossLGNet based on multiple downstream tasks to demonstrate its advantages in model performance, label efficiency, robustness, and computational complexity. Notably, CrossLGNet achieved superior performance with limited labeled data and noise interference, which was crucial to improving the clinical application value of MCG and also highlighted the potential of self-supervised learning in the automatic analysis of MCG signals.},
  archive      = {J_ESWA},
  author       = {Ruizhe Wang and Jiaojiao Pang and Dong Xu and Xiaole Han and Yanfei Yang and Zhanyi Liu and Yanmei Wang and Min Xiang and Xiaolin Ning},
  doi          = {10.1016/j.eswa.2025.129500},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129500},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossLGNet: Enhanced feature extraction for magnetocardiography via local prediction and global comparison self-supervised learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exponential stability of discrete-time switched neural networks via improved asymmetric functionals. <em>ESWA</em>, <em>297</em>, 129499. (<a href='https://doi.org/10.1016/j.eswa.2025.129499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the exponential stability of discrete-time switched neural networks (DSNNs) under mode-dependent average dwell time (MDADT) switching. A novel multiple piecewise convex and asymmetric Lyapunov-Krasovskii functional (MPCA-LKF) is proposed, which introduces linear time-varying convex combinations over partitioned switching intervals, and eliminates conventional symmetry and positive-definiteness constraints on the functional matrices. In addition, a set of free-weighting matrices (FWM) zero equations is incorporated into the augmented system to avoid nonconvex terms caused by the forward difference and improve estimation accuracy. The novelty of this work lies in the construction of the MPCA-LKF, which integrates non-symmetric, non-definite matrix structures with segment-wise convexity to enhance the tightness of Lyapunov difference estimation. To the best of our knowledge, such a structure has not been explored in existing MDADT-based LKF frameworks. Based on such functional, several new exponential stability criteria are established in the form of linear matrix inequalities (LMIs), which explicitly consider switching patterns and state-dependent behaviors. Furthermore, two corollaries are developed to address slow switching to stable modes and fast switching to unstable modes. Finally, comprehensive numerical simulations, including comparisons with several recent state-of-the-art methods, validate that the proposed approach achieves less conservatism, larger admissible delay bounds, and higher exponential convergence rates, demonstrating its clear advantages over existing approaches.},
  archive      = {J_ESWA},
  author       = {Da Chen and Kaibo Shi and Xiao Cai and Jinde Cao and Ohmin Kwon and Shiping Wen},
  doi          = {10.1016/j.eswa.2025.129499},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129499},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exponential stability of discrete-time switched neural networks via improved asymmetric functionals},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel pi-style dendritic neural network based on Kolmogorov–Arnold representation for time series modeling. <em>ESWA</em>, <em>297</em>, 129495. (<a href='https://doi.org/10.1016/j.eswa.2025.129495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is essential across domains such as energy, finance, and climate, yet conventional statistical and deep learning methods often struggle to balance accuracy, efficiency, and interpretability when modeling complex, nonlinear temporal patterns. This study introduces the Pi-style Dendritic Kolmogorov–Arnold Network (PiDKAN), a novel hybrid neural architecture that integrates the multiplicative structure of Pi-Sigma networks, the localized processing of Dendritic Neural Models, and the univariate function decomposition capability of Kolmogorov–Arnold Networks. By capturing both local and high-order interactions, PiDKAN addresses key challenges in time series modeling. The model was benchmarked against ten established neural networks using eight electricity consumption datasets spanning four years, consistently achieving superior performance in RMSE, MAE, and MAPE metrics. Statistical analyses confirmed the significance of these improvements, demonstrating PiDKAN’s strength as a robust, and accurate forecasting solution. These results suggest that PiDKAN offers a promising new direction for interpretable time series models in real-world applications.},
  archive      = {J_ESWA},
  author       = {Fatih Sağlam and Çağlar Sözen},
  doi          = {10.1016/j.eswa.2025.129495},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129495},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel pi-style dendritic neural network based on Kolmogorov–Arnold representation for time series modeling},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Impact assessment method for disturbance events in complex manufacturing scenarios. <em>ESWA</em>, <em>297</em>, 129494. (<a href='https://doi.org/10.1016/j.eswa.2025.129494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disturbances in complex manufacturing scenarios are often characterized by their simultaneous occurrences and mutual interactions. These disturbances can affect production progress, product quality, and enterprise performance. Under specific resource constraints in the workshop, it is essential to systematically assess the impact of various disturbances on workshop operations to determine the priority of responses to these disturbances. This provides valuable insights for formulating systematic response strategies for various disturbance events. However, current research faces several challenges. A key challenge is that current methods for assessing disturbance impacts are highly subjective and fail to provide comprehensive analysis of disturbances. To address these challenges, this paper proposes a method for assessing the impact of workshop disturbances based on Hesitant Fuzzy ANP-VIKOR (HF-ANP-VIKOR). First, a systematic classification and summary of workshop disturbance events are conducted, followed by the construction of a disturbance feature characterization model. Next, hesitant fuzzy theory is introduced, and the ANP method is used to calculate the weights of various indicators, which are then combined with the VIKOR method to assess the impact of disturbance events, thereby reducing the bias introduced by expert subjective judgment. A case study of an intelligent flange production workshop is conducted to validate the effectiveness of the proposed method, and its robustness is further validated through sensitivity analysis. Experimental results demonstrate that the proposed method can effectively prioritize multi-level disturbance events in workshops, thus providing a reliable foundation for production optimization and resource allocation.},
  archive      = {J_ESWA},
  author       = {Jingkai Li and Tianliang Hu and Qi Meng and Shuaichang Zhou and Songhua Ma},
  doi          = {10.1016/j.eswa.2025.129494},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129494},
  shortjournal = {Expert Syst. Appl.},
  title        = {Impact assessment method for disturbance events in complex manufacturing scenarios},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automating construction contract question answering using large language model and fine-tuning. <em>ESWA</em>, <em>297</em>, 129493. (<a href='https://doi.org/10.1016/j.eswa.2025.129493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective contract management is a critical factor in the success of construction projects. However, current contract management practices often rely heavily on expert experience, suffer from low efficiency, and lack convenient access to domain knowledge, which makes them inadequate for meeting the practical demands of construction projects. Large language models (LLMs), due to their powerful natural language understanding and generation capabilities, have demonstrated significant advantages in semantic comprehension and information extraction, offering a new approach to addressing the aforementioned problems. However, considering issues such as the privacy of construction contract data and the cost of model deployment, general-purpose LLMs are difficult to implement directly within construction companies. This paper proposes a domain adaptation method that combines supervised fine-tuning (SFT) with reinforcement learning (RL), enabling low-cost development of a contract Question Answering (QA) model tailored to the construction domain by fine-tuning a small open-source model. To support this, we constructed a high-quality QA dataset based on the FIDIC standard contract conditions and related interpretive materials, and conducted model training and evaluation. The results show that the fine-tuned model achieves performance comparable to general-purpose LLMs across multiple key dimensions. We also demonstrate a data construction framework that provides a transferable strategy for datasets generation in professional domains where QA data is scarce.},
  archive      = {J_ESWA},
  author       = {Mingyu Zhang and Chenglong Xu and Yihong Gan and Yu Wang and Yi Fu and Yongqiang Chen},
  doi          = {10.1016/j.eswa.2025.129493},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129493},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automating construction contract question answering using large language model and fine-tuning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IGA-net: An iterative low-light micro-hole inner wall image enhancement network via global illumination modulation and adaptive feature optimization. <em>ESWA</em>, <em>297</em>, 129492. (<a href='https://doi.org/10.1016/j.eswa.2025.129492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insufficient illumination inside micro-holes leads to low visibility and noise on inner walls, degrading image quality and compromising the reliability of industrial visual inspection. However, existing low-light enhancement methods often fail to effectively coordinate global and local illumination, and struggle to adaptively preserve fine-grained textures in extremely dark regions, resulting in color distortion, overexposure, and texture loss. Moreover, the high computational cost of current transformer architectures limits their suitability for real-time deployment in industrial settings. To address these challenges, this paper proposes IGA-Net, an iterative enhancement network tailored for low-light micro-hole inner wall images, which integrates Global Illumination Modulation Module (GIM) and Adaptive Feature Optimization Module (AFM). Unlike Transformer-based methods that rely on computationally intensive self-attention, the GIM captures global illumination priors via lightweight non-local modeling, effectively suppressing color distortion and overexposure. Building upon this, the AFM adaptively aggregates and refines multi-stage features across iterations, enabling real-time enhancement while preserving fine textures and minimizing noise. Extensive experiments on the micro-hole inner wall dataset demonstrate that IGA-Net achieves PSNR 33.48  dB, SSIM 0.9026, NIQE 1.28 and PIQE 2.65, surpassing LLFormer by +1.54  dB while maintaining a compact design (1.18 M parameters, 13  ms inference time). Additionally, evaluations on the MIT-Adobe FiveK and LSRW datasets further validate the robustness and generalizability of IGA-Net, underscoring its exceptional performance in low-light image enhancement across diverse real-world environments.},
  archive      = {J_ESWA},
  author       = {Zongyang Zhao and Jiehu Kang and Ning Xu and Chuanshi Cheng and Yichen Xu and Yuqi Ren and Haokai Wu and Wenjie Zhang and Bin Wu},
  doi          = {10.1016/j.eswa.2025.129492},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129492},
  shortjournal = {Expert Syst. Appl.},
  title        = {IGA-net: An iterative low-light micro-hole inner wall image enhancement network via global illumination modulation and adaptive feature optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tunable acoustic streaming-driven micropump for integration into lab-on-chip platforms for biomedical assays. <em>ESWA</em>, <em>297</em>, 129491. (<a href='https://doi.org/10.1016/j.eswa.2025.129491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An integrated pumping module is a crucial component in lab-on-a-chip (LOC) and organ-on-a-chip (OoC) devices, as it enables fluid transport and control for biomedical assays. In this study, an acoustomicrofluidic pump is proposed as a compact and integrable solution compatible with LOC platforms. The reference structure of the micropump is initially parameterized, and a design is established based on two primary variables: the inclination angle of the sharp-edge structures and the applied peak-to-peak voltage. Merits of performance were considered to be pumping rate and Maximum shear stress, latter of which is proposed as an objective function to assess acoustic micropump bio-compatibility. To analyze the functional behavior of the system, a surrogate model is constructed using a face-centered central composite design (CCD), enabling predictive assessment of the objective functions under different design configurations. It is demonstrated that by decreasing the inclination angle from its maximum to minimum value, the pumping rate increases by more than 79%, and maximum shear stress is decreased by more than 95%. Surrogate predictive model is then utilized within a Particle Swarm Optimization (PSO) algorithm to identify optimal design parameters. The resulting optimized designs exhibit an enhancement in system efficiency more than 68% compared to the reference configuration. This modeling and optimization methodology enables effective tuning of the acoustomicrofluidic pump’s performance for adapting the system to application-specific requirements. Potential biomedical uses of the optimized device include on-chip cell lysis and biofilm analysis, along with bio-nanoparticle synthesis, where controlled and efficient microfluidic pumping is essential.},
  archive      = {J_ESWA},
  author       = {Faridoddin Hassani and Ali Golshani and Afshin Kouhkord and Reza Ansari and Saeid Sahmani},
  doi          = {10.1016/j.eswa.2025.129491},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129491},
  shortjournal = {Expert Syst. Appl.},
  title        = {Tunable acoustic streaming-driven micropump for integration into lab-on-chip platforms for biomedical assays},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A lightweight semi-supervised distillation framework for hard-to-detect surface defects in the steel industry. <em>ESWA</em>, <em>297</em>, 129489. (<a href='https://doi.org/10.1016/j.eswa.2025.129489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving high-precision industrial defect detection under real-time constraints remains a significant challenge, particularly due to the presence of hard-to-detect defect types and limited computational resources. This challenge is further exacerbated by the scarcity of labeled data in rapidly changing production settings, where manual annotation is time-consuming and costly. To address these issues, we propose a lightweight framework, Deep Feature-aware Semi-Supervised Distillation (DFSSD), which integrates semi-supervised learning (SSL) and knowledge distillation (KD) into a cohesive architecture. DFSSD combines a Scale-Balanced Intersection over Union (IoU) principle to enhance localization of hard-to-detect defects in complex backgrounds, a Layer-aware Channel Distillation (LACD) strategy for efficient model compression and distillation, and a Dual-Level Adaptive Thresholding (DLAT) mechanism to generate high-quality pseudo-labels from unlabeled data, improving learning efficiency under limited supervision. Experimental results demonstrate that with only 30 % of labeled data, DFSSD matches the performance of fully supervised models while reducing model complexity from 11.13M to 3.01M parameters. The framework has been successfully deployed on a cold-rolled steel production line, demonstrating its effectiveness, efficiency, and real-time applicability for industrial defect detection. The code is publicly available at https://github.com/VVR0624/DFSSD .},
  archive      = {J_ESWA},
  author       = {Shuzong Chen and Tiantian Fu and Jun Song and Xiaoyu Wang and Minghan Qi and Changchun Hua and Jie Sun},
  doi          = {10.1016/j.eswa.2025.129489},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129489},
  shortjournal = {Expert Syst. Appl.},
  title        = {A lightweight semi-supervised distillation framework for hard-to-detect surface defects in the steel industry},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A lightweight multi-bit-width graph convolutional network system for safety-critical applications. <em>ESWA</em>, <em>297</em>, 129488. (<a href='https://doi.org/10.1016/j.eswa.2025.129488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Graph Convolutional Networks (GCNs) have been widely applied in safety–critical scenarios such as power grid scheduling, satellite task planning, and autonomous driving due to their advantages in processing non-Euclidean data. To address the demands for high energy efficiency and reliability in edge deployments, this paper proposes a novel cluster-aware quantization scheme and designs a multi-bit-width GCN accelerator architecture that supports hybrid-precision computation and integrates dedicated fault-tolerant techniques. The architecture is integrated into the Versal AI edge platform, supported by a PyTorch-based hardware-software co-design framework. Fine-grained dynamic bit-level protection and inter-cluster fault detectors are introduced to mitigate the impact of bit-level and cluster-level soft errors, fully exploiting the potential fault-tolerant properties of the graph structure. The MBW GCN achieves up to 91 × and 16.5 × speedups over CPU and GPU implementations, respectively, along with energy efficiency improvements of up to 2087 × and 1081×, while delivering performance comparable to state-of-the-art accelerators. In addition to its outstanding performance and energy efficiency, the proposed fault-tolerant techniques are demonstrated by neutron irradiation experiments to significantly improve system reliability with no more than a 6.2 % increase in resource usage. Compared to the unprotected version, the total cross section is reduced by 79.52 %, 82.53 %, and 82.69 % across the three benchmark datasets, showing strong potential for deployment in safety–critical edge computing applications.},
  archive      = {J_ESWA},
  author       = {Jing Zhang and Wangshen Wen and Zongxuan Xie and Minchi Hu and Zehao Wu and Lei Shen and Chang Cai},
  doi          = {10.1016/j.eswa.2025.129488},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129488},
  shortjournal = {Expert Syst. Appl.},
  title        = {A lightweight multi-bit-width graph convolutional network system for safety-critical applications},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MLoRA+: Transformer-fusion mixture-of-LoRA network for multi-domain click-through rate prediction. <em>ESWA</em>, <em>297</em>, 129486. (<a href='https://doi.org/10.1016/j.eswa.2025.129486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate prediction is pivotal in areas such as e-commerce, social media, and streaming media, directly impacting user experience and platform revenue. In multi-domain recommendation settings, traditional CTR models struggle with issues like data sparsity, disparate data distributions, and neglect of inter-domain correlation. Conventional approaches often employ domain-specific modules for each domain, but this strategy significantly increases parameters and fails to address inter-domain dependencies, leading to suboptimal training outcomes. We propose MLoRA+, a model-agnostic, multi-domain CTR framework that introduces a LoRA module for each domain to better address inter-domain correlations while maintaining parameter efficiency. To capture inter-domain correlations, MLoRA+ incorporates a self-attention mechanism, enabling the model to weigh domain-specific embeddings based on the contribution of each domain. The softmax function further calibrates these contributions, allowing for adaptive, domain-sensitive learning. This combined approach enables MLoRA+ to effectively leverage inter-domain correlations and achieve substantial improvements in prediction accuracy across diverse multi-domain datasets. Experimental evaluations on three benchmark datasets (Taobao-10, Amazon-6, Movielens-gen) demonstrate that MLoRA+ achieves average WAUC improvements of 0.95 %, 1.23 %, and 0.20 % over baseline models. MLoRA+ outperforms traditional methods and state-of-the-art baselines, demonstrating strong adaptability, computational efficiency, and relevance to complex real-world recommendation systems.},
  archive      = {J_ESWA},
  author       = {Dehong Gao and Shufan Chen and Zhiming Yang and Luwei Yang and Haining Gao and Muyang Wu and Shanqing Yu and Qi Xuan and Wenxiao Zhang and Libin Yang and Xiaoyan Cai},
  doi          = {10.1016/j.eswa.2025.129486},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129486},
  shortjournal = {Expert Syst. Appl.},
  title        = {MLoRA+: Transformer-fusion mixture-of-LoRA network for multi-domain click-through rate prediction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LGTime: Leveraging LLMs with feature-aware processing and multi-granularity fusion for zero-shot time series forecasting. <em>ESWA</em>, <em>297</em>, 129483. (<a href='https://doi.org/10.1016/j.eswa.2025.129483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Large Language Models (LLMs) have led to significant progress in the fields of computer vision (CV) and natural language processing (NLP) by facilitating the comprehension of text and the management of heterogeneous data for a variety of tasks, particularly in zero-shot learning. This development also finds application in the resolution of analogous issues in multivariate time series (MTS). Consequently, research endeavors focused on LLMs as a foundation for time series analysis are undergoing rapid advancement. However, in the real world, we encounter a range of prediction scenarios that are similar yet distinct, facing challenge on the model’s generalizability. In this study, we employ LLM as a backbone for MTS Zero-Shot forecasting to solve this problem. In contrast to conventional MTS analysis that typically rely on mathematical statistics, Our approach augments the semantic content of numerical data by utilizing textual descriptions for each data column, leveraging LLM’s semantic understanding to derive meaning from them. This improves LLM’s understanding of each feature and differentiates between the features to improve the accuracy of the forecasting. We also propose the hierarchical representation of MTS, which fuses MTS into a high-dimensional space of multi-scale temporal semantic information. It solves the drawback that semantic information cannot be fully mined under a single scale. The effectiveness of the proposed method is evidenced by its excellent zero-shot forecasting performance on ETT-small real-world datasets, with MSE of 0.353. Furthermore, our approach has demonstrated remarkable capabilities in enhancing the interpretability of time series analysis because of the textual description.},
  archive      = {J_ESWA},
  author       = {Shujie Wu and Yao Zhang and YiWei Yang and Zhen Li and GuangYu Yu and Long Chen and Jianwei Xu and Aziguli Wulamu},
  doi          = {10.1016/j.eswa.2025.129483},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129483},
  shortjournal = {Expert Syst. Appl.},
  title        = {LGTime: Leveraging LLMs with feature-aware processing and multi-granularity fusion for zero-shot time series forecasting},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clean-label backdoor attack via sample-customized feature alignment. <em>ESWA</em>, <em>297</em>, 129481. (<a href='https://doi.org/10.1016/j.eswa.2025.129481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep neural networks (DNNs) become increasingly prevalent in safety-critical domains such as facial recognition, autonomous driving, and medical diagnosis, their reliance on third-party data sources introduces significant security vulnerabilities, including backdoor attacks. Current clean-label backdoor attacks, while stealthier than dirty-label methods, struggle with practical constraints such as low poisoning rates ( p ≤ 1 % ), limited perturbation budgets ( ϵ ≤ 16 / 255 ), and robustness against defenses. To address these challenges, we identify that selecting samples during poison generation is crucial for the effectiveness of backdoor attacks. Specifically, we introduce an innovative clean-label backdoor attack framework that utilizes sample-customized feature alignment to strengthen the association between source-label samples and the target label. By computing the feature centroids of target-label samples and aligning the features of source-label samples with these centroids, our method significantly improves the feature representation of the desired output, thereby improving the attack success rate. A series of experiments conducted on standard benchmark datasets indicate that our method outperforms existing clean-label backdoor attacks under stringent constraints, such as low poisoning rates and limited perturbation budgets, while maintaining high accuracy on clean data in realistic scenarios. Furthermore, our method demonstrates strong robustness against backdoor defenses, highlighting its potential threat in real-world scenarios.},
  archive      = {J_ESWA},
  author       = {Chen Zhang and Shoutao Sun and Jiali Tu and Xin Chen and Danxin Wang},
  doi          = {10.1016/j.eswa.2025.129481},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129481},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clean-label backdoor attack via sample-customized feature alignment},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing customized bus routes with integrated passenger guidance under stochastic travel times. <em>ESWA</em>, <em>297</em>, 129480. (<a href='https://doi.org/10.1016/j.eswa.2025.129480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customized bus (CB) services offer a flexible and sustainable solution for urban mobility. This study presents an integrated framework that incorporates passenger guidance within CB route design under stochastic travel time conditions. When initial travel requests cannot be met, feasible alternatives are proposed for both unserved and competing requests to improve service coverage and system efficiency. We formulate a bi-objective optimization model to simultaneously determine route configuration, passenger assignment, and alternative selection, while capturing travel time variability through subregional speed distributions. To efficiently solve this complex problem, we develop an improved Newman algorithm integrated with stochastic simulation. The framework is validated through case studies on the Sioux Falls network and a real-world network in Guangzhou, China. Our results demonstrate that passenger guidance obviously enhances profitability and punctuality, with gains varying according to the scale of the CB network. Moreover, the guidance strategy is most effective for passengers with lower sensitivity to travel time, higher fare sensitivity, or longer trip distances. Additionally, explicitly modeling travel time uncertainty in CB route design further bolsters service performance. The findings also suggest that jointly optimizing profit and system-wide punctuality enables the retention of some unprofitable yet socially valuable routes, thereby expanding passenger coverage. Management implications highlight the need for government incentives to balance operator profits with social equity. Such measures can encourage operators to maintain broader service coverage and improve overall urban mobility outcomes.},
  archive      = {J_ESWA},
  author       = {Shuang Han and Hui Fu and Kunhai Yan and Xinjun Lai and Yuanyuan Liu and Yanghang Chen},
  doi          = {10.1016/j.eswa.2025.129480},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129480},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing customized bus routes with integrated passenger guidance under stochastic travel times},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Image captioning in low resource assamese language with semantic information prior and spatially encoded transformer model. <em>ESWA</em>, <em>297</em>, 129479. (<a href='https://doi.org/10.1016/j.eswa.2025.129479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on automatic image caption generation in low-resource Indian languages is still in its early stages compared to resource-rich languages like English. In this regard, this work presents a novel approach for generating image captions in the Assamese language. The first contribution of this work is the development of a semantic prior guided transformer model. The semantic prior is a feature vector derived from an initial Assamese caption. The semantic prior introduces Assamese language-specific characteristics to the transformer model. This further helps the model to synthesize a further refined Assamese caption. The second contribution of this paper is the proposal of input visual feature refinement using space-aware positional encoding. This enhances the model’s ability to capture spatial relationships among salient image regions. Additionally, a reinforcement learning based training strategy is employed to enhance the model performance. This proposal is benchmarked on COCO-Assamese and Flickr30k-Assamese datasets against four baseline methods.},
  archive      = {J_ESWA},
  author       = {Pankaj Choudhury and Sidharth Nair and Prithwijit Guha and Sukumar Nandi},
  doi          = {10.1016/j.eswa.2025.129479},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129479},
  shortjournal = {Expert Syst. Appl.},
  title        = {Image captioning in low resource assamese language with semantic information prior and spatially encoded transformer model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Retinex-guided illumination recovery and progressive feature adaptation for real-world nighttime UAV-based vehicle detection. <em>ESWA</em>, <em>297</em>, 129476. (<a href='https://doi.org/10.1016/j.eswa.2025.129476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime vehicle detection in Unmanned Aerial Vehicle (UAV) imagery is critical for intelligent transportation systems yet faces significant challenges due to low signal-to-noise ratios and pervasive small and medium-scale objects. Existing methods suffer from two critical limitations: (1) conventional low-light enhancement approaches prioritize human perception over downstream detection tasks, and (2) feature fusion frameworks exhibit inadequate cross-level interactions and computational inefficiency for UAV platforms. To address these gaps, we propose the Retinex-guided illumination Differential Transformer Detection network (ReDT-Det), which integrates a nighttime image enhancer with a robust vehicle detection module. Our approach leverages Retinex principles to design an illumination-fused differential transformer block for preliminary image enhancement and illumination recovery, which can effectively improve the quality of nighttime images while preserving critical details. To address the issue of small and medium-scale objects, we introduce a dilation-wise residual cross-stage partial module to enhance the ability to capture fine-grained features. During the feature fusion stage, we propose two key modules: a cross-level feature adaptive adjustment module for the effective integration of multi-scale features and a small object auxiliary feature module specifically designed to enhance the representation of small-scale objects. To validate our method, we curated a comprehensive benchmark dataset for real-world nighttime UAV-based vehicle detection, named NightDrone-Mix. Extensive comparative experiments demonstrate that ReDT-Det outperforms various state-of-the-art image enhancement and detection methods, highlighting its advantages in both accuracy and effectiveness. Additionally, we evaluated ReDT-Det on the DroneVehicle(Night) and ExDark datasets to assess its performance in detecting dark objects, achieving equally promising results.},
  archive      = {J_ESWA},
  author       = {Li Chen and Hongbin Deng and Guanghong Liu and Rob Law and Dongfang Li and Edmond Q. Wu and Limin Zhu},
  doi          = {10.1016/j.eswa.2025.129476},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129476},
  shortjournal = {Expert Syst. Appl.},
  title        = {Retinex-guided illumination recovery and progressive feature adaptation for real-world nighttime UAV-based vehicle detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-branch hierarchical feature fusion network for video source camera identification. <em>ESWA</em>, <em>297</em>, 129475. (<a href='https://doi.org/10.1016/j.eswa.2025.129475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of video platforms, digital video has become one of the core mediums for information dissemination. However, the extensive circulation of video content has also given rise to various social issues, including extortion, fraud, and misinformation. In this context, Video Source Camera Identification (VSCI), as a key technology in video forensics, plays an irreplaceable role in combating the spread of false information and assisting in crime identification. Traditional Source Camera Identification (SCI) methods primarily rely on various trace features generated during the capture process. However, with the popularization and advancement of image processing applications, extracting these feature traces has become increasingly challenging. Furthermore, due to storage and transmission limitations, video data often requires multiple compression processes. This multiple compression not only destroys the original features of the video but also introduces complex noise interference, making video source identification significantly more challenging than SCI for images. While Convolutional Neural Networks (CNNs) excel at local feature extraction, their ability to capture global information is limited, which constrains their identification performance in complex scenarios. We propose a dual-branch hierarchical feature fusion network structure to address the issue. The network extracts local and global features using CNN and Transformer, respectively, and achieves efficient feature fusion through a hierarchical feature fusion module, thereby comprehensively enhancing identification performance. To verify the feasibility and effectiveness of the proposed method, we conducted experiments using VISION and QUFVD dataset. The experimental results demonstrate excellent identification performance of this method.},
  archive      = {J_ESWA},
  author       = {Bo Wang and Jiaqi Chi and Zhuocheng Wu and Huimin Liu and Wei Wang},
  doi          = {10.1016/j.eswa.2025.129475},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129475},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-branch hierarchical feature fusion network for video source camera identification},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comparative analysis, enhancement and evaluation of text anonymization with pre-trained large language models. <em>ESWA</em>, <em>297</em>, 129474. (<a href='https://doi.org/10.1016/j.eswa.2025.129474'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have gained prominence for their remarkable proficiency across various natural language processing tasks. Recent studies have suggested their potential to outperform current text anonymization methods, although an objective evaluation is needed to validate these claims. To address this issue, this work introduces a comprehensive evaluation framework that automatically assesses both privacy protection and utility preservation without relying on manually curated ground-truth data. Moreover, we conduct an in-depth analysis of the LLM-based text anonymization methods proposed so far. Building on the strengths and limitations we found, we propose a novel method to enhance anonymization quality. We also report extensive experimental comparisons between LLM-based approaches and a variety of previous techniques, including those based on named entity recognition (NER), and those more oriented towards privacy-preserving data publishing (PPDP). The results show that LLM-based approaches effectively outperform traditional methods in terms of privacy and utility. Furthermore, we benchmark against manual anonymization, which performed poorly, thus highlighting the limitations of using them as evaluation ground truth. Notably, our LLM-based method stood out by achieving the best privacy protection, and the best privacy-utility trade-off.},
  archive      = {J_ESWA},
  author       = {Benet Manzanares-Salor and David Sánchez},
  doi          = {10.1016/j.eswa.2025.129474},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129474},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comparative analysis, enhancement and evaluation of text anonymization with pre-trained large language models},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TCAC-transformer: A fast convolutional transformer with temporal-channel attention for efficient industrial fault diagnosis. <em>ESWA</em>, <em>297</em>, 129473. (<a href='https://doi.org/10.1016/j.eswa.2025.129473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial fault diagnosis is an indispensable component and of great importance in process automation and equipment maintenance, particularly for complex fault patterns. Recent advancements in transformer models have demonstrated significant potential to capture intricate temporal and spatial dependencies among time series data. However, intensive computational costs, poor feature extraction capability, and limited applicability in resource-constrained environments are still open problems in complex fault diagnosis. In this paper, we propose a novel lightweight diagnostic framework, termed the Temporal-channel attention convolutional Transformer (TCAC-Transformer), specifically designed to address the aforementioned challenges. The TCAC-Transformer can incorporate a redesigned Multi-Scale Separable Convolution (MSSC) module for enhanced feature extraction and use a lightweight architecture by combining a Temporal-Channel Attention module with a Multi-Layer Perceptron (MLP) module. This paper focuses on rotating machinery fault diagnosis as the case study, the gearbox dataset from Xi’an Jiaotong University (XJTU) and the rolling bearing fault dataset from the University of Ottawa (OU) were used for experimental verification. TCAC-Transformer enables efficient real-time fault diagnosis to effectively capture local and global features while maintaining high diagnostic accuracy in industrial applications. Extensive testing across three diverse datasets shows that the proposed approach can enhance fault diagnosis performance by balancing the accuracy, computational resource allocation, and saving training time. Specifically, compared to the current state-of-the-art method (LiConvFormer), our model has only about 10% of the parameters and only about 14% of the FLOPs, and shows reductions in both training time and inference time, while maintaining accuracy. To sum up, it is a practical solution for deploying efficient and accurate fault diagnosis systems.},
  archive      = {J_ESWA},
  author       = {Wei Wu and Nan Zhou and Xiaojun Liang and Weihua Gui and Chunhua Yang and Yiqi Liu},
  doi          = {10.1016/j.eswa.2025.129473},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129473},
  shortjournal = {Expert Syst. Appl.},
  title        = {TCAC-transformer: A fast convolutional transformer with temporal-channel attention for efficient industrial fault diagnosis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting short-term wind power with multi-view attention mechanism and dual recurrent neural networks. <em>ESWA</em>, <em>297</em>, 129472. (<a href='https://doi.org/10.1016/j.eswa.2025.129472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting is critical for enhancing grid stability and optimizing energy resource allocation in renewable energy systems. This study puts forward a novel ensemble prediction model integrating multi-scale wavelet transform (MSWT), a multi-view attention mechanism, and dual recurrent neural networks (MGU and GRU). The multi-scale wavelet transform effectively reduces noise in raw wind power data. The innovative multi-view attention mechanism assigns dynamic weights from multiple perspectives, enabling the model to extract richer temporal features and improve predictive accuracy. By combining MGU and GRU into a unified framework, the model enhances computational efficiency while addressing information loss inherent in conventional recurrent architectures. Experimental results based on datasets from wind frams in Texas and Sverige demonstrate significant advantages of MSWT-MAMG over existing advanced models. On the Texas dataset, it reduced the mean absolute error (MAE) by 10.06%, the root means square error (RMSE) by 8.38%, improved the goodness of fit ( R 2 ) by 0.55%, and the increased the directional accuracy (DA) by 4.72% compared to the multi-scale wavelet transform and long short-term memory network (MSWT-LSTM) model. On the Sverige datasets, the improvements were 19.72%(MAE), 14.66%(RMSE), 0.20% ( R 2 ), and 9.42%(DA). This approach offers practical insights for the efficient management of wind energy resources, contributing to sustainable energy transition goals.},
  archive      = {J_ESWA},
  author       = {Chaoyong Qin and Jialin Xie and Yun Cao and Bangzhu Zhu},
  doi          = {10.1016/j.eswa.2025.129472},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129472},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting short-term wind power with multi-view attention mechanism and dual recurrent neural networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Text-based sentiment analysis using the tetra dominant optimized deep convolutional neural network enabled bidirectional long short-term memory. <em>ESWA</em>, <em>297</em>, 129471. (<a href='https://doi.org/10.1016/j.eswa.2025.129471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based sentiment analysis plays a significant role in social media platforms, which gains more information about the opinions and sentiments that are expressed in a context. Recently, numerous researchers have used diverse techniques to recognize the sentiment that is explored in the form of text. But they are associated with certain disadvantages as a high-dimensional feature space, intricate error, inaccurate information, dialect variations, and minimal noise handling efficiency. These difficulties are effectively eradicated by a new model called Tetra dominant optimized Convolutional Neural Network enabled Deep Bidirectional Long Short-Term Memory (TDO-DCSTM), which detects the sentiment variations and provides better evaluation accuracy specifically. Furthermore, the ability and potency of the developed model are upgraded by the TDO algorithm, which supports the removal of redundant layers, lesser/optimal parameters and selection of optimal training layer parameters. Meanwhile, the DCSTM model recognizes the contextual and semantic information of every word to provide precise evaluation results. According to this, the text information captured from the Amazon review dataset provides higher outcomes under the utilization of TDO-DCSTM. Further, the performance of TDO-DCSTM is assessed by certain estimation measures and attains the value of 97.79% accuracy, 98.89% specificity, and 95.88% sensitivity under higher training percentage evaluation.},
  archive      = {J_ESWA},
  author       = {Lal Babu Purbey and Kamlesh Lakhwani},
  doi          = {10.1016/j.eswa.2025.129471},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129471},
  shortjournal = {Expert Syst. Appl.},
  title        = {Text-based sentiment analysis using the tetra dominant optimized deep convolutional neural network enabled bidirectional long short-term memory},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised asymmetry-agnostic stereo matching with selective adaptive patch correlation. <em>ESWA</em>, <em>297</em>, 129470. (<a href='https://doi.org/10.1016/j.eswa.2025.129470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo matching is a fundamental task in computer vision with applications in robotics and autonomous driving. While supervised methods have shown impressive performance, they rely heavily on large-scale ground truth disparity data, which is difficult to acquire in real-world scenarios. Unsupervised stereo matching thus emerges as a promising alternative. However, most existing unsupervised methods assume symmetric visual properties between the left and right images, limiting their robustness in practical settings where asymmetry, such as differences in resolution or noise, is common. These asymmetries disrupt pixel correspondences and undermine the photometric consistency that many approaches depend on. To overcome this, the proposed framework introduces a robust stereo matching solution combining a photometric loss function enhanced with gradient constraints and a Selective Adaptive Patch Correlation (SAPC) module. The SAPC module is designed to extract and align features across patches, ensuring effective disparity estimation even in asymmetric scenarios. Extensive experiments demonstrate that our method achieves state-of-the-art performance under both symmetric and asymmetric conditions, outperforming existing approaches by a significant margin.The proposed model achieves superior performance in noise and resolution asymmetry experiments, improving accuracy by 7 % and 22.5 %, respectively, while maintaining robustness across diverse conditions.},
  archive      = {J_ESWA},
  author       = {Jianwei Zhao and Ximeng Li and Wenbing Tao},
  doi          = {10.1016/j.eswa.2025.129470},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129470},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unsupervised asymmetry-agnostic stereo matching with selective adaptive patch correlation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated modeling and scheduling for stochastic flexible job shops considering machine degradation and production dynamics. <em>ESWA</em>, <em>297</em>, 129469. (<a href='https://doi.org/10.1016/j.eswa.2025.129469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing dominates a crucial position in the global economy, driving technological advancement and economic development. In fact, while modern manufacturing has made great strides in efficiency, the production process still faces numerous challenges that create operational uncertainties. In recent years, the Flexible Job Shop Scheduling Problem (FJSP) has emerged as a key approach to addressing these industry issues. However, in practical production processes, random failures caused by machine degradation due to wear and tear should not be underestimated, making the Stochastic Flexible Job Shop Scheduling Problem (SFJSP) more realistic than the FJSP. This study proposes an integrated modeling and scheduling framework for flexible job shops with stochastic machine degradation. The approach combines a serial production line model that captures the dynamics of degrading machines and workpiece order processing across workshops, with an enhanced Artificial Bee Colony algorithm that simultaneously optimizes workshop assignment, makespan and processing costs. By jointly considering machine degradation patterns and production line dynamics, the proposed method demonstrates significant improvements in scheduling performance under complex operational scenarios.},
  archive      = {J_ESWA},
  author       = {Panpan Shangguan and Zhiyang Jia and Lengandong Shi},
  doi          = {10.1016/j.eswa.2025.129469},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129469},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrated modeling and scheduling for stochastic flexible job shops considering machine degradation and production dynamics},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal non-exclusive trade-in rebates design for a profit-maximizing company. <em>ESWA</em>, <em>297</em>, 129468. (<a href='https://doi.org/10.1016/j.eswa.2025.129468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trade-in program is a common marketing strategy adopted by companies to encourage customers to return their used products in exchange for a discount or rebate on the purchase of new items. A trade-in program can significantly boost sales by lowering customers’ purchasing costs while enabling the collection of returned products for recycling or remanufacturing. However, it also introduces additional operational and financial costs. Therefore, the company must carefully balance profit gains with associated costs to ensure that the trade-in program remains economically viable. This paper explores the company’s optimal non-exclusive trade-in program, under which both existing customers and competitors’ customers can trade their on-hand products for new ones. The innovation level of new generation products, the previous pricing strategy of the company and its competitor, the durability of the products, and the relative perceived value of the old generation products by customers are considered in the paper. The results show that the optimal trade-in strategy design depends on the previous pricing strategy, and setting high trade-in rebates is not always optimal to maximize profit. Moreover, whether the company should provide a higher trade-in rebate to its existing customers depends on the customers’ perceived value of the company’s past products compared to competitors’ offerings, along with both parties’ past pricing strategies, and the trade-in program does not always benefit the environment.},
  archive      = {J_ESWA},
  author       = {Zhuojun Liu and Sahand Ashtab and Sunny Agarwal},
  doi          = {10.1016/j.eswa.2025.129468},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129468},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal non-exclusive trade-in rebates design for a profit-maximizing company},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning enhanced imperialist competitive algorithm for flexible job-shop scheduling problem with limited transportation and auxiliary resources. <em>ESWA</em>, <em>297</em>, 129467. (<a href='https://doi.org/10.1016/j.eswa.2025.129467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the complex landscape of multi-dimensional coupling within intelligent manufacturing systems, optimizing decisions for the flexible job shop scheduling problem (FJSP) is influenced not only by the assignment of machine resources but also by the interplay with the transportation system and the availability of auxiliary resources. In this paper, a multi-objective FJSP model considering limited transportation and auxiliary resources is proposed in the context of hydraulic cylinder manufacturing, aiming to minimize the maximum completion time and semi-finished product inventory cost. To address the problem, a reinforcement learning enhanced imperialist competitive algorithm (RLICA) is proposed. The algorithm has the following features: multiple hybrid initialization strategies are introduced to enhance population diversity and quality. Additionally, a dynamic parameter adaptation strategy based on reinforcement learning is designed for the assimilation stage to optimize the exploration–exploitation balance during the colonization assimilation process. Finally, a two-layer neighborhood search operator is implemented to improve the algorithm’s local search capability. The experimental section evaluates the performance of the algorithm based on 33 benchmark instances and real enterprise data. The results demonstrate that RLICA significantly outperforms five other state-of-the-art algorithms regarding convergence, distribution, and robustness. Case study further demonstrates that the algorithm can effectively coordinate transportation, processing, and auxiliary resource systems, offering a robust scheduling optimization solution for complex manufacturing scenarios.},
  archive      = {J_ESWA},
  author       = {Shaofeng Yan and Wei Zhang and Hongtao Tang and Guohui Zhang and Deming Lei},
  doi          = {10.1016/j.eswa.2025.129467},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129467},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reinforcement learning enhanced imperialist competitive algorithm for flexible job-shop scheduling problem with limited transportation and auxiliary resources},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Insight any invisible: An occlusion perception method for robust pedestrian detection in crowded scenes. <em>ESWA</em>, <em>297</em>, 129464. (<a href='https://doi.org/10.1016/j.eswa.2025.129464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a fundamental research task in computer vision with important applications for autonomous driving, etc. Occlusion challenge in the spatial dimension still plague recognition tasks including pedestrian detection. Existing detectors tend to learn discriminative features from the visible parts of the objects, but fail to recognise that the essence of the occlusion challenge is that too few visible parts of occlusion objects are insufficient to support a comprehensive and robust feature, and the model lack ability to perceive occlusion information from invisible occlusion parts of occlusion objects, which limits the detection performance. To solve this issue, we propose an occlusion perception learning paradigm embedded into the crowded object detector to form a novel detection scheme, which provides a new perspective on modeling occlusion problems. First, an Occlusion Perception Decoder (OPD) with the potential to predict occlusion perception maps is proposed based on a transformer structure and forms a multi-task network with the existing detector. Then, based on existing bounding boxes annotations, we generate ground truth for occlusion parts by extracting the overlaps of annotations, and we design an Occlusion Perception Loss (OPL) function for the supervised training optimization of the OPD. Finally, we design a complementary mechanism (OPC) to complement the occlusion perception maps into the detection decoder to further improve the detection performance. Experiments show that our proposed method can significantly improve the performance of pedestrian detection in crowded scenes and outperforms most of the state-of-the-art methods. Moreover, our method is robust to various crowded scenes and significantly improves on slightly crowded scenes likely the CityPersons dataset. Especially for occlusion objects, our method improves their recall rate to 95.4 % , an improvement of 22.6 % . The code will be released.},
  archive      = {J_ESWA},
  author       = {Xuexue Li and Xuan Li},
  doi          = {10.1016/j.eswa.2025.129464},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129464},
  shortjournal = {Expert Syst. Appl.},
  title        = {Insight any invisible: An occlusion perception method for robust pedestrian detection in crowded scenes},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting algorithm for the vocational mobility of graduates with multiple attributes. <em>ESWA</em>, <em>297</em>, 129463. (<a href='https://doi.org/10.1016/j.eswa.2025.129463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of labor markets and the evolving nature of vocational education demand robust tools to forecast graduate career outcomes. This study proposes a machine learning-based forecasting algorithm that predicts the vocational mobility of graduates by integrating multiple attributes, including academic performance, technical and soft skills, socio-economic background, and regional labor market trends. Utilizing a dataset comprising 12,000 graduate profiles across various institutions, the model employs advanced feature engineering, dimensionality reduction, and a supervised XGBoost classifier to generate accurate mobility predictions categorized as Stable, Lateral, or Low. The system is further enhanced with SHAP-based interpretability to ensure transparency and actionable insights. Compared to traditional models such as logistic regression, decision trees, and support vector machines, the proposed model demonstrates superior performance, achieving an F1-score of 0.89 and an AUC-ROC of 0.93. This research not only contributes to the growing field of educational data science but also provides a practical tool for educators, policymakers, and career counselors to support evidence-based decision-making and targeted graduate interventions.},
  archive      = {J_ESWA},
  author       = {Muhammad Shoaib and Muhammad Umer Afridi and Ghassan Husnain},
  doi          = {10.1016/j.eswa.2025.129463},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129463},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting algorithm for the vocational mobility of graduates with multiple attributes},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent decision support systems for improving financial forecasting and market trend analysis. <em>ESWA</em>, <em>297</em>, 129462. (<a href='https://doi.org/10.1016/j.eswa.2025.129462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial markets are highly volatile, which makes accurate forecasting significant for enterprises to improve their investments and minimize risk. Accurate financial forecasting and market trend analysis are critical for effective enterprise decision-making. Traditional forecasting algorithms frequently struggle to include various, real-time external inputs such as public mood and political events, reducing predictive accuracy. To overcome these disadvantages, this research suggests an Intelligent Decision Support System (IDSS) that has the potential to improve financial prediction by incorporating classic market information and external prompts. Financial forecasting data is obtained by integrating multiple data sources, including historical stock market data, public sentiment, and political events. A comprehensive dataset is created by collecting historical stock market data from Yahoo! Finance, public sentiment from Twitter using sentiment analysis techniques, and key political events. Galactic Swarm Optimization (GSO), selected as it possesses greater global search ability and high-dimensional feature space optimization capability, is used for effective feature selection in an effort to select the most important features from the dataset. For financial forecasting and market trend forecasting, this evaluation presents a new Refined Bidirectional Long-Short Term Memory (RBLSTM) model that advances compared to classical BiLSTM by more efficient regularization and bi-directional temporal learning, thereby avoiding overfitting and improving predictive effectiveness. The proposed model achieved the highest outcomes with accuracy (98.42%). These findings suggest that incorporating sentiment and political signals into predictive analytics can enhance decision-making effectiveness for enterprises operating in dynamic financial environments.},
  archive      = {J_ESWA},
  author       = {Xian Zhu},
  doi          = {10.1016/j.eswa.2025.129462},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129462},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent decision support systems for improving financial forecasting and market trend analysis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal control strategy based on differential evolution algorithm for seamless transition between islanded and grid-connected operation modes in microgrid clusters. <em>ESWA</em>, <em>297</em>, 129461. (<a href='https://doi.org/10.1016/j.eswa.2025.129461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing integration of renewable energy sources and distributed energy resources is accelerating the transformation of traditional power systems into smart grids. This transformation relies heavily on the deployment of microgrids (MGs), which offer enhanced flexibility, resilience, and sustainability. However, ensuring the stable and efficient synchronization of MGs, especially during transitions between islanded and grid-connected modes, remains a critical and unresolved challenge. This challenge is further amplified in MG clusters (MGCs), where coordinated operation is essential to maintain power quality and system reliability. Driven by the need to address this challenge, this study proposes a real-time synchronization control method to enhance the dynamic performance and operational reliability of MGCs. The main objective is to design and validate an optimal control strategy capable of minimizing frequency deviations and improving power sharing during the synchronization process. To achieve this, an optimal seamless synchronization control based on a differential evolution (DE) algorithm is developed. This controller optimizes a frequency error control objective function in real time and is tested on an MGC architecture combining grid-forming (GFM) and grid-feeding (GFD) inverters. This work addresses the lack of robust, fast, and quantifiable synchronization methods for hybrid inverter-based MGCs, a gap that this study aims to fill. The proposed method enables accurate optimization of the transition between islanded and grid-connected modes. Simulation results demonstrate substantial performance gains: a 66.33% reduction in the ITSE compared to a synchronization strategy based on the fmincon optimization algorithm, and a 37.91% improvement over a conventional approach that adjusts synchronization by modifying the droop control coefficients. Furthermore, a comparative analysis with the particle swarm optimization (PSO) algorithm demonstrated that the DE-based approach reduces computation time by 20.29%, highlighting its superior efficiency and suitability for real-time embedded implementation. A sensitivity analysis involving 500 different scenarios, including evaluations under fault conditions, confirms the robustness of the approach. The average ITSE for these 500 simulations was 0.2459, with a standard deviation of 0.041, demonstrating consistent and reliable performance under varying load conditions. Moreover, a second sensitivity analysis, conducted over 250 simulations, identified the optimal DE parameters, enabling the selection of an effective combination of population size, mutation factor, and crossover rate . Finally, experimental validation using a Hardware-in-the-Loop setup, with an OPAL-RT4512 unit and a dSPACE MicroLabBox, verifies the effectiveness and real-time performance of the proposed control strategy.},
  archive      = {J_ESWA},
  author       = {Pablo Horrillo-Quintero and Pablo García-Triviño and David Carrasco-González and Luis M. Fernández-Ramírez},
  doi          = {10.1016/j.eswa.2025.129461},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129461},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal control strategy based on differential evolution algorithm for seamless transition between islanded and grid-connected operation modes in microgrid clusters},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A paradigm of evolutionary manytasking optimization for solving nonlinear equation systems: A two-stage framework with adaptive knowledge transfer, sharing and hybrid resource sampling. <em>ESWA</em>, <em>297</em>, 129459. (<a href='https://doi.org/10.1016/j.eswa.2025.129459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear Equation Systems (NESs) are essential to many scientific and industrial applications, yet solving them efficiently remains a persistent challenge due to their inherent complexity, diversity, and multi-solution characteristics. Existing approaches often address each NES independently, missing opportunities to exploit potential synergies among related tasks, known as implicit relationship. To overcome this challenge, we propose EMaTSaNES, a paradigm of evolutionary manytasking algorithm tailored for NESs. This paradigm enables concurrent optimization of dozens of NES tasks in a unified search process, facilitating knowledge transfer among tasks to improve convergence speed and solution quality. To ensure effective and adaptive cross-task collaboration, EMaTSaNES incorporates three key mechanisms. First, to improve knowledge transfer efficiency and adaptability, adaptive knowledge transfer and sharing (AKTS) mechanism is proposed, which not only adjusts knowledge transfer probabilities according to self-evolutionary trends, but also adaptively adjusts mutation strategies to enhance optimization performance. Second, to generate promising offspring and improve task-specific exploration, hybrid resource sampling (HRS) is designed, which adopts a variety of different distributions to sample and generate new individuals, aiming to balance exploration and exploitation. Moreover, considering the heterogeneity and evolving characteristics of NES tasks, self-adaptive parameter adjustment (SaPA) is developed, which continuously fine-tunes algorithmic parameters based on real-time task feedback. Extensive experiments conducted multiple types of complex NESs demonstrate that EMaTSaNES significantly outperforms existing algorithms in terms of robustness, accuracy, and scalability.},
  archive      = {J_ESWA},
  author       = {Juan Zhao and Yujun Zhang and Rui Zhong and Huiling Chen and Junbo Jacob Lian and Zheng-Ming Gao},
  doi          = {10.1016/j.eswa.2025.129459},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129459},
  shortjournal = {Expert Syst. Appl.},
  title        = {A paradigm of evolutionary manytasking optimization for solving nonlinear equation systems: A two-stage framework with adaptive knowledge transfer, sharing and hybrid resource sampling},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning assisted automatic niche selection for constrained multimodal multi-objective optimization. <em>ESWA</em>, <em>297</em>, 129458. (<a href='https://doi.org/10.1016/j.eswa.2025.129458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple equivalent constrained Pareto sets (CPSs) with the same constrained Pareto front (CPF) are presented in constrained multimodal multi-objective optimization problems (CMMOPs), and niches are widely used to search for equivalent CPSs in CMMOPs. However, it is crucial to select suitable niche techniques automatically for solving CMMOPs. To tackle this issue, this paper proposes a reinforcement learning-assisted automatic niche selection method, named RLANS, to automatically select a niche for solving CMMOPs. In the proposed RLANS, a reinforcement learning model is constructed and trained to obtain appropriate niche strategies in the evolutionary procedure. To begin with, diverse niche techniques are considered as the actions of the reinforcement learning model. Next, local convergence quality, feasibility, and diversity are designed and regarded as the states of the model. Then, a reward function with dynamic weight parameters is designed to evaluate and select suitable niches. Finally, RLANS trains the model using a backpropagation network and outputs the niche technique with the highest probability for selecting a suitable niche. In this way, a niche is automatically selected from the set of diverse niche technologies for locating different CPSs. The proposed RLANS and seven state-of-the-art algorithms are implemented in two standard CMMOP test suites. Experimental results validated that the proposed RLANS is able to automatically select niche techniques and exploit the advantages of different niche techniques.},
  archive      = {J_ESWA},
  author       = {Guoqing Li and Yu Xin and Jun Niu and Zheng Wang and Jiacheng Chen and Fei Wu},
  doi          = {10.1016/j.eswa.2025.129458},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129458},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reinforcement learning assisted automatic niche selection for constrained multimodal multi-objective optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Collaborative scheduling for heterogeneous robots with simultaneous pickup and delivery tasks in order-picking systems. <em>ESWA</em>, <em>297</em>, 129457. (<a href='https://doi.org/10.1016/j.eswa.2025.129457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the e-commerce has intensified demand on the intelligent warehouse efficiency, where the heterogeneous robots collaboration presents both opportunities and challenges. This study addresses the collaborative scheduling for heterogeneous robots with simultaneous pickup and delivery (CSHR-SPD) problem in autonomous mobile robots (AMRs) and autonomous case-handling robots (ACRs) systems. The CSHR-SPD problem involves three-stage sequential operations (ACR-AMR-ACR) with cross-stage resource competition and spatiotemporal constraints. To solve this NP-hard problem, a mathematical model is formulated to minimize makespan, and an improved variable neighborhood search (IVNS) algorithm is proposed. The algorithm incorporates several key innovations. A terminal stage driven initialization method is proposed to alleviate the delayed startup of AMR. Inspired by the taxi reservation mechanism, an idle robot reservation decoding method is introduced to reduce the waiting time of robots. A bottleneck-aware hybrid neighborhood set is proposed: a tail task reassignment operator optimizes the tail tasks that directly restrict the makespan, while a maximum gap operator focuses on eliminating major unproductive time intervals. Numerical experiments demonstrate that the proposed IVNS algorithm solves the CSHR-SPD problem effectively and efficiently.},
  archive      = {J_ESWA},
  author       = {Xingyu Zhang and Xiuli Wu},
  doi          = {10.1016/j.eswa.2025.129457},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129457},
  shortjournal = {Expert Syst. Appl.},
  title        = {Collaborative scheduling for heterogeneous robots with simultaneous pickup and delivery tasks in order-picking systems},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware metric learning for few-shot detection of counterfeit cigarettes from packaging images. <em>ESWA</em>, <em>297</em>, 129456. (<a href='https://doi.org/10.1016/j.eswa.2025.129456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfeit cigarette detection is essential for protecting public health and preventing tax losses. Traditional inspection methods are labor-intensive and subjective, while existing deep learning approaches struggle under real-world constraints such as limited counterfeit samples, degraded image quality, and continuously evolving forgery patterns. To address these challenges, we propose a robust and interpretable Region-Aware Metric Learning (RAML) framework for few-shot detection from cigarette packaging images. RAML first employs a saliency-guided Region Proposal Generation Module (RPGM) to automatically localize visually discriminative anti-counterfeiting region proposals such as text, logos, and textures. A lightweight filtering mechanism selects the most informative proposals, which are then processed by a Siamese metric learning network trained with a hybrid of contrastive and classification losses to enhance intra-class compactness and inter-class separability under data scarcity. To further improve robustness against unseen counterfeit variants, a prototype-based non-parametric classifier is used for similarity-based inference in the learned feature space. We evaluate the framework on two real-world datasets comprising over 2000 images captured using high-resolution scanners and smartphone cameras, covering ten cigarette brands with both genuine and counterfeit samples under varied lighting, angles, and resolutions. Experiments show that RAML achieves 100 % accuracy on scanner images and 98.84 % accuracy on camera images, consistently outperforming existing deepfake detection, metric learning, and few-shot approaches. Explainability analyses and a user study with domain experts further confirm its interpretability and practical applicability. These results highlight RAML’s potential for deployment in tobacco regulation and broader anti-counterfeiting domains, and demonstrate the effectiveness of integrating region-aware feature learning with prototype-based inference in real-world few-shot scenarios. Code is available at https://github.com/liyiersan/cig_rec .},
  archive      = {J_ESWA},
  author       = {Qian Zhou and Huanrou Ding and Chengzhe Li and Hua Zou and Chao Zhang and Ting Zhang},
  doi          = {10.1016/j.eswa.2025.129456},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129456},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware metric learning for few-shot detection of counterfeit cigarettes from packaging images},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modeling and PID tuning of a 3-DOF robotic manipulator using a novel chaos-artemisinin optimizer. <em>ESWA</em>, <em>297</em>, 129455. (<a href='https://doi.org/10.1016/j.eswa.2025.129455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes an integrated approach to model and control a three-degree-of-freedom (3-DOF) robotic arm, using a sophisticated optimization strategy. The motion of the system is obtained from the Lagrangian formulation, which takes into account the effects of inertia, Coriolis and gravitation in order to produce exact equations of motion. In order to improve trajectory tracking performance, a proportional-integral-derivative (PID) control strategy is applied to each joint, with optimal gain values defined through metaheuristic optimization. A new algorithm, called Chaos-Artemisinin Optimizer (CAO), is proposed by augmenting the original Artemisinin Optimizer (AO) with ten different chaotic maps (CAO1–CAO10) to improve exploration and avoid premature convergence. The performance of the CAO is compared with several standard test functions, and a trajectory tracking application. Comparative results show that CAO2, based on the circular map, consistently outperforms AO and other leading algorithms such as PSO, SMA, GWO, TLBO and CS, with lower tracking errors, faster convergence and better robustness. This study highlights the importance of chaos-enhanced optimization algorithms in robotic control systems, while paving the way for future research into their application in real-time, uncertainty management and extended remote manipulator control.},
  archive      = {J_ESWA},
  author       = {Hamza Tahiri and Mohamed Kmich and Ahmed Bencherqui and Mhamed Sayyouri and Doaa Sami Khafaga and Eman Abdullah Aldakheel},
  doi          = {10.1016/j.eswa.2025.129455},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129455},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling and PID tuning of a 3-DOF robotic manipulator using a novel chaos-artemisinin optimizer},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable decision making on clinical EEG: Trusted multi-view learning with subjective logic for uncertainty quantification. <em>ESWA</em>, <em>297</em>, 129453. (<a href='https://doi.org/10.1016/j.eswa.2025.129453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making on clinical Electroencephalogram (EEG) holds significant promise but faces critical reliability challenges due to signal complexity, noise, and inter-subject variability, which can lead to overconfident or untrustworthy predictions in safety-critical scenarios. This study presents TRUEE (Trusted Reliable Uncertainty Estimation framework for EEG), integrating multi-view learning and subjective logic to deliver clinically trustworthy uncertainty quantification. TRUEE advances reliability through three core innovations: 1) Multi-View Representation, decomposing EEG into temporally, spectrally, and time-frequency aligned views to capture complementary neurophysiological patterns; 2) View-specific Opinion Generation, employing evidential deep learning to transform each view’s features into subjective opinions (belief masses and uncertainty); and 3) Reliable Opinion Aggregation, dynamically aggregating multi-view opinions via weighted belief fusion and reliability-aware trust discounting operation. Extensive experiments on four EEG datasets (diagnosis of Autism Spectrum Disorders (ASD), mental arithmetic, seizure detection, and motor imagery) demonstrate TRUEE’s superiority over conventional uncertainty methods and multi-view baselines, achieving 86.5 % classification accuracy with 0.175 expected calibration error on ASD detection. The framework shows particular strength in robustness, it maintains 74.1 %/67.1 % accuracy under cross-age generalization tasks and successfully gains highest improvement (6 % ∼ 7 %) after rejecting unreliable predictions with lowest rejection rate (11.1 % ∼ 23.1 %). By bridging evidential learning with multi-view neurodynamic analysis, TRUEE provides clinicians with uncertainty-aware predictions that align with real-world diagnostic challenges, offering a critical step toward deployable, safety-conscious EEG decision-making tools.},
  archive      = {J_ESWA},
  author       = {Yiping Zuo and Yaodong Wang and Dan Chen and Tengfei Gao and Jingying Chen},
  doi          = {10.1016/j.eswa.2025.129453},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129453},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reliable decision making on clinical EEG: Trusted multi-view learning with subjective logic for uncertainty quantification},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view sonar image generation via GAN trained with limited data for underwater object classification and detection. <em>ESWA</em>, <em>297</em>, 129452. (<a href='https://doi.org/10.1016/j.eswa.2025.129452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have emerged as a promising approach to address the data scarcity issue in intelligent underwater object recognition. However, existing advanced GANs still suffer from the challenge of discriminator overfitting when constrained by limited sonar data. To address this challenge, this work proposes a Dual Augmentation method for GANs (DA-GAN) to stabilize training under limited data, thereby synthesizing high-fidelity and multi-view sonar images. DA-GAN incorporates two core modules: Adaptive Adversarial Example Augmentation (AAEA) and Random Differentiable Augmentation (RDA). The AAEA module generates adversarial examples by applying imperceptible perturbations to generated sonar images using Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), and Projected Gradient Descent attack (PGD), effectively deceiving the discriminator. Adversarial examples strategically replace real samples according to the degree of discriminator overfitting. Concurrently, the RDA module applies random differentiable augmentations to both real and fake sonar samples, further mitigating the overfitting. Furthermore, leveraging the local smoothness of the latent space, we design three methods—nonlinear perturbation, sparse sign perturbation, and style-mixing to perturb the latent codes, generating multi-view sonar images. Experiment results demonstrate that DA-GAN effectively mitigates discriminator overfitting, generating sonar images with superior quality compared to StyleGAN2 on the SCTD dataset, with the FID improvement from 175.341 to 87.187. On the KLSG dataset, DA-GAN achieves an FID score of 58.067. Furthermore, after augmenting the SCTD dataset, the classification model (e.g., ResNet-34) achieves a 12.50 % improvement in global accuracy, while the detection model (e.g., YOLOv5s) shows a 6.9 % increase in mAP0.5:0.95.},
  archive      = {J_ESWA},
  author       = {Ye Peng and Houpu Li and Wenwen Zhang and Junhui Zhu and Lei Liu and Guojun Zhai},
  doi          = {10.1016/j.eswa.2025.129452},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129452},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-view sonar image generation via GAN trained with limited data for underwater object classification and detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cross modal fine-grained retrieval method based on LAGC and contrastive learning. <em>ESWA</em>, <em>297</em>, 129451. (<a href='https://doi.org/10.1016/j.eswa.2025.129451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of cross-modal retrieval is for users to input any sample as a query and for the system to retrieve and provide various modal samples relevant to the query sample. While recent research has begun exploring fine-grained cross-modal retrieval, most existing methods are still constrained to limited modality pairs (e.g., image-text) and fail to fully address the challenges arising from multi-modal fine-grained retrieval. Fine-grained retrieval faces many difficulties, such as inherent heterogeneity and semantic gaps between multi-modal data, limited fine-grained datasets, challenges in measuring fine-grained data similarity, and minimal differences between sample features. These challenges are amplified in scenarios involving four or more modalities. Although local–global attention mechanisms have been widely adopted in previous studies, most existing methods either focus only on a limited set of modality pairs (e.g., image–text) or fail to fully exploit the complementarity between local and global cues in scenarios involving four or more modalities. In addition, the use of heterogeneous encoder architectures further constrains the efficiency of feature fusion. To address these limitations, this paper first employs a unified encoder architecture for different modalities and proposes the Local and Global Cross (LAGC) attention module to achieve more efficient feature extraction for fine-grained samples. This module utilizes local and global cross-attention to fully exploit the local and global features of fine-grained samples, extract fine-grained semantic information in their high-dimensional vector space, and greatly enhance the expression ability of modality-specific features in the process of single-modal feature extraction. Meanwhile, to fully integrate different modal features and achieve more effective feature interaction, the Multi Modal Cross (MMC) module is specifically designed. This module links the unique information of each modality with the commonality between different modal data, thereby enhancing the model’s expression ability in the common space. Finally, adopting the idea of contrastive learning, during the training process, the fused features are aligned semantically, greatly enhancing the cross-modal retrieval capability of fine-grained samples. Finally, through extensive experiments and ablation studies, the proposed method has been demonstrated to achieve competitive results on the public datasets PKU FG-XMedia, NUS-Wide, and MIRFlickr-25k.},
  archive      = {J_ESWA},
  author       = {Zhixiang Wang and Junzhuo Liu and Ye Zhang and Qiaosong Chen and Linxue Qian},
  doi          = {10.1016/j.eswa.2025.129451},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129451},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cross modal fine-grained retrieval method based on LAGC and contrastive learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global profits, local decisions: Why global cooperation falters in multi-level games. <em>ESWA</em>, <em>297</em>, 129450. (<a href='https://doi.org/10.1016/j.eswa.2025.129450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global cooperation often falters despite shared objectives, as misaligned interests and unequal incentives undermine collective efforts, such as those in international climate change collaborations. To tackle this issue, this paper introduces a multi-level game-theoretic model to analyze the dynamics of complex interactions within hierarchical systems. The model consists of global, local, and pairwise games, and two strategy types-binary and level-based strategies-are explored under varying parameter conditions. Using computational simulations and numerical analysis, we examine how factors across different levels influence player decisions, game dynamics and population phase transitions during the evolutionary process. Our findings reveal that although the increase of profit rates at local and pairwise games enhances cooperation within the population, the global game exerts minimal influence on player decisions and population states under both strategy settings. Particularly, analytical and simulation results show that, under binary strategies, global profit does not influence localized decision-making of players, while under level-based strategies, players cooperating at the global level are eventually outcompeted due to the evolutionary disadvantage even when global profit is substantial. These insights contribute to a theoretical understanding of cooperation dynamics in multi-level systems and may offer implications for fostering global collaboration on challenges like climate change.},
  archive      = {J_ESWA},
  author       = {Jinhua Zhao and Xinguo Yu and Rui Ding and Cuiling Gu and Xianjia Wang},
  doi          = {10.1016/j.eswa.2025.129450},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129450},
  shortjournal = {Expert Syst. Appl.},
  title        = {Global profits, local decisions: Why global cooperation falters in multi-level games},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spindle thermal error modeling with linear and nonlinear hybrid tandem metamodel based on statistical and machine learning approaches. <em>ESWA</em>, <em>297</em>, 129449. (<a href='https://doi.org/10.1016/j.eswa.2025.129449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal error resulting from thermal deformation is a key factor that significantly affects the accuracy of machine tools. This study aims to develop and evaluate a residual-based hybrid tandem metamodel for thermal error compensation that leverages the complementary strengths of linear and nonlinear modeling techniques. The linear models employed in this study include stepwise regression and time series analysis using the autoregressive integrated moving average (ARIMA) method, while the nonlinear models considered comprise support vector regression (SVR), neural network autoregression (NNAR), and eXtreme Gradient Boosting (XGBoost). Specifically, three combinations were investigated: ARIMA + SVR, Stepwise + NNAR, and ARIMA + XGBoost, with the latter integrating ARIMA to capture linear thermal trends and XGBoost to model nonlinear residual patterns. Datasets collected from actual working machines under different spindle speeds and environmental conditions were used for model training and independent testing. Experimental results demonstrate that the ARIMA + XGBoost tandem metamodel exhibits superior generalization and error control, particularly under heterogeneous axis-specific error patterns, achieving the best performance in 10 out of 12 subdatasets. It achieved average MaxAE, MAE, and MSE values of 0.7522 μm, 0.2897 μm, and 0.2997 μm 2 , respectively, with corresponding standard deviations (SD) of 0.7013, 0.3841, and 0.5720. Even in the worst case, the MaxAE was controlled to within 1.622 μm (X-axis), 0.8612 μm (Y-axis), and 2.2712 μm (Z-axis). The mean reductions in MaxAE across the three axes were 88.85 %, 97.53 %, and 73.28 %, respectively, yielding an overall mean reduction of 86.56 % (SD = 0.2141). These findings confirm that the proposed ARIMA + XGBoost hybrid metamodel provides robust and effective thermal error compensation, offering a practical pathway for deployment in high-precision manufacturing environments.},
  archive      = {J_ESWA},
  author       = {Meng-Hua Li and Mingchang Chih and Chia-Fu Kou and Ching-Yuan Chang and Li-Lun Yeh and Yun-Ting Lin},
  doi          = {10.1016/j.eswa.2025.129449},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129449},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spindle thermal error modeling with linear and nonlinear hybrid tandem metamodel based on statistical and machine learning approaches},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CPT-SFM: Conical-planar target-based stepwise feature matching calibration for heterogeneous multi-LiDAR systems. <em>ESWA</em>, <em>297</em>, 129447. (<a href='https://doi.org/10.1016/j.eswa.2025.129447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary challenge in LiDAR-based autonomous navigation for robotic platforms is the precise calibration of multiple LiDAR sensors to minimize blind areas. This study proposes a novel calibration target, the conical-planar target (CPT), and a calibration method called stepwise feature matching (SFM). This approach is designed to integrate heterogeneous multi-LiDAR sensors into a unified coordinate system. The CPT, combining conical and planar structures, provides stable geometric features irrespective of the LiDAR sensor position and orientation, allowing precise calibration using only a single stationary target without repositioning. The SFM method reduces scan noise through planarization and robustly extracts feature points by registering with a target model. By integrating the feature-point-based initial alignment with scan matching, the proposed approach achieves precise calibration between heterogeneous LiDAR sensors differing in resolution, fields of view, and scanning mechanisms. This study demonstrates the necessity of precise calibration techniques through a quantitative analysis of how decreased calibration accuracy affects the geometric integrity of spatial data. Furthermore, the proposed method achieves high-precision calibration across various sensor combinations, even with minimal sensor overlap and a single calibration target, while consistently extracting feature points across various CPT positions and orientations. Finally, simultaneous localization and mapping experiments using the calibrated multi-LiDAR data validate the practical applicability of the proposed method in autonomous robotic systems.},
  archive      = {J_ESWA},
  author       = {Minseok Kim and Hyeongnam Cho and Yu-Cheol Lee},
  doi          = {10.1016/j.eswa.2025.129447},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129447},
  shortjournal = {Expert Syst. Appl.},
  title        = {CPT-SFM: Conical-planar target-based stepwise feature matching calibration for heterogeneous multi-LiDAR systems},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CADroid: A cross-combination attention based framework for android malware detection. <em>ESWA</em>, <em>297</em>, 129446. (<a href='https://doi.org/10.1016/j.eswa.2025.129446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious software (malware) targeting mobile devices, particularly on the Android platform, is rapidly increasing, posing significant security threats to users worldwide. Although numerous deep learning-based methods have been proposed to address this issue, many of them depend on complex architectures and intricate attention mechanisms to achieve satisfactory detection performance. Therefore, these methods frequently encounter a balance challenge between efficiency and computational complexity. In this work, we propose CADroid, a lightweight yet powerful Android malware detection framework based on a novel Cross-combination Attention (CA) mechanism. In CADroid, the CA mechanism functions on a set of combination features derived from static app analysis (e.g., permissions, APIs, content providers, and hardware features). By examining the application (app) from multiple perspectives, these cost-effective static features capture its essential characteristics and typical behaviors. The CA mechanism dynamically allocates attention scores to these combined features, facilitating adaptive recalibration to highlight the most critical aspects for malware detection. Specifically, the CA mechanism is inherently flexible and can be effortlessly integrated into deep networks. To mitigate the potential issue of gradient vanishing, which may weaken the effectiveness of CA, we introduce three specialized modules: Residual CA Module (ResCAM), Single CA Module (SinCAM), and Multi-head CA Module (MulCAM). We conduct a comprehensive evaluation of CADroid using two real-world datasets containing diverse static features, as well as a public benchmark dataset. Experimental results demonstrate consistent performance improvements, affirming CADroid’s effectiveness in Android malware detection.},
  archive      = {J_ESWA},
  author       = {Kai Ma and Binqin Lu and Shangnan Yin and Chenhao Zheng and Huijuan Zhu},
  doi          = {10.1016/j.eswa.2025.129446},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129446},
  shortjournal = {Expert Syst. Appl.},
  title        = {CADroid: A cross-combination attention based framework for android malware detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning motion blur robust vision transformers for real-time UAV tracking. <em>ESWA</em>, <em>297</em>, 129445. (<a href='https://doi.org/10.1016/j.eswa.2025.129445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) tracking is critical for applications like surveillance, search-and-rescue, and autonomous navigation. However, the high-speed movement of UAVs and targets introduces unique challenges, including real-time processing demands and severe motion blur, which degrade the performance of existing generic trackers. While single-stream vision transformer (ViT) architectures have shown promise in visual tracking, their computational inefficiency and lack of UAV-specific optimizations limit their practicality in this domain. In this paper, we boost the efficiency of this framework by tailoring it into an adaptive computation framework that dynamically exits Transformer blocks for real-time UAV tracking. The motivation behind this is that tracking tasks with fewer challenges can be adequately addressed using low-level feature representations. Simpler tasks can often be handled with less demanding, lower-level features. This approach allows the model use computational resources more efficiently by focusing on complex tasks and conserving resources for easier ones. Another significant enhancement introduced in this paper is the improved effectiveness of ViTs in handling motion blur, a common issue in UAV tracking caused by the fast movements of either the UAV, the tracked objects, or both. This is achieved by acquiring motion blur robust representations through enforcing invariance in the feature representation of the target with respect to simulated motion blur. We refer to our proposed approach as BDTrack. Extensive experiments conducted on four tracking benchmarks validate the effectiveness and versatility of our approach, demonstrating its potential as a practical and effective approach for real-time UAV tracking. Code is released at: https://github.com/wuyou3474/BDTrack .},
  archive      = {J_ESWA},
  author       = {You Wu and Xucheng Wang and Dan Zeng and Hengzhou Ye and Xiaolan Xie and Qijun Zhao and Shuiwang Li},
  doi          = {10.1016/j.eswa.2025.129445},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129445},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning motion blur robust vision transformers for real-time UAV tracking},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDFusion: A multistage dynamic fusion framework for multimodal 3D object detection with leveraging cross-modal feature complementarity. <em>ESWA</em>, <em>297</em>, 129444. (<a href='https://doi.org/10.1016/j.eswa.2025.129444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection plays a vital role in environmental understanding across various fields, including autonomous driving, localization and mapping, and embodied intelligence. However, while cameras deliver rich textural context and LiDAR provides high-precision 3D structural insights, performance limitations often emerge when depending solely on a single sensing technology. In this paper, we propose a robust multimodal framework for multistage 3D object detection that fuses LiDAR and camera data without explicit view transformation. Our method builds an end-to-end detection pipeline that deeply integrates the accurate geometric representation provided by LiDAR with the rich texture information captured by RGB images, enabling synergy between geometric sensing and semantic understanding. Specifically, we propose a spatial coordinate encoding module (SCE) and an image depth guidance module (IDG) to enable deep interaction between two different modalities. Furthermore, a Transformer decoder is employed to model cross-modal and temporal dependencies. In the decision fusion stage, perform joint geometric and semantic optimization of the 3D proposals and 2D proposal results from the regional proposal networks, and finally an adaptive fusion module is designed to dynamically aggregate the results from feature fusion and decision fusion. Validation of our framework evaluated on the nuScenes test set shows that MDFusion achieves 73.9 % mAP and 75.2 % NDS.},
  archive      = {J_ESWA},
  author       = {Siyu Wang and Xiujuan Zheng and Yong Zhang and Rukai Lan and Ying Zheng},
  doi          = {10.1016/j.eswa.2025.129444},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129444},
  shortjournal = {Expert Syst. Appl.},
  title        = {MDFusion: A multistage dynamic fusion framework for multimodal 3D object detection with leveraging cross-modal feature complementarity},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unlocking compositional potential: Leveraging specific feedback for text-to-image generation in diffusion models. <em>ESWA</em>, <em>297</em>, 129443. (<a href='https://doi.org/10.1016/j.eswa.2025.129443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from feedback has been shown to enhance the alignment between text prompts and images in text-to-image diffusion models. However, due to the lack of focus in feedback content, especially for the compositional generation, current models struggle to accurately match text and image. To address this issue, we propose a fine-tuning method with specific feedback objectives, focusing on the fine-grained alignment between text and image, including three stages. First, generated images from the diffusion model are detected to obtain the object categories and quantities. Meanwhile, the confidence of category and quantity can be derived from the detection results and given prompts. Next, we define a novel matching score, based on the above confidence, to measure text-image alignment. It can guide the model for feedback learning in the form of a reward function. Finally, we fine-tune the diffusion model by backpropagating the reward function gradients to generate semantically related images. Different from previous feedback methods that primarily focus on overall matching, our approach emphasizes on the accuracy of object category and quantity to improve compositional generation of diffusion models. To support this research, we construct a novel text-to-image dataset, comprising 11,337 annotated text-image pairs with two key characteristics: 1) Compositional Diversity: Covers varying object categories and quantities. 2) Scenario Completeness: Includes common, unconventional, and unrealistic scenes, thereby addressing the limitations of existing datasets. Experimental results on this benchmark show that our model outperforms other SOTA methods in both alignment and fidelity. In addition, the proposed matching score can also serve as a metric for evaluating text-image alignment in other models. All codes and dataset are available at https://github.com-kingniu0329/Visions .},
  archive      = {J_ESWA},
  author       = {Xuexiang Niu and Jinping Tang and Ge Zhu and Lei Wang},
  doi          = {10.1016/j.eswa.2025.129443},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129443},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unlocking compositional potential: Leveraging specific feedback for text-to-image generation in diffusion models},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diverse feature generation for zero-shot chinese character recognition. <em>ESWA</em>, <em>297</em>, 129442. (<a href='https://doi.org/10.1016/j.eswa.2025.129442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot Chinese Character Recognition (ZSCCR) aims to identify unseen Chinese characters not included in the training set. Traditional ZSCCR approaches often rely on predicting radicals to bridge the gap between seen and unseen classes. However, in zero-shot learning (ZSL), these models are restricted to learning semantics from seen class data, resulting in a severe bias problem. Recently, synthesizing unseen class features using semantic information in ZSL to alleviate data imbalance has become a trend. However, few studies have explored applying this strategy to ZSCCR, and maintaining diversity in the generated features remains a significant challenge. To address these challenges, this work proposes a Diverse Feature Generation (DFG) framework for ZSCCR. Specifically, DFG synthesizes features using Ideographic Description Sequences (IDS) for unseen characters, solving the lack of training data for unseen classes and mitigating recognition bias in ZSCCR. DFG introduces a Hybrid Semantic Embedding (HSE) strategy to enrich input semantics and employ multiple generative sub-networks to produce diverse features with varying semantics. Additionally, to further enhance feature diversity, a Diversity-Increase Loss (DI-loss) is proposed, which encourages sub-networks to recognize features with distinct semantics and increases the entropy of generated features within the same class. A Prediction-Level Feature Collaboration Loss (PLFC-loss) is also introduced to encourage collaboration among sub-networks during training, helping to mitigate domain shift and further enhance performance. Experimental results demonstrate that the proposed method performs well in generalized ZSCCR settings across benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Song-Liang Pan and Kunchi Li and Da-Han Wang and Xu-Yao Zhang and Jiantao Liu and Shunzhi Zhu},
  doi          = {10.1016/j.eswa.2025.129442},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129442},
  shortjournal = {Expert Syst. Appl.},
  title        = {Diverse feature generation for zero-shot chinese character recognition},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SETDN: Signal-extraction and target-detection network for dynamic fluorescence molecular tomography. <em>ESWA</em>, <em>297</em>, 129441. (<a href='https://doi.org/10.1016/j.eswa.2025.129441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a non-invasive and highly sensitive biomedical imaging technique, Dynamic fluorescence molecular tomography (DFMT) has substantial application value in the fields of disease research and drug evaluation. However, background fluorescence interference seriously affects the target detection accuracy of DFMT. In this study, we propose a novel signal-extraction and target-detection network (SETDN), which integrates the time domain fluorescence signal extraction network (T-FSEN) and the frequency domain target-detection network (F-TDN), to achieve high precision signal extraction and target detection. T-FSEN incorporates both spatial and temporal characteristics to capture dynamic time series features and extract target fluorescence signals in dynamic situations. F-TDN can effectively identify and enhance the key frequency components in the signals and learn the nonlinear relationship between the surface optical density and the position and shape of the internal fluorescent target. Based on this, we innovatively propose an equal time interval sampling strategy based on peak features to optimize the selection of time frames. Numerical simulations and in vivo experimental results show that SETDN achieves superior performance in terms of spatial location, dual-light-source resolution, stability, generalizability, as well as in vivo practicability. This study provides a new solution for the precise imaging of DFMT technology and has important theoretical significance and application value.},
  archive      = {J_ESWA},
  author       = {Yizhe Zhao and De Wei and Heng Zhang and Shuangchen Li and Lizhi Zhang and Jintao Li and Hongbo Guo and Xiaowei He},
  doi          = {10.1016/j.eswa.2025.129441},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129441},
  shortjournal = {Expert Syst. Appl.},
  title        = {SETDN: Signal-extraction and target-detection network for dynamic fluorescence molecular tomography},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CIoEBT: Cancelable internet of ear biometric things based – A novel deep metric learning approach. <em>ESWA</em>, <em>297</em>, 129439. (<a href='https://doi.org/10.1016/j.eswa.2025.129439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric authentication is gaining widespread acceptance globally, driving the need for robust and secure systems. This study explores the use of outer ear images as a distinctive biometric modality. The human ear, much like the face, exhibits unique and permanent features, making it a promising candidate for biometric identification. However, ear biometrics, like facial recognition, face challenges such as variations in illumination, contrast, rotation, scale, and pose. To address these issues, this paper investigates the application of Convolutional Neural Networks (CNNs), a powerful tool in computer vision, for ear recognition. Specifically, we propose a hybrid approach that combines deep CNNs with metric learning. Using CaffeNet as a feature extractor and a novel Deep Effective Pairwise Constraints Metric Learning (DEP-ML) strategy, we encode ear images into secure representations called EarCodes. These codes are further protected using the Comb-filter algorithm, resulting in highly secure and reliable biometric templates. The proposed CaffeNet-DEP-ML framework is evaluated against well-known benchmarks like VGG-verydeep16 and VGG-S on two prominent ear image datasets, AWE and USTB II. Experimental results demonstrate that our method not only outperforms current state-of-the-art techniques but also benefits from fewer trainable parameters and faster processing times. This innovative approach shows strong potential for integration into Internet of Biometric Things (IoBT) environments, offering high accuracy while ensuring privacy preservation.},
  archive      = {J_ESWA},
  author       = {Ibrahim Omara and Randa F. Soliman},
  doi          = {10.1016/j.eswa.2025.129439},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129439},
  shortjournal = {Expert Syst. Appl.},
  title        = {CIoEBT: Cancelable internet of ear biometric things based – A novel deep metric learning approach},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decentralized federated learning based on bivariate controlled averaging and sharpness aware minimization. <em>ESWA</em>, <em>297</em>, 129438. (<a href='https://doi.org/10.1016/j.eswa.2025.129438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To avoid the single-point-of-failure problem of the central server of centralized federated learning (CFL) and mitigate the communication burden, decentralized federated learning (DFL) implements model training by establishing peer-to-peer communication directly among clients. However, the lack of coordination and consistency of the central server causes DFL to encounter more serious data heterogeneity challenges. In addition, different communication topologies also affect the performance of DFL aggregated models. In order to overcome the data heterogeneity challenge faced in DFL, we consider extending the client drift in CFL to DFL, and target to propose a decentralized federated learning algorithm based on bivariate controlled averaging to improve the adaptability and generalization of the model to heterogeneous data by solving the distributed client drift problem caused by data heterogeneity. Furthermore, we propose a variant based on sharpness aware minimization, which further improves the model performance and accelerates the model convergence by optimizing the gradient during the local model update. Experimental results show that our approach achieves better model performance and faster model convergence under various experimental settings on multiple datasets, as well as exhibits strong adaptability to different topologies.},
  archive      = {J_ESWA},
  author       = {Jihao Yang and Wen Jiang and Laisen Nie},
  doi          = {10.1016/j.eswa.2025.129438},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129438},
  shortjournal = {Expert Syst. Appl.},
  title        = {Decentralized federated learning based on bivariate controlled averaging and sharpness aware minimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decoupled framework for low-light image enhancement. <em>ESWA</em>, <em>297</em>, 129436. (<a href='https://doi.org/10.1016/j.eswa.2025.129436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light image enhancement (LLIE) is challenging as it needs to improve visibility, suppress noise and correct color simultaneously. Recent advances often deal with all the degradation factors as a whole, neglecting their individual characteristics and the potential mutual impacts between the factors. It can easily result in sub-optimal performance. In this paper, a fast traditional Retinex decomposition model is proposed to decouple the enhancement into a sequential process manner: brightening, denoising, and colorization. An image is decomposed into illumination color, illumination layer, and reflectance layer. Then, an illumination adjustment method based on Naka-Rushton (NR) equation is proposed to change brightness, showing superiority in handling images with uneven illumination. Second, an attention guided denoising network is proposed to remove noise introduced by reflectance layer. A gate mechanism is first introduced to suppress noise. We find that the original and improved illumination could give a noise intensity measure, which can provide the prior for global and local feature fusion, and can facilitate denoising adaptively. Lastly, image chrominance is modified with the illumination color. Extensive experiments on the commonly used LLIE datasets show that the proposed method achieves state-of-the-art (SOTA) performance.},
  archive      = {J_ESWA},
  author       = {Shuangli Du and Yichun Wen and Minghua Zhao and Jie Li and Zhenghao Shi and Yiguang Liu},
  doi          = {10.1016/j.eswa.2025.129436},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129436},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decoupled framework for low-light image enhancement},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Remote sensing vehicle detection with spatial perception enhancement and branch collaboration. <em>ESWA</em>, <em>297</em>, 129435. (<a href='https://doi.org/10.1016/j.eswa.2025.129435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial intelligence, deep learning-based vehicle detection is playing an increasingly important role in improving traffic safety and optimizing traffic management. To facilitate the application of artificial intelligence techniques in remote sensing vehicle detection, a novel detection network is proposed to tackle the challenges of remote sensing vehicle detection. Vehicles in remote sensing images have limit pixel coverage area and lack significant texture and geometric features, and critical information is easily overlooked during feature transmission. Specific traffic scenarios and peak hours lead to a high concentration of vehicles, which further increases the difficulty of vehicle detection. To address these issues, an novel remote sensing vehicle detection network with spatial perception enhancement and branch collaboration is proposed. Our designed spatial perception enhancement module employs a flexible two-branch structure, where different branches perceive the spatial features of small object vehicles in dense and sparse scenes, respectively, and enhance the features by combining spatial attention. The designed branch collaboration module fine-tunes the flow of feature information, achieving information complementarity among branches, and effectively ensures the diversity and completeness of semantic and spatial information of vehicles. Extensive experiments are conducted. Ablation experimental results show that both spatial perception enhancement module and branch cooperation module can effectively improve the detection performance and validate their effectiveness. Comparative experimental results show that our proposed detection network achieves Average Precision of 96.61 % and 72.13 % respectively on UCAS-AOD and DIOR, which is the best result among all the compared methods and validates its superiority.},
  archive      = {J_ESWA},
  author       = {Cheng Zha and Fan Feng and Junfeng Song and Guoxiang Wang and Zhen Ye and Shuisheng Yang},
  doi          = {10.1016/j.eswa.2025.129435},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129435},
  shortjournal = {Expert Syst. Appl.},
  title        = {Remote sensing vehicle detection with spatial perception enhancement and branch collaboration},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-branch image deblurring method based on frequency-domain awareness. <em>ESWA</em>, <em>297</em>, 129434. (<a href='https://doi.org/10.1016/j.eswa.2025.129434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advances have been made in recent research on deep learning-based single-image motion deblurring algorithms, with an increasing focus on the role of information from the frequency domain for image restoration. However, deblurring remains challenging in scenarios that require detailed recovery, noise suppression, and the handling of multiple types of blur. Most currently available methods to this end focus on processing features from either the spatial or the frequency domain, which makes it difficult to effectively balance these tasks. Furthermore, these approaches often indiscriminately combine all frequency-related information, such that this leads to interactions between frequencies that generate artifacts. To address these shortcomings, we propose a dual-branch method of image deblurring in this study that is based on awareness of the frequency domain. The dual-branch fusion mechanism efficiently combines information from both the spatial and frequency domains. Moreover, the branches operate independently to overcome the limitations of current approaches that cannot simultaneously analyze features from both domains. The results of experiments on the GoPro dataset demonstrated the effectiveness of our method. It achieved a peak signal-to-noise ratio of 32.75, which was a 1.5 % improvement over the baseline model, and a structural similarity index of 0.957, marking an increase of 0.42 %. This confirms its enhanced deblurring capabilities. The codes are available at https://github.com/Liu-1018/DFNet/tree/main .},
  archive      = {J_ESWA},
  author       = {Junlei Song and Ying Liu and Longyu Wei and Bei Zhou and Kaifeng Dong and Fang Jin and Wenqin Mo and Yajuan Hui},
  doi          = {10.1016/j.eswa.2025.129434},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129434},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-branch image deblurring method based on frequency-domain awareness},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UssNet: A spatial self-awareness algorithm for wheat lodging area detection. <em>ESWA</em>, <em>297</em>, 129433. (<a href='https://doi.org/10.1016/j.eswa.2025.129433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop lodging significantly impacts wheat yield and quality, necessitating rapid and accurate identification methods for post-disaster response and agricultural insurance assessment. While extreme weather events causing lodging have increased in frequency, conventional semantic segmentation approaches face limitations in global context perception. This study introduces UssNet, an innovative algorithm integrating contextual and spatial awareness by combining UNet’s semantic segmentation strengths with State Space Models (SSM). We selected UNet as our base architecture due to its proven effectiveness with limited training data, encoder-decoder structure with skip connections that preserve critical spatial information for lodging detection, and optimal balance between computational complexity and performance. UssNet implements local auxiliary mechanisms with SSM, enabling selective scanning of feature maps from multiple directions to achieve linear computation of long sequences and comprehensive extraction of global contextual information. To address class imbalance challenges and improve recognition of small lodging areas, we incorporate the Focal Loss function. Additionally, we replace ReLu with GeLu activation to mitigate the “dead ReLu” phenomenon while maintaining overfitting suppression benefits. Experimental results demonstrate UssNet’s superior performance, achieving a pixel accuracy (PA) of 0.971, mean intersection over union (mIoU) of 0.931, recall of 0.85, and F1 score of 0.82 on the test dataset. Comparative analysis against state-of-the-art models confirms UssNet’s enhanced capability in capturing global context information, providing an efficient approach for wheat lodging monitoring with valuable applications in yield estimation and disaster management.},
  archive      = {J_ESWA},
  author       = {Jun Zhang and Qiang Wu and Fenghui Duan and Mingzheng Feng and Cuiping Liu and Li Dai and Xiaochun Wang and Shuping Xiong and Hao Yang and Guijun Yang and Shenglong Chang and Xinming Ma and Jinpeng Cheng},
  doi          = {10.1016/j.eswa.2025.129433},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129433},
  shortjournal = {Expert Syst. Appl.},
  title        = {UssNet: A spatial self-awareness algorithm for wheat lodging area detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-label augmentation transformer hashing for cross-modal retrieval. <em>ESWA</em>, <em>297</em>, 129432. (<a href='https://doi.org/10.1016/j.eswa.2025.129432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing (DCMH) has become a prominent research direction in multimedia information retrieval by integrating deep learning with hashing techniques. Existing methods primarily focus on capturing pairwise similarities across modalities while often underutilizing the rich semantic information embedded in multi-label annotations. Although some approaches leverage multi-labels to supervise the learning of hashing functions, their effectiveness is limited by the sparsity of the multi-label feature space. To address these limitations, we propose a multi-label augmentation transformer hashing (MATH) method. Specifically, MATH introduces a label-modality feature fusion (LMFF) module based on attention mechanisms, which effectively integrates important semantic features from image and text modalities into the multi-label space. This fusion enhances the representational capacity and completeness of multi-label features, thereby improving their ability to guide cross-modal hashing learning. Additionally, we define a multi-label cross-modal contrastive alignment loss, which unifies image, text, and multi-label information in a contrastive learning framework to achieve more precise semantic alignment across modalities. Extensive experiments on three benchmark datasets demonstrate that the proposed MATH method achieves state-of-the-art performance in cross-modal hashing retrieval tasks.},
  archive      = {J_ESWA},
  author       = {Zhiran Yu and Lei Zhang and Wei Ye},
  doi          = {10.1016/j.eswa.2025.129432},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129432},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-label augmentation transformer hashing for cross-modal retrieval},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Blockchain access control with consensus algorithm considering optimal members and president election process for secured data sharing on software defined wireless body area networks using data encryption. <em>ESWA</em>, <em>297</em>, 129430. (<a href='https://doi.org/10.1016/j.eswa.2025.129430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, blockchain has successfully shown its significance in providing a secure platform for two-way exchange of data. Similar to this, the Software Defined Wireless Body Area Networks (SDWBAN) have grown more popular since they make network administration a simpler process. Healthcare administration services can be substantially improved by integrating SDWBANs with medical facilities. However, sharing sensitive information among multiple stakeholders in the healthcare sector is challenging due to several issues, including confidentiality and integrity. Hence, it is important to address the variety of limitations in the traditional SDWBAN technique when exchanging highly private data. Here, an innovative model is proposed for secure data sharing in the SDWBAN. In the SDWBAN model, blockchain is employed to secure sensitive information. Next, the access control for the blockchain model is offered by considering the New Consensus Algorithm based on the Optimal Members and President Election (NCA-OMPE) procedure. In this phase, required members are selected optimally using Upgraded Candidate Position-based Magnificent Frigatebird Optimization (UCP-MFO) by considering various objective functions like efficiency, scalability and Transaction Processing System (TPS). Next, the president is elected by the optimal members and also the current optimal members stand for the next presidential election. Further, the Elliptical Curve Cryptography (HECC) technique is employed to encrypt the data presented in the blockchain while data-sharing procedures are performed. Finally, several validations are employed in the proposed approach with various conventional techniques to verify its performance. Here, the designed approach has an encryption time of 0.90 (s) and a decryption time of 0.62 (s) in terms of block size as 20. Thus, the overall performance outcomes showed that the proposed approach’s superior performance, thus it helps to allow faster data transfer with better security, when dealing with high-dimensional healthcare data. Also, it enables a better data sharing process for minimizing unauthorized access and attacks.},
  archive      = {J_ESWA},
  author       = {Sayila Subrahmanyam and Rajesh Arunachalam and Swapna Thouti and S.N.V. Jyotsna Devi Kosuru and J. Rajalakshmi and Preethi Palanisamy},
  doi          = {10.1016/j.eswa.2025.129430},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129430},
  shortjournal = {Expert Syst. Appl.},
  title        = {Blockchain access control with consensus algorithm considering optimal members and president election process for secured data sharing on software defined wireless body area networks using data encryption},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-space relation-aware entity representation learning for personalized compatibility modeling. <em>ESWA</em>, <em>297</em>, 129428. (<a href='https://doi.org/10.1016/j.eswa.2025.129428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized compatibility modeling aims to provide users with personalized complementary items (e.g., top, bottom, and accessories) that are compatible with the given item. Notwithstanding the recent advancements, existing methods still encounter three limitations: (1) The deficiency in homogeneous relation modeling. (2) Limited ability to perceive dynamic relations between entities (i.e., users and items). And (3) indiscriminative fusion of the neighbor representation for information propagation. These limitations impede the dynamic perception of sampling strategies during entity iterations and the comprehensive aggregation of information among entities. To surmount these problems, we propose a D ual-space R elation-aware entity representation learning for P ersonalized C ompatibility M odeling (DR-PCM), which can enhance the representations by jointly modeling fashion entities in homogeneous and heterogeneous spaces and improve personalized recommendation performance with multi-modalities. Furthermore, we design a relation-aware dynamic neighbor sampling strategy, which perceives and learns the intricate interaction relations among entities and boosts the efficiency of neighbor node sampling. Subsequently, an adaptive feature fusion is performed from the dual space to precisely capture the varying confidences of the current representation and the neighbor representation for information propagation toward different target nodes. Extensive experiments on three public fashion datasets confirm that DR-PCM significantly outperforms state-of-the-art baselines in personalized recommendation and retrieval tasks, achieving an average improvement of 13.67 % in NDCG and 9.01 % in Hit-Rate metric.},
  archive      = {J_ESWA},
  author       = {Jinhuan Liu and Xu Cui and Xuemeng Song and Yanwei Yu and Mingzhu Xu and Junwei Du},
  doi          = {10.1016/j.eswa.2025.129428},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129428},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-space relation-aware entity representation learning for personalized compatibility modeling},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wasserstein distance-based graph contrastive learning for recommendation. <em>ESWA</em>, <em>297</em>, 129427. (<a href='https://doi.org/10.1016/j.eswa.2025.129427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) is able to learn augmentation-invariant representations from raw data and reduce the dependence on labeled data. In the field of recommendation systems, traditional GCL models become a potential solution to insufficient supervision signals by augmenting the user-item interaction graph and optimizing InfoNCE loss to learn user and item representations. However, existing GCL-based recommendation models are limited by dimensional collapse, causing the sub-optimal performance of recommendation models. To tackle this problem, we propose a Wasserstein Distance-based Graph Contrastive Learning model, namely WGCL. Specifically, we integrate the Wasserstein loss into contrastive learning-based recommendation models to align the user/item representations distribution with the isotropic Gaussian distribution, which makes the real distribution of representations more uniform, thereby alleviating dimensional collapse. In fact, Wasserstein loss measures the distinction between the real distribution of entities’ representations and the desired distribution of representations by computing the covariance of representations learned from the augmented views. As a result, Wasserstein distance metric not only enables the representations more uniformly distributed on the hypersphere, but also better preserves the original semantic information of entities. Extensive experiments conducted on three widely used datasets demonstrate that WGCL outperforms traditional recommendation models. Our code is released at https://github.com/Sodapease/WGCL .},
  archive      = {J_ESWA},
  author       = {Yonghong Yu and Zhiyu Wang and Yujie Liao and Li Zhang and Rong Gao},
  doi          = {10.1016/j.eswa.2025.129427},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129427},
  shortjournal = {Expert Syst. Appl.},
  title        = {Wasserstein distance-based graph contrastive learning for recommendation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating modularity maximization and contrastive learning for identifying spatial domain from spatial transcriptomics. <em>ESWA</em>, <em>297</em>, 129426. (<a href='https://doi.org/10.1016/j.eswa.2025.129426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in spatial transcriptomics have enabled the simultaneous preservation of gene expression profiles and spatial context, facilitating the exploration of heterogeneous regions in tissues. Spatial domain identification is one of the most critical steps in spatial transcriptomics data analysis, serving as the foundation for downstream analyses. However, effectively integrating gene expression profiles with spatial topology to identify spatial domains still faces challenges. To bridge this gap, we propose STMACL, a novel graph self-supervised learning framework that combines modularity maximization and contrastive learning for identifying spatial domains. Specifically, we first construct high-quality augmented views using data augmentation strategies and generate feature views through a masked encoding strategy. Then, we utilize encoders to adaptively learn the unique embedding for each view to extract local information. Decoders are used to reconstruct the original feature matrix and adjacency matrix, guiding the model to learn embeddings that better represent the original data. Moreover, to capture high-order proximity and global similarity among neighbors, we design a modularity maximization contrastive learning strategy. In addition, we introduce an information correlation reduction module, which enforces the similarity matrix of two augmented views to approximate an identity matrix, improving the discriminability of the embeddings and mitigating representation collapse. Finally, we validate the effectiveness of STMACL on 7 public spatial transcriptomics datasets. Extensive experimental results demonstrate that STMACL outperforms other state-of-the-art baselines, confirming its superiority in spatial domain identification.},
  archive      = {J_ESWA},
  author       = {Qi Gao and Shasha Yuan and Shengjun Li and Juan Wang},
  doi          = {10.1016/j.eswa.2025.129426},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129426},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrating modularity maximization and contrastive learning for identifying spatial domain from spatial transcriptomics},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TFSM: A network for time-frequency synergistic modeling integrating mamba temporal pathway and spectral features for electricity theft detection. <em>ESWA</em>, <em>297</em>, 129425. (<a href='https://doi.org/10.1016/j.eswa.2025.129425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity Theft Detection (ETD) is crucial for reducing economic losses and maintaining power grid stability. However, existing detection methods are often limited by rigid periodicity assumptions and struggle to effectively model both long-range dependencies and localized spectral patterns within electricity consumption data. This paper introduces TFSM, a novel Time-Frequency Synergistic Modeling network, designed to overcome these limitations. We first introduce a Periodicity Strength Index to quantitatively demonstrate the shortcomings of periodicity assumptions in real-world data. Building upon this, the TFSM framework innovatively integrates two core pathways: a Mamba-based temporal pathway that leverages its linear complexity and selective state-space mechanism to efficiently capture long-range dependencies, and a spectral pathway that employs the Continuous Wavelet Transform and a Convolutional Neural Network (CNN) to extract discriminative time-frequency features. These features are effectively fused through a cross-attention mechanism, enabling deep interaction between temporal dynamics and spectral characteristics. Extensive experiments on a large-scale, real-world electricity dataset demonstrate that TFSM significantly outperforms state-of-the-art baseline methods, achieving an AUC of 0.998 and an F1-score of 0.951. Ablation studies and efficiency analyses further validate the contributions of each component and the computational advantages of the proposed architecture. TFSM offers a robust, accurate, and efficient solution for electricity theft detection in smart grids.},
  archive      = {J_ESWA},
  author       = {Na Zhao and Zhaoyu Huang and Rui Hua and Yaokun Li and Runze Zheng and Qian Shen and Jian Wang},
  doi          = {10.1016/j.eswa.2025.129425},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129425},
  shortjournal = {Expert Syst. Appl.},
  title        = {TFSM: A network for time-frequency synergistic modeling integrating mamba temporal pathway and spectral features for electricity theft detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBTSR: A U-shaped adaptive sparse transformer for single remote sensing image super-resolution. <em>ESWA</em>, <em>297</em>, 129424. (<a href='https://doi.org/10.1016/j.eswa.2025.129424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While transformers advance image super-resolution by capturing long-range dependencies, their dense self-attention mechanisms introduce significant redundancy and noise, particularly degrading efficiency and performance in complex remote sensing imagery. To address this issue, we propose DBTSR, an adaptive sparse transformer-based U-Net architecture for single remote sensing image super-resolution. Specifically, we design the Adaptive Sparse Self-Attention (DBSA) block to eliminate spatial feature redundancy. DBSA adopts a dual-path parallel structure: the Sparse Branch (SSA) filters low-matching query-key pairs via a dynamic threshold activation function, suppressing noise from irrelevant regions; the Dense Branch (DSA) retains essential information flow through Softmax, avoiding information loss from excessive sparsity. To reduce channel-domain redundancy and enhance feature representation, we develop a Multi-Scale Pyramid Residual Feedforward Network (MSP-FFN). MSP-FFN through a lightweight three-branch structure, capturing local details, mid-range context, and global semantics. Additionally, we optimize the model using a combined loss of L 1 and Stationary Wavelet Transform (SWT), enabling better capture of image high-frequency details. Extensive experiments on the AID, DOTA, DIOR, and RSSCN7 datasets show that DBTSR outperforms state-of-the-art methods in both quantitative metrics and visual quality, while significantly reducing computational costs. This confirms its effectiveness for remote sensing image super-resolution. In brief, DBTSR outperforms the classical SwinIR and the advanced TTST methods in terms of PSNR by an average of approximately 0.12 dB and 0.05 dB, respectively, while requiring only 11.96 % and 8.21 % of the computational resources.The code is available at https://github.com/TeresaTing/DBTSR .},
  archive      = {J_ESWA},
  author       = {Ting Tang and Jiangping Liu and Xiaoling Luo and Xiaojing Gao and Xin Pan},
  doi          = {10.1016/j.eswa.2025.129424},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129424},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBTSR: A U-shaped adaptive sparse transformer for single remote sensing image super-resolution},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TAPE: A multi-agent framework for task-adaptive planning and execution in resource-constrained environments. <em>ESWA</em>, <em>297</em>, 129423. (<a href='https://doi.org/10.1016/j.eswa.2025.129423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of large language models (LLMs) has significantly enhanced task-oriented question-answering capabilities, particularly in complex planning scenarios. However, the effectiveness of LLM is constrained by their parameter size, which limits practical deployment in resource-constrained environments. To address this limitation, we propose a multi-agent framework for Task-adaptive Planning and Execution (TAPE). The framework comprises three core components: a task classification and fast response agent, a tool retrieval and reranking module, and a complex task planning and execution agent. The process begins with the task classification agent evaluating the complexity of user input tasks. Simple tasks receive immediate responses, while complex tasks are routed to the tool retrieval module. This module identifies potentially relevant tools and feeds detailed tool descriptions as prompts to the complex task planning and execution agent. Subsequently, the agent generates a plan, progressively executes and updates the task plan until final resolution. The model enhances the robustness of tool calling by constructing simulated retrieval data for fine-tuning. Experimental results demonstrate that the TAPE method using two fine-tuned 0.5B models achieves up to 16.3 % and 6.4 % higher task success rates than specialized methods in two datasets, respectively. The framework minimizes resource demands for developing personalized task agents.},
  archive      = {J_ESWA},
  author       = {Xiaoyu Zhang and Yi Wang and Along He and Haobin Wang and Tao Li},
  doi          = {10.1016/j.eswa.2025.129423},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129423},
  shortjournal = {Expert Syst. Appl.},
  title        = {TAPE: A multi-agent framework for task-adaptive planning and execution in resource-constrained environments},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified pipeline for generalized mental state detection using EEG signals. <em>ESWA</em>, <em>297</em>, 129422. (<a href='https://doi.org/10.1016/j.eswa.2025.129422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental states, a complex union of cognitive, emotional, and perceptual conditions, fundamentally shape how individuals perceive and interact with their surroundings. Detecting these states is vital, as it reveals the underlying processes that govern behaviour and enables targeted interventions across diverse fields such as mental health, education, and human-computer interaction. Generalisability across subjects and trials is essential to ensure that these interventions are effective and reliable in varied real-world settings, thereby enhancing their practical applicability. In this paper, we introduce an end-to-end optimised pipeline for classifying mental states from electroencephalography (EEG) signals. Through quantitative studies of data preprocessing and feature enhancement of continuous data collected under less stringent conditions, our pipeline utilises specially designed, cutting-edge, lightweight classifiers and achieves new state-of-the-art performance. Specifically addressing the challenge of generalisability in EEG signal research, our pipeline demonstrates robust performance, achieving a peak accuracy of 79.1 % and an average of 71.9 % in cross-subject scenarios, and a high of 89.3 % with an average of 85.4 % in cross-trial evaluations.},
  archive      = {J_ESWA},
  author       = {Yinghao Wang and Rayan Elrawas and Anh-Dung Nguyen and Maxime Girard and Pavlo Mozharovskyi and Enzo Tartaglione and Van-Tam Nguyen},
  doi          = {10.1016/j.eswa.2025.129422},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129422},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unified pipeline for generalized mental state detection using EEG signals},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ROCO: Role-oriented communication for efficient multi-agent reinforcement learning. <em>ESWA</em>, <em>297</em>, 129421. (<a href='https://doi.org/10.1016/j.eswa.2025.129421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective communication and coordination among agents are pivotal for addressing complex tasks in multi-agent systems. Conventional methods often encounter limitations in adapting to dynamic environments and efficiently managing group communication. To overcome these challenges, we propose Role-Oriented multi-agent Communication (ROCO), a framework that adaptively modulates communication strategies through role-based learning. ROCO incorporates a dual-layer communication architecture: an inter-role layer and an intra-role layer. The inter-role layer facilitates cross-functional information exchange via role-specific protocols and attention mechanisms, thereby enhancing inter-role coordination. The intra-role layer streamlines communication within role groups by leveraging mutual information-based message prediction and filtration, effectively reducing redundancy and improving decision-making processes. Empirical evaluations on established benchmarks, including the StarCraft Multi-Agent Challenge and Google Research Football, demonstrate that ROCO achieves faster convergence and higher win rates than state-of-the-art methods. Ablation studies further highlight the efficacy of its key components, underscoring ROCO’s robustness and adaptability in cooperative multi-agent learning scenarios. These results indicate that ROCO offers a principled approach for improving coordination and communication in complex multi-agent environments, establishing a solid foundation for future applications in structured and dynamic settings.},
  archive      = {J_ESWA},
  author       = {Zaipeng Xie and Sitong Shen and Yaowu Wang and Chentai Qiao and Bin Tang and Wenzhan Song},
  doi          = {10.1016/j.eswa.2025.129421},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129421},
  shortjournal = {Expert Syst. Appl.},
  title        = {ROCO: Role-oriented communication for efficient multi-agent reinforcement learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated non-invasive method for measuring chicken comb and wattle using multi-camera system and CW-measure-pose. <em>ESWA</em>, <em>297</em>, 129420. (<a href='https://doi.org/10.1016/j.eswa.2025.129420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routine inspection of comb and wattle is vital for chicken breeding and health monitoring. To overcome stress caused by invasive measurement methods and lack of automated techniques, this study proposes a noninvasive approach based on multi-view imaging system and comb wattle-measure-pose (CW-Measure-pose). The system captures images of comb and wattle, and the keypoint detection model extracts measurement points. The proposed model integrates starnet as its backbone, significantly reducing model volume and computational load without compromising accuracy. The focusing diffusion pyramid network (FDPN) and the newly developed dimension-aware selective integration module (DASI) are incorporated into the neck, facilitating adaptive fusion of detailed contextual information across multiple scales. Additionally, cross stage partial convolution with kernel size 2-star (C3k2-Star) is employed in the model head, enhancing parameter efficiency and feature representation capability. The Wise-ShapeIoU loss function dynamically adjusts gradients, effectively balancing anchor boxes of varying quality. Compared with existing lightweight models, the proposed method achieves excellent performance, reaching an mAP 0.5:0.95 of 93.30 % with minimal model volume of 1.87 MB. Furthermore, the proposed approach outperforms existing comb and wattle measurement methods in accuracy, parameter diversity, and efficiency. Results demonstrate strong consistency between measured and actual values, with Pearson correlation coefficients exceeding 0.87 for all parameters and notably 0.972 for wattle length, and 0.965 for comb height. Additionally, the MAPE of most indicators is below 10 %. Finally, average measurement duration is significantly reduced to 16.19 s, substantially shorter than manual measurement methods. Consequently, the proposed technique offers robust support for intelligent breeding and farming practices.},
  archive      = {J_ESWA},
  author       = {Jinyang Xu and Yilei Hu and Zhichao Gou and Yi Lu and Di Cui},
  doi          = {10.1016/j.eswa.2025.129420},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129420},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated non-invasive method for measuring chicken comb and wattle using multi-camera system and CW-measure-pose},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting crude oil futures price uncertainty: An explainable deep learning framework integrating news sentiment. <em>ESWA</em>, <em>297</em>, 129419. (<a href='https://doi.org/10.1016/j.eswa.2025.129419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of crude oil futures prices is crucial for guiding energy investment strategies, managing market risk, and informing policy decisions. This study proposes NewsSent-CFS-GBO-TFT, an interpretable deep learning framework that integrates cutting-edge artificial intelligence techniques with practical financial engineering methods. The framework begins by extracting sentiment signals from unstructured news text using a pretrained language model, which are then integrated with a wide range of economic variables—such as supply–demand dynamics, financial market conditions, and macroeconomic uncertainty—to form a comprehensive feature set. To address the challenges of high-dimensional data, we propose a Collaborative Feature Selection (CFS) strategy that utilizes multiple evaluation criteria to assess feature importance from various perspectives, effectively reducing redundancy and improving model robustness and generalization. Additionally, the model leverages a Gradient-Based Optimizer (GBO) to simultaneously refine the architecture and hyperparameters of the Temporal Fusion Transformer (TFT), delivering both accurate point forecasts and multi-level confidence interval estimates. Empirical results demonstrate that the NewsSent-CFS-GBO-TFT model outperforms traditional benchmark models in both forecast accuracy and uncertainty quantification. Interpretability analysis reveals that short-horizon predictions are primarily influenced by trading day effects and temporal signals, while medium- and long-term forecasts increasingly reflect macroeconomic factors and geopolitical risks. The proposed approach offers transparent, high-fidelity predictive insights, providing valuable decision-support tools for investors, risk managers, and policymakers navigating volatile market environments.},
  archive      = {J_ESWA},
  author       = {Yaqi Mao and Xiaobing Yu and Junhua Zhu and Feng Wang},
  doi          = {10.1016/j.eswa.2025.129419},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129419},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting crude oil futures price uncertainty: An explainable deep learning framework integrating news sentiment},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing streamflow forecasting using an LSTM hybrid model with lightweight frequency-domain feature learning. <em>ESWA</em>, <em>297</em>, 129418. (<a href='https://doi.org/10.1016/j.eswa.2025.129418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate streamflow forecasting underpins robust water-resources planning and flood-risk mitigation. Data-driven hydrological models—such as Long Short-Term Memory (LSTM) networks—capture temporal dependencies but seldom represent explicit interactions among hydro-meteorological variables. Hybrid approaches that embed convolutional neural networks (CNNs), graph neural networks (GNNs), or attention mechanisms (AMs) mitigate this limitation, yet they introduce substantial computational overhead and lack comprehensive benchmarking. We therefore proposed a lightweight frequency-domain multilayer perceptron (FDMLP) that transforms multivariate inputs into complex spectra along the feature dimension and applies the compact MLP to model their real and imaginary parts. Multi-step forecasts with 1-, 3-, and 5-day lead times were performed at three hydrometric stations located at the upper, middle, and lower reaches of the Yellow River. Four hybrids—AM-LSTM, CNN-LSTM, GNN-LSTM, and FDMLP-LSTM—were systematically evaluated against a plain LSTM baseline. All hybrid models outperformed the baseline. FDMLP‑LSTM was the top performer, followed by CNN‑LSTM. Moreover, FDMLP‑LSTM consistently achieved the highest performance under extreme flow conditions. Despite this, the FDMLP layers increased training and inference times by only about 40 %, markedly less than the overhead introduced by AM and GNN layers. These findings highlight the pivotal role of modeling cross-feature dependencies and demonstrate that FDMLP can deliver superior predictive skill with a favorable accuracy–efficiency trade-off.},
  archive      = {J_ESWA},
  author       = {Yubo Jia and Xiaoling Su and Te Zhang and Haijiang Wu and Yuyu Jia and Qianyu Wang},
  doi          = {10.1016/j.eswa.2025.129418},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129418},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing streamflow forecasting using an LSTM hybrid model with lightweight frequency-domain feature learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DEALSD: A deep edge assisted line segment detector. <em>ESWA</em>, <em>297</em>, 129417. (<a href='https://doi.org/10.1016/j.eswa.2025.129417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Line segment detection plays a crucial role in the analysis and understanding of geometric contents in a real-world scene. Existing methods popularly detect line segments by exploiting image gradient cues, including gradient orientation and magnitude. However, there is a challenge in detecting line segments that appear in low-contrast image regions where gradient magnitudes are low. On the other hand, these line segments could have high semantic saliency as they provide valuable structural information about the scene. As a result, the failure to detect such line segments can greatly degrade the performance of follow-up line segment applications. To address this fundamental issue, a novel method is proposed in the present paper, called the deep edge assisted line segment detector (DEALSD). In our DEALSD, a deep learning edge extraction process is implemented to capture semantically salient edges of the input image first. The outcome of the edge extraction process, i.e., a deep edge heatmap, is then incorporated into the gradient map of the image for yielding a deep edge assisted (DEA)-gradient map. Finally, line segments are extracted and validated on the DEA-gradient map. In line with expert systems, DEALSD simulates intelligent decision-making by prioritizing the detection of crucial line segments, resembling human expert perception in identifying relevant structural features. Extensive experiments conducted on benchmark datasets clearly show that our developed DEALSD can deliver superior performance over a number of state-of-the-art methods. The code will be made publicly available at https://github.com/cvszy/DEALSD_hub upon publication.},
  archive      = {J_ESWA},
  author       = {Zhongyi Sha and Baojiang Zhong and Xueyuan Chen and Zikai Wang},
  doi          = {10.1016/j.eswa.2025.129417},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129417},
  shortjournal = {Expert Syst. Appl.},
  title        = {DEALSD: A deep edge assisted line segment detector},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated class-incremental learning with prompting. <em>ESWA</em>, <em>297</em>, 129416. (<a href='https://doi.org/10.1016/j.eswa.2025.129416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Web technology continues to develop, it has become common to use data stored on different clients. At the same time, federated learning has received attention due to its ability to protect data privacy when letting models learn from data distributed across various clients. However, most existing works assume that the client’s data are fixed. In real-world scenarios, such an assumption is often not true as data may be continuously generated and new classes may also appear. To this end, we focus on the practical and challenging federated class-incremental learning (FCIL) problem. For FCIL, the local and global models may suffer from catastrophic forgetting on old classes caused by the arrival of new classes, and the data distributions of clients are non-independent and identically distributed (non-iid). In this paper, we propose a method called Federated Class-Incremental Learning with PrompTing (FCILPT). Given privacy and memory constraints, FCILPT does not use rehearsal buffers for old data. We use prompts to ease catastrophic forgetting of old classes. Specifically, we encode task-relevant and task-irrelevant knowledge into prompts, preserving old and new knowledge of local clients and solving catastrophic forgetting. We first sort task information in the prompt pool on local clients to align task information across clients before global aggregation. It ensures that the same task’s knowledge is fully integrated, addressing the non-iid problem caused by class imbalance across clients under the same incremental task. Experiments on CIFAR-100, ImageNet-Subset, and TinyImageNet show that FCILPT achieves significant accuracy improvements over state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xin Luo and Fang-Yi Liang and Jiale Liu and Yu-Wei Zhan and Zhen-Duo Chen and Xin-Shun Xu},
  doi          = {10.1016/j.eswa.2025.129416},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129416},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated class-incremental learning with prompting},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scheduling a dual-arm robotic two-cluster tool in the event of a process module failure. <em>ESWA</em>, <em>297</em>, 129415. (<a href='https://doi.org/10.1016/j.eswa.2025.129415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wafer fabrication using cluster tools is a vital upstream sector of the semiconductor industry chain. Due to a large number of multi-cluster tools operating simultaneously in wafer fabs, their process modules are prone to failures from time to time. Improperly handling such events can lead to wafer scrapping and a productivity degradation. In a multi-cluster tool system with wafer residency time constraints and no parallel process modules, the wafers in processing can no longer visit the process modules on the predefined route if one process module fails. The time and location of a failure module are uncertain to incur challenges for multiple robots to transport wafers and cooperate together. To improve the operation reliability and prevent the waste of wafers, we must force the system to enter a close-down process to empty the wafers in processing because the original schedule is not applicable. For this open problem of a dual-arm multi-cluster tool, we propose two algorithms to obtain the in-situ information for wafer distribution and determine each robot’s action to transport which wafer. Then, we propose two algorithms to find robot action sequences for most scenarios. Finally, we propose linear and nonlinear programming models to determine each robot’s action time for different failure scenarios. The programming models can also 1) incorporate deadlock avoidance at a buffer module and 2) minimize the time for feasibly shutting down the tool and obtain its optimal schedule in case of a process module failure. Experiments based on industrial production are conducted to demonstrate the application and effectiveness of the proposed method. Experimental results show that the proposed method can reduce wafer loss by 100% compared with the regular swap strategy and an existing method in the literature.},
  archive      = {J_ESWA},
  author       = {QingHua Zhu and GuangXi Zhang and Yan Hou and NaiQi Wu},
  doi          = {10.1016/j.eswa.2025.129415},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129415},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scheduling a dual-arm robotic two-cluster tool in the event of a process module failure},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy clustering enhanced competitive swarm optimizer for balancing convergence and diversity in large-scale multiobjective optimization. <em>ESWA</em>, <em>297</em>, 129410. (<a href='https://doi.org/10.1016/j.eswa.2025.129410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, optimizing multiple objectives in high-dimensional spaces is challenging due to the need to balance convergence and diversity. Traditional methods often fail to achieve optimal solutions. This paper proposes a novel method, LM-FDVA-CSO, to enhance solution efficiency and accuracy by grouping decision variables using fuzzy clustering and integrating with the competitive swarm optimizer (CSO). LM-FDVA-CSO employs fuzzy clustering to obtain a two-dimensional membership vector for each decision variable, quantifying its group membership. A novel population segmentation method based on non-dominated sorting and crowding distance divides the population into sub-populations with distinct characteristics. Each sub-population is optimized to enhance convergence or diversity. Evaluated across 54 test instances using the IGD metric, LM-FDVA-CSO demonstrated overall superiority over competitors, particularly dominating the baseline LMEA algorithm in 46 cases, achieving comparable performance in 4 cases, and showing slight inferiority in 4 cases. Statistical analysis confirms significant improvements in solution accuracy and search efficiency.},
  archive      = {J_ESWA},
  author       = {Yanyan Tan and Xiaojie Li and Yukun Zhang and Wei Zheng and Huaxiang Zhang},
  doi          = {10.1016/j.eswa.2025.129410},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129410},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fuzzy clustering enhanced competitive swarm optimizer for balancing convergence and diversity in large-scale multiobjective optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing digital cattle identification with fine-grained image analysis. <em>ESWA</em>, <em>297</em>, 129409. (<a href='https://doi.org/10.1016/j.eswa.2025.129409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods of identifying cattle, including ear tags, tattoos, microchips, notches, and electrical branding, have two primary shortcomings. These methods are invasive or distressing to animals and also face the risk of being duplicated or lost, affecting their dependability. Despite these limitations, such methods continue to be widely adopted due to their familiarity, low initial cost, and ease of application in routine farm operations. Their longstanding use has led to their acceptance as standard practice in traditional livestock management. Nonetheless, these factors emphasize the increasing need for a more reliable, non-invasive, and tamper-resistant digital identification system aligned with the evolving demands of modern livestock production. Recent research has shown that cattle, similar to humans, have a variety of unique biometric characteristics. Digital cattle biometrics, if applied for automated identification, health monitoring, and cattle tracking, may offer advantages over traditional methods by improving accuracy and efficiency. In this context, this work presents a novel framework for a cattle identification system based on a fine-grained image analysis technique. A strongly supervised object detector is utilized to perform detailed identification at the part level for the eyes, nose, and muzzle. Concurrently, the full face image serves as an object-level feature while integrating the results. The proposed technique also uses concepts like deep filters for feature extraction and the attention mechanism to enhance the feature extraction process. These fine-grained part-level and object-level feature maps are then used to generate intermediate classification outputs. Finally, the weighted part-level identification output is combined with object-level output to make a final prediction. The proposed technique has achieved 99.47 % identification accuracy on a publicly available cattle dataset [Shojaeipour et al., 2021].},
  archive      = {J_ESWA},
  author       = {Prashant Digambar Pathak and Surya Prakash},
  doi          = {10.1016/j.eswa.2025.129409},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129409},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing digital cattle identification with fine-grained image analysis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simultaneous modeling of disease screening and severity prediction: A multi-task and sparse regularization approach. <em>ESWA</em>, <em>297</em>, 129408. (<a href='https://doi.org/10.1016/j.eswa.2025.129408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying clinically relevant biomarkers and developing predictive models are central challenges in biomedical research. Biomarkers are commonly used for disease screening, and some provide information not only on the presence or absence of a disease but also on its severity. Such biomarkers can contribute to treatment prioritization and support clinical decision-making. To address both disease screening and severity prediction, this paper focuses on regression modeling for ordinal outcomes with a hierarchical structure. When the response variable is a combination of the presence of disease and severity, such as { healthy, mild, intermediate, severe }, a straightforward approach is to apply the conventional ordinal regression model. However, such models may lack the flexibility needed to capture heterogeneity in how predictors relate to response levels, particularly when the response levels have a heterogeneous association structure with predictors. Therefore, this paper proposes a model that treats screening and severity prediction as separate tasks, along with an estimation method based on structural sparse regularization. This method is designed to leverage a shared structure between the tasks. In numerical experiments, the proposed method demonstrated stable performance across many scenarios compared to existing ordinal regression methods.},
  archive      = {J_ESWA},
  author       = {Kazuharu Harada and Shuichi Kawano and Masataka Taguri},
  doi          = {10.1016/j.eswa.2025.129408},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129408},
  shortjournal = {Expert Syst. Appl.},
  title        = {Simultaneous modeling of disease screening and severity prediction: A multi-task and sparse regularization approach},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on one-dimensional data quality assurance for machinery health monitoring using compressive sensing and enhanced context encoder. <em>ESWA</em>, <em>297</em>, 129407. (<a href='https://doi.org/10.1016/j.eswa.2025.129407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstruction of abnormal data to improve data quality is of great importance for machinery health monitoring (MHM). Existing data reconstruction methods are generally limited by strict assumptions, such as signal sparsity and random sampling, along with high computational costs, making them poorly adaptable to MHM data. To assure high-quality MHM data, this study developed a novel enhanced context encoder based on compressive sensing (CS-ECE). The loss function utilized in CS-ECE is designed to consider multiple feature dimensions, enabling accurate reconstruction of signal characteristics in both time and frequency domains, which can significantly enhance the reliability of MHM results. The proposed CS-ECE’s effectiveness and superiority are confirmed through real-world data collected from a high-speed train and ablation studies. Comparative analysis shows that the proposed CS-ECE yields a higher fitting degree and lower error levels compared to four classical and five representative state-of-the-art CS algorithms, especially in terms of time cost, which is at least two orders of magnitude faster.},
  archive      = {J_ESWA},
  author       = {Qinglin Xie and Jing Wang and Guan-Sen Dong and Gongquan Tao and Chenxi Xie and Zefeng Wen},
  doi          = {10.1016/j.eswa.2025.129407},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129407},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on one-dimensional data quality assurance for machinery health monitoring using compressive sensing and enhanced context encoder},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BUT-net: Boundary-aware U-net structure with two-path transformers for lesion segmentation in mCNV using OCT images. <em>ESWA</em>, <em>297</em>, 129405. (<a href='https://doi.org/10.1016/j.eswa.2025.129405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myopic choroidal neovascularization (mCNV) is a common complication of high myopia. This disease will spread to the macular region of the retina, which has a serious impact on vision. Accurate segmentation of mCNV in retinal optical coherence tomography (OCT) plays a significant role in evaluating the condition of the disease and guiding the formulation of the treatment. However, accurate segmentation is challenging due to the blurred boundary, low contrast, tiny lesion areas, and high interference in OCT images. To this end, we propose a boundary-aware U-Net structure using two-path Transformers (i.e., BUT-Net) to accomplish lesion segmentation in mCNV using OCT images. Specifically, the encoder is built by two-path feature extractors, in which a four-stage Transformer is used to extract global features with long-distance dependency so that the network can express the morphological structure and tiny lesions. Four mixed blocks are designed by ResNet-34 and Transformer modules to excavate contextual and deep semantic features. The two-path fusion (TPF) module is utilized to fuse the two-path features by channel and spatial attention mechanism, which retains the local and global features of the fused features. For the decoder, we devise a dual attention gate (DAG) module to enhance the more complex channel dependencies in the up-sampling process. In addition, the boundary information is employed to refine the generated masks by weak supervision. The extensive experiments conducted on an in-house OCT dataset and two public different modality datasets demonstrate that our proposed method achieves superior segmentation performance. Our code is available at https://github.com/shehare9517/BUT_Net .},
  archive      = {J_ESWA},
  author       = {Hai Xie and Zhenquan Wu and Shaobin Chen and Guanghui Yue and Tianfu Wang and Chuan-Ming Liu and Lin Lu and Guoming Zhang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129405},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129405},
  shortjournal = {Expert Syst. Appl.},
  title        = {BUT-net: Boundary-aware U-net structure with two-path transformers for lesion segmentation in mCNV using OCT images},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved PSO for operational optimization of steam power systems in petrochemical enterprises. <em>ESWA</em>, <em>297</em>, 129404. (<a href='https://doi.org/10.1016/j.eswa.2025.129404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational optimization of steam power systems often involves challenges such as nonlinearity, non-convexity, multimodality, and discontinuity. Although the Particle Swarm Optimization (PSO) algorithm is widely adopted for its simplicity and efficiency, it still encounters issues like premature convergence and an imbalance between global exploration and local exploitation. To overcome these limitations, this paper proposes a Modified PSO algorithm incorporating a logarithmic decreasing adaptive inertia weight strategy (AIWLPSO). Two innovative mechanisms are introduced to update the inertia weight and enhance algorithmic performance: (1) a swarm feedback learning strategy, in which each particle’s update is based not only on global information but also incorporates chaotic properties—thus increasing population diversity and effectively suppressing premature convergence; (2) a logarithmic decreasing adaptive strategy to dynamically balance global exploration and local exploitation. In consideration of the operational characteristics of steam power systems, a differentiated strategy is adopted for updating the positions and velocities of different variables across multiple periods. The proposed method is evaluated using 25 benchmark functions, 12 CEC2022 test functions, and six steam power system scheduling cases. The results indicate that, compared with existing advanced algorithms, AIWLPSO does not show a significant advantage in the one-period case due to the model’s relative simplicity; however, it still achieves the best overall performance. For the three-period case, the algorithm achieves a performance improvement of 7.98% to 11.77%. For the six-period case, the improvement ranges from 8.84% to 9.08%. This study confirms that the improved particle swarm optimization algorithm can effectively address the operational optimization of complex steam power systems, as well as related challenges such as comprehensive energy system optimization, combined heat and power economic dispatch, and the optimization of supercritical carbon dioxide circulation systems.},
  archive      = {J_ESWA},
  author       = {Wenzhi Dai and Jiahui Wang and Yuehan Chen and Xin Wang and Xinle Yang and Heqi Zhang},
  doi          = {10.1016/j.eswa.2025.129404},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129404},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved PSO for operational optimization of steam power systems in petrochemical enterprises},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient refined UNets: Efficient segmentation networks for boundary-aware cloud and shadow detection. <em>ESWA</em>, <em>297</em>, 129403. (<a href='https://doi.org/10.1016/j.eswa.2025.129403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation aims to partition images into regions in which pixels share homogeneously semantic information and then are gathered to construct an object of interest. This property naturally can serve the detection of objects in a boundary-aware style and therefore leads to wide uses in multiple applications, for remote sensing images in particular, which has been extensively investigated in our previous research. Boundary-aware performance is one of the goals of image segmentation but efficiency problems arise in commonly quadratic implementations. This requires us to further investigate an efficient approximation of our previous solutions. In this paper, we therefore present the efficient implementations of Permutohedral Refined UNet and Refined UNet v4 by applying efficient algorithms and updating the computational flow. Specifically, vectorized forms for the message-passing steps in CRFs are given, which make it possible to deploy these parallel computations on the GPU devices in a straightforward way; also, the message-passing steps of Refined UNet v4 are updated by being split into the initialization and filtering substeps: the initialization can run only once, while the filtering is involved in the iterative CRF approximation. This transformation and update can significantly remove computational redundancy and then gives rise to a significant efficiency gain while boundary-aware segmentation performance can also be preserved. The boundary-aware effectiveness and efficient performance are verified by our extensive experiments, including performance comparisons, ablation studies, and hyperparameter tests. These computations and some experimental illustrations are publicly available at https://github.com/92xianshen/efficient-refined-unets .},
  archive      = {J_ESWA},
  author       = {Libin Jiao and Lianzhi Huo and Changmiao Hu and Ping Tang and Zheng Zhang},
  doi          = {10.1016/j.eswa.2025.129403},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129403},
  shortjournal = {Expert Syst. Appl.},
  title        = {Efficient refined UNets: Efficient segmentation networks for boundary-aware cloud and shadow detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint optimization of electric bus infrastructure planning, fleet composition, and charging schedule with multiple charging modes. <em>ESWA</em>, <em>297</em>, 129402. (<a href='https://doi.org/10.1016/j.eswa.2025.129402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public transportation electrification plays a pivotal role in combating climate change and curbing carbon emissions. However, the efficiency of battery electric bus (BEB) systems is often hindered by the separate planning of three interdependent components: fleet composition, charging infrastructure, and charging schedules. Such decoupling can lead to suboptimal performance and higher costs. To address this challenge, this study proposes a joint optimization framework that integrates these components, considering plug-in and battery swapping modes, service continuity, and time-of-use (ToU) electricity price. Firstly, a mixed integer programming model is formulated to minimize the total costs of BEB transit systems. To enhance computational efficiency, a dual extended column generation algorithm (DX-CG) is developed to solve the model. Finally, the effectiveness of the proposed method is validated using a real-world transit network in Nanjing, China, accompanied by a comprehensive analysis of the results. The findings indicates (i) an effective utilization of deployed infrastructures with corresponding charging and swapping strategy for a heterogeneous fleet, (ii) the flexibility of peak clipping and valley filling with the combination of partial charging strategies and block tariff, and (iii) an improvement of proposed algorithm in objective and run time. Moreover, the sensitivity analysis highlights the competitiveness of battery swapping under extremely constrained capacity or low battery cost. “One unit, one depot” scheme is achieved with a slight modification to the timetable. Overall, the study offers practical insights for optimizing BEB systems, contributing to sustainable transportation and reduced energy consumption.},
  archive      = {J_ESWA},
  author       = {Yihua Guo and Mingye Zhang},
  doi          = {10.1016/j.eswa.2025.129402},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129402},
  shortjournal = {Expert Syst. Appl.},
  title        = {Joint optimization of electric bus infrastructure planning, fleet composition, and charging schedule with multiple charging modes},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-UAV-aided power-up and data collection: Multi-agent DQL with genetic algorithm approach. <em>ESWA</em>, <em>297</em>, 129401. (<a href='https://doi.org/10.1016/j.eswa.2025.129401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, unmanned aerial vehicles (UAVs) are frequently used in wireless sensor networks (WSNs) as mobile power supplies and information collectors, due to their flexible deployment, high mobility, and low cost. In this paper, we consider multi-UAVs equipped with wireless power transfer (WPT) functionality, which uses array antennas to charge the batteries of sensor nodes (SNs) and collect data from them in WSNs. We aim to minimize the maximum mission completion time for all UAVs by jointly optimizing the trajectories of multiple UAVs, transmitting power, and beam-forming. To solve this complex problem, we provide two solutions, the minimum flying time algorithm and the multi-agent deep Q-learning (MA-DQL) algorithm. For the minimum flying time algorithm being used for benchmarking, we first group the SNs by using the K -means algorithm, and find the UAVs’ hovering locations. After that, we utilize the alternative optimization technique, which separates the main problem into two sub-problems. Each sub-problem is solved repeatedly until convergence using ant colony optimization (ACO) and convex optimization tools (CVX), respectively. More importantly, we develop the MA-DQL algorithm to solve this problem, a type of deep reinforcement learning (DRL) that involves multiple agents, with each agent corresponding a UAV. Furthermore, we enhance the MA-DQL framework with a genetic algorithm (MA-DQL with GA) that evolves complete decision trajectories in replay memory through crossover and mutation. This structured experience evolution improves exploration efficiency, learning stability, and constraint satisfaction during training. Simulation results demonstrate that the proposed method reduces mission completion time, improves energy efficiency, and ensures fairness across UAVs in decentralized settings.},
  archive      = {J_ESWA},
  author       = {Vitou That and Sengly Muy and Jung-Ryun Lee},
  doi          = {10.1016/j.eswa.2025.129401},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129401},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-UAV-aided power-up and data collection: Multi-agent DQL with genetic algorithm approach},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GXNSRec: Multi-behavior sequential recommender based on graph cross networks. <em>ESWA</em>, <em>297</em>, 129387. (<a href='https://doi.org/10.1016/j.eswa.2025.129387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are one of the most important technologies in e-commerce. Traditional sequential recommenders focus only on the features of interacted items, while ignoring the behavioral features of each interaction. Multi-behavior sequential recommenders introduce the features of users’ heterogeneous behaviors into preference prediction, which achieve greater performance than traditional single-behavior recommenders. Existing multi-behavior sequential recommenders often use self-attention and heterogeneous graph network (HGN) to capture sequential features of users’ behaviors. Cross feature is one of the most commonly used techniques in traditional recommender systems. However, the above two approaches ignore the cross features during the process of learning embedding vectors. Graph Cross Network (GXN) introduces the cross feature of nodes into message propagation, which is an effective approach to compute cross features of interactions. In this paper, we propose a GXN based multi-behavior sequential recommender named GXNSRec. Specifically, GXNSRec first uses GXN to compute the cross features of heterogeneous behaviors and generate the items’ embedding vectors. Then, GXNSRec uses a carefully designed behavior-aware self-attention to mine the associations between users’ heterogeneous behavior during the process of capturing sequential features. Finally, the conducted experiments show that GXNSRec achieves a performance improvement of 3.42 % over to the optimal baselines. In addition, we also measure the contribution of each component, which demonstrates the effectiveness of introducing of heterogeneous behavior information. Finally, we investigated the differences in attention weight between the GXNSRec and the baseline model through visualisation.},
  archive      = {J_ESWA},
  author       = {Ruixin Chen and Jianping Fan and Meiqin Wu and Rui Cheng and Mingxuan Chai},
  doi          = {10.1016/j.eswa.2025.129387},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129387},
  shortjournal = {Expert Syst. Appl.},
  title        = {GXNSRec: Multi-behavior sequential recommender based on graph cross networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bridging land and sea: A latent diffusion framework for high-resolution ocean floor mapping. <em>ESWA</em>, <em>297</em>, 129386. (<a href='https://doi.org/10.1016/j.eswa.2025.129386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstruction of ocean Digital Elevation Models (DEMs) remains a central challenge in Earth science, with direct impact on marine navigation, oceanography, resource exploration, and environmental monitoring. Recent deep-learning approaches rely mainly on super-resolution techniques applied to gridded DEMs and therefore under-utilize the growing body of high-resolution, non-gridded observations (e.g., ship-based sonar data). To close this gap, we cast DEM reconstruction from non-gridded data as an inpainting problem and propose a latent-diffusion framework that operates directly in irregular input space. Since large, labeled ocean DEM data is scarce, we further employ transfer learning, exploiting morphological similarities between terrestrial and oceanic topography. Extensive experiments show that our method improves reconstruction accuracy and consistently outperforms classical interpolation baselines on non-gridded ocean DEMs.},
  archive      = {J_ESWA},
  author       = {Duo Shuai and Qiang Deng and Wei Zhong and Yang Lu and Qixian Zhong and Zhonglei Wang},
  doi          = {10.1016/j.eswa.2025.129386},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129386},
  shortjournal = {Expert Syst. Appl.},
  title        = {Bridging land and sea: A latent diffusion framework for high-resolution ocean floor mapping},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-guided object detection via bayesian networks and knowledge graphs (KGBNCNet). <em>ESWA</em>, <em>297</em>, 129385. (<a href='https://doi.org/10.1016/j.eswa.2025.129385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a crucial problem in computer vision that integrates image categorization and localization to recognize objects within an image or video. It serves a pivotal function in numerous practical applications. However, existing state-of-the-art object detection algorithms largely ignore the vast quantity of background knowledge about the real world to detect small objects, including deep neural networks, which only focus on utilizing features within an image. An excessive number of items in an image always leads to occlusion, target blur, and other complications, making object detection more challenging. The detection problem is solely addressed in terms of feature extraction in object detection using a convolutional neural networks, which ignore knowledge and experience to investigate higher-level relationships between objects. This research introduces a novel approach that integrates a knowledge graph with Bayesian networks to improve the accuracy of standard object detection algorithms, as Bayesian networks provide a structured way to incorporate prior knowledge and model the probabilistic relationships between objects. The proposed framework can seamlessly incorporate any external knowledge and object detection system. This integration enhances object detection by undergoing a re-optimization process to achieve improved consistency with background knowledge. Finally, our proposed method was empirically evaluated on COCO benchmark datasets. The results demonstrate a significant boost in mAP, up to 2.02 %, relative to the state-of-the-art baseline.},
  archive      = {J_ESWA},
  author       = {Christine Dewi and Rasoul Amirzadeh and Dhananjay Thiruvady and Nayyar Zaidi},
  doi          = {10.1016/j.eswa.2025.129385},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129385},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge-guided object detection via bayesian networks and knowledge graphs (KGBNCNet)},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AMK-CDiffNet: Adaptive-multiscale K-space cold diffusion network for fast MRI reconstruction. <em>ESWA</em>, <em>297</em>, 129384. (<a href='https://doi.org/10.1016/j.eswa.2025.129384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, diffusion models have demonstrated their effectiveness in medical imaging by generating high-quality data through the incremental addition and reversal of Gaussian noise. Previous studies have successfully employed these models for accelerated Magnetic Resonance Imaging (MRI) reconstruction, which has enhanced patient experiences by reducing scan times. In this paper, we introduce a novel model called the Adaptive-Multiscale K-space Cold Diffusion Network (AMK-CDiffNet), specifically designed for MRI reconstruction. Unlike traditional models that rely on Gaussian noise, our approach utilizes undersampling techniques to create a mask and progressively decrease the sampling rate, capitalizing on the frequency characteristics of K-space. We implement frequency-domain degradation during forward diffusion and frequency-domain complementation during backward diffusion to improve reconstruction quality. The network structure consists of two specific modules: the K-space Adaptive Dilated Convolution Block (KADCB) and the Frequency-Domain Manipulation Module (FDMM). The KADCB is designed to mask and weigh frequencies, enabling the model to selectively enhance both low- and high-frequency components. The FDMM is composed of frequency degradation and frequency complementation. The degradation process uses a learnable multiscale filter to enhance robustness by attenuating high-frequency noise and amplifying low-frequency features. The complementation ensures that the model makes use of low-frequency features while compensating for any loss of high-frequency information during upsampling. Experimental results indicate that our method outperforms existing approaches, improving about 1 to 2 dB in peak signal-to-noise ratio (PSNR) and an enhancement of around 0.03 to 0.05 in structural similarity index (SSIM), along with superior MRI generation quality.},
  archive      = {J_ESWA},
  author       = {Bingchen Dong and Gengshen Wu and Xia Feng and Yi Liu and Jungong Han},
  doi          = {10.1016/j.eswa.2025.129384},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129384},
  shortjournal = {Expert Syst. Appl.},
  title        = {AMK-CDiffNet: Adaptive-multiscale K-space cold diffusion network for fast MRI reconstruction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PriSecFedFR: Privacy-secure face recognition model training via federated learning and random projection. <em>ESWA</em>, <em>297</em>, 129383. (<a href='https://doi.org/10.1016/j.eswa.2025.129383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition technology has become an essential tool for personal identity authentication in various real-world applications. However, as privacy concerns grow and regulations tighten, traditional centralized training methods based on large-scale facial data collection are becoming increasingly impractical. To address these challenges, we propose a novel approach, PriSecFedFR, for training a face recognition model within the federated learning (FL) framework while preserving biometric privacy. The proposed training strategy leverages feature representations from public datasets as learnable negative samples to tackle the issue of Non-Independent and Identically Distributed (Non-IID) face data in FL clients. This method improves the effectiveness of local model training and enhances the global model’s generalization capabilities. Additionally, the random projection technique is introduced to transform face feature representations into projected embeddings, enabling collaborative training of the federated model without exposing sensitive biometric information. Extensive experiments conducted on multiple datasets demonstrate that PriSecFedFR not only improves the accuracy of federated face recognition model but also offers stronger privacy protection compared to existing federated face recognition methods.},
  archive      = {J_ESWA},
  author       = {Jialiang Peng and Huiting Sun and Dong Yang and Ahmed A. Abd El-Latif and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.eswa.2025.129383},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129383},
  shortjournal = {Expert Syst. Appl.},
  title        = {PriSecFedFR: Privacy-secure face recognition model training via federated learning and random projection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decoding visual neural representations by multimodal with dynamic balancing. <em>ESWA</em>, <em>297</em>, 129382. (<a href='https://doi.org/10.1016/j.eswa.2025.129382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose an innovative framework that integrates EEG, image, and text data, aiming to decode visual neural representations from low signal-to-noise ratio EEG signals. Specifically, we introduce text modality to enhance the semantic correspondence between EEG signals and visual content. With the explicit semantic labels provided by text, image and EEG features of the same category can be more closely aligned with the corresponding text representations in a shared multimodal space. To fully utilize pre-trained visual and textual representations, we propose an adapter module that alleviates the instability of high-dimensional representation while facilitating the alignment and fusion of cross-modal features. Additionally, to alleviate the imbalance in multimodal feature contributions introduced by the textual representations, we propose a Modal Consistency Dynamic Balance (MCDB) strategy that dynamically adjusts the contribution weights of each modality. We further propose a stochastic perturbation regularization (SPR) term to enhance the generalization ability of semantic perturbation-based models by introducing dynamic Gaussian noise in the modality optimization process. The evaluation results on the ThingsEEG dataset show that our method surpasses previous state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by 2.0 % and 4.7 % respectively.},
  archive      = {J_ESWA},
  author       = {Kaili Sun and Xingyu Miao and Bing Zhai and Haoran Duan and Yang Long},
  doi          = {10.1016/j.eswa.2025.129382},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129382},
  shortjournal = {Expert Syst. Appl.},
  title        = {Decoding visual neural representations by multimodal with dynamic balancing},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RAMR: A role-adaptive modality recalibration network for RGBT tracking. <em>ESWA</em>, <em>297</em>, 129381. (<a href='https://doi.org/10.1016/j.eswa.2025.129381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking leverages the complementary strengths of RGB and thermal modalities but struggles with dynamic quality shifts and semantic inconsistency in complex environments. To address this, we propose RAMR, a Robust and Adaptive Multimodal Representation framework that models modality importance and alignment throughout the tracking process. RAMR comprises: a Quality-Aware Modality Management module using attention entropy to assign primary and auxiliary roles; an Asymmetric Modality Fusion Mechanism for cross-modal gated enhancement; and a Bidirectional Cross-modal Optimization and Modulation module that refines fusion via visual-language interaction. Evaluated on GTOT, RGBT210, RGBT234, and LasHeR, RAMR demonstrates competitive performance. Specifically, it achieves 71.9 % Precision, 68.5 % Normalized Precision, and 57.2% Success Rate on LasHeR, highlighting its robustness in handling single-modality degradation, such as thermal crossover, low illumination, and partial occlusion. The code of the proposed method will be available at https://github.com/ysqidong-dotcon/RAMR .},
  archive      = {J_ESWA},
  author       = {Zhao Gao and Dongming Zhou and Yisong Liu and Qingqing Shan},
  doi          = {10.1016/j.eswa.2025.129381},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129381},
  shortjournal = {Expert Syst. Appl.},
  title        = {RAMR: A role-adaptive modality recalibration network for RGBT tracking},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel stochastic-robust optimization model for emergency supplies prepositioning under uncertain scenario probabilities. <em>ESWA</em>, <em>297</em>, 129380. (<a href='https://doi.org/10.1016/j.eswa.2025.129380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strategic placement of emergency supplies has been demonstrated to have a substantial impact on the efficacy of emergency response. However, the prepositioning of emergency supplies is accompanied by a multitude of uncertainties, primarily due to the impracticality of predicting the location and intensity of a disaster. Despite the demonstrated efficacy of scenario-based stochastic optimization in addressing these uncertainties, determining scenario probabilities remains a challenging. In this paper, intervals are employed to symbolize the uncertainty in the scenario probabilities, and a stochastic-robust optimization model is formulated based on the utilization of worst-case scenario probabilities. The model under consideration integrates facility location, storage level decision, and post-disaster distribution of emergency supplies. Moreover, the deprivation cost is incorporated into the allocation of emergency supplies. A Benders decomposition algorithm is proposed by considering the optimal solution structure of the worst-case scenario probabilities. The validity and robustness of the proposed modeling approach are illustrated through a case study. A comparison of the optimal solutions for the baseline model and the proposed model reveals that the latter, despite an increase in cost of 9.36 %, successfully mitigates the cost escalation due to probabilistic uncertainty in the worst probability case by 22.12 %. A comprehensive analysis is conducted to assess the impact of the uncertainty surrounding scenario probabilities and the deprivation cost of emergency supplies.},
  archive      = {J_ESWA},
  author       = {Wuyang Yu},
  doi          = {10.1016/j.eswa.2025.129380},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129380},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel stochastic-robust optimization model for emergency supplies prepositioning under uncertain scenario probabilities},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigate discrimination caused by data bias: Learning fair representations with information reinforcement via recurrent encoding. <em>ESWA</em>, <em>297</em>, 129379. (<a href='https://doi.org/10.1016/j.eswa.2025.129379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of artificial intelligence in information management and assisted decision-making, biases in the data have become an inevitable issue. Algorithms may further amplify these biases, ultimately resulting in unfair outcomes in decision-making. To address this issue at its core, it is necessary to improve existing machine learning methods by mitigating bias at both the data processing and representation learning stages. One approach to achieving this is to refine the data representations used in these systems, ensuring more equitable decision-making outcomes across different groups. We propose a novel fair-representation algorithm, Learning Fair Representations with Information Reinforcement via Recurrent Encoding (FRE) that uses recurrent encoding to learn more useful representations. It generates counterfactual samples with different sensitive attributes from the original data while keeping other features unchanged. The original data and generated counterfactual samples are then fed into the encoder separately to produce latent representations that capture the key information of the data, laying a solid foundation for subsequent processing. Next, FRE utilizes these latent representations to predict data labels, which are then input into the encoder along with the original inputs. Through iterative learning, the model enhances its ability to extract useful information from the data, thereby improving the effectiveness of fair representations. Experimental results on six benchmark datasets demonstrate that FRE consistently outperforms existing methods. This indicates that FRE can effectively mitigate discrimination in information system decision-making.},
  archive      = {J_ESWA},
  author       = {Jialing Cai and Fei Zhu},
  doi          = {10.1016/j.eswa.2025.129379},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129379},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mitigate discrimination caused by data bias: Learning fair representations with information reinforcement via recurrent encoding},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SALLM: Open world object detection empowered by self adaptive learning and large model. <em>ESWA</em>, <em>297</em>, 129375. (<a href='https://doi.org/10.1016/j.eswa.2025.129375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open World Object Detection (OWOD) aims to develop detection systems capable of simultaneously identifying known objects and discovering unknown ones in real-world scenarios, while maintaining the ability for continuous learning. In recent years, it has become a prominent research focus. Existing methods typically rely on objectness scores derived from known categories to identify unknown objects. However, due to the inherent bias of detectors toward known categories, this assumption often fails, leading to class recognition deviations. To address this challenge, we propose a novel OWOD framework named SALLM, which integrates three core innovations: SLUDA–a Self-adaptive Learning Unsupervised Domain Adaptation strategy that dynamically adjusts confidence thresholds based on the model’s learning status, enabling class-specific and training-stage-aware thresholding to improve pseudo-label reliability; SFR–a Self-adaptive Fairness Regularization mechanism that promotes prediction diversity and mitigates early-stage confirmation bias by aligning predicted distributions with smoothed histogram priors; and KTLM–a Knowledge Transfer from Large Models approach that leverages the Segment Anything Model (SAM) to generate high-quality pseudo-labels for unknown objects, enhancing unknown object recall without manual annotation. Experimental results demonstrate that SALLM significantly outperforms existing state-of-the-art (SOTA) methods in both unknown object recall (achieving a U-Recall improvement of 21.9) and inference speed (reaching 36.25 FPS). The SLUDA strategy also greatly enhances training efficiency by accelerating model convergence.},
  archive      = {J_ESWA},
  author       = {Yangyang Huang and Linhua Ye and Ronghua Luo},
  doi          = {10.1016/j.eswa.2025.129375},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129375},
  shortjournal = {Expert Syst. Appl.},
  title        = {SALLM: Open world object detection empowered by self adaptive learning and large model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SCC3: A novel structure-connected cognition cube network for manchu word recognition. <em>ESWA</em>, <em>297</em>, 129374. (<a href='https://doi.org/10.1016/j.eswa.2025.129374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manchu script, an endangered agglutinative script that served as a primary medium during the Qing dynasty of China, provides the first-hand archival insights into multi-ethnic governance systems. Accurate recognition of Manchu words constitutes the foundational step in analyzing these archival materials. Existing methods for Manchu word recognition have attained significant improvements in accuracy. However, they still face four major challenges: deficiency in large-scale dataset, difficulty in fine-grained feature extraction, susceptibility to spatial structural distortion, and inadequate contextual semantic modeling. To handle these issues, we first establish a novel Manchu word image dataset MW14850 that comprises 124,448 high-quality samples spanning 14,850 distinct lexical units. Then we propose a novel Structure-Connected Cognition Cube network ( SCC 3 ) for Manchu word recognition. Specifically, we design a noval Structure-Aware Residual (SAR) strategy which can synergistically capture stroke-level micro-features and component-level contextual patterns. Furthermore, to enhance directional feature responses while suppressing noise, we propose a novel Detail Perception Block (DPBlock). Last, we introduce a novel Semantic Collaborative Attention (SCAtt) mechanism to model character spatial topology and filter discriminative semantic channels. SCC 3 significantly improves differentiation capability for visually similar Manchu characters while preserving spatial topological integrity. Comprehensive experiments demonstrate that SCC 3 outperforms existing methods with 97.16 % recognition accuracy. Our code will be available at https://github.com/Hunt9160/SCC3 .},
  archive      = {J_ESWA},
  author       = {Xiaojun Bi and Wenhao Tao and Zheng Chen and Haipeng Sun},
  doi          = {10.1016/j.eswa.2025.129374},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129374},
  shortjournal = {Expert Syst. Appl.},
  title        = {SCC3: A novel structure-connected cognition cube network for manchu word recognition},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Instance-aware visual prompting helps multimodal models see better. <em>ESWA</em>, <em>297</em>, 129373. (<a href='https://doi.org/10.1016/j.eswa.2025.129373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Visual-Language Models (VLMs) have made notable progress in fine-grained visual understanding, dynamic refinement via feedback, and label-driven human-model interaction for visual comprehension applications. However, even with the latest VLM technology, there are still challenges when dealing with intricate images used in these applications, particularly those with dense content or cluttered backgrounds. To address this limitation and assist VLMs in understanding complex visual information, we introduce a visual prompting method called Instance-Aware Visual Prompting (IAVP). IAVP is an image enhancement method that combines large language models (LLMs) and object detection models. It dynamically perceives “instances” based on input text and enhances the image accordingly to assist VLMs in better understanding the contextual relevance of visual inputs. Specifically, IAVP first uses LLMs to identify key objects or scenes (“instances”), which are then used as contextual anchors to guide object detection models in accurately localizing regions of interest, improving computational efficiency. Finally, IAVP introduces a label generation approach that enriches instance representations through structured semantic annotation, offering clearer and more informative contextual cues. We present how IAVP is practically applied to support VLMs in better understanding fine-grained visual content, incorporating feedback for dynamic refinement, and facilitating label-driven human-model interaction. These applications show the superior performance of IAVP, underscoring its effectiveness in complex image analysis and potential to advance multimodal systems.},
  archive      = {J_ESWA},
  author       = {Xiaoyu Lin and Jingxu Wang and Liyong Fu and He Yan and Qiaolin Ye},
  doi          = {10.1016/j.eswa.2025.129373},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129373},
  shortjournal = {Expert Syst. Appl.},
  title        = {Instance-aware visual prompting helps multimodal models see better},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tri-STANet: An advanced framework integrating dual axis transformer and morphological encoding for enhanced AS detection. <em>ESWA</em>, <em>297</em>, 129372. (<a href='https://doi.org/10.1016/j.eswa.2025.129372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aortic Stenosis is a dangerous heart condition due to the gradual narrowing of the aortic valve. This condition leads to life-threatening complications like heart failure and sudden cardiac death, if it is not treated in a timely manner. Therefore, it is important to detection this condition at the initial stage because it allows timely medical interventions. In this paper, we propose a novel diagnostic framework, named Tri-Stage Transformer Network for AS Detection (Tri-STANet), to enhance the detection accuracy of AS by analyzing echocardiogram views (Parasternal Long Axis (PLAX) and Parasternal Short Axis (PSAX)). The quality of echocardiograms is enhanced by utilizing advanced noise reduction, contrast enhancement, and structural correction with the aim of getting clearer visualizations of cardiac structures. The proposed end-to-end transformer-based model is used to process the enhanced echocardiogram data by utilizing three modules. The first module is named as In-Depth Dual Axis U-Net (IDA-U-Net), and it integrates In-depth Convolutional Analysis Kernel U-Net (IDACK-Net) with Dual Axis Transformer (DAT) by utilizing ResNet as its backbone for extracting features. The Boundary Attention Refinement Unit (BARU) is utilized as second module with the aim of refining boundary delineation and capturing morphological features such as complicated edges of aortic valve. Lastly, we employ Gompertz-Inspired Morphological AutoEncoding Network (GIMA-Net) for detecting AS in a precise and reliable way. The proposed framework works effectively by extracting and capturing complex morphological features within echocardiograms. The final results unveil that the proposed framework outperforms the existing works in terms of performance.},
  archive      = {J_ESWA},
  author       = {Mohd Anul Haq and Rakesh Kumar Mahendran and Arafat Khan and Farman Ali and Jayadev Gyani},
  doi          = {10.1016/j.eswa.2025.129372},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129372},
  shortjournal = {Expert Syst. Appl.},
  title        = {Tri-STANet: An advanced framework integrating dual axis transformer and morphological encoding for enhanced AS detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging mamba for reference audio-visual segmentation with vote and cache mechanism. <em>ESWA</em>, <em>297</em>, 129371. (<a href='https://doi.org/10.1016/j.eswa.2025.129371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference audio-visual segmentation (Ref-AVS) aims to segment target objects in videos based on textual prompts, leveraging an understanding of both audio and visual information. This task imposes stringent requirements for the balanced utilization of multimodal data and comprehensive understanding of temporal-wise information. In this paper, we propose a new model, VoCa, building upon the Mamba backbone. VoCa incorporates vote mechanisms, including individual consideration and group discussion, to balance the contributions of different modalities, thereby enhancing adaptability and accuracy in complex scenarios. Furthermore, an audio-visual cache module is introduced to improve the model’s ability to perceive temporal variations and dynamics across frames. Experimental results on the Ref-AVS benchmark demonstrate that VoCa surpasses existing methods across multiple metrics, showcasing its effectiveness in handling complex multimodal information and temporal dependencies. We applied VoCa to several other audio-visual collaborative tasks and achieved competitive results, demonstrating the generalization of our method.},
  archive      = {J_ESWA},
  author       = {Cunhan Guo and Heyan Huang and Yang-Hao Zhou and Changsen Yuan and Danjie Han},
  doi          = {10.1016/j.eswa.2025.129371},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129371},
  shortjournal = {Expert Syst. Appl.},
  title        = {Leveraging mamba for reference audio-visual segmentation with vote and cache mechanism},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A modified IF-AHP intuitionistic fuzzy FMEA methodology to prioritize maintenance management deficiencies in a health care organization. <em>ESWA</em>, <em>297</em>, 129370. (<a href='https://doi.org/10.1016/j.eswa.2025.129370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance plays a very important role in healthcare organizations. The availability and safety of medical facilities and equipment can affect both patient waiting times for diagnosis, treatment, or rehabilitation, and healthcare and non-healthcare staff when using damaged or malfunctioning equipment by both. This impacts the quality of care and can have adverse consequences for people’s lives. Despite its importance, there is nonetheless an almost complete lack of research focused on continuous improvement that prioritizes failure modes in the field of hospital maintenance management. Furthermore, the literature recognizes that the traditional Failure Mode and Effects Analysis (FMEA) method has a number of shortcomings when used in real-world problems. Therefore, this research aims to create, for the first time, a classification of failure modes related to continuous improvement in the maintenance management services of a Spanish public general hospital. A modified Intuitionistic Fuzzy FMEA methodology will be used for this purpose, integrating the Intuitionistic Fuzzy Analytic Hierarchy Process (IF-AHP) and Intuitionistic Fuzzy Hybrid Weighted Euclidean Distance (IFHWED) operators, with four different distance measures. This is intended to incorporate the doubts and uncertainties present in real-world decision making. Expected cost has also been included along with traditional risk factors. Subjective weights are provided by IF-AHP, and objective weights are calculated by four different intuitionistic fuzzy entropy measures. The results show that the failure mode identified in the top position is Little or no technical qualifications in management.},
  archive      = {J_ESWA},
  author       = {María Carmen Carnero},
  doi          = {10.1016/j.eswa.2025.129370},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129370},
  shortjournal = {Expert Syst. Appl.},
  title        = {A modified IF-AHP intuitionistic fuzzy FMEA methodology to prioritize maintenance management deficiencies in a health care organization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A fuzzy multi-objective portfolio model with DEA cross-efficiency. <em>ESWA</em>, <em>297</em>, 129369. (<a href='https://doi.org/10.1016/j.eswa.2025.129369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional portfolio models often fail to capture the investor’s varying risk preferences of multiple objectives and the relative efficiency of candidate assets. To address multi-objective portfolio problem under fuzzy environment, this study employs fuzzy credibilistic mean and mean-absolute-semi-deviation (MASD) to quantify portfolio return and risk respectively. Additionally, fuzzy data envelopment analysis (DEA) is utilized to measure the cross-efficiency of invested assets. This paper proposes a novel fuzzy multi-objective portfolio optimization model that aims to maximize the credibilistic mean and cross-efficiency of the portfolio while minimizing MASD and Value-at-Risk (VaR) of the portfolio. By applying the weighted fuzzy programming method, the complex multi-objective portfolio model is transformed to a single-objective model, which is then solved using the designed genetic algorithm. Some numerical examples are provided to demonstrate the effectiveness of the proposed portfolio model. Comparative analyses are also conducted to highlight the advantages of the presented fuzzy portfolio model. The model can effectively reflect investors’ psychological factors by incorporating different objective preference vectors and confidence levels of VaR.},
  archive      = {J_ESWA},
  author       = {Qiansheng Zhang and Qimin Chen},
  doi          = {10.1016/j.eswa.2025.129369},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129369},
  shortjournal = {Expert Syst. Appl.},
  title        = {A fuzzy multi-objective portfolio model with DEA cross-efficiency},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Supply chain coordination and exchange rate risk hedging strategy under 3PL financing in cross-border e-commerce. <em>ESWA</em>, <em>297</em>, 129367. (<a href='https://doi.org/10.1016/j.eswa.2025.129367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion of cross-border e-commerce (CBEC), small and medium sized CBEC enterprises have become important drivers of economic growth. However, these enterprises often encounter capital constraints, demand uncertainty, and exchange rate fluctuations, all of which threaten their operational stability and competitiveness. Third-party logistics (3PL) enterprises that provide financing services can ease funding pressures, but effective decision making under multiple risk factors remains insufficiently addressed. Thus, this research develops a CBEC supply chain model that integrates capital constraints, demand uncertainty, and exchange rate risk. The model considers both decentralized and centralized scenarios, distinguishing between independent and coordinated decision making in the supply chain. It also reveals how each decision scenario influences overall supply chain performance, and analyzes the decision processes and coordination mechanisms for 3PL financing rate and overseas pricing strategy of CBEC enterprise. This study examines the combined effects of multiple risk factors on decision making under both decentralized and centralized scenarios, and incorporates an exchange rate hedging strategy into the decision model to comprehensively evaluate its mechanisms and effectiveness across different scenarios. The results indicate that optimal pricing is more robust under decentralized scenarios, whereas centralized scenarios show greater sensitivity to overseas market demand and exchange rate fluctuations. However, applying exchange rate risk hedging strategy in centralized scenarios can more effectively enhance the stability of pricing decisions for CBEC enterprise. Overall, this study provides both a theoretical foundation and practical guidance for 3PL and CBEC enterprises in decision making, supply chain coordination, and management within complex environments.},
  archive      = {J_ESWA},
  author       = {Jialu Ji and Mingjun Ji and Shengzhong Ji and Lingrui Kong},
  doi          = {10.1016/j.eswa.2025.129367},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129367},
  shortjournal = {Expert Syst. Appl.},
  title        = {Supply chain coordination and exchange rate risk hedging strategy under 3PL financing in cross-border e-commerce},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainability takes flight: A hybrid approach to optimizing air cargo routes. <em>ESWA</em>, <em>297</em>, 129366. (<a href='https://doi.org/10.1016/j.eswa.2025.129366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air cargo transportation is essential for businesses, even during global epidemics, wars, and other crises. To increase their competitiveness, airline companies develop strategic plans by prioritizing the addition of routes to new destinations. The primary reasons for do so include competition, enhanced profitability, and improved sustainability. This study uses a multi-criteria decision-making method to develop a solution approach for sustainable air cargo route selection (SACRS) originating from Turkey. More specifically, the study aims to contribute to the literature by proposing an integrated model for SACRS, determine the most sustainable routes originating from Turkey among the selected routes, rank them according to sustainability. The criteria were evaluated using Bayesian Best Worst Method (BBWM), while the routes were ranked according to the Measurement of Alternatives and Ranking according to the Compromise Solution (MARCOS) method. To demonstrate the accuracy and validity of the BBWM-MARCOS analysis results, they were compared with those of the BWM and VIKOR-TOPSIS methods. The ranking results were analyzed through a sensitivity analysis to demonstrate the accuracy and applicability of the proposed model. According to the experts’ answers, the most important criteria for evaluating sustainable air cargo route selection were the Economic and Commercial Criteria, with the most important sub-criteria being Season, Annual Cargo Volumes, and Competitor Density. Analysis of the proposed model indicated that the most sustainable route among the six examined was Shanghai, while the least sustainable route was Doha.},
  archive      = {J_ESWA},
  author       = {Mehmet Gurturk and Erkan Celik},
  doi          = {10.1016/j.eswa.2025.129366},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129366},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainability takes flight: A hybrid approach to optimizing air cargo routes},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Longest chain-based battery mule scheduling in a multi-UAV swarm. <em>ESWA</em>, <em>297</em>, 129365. (<a href='https://doi.org/10.1016/j.eswa.2025.129365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limited battery capacity has severely restricted the operating time of electric Unmanned Aerial Vehicles (UAVs), hindering their effectiveness in long-duration applications such as critical surveillance, large-scale infrastructure monitoring, and persistent communication relay. On-board battery swapping, where a battery “mule” replaces UAV batteries mid-air, is a promising solution for extending service continuity. Scheduling mule’s trajectory in a larbluege, dynamic swarm to maximize long-term Continuous Service Ratio (CSR) is challenging. To solve this problem, we formulate mule scheduling as an optimization problem maximizing swarm CSR. We propose a novel graph-based approach: (1) Constructing a directed graph where nodes represent UAVs and edges exist only if mule can feasibly travel between two UAVs while respecting their Latest Battery Swapping Times (LBST) and Gap Time Ratio (GTR) constraint; (2) Developing a longest chain algorithm that utilizes Depth-First Search (DFS) to find the longest feasible chain on this graph, maximizing number of UAVs served on-board per timeslot; (3) Designing auxiliary algorithms to merge isolated UAVs onto the longest chain under various scenarios. When accounting for practical communication interference, results from large-scale simulations demonstrate that our algorithm greatly outperforms seven mainstream scheduling benchmarks (including GreedyReloc and PEACO), achieving 91 % CSR under specific parameter constraints.},
  archive      = {J_ESWA},
  author       = {Xianglin Wei and Xiaolong Xu and Mingyu Li},
  doi          = {10.1016/j.eswa.2025.129365},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129365},
  shortjournal = {Expert Syst. Appl.},
  title        = {Longest chain-based battery mule scheduling in a multi-UAV swarm},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study of a matrix manufacturing system scheduling method considering equipment degradation. <em>ESWA</em>, <em>297</em>, 129363. (<a href='https://doi.org/10.1016/j.eswa.2025.129363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equipment reconfigurability and equipment degradation endow scheduling in Matrix Manufacturing System (MMS) with enhanced physical significance and more complex scheduling constraints. Equipment reconfigurability introduces setup time as the third temporal parameter in addition to traditional machining duration and logistics time, while equipment degradation-induced dynamic variability and real-time characteristics of real processing time supersede theoretical processing durations. This study innovatively addresses equipment degradation in MMS by proposing a Scheduling Problem in MMS with Real Processing Time (SPMMS-RPT). First, a mathematical model for SPMMS-RPT is constructed, comprehensively considering the impacts of equipment degradation and predictive maintenance (PM) on temporal parameters. Subsequently, a Double Deep Q Network (DDQN)-based solving algorithm designed, featuring a degradation-aware state space, a discrete scheduling rule-based action space, and a reward function incorporating virtual feedback. Experimental validation demonstrates the effectiveness of the proposed model and algorithm. Results indicate that the DDQN-based SPMMS-RPT solution achieves superior makespan and shorter computation time compared to conventional methods.},
  archive      = {J_ESWA},
  author       = {Fengque Pei and Hongwei Xiang and Cunbo Zhuang and Jianhua Liu and Jiaxuan Zhang and Chunguang Yang and Huihui Hao},
  doi          = {10.1016/j.eswa.2025.129363},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129363},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study of a matrix manufacturing system scheduling method considering equipment degradation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-period optimization model for hydroponic crop planning and scheduling in a centralized supply chain. <em>ESWA</em>, <em>297</em>, 129362. (<a href='https://doi.org/10.1016/j.eswa.2025.129362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient crop planning and scheduling pose significant issues in the hydroponic agriculture sector, particularly as the demand for high-quality and sustainable produce increases. Nonetheless, when multiple farms cultivate various crops with heterogeneous yields, independent decision-making often results in operational inefficiencies, underutilization of resources, and economic losses. Moreover, hydroponic crops possess a short growth cycle, necessitating regular decisions regarding which crops to cultivate at each period to satisfy market demand and volume. To address these challenges, this study proposes a centralized mathematical optimization model to coordinate crop production, harvest scheduling, and transportation across various hydroponic farms and crop varieties. The model incorporates unique yield characteristics, flexible harvesting windows, and resource and logistical limitations, with the goal of maximizing overall supply chain profitability. Applied to a real-world case involving hydroponic farms in Thailand, the proposed approach exhibited enhanced profit distribution among farms and improved resource utilization, outperforming previous decentralized methods. This study demonstrates the importance of integrated and data-driven supply chain management in supporting sustainable, profitable, and scalable hydroponic farming systems. The proposed approach provides both theoretical advancement in agricultural logistics modelling and practical decision support for the expanding hydroponic sector.},
  archive      = {J_ESWA},
  author       = {Manop Donmuen and Aganis Suntinac and Sirawadee Arunyanart},
  doi          = {10.1016/j.eswa.2025.129362},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129362},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-period optimization model for hydroponic crop planning and scheduling in a centralized supply chain},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Collaborative operation planning for post-disaster victim evacuation and relief distribution on considering heterogeneous rescue teams. <em>ESWA</em>, <em>297</em>, 129361. (<a href='https://doi.org/10.1016/j.eswa.2025.129361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the escalating frequency and intensity of natural disasters, participants of emergency rescue operations are expanding from professional rescue teams to all members of society. Improving the integration of diverse rescue forces and enhancing the efficiency of collaborative efforts are broadly endorsed as key strategies by governments and organizations around the world. To address the challenge of efficiently coordinating heterogeneous rescue teams with different qualifications, capabilities, and operational patterns, this paper introduces the Multi-type Rescue Teams Collaborative Operation Planning Problem (MRTCOPP). By considering heterogeneous rescue teams, multi-level disaster points, time-dependent travel speed, and other rescue operation constraints in post-disaster victim evacuation and relief distribution, the MRTCOPP comprehensively characterizes collaborative operation planning in complex emergency response scenarios. A Mixed Integer Linear Programming (MILP) model for MRTCOPP is developed by introducing a piecewise linear function of arc travel time. The model aims to minimize the total waiting time for rescue of all victims while considering constraints including maximum trip duration, maximum number of rescue visits, and minimum rest time. To efficiently solve this problem, an Improved Adaptive Large Neighborhood Search (I-ALNS) algorithm is proposed. I-ALNS employs three construction-based heuristics to generate initial solutions and utilizes an adaptive search strategy to improve these solutions iteratively. Combining a diverse set of problem-specific neighborhood structures with a pre-computation-based move evaluation technique, the I-ALNS algorithm demonstrates outstanding performance. Based on diverse disaster scenarios, comprehensive computational experiments are designed to validate the algorithm performance and reveal how disaster scenarios and key rescue team parameters impact collaborative rescue performance.},
  archive      = {J_ESWA},
  author       = {Ruiyang Li and Zhongbao Zhou and Enming Chen and Xing Luo and Lining Xing},
  doi          = {10.1016/j.eswa.2025.129361},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129361},
  shortjournal = {Expert Syst. Appl.},
  title        = {Collaborative operation planning for post-disaster victim evacuation and relief distribution on considering heterogeneous rescue teams},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integration of sustainable diet planning problem under neutrosophic fuzzy multi-objective optimization. <em>ESWA</em>, <em>297</em>, 129360. (<a href='https://doi.org/10.1016/j.eswa.2025.129360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable diet planning for diabetic individuals requires a complex trade-off among nutritional adequacy, cultural preferences, affordability, and environmental impact under uncertainty. Existing optimization approaches, including intuitionistic fuzzy sets (IFS), capture acceptance and rejection but fail to model indeterminacy, which is an important aspect of real-world dietary decisions. This study proposes a Neutrosophic Fuzzy Multi-objective Optimization (NFO) framework that incorporates truth, indeterminacy, and falsity membership functions to handle hesitancy in nutritional planning. The model optimizes the six conflicting objectives, maximizing the intake of fiber, protein, and carbohydrates and minimizing fat, sugar, and cost, subject to constraints aligned with Indian Council of Medical Research (ICMR) guidelines. A case study involving 11 common Indian food items across different age and gender groups validates the proposed framework. Comparative analysis with an IFS-based model and two variants of the NFO model reveals that NFO Model II consistently yields more balanced and robust diet plans across demographic groups. The proposed approach offers a computationally efficient and adaptable model for personalized diabetic meal planning, with broader implications for public health nutrition and sustainable food policy.},
  archive      = {J_ESWA},
  author       = {Kumari Divya and Prabjot Kaur},
  doi          = {10.1016/j.eswa.2025.129360},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129360},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integration of sustainable diet planning problem under neutrosophic fuzzy multi-objective optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MBCMEA: Multi-armed bandit model-based constraint multimodal multi-objective optimization algorithm. <em>ESWA</em>, <em>297</em>, 129359. (<a href='https://doi.org/10.1016/j.eswa.2025.129359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint optimization and multimodal optimization have always been important challenges in industrial production. Currently, a large number of constraint evolutionary algorithms have emerged in the field of multi-objective evolutionary algorithm research. However, there has been relatively little research on multimodal constraint optimization problems. In constrained multimodal optimization problems, the algorithm needs to simultaneously consider both the diversity and feasibility issues of each solution within a complex decision space. To address this issue, this paper proposes a Constraint Multimodal Multi-Objective Optimization Algorithm (MBCMEA) based on multi-armed bandit model, which effectively solves this problem. To effectively address the limitations imposed by complex constraint conditions on the search space, MBCMEA introduces a multi-armed bandit (MAB) model to assist the algorithm in selecting effective search directions and step sizes. Additionally, a specialized fitness function is employed to balance the constraint conditions and the multimodal objectives. The algorithm is designed in two phases and employs a fitness function specifically designed for multimodal problems. In the first phase, two distinct populations perform different explorations to obtain a high-quality set of solutions. In the second phase of the algorithm, effective information selected by the multi-armed bandit model is used to assist the algorithm in local search, uncovering additional non-dominated feasible solutions. The proposed MBCMEA algorithm has been tested on multiple benchmark problems and real-world problem. Experimental results demonstrate that the algorithm performs well and exhibits competitiveness in solving both constrained multi-objective and constrained multimodal multi-objective problems.},
  archive      = {J_ESWA},
  author       = {Lingyu Wu and Zenglin Qiao and Xinchao Zhao and Lingjuan Ye and Xingquan Zuo},
  doi          = {10.1016/j.eswa.2025.129359},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129359},
  shortjournal = {Expert Syst. Appl.},
  title        = {MBCMEA: Multi-armed bandit model-based constraint multimodal multi-objective optimization algorithm},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced active learning and library compression for high-dimensional evolutionary learning and seismic intensity attenuation relationship case. <em>ESWA</em>, <em>297</em>, 129358. (<a href='https://doi.org/10.1016/j.eswa.2025.129358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary learning algorithms offer powerful frameworks for addressing complex modeling and optimization tasks in domains ranging from engineering design to data analysis. Among these, Genetic Programming (GP) and its variants have proven effective for symbolic regression, automatically discovering mathematical expressions that fit data. In particular, Semantic GP (SGP) improves search by operating on program behaviors (semantics) rather than purely syntactic representations, leading to performance gains over standard GP. However, SGP faces the challenge of an intrinsically high-dimensional semantic space — each training point contributes one dimension — which exacerbates the curse of dimensionality and complicates the search. This paper proposes a novel approach to address this issue: High-Dimensional Efficient Semantic Genetic Programming (HDE-SGP). HDE-SGP integrates three key strategies to reduce semantic complexity: an active sampling mechanism that iteratively selects informative subsets of training data to focus the search (mitigating semantic dimensionality per generation), a semantic library compression method using OPTICS clustering to retain only diverse, representative solutions from the evolving population, and a rank-based semantic similarity measure (Spearman’s rank correlation) to guide crossover and selection toward behaviorally novel offspring. Experimental results on 16 benchmark symbolic regression datasets—covering both synthetic and real-world problems—show that, with almost no loss in predictive accuracy, HDE-SGP reduces average runtime by approximately 50 % and decreases evolved program size by nearly 50 % compared to conventional GP and SGP baselines. Moreover, a case study on the Seismic Intensity Attenuation Relationship further validates the effectiveness of the method.},
  archive      = {J_ESWA},
  author       = {Quanhong Li and Wang Hu and Yu Zhang},
  doi          = {10.1016/j.eswa.2025.129358},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129358},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced active learning and library compression for high-dimensional evolutionary learning and seismic intensity attenuation relationship case},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalizable deepfake detection framework using hybrid convolution-based EfficientNetB7 with attention mechanism. <em>ESWA</em>, <em>297</em>, 129357. (<a href='https://doi.org/10.1016/j.eswa.2025.129357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly realistic fake videos have been created by the deepfake technology in recent years. The political and societal consequences occurred because of the misinformation disseminated by the fake videos. To prevent these issues, automated approaches for deep fake detection are necessary. The deep fake video is detected in this work using hybrid deep learning. The main contribution of the proposed research is to determine deepfakes from videos, which aims to avoid the spread of malicious rumours. The differences between the real and deepfake videos are effectively identified through this developed approach, as they utilize the different features from the facial landmarks along with the eye blinks for determining the sophisticated fakes from the authenticated visual contents. The required videos are collected from the public databases. The frames are extracted from the collected videos. The attained video frames are given to the facial landmark detection process, where the coordinates of the eyes, lips, and nose are extracted. From these detected facial landmarks, the texture features, shape features, and the number of eye blinks are obtained for better detection purposes. The extracted features are integrated with the optimized weights for attaining the weighted fused feature, where the Updated Random Parameter-aided Fennec Fox Optimization (URP-FFO) is used for tuning the weights optimally. Each frame of 1-dimensional data forms 2-dimensional original video frames, which are taken as feature set 1 from the weighted fused features. The 3-dimensional data from the facial images is considered as feature set 2. The attained features are given to the Hybrid 2D-3D Convolution-based EfficientNetB7 with Attention Mechanism (HC-EB7AM) for differentiating the real and fake videos. The manipulated contents are easily identified by this approach. Finally, several measures are used for validating the performance. The potential strength of the proposed model is validated by the experimentation with the accuracy of 93.66% using dataset 1 and 94.38% using dataset 2, respectively.},
  archive      = {J_ESWA},
  author       = {Tirupathi Rajesh and S. Maruthupermal},
  doi          = {10.1016/j.eswa.2025.129357},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129357},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generalizable deepfake detection framework using hybrid convolution-based EfficientNetB7 with attention mechanism},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State estimation of subsea pipeline inspection gauge based on multi-mode signal composite decomposition and reconstruction. <em>ESWA</em>, <em>297</em>, 129356. (<a href='https://doi.org/10.1016/j.eswa.2025.129356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex environment inside subsea pipelines, the pipeline inspection gauge (PIG) often experiences significant velocity deviations under nonlinear, time-varying disturbances. Traditional mileage recording methods tend to incur large errors, which directly affect the accuracy of defect localization by the detector. To address the problem of estimating detector velocity under multi-modal aliased signals, this study proposes a hybrid speed estimation framework. Specifically, the proposed model decomposes the input signal using a Stable Complete Ensemble with Mirror-extended Noise (SCEMN) and a Robust Adaptive Variational Mode Decomposition (RAVMD) algorithm. The decomposition results are then reconstructed by assigning weights determined based on the distance correlation coefficient. The reconstructed signal is then used as the input to a hybrid deep learning model that combines an Autoregressive Integrated Moving Average (ARIMA) model and a residual-based Long Short-Term Memory (Res-LSTM) network, which is designed to extract long-term trends while capturing short-term fluctuations and nonlinear relationships. An experimental platform for PIG velocity estimation was established. Experimental results show that, under various conditions, the proposed method improves MAE by 17.6%-71.2% over mainstream signal reconstruction algorithms and by 9.8%-67.1% over deep learning models. The effectiveness of the proposed velocity estimation framework is validated, providing theoretical and technical support for achieving high-precision and robust PIG velocity estimation in complex environments.},
  archive      = {J_ESWA},
  author       = {Zhongchao Zhang and Guangqiu Wang and Yiming Li and Kai Huang},
  doi          = {10.1016/j.eswa.2025.129356},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129356},
  shortjournal = {Expert Syst. Appl.},
  title        = {State estimation of subsea pipeline inspection gauge based on multi-mode signal composite decomposition and reconstruction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SubG4TJ: A collaborative subgraph classification method based on multidimensional attributes for hardware trojan detection. <em>ESWA</em>, <em>297</em>, 129355. (<a href='https://doi.org/10.1016/j.eswa.2025.129355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of third-party Intellectual Property cores in Integrated Circuit design has introduced significant security risks, particularly the threat of hardware Trojans (HTs). Existing HT detection methods based on single-gate granularity analyze individual gate attributes but overlook the multi-gate structure of HTs, leading to excessive false positives and heavy manual verification. Comparatively, full-netlist analysis methods, while comprehensive, suffer from poor locating precision and scalability issues in large-scale netlists. Subgraph-based approaches aim to overcome these limitations but often rely on non-feature-based, non-collaborative techniques such as random sampling, to build subgraphs, incurring high computational overhead and low detection accuracy. To address these challenges, we propose SubG4TJ, a collaborative subgraph-based framework that integrates intrinsic gate attributes with structural connectivity for accurate and efficient HT detection. SubG4TJ identifies a specific class of gates – termed Less-Toggle Gates (LTGs) – that exhibit asymmetric 0/1 controllability, and introduces a concealment-based metric to quantify this property. By combining this intrinsic indicator with inter-gate structural features that capture Trojan interconnectivity, SubG4TJ enables targeted subgraph extraction centered on LTGs, substantially reducing analysis scope. A graph neural network then jointly model nodes’ concealment attributes and subgraphs’ topology features, enabling collaborative and end-to-end classification of suspicious subgraphs. This joint modeling of controllability asymmetry and structural connectivity allows SubG4TJ to effectively balance detection accuracy, false positive suppression, and runtime scalability. Evaluations in various benchmark circuits demonstrate that SubG4TJ improves true positive rate by up to 13.6 % and achieves a speed-up of 120 × , with performance gains increasing in larger designs.},
  archive      = {J_ESWA},
  author       = {Xing Hu and Yang Zhang and Sheng Liu and Xiaowen Chen and Yaohua Wang and Zhenyu Zhao and Yang Guo and Keqin Li},
  doi          = {10.1016/j.eswa.2025.129355},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129355},
  shortjournal = {Expert Syst. Appl.},
  title        = {SubG4TJ: A collaborative subgraph classification method based on multidimensional attributes for hardware trojan detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SKGRec: Unifying temporal dynamics and knowledge graphs for robust recommendations. <em>ESWA</em>, <em>297</em>, 129354. (<a href='https://doi.org/10.1016/j.eswa.2025.129354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems are crucial in domains like e-commerce and social media, where personalized content delivery enhances user engagement. Traditional collaborative filtering methods often struggle with data sparsity, cold-start issues, and dynamic user preferences. While recent approaches incorporate social networks and knowledge graphs to address these challenges, they fail to effectively model evolving social relationships, heterogeneous knowledge interactions, and noisy data structures. This paper introduces SKGRec , a novel unified framework that integrates temporal-aware social graphs and semantic-rich knowledge graphs to enhance recommendation robustness. Unlike existing methods, SKGRec dynamically models evolving user interactions while leveraging knowledge graph semantics to enrich representations and improve generalization. Through multi-scale temporal evolution modeling, SKGRec captures both short-term and long-term user preferences, while relation-aware knowledge aggregation enhances item understanding. To further improve representation learning and mitigate noise, SKGRec introduces cross-view contrastive learning, enforcing alignment between knowledge-enhanced interaction and social graphs. Additionally, a bidirectional knowledge distillation mechanism enables mutual refinement between models trained on user-item interactions and social structures, ensuring more robust and accurate recommendations. Extensive experiments on real-world datasets demonstrate that SKGRec significantly outperforms state-of-the-art methods, achieving up to 8.9 % performance improvement. These results underscore the effectiveness of fusing temporal, social, and knowledge-aware learning to advance recommendation quality and robustness.},
  archive      = {J_ESWA},
  author       = {Yichen Liu and Shengxi Fu and Qianqian Ren and Xingfeng Lv and Jinbao Li},
  doi          = {10.1016/j.eswa.2025.129354},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129354},
  shortjournal = {Expert Syst. Appl.},
  title        = {SKGRec: Unifying temporal dynamics and knowledge graphs for robust recommendations},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Electroencephalographic biomarker-guided early detection of alzheimer’s disease via cortically subdivided neurodynamic PINN. <em>ESWA</em>, <em>297</em>, 129353. (<a href='https://doi.org/10.1016/j.eswa.2025.129353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD), a prototypical neurodegenerative disorder, is characterized by aberrant amyloid-beta ( A β ) aggregation and hyperphosphorylated Tau-induced synaptic dysfunction. Noninvasive Electroencephalography (EEG) facilitates scalable screening yet encounters two fundamental constraints: spatial heterogeneity in neurophysiological feature representation and pathological cross-frequency coupling (CFC) decoding complexity. Addressing these intrinsic limitations, a computational method, CodimNet, is proposed to enhance AD early detection by utilizing 19-channel EEG signals. CodimNet incorporates a neuroanatomically stratified cortical partitioning mechanism, which enables region-specific feature extraction, mitigating cross-regional feature entanglement and preserving spatially distributed neurophysiological oscillations. To further refine spectral representations, we introduce the Neurodynamic Physics-Informed Neural Network (ND-PINN), an embedded spectral regularization module that enforces biologically informed constraints on frequency-domain power spectral density. Empirical evaluations on the largest publicly available EEG-based AD detection dataset, CAUEEG, validate CodimNet’s efficacy, achieving an impressive 76.27 % accuracy. The generalization performance was further evaluated on the Thessaloniki and Tehran datasets, achieving accuracies of 80.68 % and 72.57 %, respectively.CodimNet surpasses multiple mainstream AD detection benchmarks such as EEGNet and ShallowConvNet, excelling in classification robustness and discriminatory precision. The findings substantiate the capability of CodimNet to integrate spatiotemporal-frequency EEG features, delineating a computational framework with translational potential in clinical AD diagnostics. The code is publicly available at https://github.com/IMOP-lab/CodimNet .},
  archive      = {J_ESWA},
  author       = {Zhengliang Zhang and Yachen Wei and Xin Rao and Liyang Yu and Wen Sun and Ruixue Li and Xiaoshuai Zhang and Xiaodong Chen and Xingru Huang},
  doi          = {10.1016/j.eswa.2025.129353},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129353},
  shortjournal = {Expert Syst. Appl.},
  title        = {Electroencephalographic biomarker-guided early detection of alzheimer’s disease via cortically subdivided neurodynamic PINN},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond structural balance: Imbalance-aware embedding for signed networks. <em>ESWA</em>, <em>297</em>, 129352. (<a href='https://doi.org/10.1016/j.eswa.2025.129352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed networks encode both cooperative and antagonistic relationships, providing a powerful framework for modeling complex relational dynamics. However, most existing embedding methods are grounded in structural balance theory and rely on geometric proximity to preserve link polarity and balanced structures. Consequently, these approaches often fail to capture structurally unbalanced patterns that play a crucial role in bridging polarized communities while exaggerating group-level polarization in the original network. Recent studies reveal that node attribute heterogeneity is closely related to the emergence of such unbalanced patterns. To overcome this limitation, we propose a novel polarity link modeling framework that integrates geometric proximity and attribute similarity to jointly determine both the existence and sign of links. To validate its applicability to real-world signed networks, we instantiate this framework into a generative model, enabling the controlled synthesis of networks with varying proportions of balanced and unbalanced structures. Building on this, we introduce ISNE, an Imbalance-aware Signed Network Embedding method that dynamically adapts to the structural balance ratio of the input network. By maximizing the likelihood function between the observed and generated networks, ISNE learns node representations that not only preserve link polarity and balanced structures but also faithfully capture functionally significant unbalanced structures. Extensive experiments on synthetic and real-world signed networks demonstrate that ISNE substantially outperforms existing methods in link sign prediction tasks, particularly in networks with high proportions of unbalanced structures. These findings highlight the importance of modeling unbalanced patterns and the effectiveness of ISNE in advancing signed network representation.},
  archive      = {J_ESWA},
  author       = {Liang Du and Hao Jiang and Hui Lin and Hao Li},
  doi          = {10.1016/j.eswa.2025.129352},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129352},
  shortjournal = {Expert Syst. Appl.},
  title        = {Beyond structural balance: Imbalance-aware embedding for signed networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust learning framework for spatial-temporal-spectral radio map prediction. <em>ESWA</em>, <em>297</em>, 129351. (<a href='https://doi.org/10.1016/j.eswa.2025.129351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum map prediction, as one of the key technologies for spectrum situation generation, has garnered increasing attention. Although significant efforts have been devoted to spectrum map prediction, most existing spectrum map prediction schemes focus on the spatial-temporal domain (single frequency spectrum map prediction) with ideal spectrum measurements, neglecting inherent spectral correlations, missing data, and outliers. This work aims to achieve accurate spatial-temporal-spectral spectrum map prediction with incomplete and corrupted observations. A two-stage learning framework integrating deep learning and tensor completion is designed to address the above challenges. Specifically, we first model the spectrum map as a fourth-order spectrum tensor to fully exploit the inherent spatial-temporal-spectral structures of the spectrum data. Second, a developed Transformer with forget-sparse interpolation attention mechanism is employed to fill in partial values of the future spectrum map. Finally, we propose a novel online spectrum map prediction algorithm that integrates the Alternating Direction Method of Multipliers (ADMM) and Recursive Least Squares (RLS). Validated on real-world spectrum measurements, our proposed framework has a significant advantage over the state-of-the-art baselines.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Jun Hu and Dan Jiang and Zengping Chen},
  doi          = {10.1016/j.eswa.2025.129351},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129351},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust learning framework for spatial-temporal-spectral radio map prediction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-graph attention network for joint information extraction. <em>ESWA</em>, <em>297</em>, 129350. (<a href='https://doi.org/10.1016/j.eswa.2025.129350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transforming a sentence into a token graph shows great potential for supporting joint information extraction, where all edges can be simultaneously labeled to identify instances, e.g., named entities, relations and events. The main problem is that a sentence may contain various categories of knowledge and substantial instances. They lead to complicated semantic interactions, which are ignored in related works. Moreover, in joint information extraction, every token pair should be evaluated to find all possible labels. It also leads to a large ratio of negative instances. In this condition, a traditional deep network is hard to attend to positive instances. To address this challenge, we propose a Multi-Graph Attention Network (MGAN) to overcome the limitations of token graphs for joint information extraction. Specifically, MGAN explicitly models semantic interactions through two components: a Category Interaction Component (CIC) and an Instance Interaction Component (IIC). CIC dynamically captures dependencies among different semantic categories, while IIC refines instance-level edge confidence by emphasizing critical semantic instances. Evaluations on six public datasets show that our method achieves state-of-the-art performance, outperforming all baseline models. Analytical experiments demonstrate that MGAN effectively exploits interactions within token graphs, which enhances the discriminability of deep networks and significantly benefits joint information extraction and other NLP tasks.},
  archive      = {J_ESWA},
  author       = {Hui Huang and Yanping Chen and Chuan Lin and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129350},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129350},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-graph attention network for joint information extraction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A newly-constructed training dataset and an extremely-simplified network for copy-move forgery detection. <em>ESWA</em>, <em>297</em>, 129349. (<a href='https://doi.org/10.1016/j.eswa.2025.129349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most deep learning-based copy-move forgery (CMF) detection (CMFD) networks typically adopt the segmentation-based design principles without profoundly exploring copy-move tampered traces, which are key factors affecting the CMFD performance. Copy-move tampered traces are hidden by various transformations (e.g., rotation) that are exploited during the process of synthesizing CMFD training datasets to enhance the authenticity and diversity of each forged sample. The existing segmentation-based CMFD networks inherently utilize high-level semantic information between similar regions for detecting CMF, while ignoring tampered traces that are mainly contained in low-level features. In this paper, we innovatively present a very shallow CMFD network, named BCMNet, equipped with a high-quality synthetic training dataset (HQSTD), aiming at avoiding the loss of tampered traces and improving detection accuracy. HQSTD is constructed to preserve as many tampered traces as possible while maintaining the authenticity and diversity of the entire synthetic training dataset. BCMNet focuses on extracting low-level features while avoiding the extraction of redundant high-level features. BCMNet can notably boost the network’s sensitivity to copy-move tampered traces, and further enhancing the model’s generalization. The experimental results on three publicly available databases demonstrate that BCMNet significantly outperforms several state-of-the-art algorithms in terms of various evaluation metrics.},
  archive      = {J_ESWA},
  author       = {Liwen Chen and Tangguo Zhu and Shaowei Weng and Chunyu Zhang},
  doi          = {10.1016/j.eswa.2025.129349},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129349},
  shortjournal = {Expert Syst. Appl.},
  title        = {A newly-constructed training dataset and an extremely-simplified network for copy-move forgery detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards smart 6G: Mobility prediction for dynamic edge services migration. <em>ESWA</em>, <em>297</em>, 129348. (<a href='https://doi.org/10.1016/j.eswa.2025.129348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the challenge of maintaining high Quality of Service (QoS) of edge services provided to constantly moving devices, especially in urban environments such as connected vehicles. To support proactive service migration and maintain low latency in these environments we propose a long short-term memory model that predicts the end device trajectory in terms of future base stations. In our work, we have used traffic data from urban environments combined with wireless channel metrics from cellular networks to be able to generate an efficient predictive model that works well with varying traffic densities. Our experimental results show that the proposed model offers high accuracy in predicting an array of future coverage cells while remaining resilient to constantly changing traffic volumes and patterns. This study highlights the importance of unifying artificial intelligence and machine learning for dynamic resource orchestration and ensuring QoS in real-time applications operating on smart 6G networks.},
  archive      = {J_ESWA},
  author       = {Cristina Bernad and Aleksandra Dedinec and Katja Gilly and Sonja Filiposka and Anastas Mishev},
  doi          = {10.1016/j.eswa.2025.129348},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129348},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards smart 6G: Mobility prediction for dynamic edge services migration},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ExSGD: Exploiting previous gradient for distributed large-batch training of building extraction network. <em>ESWA</em>, <em>297</em>, 129347. (<a href='https://doi.org/10.1016/j.eswa.2025.129347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed large-batch training offers an effective way to accelerate the training of deep convolutional neural network (DCNN) on massive labeled datasets. However, the exploration of distributed large-batch training for building extraction is still in its infancy, lacking tailored optimization algorithm and with unsatisfactory performance. In this paper, we propose an extrapolative stochastic gradient descent (ExSGD) algorithm for building extraction tasks under distributed large-batch training. On the one hand, since gradient loss is inevitable in distributed large-batch training and often leads to suboptimal performance of DCNN, ExSGD collects gradient distributions from previous epochs and aggregates them based on temporal characteristics, effectively strengthening the gradient signal for optimizing the building extraction network. Furthermore, in order to enhance convergence stability under distributed large-batch training, ExSGD introduced an adaptive layer-wise learning rate strategy that leverages parameter distributions to regulate the learning rate for each layer, thereby helping the building extraction network escape locally optimal solutions. We further establish an error bound under the risk minimization framework to theoretically guarantee the of the convergence and stability of ExSGD. Experimental results on three building extraction datasets show that ExSGD consistently outperforms state-of-the-art optimizers, AdaBelief and Shampoo, achieving up to 14.3 % improvement in F1 and 16.56 % in IoU under large-batch distributed training.},
  archive      = {J_ESWA},
  author       = {Panle Li and Xiaohui He and Tao Zhou and Mengjia Qiao and Xijie Cheng and Haofei Li and Mingkai Yue and Lei Zhang and Jiandong Shang},
  doi          = {10.1016/j.eswa.2025.129347},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129347},
  shortjournal = {Expert Syst. Appl.},
  title        = {ExSGD: Exploiting previous gradient for distributed large-batch training of building extraction network},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Density-guided two-stage small object detection in UAV images. <em>ESWA</em>, <em>297</em>, 129346. (<a href='https://doi.org/10.1016/j.eswa.2025.129346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in Unmanned Aerial Vehicle (UAV) images is highly challenging due to the sparse distribution, local clustering of objects, and the small size of objects caused by long shooting distances, making it difficult to achieve accurate localization in high-resolution UAV images. Traditional methods struggle to capture small object features in dense regions, limiting their effectiveness in improving detection performance. To address these issues, we propose a Density-Guided Two-Stage Object Detection (DG-TSOD) framework for recognizing small objects. First, we design a dense object region seeker that focuses on high-density areas, enabling density-guided training and inference. Second, to enhance the accuracy of bounding box regression, we introduce the normalized Wasserstein distance as the loss function. This metric offers significant advantages for small object detection due to its scale invariance, smooth response to positional deviations, and ability to measure similarity between non-overlapping boxes. Finally, efficient multi-scale and deformable convolution modules are employed in the detection head to enhance multi-scale object localization without significantly increasing computational cost. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the VisDrone, UAVDT, and TinyPerson datasets.},
  archive      = {J_ESWA},
  author       = {Bojun Xie and Yanjie Wang and Meihui Han and Yidan Wang and Junfen Chen},
  doi          = {10.1016/j.eswa.2025.129346},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129346},
  shortjournal = {Expert Syst. Appl.},
  title        = {Density-guided two-stage small object detection in UAV images},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffBlender: Composable and versatile multimodal text-to-image diffusion models. <em>ESWA</em>, <em>297</em>, 129345. (<a href='https://doi.org/10.1016/j.eswa.2025.129345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we aim to enhance the capabilities of diffusion-based text-to-image (T2I) generation models by integrating diverse modalities beyond textual descriptions within a unified framework. To this end, we categorize widely used conditional inputs into three modality types: structure, layout, and attribute. We propose a multimodal T2I diffusion model, DiffBlender, which is capable of processing all three modalities within a single architecture. Importantly, this is achieved without modifying the parameters of the pre-trained diffusion model, as only a small subset of components is updated. Our approach sets new benchmarks in multimodal generation through extensive quantitative and qualitative comparisons with existing conditional generation methods. We demonstrate that DiffBlender effectively integrates multiple sources of information and supports diverse applications in detailed image synthesis. The code and demo are available at https://github.com/sungnyun/diffblender .},
  archive      = {J_ESWA},
  author       = {Sungnyun Kim and Junsoo Lee and Kibeom Hong and Daesik Kim and Namhyuk Ahn},
  doi          = {10.1016/j.eswa.2025.129345},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129345},
  shortjournal = {Expert Syst. Appl.},
  title        = {DiffBlender: Composable and versatile multimodal text-to-image diffusion models},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). One-shot motion talking head generation with audio-driven model. <em>ESWA</em>, <em>297</em>, 129344. (<a href='https://doi.org/10.1016/j.eswa.2025.129344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exciting achievements have been made in audio-driven face-talking head generation. However, while existing methods excel at generating a speaking head from a frontal identity image, generating a speaking head with a head pose does not yield satisfactory results when the identity is based on a side image of the face. To address this limitation, a concise and effective approach is proposed in this work. Our method generates efficient talking head videos using a side face image as the identity. It uses facial features and head posture to predict frontal keypoints, during which facial expression features are added as additional features. The method achieves impressive head motion effects and maintains identity information consistency during motion. Additionally, a Transform-based lip-sync expert discriminator is designed to guide the lip synchronization of the generated video. A cross-attention is employed to jointly learn the front and back frames, extracting contextual information that improves lip synchronization over long sequences. Our method is tested on several datasets, such as VoxCeleb2 and LRS2, and compared with multiple advanced methods, demonstrating its outstanding performance through experiments.},
  archive      = {J_ESWA},
  author       = {Peng Tang and Huihuang Zhao and Weiliang Meng and Yaonan Wang},
  doi          = {10.1016/j.eswa.2025.129344},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129344},
  shortjournal = {Expert Syst. Appl.},
  title        = {One-shot motion talking head generation with audio-driven model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Supply chain competition and enterprise channel structure selection strategies considering product brand differentiation and greenness. <em>ESWA</em>, <em>297</em>, 129343. (<a href='https://doi.org/10.1016/j.eswa.2025.129343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the backdrop of growing eco-conscious consumption, consumers increasingly prioritize low-carbon, energy-efficient green products, with brand preference and product greenness (PGS) being key purchase drivers. This study models a two-echelon supply chain with two competing firms to analyze how product brand differentiation (PBD) and PGS affect supply chain channel structure choices in competitive settings. Using game theory, it can be found that increasing PGS boosts firm-retailer profits and social welfare, while higher PBD reduces consumer surplus and social welfare. When PBD is low, competing firms’ PGS enhancements may decrease consumer surplus, whereas the opposite holds under high PBD. Firms tend to favor decentralized channels, but this structure harms consumer interests and social welfare. As firms invest more in greenness, government policies are critical to incentivize direct-sales channels for improved social welfare. However, goal misalignment between governments and firms creates a decision-making dilemma. This research highlights the need for firms to balance PGS and PBD, and for governments to design policies aligning channel choices with public welfare.},
  archive      = {J_ESWA},
  author       = {Lei Yan and Wei Yu and Manfang Deng},
  doi          = {10.1016/j.eswa.2025.129343},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129343},
  shortjournal = {Expert Syst. Appl.},
  title        = {Supply chain competition and enterprise channel structure selection strategies considering product brand differentiation and greenness},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAML-based temporal supervised information maximizing GAN for few-shot time series data generation. <em>ESWA</em>, <em>297</em>, 129342. (<a href='https://doi.org/10.1016/j.eswa.2025.129342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating high–quality data in industrial scenarios poses major challenges due to poor data quality, changing working conditions, and high labeling costs. This paper focuses on few-shot learning in situations characterized by temporal complex and high–dimensional data. A novel framework, the model–agnostic meta–learning–based temporal supervised information maximizing generative adversarial network (MAML-T-InfoGAN), is designed to generate data from limited samples ensuring temporal consistency with actual industrial processes. The approach combines innovations at both the model and algorithmic levels. The T-InfoGAN improves temporal alignment of generated data, while the MAML strategy optimizes network parameters for quick adaptation to few-shot learning tasks, thereby enhancing data generation efficiency. Recognizing inadequacies in current evaluation metrics for few-shot data generation, a comprehensive evaluation framework is proposed, considering fit quality, clustering characteristics, temporal correlation, and effectiveness in fault diagnosis scenarios. Validation on the Tennessee Eastman Process demonstrates that MAML-T-InfoGAN outperforms existing methods across multiple metrics, highlighting its superiority in addressing industrial few-shot data generation challenges.},
  archive      = {J_ESWA},
  author       = {Hanwen Zhang and Houze Guo and Haojie Bai and Chuanfang Zhang and Linlin Li},
  doi          = {10.1016/j.eswa.2025.129342},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129342},
  shortjournal = {Expert Syst. Appl.},
  title        = {MAML-based temporal supervised information maximizing GAN for few-shot time series data generation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-scale representation and multi-level decision learning network for multimodal sentiment analysis. <em>ESWA</em>, <em>297</em>, 129341. (<a href='https://doi.org/10.1016/j.eswa.2025.129341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) involves fusing multimodal information from different modalities to predict sentiment states, such as spoken language, acoustic features, and facial expressions. Previous efforts in this area mainly focus on sequential multimodal learning and rely on single-level representations for final decision. However, these methods fail to learn and leverage multimodal information present in different layers to achieve accurate sentiment prediction. To address these issues, this paper proposes a novel M ulti-scale representation and M ulti-level decision L earning N etwork (MMLN) for multimodal sentiment analysis. Specifically, a Hybrid Multi-scale Transformer (HMT) module is developed to progressively learn multimodal representations across multiple scales. HMT employs shared routing tokens to collect and aggregate multimodal information of different layers, with each layer corresponding to a specific scale. Moreover, a Layer-wise Correlation Learning (LCL) module is incorporated to refine the multi-scale representations and enhance cross-modal dependencies. LCL minimizes the Jensen-Shannon divergence to encourage the model to facilitate representation learning and fusion at each scale. Ultimately, a Multi-level Decision Fusion (MDF) module is introduced to leverage refined multi-scale representations to produce multiple layers of prediction results that are adaptively fused to enhance sentiment prediction robustness. Extensive experiments on four widely-recognized MSA datasets (two in English and two in Chinese) demonstrate that MMLN outperforms the current leading baselines on most evaluation metrics. Notably, on the MOSEI dataset, our model achieves the best Acc-7 and binary accuracy of 54.6 % and 86.7 %, respectively, with comparable improvements observed across the other benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Xiang Li and Zhiqiang Dong and Xianfu Cheng and Dezhuang Miao and Haijun Zhang and Tianbo Wang and Xiaoming Zhang and Zhoujun Li},
  doi          = {10.1016/j.eswa.2025.129341},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129341},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-scale representation and multi-level decision learning network for multimodal sentiment analysis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learn from the best: A universal self-distillation approach with historical logits. <em>ESWA</em>, <em>297</em>, 129340. (<a href='https://doi.org/10.1016/j.eswa.2025.129340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, deep learning has made significant progress and has become a prominent area of artificial intelligence. During the training process of deep neural networks, a large amount of diverse historical data is accumulated, including gradients, model weights, features, logits, probability distributions, and losses. These historical data can be used to help train the current model. Recent studies have tried to use the last epoch/batch’s probability distribution as soft labels to supervise the training of the current model. However, the last epoch/batch’s probability distribution may not be optimal for the current training, resulting in limited performance improvements. In this paper, we introduce a simple and universal method called L earn F rom the B est (LFB). We introduce the concept of “the best”, which is reflected in two levels: the best historical model weights and dynamic supervision. To achieve sample-level logits supervision, we introduce a dynamic loss function called Historical Logits Contrastive (HLC) loss. Our method has been extensively evaluated on various benchmark datasets, demonstrating its universality and effectiveness. Compared to various self-distillation and regularization methods, the LFB method has achieved state-of-the-art performance. Furthermore, additional experimental analysis has shown that this method achieves rapid convergence and exhibits remarkable anti-overfitting and anti-noise capabilities.},
  archive      = {J_ESWA},
  author       = {Lida Shi and Fausto Giunchiglia and Hongda Zhang and Daqian Shi and Rui Song and Jian Li and Xiaolei Diao and Alan Zhao and Hao Xu},
  doi          = {10.1016/j.eswa.2025.129340},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129340},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learn from the best: A universal self-distillation approach with historical logits},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overtake detection in trucks using CAN bus signals: A comparative study of machine learning methods. <em>ESWA</em>, <em>297</em>, 129339. (<a href='https://doi.org/10.1016/j.eswa.2025.129339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe overtaking manoeuvres in trucks are vital for preventing accidents and ensuring efficient traffic flow. Accurate prediction of such manoeuvres is essential for Advanced Driver Assistance Systems (ADAS) to make timely and informed decisions. In this study, we focus on overtake detection using Controller Area Network (CAN) bus data collected from five in-service trucks provided by the Volvo Group. We evaluate three common classifiers for vehicle manoeuvre detection, Artificial Neural Networks (ANN), Random Forest (RF), and Support Vector Machines (SVM), and analyse how different preprocessing configurations affect performance. We find that variability in traffic conditions strongly influences the signal patterns, particularly in the no-overtake class, affecting classification performance if training data lacks adequate diversity. Since the data were collected under unconstrained, real-world conditions, class diversity cannot be guaranteed a priori. However, training with data from multiple vehicles improves generalisation and reduces condition-specific bias. Our per-truck analysis also reveals that classification accuracy, especially for overtakes, depends on the amount of training data per vehicle. To address this, we apply a score-level fusion strategy, which yields the best per-truck performance across most cases. Overall, we achieve an accuracy via fusion of TNR =93 % (True Negative Rate) and TPR =86.5 % (True Positive Rate). This research has been part of the BIG FUN project, which explores how Artificial Intelligence can be applied to logged vehicle data to understand and predict driver behaviour, particularly in relation to Camera Monitor Systems (CMS), being introduced as digital replacements for traditional exterior mirrors.},
  archive      = {J_ESWA},
  author       = {Fernando Alonso-Fernandez and Talha Hanif Butt and Prayag Tiwari},
  doi          = {10.1016/j.eswa.2025.129339},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129339},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overtake detection in trucks using CAN bus signals: A comparative study of machine learning methods},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interactive multiple instance learning network for whole slide image analysis. <em>ESWA</em>, <em>297</em>, 129338. (<a href='https://doi.org/10.1016/j.eswa.2025.129338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whole Slide Image (WSI) classification presents unique challenges in digital pathology due to gigapixel-scale images and complex tissue structures. While Multiple Instance Learning (MIL) has emerged as a promising approach for WSI analysis, existing methods often overlook crucial textual information and contextual correlations between instances. We propose an interactive multiple-instance learning (iMIL) framework that addresses these limitations through two novel perspectives: Multiple-instance Aggregation and Prompt-Guided Attention. The Multiple-instance aggregation module effectively combines instance-level features (local details), slide-level features (global context), and clinical textual information, providing a more comprehensive representation of each WSI. The Prompt-Guided Attention module employs learnable prompts to modulate the network’s attention toward specific features within instances, enabling the model to focus on lesion-relevant areas even with weak annotations. Additionally, an Interactive Refinement Module enables continuous model improvement through multiple-level features and contextual information feedback. Our framework uniquely integrates visual patterns with associated clinical textual information to establish accurate correspondences from slide-level to instance-level features under weak supervision. Experimental results verify that iMIL consistently outperforms SOTA MIL models across multiple public WSI datasets, significantly improving both WSI classification and positioning performance through interactive pseudo-label reasoning.},
  archive      = {J_ESWA},
  author       = {Qi Lai and Chi-Man Vong and Tao Yan and Xiaokun Liang},
  doi          = {10.1016/j.eswa.2025.129338},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129338},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interactive multiple instance learning network for whole slide image analysis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable named entity recognition via integrating logical rule learning with deep neural networks. <em>ESWA</em>, <em>297</em>, 129337. (<a href='https://doi.org/10.1016/j.eswa.2025.129337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been grappling with limited interpretability, whereas logical rule learning methods offer clear interpretability. Research has shown that neural networks adapting logical rules perform remarkably well and offer interpretability in visual and graph-related tasks. However, in language-related tasks, recent advancements in logical rule learning have mainly concentrated on text classification. Exploring the fusion of logical rule learning and neural networks in tasks like named entity recognition (NER) remains uncharted territory. Hence, to bridge this gap, we propose a new method called knowledge-aware deep logic learning (KDL) explicitly designed for NER, emphasizing interpretability. We delve into implementing KDL for bidirectional recurrent neural networks (BRNNs) and empirically validate its efficacy, demonstrating that KDL excels in performance and interpretability by integrating label knowledge and learning logical rules. Particularly, BRNN with KDL outperforms the recent interpretable baselines with significant improvements of 3.57 %, 3.09 %, 2.66 %, 1.15 % and 1.19 % in terms of macro F 1 metric on GEVIA dataset. Furthermore, we conduct case studies to illustrate how KDL generates explanations consistent with the underlying decision-making logic of deep models through causal reasoning. Our assessment showcases that KDL offers explanations consistent with the decision logic of these models. We also uncover the concepts deep models rely on for decision-making and investigate how KDL-based BRNNs aid users by conducting a comparative experiment involving humans.},
  archive      = {J_ESWA},
  author       = {Yulin Chen and Bo Yuan and Beishui Liao and Dov M. Gabbay and Lu Cheng},
  doi          = {10.1016/j.eswa.2025.129337},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129337},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable named entity recognition via integrating logical rule learning with deep neural networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep durrmeyer neural network interpolation: A multilayer kernel-based framework for function approximation and functional connectivity. <em>ESWA</em>, <em>297</em>, 129336. (<a href='https://doi.org/10.1016/j.eswa.2025.129336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical interpolation methods struggle with high-dimensional, complex data, while shallow neural network operators lack the expressive power for hierarchical patterns. This paper introduces the Deep Durrmeyer Neural Network Interpolation (DDNNI) operator, a novel framework designed to bridge this gap by integrating the mathematical rigor of approximation theory with the power of deep architectures. The primary objective is to create a robust, stable, and highly flexible deep neural network operator for advanced function approximation. Our method is built on a multi-layered structure where an inner neural operator performs a non-linear coordinate transformation before a Durrmeyer-type outer layer conducts kernel-based weighted averaging. The framework’s originality is further established by a new class of tunable, multi-dimensional activation functions and a dual-kernel design that ensures both precision and stability, overcoming limitations of traditional methods. The practical significance and superiority of this method are demonstrated in a challenging application: enhancing dynamic functional connectivity (dFC) analysis from fMRI time series. Traditional connectivity analyses suffer from noise and low temporal resolution, which obscure true neural interactions. By applying DDNNI as a signal enhancement step, we show that Transfer Entropy (TE)-based connectivity estimates become significantly more stable and robust. Our results reveal stronger, more biologically meaningful neural pathways and, crucially, allow for the detection of transient neural events–short-lived bursts of information flow–that are invisible in the raw data. Our work makes several original contributions: we provide the full theoretical construction of the DDNNI operator with proofs of its convergence properties; we demonstrate its superior accuracy against other NN-based methods in numerical benchmarks; and we validate its real-world utility in a complex neuroscientific problem. DDNNI offers a scalable and powerful solution for interpolation-driven data enhancement, with significant potential for applications in signal processing, geospatial modeling, and reinforcement learning.},
  archive      = {J_ESWA},
  author       = {Ugur Kadak},
  doi          = {10.1016/j.eswa.2025.129336},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129336},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep durrmeyer neural network interpolation: A multilayer kernel-based framework for function approximation and functional connectivity},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaBIR: A residual pyramid network for brain image registration with state-space model. <em>ESWA</em>, <em>297</em>, 129335. (<a href='https://doi.org/10.1016/j.eswa.2025.129335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain image registration faces two primary challenges. First, the complex non-rigid deformations of brain tissue—encompassing global displacements, rotations, and localized distortions such as stretches—pose significant difficulties for accurate registration. Second, traditional methods often demand extensive computational resources that exceed the capabilities of standard computing equipment. To address these challenges, we propose a pyramidal brain image registration model, termed MambaBIR (Mamba-based Brain Image Registration), a residual pyramid network for brain image registration with a state-space model. Specifically, we develop a pyramid-based registration framework that processes brain images at multiple levels of granularity to enhance registration accuracy. Additionally, we incorporate a state-space model architecture into the encoder, which efficiently handles large-scale sequence data with reduced computational complexity, thereby mitigating resource constraints. Lastly, we design an all-level semantic information transfer strategy to facilitate effective feature fusion across different pyramid levels, minimize detail loss during transfer, and ensure high-quality registration results. Our model was trained and evaluated using two public datasets (Mindboggle, IXI) and clinical datasets. Experimental results demonstrate that MambaBIR outperforms state-of-the-art methods in registration accuracy. On the evaluated datasets, it achieves a Dice score of up to 65.5 % and an ASSD score of 1.22, while also showing significant improvements in both HD95 and the percentage of voxels with a non-positive Jacobian determinant. The code is available at: https://github.com/wxy425/EMambaBIR/tree/master .},
  archive      = {J_ESWA},
  author       = {Yonglin Chen and Xiye Wang and Chen Qian and Xuanru Guan and Xingliang Dai and Peng Gao},
  doi          = {10.1016/j.eswa.2025.129335},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129335},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaBIR: A residual pyramid network for brain image registration with state-space model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SV-2DGS: Optimization of sparse view 3D reconstruction based on 2DGS models. <em>ESWA</em>, <em>297</em>, 129334. (<a href='https://doi.org/10.1016/j.eswa.2025.129334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of three-dimensional reconstruction, recovering structure from scene images captured from sparse viewpoints has always been a challenging task. The currently popular 3DGS model often encounters issues of blurry rendered scenes and inconsistencies in Gaussian ellipsoids when processing sparse viewpoint data, leading to increased errors. To address these, this study proposes the SV-2DGS model, an optimization method for three-dimensional reconstruction from sparse views based on 2DGS. This model primarily optimizes the point cloud matching in Colmap and the 2DGS reconstruction process. To capture details from blurry views, SV-2DGS introduces a data augmentation framework within Colmap, employing feature extraction and upsampling techniques to generate high-resolution three-dimensional point clouds and camera poses. Furthermore, to enhance the consistency of reconstruction, SV-2DGS employs Gaussian disc reconstruction techniques, which focus on reconstructing those discs with high proximity values by constructing a proximity graph of the Gaussian disk, thereby achieving a smoother reconstruction outcome. Through case analysis, this study demonstrates that SV-2DGS achieves a 0.399 dB improvement in PSNR compared to the pre-optimized 2DGS model, exhibiting outstanding reconstruction accuracy and detail capture in 24-view and high-clarity scenes. Additionally, experiments conducted on self-collected datasets confirm that the SV-2DGS model is suitable for reconstructing low-pixel scene images captured with non-professional equipment in everyday life.},
  archive      = {J_ESWA},
  author       = {Ming Liu and Yuxuan Liang and Siwei Chen and Junjie Wang and Yang Na},
  doi          = {10.1016/j.eswa.2025.129334},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129334},
  shortjournal = {Expert Syst. Appl.},
  title        = {SV-2DGS: Optimization of sparse view 3D reconstruction based on 2DGS models},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced recommendation with hypergraph mixture of experts. <em>ESWA</em>, <em>297</em>, 129333. (<a href='https://doi.org/10.1016/j.eswa.2025.129333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference modeling based on hypergraphs has shown significant potential in recommender systems. However, existing methods model complex higher-order relations rely on existing hypergraph structures, such well-constructed hypergraphs are not readily accessible in every situation. Furthermore, since existing methods perform message-passing based on the same hypergraph convolution function, they often overlook diverse relation patterns, thus lacking precision. In this work, we propose an Enhanced Recommendation Framework with Hypergraph Mixture of Experts (HMoRec). Specifically, we first employ a sparse optimal transport clustering mechanism to generate high-quality hypergraph without requiring external knowledge. Then, we model diverse higher-order interactions and enhance representation learning based on the hypergraph mixture of experts and cross-view representation fusion. Extensive experiments on four real-world multi-domain datasets have shown that our HMoRec achieves significant performance gains.},
  archive      = {J_ESWA},
  author       = {Zihao Zhou and Zhijun Chen and Guofang Ma and Zhenghong Lin and Yanchao Tan and Shiping Wang and Carl Yang},
  doi          = {10.1016/j.eswa.2025.129333},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129333},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced recommendation with hypergraph mixture of experts},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A edge prior constraint mamba network for medical image super-resolution generation. <em>ESWA</em>, <em>297</em>, 129331. (<a href='https://doi.org/10.1016/j.eswa.2025.129331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning-based algorithms for super-resolution generation of medical images are usually based on convolutional architecture or transformer module. Algorithms based on convolutional architecture are limited by the inherent inductive bias to efficiently acquire global contextual information, while algorithms based on transformer module cannot be practically deployed due to the high computational cost. To overcome these problems, a cyclic scanning Mamba network is guided by edge prior knowledge constraints for achieving super-resolution generation of medical images. In this paper, we propose to integrate the Mamba module into the Unet network to acquire long range dependencies between regions in medical images at a small computational cost. In addition, a sequence cyclic scanning component is designed to process the input image sequences from both forward and backward directions, which enhances the sensitivity of our model to changes in orientation information. Meanwhile, an edge prior control module is developed to add additional steering features and constraints to the generation process. The results of our comparison and ablation experiments show that the super-resolution performance and computational resource occupancy outperform existing methods on IXI and fastMRI medical image datasets. The downstream visual task of brain tumour segmentation using a medical image segmentation network also shows the effectiveness of our method with a mean Dice Score of 57.73 % on the BraTS2021 dataset.},
  archive      = {J_ESWA},
  author       = {Boyu Zhao and Qian Zhou and Weichao Li and Yingying Xie},
  doi          = {10.1016/j.eswa.2025.129331},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129331},
  shortjournal = {Expert Syst. Appl.},
  title        = {A edge prior constraint mamba network for medical image super-resolution generation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Digital twin development and implementation for the management of irrigation networks. <em>ESWA</em>, <em>297</em>, 129330. (<a href='https://doi.org/10.1016/j.eswa.2025.129330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Twin (DT) developments for design, construction and infrastructure management are gaining presence in both research and practice environments nowadays. Its implementation in many infrastructure types, such as roads, railways, and power transmission lines, have shown important benefits: multidisciplinary coordination, advanced visualisation, analysis, data and project lifecycle management. DT can help decision-making process of project planning, design, construction, and management supported by communication between the physical and the digital assets, in this case, applied to irrigation systems. By leveraging Digital Twins, stakeholders can overcome the challenges with advantages such as accuracy, real-time data access, cost-effectiveness, and long-term sustainability. Nevertheless, infrastructure digitalization not only hosts benefits, also it carries many challenges as the lack of knowledge for its usage, accessibility or interoperability. This study shows an example by deploying an online cloud platform to digitalise a traditional irrigation network located at Alicante University (UA). It also discusses the challenges of traditional design methods, such as coordination issues, limited visualization, and inefficient data management. Furthermore, it emphasizes the benefits of integrated design and collaboration, enhanced visualization, and efficient data management and documentation. This platform provides with critical information to managers and stakeholders of pressurized irrigation networks and decision-makers. With this project, essential data is available, ensuring successful operation and data-backed decisions can be taken. This innovative project has not only addressed the data gathering challenges but has also introduced a new platform for displaying real-time data and incidents management.},
  archive      = {J_ESWA},
  author       = {R. Muñoz Pavón and O. Galao and M.A. Pardo and M.G. Alberti},
  doi          = {10.1016/j.eswa.2025.129330},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129330},
  shortjournal = {Expert Syst. Appl.},
  title        = {Digital twin development and implementation for the management of irrigation networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved large-scale multi-objective competitive swarm optimizer with direction learning and decision enhancement. <em>ESWA</em>, <em>297</em>, 129328. (<a href='https://doi.org/10.1016/j.eswa.2025.129328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-objective optimization aims to acquire a set of approximate Pareto-optimal solutions in the decision space, but its performance faces significant challenges brought by complex local optimal solutions and a huge search space. With the competitive update paradigm, the competitive swarm optimizer (CSO) has demonstrated stronger convergence capabilities than other meta-heuristic approaches in large-scale multi-objective optimization problems (LSMOPs). However, there are still two shortcomings that hamper the scalability of the optimizer. (1) The search direction of CSO is mainly determined by the positions of two randomly paired particles, which may lead to inefficiency in large-scale decision spaces and requires substantial computing resources. (2) CSO may be significantly influenced by a subset of clustered elite particles, leading to local-optimal convergence. In this paper, we address the first shortcoming by integrating historical convergence trends into the particle update mechanism, which can provide a more informed evolutionary trajectory than mere particle velocity. For the second issue, we perform a perturbation search on the extracted diversity-related variables to effectively mitigate the population degradation during the exploration process. Furthermore, we apply the proposed CSO into a decomposition-based framework to achieve a trade-off between convergence and diversity in LSMOPs. The experimental results demonstrate that our algorithm is more competitive than six other state-of-the-art peer algorithms on both LSMOP/LMF benchmarks and a real-world problem.},
  archive      = {J_ESWA},
  author       = {Juan Zou and Maolin Zhou and Zhanglu Hou and Yuan Liu and Hui Bai and Jinhua Zheng},
  doi          = {10.1016/j.eswa.2025.129328},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129328},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved large-scale multi-objective competitive swarm optimizer with direction learning and decision enhancement},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Q-learning-based hyper-heuristic algorithm for priority and precedence dual-driven task assignment in spatial crowdsourcing. <em>ESWA</em>, <em>297</em>, 129327. (<a href='https://doi.org/10.1016/j.eswa.2025.129327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spatial crowdsourcing, a core issue is to formulate an effective task assignment plan, based on the bipartite matching between the two parties, i.e. , workers and tasks. In this context, one key challenge is how to suitably assign tasks to available workers and determine their execution order, with the consideration of the priority of all tasks, under the precedence constraint of tasks. To this end, we investigate an important problem, namely, priority and precedence dual-driven task assignment problem in spatial crowdsourcing (PDTAP-SC). A Q -learning-based hyper-heuristic (QLHH) algorithm is proposed to address this problem, which strives to simultaneously minimize the task completion time ( i.e. , makespan) and the overall completion time of all priority tasks. Specifically, QLHH utilizes a Q- learning-based high-level strategy to autonomously choose appropriate heuristics from a predefined set of low-level heuristics. At various stages of the optimization process, the chosen heuristic is treated as an executable action and applied to the solution space for better results. Moreover, critical configurations of parameters are systematically analyzed by conducting a design-of-experiment (DOE) approach. Finally, as a verification, both computational simulation and comparison are carried out in cases of different scales collected from a synthetic dataset, which is created by extending a real dataset, and the results demonstrate the effectiveness and efficiency of the proposed QLHH.},
  archive      = {J_ESWA},
  author       = {Xing-Han Qiu and Shu-Juan Tian and An-Feng Liu and Ye-Hua Wei and Hiroo Sekiya and Young-June Choi},
  doi          = {10.1016/j.eswa.2025.129327},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129327},
  shortjournal = {Expert Syst. Appl.},
  title        = {Q-learning-based hyper-heuristic algorithm for priority and precedence dual-driven task assignment in spatial crowdsourcing},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated scheduling method for heavy-haul transportation with virtual coupling based on two-phase optimization strategy. <em>ESWA</em>, <em>297</em>, 129326. (<a href='https://doi.org/10.1016/j.eswa.2025.129326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heavy-haul transportation, as an important means for transporting bulk commodities, features complex scheduling interdependence between station operations, timetables, and train combinations. Although virtual coupling (VC) simplifies the train combination/de-combination processes, integrated scheduling methods for heavy-haul trains (HHTs) utilizing VC remain undeveloped. This paper addresses the large-scale integrated scheduling problem for HHTs with VC, and optimizes the loading/unloading working plans, timetables, and VC combination schemes. An integer programming model, incorporating concepts from the flexible job shop scheduling problem, is formulated to describe the problem. To solve the large-scale problem efficiently, we propose a novel hierarchical optimization framework–two-phase optimization based on genetic algorithm (GA), local search (LS), and Monte Carlo tree search (MCTS), abbreviated as TPO-GLM. TPO-GLM employs a two-phase approach: a high-level GA performs global searches for train sequences and working-line dispatch, while low-level LS and MCTS refine the working-line choices and VC decisions, respectively. A novel depth-first-search (DFS)-based decoding method facilitates solution evaluation throughout the framework. Comprehensive experiments on realistic scenarios show that TPO-GLM outperforms the existing heuristic and metaheuristic methods, achieving high-quality solutions comparable to those of commercial solvers for small-scale cases, but with substantially higher speeds. It also scales effectively to solve problems with hundreds of trains, which cannot be solved within an acceptable time by commercial solvers. The effectiveness of each component (DFS, LS and MCTS) and the impact of their parameter settings are studied via comprehensive experiments.},
  archive      = {J_ESWA},
  author       = {Lezhou Wu and Zhongcan Li and Wei Dong and Hao Ye and Ming Jiang},
  doi          = {10.1016/j.eswa.2025.129326},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129326},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrated scheduling method for heavy-haul transportation with virtual coupling based on two-phase optimization strategy},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic multiobjective evolutionary algorithm based on a knee point driven gaussian model. <em>ESWA</em>, <em>297</em>, 129325. (<a href='https://doi.org/10.1016/j.eswa.2025.129325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knee point driven dynamic multiobjective evolutionary algorithms have been proven to be promising, however, the predicted knee points with worse quality may mislead the evolution. One of reasons for obtaining worse knee points is that previous methods focus on various prediction models, but neglects the effective strategy for exploring knee points according to the characteristics of decision vectors, falling into incorrect prediction direction. To address this issue, dynamic multiobjective evolutionary algorithm based on a knee point driven Gaussian model is proposed, termed KG-DMOEA. Once an environmental change is detected, knee points of last environment are extracted, and decision variables are classified into convergence and diversity related ones. Following that, knee point exploration strategy is developed to estimate new knee points in terms of historical knee points and convergence related variables. These estimated ones are further introduced to build the Gaussian function as generative model, and diversity related variables are utilized to update the generative model, with the purpose of overcoming the challenge that these decision variables may change over time. Based on this model, an initial population is produced at new time, and the model is also updated during evolutionary process to generate offspring individuals, speeding up the convergence. The intensive experiments demonstrate that the proposed KG-DMOEA has promising computational efficiency and performance in solving dynamic multiobjective optimization problems, outperforming several state-of-the-art DMOEAs.},
  archive      = {J_ESWA},
  author       = {Guoyu Chen and Yinan Guo and Xiao Yang and Tianbing Ma and Shengxiang Yang and Liang Yuan},
  doi          = {10.1016/j.eswa.2025.129325},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129325},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic multiobjective evolutionary algorithm based on a knee point driven gaussian model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Landslide susceptibility classification using multi hive artificial bee colony programming: A novel symbolic regression framework. <em>ESWA</em>, <em>297</em>, 129324. (<a href='https://doi.org/10.1016/j.eswa.2025.129324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Landslides, highly destructive natural hazards, threaten mountainous regions impacted by rainfall, seismic activity, and human actions. Machine learning (ML) techniques for landslide susceptibility mapping (LSM) often face challenges like interpretability, overfitting, and handling high-dimensional data. This study presents Multi Hive Artificial Bee Colony Programming (MHABCP), a novel symbolic regression framework merging swarm intelligence and multi-tree programming to create interpretable, robust LSM models. A key feature is the integration of the Relative Outlier Cluster Factor method for outlier detection, enhancing data quality and model stability. Tested against Multi Gene Genetic Programming (MGGP) using a dataset from Varto, eastern Turkey, with 18 environmental and topographic factors, MHABCP achieved 90.57 % test accuracy and a 90.51 % F1-score, surpassing MGGP in all metrics while remaining interpretable. MHABCP also showed consistency across 100 runs and better classified landslide-prone areas, offering a scalable, explainable solution for disaster risk reduction and geospatial planning.},
  archive      = {J_ESWA},
  author       = {Sibel Arslan and Suleyman Evsen and Coskun Ozkan},
  doi          = {10.1016/j.eswa.2025.129324},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129324},
  shortjournal = {Expert Syst. Appl.},
  title        = {Landslide susceptibility classification using multi hive artificial bee colony programming: A novel symbolic regression framework},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-phase federated learning framework for machinery fault diagnosis with cloud-edge collaborative computing. <em>ESWA</em>, <em>297</em>, 129323. (<a href='https://doi.org/10.1016/j.eswa.2025.129323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Industrial Internet of Things (IIoT) technology, data-driven machinery fault diagnosis methods have recently emerged and successfully developed in recent years. While achieving promising diagnostic performance, the existing methods also require massive high-quality supervised data, which are impractical in actual industrial circles. Therefore, there exists a compelling rationale for the integration and utilization of distributed data from multiple clients to develop a powerful global diagnostic model. Nonetheless, that fundamentally necessitates data sharing among various clients, which is usually not feasible in real industries because of potential conflicts of interests. To address the issue, a two-phase federated learning framework namely TPFed, which combines data augmentation and fault diagnosis, is proposed in this study. Specifically, a cloud-edge collaborative federated generative adversarial network is developed with client-side discriminators and cloud-based block generators to mitigate semantic differences in a privacy-preserving manner whilst alleviating the burden of clients on model training. Afterwards, a mixed focal loss function considering the contribute levels of original and generated samples is designed to enhance the performance of local diagnostic models. Furthermore, a joint allocation scheme for the aggregation weights is devised to construct a powerful global model taking account of high-assurance clients, thereby achieving excellent diagnosis tasks. The diagnostic performance and operational efficiency of proposed TPFed framework are demonstrated through the results of comparative experiments on two rotating machinery datasets.},
  archive      = {J_ESWA},
  author       = {Yudi Zhang and Hongpeng Yin and Rui Wang and Tengfei Zhang},
  doi          = {10.1016/j.eswa.2025.129323},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129323},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-phase federated learning framework for machinery fault diagnosis with cloud-edge collaborative computing},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive optimization method for reliable encapsulation of manufacturing service based on a graph convolution network with multi-dimensional feature fusion. <em>ESWA</em>, <em>297</em>, 129322. (<a href='https://doi.org/10.1016/j.eswa.2025.129322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of mass customization, manufacturing services require frequent adjustment and configuration of resources. Enterprises lack a unified model to describe the reliability of manufacturing service encapsulation under complex resource combinations. Meanwhile, during the encapsulation process, the latent relationships between heterogeneous resources are challenging to extract, making it difficult to guarantee the reliability of manufacturing services, ultimately resulting in production efficiency and product quality failing to meet customer demands. To address the issues above, this paper proposes A novel adaptive optimization method for reliable encapsulation of manufacturing service based on a graph convolution network with multi-dimensional feature fusion. First, a novel adaptive optimization method for manufacturing service reliability encapsulation (AO-MSRE) is constructed to characterize encapsulation reliability under diverse resource combinations. Subsequently, based on the characteristics of this model, the graph convolutional network (GCN) algorithm was improved, and the improved GCN algorithm was combined with the edge graph neural network (EGNN). A novel multi-dimensional feature fusion graph convolutional network (MFFGCN) framework—specifically, the reliability characterization network (RCN)—was designed. This framework integrates node, edge, and edge-graph feature information to comprehensively analyze the impacts of heterogeneous resources, resource relationships, and implicit interference between relationships on encapsulation reliability. Experimental results demonstrate that RCN achieves outstanding performance in optimizing manufacturing service reliability encapsulation, with a mean absolute percentage error (MAPE) as low as 1.95% while maintaining robustness under noise interference. This work provides a theoretical foundation and practical tools for reliable manufacturing service encapsulation in dynamic production environments.},
  archive      = {J_ESWA},
  author       = {Zhengchao Liu and Yongjun Cheng and Chunrong Pan and Lei Wang and Hongtao Tang and Zhihao Zeng},
  doi          = {10.1016/j.eswa.2025.129322},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129322},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive optimization method for reliable encapsulation of manufacturing service based on a graph convolution network with multi-dimensional feature fusion},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Imputation for incomplete data based on granulated single output neural network group. <em>ESWA</em>, <em>297</em>, 129321. (<a href='https://doi.org/10.1016/j.eswa.2025.129321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imputation is a fundamental task for analyzing and mining incomplete data. Most existing methods for imputing missing values are of numeric type meaning that the estimated values are unique and have a certain degree of error. With the advancement of granular computing, granular imputation for incomplete data has gradually emerged as an intriguing problem of deserves careful investigation. In this paper, we construct an attribute correlation model based on granulated single output neural network group (GSONNG) for multidimensional incomplete data with the aim of achieving granular imputation of missing values. Since granular imputation is based on numeric imputation to some extent, we first propose a numeric imputation method for incomplete data based on single output neural network group (SONNG) with iterative learning. In this method, SONNG is used to capture the correlation relationship between each attribute of incomplete data and other attributes. In the process of network modeling, in order to leverage all the information about existing values, the missing values in incomplete samples are regarded as variables and participate in network training together with complete data, and then the network parameters and the numeric imputation results of missing values can be obtained simultaneously once the network training has been completed. Subsequently, based on the trained SONNG, we granulate the network parameters by allocating interval information granularity, which can elevate them from numeric form to interval form. This transformation facilitates the establishment of granular correlation models between each attribute of incomplete data and other attributes. In the process of granular modeling, we choose coverage and specificity as the comprehensive index. Based on the constructed granular model, the missing values of any attribute can be imputed in interval form by its corresponding granulated single output neural network. Experimental results on several public datasets demonstrate the effectiveness of the proposed granular imputation method. Granular imputation expands the concept of missing value estimation results, which enhances the interpretability of imputation results and yields more cognitive descriptions.},
  archive      = {J_ESWA},
  author       = {Meitong Chen and Liyong Zhang and Wei Lu and Xiaodong Liu and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129321},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129321},
  shortjournal = {Expert Syst. Appl.},
  title        = {Imputation for incomplete data based on granulated single output neural network group},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HCLGT-DRP: Hypergraph contrastive learning and graph transformer for drug response prediction. <em>ESWA</em>, <em>297</em>, 129320. (<a href='https://doi.org/10.1016/j.eswa.2025.129320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate drug response prediction (DRP) is crucial for personalized therapy. Recently, graph representation learning has demonstrated promising potential in DRP due to its robust expressive capability. However, existing graph-based methods still face three major issues: 1) failing to capture the high-order complex relations among cell lines, 2) not fully utilizing drug structure information, and 3) insufficiently leveraging cell line-drug association. To address these issues, a novel computational framework, termed HCLGT-DRP, is proposed based on hypergraph contrastive learning and graph transformer for predicting drug response. Specifically, we construct a hypergraph for each type of omics and introduce a hypergraph aggregation mechanism to optimize the hypergraph structure, enabling the capture of high-order relations within omics-specific hypergraphs. To explore interactions across multiple omics data, a hypergraph fusion approach based on a graph-level attention mechanism is proposed to integrate omics-specific hypergraphs into a unified one, enhancing the representation of complex multi-relational data. Moreover, a contrastive learning approach is employed to enhance the ability of representation learning across hypergraphs for multi-omics and heterogeneous graphs for cell line-drug association, obtaining the effective representations of cell lines. Furthermore, a graph transformer with molecular-specific attention is designed to learn drug representations, using the structural information within drug molecules. Extensive experiments conducted on two publicly available datasets show that HCLGT-DRP surpasses state-of-the-art methods across various DRP tasks. External validation on in vivo dataset further confirms its effectiveness. This study reveals the value of hypergraph structures in capturing high-order relations among cell lines while emphasizing the potential of sufficiently utilizing drug structure information and cell line-drug association to enhance the predictive performance.},
  archive      = {J_ESWA},
  author       = {Wen Zhang and Hang Qiu},
  doi          = {10.1016/j.eswa.2025.129320},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129320},
  shortjournal = {Expert Syst. Appl.},
  title        = {HCLGT-DRP: Hypergraph contrastive learning and graph transformer for drug response prediction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EECF: An edge-end collaborative framework with optimized lightweight model. <em>ESWA</em>, <em>297</em>, 129319. (<a href='https://doi.org/10.1016/j.eswa.2025.129319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of the Internet of Things (IoT) has led to an exponential growth in end devices, making edge computing (EC)-based task scenarios more pragmatically significant than cloud computing. However, the inherent limitation in the resources of edge devices impedes the deployment of machine learning models characterized by extensive parameters or intricate structures. To address this conundrum, we contemplate an E dge-end C ollaborative F ramework (EECF). Specifically, within an image classification task, a CNN model is pre-trained using a subset of representative samples, leveraging the abundant resources at the edge side. Subsequently, the CNN model is deployed to the end side to extract features from the samples, realizing a magnitude reduction in the dimensionality of the samples. Then, an SVM model is deployed at the end side, where a quasi-bird swarm algorithm (QBSA) is utilized for optimizing the parameters of SVM, and the fine-tuned SVM model performs task training based on the dimensionality-reduced samples. Moreover, the analysis of the convergence of QBSA is given to guarantee the successful application. Finally, the performance of EECF is appraised using the Receiver Operating Characteristic (ROC) curve analysis. Empirical results substantiate that the EECF enhances the precision of the model significantly, achieving an uptick in accuracy of up to 10.86 %, compared to benchmarks. In addition, the core code can be accessible via the link: https://tinyurl.com/yuy3snrz .},
  archive      = {J_ESWA},
  author       = {Dewen Qiao and Zhenyan Wang and Jiamiao Liu and Xuetao Chen and Di Zhang and Maolan Zhang},
  doi          = {10.1016/j.eswa.2025.129319},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129319},
  shortjournal = {Expert Syst. Appl.},
  title        = {EECF: An edge-end collaborative framework with optimized lightweight model},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Local attribute reduction for large scale hybrid data with limited missing labels via self information and overlap degree. <em>ESWA</em>, <em>297</em>, 129318. (<a href='https://doi.org/10.1016/j.eswa.2025.129318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the case where the proportion of samples with missing labels is extremely small and has a negligible impact on the overall performance of the dataset, we can focuses computational resources and storage space on the samples where labels exist (target set), thereby effectively simplifying and accelerating data processing. This paper studies local attribute reduction for large scale hybrid data with limited missing labels via self information and overlap degree. First, the similarity between samples is calculated. Then, the tolerance classes on the target set are obtained. Then, local lower and upper approximations on the target set are defined to construct a local rough set model. This model improves the processing speed of large scale data, shortens computational time, and reduces error sources. Since self information on the target set is closely related to both the lower and upper approximations of the decision, it is introduced for the standard of attribute reduction. Before attribute reduction, overlap degree is proposed to evaluate and reorder the attributes. The strategy of prioritizing key attributes with low overlap degree from the pre-ranked attribute set significantly enhances the efficiency of obtaining the optimal subset. Next, an attribute reduction algorithm via self information and overlap degree are designed. Finally, a series of experiments are conducted. The results show that the designed algorithm performs exceptionally well in classification and clustering tasks, outperforming the existing five algorithms. The classification accuracy and Macro-F1 score of the algorithm are further analyzed and compared with those of the other five algorithms. The statistical analysis of classification accuracy and Macro-F1 score shows that LSO improves precision by 5.3 % and 7.1 % compared to the other five algorithms, respectively.},
  archive      = {J_ESWA},
  author       = {Run Guo and Yonghua Lin and Zhaowen Li},
  doi          = {10.1016/j.eswa.2025.129318},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129318},
  shortjournal = {Expert Syst. Appl.},
  title        = {Local attribute reduction for large scale hybrid data with limited missing labels via self information and overlap degree},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep multi-task learning framework leveraging multi-modal behavioral signals: Real-time, fine-grained assessment of IIVIS-induced driver distraction. <em>ESWA</em>, <em>297</em>, 129317. (<a href='https://doi.org/10.1016/j.eswa.2025.129317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver distraction, intensified by increasingly complex Intelligent In-Vehicle Information Systems (IIVIS), compromises modern traffic safety. Real-time, fine-grained assessment of driver distraction states is crucial for timely and appropriate interventions. This paper introduces a comprehensive assessment framework that accounts for the interaction effects of driving and IIVIS tasks on driver behavior. The framework leverages multi-modal behavioral signals (visual, manual, and driving behaviors) to assess both IIVIS-induced distraction performance and concurrent driving performance in real time into 7 levels each. Based on domain expertise, features were extracted from these signals and then subjected to analysis of variance and principal component analysis. These analyses guided the interpretable classification and labeling of these signals by cluster analysis. We proposed a Dual-task Shared Attention-InceptionTime (DSA-InceptionTime) model, which integrates the InceptionTime deep convolutional neural network and a multi-task learning architecture with a shared attention mechanism. This design allows DSA-InceptionTime model to extract multi-scale temporal features from 3 s signal segments and take interaction effects into account when simultaneously assessing the two-aspect performance of distraction state. The framework was developed and validated using a dataset of these signals acquired from 27 participants in 15 experiment scenarios involving various typical driving and IIVIS multi-modal interaction tasks using non-invasive measurements. Principal results showed the DSA-InceptionTime model outperformed baseline models, achieved a quadratic weighted kappa of 0.916, and demonstrated the value of fusing these multi-modal signals. This framework, driven by expertise and data, effectively improves the accuracy, granularity, and reliability of real-time driver distraction state assessment. This is crucial for developing more intelligent in-vehicle systems to promote human-machine collaboration and traffic safety.},
  archive      = {J_ESWA},
  author       = {Xinyi Li and Li Jia and Qihang Sun and Gang Guo and Wenbo Li},
  doi          = {10.1016/j.eswa.2025.129317},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129317},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep multi-task learning framework leveraging multi-modal behavioral signals: Real-time, fine-grained assessment of IIVIS-induced driver distraction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised attribute reduction for heterogeneous data based on misclassification cost and self-information. <em>ESWA</em>, <em>297</em>, 129316. (<a href='https://doi.org/10.1016/j.eswa.2025.129316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous data widely exist in the fields of data mining and machine learning, which often face the problem of missing partial labels. Semi-supervised attribute reduction can effectively reduce the dimension of partially labeled data and has received much attention in recent years. Many semi-supervised methods make predictions based on labeled data, while ignoring the cost of misclassification of unlabeled data. Self-information considers the classification information provided by the lower approximation and upper approximation in the decision class, and is a representative uncertainty measure in rough set theory. However, it has not been combined with semi-supervised attribute reduction. To address these problems, this paper constructs a semi-supervised attribute reduction method based on misclassification cost and self-information for partially labeled heterogeneous data. First, the concept of misclassification cost is introduced to quantify the possibility and cost of sample misclassification to improve the prediction accuracy of unlabeled data. Second, self-information based on misclassification cost is defined. Then, the attribute importance function based on self-information is constructed. And an attribute reduction algorithm based on misclassification cost and self-information is designed. Finally, the experimental results on twelve public datasets show that the constructed semi-supervised algorithm has superior classification performance. Furthermore, the robustness of proposed method is proved by parameter analysis.},
  archive      = {J_ESWA},
  author       = {Chunyong Wang and Yuanxia Zhang and Shengda Tao and Yonghua Huang},
  doi          = {10.1016/j.eswa.2025.129316},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129316},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semi-supervised attribute reduction for heterogeneous data based on misclassification cost and self-information},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiscale group behavior perception for intelligent social bot detection. <em>ESWA</em>, <em>297</em>, 129315. (<a href='https://doi.org/10.1016/j.eswa.2025.129315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have significantly advanced social bot detection. However, traditional GNNs typically adopt a star-shaped message-passing paradigm, modeling only the influence of neighbors on a central node while ignoring interactions among the neighbors themselves. They also aggregate node features without considering the varying relational strengths between accounts. To address these limitations, we propose an Adaptive Multiscale Group behavior Perception network (AMGP). AMGP begins by adaptively partitioning accounts into subgroups, each associated with a hyperedge. Local features within each subgroup are aggregated to the hyperedge and then combined with individual node features to update account representations. To capture higher-order group interactions, we recursively construct a multiscale hypergraph hierarchy by treating each subgroup as a new node and applying further adaptive partitioning. Hypergraph convolution is applied at each scale, and the resulting multiscale features are concatenated to form comprehensive node representations. Experiments on three benchmark datasets demonstrate that AMGP consistently outperforms existing methods in social bot detection.},
  archive      = {J_ESWA},
  author       = {Feng Liu and Bingchuan Jiang and Rui Ma},
  doi          = {10.1016/j.eswa.2025.129315},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129315},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multiscale group behavior perception for intelligent social bot detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secure data transmission and attack detection framework for IOT-enabled smart cities using FHE-based-maes and DHGNN. <em>ESWA</em>, <em>297</em>, 129314. (<a href='https://doi.org/10.1016/j.eswa.2025.129314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present SCs’ landscape, the increasing development and distribution of the Internet of Things (IoT) and Internet of Everything (IoE) technologies are represented as a significant enabler, which leads the SC paradigm to the big data scale. Nevertheless, in IoT systems, the data gathered is highly prone to availability, integrity, and privacy threats. Thus, a novel Deep Hamiltonian Generator Neural Network (DHGNN) and Modified Advanced Encryption Standard (MAES)-based secure data transmission and attack detection model for the IoT-enabled SCs is proposed in this paper. Firstly, the Sensor Nodes (SNs) are initialized in the data acquisition phase; then, by utilizing Cosine Similarity and Density-Based Spatial Clustering of Applications with Noise (CS-DBSCAN), the nodes are clustered. The data are aggregated via clustering and further transformed into the base station. By utilizing Bit Stuffing Rivest, Shamir, Adleman (BSRSA), the nodes are authenticated to discover a secure routing path before transmitting the data securely. Subsequently, in the attack detection phase, the data transferred via the secured path is verified. Here, the data’s features are gathered from the dataset and trained using DHGNN for attack detection. Lastly, by employing the MAES algorithm, the FHE encrypts the non-attacked data extracted from the attack detection phase; these data are then stored in the server. The experiential outcome depicts that when contrasted with the existing methods, the proposed model identifies attacks with higher accuracy (97.92 %) and precision (97.49 %). Also, the proposed model obtains a lower ET ranging between 1.344 ms-3.103 ms for 100–500 nodes. Likewise, the proposed methodology transmits data with minimal end-to-end delay (1.01 ms).},
  archive      = {J_ESWA},
  author       = {Anita Chaudhari and Rajesh Bansode},
  doi          = {10.1016/j.eswa.2025.129314},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129314},
  shortjournal = {Expert Syst. Appl.},
  title        = {Secure data transmission and attack detection framework for IOT-enabled smart cities using FHE-based-maes and DHGNN},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Probabilistic approach for the prediction of flight processes with uncertainty quantification – Application to block time. <em>ESWA</em>, <em>297</em>, 129313. (<a href='https://doi.org/10.1016/j.eswa.2025.129313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are increasingly being used to predict flight processes, such as the early estimation of the flight block time, that is, the gate-to-gate time (the time from leaving the departure airport until the arrival at their destination). These predictions support airline operations through early identification of possible disruptions. The performance of machine learning models tends to be described by metrics that represent their overall quality, not capturing the uncertainty of individual predictions. However, modelling and considering the uncertainties of individual processes is fundamental when integrating these models into decision support tools. This is particularly relevant in the air transport domain due to the non-linearities on delay propagation (for flights and passengers) and cost, as some events can trigger a sharp increase in these, e.g. with passengers missing their connections. This article presents a generic approach to describe the level of uncertainty of each prediction based on the combined use of two models. This methodology could be applied to many transport indicators and expert systems; in this article, the target variable used to illustrate the methodology is the block time of flights. The approach consists of the combination of two models: the first model produces a first estimation of the target value (with a regression); this estimation is then corrected by the outcome of a second model, which characterises (with a probabilistic classifier) the error of the first model for this estimation. The outcome of the combined models is a probabilistic distribution of the target indicator. The performance of the models generated in this manner is studied through parametric analysis and using three metrics: accuracy, uncertainty and prediction interval coverage probability ( PICP ). The VIKOR methodology is used to assist and streamline the decision-making process of the end user by filtering and ranking Pareto alternatives across various modelling parameters. This approach is compared with alternatives such as considering a Gaussian distribution of error for all estimations, quantile regression modelling and bootstrapping.},
  archive      = {J_ESWA},
  author       = {Paolino De Falco and Luis Delgado},
  doi          = {10.1016/j.eswa.2025.129313},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129313},
  shortjournal = {Expert Syst. Appl.},
  title        = {Probabilistic approach for the prediction of flight processes with uncertainty quantification – Application to block time},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A HEVC video steganalysis algorithm for transform unit partition modes. <em>ESWA</em>, <em>297</em>, 129312. (<a href='https://doi.org/10.1016/j.eswa.2025.129312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing video steganalysis methods struggle to effectively detect and analyze TU-based steganography algorithms. To address this issue, a novel steganalytic approach is proposed in this paper. Firstly, video steganography based on TU partition modes is introduced. It has been observed that this steganography algorithm exerts a discernible influence on the distribution of various coding unit (CU) types, specifically the 16×16 CUs and 8×8 CUs with different partition unit (PU) partition modes and TU partition modes. Consequently, we have classified these two distinct CU sizes into three separate types based on their PU and TU partitioning modes. The area ratio occupied by different kinds of CUs is utilized as the first feature set. Moreover, certain specific types of CUs exhibit a susceptibility to the influence of the TU-based steganography algorithm. Therefore, the proportions of these CU types are utilized for extracting the remaining feature set. Experiments were processed in HM 16.15 and LibSVM with an Intel Core i5-11400. Experimental results indicate that the proposed feature sets exhibit strong performance in detecting video steganography based on TU partition modes.},
  archive      = {J_ESWA},
  author       = {Mingyuan Cao and Lihua Tian and Chen Li},
  doi          = {10.1016/j.eswa.2025.129312},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129312},
  shortjournal = {Expert Syst. Appl.},
  title        = {A HEVC video steganalysis algorithm for transform unit partition modes},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). User profile constructed by multiple attributes for optimizing linguistic steganalysis in social networks. <em>ESWA</em>, <em>297</em>, 129311. (<a href='https://doi.org/10.1016/j.eswa.2025.129311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linguistic steganalysis (LS) tasks aim to detect whether a text contains secret information. Existing LS methods focus on deep-learning model design and achieve excellent results in ideal data. However, they overlook unique user characteristics, resulting in weaker performance in social networks. And a few stegos here that further complicate detection. We propose UP4LS, a framework that incorporates the U ser P rofile for enhancing LS in realistic scenarios. Three kinds of user attributes, such as writing habits, are explored to build the profile. For each attribute, a specific feature extraction module is designed. The extracted features are mapped to high-dimensional user features via the deep-learning model of the method to be improved. The content feature is extracted by the language model. Then, the user and content features are integrated. Existing methods can improve LS results by incorporating the UP4LS framework without altering their deep-learning models. Experiments show that UP4LS can significantly enhance the performance of LS-task baselines in realistic scenarios, with overall Acc increased by 25 %, F1 increased by 51 %, and achieving state-of-the-art (SOTA) results. The improvement is especially pronounced when fewer stegos are present. Additionally, UP4LS also paves the way for related-task SOTA methods to efficient LS. Our codes and data are available at: https://github.com/WangYH-BUPT/UP4LS .},
  archive      = {J_ESWA},
  author       = {Yihao Wang and Ruiqi Song and Lingxiao Li and Yifan Tang and Ru Zhang and Jianyi Liu},
  doi          = {10.1016/j.eswa.2025.129311},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129311},
  shortjournal = {Expert Syst. Appl.},
  title        = {User profile constructed by multiple attributes for optimizing linguistic steganalysis in social networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-supervised temporal localization of PQD via hierarchical differential attention and spatiotemporal dual-threshold. <em>ESWA</em>, <em>297</em>, 129310. (<a href='https://doi.org/10.1016/j.eswa.2025.129310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for detecting power quality disturbances are hindered by limited labeled data and predominantly emphasize classification, often failing to achieve precise temporal localization. To address these issues, this paper proposes a semi-supervised temporal localization via hierarchical differential attention and spatiotemporal dual-threshold. A teacher network, constructed with differential attention mechanisms and dilated causal convolutions, is trained on a small labeled dataset to capture time-varying features and generate high-confidence pseudo-labels from unlabeled data. To address the granularity mismatch commonly observed in conventional pseudo-label filtering, a refined spatiotemporal dual-threshold mechanism is introduced, which performs collaborative filtering at both the time-point and sample levels. This approach preserves reliable supervision at high-confidence time points while suppressing the temporal propagation of local prediction errors, thereby significantly enhancing the quality of pseudo-labels and improving localization performance. These pseudo-labels are then leveraged, together with the labeled data, to train a lightweight student network based on ShuffleNet. Experimental results show that with only 20 labeled samples per class, the student network achieves 94.31 % accuracy on simulated data and 98.73 % on real-world data, with an average inference time of just 55.12  ms. These findings highlight the proposed framework’s robustness under small-sample conditions, the effectiveness of the dual-threshold pseudo-labeling strategy, and its practical suitability for real-time disturbance detection on resource-constrained devices.},
  archive      = {J_ESWA},
  author       = {Ziao Gao and Yuzhen Xu and Yulong Liu and Xianyang Cui and Tao Jin},
  doi          = {10.1016/j.eswa.2025.129310},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129310},
  shortjournal = {Expert Syst. Appl.},
  title        = {A semi-supervised temporal localization of PQD via hierarchical differential attention and spatiotemporal dual-threshold},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty oriented pattern extracting and analyzing via sliding window control. <em>ESWA</em>, <em>297</em>, 129309. (<a href='https://doi.org/10.1016/j.eswa.2025.129309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain pattern analysis is one of the diverse data analysis techniques that discover hidden information in stream data. The uncertain pattern analysis method integrated into intelligent systems aims to discover insightful patterns from uncertainty-driven data by considering the existential probability of the information comprising the data. In the consistently accumulated stream data, it is necessary to consider the latest information more important than the old information. Previous pattern analysis methods reflect the information included in all scanned data in global data structures to analyze uncertain patterns from uncertainty-driven data. Specifically, the latest list-based uncertain pattern analysis methods do not adequately discover hidden insights reflected in the recent trend from stream data. Motivated by the limitation, we present a novel list-based uncertain pattern analysis method with the sliding window control. The proposed method removes information related to the oldest data, which does not properly reflect recent trends, and analyzes result patterns from the latest transactions. Pruning strategies satisfying the anti-monotone property are presented, which are suitable for the sliding window technique. The experimental results demonstrate that the proposed method has superior runtime, memory usage, and scalability compared to other comparison methods. Moreover, additional evaluations demonstrate that the proposed method has completeness and effectiveness for analyzing large-scale data with practical applicability in real-world environments where numerous streams occur.},
  archive      = {J_ESWA},
  author       = {Seungwan Park and Doyoung Kim and Seongbin Park and Unil Yun},
  doi          = {10.1016/j.eswa.2025.129309},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129309},
  shortjournal = {Expert Syst. Appl.},
  title        = {Uncertainty oriented pattern extracting and analyzing via sliding window control},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The synergy of statistical and fuzzy logic approaches in mining patterns from the peer-to-peer lending data. <em>ESWA</em>, <em>297</em>, 129308. (<a href='https://doi.org/10.1016/j.eswa.2025.129308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical measures, such as correlation, compute numeric values. However, it is not always the best option for domain experts. A promising way is to augment these measures linguistically. Therefore, the main objective of this work is the synergy of statistical and fuzzy logic approaches in mining and interpreting valuable information from financial lending data. The correlation reveals whether attributes are related while exhibiting relatively low computational costs. Fuzzy functional dependencies recognize the direction of influence but are demanding in terms of computational cost. Finally, linguistic summaries explore and interpret dependencies between the subdomains of the considered attributes. These two approaches are less influenced by a smaller vagueness in the data. In addition, the support for decision making validated by diverse approaches and explained from different points of view is more reliable. These approaches are integrated and applied to peer-to-peer (P2P) anonymized lending data consisting of 266,483 loans. Among other things, a significant correlation between loan amount and loan duration (r = 0.25) is explained further, indicating that the direction of influence is slightly stronger from loan duration to loan amount than the opposite case. At the same time, the dependency is very strong from low duration to low amount, but relatively weak from high duration to high amount. Finally, further research and application directions are outlined.},
  archive      = {J_ESWA},
  author       = {Miroslav Hudec and Bálint Molnár and Galena Pisoni and Miljan Vučetić and Nina Barčáková and Barbara Będowska-Sójka and Belma Öztürkkal and Rezarta Perri Shkurti and Hanna Kristín Skaftadóttir and Maria Iannario},
  doi          = {10.1016/j.eswa.2025.129308},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129308},
  shortjournal = {Expert Syst. Appl.},
  title        = {The synergy of statistical and fuzzy logic approaches in mining patterns from the peer-to-peer lending data},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new graphical modelling and nearest neighborhood search algorithm for resource-constrained project scheduling problem with multi-skill staff. <em>ESWA</em>, <em>297</em>, 129307. (<a href='https://doi.org/10.1016/j.eswa.2025.129307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Resource-Constrained Project Scheduling Problem with Multi-Skill Staff (MS-RCPSP) is a combinatorial optimization problem with increasing attentions. The introduction of skills domain has increased the scheduling difficulty for managers due to more choices. Hence, a disjunctive graph model and a novel Nearest Neighborhood Search algorithm based on Project Duration Float Value Guided ( ν -GNNS) are proposed to minimize the project completion time of MS-RCPSP. The proposed algorithm progressively explores the optimal solution in a stable and predictable neighborhood solution space. It first extracts four characteristics from the model, and further introduces a new attribute matrix, ν -table, to record the improvements of all nearest neighboring solutions around the feasible one. This attribute matrix can guide the forward-backward alternating search of the ν -GNNS algorithm. Then, a resource-oriented encoding is developed by combining the disjunctive graph-based representation and preference list-based representation. Furthermore, the forward pass of the Critical Path Method (CPM) is embedded into the decoding mechanism to translate the encoding into a high-quality scheduling plan efficiently. Finally, the efficacy of the ν -GNNS algorithm is validated by comparing experimental results with five meta-heuristic algorithms on the iMOPSE benchmark dataset, and the evaluation efficiency of the ν -table is verified through experiments. The findings of the experiments show that the ν -GNNS algorithm outperforms the five comparison algorithms and reaches lower bounds in 21 instances, taking 1.14 h less on average to complete a project than the top-performing GP-HH algorithm in five comparison algorithms.},
  archive      = {J_ESWA},
  author       = {Min Hu and Min Zhou and Zikai Zhang and Zixiang Li and Liping Zhang},
  doi          = {10.1016/j.eswa.2025.129307},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129307},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new graphical modelling and nearest neighborhood search algorithm for resource-constrained project scheduling problem with multi-skill staff},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic constrained multi-objective evolutionary algorithm with a dual prediction mechanism. <em>ESWA</em>, <em>297</em>, 129304. (<a href='https://doi.org/10.1016/j.eswa.2025.129304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of evolutionary algorithms for dynamic constrained multi-objective optimization problems is a significant research area, driven by the need for real-time adaptive solutions in complex real-world systems. To address this, this paper proposes DP-DCMOA, an algorithm that introduces a novel hybrid dynamic response by synergistically combining memory-based sampling and prediction-based generation. The algorithm’s novelty lies in its dual prediction approach. For the memory-based component, it leverages the predictable time-series properties of environmental similarity to guide a robust biased sampling from historical archives. For the prediction-based component, it employs an enhanced trajectory predictor to generate new, high-quality solutions. Furthermore, a key innovation is the integration of this trajectory predictor as a continuous search operator within the static optimizer, moving beyond its traditional role as a one-shot re-initialization tool. This dual-response system is supported by a specialized dual-population static optimizer. The effectiveness of the framework is validated through extensive experiments, demonstrating significant performance advantages over state-of-the-art algorithms and a high ranking in academic competitions.},
  archive      = {J_ESWA},
  author       = {Zhe Yang and Libao Deng and Chunlei Li and Yifan Qin and Lili Zhang},
  doi          = {10.1016/j.eswa.2025.129304},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129304},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic constrained multi-objective evolutionary algorithm with a dual prediction mechanism},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shifting from physical models to learning methods for trajectory prediction: A review. <em>ESWA</em>, <em>297</em>, 129303. (<a href='https://doi.org/10.1016/j.eswa.2025.129303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft trajectory prediction plays an important role in air traffic management, flight scheduling, and conflict detection and avoidance. Accurate trajectory prediction helps to reduce airspace conflicts, improve flight safety, and optimize flight operation efficiency. With the increasingly complex airspace environment and the growing demand for autonomous aircraft operations, it is of great practical significance to systematically analyze the existing methods for the trajectory prediction. This paper provides a comparative analysis of these methods, especially focusing on two perspectives: physical modeling-based, and learning-based method. First, it explores physics-based models grounded in kinematics and dynamics, analyzing their applicability and limitations in various scenarios. Then, representative machine learning methods, including Kalman Filter, Linear Regression, Random Forest, Hidden Markov Model, and Gaussian Process Regression, are examined in depth, along with several deep learning approaches-Recurrent Neural Networks, Convolutional Neural Networks, Graph Convolutional Networks, Attention Mechanisms, and Transformers. The study presents the principles and application contexts of each method, with an emphasis on their strengths and limitations in complex airspace environments. This analysis highlights the characteristics of different prediction models and provide valuable insights for air traffic control and aviation management authorities in selecting optimal methods for specific applications. Last, this paper summarizes key challenges and proposes potential directions for further improvements to advance the future trajectory prediction methods.},
  archive      = {J_ESWA},
  author       = {Xiaoxuan Xie and Yong Tian and Jiangchen Li and Lili Wan},
  doi          = {10.1016/j.eswa.2025.129303},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129303},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shifting from physical models to learning methods for trajectory prediction: A review},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Text-aided alignment for multi-view clustering. <em>ESWA</em>, <em>297</em>, 129301. (<a href='https://doi.org/10.1016/j.eswa.2025.129301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering seeks to enhance clustering performance by integrating features from various views to derive discriminative representations of samples. Nevertheless, the majority of existing approaches predominantly rely on features generated by the model itself and encounter difficulties in effectively incorporating external information to bolster the discriminative capacity of sample representations. Moreover, many methods employ fusion-layer alignment or inter-view alignment strategies at both the sample and cluster levels, which can lead to redundancy or even amplify noise during the alignment process. In this paper, we propose a Text-Aided Alignment for Multi-View Clustering (TAAMVC) method, which harnesses external text features to assist clustering and improve performance. First, we extract noun concepts from WordNet using a vision-language pretrained model and retrieve the corresponding textual representations for each sample across different views. Text-aided alignment constraints are then applied between the sample features and their associated textual features within each view. Next, to thoroughly explore consistent information across views, we introduce an optimal feature knowledge transfer module and a semantic feature enhancement module to achieve efficient alignment at both the sample and cluster levels. Extensive experiments conducted on benchmark datasets illustrate that TAAMVC attains competitive or superior clustering performance.},
  archive      = {J_ESWA},
  author       = {You Xiang and Min Meng and Jigang Liu and Jigang Wu},
  doi          = {10.1016/j.eswa.2025.129301},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129301},
  shortjournal = {Expert Syst. Appl.},
  title        = {Text-aided alignment for multi-view clustering},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Label-fusion progressive segmentation of ore and rock particles in complex illumination conditions based on SAM-Mask2Former. <em>ESWA</em>, <em>297</em>, 129300. (<a href='https://doi.org/10.1016/j.eswa.2025.129300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent identification of ore and rock particles plays a crucial role in the mining production process; however, the complex and variable illumination conditions significantly limit the application of image-based computer vision technologies. Consequently, this study presents, for the first time in the field of particle identification, a network model that integrates the Segment Anything Model and the Masked-attention Mask Transformer (SAM-Mask2Former). Additionally, a Label-Fusion Progressive method has been proposed for image processing and network training. This innovative method enables networks to autonomously learn features under complex illumination conditions, thereby fully leveraging the capabilities of the model architecture. Furthermore, the model’s sensitivity to particle size, aggregation degree, and illumination conditions, along with its optimal identification range, is systematically investigated. The findings indicate that: (1) The SAM-Mask2Former model demonstrated superior performance in detection completeness and segmentation accuracy, achieving Box_mAP values exceeding 0.844 and Segm_mAP values surpassing 0.870 on the test set. It outperformed other models within the range of 1.2% to 42.1% and achieved a false detection rate of only 7.5% in particle size extraction. (2) Particle size and aggregation degree within a 7.4% range negatively affected model accuracy, with smaller particle sizes and higher aggregation levels leading to decreased accuracy. (3) When processing images under complex illumination conditions, the model exhibited issues such as missed detections, misidentifications, over-segmentation, and under-segmentation. Conventional models performed optimally under illumination conditions of 150–2000 Lux, while the Label-Fusion Progressive method expanded this advantageous illumination range by 69.2%.},
  archive      = {J_ESWA},
  author       = {Zongsheng Dai and Hao Sun and Yuxin Zhu and Bo Wu and Xuan Qin and Le Liu and Junze Jia},
  doi          = {10.1016/j.eswa.2025.129300},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129300},
  shortjournal = {Expert Syst. Appl.},
  title        = {Label-fusion progressive segmentation of ore and rock particles in complex illumination conditions based on SAM-Mask2Former},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EipFormer: Enhancing 3D instance segmentation by emphasizing instance positions. <em>ESWA</em>, <em>297</em>, 129299. (<a href='https://doi.org/10.1016/j.eswa.2025.129299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D instance segmentation plays a crucial role in understanding complex 3D scenes. However, existing methods often depend on fixed query positions-typically selected from large point clouds via center prediction or farthest point sampling-which may deviate from actual instance centers and thus compromise the instance aggregation quality. To address this limitation, we propose EipFormer, a Transformer-based framework that involves the progressive aggregation and dual position embedding strategies. Specifically, leveraging the offset prediction branch, EipFormer combines the original and central shifted coordinate systems to aggregate instances. The progressive aggregation process includes coarse, fine, and merge stages. Based on the designed weighted farthest point sampling, the coarse stage updates instance queries to capture global context. These queries are then refined to aggregate local context using aggregation averaging and center matching techniques. Finally, we introduce a merge stage that merges fragmented instances. Extensive experiments on STPLS3D, S3DIS, and ScanNet benchmarks validate the effectiveness of EipFormer, showing consistent improvements of 1.5-3.3 in AP and 2.1-3.7 in AP 50 over state-of-the-art approaches.},
  archive      = {J_ESWA},
  author       = {Mengnan Zhao and Lihe Zhang and Yuqiu Kong and Baocai Yin},
  doi          = {10.1016/j.eswa.2025.129299},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129299},
  shortjournal = {Expert Syst. Appl.},
  title        = {EipFormer: Enhancing 3D instance segmentation by emphasizing instance positions},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ContextualGraph-LLM: A multimodal framework for enhanced darknet traffic analysis. <em>ESWA</em>, <em>297</em>, 129298. (<a href='https://doi.org/10.1016/j.eswa.2025.129298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Darknet environments present a dual challenge for cybersecurity, and they offer privacy for legitimate users yet also serve as a hub for illicit activities. Traditional detection methods struggle to cope with the sophisticated tactics employed by threat actors in this space, necessitating innovative solutions that can uncover nuanced malicious behaviors. The primary objective of this work is to overcome the limitations of traditional detection methods against nuanced malicious behaviors in Darknet environments by introducing ContextualGraph-LLM (CG-LLM). This novel framework leverages the combined power of Graph Neural Networks (GNNs) and Large Language Models (LLMs) to enhance multi-label intrusion detection accuracy across various real-world network traffic scenarios, as demonstrated by its superior performance on benchmark datasets. This paper proposes CG-LLM, a novel framework that integrates Graph Neural Networks (GNNs) with Large Language Models (LLMs) to achieve robust multi-label intrusion detection. Our approach capitalizes on the CIC-Darknet2020 dataset, along with the ToN_IoT and UNSW-NB15 datasets, which cover a variety of real-world scenarios reflective of actual Darknet traffic and broader network threats. We first transform raw network flow records into a bipartite graph structure, where nodes correspond to distinct endpoints (source–destination pairs) and edges capture flow-level features such as packet sizes and transaction volumes. These graph-based embeddings are then enriched with textual node embeddings derived from TinyLlama. By pairing structural insights with contextual semantics, CG-LLM is poised to detect subtle malicious patterns often overlooked by more conventional, single-modality methods. Our experimental results reveal that CG-LLM consistently surpasses state of the arts studies in weighted average F1-score (0.9035), precision, (0.9368) and recall (0.8803) on the CIC-Darknet2020 dataset. Furthermore, it achieved impressive results on ToN_IoT (F1-score: 0.9712, precision: 0.9750, recall: 0.9714) and UNSW-NB15 (F1-score: 0.9797, precision: 0.9809, recall: 0.9802), highlighting its capacity to tackle data imbalance and underrepresented attack categories. Notably, the model excels in detecting hard-to-spot malicious behaviors, underscoring the effectiveness of fusing graph topology with linguistic context. While the incorporation of LLM embeddings elevates detection accuracy, it also introduces computational overhead, pointing to the importance of future research on scalability and optimization. In conclusion, this study demonstrates the potential of multimodal architectures that harness the complementary strengths of GNNs and LLMs, offering an adaptable and resilient framework for safeguarding networks against ever-evolving Darknet threats.},
  archive      = {J_ESWA},
  author       = {Yujung Hwang and Furkan Kurt and Faruk Curebal and Omer Keskin and Abdulhamit Subasi},
  doi          = {10.1016/j.eswa.2025.129298},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129298},
  shortjournal = {Expert Syst. Appl.},
  title        = {ContextualGraph-LLM: A multimodal framework for enhanced darknet traffic analysis},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WADSeg: Exploiting weak attention associations for enhanced knowledge segmentation in RAG. <em>ESWA</em>, <em>297</em>, 129297. (<a href='https://doi.org/10.1016/j.eswa.2025.129297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval-Augmented Generation serves as a significant auxiliary framework for equipping Large Language Models with external knowledge, whose performance benefits from modular optimization. However, the importance of knowledge segmentation as the first stage of Retrieval-Augmented Generation is often overlooked. Both the size and quality of text chunks play a critical role in the retrieval accuracy of retrievers and the reasoning capability of Large Language Models. To address this challenge, this paper introduces WADSeg, a novel segmentation approach that analyzes document attention map features to identify natural semantic discontinuities for enhanced segmentation. WADSeg uniquely features controllable, dynamic chunk sizing for improved semantic and logical coherence and incorporates sentence-level encoding with global semantic breakpoint identification to mitigate local noise. Crucially, extensive experiments across multiple datasets demonstrate that WADSeg outperforms rule-based and large language model-based baselines in terms of retrieval accuracy and scalability. These findings validate WADSeg’s ability to perform more semantically coherent and stable knowledge segmentation, establishing it as an effective modular optimization method to improve the overall performance of Retrieval-Augmented Generation frameworks.},
  archive      = {J_ESWA},
  author       = {Tiezheng Guo and Chen Wang and Qingwen Yang and Jiawei Tang and Yanyi Liu and Yingyou Wen},
  doi          = {10.1016/j.eswa.2025.129297},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129297},
  shortjournal = {Expert Syst. Appl.},
  title        = {WADSeg: Exploiting weak attention associations for enhanced knowledge segmentation in RAG},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Investigation of teenager’s psychological orientation towards cyberbullying: Be a victim or offender. <em>ESWA</em>, <em>297</em>, 129296. (<a href='https://doi.org/10.1016/j.eswa.2025.129296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A substantial number of people use internet platforms for a variety of purposes, including business, official, and personal. On the one hand, using online platforms can improve work productivity and quality; on the other hand, they can radically alter the psyche of teens who are active in or are victims of cyberbullying. Teenagers’ Physiological Orientation was explored in this article as a potential victim or offender of cyberbullying. For the investigation, a publicly available dataset 2 was used, which included four sections: socio-demographic data, cyberbullying experience, cyberbullying location, and experience within the last 30 days. The dataset was analyzed using data visualization and a feature relevance analysis technique, and features were chosen that have a high potential for understanding changes in teenagers’ psychology. Using the selected attributes, two datasets were created: the first includes orientations toward being a victim, while the second contains orientations toward being an offender. The dataset is imbalanced and has fewer occurrences, so the SMOTE algorithm is used to balance it. Furthermore, the decision rules were developed using a machine learning algorithm (C4.5). Two sets of decision rules have been created to simulate a teenager’s orientation toward being a cyberbullying victim or offender. In order to improve the model’s performance, a grid search method was introduced. After hyper-parameter adjustment, the model achieves accuracy of up to 76 % for victim instances and 72 % for offender cases. Furthermore, precision, recall, and f-score findings have been measured, demonstrating that the serious effects of cyberbullying victim and offender are detected with greater accuracy. A new explanatory AI model has also been proposed to enhance prediction trust, transparency, and accountability in prediction. Based on the findings, it can be concluded that chat rooms, Instagram, and online gaming are the most common places for teenagers to experience cyberbullying, and that they occasionally become aggressive toward others. Furthermore, it has been noticed that spreading rumors and creating an internet website to make fun of others are common forms of bullying. Furthermore, 67 % of teenagers are never victims or offenders of bullying. Less than 3 % of teenagers are badly affected by cyberbullying, and less than 1 % are actively involved in it. Furthermore, socio-demographic variables such as age, gender, and class have little bearing on being a victim, however commonly used applications and smartphone usage length have a significant impact on being a victim and an offender, which is heavily influenced by the teenager’s age, gender, and class.},
  archive      = {J_ESWA},
  author       = {Loveleen Kaur Pabla and Prashant Kumar Jain and Prabhat Patel and Shailja Shukla},
  doi          = {10.1016/j.eswa.2025.129296},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129296},
  shortjournal = {Expert Syst. Appl.},
  title        = {Investigation of teenager’s psychological orientation towards cyberbullying: Be a victim or offender},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). “What is your MBTI?”: Predicting the personality types using hierarchical attention and graph learning. <em>ESWA</em>, <em>297</em>, 129295. (<a href='https://doi.org/10.1016/j.eswa.2025.129295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Myers—Briggs type indicator (MBTI) is a widely-used personality test that classifies user personality types into one of the 16 categories. This study first investigates whether people with identical MBTI types show similar linguistic features across different social media (i.e., Kaggle, Twitter, and Reddit). Based on the lessons learned from analysis, we propose a model that can predict a user’s MBTI type from their social media text data. To learn the linguistic characteristics of each personality type, we introduce a personality vocabulary graph that represents the relationship between used words and each personality type. We utilize hierarchical attention in the proposed model to highlight important words and sentences that reveal the user’s personality. The results demonstrate that the proposed model outperforms baseline models across the different social media, implying that the proposed model is effective in user-level personality prediction and generally applicable in various social media. This study can provide important implications on user profiling, which is essential in targeted marketing, recommender systems, and political campaigns.},
  archive      = {J_ESWA},
  author       = {Migyeong Yang and Jiwon Kim and Minji Kim and Jinyoung Han},
  doi          = {10.1016/j.eswa.2025.129295},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129295},
  shortjournal = {Expert Syst. Appl.},
  title        = {“What is your MBTI?”: Predicting the personality types using hierarchical attention and graph learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedGCLRec: Federated graph contrastive learning framework for social influence recommendations. <em>ESWA</em>, <em>297</em>, 129294. (<a href='https://doi.org/10.1016/j.eswa.2025.129294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social influence plays pivotal role in shaping user preferences, making it an essential factor in modern recommender systems. While social recommendation models exploit this influence to improve prediction accuracy, they often treat user interactions as static and fail to capture dynamically evolving social behavior. On the other hand, federated learning provides a privacy-preserving framework by allowing model training across decentralized user data without exposing raw user interactions. However, existing federated recommendation approaches face significant challenges, including non-independent and identically distributed data, communication inefficiency, and limited personalization. To overcome these limitations, a novel Federated Graph Contrastive Learning framework termed as FedGCLRec is proposed, integrating social influence learning with federated learning for more robust and personalized recommendations. FedGCLRec leverages Graph contrastive learning to disentangle social influence, learning robust user representations. Additionally, personalized federated optimization adapts model updates based on user clusters, enhancing recommendation diversity and adaptability. Experiments performed on benchmark datasets i.e., Ciao, Epinions and Douban shows that the proposed framework achieves an improvement of up to 5.3 % in NDCG@10 and 4.8 % in Precision@10 over state-of-the-art models, demonstrating superior robustness, personalization, and scalability while effectively mitigating representation collapse.},
  archive      = {J_ESWA},
  author       = {Ataus Samad and Vandana Bhatia},
  doi          = {10.1016/j.eswa.2025.129294},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129294},
  shortjournal = {Expert Syst. Appl.},
  title        = {FedGCLRec: Federated graph contrastive learning framework for social influence recommendations},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction of energy consumption and airflow of a ventilation system: A SAGA-optimised back-propagation neural network-based approach. <em>ESWA</em>, <em>297</em>, 129293. (<a href='https://doi.org/10.1016/j.eswa.2025.129293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of computational technologies and machine learning algorithms, predicting airflow in underground mine ventilation systems has become increasingly feasible. However, some algorithms present challenges due to low convergence rates and susceptibility to getting trapped in local minima, such as the back-propagation neural network (BPNN). This paper introduces a novel approach that combines the strengths of a global search genetic algorithm (GA) and a local search simulated annealing (SA) algorithm, referred to as the SAGA method, to address these limitations. The SAGA method focuses on optimising the initial weights and thresholds of the BPNN, effectively mitigating the issue of rapid convergence into local minima. A key innovation is incorporating an adaptive learning rate into the BPNN algorithm, resulting in an improved SAGA-BP prediction model. This model forecasts airflow within underground mine ventilation systems in a laboratory-based prototype. Experimental results testify to the efficacy of the SAGA-BP model. Compared to the conventional SAGA-BP model, the proposed approach consistently demonstrates higher accuracy with (R 2 of 0.941 and test MSE of 0.3513) and faster underground mine ventilation airflow prediction. Thus, this approach can revolutionise mine ventilation and monitoring technologies by lowering energy consumption and operational costs, increasing mine productivity, improving system performance and reliability, and, most importantly, improving health and safety.},
  archive      = {J_ESWA},
  author       = {Prince and Byungun Yoon and Ananda Shankar Hati and Prashant Kumar and Prasun Chakrabarti},
  doi          = {10.1016/j.eswa.2025.129293},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129293},
  shortjournal = {Expert Syst. Appl.},
  title        = {Prediction of energy consumption and airflow of a ventilation system: A SAGA-optimised back-propagation neural network-based approach},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HGAIT: Heterogeneous graph attention with inverted transformers for correlation-aware stock return prediction. <em>ESWA</em>, <em>297</em>, 129292. (<a href='https://doi.org/10.1016/j.eswa.2025.129292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces HGAIT, a novel predictive framework that substantially enhances stock return prediction by synergistically integrating Transformer-based architectures with heterogeneous graph attention networks. Building upon recent advances like inverted Transformer, HGAIT employs channel-independent GRU structures instead of traditional MLP-based embeddings, effectively preserving intrinsic temporal inductive biases characteristic of financial data. The framework explicitly models intricate inter-variable interactions through dedicated variable attention mechanisms, capturing essential nonlinear dependencies among financial indicators. Additionally, a heterogeneous graph attention layer dynamically constructs asset neighborhoods based on positive and negative correlations, comprehensively integrating structural asset interrelationships crucial for accurate return prediction. Empirical validations using comprehensive U.S. market-wide data demonstrate HGAIT’s superior predictive capabilities. Notably, the model significantly outperformed benchmark methods across multiple metrics, particularly excelling in ranking-based indicators such as Rank Information Coefficient and Rank Information Coefficient Information Ratio. Extensive portfolio back-testing further confirmed its practical effectiveness, with HGAIT achieving remarkably higher Sharpe and Sortino ratios alongside the lowest maximum drawdowns, highlighting its exceptional risk-adjusted returns and robust downside risk management. Sub-period analyses across diverse market regimes, including stable, transitional, and highly volatile periods, further validated its predictive stability, emphasizing HGAIT’s robustness in adapting to dynamic financial environments. The generalizability of these findings across comprehensive market data confirms HGAIT’s broad applicability, making it a powerful and reliable tool for real-world financial decision-making and portfolio management.},
  archive      = {J_ESWA},
  author       = {Dongwoo Lee and Seungeun Ock and Jae Wook Song},
  doi          = {10.1016/j.eswa.2025.129292},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129292},
  shortjournal = {Expert Syst. Appl.},
  title        = {HGAIT: Heterogeneous graph attention with inverted transformers for correlation-aware stock return prediction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Construction and application of conditional event-based knowledge graphs for electric power standards. <em>ESWA</em>, <em>297</em>, 129291. (<a href='https://doi.org/10.1016/j.eswa.2025.129291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for standardized and intelligent management in new power systems, the limitations of traditional knowledge graphs in characterizing logical rules of electric power standards (EPSs) have become prominent. This study proposes a conditional event-based knowledge graph (CEKG)-based digitization method for EPSs, which achieves structured modeling of complex logical rules in power standard texts through the introduction of conditional nodes and event logic relationships. To address the linguistic characteristics of EPSs, a hybrid knowledge extraction method targeting diverse linguistic objects is developed. Specifically, a term-enhanced Bidirectional Encoder Representations from Transformers (BERT) architecture is employed as the input layer of the entity extraction model to extract domain-specific knowledge from EPS texts, while rule-based pattern matching is adopted for extracting general knowledge. A production rule-based transformer condition assessment model combining Cypher query language and graph algorithms is constructed based on the CEKG framework, with its effectiveness demonstrated through case validation. The results demonstrate that the proposed named entity recognition model outperforms other Transformer-based baseline models on the power domain dataset, exhibiting significant performance improvement particularly in the identification of core physical entities. The constructed CEKG effectively preserves intrinsic relationships between the physical meanings of different graph nodes with high knowledge representation fidelity. The developed production rule-based assessment model accurately outputs condition evaluation results based on equipment status information and online monitoring data. This research provides extensible paradigms for digital applications of EPSs as well as the knowledge extraction in power domain, offering both methodological and practical contributions to intelligent power system management.},
  archive      = {J_ESWA},
  author       = {Yizhuo Hu and Hao Wang and Ji Chen and Chongxing Zhang and Ming Ren and Ming Dong and Haibin Zhang and Zhonglin Hu and Xuan Dong},
  doi          = {10.1016/j.eswa.2025.129291},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129291},
  shortjournal = {Expert Syst. Appl.},
  title        = {Construction and application of conditional event-based knowledge graphs for electric power standards},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-guided lightweight vision transformer with circular relative positional encoding for condition identification of industrial rotary kilns. <em>ESWA</em>, <em>297</em>, 129290. (<a href='https://doi.org/10.1016/j.eswa.2025.129290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The zinc oxide rotary kiln plays a crucial role in zinc smelting recovery. Accurate identification of its operating conditions is essential for efficiency and safety. However, traditional monitoring relies on operator experience, which is often suboptimal in dynamic environments, necessitating intelligent systems for robust decision support. This paper proposes a knowledge-enhanced Vision Transformer framework to address this challenge. We introduce Circular Relative Positional Encoding (CRPE), a novel scheme tailored to embed prior knowledge of the kiln’s unique circular geometry. By modeling signed radial and angular differences, CRPE captures the kiln’s rotational dynamics within the Transformer architecture. To address limited computational resources in industrial settings, CRPE is integrated with a lightweight Mobile Vision Transformer, resulting in the CRPE-MViT model, representing a notable application of lightweight ViTs in such industrial scenarios. Additionally, we design an adaptive loss function that specifically targets and penalizes the misclassification of critical abnormal conditions, effectively overcoming class imbalance and the risks of severe error types. Experiments on an industrial dataset of 3571 images validate our designs. On a standard Vision Transformer, CRPE improves accuracy by 6.78 % over a baseline without positional encoding and by 3.61 % over standard Absolute Position Encoding (APE). The final CRPE-MViT model, which integrates the lightweight architecture and our adaptive loss function, attains 92.49 % overall accuracy, with high recall rates for critical under-fired (91.74 %) and over-fired (82.7 %) conditions. This validates our approach, guided by insights into the kiln’s physical characteristics, as a reliable solution for intelligent industrial monitoring.},
  archive      = {J_ESWA},
  author       = {Hao Wang and Chaobo Zhang and Wenxiong Kang and Xiaojun Liang and Cao Liu and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.eswa.2025.129290},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129290},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge-guided lightweight vision transformer with circular relative positional encoding for condition identification of industrial rotary kilns},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). COA-HAR: Exploring contrastive online test-time adaptation for wearable sensor-based human activity recognition using sensor data augmentation. <em>ESWA</em>, <em>297</em>, 129288. (<a href='https://doi.org/10.1016/j.eswa.2025.129288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) with wearable sensors is crucial for a wide range of applications from healthcare monitoring to sports analytics, yet challenges persist in achieving accurate and efficient predictions, particularly in real-world deployment scenarios. While deep learning techniques have improved the HAR performance, issues such as data scarcity and domain shifts from changing the user pose significant challenges. Test-time adaptation (TTA) emerges as a promising solution, offering flexibility and generality in addressing distribution shifts. However, applying TTA to sensor-based HAR has so far been limited to the adaptation of normalization layers, which leads to limited improvements. This paper introduces Contrastive Online Adaptation for HAR (COA-HAR), a novel framework leveraging self-supervised and contrastive learning to enhance model adaptability at test time. Our method is the first method for HAR to employ contrastive and self-supervised learning to directly adapt the entire model to an unlabeled setting at test time. Our contributions also include a strategy for selecting augmentations as well as an extensive study on the optimal combination of data augmentation techniques addressing the challenges of adapting these techniques to HAR. COA-HAR achieves state-of-the-art performance and we demonstrate the efficacy of leveraging pretrained models on extensive, unlabeled HAR datasets, such as the UK-Biobank dataset, to improve model initialization and adaptability. Experimental results across four datasets demonstrate the superiority of COA-HAR in HAR tasks compared to existing state-of-the-art TTA methods, showing its potential for robust and user-specific real-world applications.},
  archive      = {J_ESWA},
  author       = {Vitor Fortes Rey and Pedro Martelleto Bressane Rezende and Bo Zhou and Sungho Suh and Paul Lukowicz},
  doi          = {10.1016/j.eswa.2025.129288},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129288},
  shortjournal = {Expert Syst. Appl.},
  title        = {COA-HAR: Exploring contrastive online test-time adaptation for wearable sensor-based human activity recognition using sensor data augmentation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal medical image generation from MRI to PET using robust generative adversarial network. <em>ESWA</em>, <em>297</em>, 129287. (<a href='https://doi.org/10.1016/j.eswa.2025.129287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal medical image synthesis is critical for clinical diagnosis and treatment, since it leverages the complementary strengths of different imaging modalities while reducing the limitations of direct PET acquisition, such as high cost and radiation exposure. In this paper, we propose RobustGAN, a novel generative adversarial network designed for robust and high-fidelity cross-modal medical image translation. RobustGAN incorporates several key components to enhance both synthesis quality and training stability. First, spectral normalization is applied to the discriminator’s weight matrix to enforce Lipschitz continuity, promoting stable adversarial learning. Second, a self-attention mechanism is integrated into both the generator and discriminator. In the discriminator, self-attention mechanism can improve sensitivity to spatially distributed pixel-level features, where as in the generator, self-attention mechanism can better capture fine structural details. Additionally, a content loss term is employed to preserve subtle anatomical structures and textures in the synthesized PET images. We extensively evaluate RobustGAN on three cross-modal image translation tasks: T1-to-PET, FLAIR-to-PET, and CT-to-PET. On the T1-to-PET task, RobustGAN achieves PSNR scores of 34.36 dB (ADNI) and 34.29 dB (AIBL), with corresponding SSIM values of 0.9240 and 0.9355. For FLAIR-to-PET, it attains PSNRs of 34.54 dB (ADNI) and 34.69 dB (AIBL), along with SSIMs of 0.9411 and 0.9624. In CT-to-PET synthesis using the TCIA dataset, the model reaches a PSNR of 35.04 dB and an SSIM of 0.8892. Visual comparisons with state-of-the-art methods consistently demonstrate RobustGAN’s superior ability to preserve tissue boundaries and minimize artifacts. The implementation of RobustGAN is publicly available at: https://github.com/yuetyang/RobustGAN .},
  archive      = {J_ESWA},
  author       = {Yueteng Yang and Bing Li and Wenming Cao and Xuemei Chen and Weikai Li},
  doi          = {10.1016/j.eswa.2025.129287},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129287},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal medical image generation from MRI to PET using robust generative adversarial network},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CRMA-UNet: CNN+ResMamba-based and attentional mechanisms for retinal vessel segmentation. <em>ESWA</em>, <em>297</em>, 129286. (<a href='https://doi.org/10.1016/j.eswa.2025.129286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular segmentation is important for doctors to carry out clinical diagnosis and screening of medical ophthalmic diseases. Among the mainstream deep learning image segmentation models, CNNs excel at local feature capture but are constrained in modeling long-range dependencies. And Transformer can skillfully carry out long-range feature extraction but its modeling is limited by its quadratic computational complexity. The newly introduced Mamba model demonstrates the capability to efficiently capture long-range dependencies, all while preserving linear computational complexity. However, the combination of CNN and Mamba to utilize their respective advantages to achieve optimal segmentation has not been fully explored. To this end, this paper proposes CRMA-UNet, a U-shaped encoder–decoder for retinal vascular segmentation equipped with CNNs and Mamba. Specifically, firstly, for the coding part, the residual-based ResMamba was optimized, and then the parallel encoder feature extraction structure of CNN and ResMamba was designed on this basis. Moreover, four mainstream Mamba deployment methods were used on the four-layer structure of U-Net to capture local features and global information at the same time and obtain multi-view information; a PAFF (Parallel Attention Feature Fusion) parallel feature fusion module is developed to realize the reasonable fusion of CNN and ResMamba two parallel encoder features. Secondly, a Mul-CA (Multi-Cross Attention) module is designed to enable the encoder to fully deliver multi-level information. In the decoder stage, we modify the Attention Gate (AG) mechanism to reduce sampling-induced noise in feature maps. The CRMA-UNet achieves higher accuracy and faster processing than most of competing methods on all five tested datasets. The primary objective of this study is to investigate the potential of the Mamba model and establish a novel benchmark for retinal vascular segmentation tasks.},
  archive      = {J_ESWA},
  author       = {Yirong Liu and E. Xia and Chenghao Sun and Zheng Zhou},
  doi          = {10.1016/j.eswa.2025.129286},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129286},
  shortjournal = {Expert Syst. Appl.},
  title        = {CRMA-UNet: CNN+ResMamba-based and attentional mechanisms for retinal vessel segmentation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data attribution approach for unsupervised anomaly detection on multivariate time series. <em>ESWA</em>, <em>297</em>, 129285. (<a href='https://doi.org/10.1016/j.eswa.2025.129285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a challenging task that manifests in several forms depending on its context (e.g., fraud detection, network security, fault monitoring): given a collection of data, the goal is discovering the anomalous patterns diverging from the majority. The time dimension adds complexity to defining an anomaly, especially with multivariate time series, where each channel represents possibly distinct quantities. Classical unsupervised anomaly detection approaches have been based on differences in data, sequences of data, distributions, or also by inspecting the prediction deviation errors. In this work, we propose an innovative unsupervised approach for discovering anomalies in multivariate time series by leveraging the concept of data attribution from the explainability literature. Our proposed method is flexible and data-driven, and it can be used across multiple scenarios without the necessity of domain experts. By training initially on a self-supervised task (e.g., forecasting), a model captures normal data behavior; then, by using a data attribution technique we identify potential anomalies at the time step level. We conduct experiments on several synthetic and real-world datasets, comparing the results with state-of-the-art unsupervised anomaly detection methods, achieving competitive or better performance on most datasets, with notable improvements on synthetic data and promising results on real-world data, despite certain challenges in highly anomalous scenarios. Finally, we show an in-depth investigation of this methodology, along different dimensions, in order to gain a greater understanding of the application of these functions and their characteristics within the anomaly detection landscape.},
  archive      = {J_ESWA},
  author       = {Alessio Verdone and Simone Scardapane and Massimo Panella},
  doi          = {10.1016/j.eswa.2025.129285},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129285},
  shortjournal = {Expert Syst. Appl.},
  title        = {A data attribution approach for unsupervised anomaly detection on multivariate time series},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive cross-stage interactive cascaded RCNN with dual-axis cross-spatial aggregation convolution for 3D object detection. <em>ESWA</em>, <em>297</em>, 129284. (<a href='https://doi.org/10.1016/j.eswa.2025.129284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current 3D object detection network architectures are predominantly based on traditional architectures, and their feature extraction and enhancement capabilities have not been fully explored. To address this, we propose a cascaded region-based 3D object detection model featuring two key innovations: (1) A dual-axis cross spatial aggregation convolution that synergistically combines convolutional inductive biases with attention-based long-range dependency modeling, specifically designed for Bird’s-Eye-View (BEV) feature extraction; and (2) A multi-scale hybrid attention fusion module that adaptively recalibrates critical features while expanding receptive fields. The architecture is further augmented with a progressive cross-stage interactive detection head, which iteratively refines bounding boxes through inter-stage feature aggregation, significantly improving detection accuracy for small and complex objects. On the KITTI benchmark, our method achieves a mean Average Precision (mAP) of 67.34 % at a speed of 20.9 Frames Per Second (FPS) on an RTX A5000 GPU, demonstrating a good balance between accuracy and efficiency. The code is available on https://github.com/sgrrlll/daca_code/tree/master .},
  archive      = {J_ESWA},
  author       = {Qingsong Tang and Yongkang Li and Wenhao Dong and Ziyi Wang and Yang Liu},
  doi          = {10.1016/j.eswa.2025.129284},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129284},
  shortjournal = {Expert Syst. Appl.},
  title        = {Progressive cross-stage interactive cascaded RCNN with dual-axis cross-spatial aggregation convolution for 3D object detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TileNet: A multi-module network for tiled clothes generation from human body based on TPS and image inpainting. <em>ESWA</em>, <em>297</em>, 129283. (<a href='https://doi.org/10.1016/j.eswa.2025.129283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tiled clothes image generation task aims to generate a tiled state image of clothes based on a given human image. The generation results of previous works tend to be blurry with insufficient retention of texture details, which is mainly caused by the misalignment between the clothes worn by the person and the ground truth labels used for training. To address this problem, we propose a task-driven collaborative multi-module tiled clothes generation model called TileNet. The clothes deformation module deforms the clothes on the human body into a nearly tiled state, the shape mask generation module removes most of the irrelevant information and constrains the shape, and the inpainting module identifies the regions that can be directly retained as well as the void regions and fills them. Qualitative and quantitative experiments show that the quality of the images generated by TileNet is significantly better than in previous works. Our codes can be found in https://anonymous.4open.science/r/TileNet-9007 .},
  archive      = {J_ESWA},
  author       = {Yilong Zhang and Zhong Li and Suzhou Wei and Jiahao Li and Zibo Zhang and Shusong Xing and Haining Zhang and Binhui Wang},
  doi          = {10.1016/j.eswa.2025.129283},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129283},
  shortjournal = {Expert Syst. Appl.},
  title        = {TileNet: A multi-module network for tiled clothes generation from human body based on TPS and image inpainting},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LED-net: A lightweight and efficient dual-branch convolutional neural network for high-performance fruit tree branches semantic segmentation on mobile devices. <em>ESWA</em>, <em>297</em>, 129282. (<a href='https://doi.org/10.1016/j.eswa.2025.129282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the global labor shortage, fruit-picking robot technology has emerged as a critical solution for enhancing agricultural efficiency. Precise detection of fruit tree branches is essential for collision avoidance and optimal operation. However, the inconsistent performance of existing algorithms limits their application on edge devices. To address this, we propose LED-Net, a lightweight, efficient, dual-branch convolutional neural network designed for high-performance branch semantic segmentation in resource-constrained mobile environments. LED-Net is built on the Cascaded Efficient Spatial Pyramid Block (CESPB) and leverages dilated convolution in both its context and spatial branches, harnessing the advantages of dilated convolution while preserving detailed information. The network introduces two novel components: the Global Enhancement Transformer Block (GETB) and the Spatial Edge Attention Module (SEAM), which aggregate context information and enhance spatial edge features, respectively. To evaluate the proposed method, we constructed a semantic segmentation dataset of fruit tree branches during the apple maturity stage and compared LED-Net with eight state-of-the-art lightweight networks, including DDRNet and PIDNet. Experimental results demonstrate that LED-Net achieves the lowest parameter count of 1.661M and FLOPs of 9.206G. In the branch segmentation task, LED-Net achieves the highest IoU of 81.46 %, Accuracy of 90.13 %, and F1-score of 89.78 %. For 1280 × 720 resolution images, the network achieves a segmentation speed of 177.49 frames per second on an RTX 3090 GPU, meeting real-time processing requirements. In conclusion, LED-Net achieves a balance between precision, computational cost, parameter efficiency, and real-time performance, showcasing its exceptional potential for deployment in resource-constrained mobile harvesting robots. Source code and Dataset are available at https://github.com/ly27253/LED-Net .},
  archive      = {J_ESWA},
  author       = {Xilei Zeng and Hengrong Guo and Zeming Fan and Chenyu Zhou and Hao Wan and Xiaojun Yu},
  doi          = {10.1016/j.eswa.2025.129282},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129282},
  shortjournal = {Expert Syst. Appl.},
  title        = {LED-net: A lightweight and efficient dual-branch convolutional neural network for high-performance fruit tree branches semantic segmentation on mobile devices},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual graph convolution with quantified discrepancies for fraud detection. <em>ESWA</em>, <em>297</em>, 129281. (<a href='https://doi.org/10.1016/j.eswa.2025.129281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud causes significant financial losses to cardholders and issuing banks. Graph convolution techniques have emerged as a key tool for developing novel credit card fraud detection models. However, graph convolution networks are highly sensitive to noise and outliers, and tend to introduce causal fallacies when capturing static relationships among credit card transaction nodes, which hinders the improvement of fraud classification performance. To address these issues, we propose a discrepancy-quantified counterfactual graph convolution model for fraud detection, which dynamically captures causal relationships among credit card transaction nodes. Specifically, we first design a transaction feature discrepancy quantification strategy that quantifies discrepancies in direct, indirect, and temporal features of credit card transactions. These discrepancies are weighted to calculate an average discrepancy threshold for constructing the credit card transaction network. Second, we enhance transaction features using graph convolution, capturing the interaction relationships among credit card transactions. Most importantly, we design a counterfactual hypothesis mechanism that propagates the graph-convolution-enhanced node states to the real world, generates a hypothetical world through causal elimination, and iteratively updates the causal relationships of credit card transactions by comparing causal discrepancies between the two worlds until the causal effects in the transaction network are optimized. The performance of our model is validated on three public datasets.},
  archive      = {J_ESWA},
  author       = {Jinquan Zhang and Xiaohui Man and Hanmo Zhao and Lina Ni},
  doi          = {10.1016/j.eswa.2025.129281},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129281},
  shortjournal = {Expert Syst. Appl.},
  title        = {Counterfactual graph convolution with quantified discrepancies for fraud detection},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated continual learning for task-incremental and class-incremental problems: A survey. <em>ESWA</em>, <em>297</em>, 129278. (<a href='https://doi.org/10.1016/j.eswa.2025.129278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s information-driven world, valuable data for training intelligent systems is often distributed across private devices. Transferring such data to a central server introduces privacy concerns and significant communication overhead. Federated Learning enables devices to share knowledge and train a model collaboratively. Advanced smart devices often need to learn new tasks over time, making Continual Learning techniques crucial to retrain models with new data while retaining previously learned concepts. Consider a scenario in which evolving private data is distributed across devices, and we want to train a model in Continual Learning manner. For example, assume a healthcare application on smartphones monitors factors such as heart rate, body temperature, and sleep patterns over time to detect diseases. With Continual Learning, this application can adapt to detect new disease types as they emerge. Establishing Federated Learning for this process enables collaborative Continual Learning, enhancing privacy and potentially improving generalization. Such problems are common in real-world applications, including smart vehicles, mobile devices, and IoT systems. Federated Continual Learning algorithms are designed to address these problems. This survey presents concepts and provides concise descriptions of approaches proposed for Federated Continual Learning focusing on task-incremental and class-incremental problems.},
  archive      = {J_ESWA},
  author       = {Amin Birashk and Latifur Khan},
  doi          = {10.1016/j.eswa.2025.129278},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129278},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated continual learning for task-incremental and class-incremental problems: A survey},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weight nonlinear mapping based memristor crossbar array implementation scheme for convolutional neural network off-chip training. <em>ESWA</em>, <em>297</em>, 129277. (<a href='https://doi.org/10.1016/j.eswa.2025.129277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of memory-intensive and compute-intensive technologies such as artificial intelligence has made the “Von Neumann bottleneck” increasingly prominent. In-Memory Computing (IMC) is considered as an effective way to solve the problem of limited data throughput. In which, the memristor with intrinsic property of adjustable conductance is an ideal candidate to realize IMC. Currently, nonlinear mapping strategies have been applied to the on-chip training of neural networks. However, off-chip training is still dominated by linear mapping strategies. In this paper, we propose a novel memristor-based nonlinear mapping strategy, leveraging its intrinsic nonlinear and asymmetric conductance characteristics. Compared with the linear mapping strategy, the proposed strategy can represent more conductive states and is more consistent with the real situation of the device. On this basis, two nonlinear mapping schemes for neural network weight parameters are proposed by combining the difference and the virtual column, respectively. In order to reduce the circuit overhead, the layer structure of “convolutional layer + batch normalization layer”, which is commonly used in convolutional neural networks (CNNs), is fused. Through experiments, the influences of inherent characteristics of memristor, such as nonlinearity, the number of conductive states and ON/OFF ratio, on the performances of VGG8 model based on the two proposed schemes are investigated. The two proposed schemes are applied to five classical CNNs, including VGG, DenseNet and ResNets. Based on actual memristor parameters, the inference performances of this study are better than those of the existing schemes based on linear or hybrid mapping strategies. The two proposed schemes are applied to five classical CNNs, including VGG, DenseNet and ResNets. Based on actual memristor parameters, the inference performances of this study are better than that of the existing schemes based on linear or hybrid mapping strategies. In addition, the IMC hardware accelerator architecture is designed based on NeuroSim V1.4, and ResNet56 model is subsequently implemented.},
  archive      = {J_ESWA},
  author       = {Zhuosheng Lin and Zaofeng Chen and Jilong Zhang and Jingliang Deng and Xiaona Wu and Yue Feng},
  doi          = {10.1016/j.eswa.2025.129277},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129277},
  shortjournal = {Expert Syst. Appl.},
  title        = {Weight nonlinear mapping based memristor crossbar array implementation scheme for convolutional neural network off-chip training},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DHCF-net: Dual heterodimensional context fusion network for medical image segmentation. <em>ESWA</em>, <em>297</em>, 129275. (<a href='https://doi.org/10.1016/j.eswa.2025.129275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, medical image segmentation tasks have made significant progress, and the models based on convolutional neural networks (CNNs), represented by U-Net, have become the mainstream architectures. However, the inherent local perception property of CNNs leads to difficulties in realizing long-range information interactions. Although the self-attention mechanism efficiently models long-range dependencies, its computational complexity grows quadratically. In addition, existing attention mechanisms still have significant shortcomings in multi-dimensional global-local feature interaction and multi-scale association modeling. This paper proposes the dual heterodimensional context fusion network (DHCF-Net), the core of which is the heterodimensional complementary context fusion (HCCF) and the heterodimensional multi-scale context fusion (HMCF) modules. The HCCF module constructs complementary global-local context representations in the channel and spatial dimensions. The HMCF module is designed with a dual-path synergy mechanism for multi-scale context capture and interaction along channel and spatial dimensions. Experiments on ISIC 2018, BUSI, and Kvasir-SEG datasets demonstrate that DHCF-Net achieves state-of-the-art performance.},
  archive      = {J_ESWA},
  author       = {Ke Sun and Yu Wang and Wenzheng Ma and Wenmin Wang},
  doi          = {10.1016/j.eswa.2025.129275},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129275},
  shortjournal = {Expert Syst. Appl.},
  title        = {DHCF-net: Dual heterodimensional context fusion network for medical image segmentation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-representation space recommendation with graph contrastive learning. <em>ESWA</em>, <em>297</em>, 129274. (<a href='https://doi.org/10.1016/j.eswa.2025.129274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing collaborative filtering recommendation paradigms primarily rely on co-occurrence matrices to mine user and item preference information. However, the limited interaction behavior in the real world making it difficult to learn accurate preference information. To alleviate the problem of insufficient effective recommendation signals caused by the sparsity of user-item interaction data, this paper proposes a recommendation algorithm framework named M ulti- R epresentation S pace Recommendation with G raph C ontrastive L earning(MRSGCL). Compared with previous works that indirectly model higher-order relations through first-order relations, this paper additionally extracts a homogeneous graph, thereby enhancing the model’s ability to represent preferences. To extract fine-grained preference information from user behavior, we propose an adaptive dual-representation space feature encoding module. This module learns the embeddings of users and items in heterogeneous spaces based on u ser- i tem (UI) interactions, and learns the embeddings of u ser- u ser (UU) and i tem- i tem (II) relationships in homogeneous spaces. Subsequently, to integrate the interest information learned from the two spaces, we propose an interest space alignment module. This module uses contrastive learning to bring the interest distributions of the two spaces closer together while preserving the distinct interest information learned from each space. Finally, we introduce an interest fusion module that combines the interest preferences from the two spaces using both adaptive and heuristic methods. We conducted extensive experiments on three public datasets, validating the effectiveness and robustness of our approach, achieving excellent experimental results. This demonstrates the scalability and high applicability of our method.},
  archive      = {J_ESWA},
  author       = {Xiaoda Li and Yue He and Jing Li and Kai Zhu and Jun Chang and Jiaheng Yu},
  doi          = {10.1016/j.eswa.2025.129274},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129274},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-representation space recommendation with graph contrastive learning},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing belief consistency of large language model agents in decision-making process based on attribution theory. <em>ESWA</em>, <em>297</em>, 129273. (<a href='https://doi.org/10.1016/j.eswa.2025.129273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social simulation, maintaining consistent beliefs ( e.g. , core cognition, position, and goal) is crucial for Large Language Model (LLM) agents to effectively assume specific roles and make coherent decisions. However, LLMs generate responses incrementally through next-token predictions based on preceding words, making them vulnerable to context ambiguity. This can cause their decision-making behavior to deviate from initial goals. To address this issue, we propose the Attribution-based Decision-Making Approach (ADMA), inspired by human attribution processes. ADMA comprises three modules: generation, evaluation, and attribution. Rather than making impulsive decisions, ADMA encourages LLMs to systematically attribute the underlying beliefs associated with each potential choice, and then adjust their decisions accordingly. Through iterative application, ADMA promotes better alignment between generated decisions and predefined goals. We evaluate ADMA in a debate scenario, where beliefs are continuously challenged by opposing arguments, influencing both stance and rebuttal strength. Empirical results show that the attribution process enhances belief consistency, as well as fluency, persuasiveness, and confidence. ADMA also improves LLM agents’ resistance to persuasive language. Furthermore, belief consistency increases with more attribution iterations, albeit with diminishing returns. These findings underscore the potential of attribution theory to strengthen belief stability in LLM agents.},
  archive      = {J_ESWA},
  author       = {Guoxiu He and Meicong Zhang and Tiancheng Su and Li Ma and Xiaomin Zhu},
  doi          = {10.1016/j.eswa.2025.129273},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129273},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing belief consistency of large language model agents in decision-making process based on attribution theory},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A chaotic-system-based parallel image encryption algorithm with orthogonal arrays supporting thumbnail decryption. <em>ESWA</em>, <em>297</em>, 129272. (<a href='https://doi.org/10.1016/j.eswa.2025.129272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a technology which offers users with on-demand access to various resources, and the protection of user information has turned into one significant challenge for cloud service providers (CSPs). In order to enhance the security of image files while meeting the performance demands of cloud computing, this study mainly focuses on the protection of image information in cloud environments, and then an efficient multi-image encryption strategy with fusion of DNA coding and orthogonal arrays is proposed. This scheme is tailored for parallel computing environments in the cloud, which can be able to achieve multi-threaded encryption/decryption for large numbers of images with various sizes at high speed. During the process of decryption, it allows users to spend less time decrypting the encrypted images into thumbnails or selectively decrypting specific images for easier browsing, which significantly reduces data transmission and server computation loads. The encryption keys are generated through coupling one discrete memristor and a sine map into one new chaotic map, then the orthogonal arrays and DNA coding for bit-level encryption and permutation of images are supplied to enhance the encryption security. Simulation tests and security analysis indicate that the strategy achieves high levels of safety and reliability while delivering excellent performance. The more images being encrypted, the higher the encryption efficiency will be. In the test environment, the speed can reach up to 24 MB/s, which is far exceeding encryption algorithms implemented on the same platform. In addition, this study further extends the application of proposed encryption scheme to the encryption of video data, the relevant analysis and simulations are supplied to verify the feasibility and effectiveness of the scheme.},
  archive      = {J_ESWA},
  author       = {Lili Zhou and Qilin Chen and Fei Tan and Changxin Wu},
  doi          = {10.1016/j.eswa.2025.129272},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129272},
  shortjournal = {Expert Syst. Appl.},
  title        = {A chaotic-system-based parallel image encryption algorithm with orthogonal arrays supporting thumbnail decryption},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). XRL-TO: An explainable reinforcement learning-based approach for bus timetable dynamic optimization. <em>ESWA</em>, <em>297</em>, 129271. (<a href='https://doi.org/10.1016/j.eswa.2025.129271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bus timetable optimization is crucial for a bus-centric public transportation system. Existing bus timetable optimization methods typically produce fixed timetables based on historical passenger flows, limiting their ability to meet real-time passenger demand fluctuations. Although dynamic optimization methods based on deep reinforcement learning (DRL) have been explored recently, they often fail to accurately capture real-time passenger demand and prioritize minimizing costs at the expense of service quality. Additionally, their black-box nature limits transparency, potentially introducing redundant state features that hinder the model’s ability to capture passenger demands and reduce stability. In this paper, we propose a new eXplainable Reinforcement Learning-based approach for bus Timetable dynamic Optimization (XRL-TO). Specifically, a novel Markov Decision Process (MDP) model is developed to effectively capture passenger demand and balance service quality and operating costs. An Attention-based Deep Q-Network (ADQN) is employed as the agent to process the new state representation. To enhance its transparency, a LIME-based Reinforcement Learning eXplainability method (LRLX) is proposed to analyze the decision-making process of ADQN and systematically refine the state representation, improving both the transparency and stability of XRL-TO. Experimental results on real-world data demonstrate that XRL-TO significantly reduces both operating costs and passengers’ average waiting time compared to state-of-the-art algorithms. Furthermore, LRLX substantially enhances the transparency and stability of our approach, making it highly valuable for bus timetable dynamic optimization in practice.},
  archive      = {J_ESWA},
  author       = {Guanqun Ai and Xingquan Zuo and Gang Chen and Mengchu Zhou and Binglin Wu and Xinchao Zhao},
  doi          = {10.1016/j.eswa.2025.129271},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129271},
  shortjournal = {Expert Syst. Appl.},
  title        = {XRL-TO: An explainable reinforcement learning-based approach for bus timetable dynamic optimization},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-tier linguistic and emotional modeling for cyberbullying detection in tamil social media. <em>ESWA</em>, <em>297</em>, 129270. (<a href='https://doi.org/10.1016/j.eswa.2025.129270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying presents a growing threat in online communities, with low-resource linguistic contexts like Tamil remaining critically underexplored. This study introduces a novel multi-tier computational framework designed for culturally-aware cyberbullying detection in Tamil-language social media content. We first present the Tamil Cyberbullying (TCB) dataset-comprising 47,692 manually annotated tweets-spanning age, gender, ethnicity, religion-based abuse, and non-bullying categories. Our framework integrates four key processing layers: (i) FastText-based linguistic embedding and TF-IDF noise reduction; (ii) Aho-Corasick-driven rule-based filtering for abusive lexical patterns; (iii) contextual representation learning via fine-tuned mBERT; and (iv) deep sentiment-emotion fusion using BiLSTM and Emotion-Cause Pair Extraction (ECPE), followed by hybrid classification using CNN and GNN modules. The proposed model achieves 84.00% accuracy, outperforming baseline multilingual transformers and large language models (LLMs) such as LLAMA3.1 and Mistral-405B. Precision, recall, and F1-score are 82.28%, 83.28%, and 82.75%, respectively. Human-AI comparative analysis reveals improved sensitivity to cultural expressions, while ablation studies validate the contribution of each tier. Our approach addresses the nuances of sarcasm, emotion, and linguistic diversity in Tamil, providing a scalable blueprint for multilingual cyberbullying detection. All models and data are released under open-access licensing, with rigorous ethical and privacy compliance. The framework accounts for emotion label distribution and cultural nuances in Tamil discourse, ensuring interpretability and ethical robustness.},
  archive      = {J_ESWA},
  author       = {Jothi Prakash V․ and Arul Antran Vijay S․},
  doi          = {10.1016/j.eswa.2025.129270},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129270},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-tier linguistic and emotional modeling for cyberbullying detection in tamil social media},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive online convex optimization with unknown feedback delay. <em>ESWA</em>, <em>297</em>, 129269. (<a href='https://doi.org/10.1016/j.eswa.2025.129269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Convex Optimization (OCO) with unknown feedback delay presents a considerable challenge, particularly when the delay period is not available a priori. In this paper, we propose an adaptive delayed mirror descent (ADMD) algorithm to address this issue, which incorporates a virtual iterate sequence and a learning rate based on the cumulative missed feedback instances. This method improves regret bounds and eliminates the need for prior knowledge of the delay period. Furthermore, we transform the ADMD algorithm into adaptive delayed dual averaging (ADDA) using lazy gradient descent, establishing a connection between these two frameworks. To further enhance the algorithm’s adaptability, we introduce a novel delayed doubling trick. Through extensive experiments, we demonstrate the efficacy of our approach, showing superior performance compared to existing algorithms.},
  archive      = {J_ESWA},
  author       = {Ping Wu and Heyan Huang and Haolin Lu and Zhengyang Liu},
  doi          = {10.1016/j.eswa.2025.129269},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129269},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive online convex optimization with unknown feedback delay},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-state feature importance perception and adaptive interaction importance modeling for CTR prediction. <em>ESWA</em>, <em>297</em>, 129268. (<a href='https://doi.org/10.1016/j.eswa.2025.129268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction presents a fundamental challenge in modern recommender systems, where marginal improvements in prediction accuracy can yield substantial economic returns. While existing deep learning approaches demonstrate promising performance, two critical limitations persist: (1) insufficient representation of feature importance in complex recommendation scenarios, and (2) excessive focus on the manner of feature interactions while neglecting the importance of the interactions. To address these challenges, we propose the Feature Dual-state Importance and Interaction Importance Network (FDIIIN), establishing a novel paradigm for feature representation learning and interaction importance modeling. Our model introduces a dual-state feature perception mechanism that concurrently captures static intrinsic importance and dynamic contextual importance through a parallel structure. Furthermore, we develop a dynamic learning architecture employing channel-wise attention operations with residual connections, enabling efficient computation of interaction importance across high-dimensional feature spaces. Additionally, to optimize model performance and efficiency, we introduce a weight-sharing mechanism in FDIIIN, reducing model complexity while maintaining prediction accuracy. Extensive experiments conducted on three public datasets demonstrate the superiority of the proposed method, achieving competitive performance compared to state-of-the-art baselines. A feature-level comparative analysis demonstrates that the dual-state modeling approach significantly contributes to the overall performance improvement, outperforming other perception methods, such as the conventional multi-head self-attention mechanism. The source code is in https://github.com/huagang01/FDIIIN .},
  archive      = {J_ESWA},
  author       = {Gang Hua and Qing Xie and Yuhan Wang and Lin Li and Mengzi Tang and Yongjian Liu},
  doi          = {10.1016/j.eswa.2025.129268},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129268},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-state feature importance perception and adaptive interaction importance modeling for CTR prediction},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective robust dynamic communication optimization with temporal continuity for highway vehicular networks. <em>ESWA</em>, <em>297</em>, 129266. (<a href='https://doi.org/10.1016/j.eswa.2025.129266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Ad-hoc Networks (VANETs) encounter significant communication challenges in highly dynamic highway environments due to rapid topology changes, varying vehicle densities, and unpredictable channel conditions. To address these challenges, this paper proposes a multi-objective robust optimization framework specifically designed to optimize communication delay, load balance, link quality, and temporal stability of dynamic multi-hop vehicular communication networks on highways. The proposed framework explicitly incorporates temporal continuity constraints to ensure stable and persistent communication paths despite frequent network changes. Moreover, a robust optimization model is formulated to mitigate performance deterioration arising from uncertainties in highway vehicle densities and channel fluctuations. An improved Non-dominated Sorting Genetic Algorithm II (NSGA-II) is developed to solve the multi-objective optimization problem efficiently, achieving optimal trade-offs among conflicting objectives. Extensive simulation experiments using realistic highway vehicle trajectories demonstrate that the proposed method achieves balanced performance across multiple objectives. Compared to traditional routing protocols, the framework provides substantial improvements in load balancing and link quality, while maintaining superior path stability through temporal continuity constraints. The framework demonstrates robust performance under various traffic scenarios and maintains effectiveness despite GPS positioning errors and network partitions. The results validate the framework’s applicability and effectiveness in real-world highway-based intelligent transportation systems, offering a comprehensive solution that addresses the multi-faceted challenges of vehicular communications.},
  archive      = {J_ESWA},
  author       = {Weian Guo and Wuzhao Li and Li Li and Lun Zhang and Dongyang Li and Marcin Hinz},
  doi          = {10.1016/j.eswa.2025.129266},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129266},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective robust dynamic communication optimization with temporal continuity for highway vehicular networks},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Using external knowledge to enhance user preferences for better sequential recommendation. <em>ESWA</em>, <em>297</em>, 129261. (<a href='https://doi.org/10.1016/j.eswa.2025.129261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of recommendation systems, research on sequential recommendation tasks has made progress, but these studies either ignore changes in users’ short-term interests or pay less attention to their long-term preferences. Without considering both short-term interest changes and long-term user preferences, it is impossible to better recommend diverse results and reflect the long-term dependence of user historical behaviors. In addition, the user’s preference data is imbalanced and there is a problem of data sparsity. High-quality representation and learning of user potential interests are easily affected by data sparsity. For these reasons, we propose a knowledge augmented interest representation model (KAIR), which is divided into two stages: (1) User semantic sequence augmentation and short-term fine-grained preference extraction, (2) Key value memory reading and writing for users’ long term fine-grained preferences. In the first training stage, we disentangle multiple intentions from the augmented sequence and select the user’s main intentions at the current moment as their short-term fine-grained preferences. In the second stage, we extract fuzzy interest sets from the knowledge graph and integrate them with the key value memory network. The user’s short-term fine-grained preference is used to query the key value memory network to obtain his or her long-term fine-grained preference. The combination of user short-term and long-term fine-grained preference is considered as the final preference. We conducted extensive experiments on three standard datasets and the results showed that KAIR outperformed the state-of-the-art baseline models. The code is available at https://github.com/spider-123456/KAIR .},
  archive      = {J_ESWA},
  author       = {Yubin Ma and Zhihong Zheng and Xuan Zhang and Zhi Jin and Weiyi Shang and Wei Cai and Chen Gao and Linyu Li},
  doi          = {10.1016/j.eswa.2025.129261},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129261},
  shortjournal = {Expert Syst. Appl.},
  title        = {Using external knowledge to enhance user preferences for better sequential recommendation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The role of automated planning in battle management systems for military tactics. <em>ESWA</em>, <em>297</em>, 129259. (<a href='https://doi.org/10.1016/j.eswa.2025.129259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban warfare presents complex and dynamic challenges for modern military operations, demanding adaptive and responsive support systems. This study presents a Battle Management System (BMS) based on a Wireless Sensor Network (WSN) integrated with an Artificial Intelligence (AI)-powered planner to address key operational issues such as task coordination, resource allocation, mobility management, energy optimization, and communication resilience. Unlike prior works, our study introduces a tightly coupled integration where real-time sensor data dynamically influences AI-generated plans, allowing mission adaptation under battlefield constraints. Our study covers the practical implementation of this AI-enhanced BMS, a showcase of its capabilities through comprehensive urban warfare simulations, its real-world validation at a military facility demonstrating its effectiveness in an operational setting, and a performance benchmarking against state-of-the-art planners, showing superior results in mission success, risk reduction, and resource efficiency. Our findings confirm that AI-driven planning, in conjunction with WSNs, can generate operational plans that address the unique demands of urban combat scenarios with high precision and efficiency.},
  archive      = {J_ESWA},
  author       = {J. Caballero Testón and Olaya Pérez-Mon and María D. R-Moreno},
  doi          = {10.1016/j.eswa.2025.129259},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129259},
  shortjournal = {Expert Syst. Appl.},
  title        = {The role of automated planning in battle management systems for military tactics},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Media-driven eight-compartment epidemic model with genetic algorithm tuned type-2 ANFIS. <em>ESWA</em>, <em>297</em>, 129258. (<a href='https://doi.org/10.1016/j.eswa.2025.129258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formulating real-time disease dynamics that accurately reflect real-world phenomena is a complex task, particularly when accounting for key population classes. This study addresses these challenges by investigating the critical role of media dissemination during pandemics and proposing a novel eight-compartment dynamical model, which includes Immature Susceptible, Susceptible, Aware Susceptible, Quarantined, Exposed, Infected, Under Treatment, and Recovered classes. The system’s properties, including positivity, boundedness, uniqueness, equilibrium points, and optimal control, are rigorously investigated. Advanced methodologies, such as the next generation matrix approach, are employed to derive the basic reproductive number, and a comprehensive sensitivity analysis of its parameters is conducted. To accurately predict the spread of epidemic classes, this study proposes a novel Genetic Algorithm-optimized TYPE-2 Adaptive Neuro-Fuzzy Inference System (GA TYPE-2 ANFIS). This model enhances prediction accuracy by integrating Genetic Algorithm-based backpropagation for optimized parameter tuning. This model improves time series predictions for eight classes by strategically varying time-dependent control variables, such as vaccination strategies and isolation measures, to mitigate disease transmission. Class data is obtained by solving the proposed dynamical system using the Adaptive Moment Estimation solver. Results, characterized by high fitness, low absolute errors, and a regression score exceeding 0.999, demonstrate the effectiveness of the GA TYPE-2 ANFIS. A comparative analysis with conventional Neuro-Fuzzy Inference Systems highlights the model’s superior performance in predicting complex disease dynamics, with enhanced accuracy and fluctuation capture, assessed through mean square error components. Tested on real-world COVID-19 data, it outperformed traditional models, demonstrating robust forecasting capabilities for public health applications.},
  archive      = {J_ESWA},
  author       = {Jayanta Mahato and Anirban Tarafdar and Debasish Patra and Paritosh Bhattacharya},
  doi          = {10.1016/j.eswa.2025.129258},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129258},
  shortjournal = {Expert Syst. Appl.},
  title        = {Media-driven eight-compartment epidemic model with genetic algorithm tuned type-2 ANFIS},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-predictive planning for optimizing drone service delivery. <em>ESWA</em>, <em>297</em>, 129251. (<a href='https://doi.org/10.1016/j.eswa.2025.129251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel Energy-Predictive Drone Service (EPDS) framework for efficient package delivery within a skyway network. The EPDS framework incorporates a formal modeling of an EPDS and an adaptive bidirectional Long Short-Term Memory (Bi-LSTM) machine learning model. This model predicts the energy status and stochastic arrival times of other drones operating in the same skyway network. Leveraging these predictions, we develop a heuristic optimization approach for composite drone services. This approach identifies the most time-efficient and energy-efficient skyway path and recharging schedule for each drone in the network. We conduct extensive experiments using a real-world drone flight dataset to evaluate the performance of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Guanting Ren and Babar Shahzaad and Balsam Alkouz and Abdallah Lakhdari and Athman Bouguettaya},
  doi          = {10.1016/j.eswa.2025.129251},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129251},
  shortjournal = {Expert Syst. Appl.},
  title        = {Energy-predictive planning for optimizing drone service delivery},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLaMA-MoT: A cost-effective framework for visual-linguistic instruction tuning based on multi-head adapters and chain-of-thought. <em>ESWA</em>, <em>297</em>, 129250. (<a href='https://doi.org/10.1016/j.eswa.2025.129250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models(LLMs) has sparked widespread interest among researchers in expanding their visual capabilities in recent years. Despite significant advancements in the visual analysis capabilities within visual-language large models (VLLMs), the logical rigor of the models’ inferential processes is often overlooked, and the high training costs can be prohibitive. To address these issues, we introduce the LLaMA-MoT framework, designed to reduce training costs while enhancing the models’ logical reasoning abilities. LLaMA-MoT effectively reduces resource consumption by avoiding loading visual encoders during training. It employs Multi-Head adapter technology, enabling the model to process multimodal data from multiple perspectives in parallel, thereby mitigating the impact of an unoptimized visual encoder on performance. Furthermore, LLaMA-MoT incorporates a Chain-of-Thought (CoT) training strategy, enriching the model’s logical reasoning by generating related knowledge and CoT. Simultaneously, to maintain the model’s proficiency in natural language processing, LLaMA-MoT utilizes prefix tokens to bridge the processing of unimodal and multimodal instructions. We validated the effectiveness of LLaMA-MoT across four tasks: multimodal scientific question answering, image caption generation, MMLU and multimodal dialogue. Meanwhile, compared to Llava, LLaMA-MoT saves 99.9% in storage costs and only includes 3.3M trainable parameters.},
  archive      = {J_ESWA},
  author       = {Yi Liang and Turdi Tohti and Wenpeng Hu and Tianwei Yan and Shaohuang Wang and Askar Hamdulla},
  doi          = {10.1016/j.eswa.2025.129250},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129250},
  shortjournal = {Expert Syst. Appl.},
  title        = {LLaMA-MoT: A cost-effective framework for visual-linguistic instruction tuning based on multi-head adapters and chain-of-thought},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dependency-based anomaly detection: A general framework and comprehensive evaluation. <em>ESWA</em>, <em>297</em>, 129249. (<a href='https://doi.org/10.1016/j.eswa.2025.129249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is crucial for identifying unusual behaviors in data, which often provide valuable insights. This paper introduces Dependency-based Anomaly Detection (DepAD), a general and modular framework that leverages variable dependencies to uncover meaningful anomalies with improved interpretability. DepAD reframes unsupervised anomaly detection as a sequence of supervised feature selection and prediction tasks, enabling users to tailor detection methods to their data and domain. We systematically evaluate 125 DepAD algorithm variants across 32 real-world datasets, combining different off-the-shelf feature selection and prediction techniques. We compare DepAD with twelve state-of-the-art anomaly detection methods and demonstrate its consistent superior performance. Furthermore, we demonstrate that DepAD provides intuitive and informative interpretations of detected anomalies, highlighting its utility in practical applications.},
  archive      = {J_ESWA},
  author       = {Sha Lu and Lin Liu and Kui Yu and Thuc Duy Le and Jixue Liu and Jiuyong Li},
  doi          = {10.1016/j.eswa.2025.129249},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129249},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dependency-based anomaly detection: A general framework and comprehensive evaluation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-QuadViT: A domain adaptation motor imagery classification model based on a novel quadruple ViT structure. <em>ESWA</em>, <em>297</em>, 129248. (<a href='https://doi.org/10.1016/j.eswa.2025.129248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) has garnered significant attention as one of the most promising paradigms in brain-computer interfaces (BCIs). Exploring algorithms for MI decoding and developing corresponding models are crucial. However, inherent physiological differences between individuals cause a mismatch between target and source domains in BCI decoding, thereby affecting accuracy. With the widespread adoption of deep learning methods in the field of BCIs, particularly the recent surge in transformer models, overcoming these challenges has become more feasible. In this study, we propose a novel Quadruple ViT structure based on the vision transformer (ViT), which facilitates feature interaction between the source and target domains to improve classification accuracy. Based on this structure, we develop a domain adaptation MI classification model, DA-QuadViT. DA-QuadViT first characterizes Electroencephalograms (EEGs) spatio-temporal features using a temporal convolutional network (TCN) and cross-channel convolutional block. It then enables inter-domain feature interaction and intra-domain feature retention through the Quadruple ViT structure and a domain attention block. Furthermore, the model’s generalization is enhanced by multi-task training. Finally, we conducted extensive experiments on four public datasets: BCI competition IV dataset 2a, BCI competition IV dataset 2b, high gamma dataset, and OpenBMI. The results show that DA-QuadViT improves the accuracy of the best-performing baseline method by 2.54 %, 2.57 %, 1.31 %, and 3.36 %, respectively. These findings demonstrate that DA-QuadViT is an effective end-to-end MI classification model and has the potential for generalization to other EEG decoding tasks.},
  archive      = {J_ESWA},
  author       = {Zhenxi Zhao and Yingyu Cao and Hongbin Yu and Junfen Huang},
  doi          = {10.1016/j.eswa.2025.129248},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129248},
  shortjournal = {Expert Syst. Appl.},
  title        = {DA-QuadViT: A domain adaptation motor imagery classification model based on a novel quadruple ViT structure},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-aware neighbor collaborative multi-relationship multi-interest comparative recommender system for diversified book recommendations. <em>ESWA</em>, <em>297</em>, 129235. (<a href='https://doi.org/10.1016/j.eswa.2025.129235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Book recommendation system has become an essential tool for library information transformation, and has received widespread attention recently. Emerging graph neural networks and knowledge graphs are used in today’s recommendation systems for their benefits to data mining. Although some related progress has been made, many existing researches mainly focus on recommendation accuracy too much and miss diversity. In addition, the researches that primarily focus on the interaction between users and items, overlook the multi-attribute information between users and items, which limits the collaborative signals between entity attributes, resulting in unsatisfactory recommendation effects. To address these shortcomings, an Entity-attribute Interactive Knowledge Graph (EIKG) is constructed, in which readers, books, and rich side attributes are unified through typed edges, allowing attribute semantics to propagate alongside behavioral links. This paper aims to embed attribute collaborative signals into the recommendation tasks by utilizing multi-attribute knowledge graphs of readers and books, thereby improving the accuracy and diversity of recommendation systems. Building on the EIKG, a knowledge-aware book recommendation system is proposed. Specifically, four critical parts are designed for the model: 1) a multi-relation attention component that automatically highlights semantically important edges and suppresses noisy ones, 2) the neighbor attribute collaborative component that improves reader behavior similarity and book theme consistency, 3) an attribute-guided contrastive objective that explicitly pulls together diverse themes while retaining highly relevant titles, 4) the reader multi-interest channel adaptively generates multiple interest embeddings based on the reader’s borrowing history data to tailor recommended books for each reader. The seamless coupling of these components forms a unified end-to-end framework that jointly optimizes accuracy and topically aware diversity. By applying these four components, an emerging multi-task training framework that considers recommendation accuracy and book theme diversity is constructed. Experiments on practical datasets show that the model has high recommendation recall and topic diversity.},
  archive      = {J_ESWA},
  author       = {Junchao Xiao and Linhui Wu and Fuli Zhong and Jinling Zhang},
  doi          = {10.1016/j.eswa.2025.129235},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129235},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge-aware neighbor collaborative multi-relationship multi-interest comparative recommender system for diversified book recommendations},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Logic-based benders decomposition approaches for the distributed heterogeneous precast production scheduling problem with eligibility constraints and controllable processing times. <em>ESWA</em>, <em>297</em>, 129234. (<a href='https://doi.org/10.1016/j.eswa.2025.129234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precast production scheduling is a critical component in the industrialized construction sector. This study addresses the Distributed Heterogeneous Precast Production Scheduling Problem with Eligibility Constraints and Controllable Processing Times (DHPPSP_ECCPT). The problem involves allocating production orders across multiple factories, adjusting processing times, and sequencing operations with the dual objectives of minimizing the makespan and the cost associated with processing time adjustments. To tackle this complex problem, we first present two Mixed-Integer Nonlinear Programming (MINLP) models. These models are subsequently linearized into Mixed-Integer Linear Programming (MILP) formulations to enhance tractability. In addition, a Constraint Programming (CP) model is proposed as an alternative modeling approach. Due to the complexity of the problem, particularly for large-scale instances, we develop a novel Logic-Based Benders Decomposition (LBBD) framework based on Manne-based models and problem structure. This framework integrates MINLP and CP to address the Assignment and Adjustment Master Problem (AAMP), and the Scheduling Subproblems (SSPs). To improve computational efficiency, we incorporate strong SSP relaxation-based inequalities into the AAMP within the LBBD framework. Furthermore, valid Benders optimality cuts are generated by solving the SSPs, thereby further strengthening the AAMP. We also propose a variant of the LBBD framework, termed Branch-and-Check (BCH), to address the DHPPSP_ECCPT. Moreover, the integration of the proposed position-based MINLP model with the LBBD framework enhances the robustness of the overall solution approach. Comprehensive computational experiments are conducted to evaluate the performance of the proposed LBBD methods. The results demonstrate their effectiveness and efficiency in solving the DHPPSP_ECCPT, offering valuable insights for prefabricated production scheduling as well as other production scheduling applications.},
  archive      = {J_ESWA},
  author       = {Fuli Xiong and An Ping and Muming Wu and Chengfei Xiang},
  doi          = {10.1016/j.eswa.2025.129234},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129234},
  shortjournal = {Expert Syst. Appl.},
  title        = {Logic-based benders decomposition approaches for the distributed heterogeneous precast production scheduling problem with eligibility constraints and controllable processing times},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic inventory optimization for three-warehouse: Balancing freshness-driven demand and preservation investments. <em>ESWA</em>, <em>297</em>, 129233. (<a href='https://doi.org/10.1016/j.eswa.2025.129233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Warehouses are critical components in modern business operations and function as essential hubs for order fulfilment, buffer stock management, and storage. Effective inventory strategies contribute to cost reduction, timely deliveries, and enhanced business resilience, thereby ensuring a seamless flow of goods and improved operational efficiency. The integration of innovative systems further reinforces the significance of warehouses and positions them as indispensable assets in contemporary commerce. This study investigates a three-warehouse inventory model in which demand is influenced by factors such as product freshness and pricing. The model incorporates trade credit policies, accounts for partial backlogging, and utilizes a Weibull distribution to characterize the amelioration rate. The deterioration rate is assumed to be constant and is managed through strategic investments in preservation technology. The inventory is distributed across three facilities: two rental warehouses (RWs) and an own warehouse (OW). Orders are fulfilled primarily from the RWs, whereas the OW serves as a backup to optimize stock utilization and minimize holding costs. The objective is to maximize retailer profitability while reducing operational expenses. MATLAB R2023a is used as the computational platform to execute optimization-related functions using a conventional algorithm. This implementation serves to validate the proposed model by demonstrating its effectiveness in managing stock variations. Furthermore, a sensitivity analysis is conducted to assess the effects of critical parameters, providing valuable insights for decision-making and practical inventory management. The proposed model effectively addresses challenges associated with high holding costs and demand fluctuations by optimizing inventory distribution and trade credit policies. Additionally, strategic investments in preservation technology mitigate deterioration losses, thereby contributing to a more sustainable and cost-efficient inventory management system.},
  archive      = {J_ESWA},
  author       = {E. Arunadevi and S. Umamaheswari},
  doi          = {10.1016/j.eswa.2025.129233},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129233},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic inventory optimization for three-warehouse: Balancing freshness-driven demand and preservation investments},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Low-carbon economic optimization of park integrated energy system under hybrid market regulation: A multi-scenario dispatch system integrating ladder-type carbon trading and green certificate trading. <em>ESWA</em>, <em>297</em>, 129232. (<a href='https://doi.org/10.1016/j.eswa.2025.129232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aggravation of the global greenhouse effect and the worsening of the energy crisis, renewable energy efficient utilization and low-carbon transition have become the core issues in the energy sector. Meanwhile, the multiple market regulations have increasingly emphasized the low-carbon requirements for energy development. However, the combined heat and power (CHP) units of the Park Integrated Energy System (PIES) have traditional-model limitations, which challenge the efficient consumption of renewable energy. In this regard, this research designs an optimal dispatch model based on an interaction trading mechanism of Ladder-type Carbon Trading (LCT)-Green Certificate Trading (GCT) with CCP coupling, which couples CHP, Carbon Capture and Storage (CCS) and Power-to-Gas (P2G). First, an analysis is conducted on the operation principles of LCT and GCT, followed by the development of their models and the interaction mechanism. Second, the CCP coupling model is established with subsequent investigation revealing the coupling characteristics of electricity and heat within the CCP mode. Finally, the PIES optimal dispatching model is constructed with the optimization objective of minimizing the total cost. The simulation results demonstrate that the proposed dispatching strategy significantly reduces total costs and carbon emissions, and improves renewable energy utilization. It is crucial to set reasonable carbon trading base price, interval length, green certificate price, green certificate quota coefficient and conversion coefficient among LCT-GCT. Under the CCP mode, the LCT-GCT interaction mechanism enables the PIES to achieve dual economic-ecological benefits, providing a novel and synergistic pathway for collaborative integration between traditional CHP and renewable energy projects.},
  archive      = {J_ESWA},
  author       = {Lingli Li and Dezhi Li and Yu Zhang and Shenghua Zhou and Jinbo Song and Lugang Yu and Wentao Wang and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129232},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129232},
  shortjournal = {Expert Syst. Appl.},
  title        = {Low-carbon economic optimization of park integrated energy system under hybrid market regulation: A multi-scenario dispatch system integrating ladder-type carbon trading and green certificate trading},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive switching mechanism combined with KL divergence for distributed fusion of multiple model estimators in target tracking. <em>ESWA</em>, <em>297</em>, 129231. (<a href='https://doi.org/10.1016/j.eswa.2025.129231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed fusion exhibits superior scalability and structural robustness, making it commonly employed for fusing the outputs of various multiple model estimators to achieve high-performance target tracking. However, existing distributed fusion encounter two significant challenges: inadequate utilization of local information and the complexity in determining optimal fusion weights. Concerning these issues, this paper introduces a distributed fusion method that integrates Kullback–Leibler divergence with adaptive switching mechanism. First, this method designs a criterion based on minimizing forward Kullback–Leibler divergence for fusing Gaussian mixture model outputs from each multiple model estimator, thereby fully retaining local estimation information. Through theoretical analysis, the consistency of support set and effectiveness of this fusion criterion are verified. Second, a novel adaptive switching mechanism is proposed to increase the selection precision rate of the dominant model by analyzing its historical movement. Additionally, by assessing the probability difference between adjacent moments, the delay in model switching is minimized, enabling real-time optimization of the fusion weights. Finally, simulation experiments are designed for three tracking modes in two distinct scenarios, verifying the proposed method’s effectiveness in terms of model selection precision and fusion estimation accuracy. The method significantly advances intelligent multi-sensor tracking systems.},
  archive      = {J_ESWA},
  author       = {Yida Ning and Jiongqi Wang and Juhui Wei and Bowen Hou},
  doi          = {10.1016/j.eswa.2025.129231},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129231},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive switching mechanism combined with KL divergence for distributed fusion of multiple model estimators in target tracking},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LiqBoost: Enhancing liquidity provision for blockchain-based decentralized exchanges. <em>ESWA</em>, <em>297</em>, 129230. (<a href='https://doi.org/10.1016/j.eswa.2025.129230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquidity management in decentralized exchanges (DEXs) is a crucial research area in the blockchain industry due to its fundamental role in facilitating efficient trading of cryptocurrencies and fostering market stability. However, existing DEXs often face challenges related to liquidity management, which hinders their widespread adoption and effectiveness. This paper introduces LiqBoost , a novel liquidity provision scheme specifically tailored for Uniswap V3, one of the leading DEX platforms. Our approach focuses on dynamically reallocating the positions of Liquidity Providers (LPs). Simulations using historical transaction data from Uniswap V3 demonstrate that LiqBoost significantly reduces trading costs for traders and enhances incentives for LPs compared to the status quo of Uniswap V3. We detail the system design for on-chain implementation of LiqBoost , leveraging the existing Uniswap V3 framework. This underscores the practicality and effectiveness of LiqBoost within the decentralized finance (DeFi) landscape.},
  archive      = {J_ESWA},
  author       = {Woojin Jeong and Seongwan Park and Jaewook Lee and Yunyoung Lee},
  doi          = {10.1016/j.eswa.2025.129230},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129230},
  shortjournal = {Expert Syst. Appl.},
  title        = {LiqBoost: Enhancing liquidity provision for blockchain-based decentralized exchanges},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Metacognitive skills driven knowledge tracing. <em>ESWA</em>, <em>297</em>, 129229. (<a href='https://doi.org/10.1016/j.eswa.2025.129229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) monitors students’ knowledge state and predicts their learning performance. Existing KT methods primarily incorporate cognitive skills, e.g. concept mastery, and question-solving to characterize the student learning process. However, high-order metacognitive skills, which control cognitive skills, have not been fully considered. This paper proposes the M etacognitive S kills-driven K nowledge T racing (MSKT) method and models the impact of metacognitive skills on the student’s learning process. It extracts individualized metacognitive skills from learning behaviors and applies information bottleneck and self-attention fusion modules to align and fuse cognitive and metacognitive features. Comprehensive experiments were complemented on two real-world datasets, i.e. Ednet-KT4 and private dataset, along with baseline methods including machine learning-based, deep learning-based, and large language model-based. The results demonstrate that MSKT outperforms existing KT methods and achieves state-of-the-art performance. Visualization experiments show that MSKT further enhances the modeling of the student’s learning process. The ablation study also illustrates that the introduced modules are reasonable and effective. These findings offer practical implications for the design of intelligent tutoring systems, suggesting that the integration of metacognitive skills could lead to more personalized and adaptive learning experiences.},
  archive      = {J_ESWA},
  author       = {Jiaqi Yin and Jingyang Qiao and Haoxin Xu and Tiong-Thye Goh and Yi Hu},
  doi          = {10.1016/j.eswa.2025.129229},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129229},
  shortjournal = {Expert Syst. Appl.},
  title        = {Metacognitive skills driven knowledge tracing},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The manufacturer’s optimal mode implementation strategies for third-party resale platform operations: Trade-in vs. trade-in and refurbishment. <em>ESWA</em>, <em>297</em>, 129228. (<a href='https://doi.org/10.1016/j.eswa.2025.129228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the circular economy and sustainable development, there are many manufacturers implementing trade-in and refurbishment strategies. By constructing a two-period game model involving the manufacturer and strategic consumers, we explore two trade-in strategies: trade-in vs. trade-in and refurbishment. Meanwhile, third-party resale platforms have emerged as significant sales channels for second-hand products. Consequently, along this line, we further consider whether the resale platform exists, developing four game models, i.e., Scenario NT (no resale platform exists and the manufacturer implements trade-in strategies), Scenario NTR (no resale platform exists and the manufacturer implements trade-in and refurbishment strategies), Scenario PT (a resale platform exists and the manufacturer implements trade-in strategies) and Scenario PTR (a resale platform exists and the manufacturer implements trade-in and refurbishment strategies). We examine how the manufacturer determines optimal trade-in strategies for third-party resale platform operations in four different scenarios, deriving several insights: Firstly, higher depreciation rates incentivize the manufacturer to implement trade-in strategies. However, the higher upgrade level instead puts the manufacturer in a profit dilemma when implementing either strategy. Secondly, the platform can effectively mitigate the direct shock of the depreciation rate on old products’ prices and decrease the manufacturer’s reliance on recycling channels. Ultimately, we discover that the existence of the platform is not always favorable for the manufacturer to implement trade-in strategies. The effectiveness of the platform can be fully captured only when the depreciation rate is either relatively low or high.},
  archive      = {J_ESWA},
  author       = {Xiaobing Jin and Bohai Liu and Xian Liu and Tao Zhou and Handong Zheng and Kai Li},
  doi          = {10.1016/j.eswa.2025.129228},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129228},
  shortjournal = {Expert Syst. Appl.},
  title        = {The manufacturer’s optimal mode implementation strategies for third-party resale platform operations: Trade-in vs. trade-in and refurbishment},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-scale feature extraction and attention aggregation network for underwater image enhancement. <em>ESWA</em>, <em>297</em>, 129226. (<a href='https://doi.org/10.1016/j.eswa.2025.129226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acquisition of high-quality underwater images necessitates the fulfillment of three pivotal capabilities: multi-scale feature extraction, local detail encoding, and global context modeling. Nonetheless, contemporary methods for underwater image enhancement (UIE) have consistently fallen short in effectively encapsulating all three capabilities concurrently. Thus, we introduce a novel UIE network, called MSEA-UNet, which is tailored to integrate these three capabilities effectively. Utilizing a classic encoder-decoder architecture, the proposed framework integrates multi-scale feature extraction with attention aggregation mechanisms to exhaustively enhance the quality of underwater images. Concretely, we first design the Multi-scale Feature Extraction Attention module (MFEA) to extract the shallow features of underwater images through dual pathways of spatial and channel information, and significantly enhance the expressive power of image features by leveraging multi-scale convolutions and attention mechanisms. In the encoder, we adopt an efficient Convolutional Downsampling module (ConvDown) to reduce information loss while lowering computational complexity. Besides, we use a SimAM attention module at the neck of the network to achieve adaptive weighting of features. In the decoder, we propose a Multi-scale Concurrent Spatial and Channel Upsampling module (MCSC Up), which effectively restores the spatial resolution of images through transposed convolutions and multi-scale feature fusion. Moreover, by leveraging the local feature extraction capabilities of Convolutional Neural Networks (CNNs) with the global modeling capabilities of Vision Transformer (ViT), we present a Multi-head Transposed Attention Aggregation module (MHTA). This module effectively integrates long-range dependencies between the encoder-decoder and dynamically fusing local and global features. Experimental results demonstrate that MSEA-UNet achieves performance levels comparable to the state-of-the-art UIE methods in both subjective and objective evaluation metrics, outperforming existing UIE methods.},
  archive      = {J_ESWA},
  author       = {Xiaohong Yan and Xiaotong Liu and Renteng Qu and Baihui Ning and Fengqiang Xu and Yanjuan Wang and Fengqi Li},
  doi          = {10.1016/j.eswa.2025.129226},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129226},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-scale feature extraction and attention aggregation network for underwater image enhancement},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTKGRec: A context-aware temporal knowledge graph reasoning model for next POI recommendation. <em>ESWA</em>, <em>297</em>, 129224. (<a href='https://doi.org/10.1016/j.eswa.2025.129224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next point-of-interest (POI) recommendation task aims to predict the next place of interest for a user based on their historical check-in information and current status, which is vital for improving the quality of location-based services (LBS). Existing methods often leverage rich information to construct various graphs or knowledge graphs that capture higher-order information about users and POIs. However, most knowledge graph-based POI models adopt traditional static knowledge graph methods, which makes it difficult to capture the complex temporal dynamics in user check-in data. That is, the user’s check-in data exhibits a certain habitual repetition pattern and is influenced by the global popularity trend and transient factors. In this paper, we propose CTKGRec, a model based on a context-aware temporal knowledge graph that we construct, namely CTKG. The model incorporates user personal preferences and global POI transfer preferences to recommend the next POI. The model employs a context-aware copy mechanism and generates the habit prediction for repetitive check-ins and the novelty prediction for unfamiliar POIs based on the user’s memory. Extensive experiments on two large-scale real-world datasets demonstrate that our proposed method achieves state-of-the-art performance.},
  archive      = {J_ESWA},
  author       = {Qihong Pan and Hong Zheng and Zhenzhen Zhao and Xiangjie Kong and Guojiang Shen and Xiangyu Zhao},
  doi          = {10.1016/j.eswa.2025.129224},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129224},
  shortjournal = {Expert Syst. Appl.},
  title        = {CTKGRec: A context-aware temporal knowledge graph reasoning model for next POI recommendation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view multi-scale adapter squeeze excitation network with domain generalization for cross-subject emotion recognition. <em>ESWA</em>, <em>297</em>, 129222. (<a href='https://doi.org/10.1016/j.eswa.2025.129222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition using electroencephalography (EEG) is a vital research area in brain-computer interface systems. However, existing approaches often suffer from two major limitations: (1) insufficient modeling of multi-scale emotional patterns across spatial, temporal, and spectral views, which restricts the extraction of comprehensive discriminative features; and (2) poor generalization across subjects due to the non-stationary and highly individual nature of EEG signals. To address these challenges, we propose a novel Multi-view Multi-scale Adapter Squeeze-Excitation Network with Domain Generalization (MMASE-DG) for cross-subject EEG-based emotion recognition. Specifically, the proposed model first captures emotion-related features across multiple scales and views–spatial, temporal, and spectral–enabling the model to learn both fine-grained and global representations. Then, an adapter-based squeeze-excitation (SE) module is introduced to progressively fuse multi-scale features from each view, enhancing emotional feature expression through hierarchical integration. Finally, a domain generalization mechanism is integrated into MMASE-DG to extract subject-invariant features, improving robustness to inter-subject variability. Abundant experiments on the DEAP, SEED, and SEED-IV datasets to assess our model, and experimental results demonstrate that our method consistently outperforms state-of-the-art approaches in terms of accuracy and generalization.},
  archive      = {J_ESWA},
  author       = {Cheng Cheng and Wenzhe Liu and Ziyu Jia and Weiqi He},
  doi          = {10.1016/j.eswa.2025.129222},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129222},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-view multi-scale adapter squeeze excitation network with domain generalization for cross-subject emotion recognition},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Variable-scale acoustic texture image and interpretable filter convolutional networks for defect monitoring in laser powder bed fusion. <em>ESWA</em>, <em>297</em>, 129221. (<a href='https://doi.org/10.1016/j.eswa.2025.129221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of Laser Powder Bed Fusion (LPBF) has led to an increasing interest in the process monitoring technologies. However, the common method of combining signal sensing and machine learning (ML) in LPBF defect monitoring faces two primary challenges: (1) varying laser scan speeds lead to data imbalance due to differing amounts of data collected per unit distance. (2) the widely used convolutional neural networks lack interpretability. In view of the above limitations, this paper proposes a defect monitoring method of variable-scale acoustic texture image and interpretable texture convolution. First, based on the typical characteristics of LPBF acoustic signals, this method can represent relevant physical information in the form of texture, and guide scale design in combination with process parameters. Secondly, based on the advanced texture filter function as the underlying architecture, the interpretable texture kernel convolution is extended and designed. The acoustic texture image designed in combination with processing parameters can characterize the frequency information of the LPBF process, and the interpretable texture convolution makes the feature extraction interpretable. Finally, the effectiveness of the method is verified on the LPBF defect dataset. The results show that the acoustic texture image can effectively represent process information. The interpretable texture convolution achieves interpretable feature mapping, which performs better in terms of parameter quantity, convergence speed and accuracy. In addition, the operation mode of the proposed method is verified through visual analysis.},
  archive      = {J_ESWA},
  author       = {Shuai Zhang and Zhifen Zhang and Rui Qin and Jie Wang and Jing Huang and Zhiwen Li and Yu Su and Guangrui Wen and Qi Zhang and Xuefeng Chen},
  doi          = {10.1016/j.eswa.2025.129221},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129221},
  shortjournal = {Expert Syst. Appl.},
  title        = {Variable-scale acoustic texture image and interpretable filter convolutional networks for defect monitoring in laser powder bed fusion},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedACE: A federated adaptive components exfoliation method for medical image segmentation in non-IID scenarios. <em>ESWA</em>, <em>297</em>, 129215. (<a href='https://doi.org/10.1016/j.eswa.2025.129215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has shown great promise in medical image segmentation, but data silos and privacy concerns limit its applicability. Federated learning (FL) offers a solution by enabling collaborative model training across multiple institutions without sharing sensitive data. However, FL performance degrades significantly under non-IID medical data. Through empirical analysis, we find that the response of the model to non-IID data is entropy-sensitive. Inspired by these insights, we propose Fed erated A daptive C omponents E xfoliation (FedACE), a novel framework that aggregates parameters of local model components adaptively according to their importance. The key component of FedACE is an A daptive C omponents E xfoliation (ACE) module. This module quantifies the contribution of all component parameters of the local model through sensitivity analysis and information entropy. It adaptively excludes the components with negative contributions from parameter uploading for global aggregation. We evaluate FedACE on three diverse real-world medical image segmentation datasets: CAMUD, REFUGE2, and Polyp. Experimental results demonstrate that FedACE consistently outperforms serveral state-of-the-art (SOTA) FL methods, including FedProx, FedFOR, FedPer, FedBN, Ditto and IOP-FL, achieving a maximum improvement of 11.71 % in the accuracy and reducing communication overhead by up to 22.91 % compared to baselines.},
  archive      = {J_ESWA},
  author       = {Sheng Liang and Songwen Pei and Chunhua Gu and Liu Yang and Zelei Liu and Lixin Fan and Xin Yang},
  doi          = {10.1016/j.eswa.2025.129215},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129215},
  shortjournal = {Expert Syst. Appl.},
  title        = {FedACE: A federated adaptive components exfoliation method for medical image segmentation in non-IID scenarios},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating the impact of distribution static compensators on power quality enhancement with finite element interpolated neural networks in modern power systems. <em>ESWA</em>, <em>297</em>, 129214. (<a href='https://doi.org/10.1016/j.eswa.2025.129214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing power quality (PQ) in a power system connected to a Distribution Static Compensator (DSTATCOM) is essential for boosting electrical networks’ dependability and efficiency by lowering harmonics, voltage fluctuations, and other disruptions, which leads to the best possible performance of delicate loads and equipment. The complexity of control algorithms, achieving fast response times to transient events, dealing with the variability of renewable energy sources, and ensuring compatibility with existing grid infrastructure and standards are all significant challenges in improving power quality in DSTATCOM-connected power systems. To overcome these issues; this manuscript proposed a hybrid approach for improving PQ in grid connected systems. The presented hybrid method improves power quality by combining the Black winged Kite Optimization Algorithm (BWKOA) with Finite Element Interpolated Neural Network (FEINN). Hence, it is named as BWKOA-FEINN. The goal of this study is to improve the PQ distribution system by optimizing reactive power compensation strategies for enhanced voltage regulation and stability. The Tilted Integral Fractional Derivative and Filter plus Fractional Derivative Controller (TIFDNFD) controller is used for Active power correction, voltage sag, and voltage swells. The TIFDNFD controller’s gain parameter is adjusted using the proposed BWKOA, and the TIFDNFD controller parameters are predicted using FEINN. By then, the evaluation of the proposed strategy is executed and compared with various existing strategies in MATLAB. Performance of the proposed BWKOA −FEINN approach attains 0.6 % lower Total Harmonic Distortion (THD); when analyzed through existing techniques like Particle swarm optimization (PSO) THD 1.2 %, Whale optimization approach (WOA) THD 2.1 % and Artificial Rabbits Optimizer(ARO) THD 2.2 %. The proposed technique error value is 0.01 %, the PSO algorithm error value is 0.03 %, the ANN algorithm error value is 0.02 % and the FFNN approach error value is 0.04 %, respectively.},
  archive      = {J_ESWA},
  author       = {Venkata Prasad Papana and Balasubbareddy Mallala and Venkata Krishna Reddy Chinthalacheruvu and Kowstubha Palle},
  doi          = {10.1016/j.eswa.2025.129214},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129214},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating the impact of distribution static compensators on power quality enhancement with finite element interpolated neural networks in modern power systems},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for scheduling of single-arm cluster tools with activity time variation. <em>ESWA</em>, <em>297</em>, 129213. (<a href='https://doi.org/10.1016/j.eswa.2025.129213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-arm cluster tools (SACTs) are widely used in wafer manufacturing, where efficient scheduling is crucial for maximizing productivity and minimizing wafer delay time. However, activity time in practical operations is subject to random variations, making it challenging to simultaneously minimize cycle time and total delay time. To address this issue, we propose a two-stage multi-criteria decision framework, named Bi-objective Mandatory Waiting Time Optimization Method (BMWTOM). Firstly, mandatory robot waiting time before wafer loading is set for some steps using the Mandatory Waiting Method (MWM), while the Earliest Starting Strategy (ESS) is applied to the remaining robot tasks. Secondly, several state-of-the-art multi-objective optimization meta-heuristic algorithms are employed to determine the optimal waiting time, generating a Pareto set of non-dominated solutions. The Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) is then used to rank these solutions according to decision-makers’ preferences and select the ideal schedule. Finally, numerical experiments on industrial SACT scenarios demonstrate that BMWTOM can effectively optimize both productivity and total wafer delay time under activity time variations, outperforming traditional scheduling methods.},
  archive      = {J_ESWA},
  author       = {Shan Zeng and NaiQi Wu and Yan Qiao},
  doi          = {10.1016/j.eswa.2025.129213},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129213},
  shortjournal = {Expert Syst. Appl.},
  title        = {Bi-objective optimization for scheduling of single-arm cluster tools with activity time variation},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SuKE: Structural knowledge extractor enhances large language model for knowledge graph completion. <em>ESWA</em>, <em>297</em>, 129199. (<a href='https://doi.org/10.1016/j.eswa.2025.129199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current large language model (LLM)-based knowledge graph completion (KGC) methods fail to fully leverage structural information of the knowledge graph (KG), resulting in suboptimal performance. They typically incorporate KG information into LLMs through either direct fine-tuning or employing soft prompts derived from conventional embedding-based KGC models. However, these methodologies exhibit fundamental limitations in their capacity to comprehensively encode and exploit the intricate structural information contained within KGs. To address these issues, we first develop KG-infused in-context learning and KG-infused instruction tuning by extending existing LLM paradigms to inject structural information through textual representations. Then we propose a S tr u ctural K nowledge E xtractor (SuKE), a trainable encoder-decoder architecture designed to extract both structural and semantic information from KGs and incorporate it into LLMs, with the overarching goal of enhancing the structural reasoning capabilities of LLMs for KGC tasks. Specifically, in encoder, we propose a Group-wise Graph Attention Network with relation-augmented message function for entity embeddings generation and a dynamic relation representation module using subgraph relational path to produce relation embeddings. Subsequently, a global embedding mechanism is introduced to mitigate the over-smoothing issue of entity and relation embeddings. In decoder, a cross-modal projection mechanism transforms the embeddings of triples into virtual tokens within the textual space, which are then pretended as prefixes to the prompt tokens and injected into the LLM. Experimental performance outperforms the state-of-the-art methods, demonstrating that SuKE significantly boosts the performance of LLMs on KGC tasks and revealing the effectiveness of structural information.},
  archive      = {J_ESWA},
  author       = {Yunhai Ye and Shuo Wang},
  doi          = {10.1016/j.eswa.2025.129199},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129199},
  shortjournal = {Expert Syst. Appl.},
  title        = {SuKE: Structural knowledge extractor enhances large language model for knowledge graph completion},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective hyper heuristic memetic algorithm for time-dependent vehicle routing problem with drone considering simultaneous pickup and delivery. <em>ESWA</em>, <em>297</em>, 129196. (<a href='https://doi.org/10.1016/j.eswa.2025.129196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates a multi-objective time-dependent vehicle routing problem with drone considering simultaneous pickup and delivery, in which multiple vehicle-drone pairs (each consisting of one vehicle and one drone) are used to serve customers. In this problem, various factors are considered, including the capabilities of vehicles and drones to pick up and/or deliver parcels, multiple visits per drone trip, mutual waiting of vehicles and drones, energy consumption during drone hovering, differentiated service times based on parcel weight, time-dependent road network, time windows, and multiple optimization objectives. With the goal of minimizing the total cost and total violation time, a multi-objective mathematical model is first established. To address the problem effectively, a multi-objective hyper heuristic memetic algorithm is proposed. Specifically, a novel solution representation method is designed, two evaluation functions are developed to check the feasibility of the solution, and based on them, a fast evaluation method is proposed to accelerate the evaluation of the solution. In addition, to maintain the size of the feasible solution set and utilize the information of infeasible solutions, a solution set update strategy is introduced. Then, based on the problem characteristics and the encoding scheme, 12 low-level heuristics are carefully designed and used for generating new solutions. With these low-level heuristics, an estimation of distribution algorithm based hyper heuristic and a decomposition based local search strategy are proposed to achieve an effective search in the solution space of the problem. Finally, experimental tests and analyses are performed to show the accuracy of the mathematical model and the effectiveness of the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Haohao Duan and Xiaoling Li and Yanxiang Feng and Guanghui Zhang and Qingchang Lu and Xu Meng},
  doi          = {10.1016/j.eswa.2025.129196},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129196},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective hyper heuristic memetic algorithm for time-dependent vehicle routing problem with drone considering simultaneous pickup and delivery},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving the response surface methodology optimization with metaheuristics: A practical approach. <em>ESWA</em>, <em>297</em>, 129195. (<a href='https://doi.org/10.1016/j.eswa.2025.129195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Response Surface Methodology (RSM) is a powerful statistical technique that explores the relationship between input and output response variables using statistical methods and mathematical tools throughout the process. Optimization in the RSM is carried out using deterministic models that usually fall into local optima, losing the possibility of finding parameters that achieve better results. To overcome this problem, this article proposes applying metaheuristic algorithms (MA) in the optimization phase of RMS. Here MA offers a solution by optimizing the models derived from RSM. Three real problems are used to verify the performance of the combination of MA with RSM: removal of chemical oxygen demand, biodiesel synthesis from Ceiba pentandra oil, and biodegradation yield of reactive blue. The experimental results validate that the RSM with MA optimize with better results than the models obtained from the analysis of variance. For experimental purposes nine MA were used: Covariance Matrix Adaptation Evolution Strategy (CMAES), Differential Evolution (DE), Estimation of Distribution Algorithm (EDA), Particle Swarm Optimization (PSO), Comprehensive Learning PSO (CLPSO), Runge Kutta Optimizer (RUN), Dung Beetle Optimizer (DBO) Liver Cancer Algorithm (LCA), and Sea-Horse Optimizer (SHO). The metaheuristic with the best results in solving the three problems was the DE. The DE obtained an improvement of 0.56 % over the removal of the first problem, for the second problem it obtained the same result as the deterministic technique, but in the third problem that showed surfaces with greater complexity, an improvement of 5.92 % was obtained. This research is a starting point for work in which RSM is applied to solve real-world problems that generate complex models.},
  archive      = {J_ESWA},
  author       = {Jorge Ramos-Frutos and Javier Cruz-Salgado and Oscar Ramos-Soto and Israel Miguel-Andrés and Ricardo Pérez-Chávez and Diego Oliva and Ángel Casas-Ordaz and Emre Çelik and Mohammad H. Nadimi-Shahraki},
  doi          = {10.1016/j.eswa.2025.129195},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129195},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improving the response surface methodology optimization with metaheuristics: A practical approach},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SQGKT: Student-question interaction graph-based knowledge tracing. <em>ESWA</em>, <em>297</em>, 129175. (<a href='https://doi.org/10.1016/j.eswa.2025.129175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) aims to predict students’ performance by assessing their knowledge states and has been widely applied in online education. However, existing KT models have not delved into the implicit information in the process of students’ answering, such as learning ability, attempt counts, hint counts, etc., so modeling the dynamic relationships among students, questions, and skills based on students’ answer details remains a challenge. In addition, existing models overlook the high-order relationships between students and questions, resulting in the inability to utilize the answering behaviors of students other than the target student. To address these problems, we propose a new graph-based knowledge tracing model named S tudent- Q uestion interaction G raph-based K nowledge T racing (SQGKT) to trace students’ knowledge states and predict the probability that students answer the question correctly next time. Firstly, we quantify learning ability, attempts, and hints to assess students’ learning performance on questions. Then, we construct a student-question graph and a question-skill graph to describe the multiple relationships among students, questions, and skills, respectively. Next, we design a graph embedding and fusion module to perform graph convolution on two graphs and fuse their question embeddings, forming enhanced question representations that integrate students’ answering performance and skill information. Finally, we employ LSTM to trace students’ knowledge states and predict their performance. We conduct extensive experiments on three public datasets (i.e., ASSISTments 2009, ASSISTments 2012, and Junyi), and the experimental results demonstrate that our SQGKT significantly outperforms all baselines, with improvements of at least 2.40 % in AUC and at least 4.72 % in ACC.},
  archive      = {J_ESWA},
  author       = {Tao Xu and Yingying Zhao and Juntao Zhang and Jiaming Deng and Zhilong Zhao and Daojun Han and Fengsi Wang and Xiangqian Wei},
  doi          = {10.1016/j.eswa.2025.129175},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129175},
  shortjournal = {Expert Syst. Appl.},
  title        = {SQGKT: Student-question interaction graph-based knowledge tracing},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Machine learning based optimal, reliable, and cost-effective energy management of a hybrid renewable energy integrated with hybrid solid gravity energy storage. <em>ESWA</em>, <em>297</em>, 129174. (<a href='https://doi.org/10.1016/j.eswa.2025.129174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integration of renewable energy into microgrids is an effective strategy to cope with energy generation and fluctuations in power demand. However, the design of an ideal and reliable energy management system is a challenge since the uncertainties in the renewable output and the reliability of the equipment are considerable. The paper proposes an optimized configuration and management strategy for a hybrid photovoltaic–wind system connected with a hybrid solid oxide fuel cell energy storage system. The model incorporates equipment outage rates and reliability constraints through the load loss probability index. To tackle the problem, a grey-wolf-based machine learning algorithm is adopted, which exhibits a more rapid convergence rate and greater precision than traditional algorithms. Simulation scenarios are conducted with or without consideration of equipment failure issues. According to the obtained results, the authors of the paper observed that obliviousness to the outage rates led to an underestimation of the costs and an overestimation of reliability. Out of the tested combinations, the photovoltaic–wind–storage system outperformed the rest, presenting a total net present cost of £ 1.342 million and a reliability value of 0.00612%. The proposed energy storage system addresses the limitations of energy-based and power-based storage technologies, offering advantages such as higher adaptability and stronger resilience. As a whole, the study provides support for the claim that realistic system behavior and advanced optimization techniques play a crucial role in enhancing the cost-efficiency and reliability of hybrid renewable energy systems in small-scale grid applications.},
  archive      = {J_ESWA},
  author       = {Liang Cai},
  doi          = {10.1016/j.eswa.2025.129174},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129174},
  shortjournal = {Expert Syst. Appl.},
  title        = {Machine learning based optimal, reliable, and cost-effective energy management of a hybrid renewable energy integrated with hybrid solid gravity energy storage},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel data-free class incremental learning framework with adaptive sparse reasoning for EEG emotion recognition. <em>ESWA</em>, <em>297</em>, 129164. (<a href='https://doi.org/10.1016/j.eswa.2025.129164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the framework of incremental learning based on electroencephalography (EEG), cross-subject samples of the same emotion category tend to exhibit highly similar feature distributions. Such homogeneity frequently triggers catastrophic forgetting during model updates. While replaying historical samples or features may alleviate this issue, sample replay requires model retraining, and feature replay typically extracts only terminal-layer features containing limited discriminative information for classification. Therefore, we propose a data-free class incremental learning framework with adaptive sparse reasoning (DCIL-ASR). Specifically, a feature extraction network incorporating Alterable Kernel Convolution (AKConv) and Adaptive Sparse Feature Refinement (ASFR) module is designed to accommodate incremental learning tasks characterized by continuous sample updates. AKConv dynamically constructs diverse sampling structures to enrich feature extraction patterns, while ASFR enhances sparse attention mechanisms to focus on core discriminative features. Subsequently, embedded distillation is employed to extract discriminative features concealed within the intermediate layers of the network, enabling the classification knowledge relevant to the current task to be fully captured. Additionally, the feature generation method of the variational autoencoder is optimized using discriminative knowledge, guiding the model to effectively revisit a substantial set of features that encapsulate task-related discrimination knowledge. By relying on a rich repository of discriminative knowledge and a task-oriented feature generation strategy, the network is endowed with sufficient learning and memory capabilities, thereby eliminating its dependence on original samples. Under the condition of no saved samples, the DCIL-ASR achieved an emotion recognition accuracy of 83.5% for 22 categories and 81.4% for 23 categories, demonstrating its effectiveness in incremental learning.},
  archive      = {J_ESWA},
  author       = {Shuo Zhai and Xiaoliang Guo},
  doi          = {10.1016/j.eswa.2025.129164},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129164},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel data-free class incremental learning framework with adaptive sparse reasoning for EEG emotion recognition},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTEA: Camouflaged topological element attack via causal influence discovery. <em>ESWA</em>, <em>297</em>, 129160. (<a href='https://doi.org/10.1016/j.eswa.2025.129160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have gained significant attention for their ability to process graph-structured data. However, their security and robustness remain critical concerns. Existing attack methods often perturb the entire graph indiscriminately, overlooking limited attack budgets and vulnerable node differences. These methods do not provide appropriate selection of critical topological elements (e.g., nodes, edges or subgraphs), which leads to the inefficient utilization of resources and the limited success rates. To address the aforementioned challenges, we propose a camouflaged topological element attack (CTEA) scheme to perceive vulnerable graph-structured elements through causal influence discovery. The proposed CTEA applies the hierarchical filtering mechanism to identify vulnerable nodes that demand minimal attack resources, which ensures that the resources are allocated in a more targeted manner. Furthermore, it integrates the causal effect evaluation to determine the nodes that play a pivotal role in influencing the performance of GNN model. Finally, our CTEA adopts the iterative greedy gradient perturbation to conduct the optimal element operations (e.g., addition or deletion), with the aim of maximizing the impact of attack under budget constraints. Experimental results demonstrate that CTEA achieves substantial performance degradation across multiple benchmarks, which reduces the classification accuracy by 16.7 % on Cora, 9.0 % on Citeseer, 18.6 % on Reddit, and 16.8 % on Pubmed. It consistently outperforms existing methods in terms of both attack effectiveness and computational efficiency, while exhibiting strong adaptability across diverse GNN architectures and perturbation levels.},
  archive      = {J_ESWA},
  author       = {Ju Jia and Pengyuan Gao and Meng Luo and Cong Wu and Jiabao Guo},
  doi          = {10.1016/j.eswa.2025.129160},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129160},
  shortjournal = {Expert Syst. Appl.},
  title        = {CTEA: Camouflaged topological element attack via causal influence discovery},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Indoor cooperative exploration using robot swarms enhanced by human understanding. <em>ESWA</em>, <em>297</em>, 129090. (<a href='https://doi.org/10.1016/j.eswa.2025.129090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor cooperative exploration refers to deploying robots/vehicles to complete exploration, search, or rescue tasks inside buildings. Traditional cooperative exploration methods based on control science or swarm intelligence struggle to achieve high effectiveness and efficiency due to singularities or local optima in complex environments. Integrating human rationales into robotic swarm systems through Human-Swarm Interaction (HSI) has been shown to be able to enhance system reliability, but its potential benefits for improving indoor cooperative exploration remain unknown. To address this, we propose an HSI-based approach that 1) leverages human understanding to guide a swarm of autonomous robots from a global perspective when exploring an unknown environment, 2) enables the robot swarm to learn human experiences in problem-solving. We developed a prototype system and conducted experiments with human operators, showing that our HSI-based method considerably improves the success rate of autonomous swarm algorithms by 41 % while decreasing the average consumed distance by 15 %. Through experiments, we also showed the potential benefits of integrating heuristics learned from human operators’ experience into current exploration algorithms, enhancing traditional exploration methods and gaining valuable insights for human-AI collaboration design in the future.},
  archive      = {J_ESWA},
  author       = {Cong Hu and Zhengqiu Zhu and Yaqiong Zhou and Yong Zhao and Sihang Qiu and Quanjun Yin},
  doi          = {10.1016/j.eswa.2025.129090},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129090},
  shortjournal = {Expert Syst. Appl.},
  title        = {Indoor cooperative exploration using robot swarms enhanced by human understanding},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective optimization of energy-efficient dynamic distributed job shop by multi-agent expected deep Q-network. <em>ESWA</em>, <em>297</em>, 129048. (<a href='https://doi.org/10.1016/j.eswa.2025.129048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic events will significantly affect production plans and energy consumption in distributed factories. Therefore, this paper proposes an energy-efficient dynamic distributed job shop scheduling problem (EDDJSP). Meanwhile, a mathematical model of the EDDJSP is rigorously established and validated. To tackle the EDDJSP, a novel multi-agent expected deep Q-network (EDQN)-based dynamic scheduling method is developed. Its scheduling framework includes a production guiding agent (G-agent) and two production executing agents, namely the job selecting agent (S-agent) and the factory distributing agent (D-agent), which are trained by the novel EDQN. Specifically, the EDDJSP is modeled as a Markov decision process at first. Then, 18 representative state features are elaborately extracted from the energy-efficient dynamic scheduling environment. Seven objective-related job selection rules and two target-oriented factory distribution rules are designed as the actions of S-agent and D-agent, respectively. To guide the production execution agents, two novel reward functions are developed as the actions of G-agent. Finally, our method’s superiority is comprehensively verified by extensive comparison experiments. The case study suggests that our method can not only enrich the energy-efficient dynamic distributed production scheduling theory but also provide environment-friendly methodological support for green sustainable manufacturing practices.},
  archive      = {J_ESWA},
  author       = {Yong Lei and Qianwang Deng and Zenghui Yi and Kaidan Deng and Yijia Ge and Jingxing Zhang},
  doi          = {10.1016/j.eswa.2025.129048},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129048},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective optimization of energy-efficient dynamic distributed job shop by multi-agent expected deep Q-network},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comparative study of word embedding techniques for classification of star ratings. <em>ESWA</em>, <em>297</em>, 129037. (<a href='https://doi.org/10.1016/j.eswa.2025.129037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telecom services are at the core of today’s societies’ everyday needs. The availability of numerous online forums and discussion platforms enables telecom providers to improve their services by exploring the views of their customers to learn about common problems that customers face. Natural Language Processing (NLP) tools can be used to process the free text collected. One way of working with such data is to represent text as numerical vectors using one of many word embedding models based on neural networks. This research uses a novel dataset of telecom customers’ reviews to perform an extensive comparative study showing how different word embedding algorithms can affect the text classification process. A variety of state-of-the-art word embedding techniques are considered, including BERT, Word2Vec, FastText, and Doc2Vec. Several PCA-based approaches are explored for feature engineering. Moreover, the energy consumption used by the different word embeddings is investigated. The findings show that BERT combined with PCA lead to consistently better text classifiers in terms of precision, recall and F1-Score, particularly for more challenging classification tasks. Moreover, our proposed PCA approach of combining word vectors using the first principal component shows clear advantages in performance over the traditional approach of taking the average.},
  archive      = {J_ESWA},
  author       = {Hesham Abdelmotaleb and Craig Mcneile and Małgorzata Wojtyś},
  doi          = {10.1016/j.eswa.2025.129037},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129037},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comparative study of word embedding techniques for classification of star ratings},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-efficient creativity evaluation in museum cultural creative products: A machine learning framework for data-driven decision-making in product development. <em>ESWA</em>, <em>297</em>, 129014. (<a href='https://doi.org/10.1016/j.eswa.2025.129014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a critical gap in the evaluation of Museum Cultural and Creative Products (MCCPs), where existing models, such as the Museum Product Creativity Measurement (MPCM) model, though effective, are often too complex and impractical for real-world application, especially when supporting data-driven decision-making in product development. The research investigates whether the MPCM model can be simplified without compromising its predictive accuracy and explores the most suitable machine learning algorithms for creativity prediction. The study consists of two phases and utilizes a comprehensive dataset containing 5,423 participants and 17,853 data points from four distinct sources. In the pilot phase, data were collected through online and offline surveys, resulting in the development of three models: the Expert Suggested Model, the Hybrid Opinion Model, and a Machine Learning Model. The in-depth phase involved evaluating five machine learning models—Random Forest (RF), Gradient Boosting Decision Trees (GBDT), Light Gradient Boosting Machine (LightGBM), Support Vector Regression (SVR), and eXtreme Gradient Boosting (XGBoost)—using statistical analysis, model validation, and cross-validation techniques. The RF model underwent four rounds of testing, consistently demonstrating superior performance compared to the MPCM model, especially in predicting creativity with smaller sample sizes (200–300), with average RMSE and MAE values of 0.127 and 0.111, respectively. It indicates a notable difference between consumer-rated and RF-predicted creativity. This research contributes to the theoretical advancement and practical streamlining of creativity evaluation frameworks, enhancing their applicability to MCCPs across diverse cultural contexts. Furthermore, it offers methodological insights into how data-driven approaches inform and enhance decision-making processes in product development.},
  archive      = {J_ESWA},
  author       = {Hui Cheng and Bing-jian Liu and Xu Sun and Xiao Qiu},
  doi          = {10.1016/j.eswa.2025.129014},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {129014},
  shortjournal = {Expert Syst. Appl.},
  title        = {Data-efficient creativity evaluation in museum cultural creative products: A machine learning framework for data-driven decision-making in product development},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modeling impact of covid-19 pandemic on spatial temporal human mobility. <em>ESWA</em>, <em>297</em>, 128972. (<a href='https://doi.org/10.1016/j.eswa.2025.128972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-derived and statistical algorithms are utilized for modeling spatial–temporal human mobility. Post Covid-19, use of SEIR and GLM frameworks incorporating epidemiological, NPIs, and human mobility attributes have been investigated to further understanding of NPI impact on human mobility. All of these approaches have reported limited effectiveness due to various constraints including theoretical models holding true to physical boundaries, statistical models adhering to Gaussian and other assumptions, complexity and resource demand of SEIR models, and simplicity of GLM for modeling human mobility patterns. This paper introduces a novel computational and time efficient methodology for forecasting human mobility under conditions of NPI imposition. Methodology integrates statistical data quality improvement and dimension-reduction techniques with DNN algorithms. It is optimized via grid search hyperparameter tuning and pruning input attributes based on weighted connectivity contributions. Training on 11,418 records produced DNN model optimal configuration comprising 19 inputs including 6 NPIs, 3 hidden layers with 8 neurons each, and output—predicted change in human mobility. Training goodness of fit statistics were: R 2 = 0.9423 and average absolute error (AAE) = 0.03282 while validation on 2,898 set aside records yielded R 2 of 0.9432 and AAE of 0.03147. Counterfactual scenarios simulating NPI impact on human mobility reveals workplace closures; restrictions on gatherings and public transport; and stay-at-home orders reduced human mobility. The methodology, demonstrates high prediction accuracy, ability to generalize, and efficient resource utilization processing unstructured, high-dimensional data and forecasting human mobility. It fills the gap when resource-efficient models with high predictive accuracy is lacking.},
  archive      = {J_ESWA},
  author       = {Leslie Titus-Glover},
  doi          = {10.1016/j.eswa.2025.128972},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {128972},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling impact of covid-19 pandemic on spatial temporal human mobility},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reward-shaping dueling distributed multi-agent deep reinforcement learning framework for dynamic flexible job shop scheduling with random job arrivals. <em>ESWA</em>, <em>297</em>, 128951. (<a href='https://doi.org/10.1016/j.eswa.2025.128951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time scheduling in response to unpredictable events and dynamic disruptions has become increasingly important in practical production environments. Recent decades have witnessed the significant interest in multi-agent deep reinforcement learning (MADRL) for dynamic flexible job shop scheduling problems (DFJSPs). This article proposes a distributed contrastive multi-agent double dueling deep Q -network (DCMAD3QN) framework to solve DFJSP by minimizing tardiness. This framework integrates a marginal contribution evaluation strategy (MCES), a distributed multi-agent dueling DQN (DMAD3QN), and a contrastive reward-shaping double DQN (CDDQN), Within the DCMAD3QN framework, job agents and machine agents collaboratively generate joint decisions on job sequencing and machine assignment in dynamic environments via DMAD3QN. The CDDQN trains reward-mapping agents to evaluate each agent’s contribution to the overall performance after executing joint decisions. To describe dynamic job shop environments, state features reflecting real-time processing information are defined for each agent, coupled with a joint action space comprising job-machine pairs. The MCES then evaluates these joint actions, while the separate reward mapping agent provides feedback on the decision-making effectiveness of the job and machine agents based on these evaluations. Finally, all agents are trained under the framework of DCMAD3QN to optimize the joint decision-making process between job and machine agents. Experimental results demonstrate that DCMAD3QN significantly outperforms priority dispatching rules (PDRs) and other state-of-the-art DRL-based methods across 72 distinct production scenarios with dynamic disruptions. Statistical analyses validate the effectiveness and efficiency of our proposed multi-agent DRL-based framework in optimizing joint decision-making, highlighting the robustness and superiority of DCMAD3QN.},
  archive      = {J_ESWA},
  author       = {Zi-Qi Zhang and Zhao-Meng Wu and Bin Qian and Rong Hu},
  doi          = {10.1016/j.eswa.2025.128951},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {128951},
  shortjournal = {Expert Syst. Appl.},
  title        = {A reward-shaping dueling distributed multi-agent deep reinforcement learning framework for dynamic flexible job shop scheduling with random job arrivals},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Analysis and extension of ordinal priority approach for multi-attribute group decision-making problems. <em>ESWA</em>, <em>297</em>, 128449. (<a href='https://doi.org/10.1016/j.eswa.2025.128449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ordinal priority approach (OPA) model, which requires only ordinal preference rankings as input, is used to assess the weights of alternatives, attributes, and experts in multi-attribute group decision-making problems. In this paper, we revisit the OPA model and present a closed-form solution derived through convex analysis. From a methodological perspective, this analysis not only enhances computational convenience by eliminating the need for linear programming software, but also provides deeper insight into the underlying structure of the OPA model. In addition, we introduce a decreasing convex sequence of weights among ranked alternatives. From a model refinement standpoint, this further restricts the feasible region of the original OPA model, thereby facilitating a clearer identification of preferred alternatives. Finally, from the perspective of attribute structure, we propose a new OPA model with a hierarchical structure of attributes, which broadens the model’s applicability to a wider range of real-world decision-making problems, as demonstrated through a supplier selection case study.},
  archive      = {J_ESWA},
  author       = {Byeong Seok Ahn and Hyung-Tae Ha},
  doi          = {10.1016/j.eswa.2025.128449},
  journal      = {Expert Systems with Applications},
  month        = {2},
  pages        = {128449},
  shortjournal = {Expert Syst. Appl.},
  title        = {Analysis and extension of ordinal priority approach for multi-attribute group decision-making problems},
  volume       = {297},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient ensemble learning with multi-scale fusion based deep neural network for skin lesion classification. <em>ESWA</em>, <em>296</em>, 129302. (<a href='https://doi.org/10.1016/j.eswa.2025.129302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanoma, a type of skin cancer, is a severe skin cancer that is critical for early diagnosis but difficult to detect. Deep learning is promising in melanoma diagnosis because it can automatically analyze visual features and perform end-to-end learning. However, achieving the optimum balance between performance and computational efficiency for the effective use of these models in clinical applications is an important research topic. In this study, three innovative methods are proposed for skin cancer detection: PADSCNet, P-DEFF, and M–DEFF. The PADSCNet is an effective neural network developed with CNN and multi-head attention techniques, designed with fusion methods, and stands out with its minimum number of parameters despite being quite deep. The P-DEFF and M–DEFF are based on ensemble learning techniques; P-DEFF was developed with a single deep learning model, and M–DEFF was developed with multiple pre-trained deep learning models. The proposed approaches were tested on the Skin Cancer: Malignant vs. Benign dataset, which was pre-processed using image enhancement techniques. According to the experimental results, PADSCNet achieved accuracy rates of 88.12 %, P-DEFF 93.75 %, and M–DEFF 95.00 %. In additional experiments conducted with the PADSCNet model, 93.12 % accuracy rates were achieved in the CNN for Melanoma Detection Dataset, and 95.00 % accuracy rates were achieved in the PH 2 dataset. These findings show that the proposed methods are effective in skin cancer detection and can achieve successful results in clinical applications.},
  archive      = {J_ESWA},
  author       = {Hatice Catal Reis and Veysel Turk},
  doi          = {10.1016/j.eswa.2025.129302},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129302},
  shortjournal = {Expert Syst. Appl.},
  title        = {Efficient ensemble learning with multi-scale fusion based deep neural network for skin lesion classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing performance transformer models algorithm for prediction from storytelling. <em>ESWA</em>, <em>296</em>, 129289. (<a href='https://doi.org/10.1016/j.eswa.2025.129289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing models to predict emotional trajectories in narrative texts remains a limited research area. This study investigates the impact of narrative coherence and historical context on sentence-level sentiment prediction (regression) using the novel Harry Potter and The Philosopher’s Stone. We evaluated seven feature configurations, ranging from using only sentiment scores (Feature A) to combinations of Transformer embeddings (cross-encoders like BERT and RoBERTa) and preceding sentiment information (Features B-G). Two data segmentation strategies were applied: Chapter Split, which preserves narrative flow, and Random Split, which randomizes sentences. Results consistently showed that Chapter Split yielded higher R-squared performance, with the combination of RoBERTa + Feature G+ a one-sentence window size achieving the highest R-squared of 0.449. Conversely, performance drastically decreased with Random Split, indicating that narrative coherence is crucial. Nevertheless, features focusing on current sentence representations (Feature F) remained robust on randomized data, while Feature D generally produced identical performance for both Chapter Split and Random Split. This study also demonstrates the superiority of cross-encoders over bi-encoders for narrative contextual sentiment modeling. This research emphasizes that integrating historical features and understanding narrative structure are essential for accurate sentiment prediction in narrative texts.},
  archive      = {J_ESWA},
  author       = {Maya Rini Handayani},
  doi          = {10.1016/j.eswa.2025.129289},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129289},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing performance transformer models algorithm for prediction from storytelling},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-structural view knowledge distillation for node influence prediction in complex networks. <em>ESWA</em>, <em>296</em>, 129280. (<a href='https://doi.org/10.1016/j.eswa.2025.129280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes in complex networks is a fundamental problem with important applications in viral marketing, epidemic control, and social influence analysis. A key challenge in this domain is the scarcity of ground-truth labels: computing accurate influence scores typically requires repeated simulations using diffusion models, which is computationally expensive on large-scale graphs. Additionally, existing deep learning models, particularly those based on graph neural networks (GNNs), often incur high inference costs, limiting their practical deployment. To address these challenges, we propose DistillRWGCN, a knowledge distillation framework based on multi-structural views that captures both structural and local topological features for influence prediction. The framework integrates global and local views of the graph using breadth-first search and depth-first search strategies, fuses the resulting embeddings through an attention mechanism, and distills this knowledge into a lightweight TinyGCN student model via contrastive alignment. DistillRWGCN is trained using only a small subset of influence scores and employs a novel hybrid loss that combines pairwise ranking and Spearman correlation to enhance both prediction accuracy and ranking consistency. Extensive experiments on nine real-world datasets demonstrate that DistillRWGCN achieves up to 23.7 % lower error and 12.5 % higher ranking correlation than state-of-the-art baselines, while significantly reducing inference time. These results highlight the mode’s effectiveness in label-scarce and resource-constrained scenarios.},
  archive      = {J_ESWA},
  author       = {Seyed Amir Sheikh Ahmadi and Parham Moradi and Laleh Tafakori and Mahdi Jalili},
  doi          = {10.1016/j.eswa.2025.129280},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129280},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-structural view knowledge distillation for node influence prediction in complex networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSPI-net framework: A novel optimizer-powered multi-source physical information fusion approach for intelligent diagnosis and interpretability of bearings. <em>ESWA</em>, <em>296</em>, 129279. (<a href='https://doi.org/10.1016/j.eswa.2025.129279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning’s powerful data understanding capabilities triggered a technological revolution in the field of machinery fault diagnosis. However, high-power inverter wind turbine bearings faced significant challenges, including multiple excitation sources of galvanic corrosion faults. These factors made the accurate identification of electrical corrosion faults a technical challenge that needed to be solved. Meanwhile, existing deep inference models were hindered by computational complexity and a lack of transparency in internal mechanisms. To address these inadequacies, this study combined theoretical and applied innovations to propose a novel intelligent diagnosis method for insulated bearings, called MSPI-Net, and enhanced it with a new optimizer. First, a feature information fusion module was uniquely designed to address the problem that single-source information was insufficient to accurately represent the state of insulated bearings. Second, an innovative deep residual contraction module was developed to integrate soft thresholding functionality into the attention mechanism and combine it with the residual network structure. In addition, a novel optimizer named Fast Non-Gradient Descent (YL-FNGD), which was inspired by Newton’s iterative method, was derived. This optimizer achieved fast global convergence of the MSPI-Net framework. Finally, the t-SNE descent technique was introduced to account for the process of extracting features associated with electrical erosion faults by the framework. The framework was evaluated on an experimentally acquired dataset of bearings, revealing outstanding effectiveness, and impressive generalization ability.},
  archive      = {J_ESWA},
  author       = {Tongguang Yang and Shunlian Wang and Shuting Jiang and Hui Ma and Lingli Jiang and Qingkai Han and Xingang Wang and Xiaoyong Li},
  doi          = {10.1016/j.eswa.2025.129279},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129279},
  shortjournal = {Expert Syst. Appl.},
  title        = {MSPI-net framework: A novel optimizer-powered multi-source physical information fusion approach for intelligent diagnosis and interpretability of bearings},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain-specific multi-transfer approaches for deep learning-based glaucoma screening in high myopia patients. <em>ESWA</em>, <em>296</em>, 129265. (<a href='https://doi.org/10.1016/j.eswa.2025.129265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a leading cause of irreversible blindness worldwide, with early detection being essential to preventing vision loss. However, diagnosing glaucoma in highly myopic patients poses significant challenges due to anatomical alterations, such as optic nerve head deformation and retinal nerve fiber layer thinning, potentially obscuring key disease features and causing misdiagnosis. To address these limitations, we propose a novel deep learning-based framework for automated glaucoma screening in highly myopic eyes. Our approach leverages multi-transfer learning, integrating large-scale pretraining with domain-specific adaptation using ophthalmic disease datasets. This methodology enables the model to extract robust and highly discriminative features, improving sensitivity to glaucomatous changes in myopic eyes. Additionally, we incorporate domain transfer pipeline to address the distributional differences between standard datasets and myopia-specific cases, further enhancing the model’s generalization capabilities. To rigorously evaluate our approach, we conduct a comprehensive analysis of state-of-the-art architectures and transfer learning strategies, assessing their impact on classification performance. Experimental results demonstrate that the proposed model consistently outperforms baseline methods, achieving superior accuracy and robustness in glaucoma detection within highly myopic populations. These findings underscore the potential of AI-driven screening tools as reliable and accurate diagnostic aids, supporting clinicians in the early detection and effective management of glaucoma in complex cases.},
  archive      = {J_ESWA},
  author       = {Elena Goyanes and Joaquim De Moura and Antoine Lelong and Patricia Robles-Amor and José M. Martínez-De-La-Casa and Javier Moreno-Montañes and Francisco J. Muñoz-Negrete and Ignacio Uña and Jorge Novo and Marcos Ortega},
  doi          = {10.1016/j.eswa.2025.129265},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129265},
  shortjournal = {Expert Syst. Appl.},
  title        = {Domain-specific multi-transfer approaches for deep learning-based glaucoma screening in high myopia patients},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal multi-objective firefly algorithm with multi-stage niches and route planning application. <em>ESWA</em>, <em>296</em>, 129264. (<a href='https://doi.org/10.1016/j.eswa.2025.129264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective Firefly Algorithm faces challenges when address multi-modal multi-objective optimization problems, such as the inability to recognize equivalent solutions and poor Pareto set completeness. To address these challenges, this paper proposes Multi-modal Multi-objective Firefly Algorithm with Multi-stage Niches (MMOFA-MN). In the niche initialization stage, non-dominated individuals and clustering algorithms are employed to find species seeds. This is accomplished by assigning population individuals to their corresponding species based on proximity. The species radius and the species archive capacity are calculate according to the species distribution, forming stable niches. During the evolutionary stage, each niche evolves independently, enabling the algorithm to recognize the equivalent solution. A learning mechanism and variation operators are incorporated to improve the attraction model of firefly algorithm, thereby improving the population’s exploitation capability. In the niche evaluation stage, each niche undergoes global evaluation to eliminate inferior individuals. Additionally, an update strategy based on the special crowding distance is introduced to increase the species diversity. MMOFA-MN was compared with 9 competing algorithms on 20 test functions through experimental evaluations and Friedman tests based on two performance metrics. Stability analysis revealed that the average success rates and the average computation time of the top three performing algorithms MMOFA-MN, DRSC-MOAGDE, and MMEA-PSL were (86.55 %, 15.02 s), (73.01 %, 3.13 s), and (43.79 %, 42.62 s), respectively. Lastly, MMOFA-MN was applied to weighted grid map route planning, resulting in a collection of high-quality solutions with superior diversity.},
  archive      = {J_ESWA},
  author       = {Li Lv and Wen-Lai Xing and Jeng-Shyang Pan and Hui Wang and Run-Xiu Wu and Ivan Lee},
  doi          = {10.1016/j.eswa.2025.129264},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129264},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-modal multi-objective firefly algorithm with multi-stage niches and route planning application},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimized reconfiguration scheme for a photovoltaic system to boost global peak power under realistic shading conditions: Experimental validation. <em>ESWA</em>, <em>296</em>, 129263. (<a href='https://doi.org/10.1016/j.eswa.2025.129263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting maximum power from solar photovoltaic systems under partial shading conditions (PSC) is challenging. PSC leads to an intense power drop, resulting in shading losses (SL). Hence, it is essential to address this issue by reconfiguring the solar array. This is accomplished by a newly optimized Super Magic-square Reconfiguration (SMR). The proposed SMR is based on 4 × 4 magic squares with distinct numerical symmetry and geometric coherence. The novel SMR has been tested under six realistic shadings, namely: building shade (S-1), tree shade (S-2), lamp-post shade (S-3), chimney shade (S-4), oblique shade (S-5), and horizontal shade (S-6). The strength of the novel SMR has been investigated against conventional solar models (Series-Parallel (SP), Total-Cross Tied (TCT), odd–even (O-E), and odd–even-prime (O-E-P)). The proposed SMR is effectively compared by evaluating the performances like global peak power (GP), power enhanced (PE), performance ratio (PR), shading loss (SL), fill factor (FF), current loss (CL), and local peak numbers (LPN). The proposed SMR boosts the GP by 3.23%-34.32%, FF by 1.11%-26.64%, and SL is attenuated by 4.93%-80.51% during S-1 to S-6 over the considered topologies. Further, a hardware prototype tested under S-1 to S-4 for the novel SMR verifies the authenticity of the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Vijay Laxmi Mishra and Yogesh Kumar Chauhan and Kripa Shankar Verma and Ram Sharan Bajpai},
  doi          = {10.1016/j.eswa.2025.129263},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129263},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimized reconfiguration scheme for a photovoltaic system to boost global peak power under realistic shading conditions: Experimental validation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual tracking of dynamic defective contour based on fused long short-term memory model. <em>ESWA</em>, <em>296</em>, 129262. (<a href='https://doi.org/10.1016/j.eswa.2025.129262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the rapid detection of high-speed objects in a compact dynamic environment, visual simultaneous localization and mapping (VSLAM) may fail to extract defective contours caused by occlusion. Combined with the long short-term memory (LSTM) model, a fast and accurate method is proposed to detect and track dynamic defective contour. Specifically, to improve the perception ability of the LSTM model, visual geometry group (16) (VGG16) and Canny edge detection are balanced to extract high-dimensional spatial features and low-dimensional edge features, respectively. These features are linearly concatenated to form multimodal inputs. Next, by suppressing defective objects caused by the jitter of bounding box, an overlap bounding box perceptual method combined with Kalman filtering is introduced to realize the cross-frame tracking efficiency of dynamic object from low to high. Finally, to address devices occlusion in the feeding system under varying working conditions, a contour transfer approach in the temporal occlusion domain is introduced, leveraging Lucas-Kanade optical flow to enhance contour continuity. Experiments are conducted on simulated videos of motion coordination between stamping stations and handling manipulators in a periodic high-speed stamping production line. Results demonstrate that the proposed method achieves stable and efficient visual tracking of defect contour in dynamic environments.},
  archive      = {J_ESWA},
  author       = {Luchuan Yu and Wenhao Chai and Shenquan Huang and Youzhi Zhang},
  doi          = {10.1016/j.eswa.2025.129262},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129262},
  shortjournal = {Expert Syst. Appl.},
  title        = {Visual tracking of dynamic defective contour based on fused long short-term memory model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Analysis on vision sensing and image processing trends in unmanned aerial vehicles. <em>ESWA</em>, <em>296</em>, 129260. (<a href='https://doi.org/10.1016/j.eswa.2025.129260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study real-time performance optimization, this article offers research of new developments and technological difficulties in vision sensing and image processing for Unmanned Aerial Vehicles (UAVs). By comparing to the previous research done, this study critically evaluates new developments in YOLO-based detection frameworks, such as attention-integrated tracking models and YOLO-D, which are especially suited for UAV applications. The primary innovation of this paper is emphasizing clearly on improving positioning accuracy, which has been a recurring drawback in traditional YOLO implementations due to crude grid-based localization and basic bounding box regressions. In order to combat the factors that directly reduce spatial accuracy in UAV image processing, such as occlusion, backdrop clutter, and scale variance, the study assesses sophisticated designs that incorporate feature enhancement modules, attention mechanisms, and trajectory prediction networks. These enhancements show improvement in precision and resilience, especially in dynamic and limited contexts during the benchmarking across datasets and real-world scenarios. By analyzing swarm coordinating techniques with Wireless Mesh Networks (WMNs), Ad hoc systems, and Flying Ad hoc Networks (FANETs), along with a thorough analysis of their routing protocols, formation dynamics, and security frameworks, this article also tackles important communication bottlenecks. This study provides a comprehensive roadmap toward high-precision, real-time autonomous UAV systems by integrating developments in detection algorithms and network architectures. It serves as a technical reference and a strategic basis for further research and deployment.},
  archive      = {J_ESWA},
  author       = {Tan Jian Ding and Chen Yujun and Lee Yan Kang and Tee Wei Hown and Mohammadmadhi Ariannejad and Mohammad Arif Sobhan Bhuiyan},
  doi          = {10.1016/j.eswa.2025.129260},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129260},
  shortjournal = {Expert Syst. Appl.},
  title        = {Analysis on vision sensing and image processing trends in unmanned aerial vehicles},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimization strategy for longitudinal slip characteristics of unmanned ground vehicles with variable structures. <em>ESWA</em>, <em>296</em>, 129257. (<a href='https://doi.org/10.1016/j.eswa.2025.129257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the current challenges—such as excessive wheel spin during driving and inadequate grip during braking—related to the maneuverability and task execution capabilities of a specific type of distributed-drive unmanned ground vehicle with variable structures, this paper proposes an optimized control strategy to enhance longitudinal slip characteristics. The strategy focuses on selecting and switching the optimal slip rate, with slip rate control as the primary component and four-wheel steering as an auxiliary feature, to enhance the overall driving performance of unmanned ground vehicles. First, a vehicle dynamics model is established, and the architecture of the optimization strategy is designed. Next, using the magic tire model and a Switch-Extended State Observer, the identification of the road adhesion coefficient and the design of the optimal slip rate rule are conducted. An adaptive event-triggered mechanism is introduced for optimal slip rate switching, particularly for driving on docking roads. Following this, a heading angle tracking method centered on four-wheel steering and Proportional Integral Differential control is developed to assist in the driving and braking processes. Additionally, slip rate control for each wheel is implemented based on Model Free Adaptive-modified Sliding Mode Control to mitigate interference from factors such as time delay, strong nonlinearity, and significant coupling, thereby achieving improved response speed and control accuracy. Finally, the reliability and effectiveness of the proposed strategy are validated through co-simulations under various driving conditions and principled experiments conducted with a scaled prototype. Results from both simulations and experiments demonstrate that the proposed strategy holds significant engineering importance for optimizing the longitudinal slip characteristics of distributed-drive vehicles.},
  archive      = {J_ESWA},
  author       = {Shengyang Lu and Yue Jiang and Xiaojun Xu},
  doi          = {10.1016/j.eswa.2025.129257},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129257},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimization strategy for longitudinal slip characteristics of unmanned ground vehicles with variable structures},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clinical CT image super-resolution using pixel-wise hybrid high-dimension mapping-based implicit neural representation. <em>ESWA</em>, <em>296</em>, 129256. (<a href='https://doi.org/10.1016/j.eswa.2025.129256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution computed tomography (HRCT), with its precise fine structure imaging character, is of growing importance in modern clinical practice. Emerging deep-learning-based CT super-resolution (SR) approaches, particularly those arbitrary-scale SR networks employing implicit neural representation (INR), are demonstrated with promising results. Nevertheless, existing INR algorithms are still hindered by the inferior ability to capture CT fine structural detail since the multilayer perceptron module (MLP) in INR is biased to learn high-frequency components. In this paper, we propose to incorporate a pixel-wise hybrid high-dimension mapping (HHM) module into INR to alleviate the above issues. The HHM module applies sinusoidal function simultaneously on both latent features and spatial coordinates before MLP, projecting the incorporated spatial and image features into a higher dimensional space, to force the INR network to learn more high-frequency details. The fine structural detail in arbitrary-scale SR CT is thus enhanced. We train the proposed network using real low- and high- resolution clinical CT images rather than using down-sampling images, which is more practical in the clinic. We validate the proposed method in detail using qualitative and quantitative evaluations on the thoracic and pelvic dataset, and the results indicate that our method is accurate and robust, outperforming the other deep learning methods.},
  archive      = {J_ESWA},
  author       = {Yi Xue and Liuze Li and Shengpeng Jiang and Sheng Huang and Yangkang Jiang and Jianrong Dai and Wei Wang and Zhiyong Yuan},
  doi          = {10.1016/j.eswa.2025.129256},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129256},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clinical CT image super-resolution using pixel-wise hybrid high-dimension mapping-based implicit neural representation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAINet: Multi-scale attention interaction network for diabetic retinopathy lesion segmentation. <em>ESWA</em>, <em>296</em>, 129247. (<a href='https://doi.org/10.1016/j.eswa.2025.129247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy ranks among the leading causes of blindness worldwide, severely impacting the quality of individual life. Therefore, early screening and timely diagnosis are of great importance in controlling disease progression and alleviating patient suffering. However, the complex structures, varying scales, scattered distribution and blurred edges of DR lesions pose significant challenges for automated and accurate segmentation. To address the issues of inconsistent scales and insufficient information interaction between adjacent encoding features, this paper introduces a multi-scale attention interaction network named MAINet for concurrently segmenting four types of diabetic retinopathy lesions. The VGG16 backbone is initially employed to extract features from retinal images. Then, the global-local attention module utilizes a parallel global-local architecture to capture global channel attention features, global spatial attention features and local detail features, thereby providing enriched contextual representations of the lesions. Moreover, the cross-attention interaction module performs a cross scale fusion of global-local attention features from different levels using a weight-sharing mechanism, which learns high-level semantic features and fine-grained detail features while mitigating information loss. Comprehensive comparative and ablation studies were performed on the IDRiD, DDR, and FGADR datasets. The experimental results indicate that the proposed method surpasses current leading models in segmentation performance, with significant improvements particularly in microaneurysms and soft exudates.},
  archive      = {J_ESWA},
  author       = {Yanfei Guo and Chenglong Yang and Zhenhua Zhang and Yuanke Zhang and Fei Ma and Jing Meng},
  doi          = {10.1016/j.eswa.2025.129247},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129247},
  shortjournal = {Expert Syst. Appl.},
  title        = {MAINet: Multi-scale attention interaction network for diabetic retinopathy lesion segmentation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trajectory tracking and state estimation for quadcopter UAVs using particle filters in an inner-outer loops controller. <em>ESWA</em>, <em>296</em>, 129245. (<a href='https://doi.org/10.1016/j.eswa.2025.129245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), such as quadcopters, have become widely used in high-risk applications, such as firefighting and rescue in earthquake regions, requiring reliability and resilience to noise and possible sensor failures. Traditional state estimators like the Extended Kalman Filter (EKF) handle Gaussian noise effectively but struggle with nonlinearities and non-Gaussian noise. In contrast, Particle Filters (PF) offer greater robustness and adaptability to such conditions. This paper presents a state estimation approach for quadcopters based on PF integrated with an inner-outer loops controller to achieve precise positioning and trajectory tracking. The study aims to validate the efficiency of the proposed PF-based algorithm for UAV state estimation, even amidst noisy sensor data and limited measurements. Computational simulations using the Julia programming language were conducted for a specific quadcopter model and two different tasks were tested: spatial positioning and trajectory tracking. The obtained results demonstrate that the PF algorithm effectively estimated the drone’s state, allowing the control system to guide the UAV to the desired position or trajectory with high repeatability and accuracy. For the positioning task, the mean computational processing time and settling time interval are 0.108 s and 1.6–2.6 s for 10 particles, 0.155 s and 1.8–15.2 s for 100 particles and 0.947 s and 2.0–35.6 s for 1000 particles, respectively. The results indicate that increasing the number of filter particles reduces initial variability in state estimates. However, it also increases posterior variability, computational costs, and convergence times, highlighting the need to balance particle count for optimal system performance.},
  archive      = {J_ESWA},
  author       = {Vitorino Biazi and Jan Nedoma and Carlos Marques},
  doi          = {10.1016/j.eswa.2025.129245},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129245},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trajectory tracking and state estimation for quadcopter UAVs using particle filters in an inner-outer loops controller},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Application of soil parameter back analysis method based on MLAPSO in staged excavation deformation prediction. <em>ESWA</em>, <em>296</em>, 129244. (<a href='https://doi.org/10.1016/j.eswa.2025.129244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With rapid urbanization, deep excavations adjacent to existing structures pose significant safety challenges, requiring accurate deformation predictions. Traditional optimization algorithms often encounter limitations such as premature convergence to local optima and insufficient accuracy when handling high-dimensional problems. This paper proposes a Multi-Level Learning Adaptive Particle Swarm Optimization (MLAPSO) algorithm that integrates good point set (GPS) initialization, adaptive coefficient (AC) mechanisms, multi-level learning (MLL) strategies, and mutation-elimination (ME) mechanisms. The algorithm demonstrates superior performance in global search capability and stability when tested on the benchmark functions, particularly for complex optimization problems. Based on MLAPSO, a stage-specific parameter back analysis framework is developed that dynamically updates soil parameters and sensitivity during the excavation process, showing excellent capability in avoiding local optima and achieving higher accuracy. Validation through the Shanghai Metro Line 21 Junmin Road Station project demonstrated that prediction accuracy continuously improved throughout construction stages, ultimately achieving a relative error below 1%. These results confirm that the monitoring-based parameter back analysis approach enhances simulation accuracy, enabling reliable deformation predictions for excavation risk assessment and control, with potential extensions to other geotechnical applications requiring parameter identification.},
  archive      = {J_ESWA},
  author       = {Ping He and Huiji Guo and Honggui Di and Ziyu Guan},
  doi          = {10.1016/j.eswa.2025.129244},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129244},
  shortjournal = {Expert Syst. Appl.},
  title        = {Application of soil parameter back analysis method based on MLAPSO in staged excavation deformation prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Blind identification of incident waves and response transfer functions of a marine vessel based on measured responses. <em>ESWA</em>, <em>296</em>, 129236. (<a href='https://doi.org/10.1016/j.eswa.2025.129236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating incident waves onboard is crucial for ensuring safe and efficient operation of a marine vessel. This paper is concerned with an in-situ response-based wave estimation method, in which incoming waves are inversely estimated via measured wave-induced responses and corresponding transfer functions (TRFs); a method widely referred to as the ’Wave Buoy Analogy (WBA)’. Specifically, a new phase-resolved WBA technique is studied. In a transfer function-dependent technique, the accuracy of estimated waves via the WBA is in principle contingent upon the accuracy of TRFs. However, it can be challenging to provide precise TRFs onboard, as the vessel’s weight distribution and the operational conditions may vary from voyage to voyage. To address this issue, this paper proposes a novel approach to simultaneously attain estimations of response TRFs and incoming wave profiles based on measured wave-induced responses. Specifically, parametrized TRFs (P-TRFs) are introduced using a well-trained Artificial Neural Network (ANN), and the parameters characterizing the P-TRFs are identified through optimization, based on pseudo responses under reconstructed phase-resolved incident waves. A linear strip theory, the so-called New Strip Method (NSM), is utilized to train the ANN. Bayesian Optimization (BO) is employed to identify the parameters in the P-TRF. A numerical investigation using synthetic measurements generated via known TRFs is first made. Following this, the proposed approach is validated against experimental campaigns using scaled models of a bulk carrier and container ship, respectively, in long-crested irregular waves. It is unveiled that the estimation results of TRFs and incoming waves demonstrate a high degree of correlation with the experimental measurements. The computational cost of the presented approach is low, thus making the approach practically feasible for real-time applications.},
  archive      = {J_ESWA},
  author       = {Tomoki Takami and Ulrik Dam Nielsen and Raphaël Emile Gilbert Mounet and Jørgen Juncher Jensen and Ryota Mori and Yusuke Komoriyama},
  doi          = {10.1016/j.eswa.2025.129236},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129236},
  shortjournal = {Expert Syst. Appl.},
  title        = {Blind identification of incident waves and response transfer functions of a marine vessel based on measured responses},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ForestBerryNet: A dual-backbone architecture with hierarchical attention fusion for efficient forest berry detection. <em>ESWA</em>, <em>296</em>, 129227. (<a href='https://doi.org/10.1016/j.eswa.2025.129227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of wild berries is a critical task for applications in automated harvesting and ecological monitoring.owever, research in this area remains limited, with most existing studies focusing on single berry species. To address this gap, we propose ForestBerryNet, a dual-backbone architecture with hierarchical attention fusion for efficient forest berry detection. First, we introduced DualFuseNet, a dual-path network that leverages Cross Stage Partial Darknet (CSPDarknet) and High-Performance GPU Network V2 (HGNetV2) as its backbones. It synergistically extracts and integrates multi-scale features from both paths via a Hierarchical Attention Fusion (HiAFusion) module, optimizing their weighted fusion. We also present a Lightweight Hybrid Encoder, which incorporates an Efficient Up-convolution Block (EUB) and a Heterogeneous Convolutional Branch Refinement (HCBR) module. This design significantly enhances the efficiency of multi-scale feature fusion while reducing computational complexity. Additionally, a Lightweight Decoder module is proposed, which optimizes the detection head by employing grouped convolutions. This approach reduces computational overhead while maintaining detection accuracy. To address the issue of false suppression for densely packed targets in complex backgrounds, we integrate the Soft Non-Maximum Suppression (Soft-NMS) post-processing mechanism, which substantially enhances berry detection accuracy. Experimental results demonstrate that ForestBerryNet achieves a mean Average Precision at Intersection over Union (IoU) thresholds from 50 % to 95 % (mAP50:95) of 56.30 % on the WildBerry dataset, with notable reduction in parameter count (0.38M), computational complexity 1.4G Floating Point Operations per second (FLOPs), and model size (1.2MB), making it well-suited for resource-constrained platforms. This framework offers an efficient solution for automated wild berry detection and provides a solid foundation for future deployment on drones or edge computing devices.},
  archive      = {J_ESWA},
  author       = {Xiaorong Zhang and Xuting Hu and Han Liao},
  doi          = {10.1016/j.eswa.2025.129227},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129227},
  shortjournal = {Expert Syst. Appl.},
  title        = {ForestBerryNet: A dual-backbone architecture with hierarchical attention fusion for efficient forest berry detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A swarm intelligence-enhanced ransomware detection framework via dynamic memory feature optimization. <em>ESWA</em>, <em>296</em>, 129225. (<a href='https://doi.org/10.1016/j.eswa.2025.129225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional detection methods fail to counter fileless attacks and virtualization evasion techniques. To address this limitation, we propose a ransomware detection framework based on memory forensics. However, memory forensic feature analysis faces challenges including high-dimensional feature noise, class imbalance, and coupled optimization of model parameters and feature selection. To address these issues, we have developed the LNPSPE framework, which incorporates feature quality assessment and swarm intelligence. The essential elements comprise: 1) a dynamic penalty mechanism that integrates feature importance deviation metrics with Particle Swarm Optimization (PSO) to attenuate noise and identify critical features; 2) an adaptive ensemble model that combines self-paced ensemble techniques with PSO to refine hyperparameters and alleviate model deterioration resulting from feature redundancy and class imbalance. The evaluation of CIC-MalMem-2022 dataset shows that LNPSPE selects 9 important memory forensics features, and its performance index reaches 99 %, which exceeds 21 benchmark methods, highlighting its efficiency in eliminating redundant features and noise features. SHAP study indicates negative correlations between ransomware detection and memory features, Hdl_Event and Hdl_Key have negative impacts, while SVC_SharedProc and LDR_Mem have positive impacts, providing principled explanatory information for more accurate ransomware type detection. In addition, the datasets and source code are available from this link: https://github.com/transparent-n/LNPSPE .},
  archive      = {J_ESWA},
  author       = {Yan Wu and Yanyan Liu and Zhaoyuan Zhang and Xiaoshi Yi and Lanlan Yi},
  doi          = {10.1016/j.eswa.2025.129225},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129225},
  shortjournal = {Expert Syst. Appl.},
  title        = {A swarm intelligence-enhanced ransomware detection framework via dynamic memory feature optimization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSSTGIN: A novel adaptive graph method for long-term traffic speed forecasting considering global-local multiscale spatiotemporal correlations. <em>ESWA</em>, <em>296</em>, 129223. (<a href='https://doi.org/10.1016/j.eswa.2025.129223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term traffic speed forecasting is crucial for alleviating congestion and aiding traffic management. It is more challenging than short-term forecasting because of the complex and dynamic patterns present in extended time series, which make accurate predictions difficult. However, existing hybrid spatio-temporal models face two key limitations: (1) they fail to effectively integrate local-scale dynamics (e.g., congestion propagation) with global-scale trends (e.g., periodic patterns), and (2) they rely heavily on predefined road network topologies, overlooking implicit correlations among non-adjacent but behaviorally similar road segments. To address these gaps, we propose MSSTGIN, a novel multi-scale spatio-temporal network with three core innovations: A global-local spatio-temporal module that hierarchically aggregates multi-scale traffic patterns, capturing both fine-grained fluctuations and long-term trends. A topology-agnostic graph learning mechanism combining graph autoencoders and attention to infer static and dynamic relationships beyond adjacency, reducing reliance on rigid road network structures. A speed-time enhanced encoder that explicitly models abrupt speed changes (e.g., due to accidents) alongside periodic trends. Generalization tests conducted on the main freeways in Fujian Province using Electronic Toll Collection (ETC) data have demonstrated that this model’s predictive capabilities outperforms state-of-the-art methods and reduces 1.03 %-5.94 % and 1.29 %-8.42 % in terms of RMSE and MAE metrics, respectively. The final experimental results confirm that incorporating both global and local traffic information, as well as considering the implicit relationships of non-adjacent points, effectively enhances traffic speed prediction. This approach offers a new perspective for promoting long-term traffic speed forecasting and advancing intelligent transportation systems.},
  archive      = {J_ESWA},
  author       = {Chentao Yao and Fumin Zou and Xu Luo and Zihan Ye},
  doi          = {10.1016/j.eswa.2025.129223},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129223},
  shortjournal = {Expert Syst. Appl.},
  title        = {MSSTGIN: A novel adaptive graph method for long-term traffic speed forecasting considering global-local multiscale spatiotemporal correlations},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing cybersecurity methodologies: Integrating competitiveness factor for risk analysis and IT system design. <em>ESWA</em>, <em>296</em>, 129220. (<a href='https://doi.org/10.1016/j.eswa.2025.129220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the study is to assess the potential of the developed methodology, in particular, for security analysts, security engineers, security architects, system administrators, auditors/testers with junior and intermediate experience. The growing use of information technology solutions leads to an increase in cybersecurity threats, which requires improved approaches to protecting data and information systems. This study employed a structured electronic survey among 500 cybersecurity professionals, including security analysts, engineers, system administrators, auditors, and managers with varying experience levels. The survey, conducted over one month, gathered data on respondents’ roles, experience, and their perceptions of the proposed cybersecurity risk assessment methodology. Key dimensions measured included perceived utility, ease of use, attitude, subjective norms, and behavioural intentions regarding the methodology. Quantitative analyses such as descriptive statistics, subgroup comparisons, and correlation assessments were applied to evaluate acceptance and readiness to adopt the methodology. Competitiveness assessment is an important tool for ensuring the sustainability and success of enterprises in the face of ever-growing cyber threats. This approach will also help to raise awareness of cybersecurity issues among the business community and facilitate the development of effective defence strategies. A survey was conducted among information security professionals to objectively assess the proposed methodology. The proposed methodology can be used to calculate the competitiveness coefficient of an enterprise and assess its readiness for cyber threats. The results obtained indicate the effectiveness of the proposed methodology in calculating the competitiveness coefficient of enterprises and assessing their readiness for cyber threats. This analysis led to the conclusion that the developed methodology is an effective tool for improving the competitiveness of enterprises in the context of cybersecurity and determining their readiness to these threats.},
  archive      = {J_ESWA},
  author       = {Przemyslaw Jatkiewicz},
  doi          = {10.1016/j.eswa.2025.129220},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129220},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing cybersecurity methodologies: Integrating competitiveness factor for risk analysis and IT system design},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). VCR-imputer: Discrete data imputation considering variable causal relationships. <em>ESWA</em>, <em>296</em>, 129219. (<a href='https://doi.org/10.1016/j.eswa.2025.129219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal structure learning is an essential tool for understanding causal relationships between variables. However, handling discrete observational data often faces the challenge of missing data. Existing imputation methods fail for discrete causal data due to high correlations and limited value space, propagating spurious dependencies. To address this issue, this paper proposes VCR-imputer(Variable Causal Relationships imputer), a novel method for imputing discrete missing data that leverages the causal relationships between variables. The framework operates in two stages: (1) Data Pre-Imputation to construct an initial causal skeleton, and (2) Data Re-Imputation to refine neighborhoods using causal features and Large Language Model knowledge. To demonstrate its effectiveness in handling missing data, the imputation algorithm is applied to different causal structure learning algorithms for analysis. Experimental results show that this method outperforms other methods and is suitable for various causal structure learning algorithms.},
  archive      = {J_ESWA},
  author       = {Yuhan Xiong and Li Ma and Xiaomin Zhu and Xiong Li},
  doi          = {10.1016/j.eswa.2025.129219},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129219},
  shortjournal = {Expert Syst. Appl.},
  title        = {VCR-imputer: Discrete data imputation considering variable causal relationships},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale gaussian feature enhancement and prototype graph convolutional network for domain-generalized rolling bearing fault diagnosis. <em>ESWA</em>, <em>296</em>, 129218. (<a href='https://doi.org/10.1016/j.eswa.2025.129218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis systems often run under changing conditions and unseen domains, making model adaptation in these scenarios challenging. Domain generalization (DG) is crucial for maintaining performance on new, unseen data. However, many DG methods struggle with unstable alignment objectives, which slow convergence and weaken robustness. To address these issues, this paper presents a DG method for fault diagnosis, combining multi-scale Gaussian feature enhancement with a prototype graph convolutional network (MGF-PGCN). The multi-scale Gaussian feature enhancement module uses unimodal and bimodal Gaussian functions for aligning fault features, ensuring consistent feature representations across domains by creating dynamic intermediate distributions. A multi-scale weight block further improves feature representation by capturing features at multiple scales. The prototype graph convolutional network constructs a Gaussian prototype adjacency matrix that dynamically measures and updates connectivity between prototypes. This enables adaptive fault type characterization and enhances robustness. Experimental results on three bearing datasets demonstrate that MGF-PGCN outperforms state-of-the-art methods, with an average accuracy of 94.14 %, 94.75 %, and 88.99 %, respectively.},
  archive      = {J_ESWA},
  author       = {Xiao Cong and Yinghao Zhuang and Yibin Li and Daichao Wang and Yu Zhang and Yan Song},
  doi          = {10.1016/j.eswa.2025.129218},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129218},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scale gaussian feature enhancement and prototype graph convolutional network for domain-generalized rolling bearing fault diagnosis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient depth from defocus imaging for environmental perception. <em>ESWA</em>, <em>296</em>, 129217. (<a href='https://doi.org/10.1016/j.eswa.2025.129217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular, stable, low-computation-cost, and high-precision stereo imaging has been a key focus in the fields of robotics, autonomous driving, and machine vision. However, the majority of current stereo imaging research tends to prioritize the stereoscopic effects while neglecting the importance of computational efficiency. This significantly impacts the deployment and application of stereo imaging in industrial settings. In this paper, we propose a stereo imaging scheme based on depth from defocus, integrating the latest advancements in optical systems to overcome the computational efficiency limitations of existing algorithms. By introducing aberration analysis of the optical system, we re-derive the principles of depth from defocus to enhance both the accuracy and range of stereo imaging. Experimental results validate the effectiveness of the proposed method and the accuracy of the precision calculations. Finally, we analyze the impact of optical system parameters on the relevant methods. Theoretical derivations reveal the relationships between spatial resolution, depth resolution, and the range of stereo imaging in depth from defocus approaches, providing theoretical guidance for the design and deployment of such methods in practical application scenarios.},
  archive      = {J_ESWA},
  author       = {Yi Huang and Yiting Li and Jiangyu Tian and Junya Wang and Jiajing Cao and Xinxin Shi and Jun Chang},
  doi          = {10.1016/j.eswa.2025.129217},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129217},
  shortjournal = {Expert Syst. Appl.},
  title        = {Efficient depth from defocus imaging for environmental perception},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning semantic-aware threshold for multi-label image recognition with partial labels. <em>ESWA</em>, <em>296</em>, 129216. (<a href='https://doi.org/10.1016/j.eswa.2025.129216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image recognition with partial labels (MLR-PL) is designed to train models using a mix of known and unknown labels. Traditional methods rely on semantic or feature correlations to create pseudo-labels for unidentified labels using pre-set thresholds. This approach often overlooks the varying score distributions across categories, resulting in inaccurate and incomplete pseudo-labels, thereby affecting performance. In our study, we introduce the Semantic-Aware Threshold Learning (SATL) algorithm. This innovative approach calculates the score distribution for both positive and negative samples within each category and determines category-specific thresholds based on these distributions. These distributions and thresholds are dynamically updated throughout the learning process. Additionally, we implement a differential ranking loss to establish a significant gap between the score distributions of positive and negative samples, enhancing the discrimination of the thresholds. Comprehensive experiments and analysis on large-scale multi-label datasets, such as Microsoft COCO and VG-200, demonstrate that our method significantly improves performance in scenarios with limited labels.},
  archive      = {J_ESWA},
  author       = {Haoxian Ruan and Zhihua Xu and Zhijing Yang and Guang Ma and Jieming Xie and Changxiang Fan and Tianshui Chen},
  doi          = {10.1016/j.eswa.2025.129216},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129216},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning semantic-aware threshold for multi-label image recognition with partial labels},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on injection molded defects detection algorithm based on physics-guided regularization constraints. <em>ESWA</em>, <em>296</em>, 129212. (<a href='https://doi.org/10.1016/j.eswa.2025.129212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection in injection molded parts is important for quality control but remains challenging due to small, complex defects and high background noise. To address this, we propose a real-time defect detection model, PHDL-RTDETR, which integrates physics-guided and attention-based components to improve performance. PHDL-RTDETR is comprises four key modules: Physics-guided Network (PhyGuideNet), Hybrid Attention Gated Convolution (HAGConv), Detail-Enhanced Attention CARAFE (DEA-CARAFE), and Learnable Weighted Fusion (LW-Fusion). PhyGuideNet is a physics-guided Convolutional Neural Network (CNN) that integrates Bias Normalization and Laplacian smoothing diffusion to improve feature extraction while suppressing noise. HAGConv enhances the capture of high-frequency defect features, DEA-CARAFE improves small-object detection through edge-aware upsampling, and LW-Fusion adaptively integrates multi-scale features using a learnable weighting strategy. Experimental results on the custom datasets demonstrate that PhyGuideNet reduces computational cost by 50 % while improving Precision by 1.4 % and mAP by 0.2 %. Overall, PHDL-RTDETR achieves 90.1 % Precision, 88.4 % mAP, and 75 FPS, while reducing Param by 43 % and FLOPs by 54 %, outperforming other detectors including YOLOv5-v11, Faster R-CNN, and RT-DETR. The model’s strong generalization capability is furthered validated on public datasets for PCB, fabric, and steel surface defect detection, showing significant improvements in small target detection and robustness under complex background conditions. The code is available at https://github.com/CodeDisclosureProject/PHDL-RTDETR .},
  archive      = {J_ESWA},
  author       = {Zhiguang Guan and Rongnan Zhang and Mingxing Lin},
  doi          = {10.1016/j.eswa.2025.129212},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129212},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on injection molded defects detection algorithm based on physics-guided regularization constraints},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identifying the trustworthy government for the media: The signaling game with a reward-punishment mechanism. <em>ESWA</em>, <em>296</em>, 129211. (<a href='https://doi.org/10.1016/j.eswa.2025.129211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In crisis management, public reliance on the media has increased, with media reports significantly shaping perceptions of crises and evaluations of government capabilities. Governments gradually realize that relying solely on control and management not only fails to maximize their interests but also forfeits opportunities to guide public opinion. Consequently, governments are increasingly seeking cooperation with the media. However, commercial interests and political considerations often lead to disagreements, ultimately causing collaboration breakdowns. Therefore, in this paper, we reconstruct the relationship between the government and the media through a signaling game in which the government (sender) possesses private information about its emergency response capacity and sends a signal to the media (receiver), who decides whether to cooperate and report the information. Additionally, we propose an information quality reward-punishment mechanism. The main findings are as follows: (1) In the benchmark model, information cooperation consistently leads to a chaotic pooling equilibrium. (2) Introducing the reward-punishment mechanism establishes a stable separating equilibrium, enabling the media to effectively discern government types. (3) We also derive that the media’s willingness to cooperate is decreasing with its reputation loss. (4) Finally, we find that this mechanism increases media profits in most scenarios. This study provides theoretical insights into stabilizing government-media interactions and enhancing public-oriented government regulation.},
  archive      = {J_ESWA},
  author       = {Haoqian Xie and Chunbing Bao and Yi Du and Xiaoman Fan and Qingchun Meng},
  doi          = {10.1016/j.eswa.2025.129211},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129211},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identifying the trustworthy government for the media: The signaling game with a reward-punishment mechanism},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Autonomous navigation of non-perception firefighting robot through CCTV-informed vision sharing. <em>ESWA</em>, <em>296</em>, 129210. (<a href='https://doi.org/10.1016/j.eswa.2025.129210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying smart firefighting robots indoors is a prospective measure to realize fast-response and zero-casualty firefighting operations. Most existing firefighting robots require manual control or pre-input information for navigation. This work proposes a CCTV-informed autonomous navigation system for robot to reach target flame via the safest and fastest route. This proposed system uses the vision of building CCTV-camera network and provides a full-process navigation pipeline to guide imperceptive firefighting robots. Demonstrations show that the navigation system enables the robot to have a complete perception of floorplan and understand the evolution of fire scenes. The robot can autonomously move towards the target flame even if carry-on vision sensors are blocked or damaged. Finally, the dynamic system responsiveness is validated to prove its effectiveness in addressing randomly moving obstacles. This framework can be further integrated with smart building maintenance system, which offers low-cost, early-response, and more resilient solutions for firefighting and safety patrol robots.},
  archive      = {J_ESWA},
  author       = {Rong Deng and Saizhe Ding and Yifei Ding and Meng Wang and Xinyan Huang and Asif Sohail Usmani},
  doi          = {10.1016/j.eswa.2025.129210},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129210},
  shortjournal = {Expert Syst. Appl.},
  title        = {Autonomous navigation of non-perception firefighting robot through CCTV-informed vision sharing},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A heterogeneous information network-based approach for cold-start bundle recommendation. <em>ESWA</em>, <em>296</em>, 129209. (<a href='https://doi.org/10.1016/j.eswa.2025.129209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike warm-start bundle recommendation scenario where models can rely on both user-bundle and user-item interaction data, the cold-start bundle recommendation scenario presents a challenge due to the absence of historical interactions for new bundles. Existing cold-start bundle recommendation methods have made some progresses by using only user-item interactions to predict user preferences for new bundles. However, these methods fail to finely differentiate new bundles using the amount of overlapped items and overlook the distinct interaction patterns between user-bundle and user-item interactions. To address the above limitations, we propose the Heterogeneous Information Network-based Cold-start Bundle Recommendation (HINCBR) framework, which introduces attribute information into user-item interactions to enhance the learned representations. Specifically, we first expand the user-item interactions into a HIN and design a simplified graph neural network to encode diverse interactions within it. Then, we devise a personalized semantic fusion module to learn users’ and bundles’ representations by adaptively aggregating interaction information. At last, we adopt the contrastive learning approach to further improve the quality of learned representations by aligning user-bundle and user-item interaction view. The experimental results on three real-world datasets validate the superiority of HINCBR over existing state-of-the-art models, achieving up to a 0.0938 and 0.0739 absolute gain in Recall@20 and NDCG@20, respectively. Furthermore, the subsequent ablation study and meta-path analysis demonstrate the effectiveness of the framework design and the utilization of the HIN.},
  archive      = {J_ESWA},
  author       = {Wenchuan Yang and Jichao Li and Suoyi Tan and Yuejin Tan and Xin Lu},
  doi          = {10.1016/j.eswa.2025.129209},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129209},
  shortjournal = {Expert Syst. Appl.},
  title        = {A heterogeneous information network-based approach for cold-start bundle recommendation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An automatic counting algorithm for the quantification and uncertainty analysis of the number of microglial cells trainable in small and heterogeneous datasets. <em>ESWA</em>, <em>296</em>, 129208. (<a href='https://doi.org/10.1016/j.eswa.2025.129208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counting immunopositive cells on biological tissues generally requires either manual annotation or (when available) automatic rough systems, for scanning signal surface and intensity in whole slide imaging. In this work, we tackle the problem of counting microglial cells in lumbar spinal cord cross-sections of rats by omitting cell detection and focusing only on the counting task. Manual cell counting is, however, a time-consuming task and additionally entails extensive personnel training. The classic automatic color-based methods roughly inform about the total labeled area and intensity (protein quantification) but do not specifically provide information on cell number. Since the images to be analyzed have a high resolution but a huge amount of pixels contain just noise or artifacts, we first perform a pre-processing generating several filtered images (providing a tailored, efficient feature extraction). Then, we design an automatic kernel counter that is a non-parametric and non-linear method. The proposed scheme can be easily trained in small datasets since, in its basic version, it relies only on one hyper-parameter. However, being non-parametric and non-linear, the proposed algorithm is flexible enough to express all the information contained in rich and heterogeneous datasets as well (providing the maximum overfit if required). Furthermore, the proposed kernel counter also provides uncertainty estimation of the given prediction, and can directly tackle the case of receiving several expert opinions over the same image. Different numerical experiments with artificial and real datasets show very promising results. Related Matlab code is also provided.},
  archive      = {J_ESWA},
  author       = {L. Martino and M.M. Garcia and P.S. Paradas and E. Curbelo},
  doi          = {10.1016/j.eswa.2025.129208},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129208},
  shortjournal = {Expert Syst. Appl.},
  title        = {An automatic counting algorithm for the quantification and uncertainty analysis of the number of microglial cells trainable in small and heterogeneous datasets},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Comfort temperature assessment for honeybee colonies based on long-term monitoring. <em>ESWA</em>, <em>296</em>, 129207. (<a href='https://doi.org/10.1016/j.eswa.2025.129207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bees are the most critical pollinators to ensure human food security, but the increasing of extreme weather seriously threatens their survivals. Although the beehive temperatures are easy to be monitored by the internet of things (IoT) as so far, the comfort temperatures for bee colonies are still unclear that limit the protection during extreme weathers. This study utilizes an IoT system to conduct a long-term monitoring for dozens of bee colonies over two years, analyzing the impact of environmental changes on hive temperature and presenting a novel model for comfort temperature assessment. The study finds that external environmental and seasonal changes significantly affect hive temperature and colony health status. Further, the Changes in nighttime honeycomb weight (CNHW) are recommended as a comfort indicator, and the comfort temperatures are proposed for different seasons at the first time. The validation result showed that maintaining hive temperature within these optimal ranges will benefit for bee colony development. Finally, this study presents a hive temperature evaluation model that provides a robust tool for mitigating the impacts of climate change on bee colony, thereby reducing colony collapse and advancing precision beekeeping.},
  archive      = {J_ESWA},
  author       = {Yuntao Lu and Wei Hong and Wei Wu and Jie Zhang and Shijuan Li and Shengping Liu},
  doi          = {10.1016/j.eswa.2025.129207},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129207},
  shortjournal = {Expert Syst. Appl.},
  title        = {Comfort temperature assessment for honeybee colonies based on long-term monitoring},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tactical planning of the wind turbine manufacturing supply chain: Modeling, solution methods, and real case study. <em>ESWA</em>, <em>296</em>, 129206. (<a href='https://doi.org/10.1016/j.eswa.2025.129206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbines have become an indispensable part of renewable energy systems, attracting considerable attention from academic researchers and practitioners. However, the existing literature on the optimization of wind turbine manufacturing supply chain is notably scarce. This paper focuses on optimizing the tactical plan of the wind turbine manufacturing supply chain under uncertainties. The budgeted uncertainty set is employed to characterize the randomness of transportation costs and project demands without probability information. A novel two-stage robust optimization model is proposed. In order to address the computational challenges caused by the pure-integer recourse, multi-parameter uncertainties, and large-scale applications, we study both the exact and approximate solution methods. A variant of the cutting-edge Nested Column-and-Constraint Generation algorithm, is designed for an optimal solution. A tailored inexact solution method is also proposed for an efficient solution, in which, the robust optimization model is approximately reformulated as a tractable mixed-integer linear programming by using the linear decision rule. Finally, a real-world case study is presented to design a tactical plan for 357 wind turbines in 10 wind farms by using the proposed model and solution methods. Sensitivity analysis and out-of-sample test are conducted to not only validate the efficiency of the proposed model, but also demonstrate the effectiveness of the exact solution method. Additionally, the inexact solution method proves to be a viable alternative when considering both computational time and evaluation performance. This study extends existing research on wind turbines by integrating wind turbine manufacturing, supply chain optimization and robust optimization, and provides practitioners in the wind turbine industry with a comprehensive methodological framework for decision-making on manufacturing supply chain planning.},
  archive      = {J_ESWA},
  author       = {ChangJun Wang and Jia Chen and Dong Yang and Bing Wang and XiaoZhi Wang},
  doi          = {10.1016/j.eswa.2025.129206},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129206},
  shortjournal = {Expert Syst. Appl.},
  title        = {Tactical planning of the wind turbine manufacturing supply chain: Modeling, solution methods, and real case study},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hierarchical ORCA framework for multi-UAV navigation in unstructured environments with velocity optimization and local minima avoidance. <em>ESWA</em>, <em>296</em>, 129205. (<a href='https://doi.org/10.1016/j.eswa.2025.129205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic unstructured environments, traditional reciprocal collision-avoidance methods struggle to adapt to dense and irregular terrains on account of the intricate kinematic constraints associated with unmanned aerial vehicles (UAVs). The optimal reciprocal collision avoidance (ORCA) algorithm, though allowing real-time motion adjustment, is limited by UAVs’ physical constraints and velocity mutation. This paper proposes a hierarchical ORCA (H-ORCA) framework. Firstly, a velocity-smoothed ORCA (VS-ORCA) algorithm is proposed to solve the common velocity-mutation issue in original ORCA algorithms by optimizing velocity changes. Secondly, a local minima avoidance algorithm adjusts the velocity selection domain based on obstacle distribution to avoid UAV stagnation. Simulations in large-scale coordination, static-obstacle free, and unstructured terrain scenarios compare H-ORCA with other algorithms. The results demonstrate that the H-ORCA framework achieves lower detour time, distance ratio, failure rate and collision frequency in large-scale scenarios minimizes abrupt UAV motion changes, and preserves trajectory curvature continuity with stable acceleration. These improvements collectively enhance operational safety and motion reliability in complex unstructured environments.},
  archive      = {J_ESWA},
  author       = {Wenna Wang and Huaming Qian},
  doi          = {10.1016/j.eswa.2025.129205},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129205},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hierarchical ORCA framework for multi-UAV navigation in unstructured environments with velocity optimization and local minima avoidance},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy evaluation of classification models on partially labeled datasets. <em>ESWA</em>, <em>296</em>, 129204. (<a href='https://doi.org/10.1016/j.eswa.2025.129204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional evaluation of deep learning models heavily depends on fully labeled testing datasets. However, in many real-world scenarios, labels are often only partially available. To address this challenge, we propose a semi-automated model evaluation method based on semi-supervised prototypical learning, which leverages semi-supervised clustering and contrastive learning with prototypical consistency to assess model performance on partially labeled datasets. Specifically, our method consists of two components: model updating and model evaluation. Model updating component focuses on adapting a model trained on fully-labeled source datasets to the partially labeled target testing dataset. This is achieved through joint optimization of a supervised loss on labeled samples and a self-supervised loss on unlabeled samples, resulting in a model tailored to the target data. To facilitate this process, we introduce a semi-supervised clustering method, a contrastive prototypical consistency learning approach, and a projection consistency loss. Model evaluation component assesses the model’s performance on the partially labeled test dataset by using the model’s predictions as inferred ground truth labels. Extensive experiments validate the effectiveness of our approach, achieving state-of-the-art performance in automated model evaluation.},
  archive      = {J_ESWA},
  author       = {Huanjie Tao and Wu Gao},
  doi          = {10.1016/j.eswa.2025.129204},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129204},
  shortjournal = {Expert Syst. Appl.},
  title        = {Accuracy evaluation of classification models on partially labeled datasets},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Class-specific image segmentation across multiple domains using customized U-net pipelines. <em>ESWA</em>, <em>296</em>, 129203. (<a href='https://doi.org/10.1016/j.eswa.2025.129203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a class-specific U-Net-based segmentation framework designed for high-precision segmentation across diverse image domains, including underwater inspection, surface crack detection, and medical imaging. Unlike traditional multi-class models, our approach trains a separate U-Net for each class, enabling domain-specific tuning and threshold optimization. The proposed framework includes a Dice ( F 1 score) loss function tailored for multi-image performance, domain-customized preprocessing, and a stratified training pipeline. Evaluations across three distinct datasets, including underwater concrete inspection, the Roboflow surface crack dataset, and clinical cardiac magnetic resonance imaging (MRI), demonstrate consistent performance improvements over state-of-the-art methods, such as the You Only Look Once (YOLO) model and the baseline U-Net. Our results show that this modular segmentation strategy achieves superior Dice coefficients, Intersection over Union (IoU), and class precision, particularly for small or ambiguous structures. The computational trade-offs and the method’s potential for real-world deployment in healthcare and infrastructure monitoring are discussed to prove the model’s applicability.},
  archive      = {J_ESWA},
  author       = {Lucija Žužić and Franko Hržić and Xiumei Li and Jonatan Lerga},
  doi          = {10.1016/j.eswa.2025.129203},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129203},
  shortjournal = {Expert Syst. Appl.},
  title        = {Class-specific image segmentation across multiple domains using customized U-net pipelines},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal feature learning for gait recognition of camouflaged individuals. <em>ESWA</em>, <em>296</em>, 129202. (<a href='https://doi.org/10.1016/j.eswa.2025.129202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition, which identifies individuals by walking patterns from afar, stands as a key video surveillance technology. Methods generally fall into silhouette-based and skeleton-based types, though progress has been made, recognizing camouflaged individuals in complex environments remains a challenge. Silhouettes are susceptible to environmental or clothing influences and contain only external contours. Skeletons comprise internal structure information but ignore body shape. To address this, a novel gait recognition framework based on multimodal feature learning is proposed in this paper to learn rich gait representation. Firstly, a multi-branch network based on the hybrid fusion strategy is introduced to leverage the complementarity of two modalities. Secondly, the silhouette branch utilizes multi-scale convolution with diverse kernel sizes for appearance feature extraction across various receptive fields, while a pyramidal attention mechanism is integrated to highlight critical information within these features. Moreover, a residual graph convolutional network is utilized to obtain hierarchical information on body joints in the skeleton. Considering the strengths and weaknesses of each modality, this paper utilizes the cross-modal transformer to obtain comprehensive gait features in the fusion branch. Ultimately, multi-branch gait features are integrated to enhance the overall recognition performance. Additionally, we build a novel gait dataset of camouflaged individuals captured by the unmanned aerial vehicle for research. It achieves a Rank-1 accuracy of 89.2 % on GCI-150, 96.5 % on CASIA-B, and 90.6 % on OUMVLP respectively. Particularly for clothing changes in complex environments, our method obtains performance gains compared to other methods. For instance, it achieves 94.5 % accuracy for coat-wearing walking conditions on CASIA-B, thereby proving its potential for military applications.},
  archive      = {J_ESWA},
  author       = {Hui-peng Li and Cong-qing Wang and Yang Liu},
  doi          = {10.1016/j.eswa.2025.129202},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129202},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal feature learning for gait recognition of camouflaged individuals},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inter-view dual-domain guided stable diffusion for real-world stereo image super-resolution. <em>ESWA</em>, <em>296</em>, 129201. (<a href='https://doi.org/10.1016/j.eswa.2025.129201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, pre-trained text-to-image diffusion models have shown promising potential in restoring texture details lost in low-resolution images due to their powerful generative ability. However, directly applying these models to real-world stereo image super-resolution (Real-SSR) neglects the essential consistency between left and right views, resulting in inconsistent stereo content and amplified visual artifacts. To address this problem, we propose a Complementary Semantic-aware Inter-view Dual-domain Guided Stable Diffusion (CSID-Diff) network for Real-SSR, which leverages complementary texture, structural, and semantic information from low-resolution stereo images to guide the diffusion model to generate high-quality results with inter-view consistency. Specifically, we propose a Dual-domain Guided ControlNet that establishes complementary interactions in both the image feature domain and the disparity domain, and fuses dual-domain features to enforce inter-view texture and structural consistency. To further address viewpoint-induced discrepancies in semantic information between left and right images, we introduce a Complementary Semantic Feature Extraction Module (CSFEM) to enforce inter-view semantic consistency. Extensive experiments demonstrate that our approach delivers superior stereo image reconstruction, achieving both high quality and inter-view consistency, outperforming state-of-the-art methods on both synthetic and real-world datasets.},
  archive      = {J_ESWA},
  author       = {Jingcheng Zhang and Yu Zhu and Axi Niu and Jinqiu Sun and Yanning Zhang},
  doi          = {10.1016/j.eswa.2025.129201},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129201},
  shortjournal = {Expert Syst. Appl.},
  title        = {Inter-view dual-domain guided stable diffusion for real-world stereo image super-resolution},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SemDNet: Semantic-guided despeckling network for SAR images. <em>ESWA</em>, <em>296</em>, 129200. (<a href='https://doi.org/10.1016/j.eswa.2025.129200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) is highly valued for its all-weather and all-day imaging capabilities. However, SAR images are often severely degraded by speckle noise, which poses significant challenges to accurate image interpretation. Recently, deep learning-based methods have shown great promise in despeckling tasks. However, most existing approaches process images at a global level, failing to account for the semantic differences between regions. Ideally, a despeckling algorithm should suppress speckle noise effectively in homogeneous areas while preserving fine texture details in heterogeneous regions. To address this limitation, we propose a novel semantic-guided despeckling network (SemDNet), which leverages high-level semantic information to reconstruct high-quality despeckled images. SemDNet consists of three core components: a coarse despeckling module (CDM), a semantic segmentation module (SSM), and a semantic-guided despeckling module (SGDM). The CDM first generates a coarse despeckled image, which is then processed by the SSM to extract semantic segmentation features. These features, together with the coarse despeckled image, are further refined by the SGDM, enabling an effective interaction between low-level pixel information and high-level semantic features, resulting in enhanced despeckling performance. Additionally, the proposed SGDM can function as a plug-and-play module that can be integrated into existing despeckling networks to improve their performance. Extensive experiments demonstrate that SemDNet achieves performance gains of up to +0.98 dB in PSNR and +2.1 % in SSIM compared to baseline methods. In real SAR images, it also shows an improvement of 13 % in the NIQE score and a reduction of 19 % in the BRISQUE score, confirming its superior ability to balance noise suppression with detail preservation. The source code of our proposed method is available at https://github.com/BFY-official/SemDNet .},
  archive      = {J_ESWA},
  author       = {Fuyu Bo and Yi Jin and Xiaole Ma and Yigang Cen and Shaohai Hu and Yidong Li},
  doi          = {10.1016/j.eswa.2025.129200},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129200},
  shortjournal = {Expert Syst. Appl.},
  title        = {SemDNet: Semantic-guided despeckling network for SAR images},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HorD2CN: High-order deformable differential convolution network for hyperspectral image classification. <em>ESWA</em>, <em>296</em>, 129198. (<a href='https://doi.org/10.1016/j.eswa.2025.129198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification confronts significant challenges in modeling high-order spectral-spatial interactions and adaptively capturing fine-grained structural details, as existing deep learning methods typically suffer from inherent limitations in modeling nonlinear high-order features and reliance on fixed spatial sampling that fails to adapt to complex geometric variations of ground objects. To address these limitations, we propose a novel high-order deformable differential convolution network (HorD 2 CN) that enables explicit modeling of high-order feature interactions and adaptive capture of spatial structural details. The core innovation lies in the design of a high-order multi-scale differential convolution (HorMSDC) block, which is engineered to enhance the extraction of complex high-order patterns from HSI data and facilitate the representation of discriminative spectral-spatial information. This block integrates two synergistic modules: the high-order spectral differential convolution (HSEDC) module, which performs 1D high-order differential convolution via an adaptive spectral shift (ASES) operation to capture subtle spectral band variations between distinct land cover types and enhance fine-grained feature discriminability, and the high-order spatial differential convolution (HSADC) module, which employs 2D differential convolution with a deformable spatial shift (DSAS) operation to strengthen the modeling of multi-scale spatial structural details. By integrating these modules, HorD 2 CN enables adaptive extraction of high-order spectral-spatial features. Comprehensive experiments on five benchmark HSI datasets demonstrate that HorD 2 CN outperforms ten state-of-the-art deep learning methods, validating its effectiveness in HSI classification tasks.},
  archive      = {J_ESWA},
  author       = {Zitong Zhang and Fujie Jiang and Chengcheng Zhong and Qiaoyu Ma},
  doi          = {10.1016/j.eswa.2025.129198},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129198},
  shortjournal = {Expert Syst. Appl.},
  title        = {HorD2CN: High-order deformable differential convolution network for hyperspectral image classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Measures of type-2 fuzzy numbers: Balancing fast and slow thinking in decision analysis. <em>ESWA</em>, <em>296</em>, 129197. (<a href='https://doi.org/10.1016/j.eswa.2025.129197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by dual-process theory (DPT), type-2 fuzzy numbers (T2FNs) are introduced to model human judgment. Specifically, the judgment is functioned simultaneously by two systems: the intuitive System 1 referred to as fast thinking, and the analytical System 2 referred to as slow thinking. As a novel modeling tool for decision making, T2FNs have a wide range of potential applications in artificial intelligence, decision analysis, and related domains. To facilitate their extensive application, we adhere to DPT’s thinking mechanism, in which the processes of fast and slow thinkings are relatively autonomous while also being capable of mutual cooperation, and then develop some measures for T2FNs, including fuzzy entropy, distance measure, similarity measure, and correlation coefficient. In contrast to the existing fuzzy measures, the proposed ones allow for the quantification of mechanism between fast and slow thinkings. As such, they offer a solid theoretical interpretation for decision analysis. Finally, a numerical example is given to show that the proposed measures are capable of capturing the balanced interplay between fast thinking and slow thinking in human decision making.},
  archive      = {J_ESWA},
  author       = {Bin Zhu and Yuanzhen Xu and Xiaohan Yu and Zeshui Xu and Kun Yu},
  doi          = {10.1016/j.eswa.2025.129197},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129197},
  shortjournal = {Expert Syst. Appl.},
  title        = {Measures of type-2 fuzzy numbers: Balancing fast and slow thinking in decision analysis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). NRBO-AGP: A novel feature selection approach for accurate protein solubility prediction. <em>ESWA</em>, <em>296</em>, 129194. (<a href='https://doi.org/10.1016/j.eswa.2025.129194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein solubility determines how well a protein dissolves in an aqueous solution, and this property is a critical factor in the functional analysis of proteins and biotechnological applications. Accurately estimating solubility can provide significant advantages in areas such as protein engineering and drug discovery. This study proposes a new feature selection method, Newton-Raphson-based Optimization and Adaptive Gradient Perturbation (NRBO-AGP) for predicting protein solubility. The research combines the accuracy and speed of the Newton-Raphson method with the capacity of population-based optimization techniques to balance exploration and exploitation. Using 3144 protein sequences from the eSOL database, descriptor features were obtained for each protein, resulting in a dataset with 3104 features. The performance of NRBO-AGP was compared with eight different metaheuristic algorithms and evaluated using five regression models: MLP, AdaBoost, Gradient Boosting Trees, Random Forest, and Support Vector Regressor (SVR). The best results were obtained with the Gradient Boosting and Random Forest. Mean absolute error (MAE), root mean square error (RMSE), and coefficient of determination ( R 2 ) metrics were used for performance evaluation. The results show that NRBO-AGP outperforms other metaheuristic algorithms in all regression models. The best results were achieved with Gradient Boosting and Random Forest, reaching MAE: 0.0001 ± 0.0000 , RMSE: 0.0008 ± 0.0000 , and R 2 : 0.9908 ± 0.0005 , and MAE: 0.0002 ± 0.0000 , RMSE: 0.0025 ± 0.0000 , and R 2 : 0.9908 ± 0.0005 . These findings show that NRBO-AGP is an effective feature selection tool for predicting protein solubility. Multiple statistical analyses based on Friedman and Nemenyi tests show that the NBRO-AGP method exhibits statistically significant superior performance ( p < . 05 ) compared to other metaheuristic algorithms in MAE and RMSE metrics and also achieves the highest performance in the R 2 score.},
  archive      = {J_ESWA},
  author       = {Zahra Elmi and Soheila Elmi and Sebelan Danishvar},
  doi          = {10.1016/j.eswa.2025.129194},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129194},
  shortjournal = {Expert Syst. Appl.},
  title        = {NRBO-AGP: A novel feature selection approach for accurate protein solubility prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction and warning method for large passenger flow in metro transfer stations based on spatial and temporal characteristics of personnel trajectories. <em>ESWA</em>, <em>296</em>, 129193. (<a href='https://doi.org/10.1016/j.eswa.2025.129193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key node in the metro network, metro transfer stations are more likely to face the risk of large passenger flow under emergencies than general stations. Therefore, for the early warning of large passenger flow risk, it is greatly significant to predicting the transfer passenger flow in metro transfer stations accurately. This paper proposes S-DGNN (Sequence Directed Graph Neural Network) for predicting transfer passenger flow at transfer stations based on the spatial and temporal characteristics of personnel trajectories. The method designs a metro network topology as directed graph Neural Network (DGNN), which centers on transfer stations. DGCN describes the passenger flow correlations between general stations and transfer stations, as well as between transfer stations. The former correlation denotes the spatial and temporal correlation between entry passenger flow at general stations and passenger flow at transfer stations. This correlation is used to predict the passenger flow (without transfer) at transfer stations caused by the entry passenger inflow at general stations. The latter correlation is to predict the passenger flow at transfer stations caused by the transfer passenger flow at other transfer stations on the same line as the transfer station. S-DGNN takes stations as graph nodes, entry passenger flow as a graph node attribute, the time-varying correlation matrix as the attention weights of the directed edges, and the number of interval stations and the departure interval as edge time-delay attributes. The time-varying correlation matrix is predicted by The Prophet model through mining the trajectory and dynamic evolution characteristics of passenger flow at transfer stations. Further, GRU is adopted to capture the temporal correlation of the passenger. It is predicted by The Prophet model through mining the trajectory and dynamic evolution characteristics of passenger flow at transfer stations. The method has been applied to a metro system in a city in eastern China to achieve the prediction of transfer passenger flow in a 15-minute time period. The accuracy can reach the realistic demand, and the prediction results can provide valuable references for the safety decision-making of the relevant departments.},
  archive      = {J_ESWA},
  author       = {Dawei Cui and Zewei Zhang and Tongfeng Sun},
  doi          = {10.1016/j.eswa.2025.129193},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129193},
  shortjournal = {Expert Syst. Appl.},
  title        = {Prediction and warning method for large passenger flow in metro transfer stations based on spatial and temporal characteristics of personnel trajectories},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identifying important nodes based on local and global information. <em>ESWA</em>, <em>296</em>, 129192. (<a href='https://doi.org/10.1016/j.eswa.2025.129192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes in complex networks attracted attentions recently. However, many researches have focused on a single topology layer or on the integration of multi-layers structure information. But they are inherently limited in their partiality and subjectivity. In order to solve the problems of insufficient local information representation, high time complexity and parameter dependency existing hybrid information algorithms based on heterogeneous integration, we propose a new multi-dimensional parameterized computing framework and design an Improved Local and Global Centrality algorithm. Experimental results for six real datasets show that, comparing with the traditional LGC method, the Kendall’s, average speaking, could be increased by 9.96 % to 28.35 %. Moreover, the proposed method could identify the top node sets more accurately, which suggests that both local and global information play an important role for spreading influence node identification.},
  archive      = {J_ESWA},
  author       = {Qiang Guo and Meng-Meng Ye and Jian-Guo Liu},
  doi          = {10.1016/j.eswa.2025.129192},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129192},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identifying important nodes based on local and global information},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Driving policy distillation in autonomous racing with adaptive racing vocabulary and optimal driving guidance. <em>ESWA</em>, <em>296</em>, 129191. (<a href='https://doi.org/10.1016/j.eswa.2025.129191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous racing poses unique challenges - including high-speed dynamics, close competition, and operation at the limits of vehicle performance - that are not fully addressed by current learning-based driving policies. In this paper, we propose a specialized neural network driving policy architecture for real-time autonomous racing to tackle these challenges. Our approach introduces an adaptive racing vocabulary that encodes track geometry and vehicle state information, enabling the policy to respond effectively to rapidly changing racing conditions. We further employ policy distillation with multiple cost heads guided by an optimal driving reference, thereby reducing the reliance on large expert-driving datasets. In addition, Bayesian optimization dynamically combines cost components (controllability, safety, speed, etc.), minimizing lap time while maintaining vehicle control. In high-fidelity vehicle dynamics simulations, the proposed architecture demonstrates robust and adaptive driving behavior, successfully handling the complex and demanding scenarios inherent in autonomous racing.},
  archive      = {J_ESWA},
  author       = {Jonghyun Lee and Hyunwook Kang and Yuseung Na and Jeonghun Kang and Junhee Lee and Seongjae Jeong and Jiwon Seok and Kichun Jo},
  doi          = {10.1016/j.eswa.2025.129191},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129191},
  shortjournal = {Expert Syst. Appl.},
  title        = {Driving policy distillation in autonomous racing with adaptive racing vocabulary and optimal driving guidance},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SHINE: Synergizing transformers with contrastive learning for thriving rPPG-based SpO2 estimation. <em>ESWA</em>, <em>296</em>, 129190. (<a href='https://doi.org/10.1016/j.eswa.2025.129190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood oxygen saturation (SpO 2 ) is a critical physiological indicator for assessing respiratory and cardiovascular health. Conventional pulse oximetry systems, while widely used, require direct skin contact, thereby limiting remote applications. Remote photoplethysmography (rPPG) offers a non-contact alternative by using RGB cameras to estimate SpO 2 from facial videos. Despite its potential, current rPPG-based SpO 2 systems often depend on hand-crafted features and traditional machine learning, limiting their ability to capture complex temporal patterns. These systems also struggle with generalizability due to the lack of diverse datasets, particularly those representing darker skin tones. To address these challenges, we introduce SHINE , a novel transformer-inspired system for non-contact SpO 2 estimation from rPPG signals. SHINE is the first system in this domain to leverage transformers, enabling it to model temporal dynamics and global patterns more effectively. It further enhances feature learning through supervised contrastive learning and incorporates all combinations of red, green, and blue channel ratios of ratios (RoRs), accounting for skin tone differences in light absorption. Additionally, it utilizes a quality-weighted consolidation strategy that prioritizes less noisy RoRs, ensuring more reliable SpO 2 estimation. We also present a new large-scale rPPG dataset, including subjects with diverse skin tones, helping bridge the fairness gap in rPPG-based SpO 2 estimation. SHINE consistently outperforms existing systems on our proposed dataset, as well as on two publicly available datasets, PURE and MSPM, demonstrating the effectiveness and importance of each of its components. Upon acceptance, our dataset will be made publicly available to foster fairness and advance future research in this field.},
  archive      = {J_ESWA},
  author       = {Vaidehi Agarwal and Trishna Saikia and Anup Kumar Gupta and Puneet Gupta},
  doi          = {10.1016/j.eswa.2025.129190},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129190},
  shortjournal = {Expert Syst. Appl.},
  title        = {SHINE: Synergizing transformers with contrastive learning for thriving rPPG-based SpO2 estimation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous depots vehicle routing problem with sequential visiting. <em>ESWA</em>, <em>296</em>, 129189. (<a href='https://doi.org/10.1016/j.eswa.2025.129189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a variant of the Multi-Depot Vehicle Routing Problem (MDVRP) that incorporates heterogeneous depots, sequential depot visits, and customers’ multi-demand, named the Heterogeneous Depots Vehicle Routing Problem with Sequential Visiting (HDVRPSV), and develops its mathematical programming formulation. An Adaptive-Nearest-neighborhood-based Variable Neighborhood Search (ANVNS) metaheuristic is designed to solve HDVRPSV. Specifically, the depot sequential encoding scheme is proposed by considering sequential constraints between depots and customers. An initialization strategy that combines 2-opt and random insertion is proposed to generate the initial solutions. Next, an adaptive perturbation strategy is developed to dynamically shake the current solution. Finally, depot route-2-opt, nearest neighborhood reinsertion, and depot route swap operations are combined into a local search to improve solution quality. Simulation experiments demonstrate that ANVNS outperforms its five competitors in terms of solution quality, stability, and convergence. Moreover, a real-world delivery case is employed to illustrate that HDVRPSV is an effective delivery approach.},
  archive      = {J_ESWA},
  author       = {Hao Li and Xianghu Meng and Jing Tang},
  doi          = {10.1016/j.eswa.2025.129189},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129189},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous depots vehicle routing problem with sequential visiting},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Now and future of artificial intelligence-based signet ring cell diagnosis: A survey. <em>ESWA</em>, <em>296</em>, 129188. (<a href='https://doi.org/10.1016/j.eswa.2025.129188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signet ring cells (SRCs), associated with a high propensity for peripheral metastasis and poor prognosis, critically influence surgical decision-making and outcome prediction. However, their detection remains challenging even for experienced pathologists. While artificial intelligence (AI)-based automated SRC diagnosis has gained increasing attention for its potential to enhance diagnostic efficiency and accuracy, existing methodologies lack systematic review. This gap impedes the assessment of disparities between algorithmic capabilities and clinical applicability. This paper presents a comprehensive survey of AI-driven SRC analysis from 2008 through June 2025. We systematically summarize the biological characteristics of SRCs and challenges in their automated identification. Representative algorithms are analyzed and categorized as unimodal or multi-modal approaches. Unimodal algorithms, encompassing image, omics, and text data, are reviewed; image-based ones are further subdivided into classification, detection, segmentation, and foundation model tasks. Multi-modal algorithms integrate two or more data modalities (images, omics, and text). Finally, by evaluating current methodological performance against clinical assistance requirements, we discuss unresolved challenges and future research directions in SRC analysis. This survey aims to assist researchers, particularly those without medical backgrounds, in understanding the landscape of SRC analysis and the prospects for intelligent diagnosis, thereby accelerating the translation of computational algorithms into clinical practice.},
  archive      = {J_ESWA},
  author       = {Zhu Meng and Junhao Dong and Limei Guo and Fei Su and Jiaxuan Liu and Guangxi Wang and Zhicheng Zhao},
  doi          = {10.1016/j.eswa.2025.129188},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129188},
  shortjournal = {Expert Syst. Appl.},
  title        = {Now and future of artificial intelligence-based signet ring cell diagnosis: A survey},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive recursive gaussian mixture regression model for dynamic evolution prediction of multimode gas–water two-phase flow process. <em>ESWA</em>, <em>296</em>, 129187. (<a href='https://doi.org/10.1016/j.eswa.2025.129187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas-water two-phase flow exhibits both typical and transitional flow statuses. However, disturbances in the external environment or fluctuations in phase flow rates can trigger dynamic evolution. The long-term, dynamic and multimodal nature of the evolution process presents significant challenges for accurate flow status prediction performance and good fluid evolution tracking ability. Therefore, it is of great significance to predict the flow status evolution direction for early warning of dangerous situations and improving production efficiency and safety. In this work, an adaptive update prediction strategy based on recursive Gaussian mixture regression (RGMR) is designed to predict the multimode gas–water two-phase flow. Firstly, sparse local Fisher discriminant analysis is adopted to analyze the multi-sensor data and calculate the discriminant index to represent the flow evolution. Secondly, the initial global prediction model is established by RGMR based on the discriminant index, where all known directions of fluid evolution are integrated to achieve long-term prediction of flow status. When unacceptable prediction error occurs, a local prediction model is established from the data selected by the second-order similarity to capture real-time evolution properties. Then, Kullback-Leibler (KL) divergence based adaptive strategy is developed to update the global flow status prediction model, which divides into fusion and addition update strategies. When cumulative prediction error occurs with time lapse, fusion update strategy finds the mixed components of global model with similar distribution to the local model according to KL divergence and adjusts the global prediction parameters. For the emergence of new flow status, addition update strategy supplements the unknown components by learning the new evolution to track the dynamic change of fluid. The results show that the prediction strategy can obtain the future information required for flow process management with high accuracy.},
  archive      = {J_ESWA},
  author       = {Wentao Wu and Chao Tan and Shumei Zhang and Feng Dong},
  doi          = {10.1016/j.eswa.2025.129187},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129187},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive recursive gaussian mixture regression model for dynamic evolution prediction of multimode gas–water two-phase flow process},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimization model for ice and snow-covered objects based on deep learning. <em>ESWA</em>, <em>296</em>, 129186. (<a href='https://doi.org/10.1016/j.eswa.2025.129186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation plays a crucial role in national economic growth. However, safety issues such as poor driver visibility, difficulty in assessing road conditions, and weak vehicle anti-interference performance in icy and snowy weather severely impact traffic safety and autonomous driving technologies. Therefore, detecting and analyzing different types of ice and snow road coverage is of great significance. Research on ice and snow road surface coverage recognition often faces challenges such as insufficient robustness (shadow interference) and low recognition accuracy (due to limited dataset size, imbalanced dataset types, and inadequate feature extraction). To address these issues, this study introduces a Shadow Removal (SR) module to process ice and snow road surface coverage data, improving accuracy and robustness. Additionally, a Data Augmentation (DA 1,2 ) module is incorporated to expand the dataset and enhance feature extraction. Furthermore, a more comprehensive ice and snow road coverage classification model, the Mixture of Experts-based Vision Transformer Hybrid (MViT Hybrid), is proposed to enhance modeling and feature extraction capabilities. Finally, an optimal classification model for ice and snow road surface coverage recognition is proposed. Twelve different classification algorithms are compared with the SR- DA 1,2 -based MViT Hybrid method. Test results show that under the SR-DA 1,2 module, the proposed MViT Hybrid algorithm improves average recall by at least 5.80% compared to other algorithms. Compared with conventional ViT-series algorithms, the average recall improves by 5.80% to 11.51%. Moreover, it was found that adding weather interference to the original dataset negatively impacts classification accuracy, further demonstrating the robustness of the MViT Hybrid model.},
  archive      = {J_ESWA},
  author       = {Wang Zhenmin and Yang Sen and Zhang Houqing and Song Wenlong},
  doi          = {10.1016/j.eswa.2025.129186},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129186},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimization model for ice and snow-covered objects based on deep learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modeling for divisible project portfolio selection problem considering the loss from risk intensity changes. <em>ESWA</em>, <em>296</em>, 129185. (<a href='https://doi.org/10.1016/j.eswa.2025.129185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various risks seriously impact the effectiveness of project portfolios and even lead to project portfolio failure. However, although existing research has increasingly focused on selecting project portfolios from the perspective of risks, they ignore the phenomenon that the project interruption may cause changes in risk intensity and then result in losses different from expected, which is adverse for enterprises to select the optimal divisible project portfolio and realize the expected benefits. To address the gaps, this paper first considers the loss from risk intensity change when selecting a divisible project portfolio. Based on the expanded SIR model, a new method to quantify the loss from risk intensity change caused by project interruptions is proposed. A divisible project portfolio selection model to maximize profit is developed, and a comparative experiment is designed to verify the validity of the model. The results show that considering loss from risk intensity change can help enterprises get a more reasonable project portfolio execution plan and obtain more profits. This paper offers practical insight to enhance the resilience of project portfolios in complex environments.},
  archive      = {J_ESWA},
  author       = {Qi Wang and Xingmei Li and Qinliang Tan and Zhong Shen and Xiaoyan Lv},
  doi          = {10.1016/j.eswa.2025.129185},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129185},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling for divisible project portfolio selection problem considering the loss from risk intensity changes},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A bayesian network based framework for ripple effect analysis in cross-tier shipbuilding supply chains. <em>ESWA</em>, <em>296</em>, 129184. (<a href='https://doi.org/10.1016/j.eswa.2025.129184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern shipbuilding supply chains are increasingly vulnerable to cascading risks across multiple tiers. However, existing analytical models fail to adequately capture the nonlinear propagation of disruptions due to oversimplified dependency mappings and the neglect of latent risks. This limitation impairs managers’ ability to effectively manage ripple effects within multi-level production systems. This study proposes a Bayesian network (BN) with a leaky noisy-or to evaluate disruption propagation and resilience in both multi-level cross-tier and single-level linear shipbuilding supply chains. The framework models bidirectional dependencies and latent risks, quantifying how cross-tier structures leverage redundant pathways to mitigate downstream disruptions. Additionally, it identifies critical nodes and evaluates disruption scenarios through probabilistic analysis of interdependency. To validate the proposed framework, we conducted a 23-node shipbuilding supply network based on the operations data of J-shipyard. This work comparatively analyzes between cross-tier BN structures and conventional linear network representations. The cross-tier network demonstrated superior performance reducing downstream disruptions by 10.3%, thereby highlighting the resilience advantages of alternative pathways. Sensitivity analysis revealed that raw material suppliers are critical vulnerabilities, as indicated by a sensitivity index exceeding 0.25. This research advances the field of disruption analysis in complex production systems by enabling precise risk prioritization and optimizing pathway redundancy. Practitioners can utilize this framework to enhance the resilience of tiered supply chains, particularly in industries characterized by complex supply chains. The adaptability allows for its application across various multi-level organizations.},
  archive      = {J_ESWA},
  author       = {Yiqi Zhang and Yanhui Ma and Le Wang and Zhiqiong Wang and Lixia Zhang},
  doi          = {10.1016/j.eswa.2025.129184},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129184},
  shortjournal = {Expert Syst. Appl.},
  title        = {A bayesian network based framework for ripple effect analysis in cross-tier shipbuilding supply chains},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated ternary scheduling and execution bottleneck identification in stochastic job shops. <em>ESWA</em>, <em>296</em>, 129183. (<a href='https://doi.org/10.1016/j.eswa.2025.129183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an integrated hierarchical evolutionary framework for addressing the stochastic job shop scheduling problem (SJSSP) with triangularly distributed processing times, incorporating both ternary scheduling and execution bottleneck identification. To capture uncertainty, processing times are modeled using symmetrical ternary random numbers (STRNs), which represent lower bound, expected value, and upper bound in a unified format. Based on this representation, a ternary genetic algorithm (T_GA) is developed to generate three scheduling scenarios, i.e., optimistic, expected, and pessimistic, within the framework. Subsequently, a ternary extension of the technique for order preference by similarity to ideal solution (T_TOPSIS) method is proposed to identify the execution bottleneck, leveraging multi-attribute performance indicators derived from the ternary schedule. The effectiveness of T_GA and T_TOPSIS is demonstrated in the numerical studies, where it is shown that execution bottlenecks frequently differ from planning bottlenecks in stochastic job shops and vary with specific production schedules. Moreover, it is observed that as scheduling quality improves, the execution bottleneck tends to stabilize, revealing a convergence pattern with practical implications for production management and control in uncertain environments.},
  archive      = {J_ESWA},
  author       = {Cui-Lin Zhang and Jian Chen and Yao-Wen Sang and Jun-Qiang Wang},
  doi          = {10.1016/j.eswa.2025.129183},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129183},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrated ternary scheduling and execution bottleneck identification in stochastic job shops},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards sustainable closed-loop photovoltaic supply chains: A hybrid framework integrating reinforcement learning and mathematical models. <em>ESWA</em>, <em>296</em>, 129182. (<a href='https://doi.org/10.1016/j.eswa.2025.129182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of the deleterious consequences of excessive fossil fuel consumption, the transition to renewable energy sources, particularly solar energy, is inevitable. Consequently, designing an efficient supply chain that enhances recycling management and achieves sustainability goals is imperative. This study unveils an innovative approach for the sustainable management of photovoltaic system supply chains, employing a two-stage methodology based on reinforcement learning and mathematical modeling. Given technological advances, a dynamic environment, and uncertainties in selecting solar panels, the first phase uses reinforcement learning to identify the panel with the highest efficiency. The second stage focuses on designing a closed-loop supply chain network to minimize economic costs, mitigates environmental impacts, and incorporate social sustainability into decision-making. Likewise, time series models for forecasting photovoltaic energy demand enhance the model’s accuracy and efficiency. The proposed approach includes a comprehensive case study in Iran to demonstrate its real-world applicability. Key results indicate that the crystalline silicon panel emerges as the optimal choice through reinforcement learning. The demand forecasting model reveals an upward trend, and multi-objective optimization produces balanced network configurations that support trade-offs among economic, environmental, and social.},
  archive      = {J_ESWA},
  author       = {Reihaneh Ahadzadeh and Ehsan Dehghani and Peiman Ghasemi},
  doi          = {10.1016/j.eswa.2025.129182},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129182},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards sustainable closed-loop photovoltaic supply chains: A hybrid framework integrating reinforcement learning and mathematical models},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Theory-guided agent-based modeling for crime prediction and decision support. <em>ESWA</em>, <em>296</em>, 129181. (<a href='https://doi.org/10.1016/j.eswa.2025.129181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing effective crime prevention strategies remains essential in contemporary societies with a long-standing commitment to public safety. While agent-based modeling (ABM) of crime has made considerable progress in recent decades, many existing models face challenges in accurately reflecting the complexities of real-world crime dynamics, including the patterns of where and when crimes occur and the interactions among offenders, citizens, and police. This study introduces a comprehensive simulation framework designed to model street crimes—specifically robbery, burglary, and larceny—simultaneously, grounded in criminological theories such as Routine Activity Theory (RAT), Rational Choice Theory (RCT), and Crime Pattern Theory (CPT). The simulation incorporates real-world crime data, environmental data, census data, and other relevant datasets to model realistic human behaviors, including mobility patterns. The model’s outputs represent the spatial and temporal distribution of crimes, which are then used to evaluate two key policing strategies. The first experiment simulates hotspot patrolling at various times, targeting areas with high crime intensity. The second introduces a randomized patrol strategy, where officers—whose primary responsibility is not hotspot patrolling—allocate a specified percentage of their time to patrolling these areas. This study aims to provide actionable insights for optimizing patrol strategies and enhancing crime prevention efforts in urban settings. The results indicate that hotspot patrolling significantly reduces all three types of crime when considering two different strategies for implementing hotspot patrolling.},
  archive      = {J_ESWA},
  author       = {Shohreh Moradi and Yuan Zhou and Christi L. Gullion and Jay Michael Rosenberger and Victoria C.P. Chen and Chen Kan},
  doi          = {10.1016/j.eswa.2025.129181},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129181},
  shortjournal = {Expert Syst. Appl.},
  title        = {Theory-guided agent-based modeling for crime prediction and decision support},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A WebGIS-based digital twin platform for intelligent operation and maintenance of rail transit infrastructure. <em>ESWA</em>, <em>296</em>, 129180. (<a href='https://doi.org/10.1016/j.eswa.2025.129180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital twin, which integrates multidisciplinary attributes to achieve interactions between the virtual and the real worlds, has found numerous applications in the field of smart cities and transportation infrastructure. With the acceleration of urbanization, rail transit, as a key component of urban infrastructure, faces increasing challenges in maintenance and management. Traditional reactive maintenance methods can no longer meet the growing volume of user demands. This study presents an architecture of intelligent operation and maintenance platform for the rail transit infrastructure based on WebGIS, paving the way for a digital-twin solution driven by predictive maintenance. We present a case study of the Shanghai Metro Long Yang Road-Zhang Jiang High Tech experimental line, which demonstrates the significant advantages of our platform in real-time data integration, 3D visualization, and intelligent decision support. Dynamic simulation integrating finite element and multibody dynamics software further validate the effectiveness of digital twin technology in the identification and prediction of rail fastener damage.},
  archive      = {J_ESWA},
  author       = {Yifan Xu and Wei Huang and Junhua Xiao and Jie Shan and Mengbo Liu and Weian Guo and Yushan Zhu and Jing Zhang and Yu Yan},
  doi          = {10.1016/j.eswa.2025.129180},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129180},
  shortjournal = {Expert Syst. Appl.},
  title        = {A WebGIS-based digital twin platform for intelligent operation and maintenance of rail transit infrastructure},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ink removal by design: Leveraging structural cues for efficient and generalizable ink removal in whole slide pathology. <em>ESWA</em>, <em>296</em>, 129179. (<a href='https://doi.org/10.1016/j.eswa.2025.129179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Pathological images, particularly whole slide images (WSIs), serve as a cornerstone for clinical studies and diagnostics. However, the presence of permanent ink markings used by pathologists poses a significant challenge for the computational analysis of these images. Existing methods for ink removal have limitations, such as being computationally expensive, struggling with complex ink markings and staining differences, or relying on extensive annotated data. Purpose To address these limitations, we propose a novel two-stage method for robust and efficient ink removal from pathological images. Our method combines pixel clustering and deep learning classification to capture the structural features of ink markings, making it more generalizable and less dependent on annotated data. Method The first stage involves pixel clustering using a novel distance metric that incorporates spatial information and multiple color spaces. This separates ink markings from tissue regions based on structural characteristics. In the second stage, a pretrained ResNet50 model classifies the clustered pixels as ink markings or tissue by leveraging the structural features. This two-stage approach is designed to be robust to staining variations and cancer cell differences while enabling real-time processing. Results Evaluated on a large cancer dataset, our method outperformed the existing tools and methods, achieving an Obj-Dice of 0.92, Obj-HD of 84.2 µm, and Obj-HD95 of 46.5 µm. Furthermore, it generalized well to two other clinical datasets with multiple cancer types, achieving a success rate of 98.8 % on both datasets. Implications Our method’s ability to capture structural features of ink markings makes it robust and generalizable, suitable for widespread clinical application. The structural approach simplifies the classification task, reducing labeling effort and enabling real-time processing. These promising results suggest the potential of our method for improving computational analysis of pathological images in clinical settings.},
  archive      = {J_ESWA},
  author       = {Huer Wen and Yan Wu and De Shuang Huang},
  doi          = {10.1016/j.eswa.2025.129179},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129179},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ink removal by design: Leveraging structural cues for efficient and generalizable ink removal in whole slide pathology},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reinforcement learning framework using pointer networks to address tampering of pollutant control systems in freight transportation. <em>ESWA</em>, <em>296</em>, 129178. (<a href='https://doi.org/10.1016/j.eswa.2025.129178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road freight transportation, heavily reliant on diesel fuels, is a major source of emissions (i.e., air pollutants and greenhouse gases). To address this, governments enforce regulations like type approval, regular roadworthiness tests, and technical roadside inspections. While type approval ensures new vehicles meet emission standards, emissions worsen as vehicles age or when emissions control systems are tampered with or removed. Similarly, roadside screening is a timely, cost-effective way to detect high-emitting vehicles. Authorities can also identify tampered vehicles that fraudulently pass inspections but emit heavily in real-world conditions. However, logistics service providers (LSPs) often prioritize cost savings over environmental concerns and resort to vehicle tampering instead of fleet upgrades. Using the Stackelberg game to analyze decision-makers ’ behavior, this paper explores the conflict between LSPs and government agencies. A deep reinforcement learning (DRL) algorithm with pointer networks (PN) is proposed to solve this complex problem. Computational results from randomly generated instances highlight that the algorithm significantly outperforms existing methods and achieves convergence reasonably.},
  archive      = {J_ESWA},
  author       = {Masoumeh Messi Bidgoli and Emrah Demir},
  doi          = {10.1016/j.eswa.2025.129178},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129178},
  shortjournal = {Expert Syst. Appl.},
  title        = {A reinforcement learning framework using pointer networks to address tampering of pollutant control systems in freight transportation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Super resolution enhanced multi-view stereo network based on gumbel sampling. <em>ESWA</em>, <em>296</em>, 129177. (<a href='https://doi.org/10.1016/j.eswa.2025.129177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Stereo (MVS), as a method for visual 3D reconstruction, has seen notable advancements of depth prediction techniques in recent years. Nevertheless, there has not been sufficient research on the detailed characteristics of the probability distributions generated by depth estimation algorithms. In this paper, we impose constraints on the depth probability map shape by modifying the training objective function, which confines the location of the probability peaks. The employment of Gumbel sampling for reparameterization during training further refines the learning process. Additionally, the integration of an auxiliary super-resolution branch enhances the feature extraction process and reduces information loss during downsampling. Experimental results on public datasets DTU and Tanks&Temples demonstrate that our proposed method delivers excellent comprehensive performance. Specifically, on the DTU datasets, the Acc test result decreased by 0.009 mm, the Comp test result decreased by 0.05 mm, and the Overall result decreased by 0.03 mm. On the Tanks&Temples datasets, the mean F-score increased by 0.95.},
  archive      = {J_ESWA},
  author       = {Shichao Wang and Mingxing Jia and Shijie Chang and Dapeng Niu},
  doi          = {10.1016/j.eswa.2025.129177},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129177},
  shortjournal = {Expert Syst. Appl.},
  title        = {Super resolution enhanced multi-view stereo network based on gumbel sampling},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid layer-fusion convolutional neural network and machine learning framework for automated detection and classification of CAD and CHF cardiac diseases. <em>ESWA</em>, <em>296</em>, 129176. (<a href='https://doi.org/10.1016/j.eswa.2025.129176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary Artery Disease (CAD) and Congestive Heart Failure (CHF) are significant contributors to global mortality. Early diagnosis and intervention in cardiac subjects are crucial for reducing mortality rates and minimizing the associated treatment costs linked to these conditions. This highlights the critical need for efficient healthcare strategies aimed at the early detection and classification of cardiac diseases to improve patient outcomes. This study proposed a hybrid model combination of layer fusion Convolutional Neural Network (LF-CNN) and Machine Learning (ML) techniques, including Bayesian Optimized Support Vector Machine (BO-SVM), k-nearest neighbor (KNN), and Random Forest (RF) for detecting Normal (healthy), CAD, and CHF arrhythmia conditions. For training and validation, time-series and spectral features are extracted from HRV database of cardiac diseases to feed input of proposed model. Additionaly, to speedup the training, validation and to overcome overfitting, batch normalization was employed to adjust the distribution of features. This study also employed t-distributed Stochastic Neighbor Embedding (t-SNE) within deep CNN to visualize data and ensuring that fusion of different features. The simulation results demonstrated that the proposed method achieved an accuracy (Ac) of 99.88 %, a precision (Pr) of 99.89 %, a recall (sensitivity) of 99.68 %, and an F1-score of 99.79 % by integrating BO-SVM, KNN, and RF ML techniques with LF-CNN. The findings indicate that classifier performance can be significantly enhanced by fusion of multiple features instead of relying on a single feature and emphasizing the benefits of integrating ML with deep learning (DL) techniques.},
  archive      = {J_ESWA},
  author       = {Henok Mezemr Besfat and Demissie Jobir Gelmecha and Ram Sewak Singh},
  doi          = {10.1016/j.eswa.2025.129176},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129176},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid layer-fusion convolutional neural network and machine learning framework for automated detection and classification of CAD and CHF cardiac diseases},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive backstepping neural control for quadrotor UAVs under asymmetric state constraints and event-triggered mechanisms. <em>ESWA</em>, <em>296</em>, 129173. (<a href='https://doi.org/10.1016/j.eswa.2025.129173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive backstepping neural distributed control scheme for quadrotor unmanned aerial vehicles (UAVs) under asymmetric state constraints and event-triggered mechanisms. A thorough modeling methodology for the dynamic system of the quadrotor UAV is established, taking into account uncertainties, external disturbances, and associated drag effects. First, the speed function reconstructs the error signal to accelerate the convergence rate of the tracking signal. Second, asymmetric boundaries are designed to restrict the errors into the prescribed constraints. Third, a type-2 fuzzy wavelet neural network (T2FWNN) is developed to approximate uncertain functions in the UAV dynamics. In order to cope with the “complexity explosion” problem, a hyperbolic tangent tracking differentiator (HTTD) is integrated to accurately estimate the virtual control laws. Meanwhile, event-triggered mechanisms are employed to reduce the waste of communication resources. The proposed scheme not only effectively addresses the above issues, but also fulfills the prescribed performance criteria and the boundedness of all signals within the closed-loop system. Finally, simulation results demonstrate that the UAVs achieve distributed tracking control of lemniscate trajectories.},
  archive      = {J_ESWA},
  author       = {Pengxuan Wei and Fengyun Li and Shenghai Zhang and Yeqing Shan},
  doi          = {10.1016/j.eswa.2025.129173},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129173},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive backstepping neural control for quadrotor UAVs under asymmetric state constraints and event-triggered mechanisms},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive data-driven MCDM approach to determine the best single objective function for the aircraft sequencing and scheduling problem. <em>ESWA</em>, <em>296</em>, 129172. (<a href='https://doi.org/10.1016/j.eswa.2025.129172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aircraft sequencing and scheduling problem (ASSP) is a complex optimization problem, which becomes increasingly difficult to solve as the number of aircraft and objective increases. While metaheuristic approaches have been used to produce near-optimal solutions in a reasonable amount of time, these solutions may not be sufficient and detailed for the tactical planning phase of air traffic management (ATM). To obtain optimal solutions, exact solution methods such as mixed integer programming (MIP) or integer programming (IP) are often used; however, these approaches are computationally inefficient, and the solution time increases as the number of objectives in the problem increases. However, as there are several stakeholders in the ATM system, ASSP should include several objectives. To address this challenge, a multi criteria decision-making (MCDM) approach was proposed in this study to identify the single objective that provides the best overall results for all stakeholders. The ASSP was modeled using MIP, with the Istanbul Sabiha Gökçen Airport (LTFJ) airspace and runway structure integrated as a case study. 120 different traffic samples were run, and the results were quantified based on eight different objective functions evaluated in terms of 17 different criteria commonly used in the literature. A data-driven approach, namely Method based on the Removal Effects of Criteria (MEREC), was used to weight the criteria, and the Measurement of Alternatives and Ranking according to Compromise Solution (MARCOS) method was used to rank and validate the effectiveness of the objective functions. In addition, a rigorous two-fold sensitivity analysis considering simulated criteria weights and comparative analyses was performed at the end of the study. The results indicated that the minimization of average delay was the most significant objective function based on the current criteria, followed by the minimization of total flight times. This approach can be useful for decision-makers when trying to select or evaluate the trade-offs between different objectives in the ASSP.},
  archive      = {J_ESWA},
  author       = {Kadir Dönmez and Mahmut Bakır and Ramazan Kursat Cecen},
  doi          = {10.1016/j.eswa.2025.129172},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129172},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comprehensive data-driven MCDM approach to determine the best single objective function for the aircraft sequencing and scheduling problem},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ASPEN-WIND: Adaptive spectral and self-supervised interactive CNN-LSTM for enhanced wind power forecasting. <em>ESWA</em>, <em>296</em>, 129171. (<a href='https://doi.org/10.1016/j.eswa.2025.129171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting (WPF) is crucial for integrating renewable energy into power grids and optimizing energy management systems. However, existing forecasting methods often struggle to capture the complex temporal dynamics and nonlinear relationships inherent in wind power data. This paper introduces ASPEN-WIND (Adaptive Spectral and Self-supervised Predictive Network - Wind Integrated Neural Dynamics), a novel deep learning (DL) model for enhanced WPF. ASPEN-WIND combines an adaptive spectral block (ASB), an interactive convolution block (ICB), long short-term memory (LSTM) networks, and self-supervised learning (SSL). The ASB employs Fourier analysis to capture multi-scale temporal patterns and adaptively filter noise, while the ICB extracts complex spatial-temporal features. LSTM networks model long-term dependencies, and self-supervised pre-training improves the model’s ability to learn from limited labeled data. We evaluated ASPEN-WIND on multiple real-world wind farm datasets, demonstrating its superior performance compared to traditional and recent DL-based forecasting methods across various time horizons. The results, averaged over multiple runs (e.g., 10 runs with different random seeds), show significant improvements in forecasting accuracy, with average reductions in mean absolute error (MAE) and root mean square error (RMSE) of 5–8 % and 8–12 %, respectively.},
  archive      = {J_ESWA},
  author       = {Md Rasel Sarkar and Sreenatha G. Anavatti and Md Meftahul Ferdaus and Tanmoy Dam},
  doi          = {10.1016/j.eswa.2025.129171},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129171},
  shortjournal = {Expert Syst. Appl.},
  title        = {ASPEN-WIND: Adaptive spectral and self-supervised interactive CNN-LSTM for enhanced wind power forecasting},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DMN4DQ+: Optimising data repair to enhance data usability. <em>ESWA</em>, <em>296</em>, 129170. (<a href='https://doi.org/10.1016/j.eswa.2025.129170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data quality has become crucial in decision-making and data analysis. There is an intrinsic relationship between data quality and usability; however, acceptable levels of data quality depend on the contextual requirements and operational priorities of an organisation. The context of use, business needs, and the organisation’s appetite for risk all influence the usability of data. Achieving adequate levels of usability sometimes requires specific corrections, which can be costly and may incur have far-reaching consequences. This paper introduces the concept of target usability, by representing the minimum level of usability determined by business analysts at which data records can be used without compromising organisational performance. When data records fail to meet this threshold, a combination of corrective actions can be implemented to improve both quality and usability. To achieve near-optimal outcomes, the data quality analyst can effectively combine these sets of actions. This paper proposes DMN4DQ+, an extension of DMN4DQ, where the optimal combination of corrective actions can be derived from the application of constraint optimisation techniques based on the data quality rules described in decision models, the cost model of the actions, and on the usability profile of the record to be improved. The development of a technological stack has conveniently supported DMN4DQ+, and it has been evaluated using a real dataset, thereby demonstrating its applicability and performance.},
  archive      = {J_ESWA},
  author       = {Álvaro Valencia-Parra and Ángel Jesús Varela-Vaca and Luisa Parody and Ismael Caballero and María Teresa Gómez-López},
  doi          = {10.1016/j.eswa.2025.129170},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129170},
  shortjournal = {Expert Syst. Appl.},
  title        = {DMN4DQ+: Optimising data repair to enhance data usability},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning in action: Powering intelligent intrusion responses to advanced cyber threats in realistic scenarios. <em>ESWA</em>, <em>296</em>, 129168. (<a href='https://doi.org/10.1016/j.eswa.2025.129168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the increasing incidence of sophisticated cyber-attacks, particularly Advanced Persistent Threats (APTs), there is a growing need for intelligent and adaptive intrusion response solutions. In this paper, we propose a Reinforcement Learning (RL)-based model for APT intrusion response that can manage dynamic, multi-stage attacks and large observation spaces. The model supports both policy-based and value-based learning approaches, enabling comparative evaluation between different strategies. We introduce a realistic RL training environment based on emulation infrastructure, which accurately reproduces APT scenarios using real systems and executes a wide range of authentic Intrusion Response System (IRS) actions. This setup includes time and variability constraints commonly encountered in operational environments, offering a more practical alternative to traditional simulations. The RL agents, implemented using Proximal Policy Optimization (PPO) and Deep Q-Network (DQN) algorithms, were both trained and evaluated within this industrial-style emulated environment. Empirical results demonstrate that both DRL algorithms successfully learned effective and well-timed defensive actions under realistic constraints, confirming their capability to operate in dynamic, real-world APT scenarios.},
  archive      = {J_ESWA},
  author       = {Eider Iturbe and Angel Rego and Oscar Llorente-Vazquez and Erkuden Rios and Christos Dalamagkas and Dimitris Merkouris and Nerea Toledo},
  doi          = {10.1016/j.eswa.2025.129168},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129168},
  shortjournal = {Expert Syst. Appl.},
  title        = {Reinforcement learning in action: Powering intelligent intrusion responses to advanced cyber threats in realistic scenarios},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluation of supervised machine learning techniques for cavitation detection and diagnosis in a pump-as-turbine system. <em>ESWA</em>, <em>296</em>, 129167. (<a href='https://doi.org/10.1016/j.eswa.2025.129167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition to sustainable and efficient energy systems has driven a rapid adoption of variable renewable energy sources such as wind and solar, increasing the demand for reliable and flexible power generation. Hydropower remains essential to grid stability; however, aging infrastructure and the need for more flexible operation present significant challenges. Digitalization has emerged as a key strategy to modernise hydropower systems with Machine Learning (ML) playing an increasingly important role in predictive maintenance. This study explores the application of ML techniques for cavitation detection in pump-as-turbine (PAT) systems using vibration data. Decision Trees (DT), Support Vector Machines and Artificial Neural Network (ANN) models were evaluated for applicability in a predictive maintenance system. A novel hybrid framework is proposed that integrates a DT model to provide transparent, interpretable rules for predictions with an ANN model that assures high accuracy cavitation state predictions. Experimental results show that the ANN model achieved the highest classification performance (accuracy: 99.86%, F1-score: 99.84%), while the DT offers valuable interpretability with competitive accuracy (99.66%). Agreement between the model’s predictions implies confidence while disagreements prompt further investigation. This hybrid framework supports informed decision-making, reduced downtime, and improved diagnostics in digital hydropower systems.},
  archive      = {J_ESWA},
  author       = {Calvin Stephen and Biswajit Basu and Aonghus McNabola},
  doi          = {10.1016/j.eswa.2025.129167},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129167},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluation of supervised machine learning techniques for cavitation detection and diagnosis in a pump-as-turbine system},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MADViT: A vision transformer-based multilayer distillation framework for explainable anomaly detection in aerial imagery. <em>ESWA</em>, <em>296</em>, 129166. (<a href='https://doi.org/10.1016/j.eswa.2025.129166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in aerial imagery, such as drone footage or surveillance feeds, is critical for infrastructure inspection and security monitoring applications. Existing convolutional approaches struggle to capture the global context essential for reliable anomaly detection in aerial imagery scenes in which spatial relationships and subtle deviations (e.g., small-scale damage on railway tracks or environmental shifts in urban areas) are critical cues. Moreover, supervised methods demand annotated anomalies that are costly and often impractical to obtain in dynamic, cluttered environments. This paper proposes M A D V i T (Multi-layer Anomaly Detection Vision Transformer), a novel unsupervised anomaly detection framework leveraging Vision Transformers ( V i T s ) within a teacher-student distillation paradigm. We employs a pre-trained Data-efficient Image Transformer ( D e i T ) as a teacher to guide a smaller student D e i T model initialized with Kaiming initialization through multilayer knowledge distillation. By aligning intermediate patch-based representations and distillation tokens, we achieve robust anomaly detection with coarse localization. Evaluated on the Drone-Anomaly dataset and UIT-ADrone dataset, our approach outperforms state-of-the-art methods in terms of Area Under the ROC Curve (AUC). Our method achieves 83.65 % AUC on the challenging UIT-ADrone benchmark-improving over the state of the art method to 68.13 % (DAD-FSM) by +15.5 percentage points -and an AUC/EER of 88.33 %/0.210 on the Highway scene of the Drone-Anomaly dataset (State of the art method 87.08 %/0.20). Across four Drone-Anomaly inspection scenarios, we deliver per-scene AUC/EER of 84.20 %/0.250 (Bike Roundabout), 79.65 %/0.267 (Farmland Inspection), and 80.48 %/0.276 (Solar Panel Inspection), each representing clear gains over leading baselines. We demonstrate that multilayer distillation strengthens feature robustness and that our patch-based anomaly mapping enables explainable anomaly detection by clearly pinpointing the regions responsible for an anomaly, making this method a noteworthy advancement in unsupervised anomaly detection. The implementation details and pretrained models are publicly available in our GitHub repository https://github.com/manoj_balwant/MAD-ViT},
  archive      = {J_ESWA},
  author       = {Manoj Kumar Balwant and Shivendu Mishra and Rajiv Misra},
  doi          = {10.1016/j.eswa.2025.129166},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129166},
  shortjournal = {Expert Syst. Appl.},
  title        = {MADViT: A vision transformer-based multilayer distillation framework for explainable anomaly detection in aerial imagery},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-enhanced ConvNeXt for accurate, efficient, and interpretable crack detection. <em>ESWA</em>, <em>296</em>, 129165. (<a href='https://doi.org/10.1016/j.eswa.2025.129165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early crack detection is crucial for concrete infrastructure, yet manual inspections are slow and error-prone, making automated systems essential. This study presents an advanced hybrid deep learning model, based on Convolutional Neural Networks (CNNs) and attention mechanisms, that are fully optimized for both binary and multi-class crack classification tasks. The model fundamentally enhances the ConvNeXt architecture by re-scaling and optimizing it specifically for crack detection. It substitutes standard normalization layers with Global Response Normalization (GRN) to foster competition among feature channels. This approach amplifies salient features associated with cracks while suppressing background noise, thereby increasing the model’s discriminative power. Furthermore, the architecture integrates Block and Grid attention mechanisms inspired by Vision Transformers (ViTs). Block Attention improves local accuracy by analyzing fine-grained morphological details of cracks, such as width and texture, while Grid Attention captures global structural continuity by connecting fragmented segments, which enhances the detection of elongated cracks. Evaluated on the METU (binary) and SDNET2018 (multi-class) datasets, the model outperformed over 40 state-of-the-art architectures. It achieved 99.98 % accuracy on METU and 94.73 % on SDNET2018, a 2–3 % improvement over leading literature models. Computationally lightweight with 13.49 M parameters and 8.52 GFLOPS, it is ideal for real-time mobile deployment. Grad-CAM analysis validates the model’s interpretability by visually confirming its focus on relevant crack regions, enhancing trust in automated structural health monitoring.},
  archive      = {J_ESWA},
  author       = {Burhanettin Ozdemir and Fethi Sermet and Ishak Pacal},
  doi          = {10.1016/j.eswa.2025.129165},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129165},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-enhanced ConvNeXt for accurate, efficient, and interpretable crack detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IMFF: A dual-space optimization network via multi-level feature fusion and boundary-aware learning for high-resolution remote sensing scene classification. <em>ESWA</em>, <em>296</em>, 129163. (<a href='https://doi.org/10.1016/j.eswa.2025.129163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution remote sensing classification has emerged as a critical research frontier in geospatial analysis, particularly for urban planning and agricultural monitoring applications. Despite deep learning architectures have significantly advanced classification accuracy, two critical challenges remain: significant intra-class variance (e.g., seasonal changes in agricultural fields) and ambiguous inter-class distinctions (e.g., agricultural fields and forests exhibit similar visual characteristics). To address these issues, this study proposes a novel remote sensing image scene classification network, IMFF, a dual-space optimization architecture via multi-level feature fusion and boundary-aware learning with entropy-guided localization. Specifically, the framework is implemented through a coordinated three-pathway strategy: 1) a multi-scale context aggregation pathway used to capture hierarchical patterns through multi-level discriminative fusion structure (MDFS); 2) an information-guided refinement pathway, which is proposed to simultaneously enhance boundary discrimination via optimized laplacian-gaussian edge magnifier (LOGM) and dynamically localize semantically critical regions through high-entropy region contextualization module (HECM); 3) a discriminative feature distillation pathway effectively extracts high-order semantic information through a deep information miner (DIM). This unified optimization mechanism simultaneously enhances inter-class separability through boundary-aware learning while reducing intra-class variance through entropy-guided localization. Moreover, extensive experiments on three benchmarks demonstrate the excellent performance of the proposed model: it achieves 99.88 % accuracy on UC Merced, 97.65 % on AID, and 94.96 % on NWPU-RESISC45, outperforming existing methods while maintaining competitive efficiency (0.002s/image inference). The code is available at https://github.com/Codeater1/-IMFF-Net- .},
  archive      = {J_ESWA},
  author       = {Jianjun Yuan and Fujun Wu and Luoming Zhao and Qixin Zhang and Yaohong Chen},
  doi          = {10.1016/j.eswa.2025.129163},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129163},
  shortjournal = {Expert Syst. Appl.},
  title        = {IMFF: A dual-space optimization network via multi-level feature fusion and boundary-aware learning for high-resolution remote sensing scene classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Double population cooperation constrained multi-objective optimization for flood control and power generation scheduling in cascade reservoirs. <em>ESWA</em>, <em>296</em>, 129162. (<a href='https://doi.org/10.1016/j.eswa.2025.129162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water is the source of life. The management and efficient utilization of water resources are central concerns for society. The optimal scheduling of cascade reservoir systems plays an indispensable role in all aspects of water resource regulation. In response to the practical demands of flood control and power generation during the flood season, we constructed a flood control and power generation optimization scheduling model aimed at minimizing the water level at the dam front and the sum of squared discharge flows of the cascade reservoirs. To solve this model, the Double Population Cooperation Constrained NSGA-II (DPCCNSGA-II) algorithm was developed. The algorithm introduces an improved population initialization strategy, an adaptive non-dominated sorting strategy specifically designed for double population cooperation, and a rotation-based crossover operator. To validate the effectiveness of the proposed algorithm, it was applied to the real-world scheduling problem of the cascade reservoirs in the Huangbai River Basin. The experimental results demonstrate the superior performance of the algorithm in both benchmark tests and practical applications.},
  archive      = {J_ESWA},
  author       = {Qinghua Wu and Xuesong Yan},
  doi          = {10.1016/j.eswa.2025.129162},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129162},
  shortjournal = {Expert Syst. Appl.},
  title        = {Double population cooperation constrained multi-objective optimization for flood control and power generation scheduling in cascade reservoirs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diffusion prior guided deep model driven network for infrared and visible image fusion. <em>ESWA</em>, <em>296</em>, 129161. (<a href='https://doi.org/10.1016/j.eswa.2025.129161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods have achieved significant success in the field of image fusion, where the design of network architectures plays a crucial role in the fusion task. However, most deep learning fusion architectures still operate as black boxes and lack awareness of frequency domain information. To enhance the interpretability of fusion tasks and effectively utilize the frequency domain information from source images while ensuring the generation of high-quality fused images, we propose a novel deep model-driven network for infrared and visible image fusion guided by diffusion priors. The proposed algorithm generates a distribution of multi-channel input data through a diffusion process. Features produced by the denoiser serve as knowledge priors, guiding a custom model that leverages frequency domain knowledge to reconstruct high-quality fused images. Specifically, unlike some traditional fusion networks, our model can retain multi-channel data at the input stage rather than just single-channel spatial information. It uses the multi-channel features generated by the diffusion model as priors to guide the fusion process. Moreover, we innovatively design a frequency-domain-based objective function to guide the fusion process, constructing a frequency-domain learning module to simulate an interpretable deep model-driven network. Additionally, a task-driven loss function is developed to ensure the quality of the fused images. Extensive experimental evaluations across seven diverse datasets (e.g., MSRS, M3FD, RoadSence, TNO, Havard) and multiple scenarios demonstrate that the proposed algorithm significantly outperforms 9 state-of-the-art methods. Specifically, it delivers superior fusion results on eight metrics (e.g., EN, SF, VIF) with notable improvements in interpretability and robustness, as validated through comprehensive experiments on these seven benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Shuo Wang and Dapeng Cheng and Jinjiang Li},
  doi          = {10.1016/j.eswa.2025.129161},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129161},
  shortjournal = {Expert Syst. Appl.},
  title        = {Diffusion prior guided deep model driven network for infrared and visible image fusion},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient deployment of multiple jumping robots in uneven terrains using deep reinforcement learning. <em>ESWA</em>, <em>296</em>, 129159. (<a href='https://doi.org/10.1016/j.eswa.2025.129159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biologically-inspired jumping robots are capable of leaping over or onto obstacles, showcasing remarkable environmental adaptability. However, path planning for efficient deployment of multiple jumping robots remains a difficult challenge in uneven three-dimensional terrains. In this work, we present a locust-inspired jumping robot (JumpBot) with multiple locomotion modes (crawling, turning and jumping), and propose a multi-robot coordination algorithm (MCA) using deep reinforcement learning. MCA employs a centralized training framework with decentralized execution to enhance training efficiency. Additionally, we integrate long short-term memory (LSTM) networks into the training framework, which improves the ability of policy networks to process critical features for effective robot collaboration. For multi-target autonomous deployment tasks, we developed a simulation platform with experimental scenarios of different sizes and randomly placed obstacles. Simulation results demonstrate that JumpBot effectively combines both jumping and crawling modes, reducing the average path cost by 22.9 % compared to crawling alone. Moreover, our algorithm achieved an 81.2 % ± 2.39 % success rate, outperforming typical benchmark algorithms. Finally, we completed the deployment task of multiple jumping robots in a real-world environment for the first time, providing a novel approach to intelligent decision-making and collaboration for terrestrial robots.},
  archive      = {J_ESWA},
  author       = {Qijie Zhou and Gangyang Li and Yi Xu and Weitao Zhang and Liang Peng and Qing Shi},
  doi          = {10.1016/j.eswa.2025.129159},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129159},
  shortjournal = {Expert Syst. Appl.},
  title        = {Efficient deployment of multiple jumping robots in uneven terrains using deep reinforcement learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A feature-based knowledge distillation (FKD) for offline signature feature learning without signatures. <em>ESWA</em>, <em>296</em>, 129158. (<a href='https://doi.org/10.1016/j.eswa.2025.129158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel approach to harnessing the knowledge of pre-trained expert models for training new Convolutional Neural Networks, particularly in domains with limited or unavailable task-specific data. The method is applied to offline handwritten signature verification (OffSV), a biometric field that faces challenges related to data scarcity, often due to regulatory constraints. The proposed Student-Teacher (S-T) framework employs feature-based knowledge distillation (FKD), integrating graph-based similarity for local activations and global similarity measures to guide the student model’s training, using only handwritten text data. Notably, the models trained with this method show performance on par with, or exceeding, that of the teacher model across three widely used signature datasets. More importantly, these results are attained without employing any signatures during the feature extraction training process. This study demonstrates the efficacy of leveraging existing expert models to overcome data scarcity challenges in OffSV and potentially other related domains. The proposed methodology is available at https://github.com/dimTsourounis/FKD .},
  archive      = {J_ESWA},
  author       = {Dimitrios Tsourounis and Ilias Theodorakopoulos and Elias N. Zois and George Economou},
  doi          = {10.1016/j.eswa.2025.129158},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129158},
  shortjournal = {Expert Syst. Appl.},
  title        = {A feature-based knowledge distillation (FKD) for offline signature feature learning without signatures},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Delay-sensitive compound service function chain deployment in multi-provider edge cloud: A learning-based approach. <em>ESWA</em>, <em>296</em>, 129157. (<a href='https://doi.org/10.1016/j.eswa.2025.129157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Provider Edge Cloud (MPEC) is an important 5G network paradigm where Virtual Network Functions (VNFs) can be deployed on capacity-limited edge servers from different providers and near users, delivering low latency services. Compound Service Function Chains (SFCs) are ordered chains consisting of user-requested VNFs and Supplementary VNFs (S-VNFs) that bridge requested VNFs from different providers. However, different deployment schemes of requested VNFs determine the presence of distinct S-VNFs with varying capacity demands and processing delays. How to deploy VNFs of compound SFCs on edge servers and route their traffic through these VNFs within MPEC networks to minimize total service delay poses a great challenge. In this paper, we first formulate the compound SFC deployment problem as an integer nonlinear program and prove its NP-hard. To solve this problem, we analyze the components of service delay, decompose the problem into three subproblems and propose a heuristic algorithm. We further consider a condition that collaborations among providers are constrained to a limited scope and devise a reinforcement learning-based scheme to address this condition. Next, we present a theoretical analysis of the two proposed algorithms, including time complexity and worst-case performance bounds. Finally, extensive experiments on real-world datasets demonstrate that our algorithms outperform several existing methods.},
  archive      = {J_ESWA},
  author       = {Junbin Liang and Xi Chen and Min Chen},
  doi          = {10.1016/j.eswa.2025.129157},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129157},
  shortjournal = {Expert Syst. Appl.},
  title        = {Delay-sensitive compound service function chain deployment in multi-provider edge cloud: A learning-based approach},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale hypergraphs for trajectory imputation and prediction in real-world scenarios. <em>ESWA</em>, <em>296</em>, 129156. (<a href='https://doi.org/10.1016/j.eswa.2025.129156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction involves forecasting future paths based on observed trajectories. Many state-of-the-art methods assume that the observed agent sequences are complete an unrealistic assumption that overlooks inherent uncertainties in real-world data. Understanding the pedestrian behavior in the context of missing values within the observed sequence is essential for improving the performance of predictive models. In this work, we introduce the MultiScale Hypergraph for Trajectory Imputation and Prediction (MS-TIP), a novel method that simultaneously addresses the imputation of missing observations and the prediction of future trajectories. We utilize transformers with diagonal masked self-attention to handle incomplete observations. Our method enhances the modeling of complex interactions through multi-scale hypergraphs, which optimize our trajectory prediction module to capture various types of interactions. By incorporating scenic attention, our method learns contextual scene information instead of relying solely on spatial coordinates. Additionally, our approach utilizes an intermediate control point to infer future trajectory endpoints accurately. Furthermore, the trajectory refinement module improves the initially predicted trajectory, resulting in a more accurate future trajectory. Extensive experiments demonstrate the efficacy of MS-TIP in precisely predicting pedestrian trajectories. We also evaluate MS-TIP in additional real-world settings and provide a thorough comparison with state-of-the-art methods on different levels of missing values, further validating our approach. Code is publicly available at https://github.com/Pranav-chib/MS-TIP .},
  archive      = {J_ESWA},
  author       = {Pranav Singh Chib and Pravendra Singh},
  doi          = {10.1016/j.eswa.2025.129156},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129156},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scale hypergraphs for trajectory imputation and prediction in real-world scenarios},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TIPTrack: Time-series information prompt network for RGBT tracking. <em>ESWA</em>, <em>296</em>, 129155. (<a href='https://doi.org/10.1016/j.eswa.2025.129155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking explores an effective approach that improves the performance of visual object tracking (VOT) by incorporating thermal images. However, they are prone to collapse for ignoring time-varying features of object appearance during tracking processing. Therefore, this work proposes a time-series information prompt network (TIPTrack) that addresses appearance variations by treating the variation features of object appearance as a time-series prompt. The time-series information prompt records the variation features of the current frame and passes them to the next frame to assist the tracker in capturing the variation of object appearance. To further facilitate feature interaction of RGBT images, the dual-modal feature bridge (DFB) is employed to produces a mutual template feature that serves as a connected path, enhancing the common features of different modalities according to commutative attention computing. TIPTrack also incorporates high-and-low frequency fusion (HiLoFF), enabling the tracker to refine different features and integrate complementary attributes for RGBT images based on frequency distinctions. We evaluate and analyze TIPTrack on GTOT, RGBT210, RGBT234, LasHeR, and VTUAV. The evaluation results demonstrate that TIPTrack exhibits more remarkable performance on the evaluated datasets, and it is also more reliable in scenarios where object appearances change drastically or suddenly disappear.},
  archive      = {J_ESWA},
  author       = {Kaixiang Yan and Wenhua Qian},
  doi          = {10.1016/j.eswa.2025.129155},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129155},
  shortjournal = {Expert Syst. Appl.},
  title        = {TIPTrack: Time-series information prompt network for RGBT tracking},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Different-hop node interactions graph attention network with cross-scale guided feature fusion for hyperspectral image classification. <em>ESWA</em>, <em>296</em>, 129153. (<a href='https://doi.org/10.1016/j.eswa.2025.129153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks, which perform convolution as a weighted sum of neighboring features to generate a target node’s representation, have become a promising method for hyperspectral image (HSI) classification. However, this weighted sum operation assumes that neighbors are independent, overlooking potential interactions among them. In addition, existing classification methods use straightforward multiscale feature fusion techniques, such as addition and concatenation, which limit their ability to effectively distinguish between land cover categories. To tackle these issues, a different-hop node interactions graph attention network with cross-scale guided feature fusion (DNIGAT-CFF) is proposed for HSI classification. The DNIGAT-CFF comprises a graph attention network (GAT)-based subnetwork and a cross-scale feature fusion subnetwork. In the GAT-based subnetwork, a different-hop node interactions GAT is designed to construct adjacency matrices for different-hop node interactions from the spectral and spatial channels, enhancing the GAT’s ability to learn spectral and spatial features. In the cross-cale feature fusion subnetwork, considering the complementary and correlated relationships among features of different scales, a cross-scale guided feature fusion module is developed to effectively fuse the extracted multiscale features. Moreover, a weighted attention mechanism is employed to accentuate the significant features in the fused multiscale features. Experimental results demonstrate that more competitive classification performance is exhibited by DNIGAT-CFF compared to other state-of-the-art methods on five widely used HSI datasets. Specifically, overall accuracies of approximately 99.09 %, 97.63 %, 97.38 %, 91.35 % and 97.61 % are achieved on the Pavai University, Indian Pines, WHU-Hi-Honghu, Houston 2013 and Botswana datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Hui Yan and Haizhu Pan and Haimiao Ge and Moqi Liu and Bopeng Ren},
  doi          = {10.1016/j.eswa.2025.129153},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129153},
  shortjournal = {Expert Syst. Appl.},
  title        = {Different-hop node interactions graph attention network with cross-scale guided feature fusion for hyperspectral image classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inverse-free jacobian-estimated zeroing neural network model for mechanical arm path tracking with minimal joint motion. <em>ESWA</em>, <em>296</em>, 129152. (<a href='https://doi.org/10.1016/j.eswa.2025.129152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical arm path tracking with minimal joint motion is a significant research issue in the field of the mechanical arm control. Traditional zeroing neural network (ZNN) has been widely applied to effectively solve this issue by fully utilizing time derivative feedforward information and error feedback information. However, existing ZNN models face two main challenges that urgently need to be addressed. On one hand, Jacobian-based models require prior and real-time knowledge of the accurate Jacobian matrix of the mechanical arm. Nevertheless, obtaining the matrix is often challenging or impossible due to the mechanism complications, external environments, and uncertainties. On the other hand, existing models that estimate the Jacobian matrix require inverse matrix computations, imposing a significant computational load and reducing their efficiency. In this paper, on the basis of the ZNN method, we ingeniously design an inverse-free ZNN submodel and a Jacobian-estimated submodel, leading to the proposal of the inverse-free Jacobian-estimated ZNN (IFJEZNN) model. The IFJEZNN model not only has a low computational time complexity but also maintains high computational precision. Simulation and experiment verifications of various mechanical arms (i.e., planar four-link, UR5, and Franka Emika Panda mechanical arms) on various platforms (i.e., MATLAB, CoppeliaSim, and physical platforms) confirm the efficiency and applicability of the proposed model. Furthermore, comparative experiments with other state-of-the-art models further emphasize the exceptional capabilities of the IFJEZNN model.},
  archive      = {J_ESWA},
  author       = {Jielong Chen and Yan Pan and Yunong Zhang and Shuai Li and Min Yang},
  doi          = {10.1016/j.eswa.2025.129152},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129152},
  shortjournal = {Expert Syst. Appl.},
  title        = {Inverse-free jacobian-estimated zeroing neural network model for mechanical arm path tracking with minimal joint motion},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing the dependability of autonomous surface vehicles through robustness benchmarking of real-time object detection models. <em>ESWA</em>, <em>296</em>, 129151. (<a href='https://doi.org/10.1016/j.eswa.2025.129151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Autonomous Surface Vehicle (ASV) market is expected to double by 2030, rapidly transforming maritime logistics through faster deliveries, lower costs, reduced risks from human error, and the potential to save human lives. ASVs depend on robust object detection models to ensure safe navigation. However, existing models are often susceptible to natural corruptions such as blur, noise, adverse weather, and occlusions-risks to perception robustness further intensified by the lack of domain-specific robustness benchmarks. To fill this gap, we propose the first waterborne-focused robustness benchmark, incorporating 25 synthetic corruptions (15 adapted from ImageNet-C plus 10 novel ones for ASVs) across five severity levels. We also incorporate mixed corruptions to capture real-world complexity. Building on three public waterborne datasets (SeaShips, SMD, SSAVE), we create SeaShips-C, SMD-C, and SSAVE-C, each augmented with our corruption suite. A comprehensive robustness evaluation is conducted on multiple sizes of YOLOv8, SSD, NanoDet-Plus, and RT-DETR, revealing critical vulnerabilities: e.g., YOLOv8n’s mAP 50 drops by 43.0 % under contrast corruption on SeaShips-C, reaching a 59.5 % decline when combined with raindrops. Larger variants (e.g., YOLOv8x) exhibit greater robustness, offering insights for safer deployments. Aligned with ISO/IEC TR 5469 and IEC 61508, our benchmark supports pre-deployment verification. By identifying risk-prone conditions, practitioners can apply targeted mitigation strategies, such as data augmentation and human oversight. To promote further research and support industrial practice, we provide open access to all benchmark datasets and code-which can also serve as a data augmentation resource to enhance model training.},
  archive      = {J_ESWA},
  author       = {Yunjia Wang and Zihao Zhang and Kaizheng Wang and Holger Caesar and Jeroen Boydens and Davy Pissoort and Mathias Verbeke},
  doi          = {10.1016/j.eswa.2025.129151},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129151},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing the dependability of autonomous surface vehicles through robustness benchmarking of real-time object detection models},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TS-ENAS: Two-stage evolution for cell-based network architecture search. <em>ESWA</em>, <em>296</em>, 129150. (<a href='https://doi.org/10.1016/j.eswa.2025.129150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network architecture search provides a solution to the automatic design of network structures. However, it isn’t easy to search a whole network architecture directly. Although using stacked cells to search neural network architectures is an effective way to reduce the complexity of searching, these methods cannot find the global optimal neural network structure since the number of layers, cells, and connection methods is fixed. In this paper, we propose a Two-Stage Evolution for Cell-based Network Architecture Search (TS-ENAS), including one stage in which searching is based on stacked cells and a second stage that adjusts the cells. In our algorithm, a cell-based search space and an effective two-stage encoding method are designed to represent both cells and overall neural network structures effectively. In addition, a cell-based weight inheritance strategy is intended to initialize the weight of the network, which significantly reduces the running time of the algorithm. The proposed method was tested on four image classification datasets, Fashion-MNIST, CIFAR10, CIFAR100, and ImageNet. After comparing with 22 state-of-the-art algorithms, the experimental results show that TS-ENAS can more effectively find the neural network architecture. Code is available at: https://github.com/Francis-Xia/TS-ENAS .},
  archive      = {J_ESWA},
  author       = {Juan Zou and Jinghui Tong and Yizhang Xia and Shenghong Wu and Weiwei Jiang and Yuan Liu},
  doi          = {10.1016/j.eswa.2025.129150},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129150},
  shortjournal = {Expert Syst. Appl.},
  title        = {TS-ENAS: Two-stage evolution for cell-based network architecture search},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automatic dimensional quality inspection system for regular precast concrete elements based on 3D structure lighting scan technology. <em>ESWA</em>, <em>296</em>, 129149. (<a href='https://doi.org/10.1016/j.eswa.2025.129149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of precast concrete elements (PCEs) in the construction industry necessitates precise inspection techniques. Conventional manual inspection methods are both labor-intensive and prone to errors, while terrestrial laser scanning, which acquires three-dimensional (3D) point clouds, is costly, time-consuming, and requires specialized operators. To address these challenges, this paper introduces an automatic dimensional quality inspection system (ADQIS) designed for regular PCEs. This system utilizes structured light scanning (SLS) technology and is supported by a 5-degree-of-freedom motion platform that includes two-dimensional (2D) rotating equipment and an XYZ-axis sliding module, controlled visually through a computational graphical user interface (GUI). Furthermore, this study presents a novel, lightweight algorithm for uniform point cloud simplification. Based on this hardware, the paper proposes a new method for registering local point clouds of PCEs without the need for target markers. Additionally, a dimensional estimation method is detailed, involving the identification of rebar, concrete, and sleeves, and the application of circle and line fitting techniques to identify corners. Experimental results confirm the system’s effectiveness, demonstrating a maximum absolute dimensional discrepancy of no more than 2.06 mm when compared to conventional manual inspection, thereby establishing ADQIS as a viable option for routine PCE inspection.},
  archive      = {J_ESWA},
  author       = {Zhengtao Yang and Debiao Tang and Dongsheng Li and Tianze Chen and Jiepeng Liu and Hongtuo Qi and Zhou Wu and Junwen Zhou},
  doi          = {10.1016/j.eswa.2025.129149},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129149},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automatic dimensional quality inspection system for regular precast concrete elements based on 3D structure lighting scan technology},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CaRe-ego: Contact-aware relationship modeling for egocentric interactive hand-object segmentation. <em>ESWA</em>, <em>296</em>, 129148. (<a href='https://doi.org/10.1016/j.eswa.2025.129148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Egocentric Interactive hand-object segmentation (EgoIHOS) requires segmenting hands and interacting objects in egocentric images, which is crucial for understanding human behaviors in assistive systems. Current methods often overlook the essential interactive relationships between hands and objects, or merely establish coarse hand-object associations to recognize targets, leading to suboptimal accuracy. To address this issue, we propose a novel CaRe-Ego method that achieves state-of-the-art performance by emphasizing contact between hands and objects from two aspects. First, to explicitly model hand-object interactive relationships, we introduce a Hand-guided Object Feature Enhancer (HOFE), which utilizes hand features as prior knowledge to extract more contact-relevant and distinguishing object features. Second, to promote the network concentrating on hand-object interactions, we design a Contact-Centric Object Decoupling Strategy (CODS) to reduce interference during training by disentangling the overlapping attributes of the segmentation targets, allowing the model to capture specific contact-aware features associated with each hand. Experiments on various in-domain and out-of-domain test sets show that Care-Ego significantly outperforms existing methods while exhibiting robust generalization capability. Codes are publicly available at https://github.com/yuggiehk/CaRe-Ego/ .},
  archive      = {J_ESWA},
  author       = {Yuejiao Su and Yi Wang and Lap-Pui Chau},
  doi          = {10.1016/j.eswa.2025.129148},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129148},
  shortjournal = {Expert Syst. Appl.},
  title        = {CaRe-ego: Contact-aware relationship modeling for egocentric interactive hand-object segmentation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriC: Cross-hierarchy consistency constraints for point cloud understanding. <em>ESWA</em>, <em>296</em>, 129147. (<a href='https://doi.org/10.1016/j.eswa.2025.129147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable success of deep learning technologies in various 3D point cloud tasks, existing methods primarily rely on max-pooling operations to extract permutation-invariant features. However, these approaches discard a significant amount of valuable information, limiting the system’s ability to accurately perceive the environment. To address this limitation, we propose a novel framework, TriC, designed to leverage the discarded points more effectively. Our approach begins with a multi-stage feature extraction module that decomposes the feature map into fine-grained and coarse-grained components. Next, we enhance feature invariance by feeding both the original and the newly generated fine-grained features into a consistency regularizer, which yields a more robust and reliable feature representation. Coarse-grained features, which differ significantly from fine-grained ones, offer a complementary perspective on point cloud understanding. Promoting equivariance by increasing feature distance between the original feature and coarse-grained features, we gain additional insights into the point cloud. Finally, we combine the dual constraints of invariance and equivariance by fusing the multi-granularity features. TriC is a lightweight plug-in, and extensive experiments demonstrate its effectiveness in various downstream tasks. Specifically, when integrated with the advanced DGCNN model, TriC achieves an impressive instance accuracy of 83.92 % on the real-world ScanObjectNN dataset, surpassing the baseline by 1.75 %. For part segmentation on the ShapeNetPart dataset, AGConv+TriC attains a mean mIoU score of 86.3 %. For semantic segmentation, TriC shows a 2.1 % improvement in mIoU for key semantic components on the large-scale S3DIS dataset. Regarding model robustness, TriC outperforms state-of-the-art methods in handling challenges such as jitter, dropout, and even adversarial attacks.},
  archive      = {J_ESWA},
  author       = {Zhuang Chen and Ye Su and Xiao Jiang and Lili Li and Chuwei Jin and Zhiyong Xiao and Zhouping Huang and Yichen Ye and Yiyuan Xie},
  doi          = {10.1016/j.eswa.2025.129147},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129147},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriC: Cross-hierarchy consistency constraints for point cloud understanding},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spectrum occupancy detection supported by centralized or distributed federated learning. <em>ESWA</em>, <em>296</em>, 129146. (<a href='https://doi.org/10.1016/j.eswa.2025.129146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum occupancy detection is a key issue in enabling dynamic spectrum access. Nowadays, to improve detection effectiveness, the application of machine learning (ML) solutions is popular, and the issue of federated learning (FL) deserves special attention. A key challenge in spectrum occupancy detection is the limited access to labeled training data at the sensors. The sensor network studied in this work comprises a few sensors. These sensors have only partial access to labeled data during the ML model training process. The approach presented in this work uses the exchange of ML model coefficients to overcome the issue of limited training data at individual sensors. Both centralized and distributed FL variants were considered. The results of a hardware experiment involving the detection of the DVB-T signal by several sensors are discussed. In the presence of the sensor without access to labeled data probability of detection in the system increases from 52.06 % to 68.96 % in distributed variant, and to 78.87 % in centralized one. Moreover, the influence of neural network size on additional data transfer was analyzed due to the ML model coefficients exchange.},
  archive      = {J_ESWA},
  author       = {Łukasz Kułacz and Adrian Kliks},
  doi          = {10.1016/j.eswa.2025.129146},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129146},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spectrum occupancy detection supported by centralized or distributed federated learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiagent reinforcement learning in enhancing resilience of microgrids under extreme weather events. <em>ESWA</em>, <em>296</em>, 129145. (<a href='https://doi.org/10.1016/j.eswa.2025.129145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grid resilience is crucial in light of power interruptions caused by increasingly frequent extreme weather events. Well-designed energy management systems (EMS) have made progress in improving microgrid resilience through the coordination of distributed energy resources (DERs), but still face significant challenges in addressing the uncertainty of load demand caused by extreme weather. The integration of deep reinforcement learning (DRL) into EMS design enables optimized microgrid control strategies for coordinating DERs. Building on this, we proposed a cooperative multi-agent deep reinforcement learning (MADRL)-based EMS framework to provide flexible scalability for microgrids, enhance resilience and reduce operational costs during power outages. Specifically, the gated recurrent unit with a gating mechanism was introduced to extract features from temporal data, which enables the EMS to coordinate DERs more efficiently. Next, the proposed MADRL method incorporating action masking techniques was evaluated in the IEEE 33-Bus system using real-world data on renewable generation and power load. Finally, the numerical results demonstrated the superiority of the proposed method in reducing operating costs as well as the effectiveness in enhancing microgrid resilience during power interruptions.},
  archive      = {J_ESWA},
  author       = {Yin Wu and Wei-Yu Chiu and Yuan-Po Tsai and Shangyuan Liu and Weiqi Hua},
  doi          = {10.1016/j.eswa.2025.129145},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129145},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multiagent reinforcement learning in enhancing resilience of microgrids under extreme weather events},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto evolutionary algorithm based on markov chain for portfolio optimization considering profit of assets. <em>ESWA</em>, <em>296</em>, 129144. (<a href='https://doi.org/10.1016/j.eswa.2025.129144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional portfolio optimization problem aims to maximize returns and minimize risks, which is of importance in financial areas. In this work, we focus on a special kind of multi-objective portfolio optimization problem that considers the profit of assets (MOPOPA). MOPOPA differs from conventional portfolio optimization problems in that it optimizes the profit of assets and the risk of the portfolio simultaneously. Given the features of real-life investment management, we propose the MOPOPA model for the first time. To solve the problem, a Pareto evolutionary algorithm based on the Markov chain (PEAMC) is proposed. In PEAMC, we first present an offline-collected method to generate a high-quality initial population. Then, a learning approach based on the Markov chain and the Gaussian distribution model is proposed to learn pertinent information. Thereby, we predict a population based on the learned information, while producing another population through the nondominated sorting method. Afterward, a simple yet effective cooperation-based improvement mechanism is proposed to integrate the two populations and generate the offspring solutions of PEAMC. Results of experiments on 50 instances with up to 200 assets show that the proposed PEAMC performs better than state-of-the-art methods. Moreover, we make the 50 instances publicly available to facilitate future research on MOPOPA.},
  archive      = {J_ESWA},
  author       = {Zuocheng Li and Qianlei Xing and Rong Hu and Bin Qian},
  doi          = {10.1016/j.eswa.2025.129144},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129144},
  shortjournal = {Expert Syst. Appl.},
  title        = {Pareto evolutionary algorithm based on markov chain for portfolio optimization considering profit of assets},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A collaborative evolution algorithm for unmanned equipment project distributed scheduling optimization with grouping and due window constraints. <em>ESWA</em>, <em>296</em>, 129143. (<a href='https://doi.org/10.1016/j.eswa.2025.129143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of unmanned devices across various industries, the timeliness of project completion has become a critical factor influencing supply chain management and business operations. Focusing on the equipment delivery and processing phase in the project investment process, such as unmanned equipment, we address the distributed flowshop group scheduling problem with due windows (DFGSPDW) in this paper, aiming to minimize total weighted earliness and tardiness. To address DFGSPDW, a mathematical model is first developed, and then a collaborative evolution algorithm based on the iterated greedy (Co-IG) is proposed. The Co-IG incorporates an enhanced heuristic based on seven rules for generating initial solutions. In destruction and reconstruction phase, a collaborative destruction and reconstruction strategy is designed to enhance global search capabilities. In addition, an improved simulated annealing designed for DFGSPDW is proposed for avoiding the local optimum. Finally, experimental results from 405 instances show that Co-IG significantly outperforms state-of-the-art algorithms, providing superior solutions.},
  archive      = {J_ESWA},
  author       = {Xin Zhou and Ziyi Chen and Meigen Huang and Zhi Zhu and Tao Wang},
  doi          = {10.1016/j.eswa.2025.129143},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129143},
  shortjournal = {Expert Syst. Appl.},
  title        = {A collaborative evolution algorithm for unmanned equipment project distributed scheduling optimization with grouping and due window constraints},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic granularity-based multi-objective evolutionary algorithm for coal mine integrated energy system dispatch optimization. <em>ESWA</em>, <em>296</em>, 129142. (<a href='https://doi.org/10.1016/j.eswa.2025.129142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dispatch optimization of coal mine integrated energy system (CMIES) requires energy configuration at each time period (the smallest dispatch unit), which means the dimensionality of the variable space grows exponentially as the total number of time periods increases. Existing constrained multi-objective evolutionary algorithms converge slowly and struggle to identify tiny and disconnected feasible regions when solving the large-scale CMIES dispatch optimization problem. To this end, this paper develops a dynamic dispatch granularity-based multi-objective evolutionary algorithm, termed DGMA, where the dispatch granularity refers to the number of time periods represented by one dispatch unit. In particular, at the beginning of the evolution, the dispatch granularity is coarse (one dispatch unit denotes a large number of periods), which greatly reduces the search space and allows the proposed DGMA to rapidly detect potentially good solutions. As the evolution progresses, the dispatch granularity gradually refines, until one dispatch unit represents a single period. Through this gradual refinement, DGMA can perform a more refined search, thereby obtaining higher-quality dispatch plans. Furthermore, a diversity-enhanced environmental selection strategy is designed, which integrates the partition idea into the constraint relaxation method to promote both global and local diversity. The effectiveness and superiority of the proposed DGMA are validated through comparisons with seven state-of-the-art algorithms on various CMIES dispatch optimization problems.},
  archive      = {J_ESWA},
  author       = {Xiaoyu Zhong and Xiangjuan Yao and Kangjia Qiao and Dunwei Gong},
  doi          = {10.1016/j.eswa.2025.129142},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129142},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic granularity-based multi-objective evolutionary algorithm for coal mine integrated energy system dispatch optimization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Marker and dynamic geometry aware transformer for robust point cloud registration. <em>ESWA</em>, <em>296</em>, 129141. (<a href='https://doi.org/10.1016/j.eswa.2025.129141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based point cloud registration methods have attracted increasing attention in recent years due to their superior performance and global modeling capabilities. The key step is the matching of superpoints with structural similarity. However, existing approaches still face the challenge of ambiguous superpoint correspondences, as the sparsity of point clouds can lead to geometric ambiguity in overlapping regions, resulting in incorrect matches. To address this issue, we propose a novel method: Marker and Dynamic Geometry Aware Transformer (MDGT). First, we introduce a novel attention mechanism paradigm, Marker Attention, which enhances the model’s utilization of global information and improves matching accuracy through marker-based feature aggregation and broadcasting. Second, we design a Geometry aware Feature Fusion (GFF) module that enables the Transformer to more effectively leverage geometric information in point clouds and better exploit structural similarities between 3D point clouds. Finally, we develop a dynamic k-value adjustment strategy for the GFF module (DGFF), which generates more discriminative geometric features and further enhances feature distinctiveness, significantly reducing matching ambiguity. We conduct extensive experiments on benchmark datasets such as ModelNet, 3DMatch, and KITTI. Compared with state-of-the-art methods, our approach achieves the lowest relative rotation and translation errors on ModelNet, while demonstrating significant improvements of 4.62 % in inlier ratio on 3DMatch and an even more remarkable 9.23 % enhancement on 3DLoMatch. Comprehensive experimental results confirm that our method exhibits substantial advantages in both performance and robustness.},
  archive      = {J_ESWA},
  author       = {Yilin Chen and Qinjie Zheng and Tao Lu and Lu Zou and Xiantao Cai and Xiangyun Liao},
  doi          = {10.1016/j.eswa.2025.129141},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129141},
  shortjournal = {Expert Syst. Appl.},
  title        = {Marker and dynamic geometry aware transformer for robust point cloud registration},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Missing traffic data imputation with a conditional diffusion framework. <em>ESWA</em>, <em>296</em>, 129140. (<a href='https://doi.org/10.1016/j.eswa.2025.129140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic data is critical to Intelligent Transport Systems (ITS), but the original traffic data collected is often incomplete with sensor failures, transmission problems, and weather interference. Traffic data imputation aims to fill in missing values based on the complex patterns of traffic observations as well as its spatiotemporal dependence. The current dominant autoregressive model for missing value imputation suffers from error accumulation. Diffusion probabilistic models have recently outperformed existing counterparts in many tasks such as image generation and audio synthesis, and are promising for traffic data imputation. However, the construction and utilisation of conditional information is an unavoidable challenge when applying diffusion models to traffic data imputation. To address the above issues, we propose a conditional diffusion framework based on variational autoencoder (VAE) and multi-scale trend information extraction. The framework constructs conditional information based on complex temporal patterns of observations and takes full advantage of the conditional information through a conditional feature extraction module. Our model outperforms existing imputation methods in various missing patterns of traffic data and is adapted to various traffic scenarios.},
  archive      = {J_ESWA},
  author       = {Jie Li and Dun Lan and Yongshun Gong and Long Zhao and Wenpeng Lu and Yuhai Zhao and Xiangjun Dong and Xiaoming Wu},
  doi          = {10.1016/j.eswa.2025.129140},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129140},
  shortjournal = {Expert Syst. Appl.},
  title        = {Missing traffic data imputation with a conditional diffusion framework},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic adaptive attention optimization for cross-domain few-shot learning. <em>ESWA</em>, <em>296</em>, 129139. (<a href='https://doi.org/10.1016/j.eswa.2025.129139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Domain Few-Shot Learning (CD-FSL) has garnered significant interest recently, aiming to tackle the challenge of Few-Shot Learning (FSL) across extremely disparate domains. Current CD-FSL studies primarily focus on transfer learning-based methods, which typically transfer knowledge at the algorithmic level and rely on generic features acquired from the source domain. These methods have not fully explored the potential of dynamic feature selection and optimization to enhance the model’s feature representation capability for target domain-specific information. To address this problem, this paper introduces few unlabeled target domain data during the cross-domain transfer stage and designs a dynamic adaptive attention method, which can dynamically adjust the network’s attention to feature channels and spatial locations and improve the model’s feature extraction ability and cross-domain adaptability. Furthermore, to alleviate overfitting during the target domain adaptation stage, a dropout regularization strategy is considered into the fine-tuning process, which reduces the model’s dependence on specific training samples by randomly dropping a partion of neurons, thereby enhancing its generalization capability for novel classification tasks. Comprehensive experimental results reveal that our approach attains 58.69 % and 67.04 % average accuracy on the BSCD-FSL benchmark under 5-way 1-shot and 5-shot settings. In particular, the proposed method achieves 99.25 % and 97.38 % accuracy on CropDisease and EuroSAT under 50-shot setting. The results highlight the superiority of our proposed method and achieve competitive results against recent CD-FSL methods.},
  archive      = {J_ESWA},
  author       = {Jinfang Jia and Xiang Feng and Huiqun Yu},
  doi          = {10.1016/j.eswa.2025.129139},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129139},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic adaptive attention optimization for cross-domain few-shot learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sparsity enhanced tensor denoising based on weighted noise-free and noise estimation via discrete cosine transform. <em>ESWA</em>, <em>296</em>, 129138. (<a href='https://doi.org/10.1016/j.eswa.2025.129138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust Tensor Principal Component Analysis (RTPCA) has gained widespread popularity for tensor denoising in recent years due to its strong interpretability. However, the RTPCA model and its variants often suffer from high computational complexity, primarily due to their reliance on the Discrete Fourier Transform (DFT), and typically exhibit slow convergence rates because they depend heavily on the Iterative Shrinkage Thresholding (IST) algorithm. To address these limitations, we propose two novel tensor denoising models based on the low-complexity Discrete Cosine Transform (DCT): RTPCA with Double Sparse components (RTPCA-DS) and Re-weighted RTPCA-DS (RRTPCA-DS). To further mitigate the performance degradation that may arise from the use of DCT, noise location priors are explicitly incorporated to provide auxiliary guidance by estimating the weights of noise-free and noisy regions. Moreover, a new denoising framework that integrates refined ℓ 1 regularization terms with a theoretically guaranteed non-convex formulation is established to enhance noise removal effectiveness. In addition, we develop a high-dimensional accelerated proximal gradient algorithm for model optimization, which achieves a convergence rate of O ( k − 2 ) and reaches an ϵ -optimal solution within O ( 1 ϵ ) iterations. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness and superiority of the proposed models across various evaluation metrics.},
  archive      = {J_ESWA},
  author       = {Weidong Zhang and Yali Fan and Yan Song},
  doi          = {10.1016/j.eswa.2025.129138},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129138},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sparsity enhanced tensor denoising based on weighted noise-free and noise estimation via discrete cosine transform},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel hybrid AHP-entropy weighted dynamic network DEA framework for comprehensive efficiency assessment. <em>ESWA</em>, <em>296</em>, 129137. (<a href='https://doi.org/10.1016/j.eswa.2025.129137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel hybrid AHP-Entropy Weighted Dynamic Network Data Envelopment Analysis (DEA) framework for comprehensive efficiency assessment. Traditional DEA models often fail to capture the intricate interdependencies and multidimensional, dynamic nature of real-world systems, typically treating performance measurement as a static process. Even advanced network and dynamic DEA models face challenges in weight determination, as flexible schemes can distort efficiency assessments and yield unrealistic results. Existing weighting methods either rely solely on subjective judgments, potentially introducing bias, or purely on objective data, which may ignore contextual knowledge and stakeholder preferences. To address these fundamental limitations, this research synthesizes the Analytic Hierarchy Process (AHP) with entropy methods, integrating subjective expert judgments and objective data-driven weights. This hybrid approach mitigates potential biases and enables a more nuanced understanding of performance by capturing interdependencies across different stages and periods. These integrated weights are incorporated into dynamic network DEA frameworks employing directional distance vectors for flexible efficiency measurement. Applying this framework to evaluate the efficiency of the Indian state-level school education system from 2018 to 2022, utilizing a dynamic network DEA model, reveals significant disparities in performance across states. Key findings indicate that only a few states, such as Himachal Pradesh, Nagaland, Goa, Tripura, and Mizoram, achieved complete efficiency across all educational divisions, while others, like Gujarat, Karnataka, and Bihar, were found to be inefficient, particularly in Division 4 (Higher Secondary). The novel integration of weighting methodologies within a dynamic network DEA framework contributes significantly to the literature on performance measurement by advancing both methodological understanding and practical application in complex organizational performance assessments.},
  archive      = {J_ESWA},
  author       = {Shivani Kalyan and Pooja Bansal and Sunil Kumar},
  doi          = {10.1016/j.eswa.2025.129137},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129137},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel hybrid AHP-entropy weighted dynamic network DEA framework for comprehensive efficiency assessment},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A time-efficient lane-changing strategy for connected and autonomous vehicle platoons in mixed traffic. <em>ESWA</em>, <em>296</em>, 129136. (<a href='https://doi.org/10.1016/j.eswa.2025.129136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected and autonomous vehicles (CAV) are expected to form closely spaced platoons due to their potential to enhance traffic safety, increase road capacity, and improve energy efficiency. However, in mixed traffic environments involving Human-driven vehicles (HDV), platoon lane-changing becomes a significant challenge, as it is inevitably influenced by HDVs and requires substantial space to accommodate the entire platoon. Existing studies reveal significant limitations in the efficiency of platoon lane-changing, which may increase collision risks in scenarios requiring rapid lane changes to avoid obstacles. To tackle this challenge, this paper introduces a time-efficient platoon lane-changing strategy (TEPLC), enabling CAV platoons to efficiently transition to the target lane in mixed traffic environments. The TEPLC strategy achieves efficient lane-changing through a two-step process: First, any acceptable gaps in the target lane are identified, and a portion of the platoon is prioritized to occupy these gaps. Second, the CAVs that have already changed lanes coordinate their longitudinal movements to create additional space for the remaining vehicles. Finally, the remaining vehicles are guided to complete their lane changes sequentially. To ensure the safe and efficient execution of these coordinated maneuvers, a cooperative lane-changing motion planning model and a longitudinal coordination planning model are developed. Additionally, an HDV motion prediction model is introduced to address the uncertainties associated with HDVs in the target lane, ensuring collision avoidance during the execution of coordinated maneuvers by CAVs. Simulation results validate the efficiency and robustness of the TEPLC method across various scenarios. The efficiency analysis provides insights into the distance and time required for platoon lane-changing using the TEPLC method under different platoon sizes and traffic demand scenarios in both non-emergency and emergency situations. Compared to the state-of-the-art method, the TEPLC method demonstrates significantly higher efficiency across all tested scenarios, indicating its superior performance and potential as an advanced solution for platoon lane changing.},
  archive      = {J_ESWA},
  author       = {Fansheng Xing and Chenglin Liu and Zhigang Xu and Jiatong Xu and Haotong Tang and Ying Gao and Xiangmo Zhao and Xiaobo Qu and Xiaopeng Li},
  doi          = {10.1016/j.eswa.2025.129136},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129136},
  shortjournal = {Expert Syst. Appl.},
  title        = {A time-efficient lane-changing strategy for connected and autonomous vehicle platoons in mixed traffic},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Real-time classification model for anomalous sensor data in dam safety monitoring based on convolutional neural networks and transfer learning. <em>ESWA</em>, <em>296</em>, 129135. (<a href='https://doi.org/10.1016/j.eswa.2025.129135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and timely identification of sensor- and environment-induced anomalies prior to structural health assessment is critical for enhancing the effectiveness of dam safety monitoring. This study proposes a method based on Convolutional Neural Networks (CNNs) and transfer learning to classify dam safety monitoring data into five categories: normal conditions, single-point sensor failure, measurement line failure, abrupt environmental change, and suspected structural anomaly. A CNN-based classifier is developed to integrate spatial monitoring data and environmental variables. To address the scarcity and imbalance of anomaly samples, a training framework is introduced based on the Hydrostatic-Seasonal-Time (HST) model and transfer learning. Additionally, a Class Activation Mapping (CAM)-based interpretability technique is used to visualize the model’s diagnostic rationale. The proposed method effectively addresses challenges such as real-time anomaly classification, poor generalization in small-sample scenarios, and the complexity of traditional diagnostic models. Validation across four monitoring projects from three ultra-high dams demonstrates its robustness, achieving a missed and false detection rate below 0.11% and an average F1-Score of 97.7%. Comparative analysis with seven baseline models confirms superior accuracy, generalizability, and interpretability, supporting its practical value for intelligent dam safety monitoring.},
  archive      = {J_ESWA},
  author       = {Jichen Tian and Jiankang Chen and Junyi Wang and Huibao Huang and Yanling Li},
  doi          = {10.1016/j.eswa.2025.129135},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129135},
  shortjournal = {Expert Syst. Appl.},
  title        = {Real-time classification model for anomalous sensor data in dam safety monitoring based on convolutional neural networks and transfer learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inter-star: A modified multi A-star approach for inter-reconfigurable robots. <em>ESWA</em>, <em>296</em>, 129134. (<a href='https://doi.org/10.1016/j.eswa.2025.129134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable robots can overcome physical limitations by combining them for larger strength and area coverage and splitting them to fit spatial constraints. The robustness and versatility of such robots are difficult to appreciate without some level of autonomy built into such systems. The paper identified that one of the issues encountered in this development is the scalability of such autonomous systems. To address one of the many problems in this issue, this paper proposes a novel approach to modifying the popularly used Astar algorithm and enabling scalability in computing path plans during the combining and splitting phase of inter-reconfiguration. The proposed Inter-Star algorithm achieves its time complexity O ( log n · x ) for multi-robot path planning in converging and diverging path plans. The team has studied the inefficiencies and redundancies of iterating the algorithm as applied widely by many contributors and practitioners. The tested and proposed algorithms space and time complexity are analyzed and discussed. At a small scale, the results of the modification have been shown to improve the scalability by at least 3.02 times more scalable than the original Astar algorithm. In addition, up to 3 Wasp Biggie robots, an inter-reconfigurable robot platform, are used to show the performance of this algorithm against Dijkstra’s and Astar algorithms. In both simulations and experiments, the proposed solution has shown superior computational time performances.},
  archive      = {J_ESWA},
  author       = {Ash Yaw Sang Wan and Yang Zhenyuan and Moo Chee Gen and M.A. Viraj J. Muthugala and Mohan Rajesh Elara},
  doi          = {10.1016/j.eswa.2025.129134},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129134},
  shortjournal = {Expert Syst. Appl.},
  title        = {Inter-star: A modified multi A-star approach for inter-reconfigurable robots},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). QuAd-caching management model for heterogeneous data lake environments. <em>ESWA</em>, <em>296</em>, 129133. (<a href='https://doi.org/10.1016/j.eswa.2025.129133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous and multi-structured data, stored at distributed geographical locations leads to latency in user query processing and unavailability of demanded data. The existing caching schemes based on the duration of the web page stay within the cache, lag while dealing with the heterogeneity of content’s demand, and fail to provision dynamic caching automatically. In this context, this paper proposes a novel dynamic and automatic cache management model named QuAd-Caching . It integrates diverse learning with the computational efficiency of Qu antum machine learning and optimal solution-finding capability of Ad am optimization for proactive estimation of caching contents. Specifically, three distinct QuAd estimators for cache size prediction, eviction, and entry, are employed to capture all-inclusive dynamic cache management in diverse data lake environments. The simulation and performance evaluation of the proposed QuAd caching using a benchmark dataset confirms its efficiency and potency in dynamic cache management while reducing average data access time up to 100.826 nsec as compared with optimal case reporting 100 nsec, and minimizing average delay up to 99 % over without QuAd-caching. Further, the number of cache hits is improved up to 52.7 % over the existing caching approaches.},
  archive      = {J_ESWA},
  author       = {Deepika Saxena and Ashutosh Kumar Singh and Volker Lindenstruth},
  doi          = {10.1016/j.eswa.2025.129133},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129133},
  shortjournal = {Expert Syst. Appl.},
  title        = {QuAd-caching management model for heterogeneous data lake environments},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-criteria decision-making framework for metaverse adoption: Evidence from higher education systems. <em>ESWA</em>, <em>296</em>, 129132. (<a href='https://doi.org/10.1016/j.eswa.2025.129132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of metaverse technology into higher education institutions (HEIs) offers transformative potential for enhancing pedagogical innovation and addressing evolving educational demands. However, its effective implementation requires a systematic assessment of enablers and implementation feasibility across diverse HEI contexts. In this study, a novel T-spherical fuzzy (T-SF) hybrid model is developed to address this issue. The proposed model first collects expert evaluation information using T-spherical fuzzy sets (T-SFSs) and utilizes a similarity measure to determine expert weights. The weighted Heronian mean aggregation (WHMA) operator is then integrated to derive conservative aggregated values. Furthermore, the T-SF-WHMA-MULTIMOOSRAL hybrid model evaluates and ranks the metaverse integration across different types of HEIs. Finally, a case study is presented to illustrate the application of the T-SF-WHMA-MULTIMOOSRAL hybrid model. The results indicate that the continual feedback for teachers and students ( E s 7 ) and the sustainability and environmental impact ( E s 6 ) as the most influential enablers of metaverse integration. This study evaluates and ranks the potential for metaverse integration across four distinct types of HEIs, with the results showing that higher vocational colleges ( O 1 ) ranked highest. The findings of this study provide practical insights for guiding the adoption of metaverse technology in diverse and complex educational environments.},
  archive      = {J_ESWA},
  author       = {Yajing Zhang and Min Kong and Wei Zhong Wang and Muhammet Deveci and Mevlut Savas Bilican and Dursun Delen},
  doi          = {10.1016/j.eswa.2025.129132},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129132},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-criteria decision-making framework for metaverse adoption: Evidence from higher education systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weekly train timetabling integrating stop planning for high-speed rail lines. <em>ESWA</em>, <em>296</em>, 129131. (<a href='https://doi.org/10.1016/j.eswa.2025.129131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-speed rail (HSR) train planning and scheduling, traditional approaches often focus on passenger demand over short periods, such as one or two hours or a single day, while overlooking demand fluctuations over an entire week. This study proposes an integrated model for weekly train timetabling and stop planning, aiming to optimize both train stops and schedules across different times of day and days of the week. To improve computational efficiency for large-scale, real-world applications, a Lagrangian relaxation algorithm is developed. Case studies based on Chinese HSR lines demonstrate that the proposed model and algorithm outperform both the commercial solver CPLEX and the conventional sequential approach of line planning followed by timetabling. The weekly timetable generated by the proposed algorithm significantly reduces train and passenger traveling costs by improving traveling speeds and the proportion of passengers traveling within their preferred periods compared to current practical timetables, making it widely applicable to a wide range of HSR lines.},
  archive      = {J_ESWA},
  author       = {Bowen Nie and Lei Nie and Huiling Fu and Zhiyuan Lin and Ronghui Liu},
  doi          = {10.1016/j.eswa.2025.129131},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129131},
  shortjournal = {Expert Syst. Appl.},
  title        = {Weekly train timetabling integrating stop planning for high-speed rail lines},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A gradient-based lightweight network automated design method for facial expression recognition. <em>ESWA</em>, <em>296</em>, 129130. (<a href='https://doi.org/10.1016/j.eswa.2025.129130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have been widely used in facial expression recognition (FER) because they extract image features automatically and have achieved significant results. Nevertheless, manually designing neural networks is prone to errors and consumes a significant amount of time, while automatically designing neural networks suffers from high time consumption and large memory occupation. To address the above problems, we propose a gradient-based lightweight network automated design method called GLA-FERNet for FER. First, we propose a gradient FER network framework based on differentiable neural architecture search to achieve accurate FER and reduce time consumption during automated search of network architectures. Second, we propose a channel sampling process strategy by random or sequential sampling a small part of the super-network to enhance search stability while maintaining low memory usage. We conduct rich experiments on RAF-DB, AffectNet, RAF-DB (10 %), RAF-DB (20 %) and RAF-DB (30 %) datasets to verify the performance of the proposed GLA-FERNet. The experimental results demonstrate that GLA-FERNet outperforms state-of-the-art representative methods in terms of accuracy, precision, recall, and F1-score on the five benchmark datasets. Furthermore, the results of ablation experiments demonstrate that the proposed channel sampling process strategy greatly improves the performance of the designed neural network and significantly reduces search time for large datasets.},
  archive      = {J_ESWA},
  author       = {Jiahao Fan and Shuchao Deng and Xiaotian Song and Jiyuan Liu and Yanan Sun},
  doi          = {10.1016/j.eswa.2025.129130},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129130},
  shortjournal = {Expert Syst. Appl.},
  title        = {A gradient-based lightweight network automated design method for facial expression recognition},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel cloud model and consensus-based success likelihood index method for human reliability analysis in air refueling operations. <em>ESWA</em>, <em>296</em>, 129129. (<a href='https://doi.org/10.1016/j.eswa.2025.129129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human reliability analysis (HRA) plays a critical role in ensuring safety and operational effectiveness in high-risk operations like air refueling. This paper presents a novel success likelihood index method (SLIM) that integrates the cloud model, water-filling theory, and full consistency method (FUCOM) to estimate human error probability (HEP) while addressing inconsistent expert assessments and unknown performance shaping factor (PSF) weights in HRA. The cloud model is used to handle uncertainty in subjective expert evaluations, followed by a consensus-reaching approach to harmonize expert opinions. Additionally, the combination of water-filling theory and FUCOM offers a balanced method for determining PSF weights by incorporating both objective data and expert judgment. The proposed SLIM framework is applied to a real-world air refueling operation case study, where tasks like pre-contact stabilization and turbulence adjustment are identified as highly error-prone, suggesting areas for targeted intervention. The proposed method not only provides robust HEP estimates under uncertainty but also advances HRA methodologies by addressing critical challenges in expert consensus and PSF weighting.},
  archive      = {J_ESWA},
  author       = {Fei Gao},
  doi          = {10.1016/j.eswa.2025.129129},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129129},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel cloud model and consensus-based success likelihood index method for human reliability analysis in air refueling operations},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic double mutation whale differential algorithms and applications to multi-constrained global optimization engineering problems. <em>ESWA</em>, <em>296</em>, 129128. (<a href='https://doi.org/10.1016/j.eswa.2025.129128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address multi-constrained global optimization problems in engineering applications, a dynamic double mutation whale differential optimization algorithm is proposed. A dynamic probability strategy and a double Lévy mutation mechanism (DLM) are incorporated into a whale optimization algorithm combined with differential evolution (WOADE). Firstly, The Logistic-Tent chaotic map initializes whale populations, enhancing randomness and ergodicity to generate diversified solutions. Secondly, to balance the global search ability of whales’ random search and the local search ability of whales’ bubble-net attack, a dynamic probability strategy is proposed. Finally, an intergenerational cooperative evolutionary strategy is proposed that guides the population toward optimal regions while preserving solution diversity, thereby enhancing convergence speed and global search performance. Extensive experiments were conducted using the CEC2017 and CEC2022 test functions to evaluate the performance of the dynamic double Lévy mutation whale optimization differential evolution (DLMWOADE) algorithm against other typical intelligence optimization algorithms. The results show that DLMWOADE compared to WOA and other typical algorithms provided high accuracy and faster convergence. Furthermore, DLMWOADE was successfully applied to four real-world engineering optimization problems, demonstrating its competitiveness for solving multi-constrained optimization challenges.},
  archive      = {J_ESWA},
  author       = {Ruizi Ma and Kailun Fu and Tianhong Yan},
  doi          = {10.1016/j.eswa.2025.129128},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129128},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic double mutation whale differential algorithms and applications to multi-constrained global optimization engineering problems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Breakthrough in fine-grained video anomaly detection on highway: New benchmark and model. <em>ESWA</em>, <em>296</em>, 129127. (<a href='https://doi.org/10.1016/j.eswa.2025.129127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of anomalies is critical for surveillance video analysis, especially for highway videos. In contrast to traditional coarse-grained methods, which only focus on identifying abnormal video clips, fine-grained detection more effectively meets practical demands. Because it can further classify the specific anomaly types which helps monitoring systems issue targeted alerts. Nevertheless, existing research often overlooks the semantic information in video descriptions, which is essential for capturing the fine contextual relationship between anomalies. Therefore, it is extremely necessary to explore how to utilize the description information to enhance fine-grained video anomaly detection. To achieve this, we construct the first Highway Anomaly Dataset (HAD) containing video descriptions and propose a novel multi-modal training paradigm called Dual-Classification with Dual-Text (DCDT). It integrates coarse-grained binary classification and fine-grained multi-class classification tasks, involving both description text and label text. In DCDT, we leverage video-description alignment to increase the intra-class similarity for normal events and inter-class differences among anomalies, while adopting video-label alignment to distinguish between normal and various types of anomalies. Experimental results demonstrate that DCDT achieves superior performance on our proposed HAD benchmark, as well as on the widely-used UCF-Crime and XD-Violence datasets. Furthermore, the HAD dataset provides an innovative platform for research in video analysis and multi-modal learning.},
  archive      = {J_ESWA},
  author       = {Chenlin Meng and Xin Wang and Chi Zhang and Zhaoyong Mao and Junge Shen and Zhiyong Cheng},
  doi          = {10.1016/j.eswa.2025.129127},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129127},
  shortjournal = {Expert Syst. Appl.},
  title        = {Breakthrough in fine-grained video anomaly detection on highway: New benchmark and model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ASC-SRN: Adaptive sparse sampling convolution-based infrared super-resolution network. <em>ESWA</em>, <em>296</em>, 129126. (<a href='https://doi.org/10.1016/j.eswa.2025.129126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared image super-resolution (SR) presents unique challenges due to the non-uniform distribution of salient features and degradation patterns across different image regions. It is difficult to effectively capture these variations using traditional convolutional operations with fixed sampling grids. To address this issue, we propose ASC-SRN, a novel network based on Adaptive Sparse Sampling Convolution (ASC), specifically designed for infrared image super-resolution. The core component, ASC, introduces a correlation-driven sampling mechanism that dynamically selects spatially sparse but informative sampling points, enabling the network to better capture regional heterogeneity and suppress irrelevant background interference. To complement this local adaptability, we further propose a Global Information Interaction Module (GIIM), which leverages linear attention to establish long-range dependencies with reduced computational cost. These modules are integrated into a hierarchical residual learning framework that capures both local structural details and global contextual dependencies within a unified framework. Extensive experiments on multiple benchmark infrared datasets demonstrate that ASC-SRN consistently achieves high reconstruction accuracy and robustness, particularly in recovering fine textures and structural details under complex degradations.},
  archive      = {J_ESWA},
  author       = {Yichun Jiang and Yue Hou and Jinxin Guo and Weida Zhan and Depeng Zhu and Yu Chen},
  doi          = {10.1016/j.eswa.2025.129126},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129126},
  shortjournal = {Expert Syst. Appl.},
  title        = {ASC-SRN: Adaptive sparse sampling convolution-based infrared super-resolution network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards lightest low-light image enhancement architecture for mobile devices. <em>ESWA</em>, <em>296</em>, 129125. (<a href='https://doi.org/10.1016/j.eswa.2025.129125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time low-light image enhancement on mobile and embedded devices requires models that balance visual quality and computational efficiency. Existing deep learning methods often rely on large networks and labeled datasets, limiting their deployment on resource-constrained platforms. In this paper, we propose LiteIE, an ultra-lightweight unsupervised enhancement framework that eliminates dependence on large-scale supervision and generalizes well across diverse conditions. We design a backbone-agnostic feature extractor with only two convolutional layers to produce compact image features enhancement tensors. In addition, we develop a parameter-free Iterative Restoration Module, which reuses the extracted features to progressively recover fine details lost in earlier enhancement steps, without introducing any additional learnable parameters. We further propose an unsupervised training objective that integrates exposure control, edge-aware smoothness, and multi-scale color consistency losses. Experiments on the LOL dataset, LiteIE achieves 19.04 dB PSNR, surpassing SOTA by 1.4 dB while using only 0.07 % of its parameters. On a Snapdragon 8 Gen 3 mobile processor, LiteIE runs at 30 FPS for 4K images with just 58 parameters, enabling real-time deployment on edge devices. These results establish LiteIE as an efficient and practical solution for low-light enhancement on resource-limited platforms.},
  archive      = {J_ESWA},
  author       = {Guangrui Bai and Hailong Yan and Wenhai Liu and Yahui Deng and Erbao Dong},
  doi          = {10.1016/j.eswa.2025.129125},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129125},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards lightest low-light image enhancement architecture for mobile devices},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mask-guided ControlNet algorithm for local motion blur removal based on frequency-domain prompts. <em>ESWA</em>, <em>296</em>, 129124. (<a href='https://doi.org/10.1016/j.eswa.2025.129124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world photography, objects undergo motion during exposure, resulting in the blending of dynamic objects with static backgrounds. Traditional image deblurring methods primarily focus on global restoration, often compromising the sharpness of non-blurred regions and introducing unnecessary computational overhead. Current local motion blur algorithms exhibit insufficient accuracy in segmenting blurred regions. To address these limitations, this paper presents a novel local motion deblurring framework that utilizes a frequency-aware, prompt-based mask generation model to guide the deblurring process. The model fine-tunes the Segment Anything model (SAM) using frequency-domain information to generate accurate motion blur masks, which are then used as conditional inputs to the control network for targeted deblurring. By leveraging frequency-domain information to localize blurred regions, we use ControlNet to regenerate degraded areas, while the non-blurred regions remain unchanged. This targeted restoration improves visual consistency and computational efficiency. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art deblurring techniques in terms of perceptual quality and quantitative metrics. The proposed framework achieves effective local motion deblurring while preserving the integrity of non-blurred regions. We will release our code on Github .},
  archive      = {J_ESWA},
  author       = {Xing Wei and Xiufen Ye and Xinkui Mei and Junting Wang and Heming Ma},
  doi          = {10.1016/j.eswa.2025.129124},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129124},
  shortjournal = {Expert Syst. Appl.},
  title        = {A mask-guided ControlNet algorithm for local motion blur removal based on frequency-domain prompts},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EViT-net: An efficient vision transformer-inspired network for enhanced multi-scale remote sensing image features. <em>ESWA</em>, <em>296</em>, 129123. (<a href='https://doi.org/10.1016/j.eswa.2025.129123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in remote sensing images is a critical technology for ensuring urban and environmental safety. However, traditional deep learning methods often struggle with poor detection accuracy, high miss rates, and high deployment costs in complex scenes with multi-scale objects. To address these challenges, we propose EViT-Net, a lightweight network inspired by Vision Transformer (ViT). It significantly improves the efficiency of multi-scale feature processing. First, CA-RepViT is introduced as the backbone network to better extract global features and long-range dependencies. Second, the Generalized Spatial Pyramid Pooling Fast (GSPPF), C3G2, and Lightweight Space-to-Depth (LSPD) components are designed to enhance multi-scale feature fusion while reducing computational costs. Additionally, P2-BiFPN is constructed as the neck network, improving feature representation through comprehensive cross-layer information interaction. Finally, EDetect is developed to optimize the classification and localization capabilities of the detection head, further enhancing detection efficiency. Compared to YOLOv11, EViT-Net reduces the number of parameters and computational load by 56.3 % and 12.5 %, respectively. On the VisDrone2019 and AI-TOD datasets, EViT-Net improves mean Average Precision (mAP) by 1.8 % and 3.9 %, recall rate by 2.0 % and 5.4 %, and Frames Per Second (FPS) by 49.3 %. The model’s reliability and generalization capability are further validated on the SIMD dataset. Experimental results demonstrate that EViT-Net successfully achieves a balance between detection accuracy and computational efficiency, offering a novel approach for advancing remote sensing image analysis.},
  archive      = {J_ESWA},
  author       = {Yaoyao Du and Li Chen and Xingxing Hao},
  doi          = {10.1016/j.eswa.2025.129123},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129123},
  shortjournal = {Expert Syst. Appl.},
  title        = {EViT-net: An efficient vision transformer-inspired network for enhanced multi-scale remote sensing image features},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust deep learning model for underwater acoustic multi-target recognition under non-target interference conditions. <em>ESWA</em>, <em>296</em>, 129122. (<a href='https://doi.org/10.1016/j.eswa.2025.129122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing multiple underwater acoustic targets from mixed ship-radiated noise is challenging, particularly under non-target interference conditions, where complex interference from multiple vessels is common in real-world scenarios. However, most existing studies focus on single-target recognition and have overlooked the task of recognizing both the types and numbers of targets from such complex mixed signals. To simulate real and ideal situations, this paper first constructs three underwater acoustic multi-target datasets (MTDs) with different target-to-interference ratio (TIR) ranges based on the ShipsEar dataset. In addition, this study proposes two novel dataset resampling strategies that effectively improve the dataset balance level. Furthermore, this paper introduces a deep learning model based on ResNet and channel attention mechanism to perform underwater acoustic multi-target recognition (UAMTR) under non-target interference conditions. The channel attention mechanism is effective in filtering channel information within feature maps, amplifying informative features while reducing noise interference. Experimental results demonstrate that the channel attention module could improve global recognition accuracy by up to 4 percentage points. The proposed method achieves a global recognition accuracy of 91.21% on the MTD where the energy of each target and non-target signal is equal.},
  archive      = {J_ESWA},
  author       = {Lu Chen and Xinwei Luo and Hanlu Zhou and Qifan Shen and Long Chen and Chuanming Huan},
  doi          = {10.1016/j.eswa.2025.129122},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129122},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust deep learning model for underwater acoustic multi-target recognition under non-target interference conditions},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-aware unsupervised cross-domain adaptation for high-fidelity enhancement of underwater concrete crack imagery. <em>ESWA</em>, <em>296</em>, 129121. (<a href='https://doi.org/10.1016/j.eswa.2025.129121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection in underwater concrete structures relies heavily on optical imaging, where high-quality images are critical for accurate detection. However, due to optical absorption, scattering, and water turbidity, underwater crack images commonly suffer from color distortion, low contrast, and blurred textures, significantly affecting detection performance. To address these challenges, this paper proposes PG-UNIT (physics-guided unsupervised image-to-image translation), a framework for underwater crack image enhancement. A self-supervised pre-correction module, guided by an underwater optical model, adaptively estimates light attenuation parameters and performs initial corrections to reduce color cast and illumination imbalance, ensuring physically consistent inputs for downstream enhancement. The improved UNIT module integrates multi-scale convolution, selective kernel attention, and a hybrid multi-attention mechanism to enhance structural feature extraction and detail restoration. Furthermore, color consistency loss and underwater light reflection loss are introduced to improve visual realism and physical plausibility. Experimental results show that PG-UNIT outperforms state-of-the-art methods, achieving improvements of 48.2 %, 58.0 % and 70.0 % in BRISQUE, NIQE and PIQE, respectively. The proposed method demonstrates strong generalization and robustness under diverse illumination and turbidity conditions, providing reliable visual inputs for automated crack detection and quantification in underwater concrete structures.},
  archive      = {J_ESWA},
  author       = {Zhihua Wu and Airong Liu and Shuai Teng and Jiyang Fu and Bingcong Chen},
  doi          = {10.1016/j.eswa.2025.129121},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129121},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-aware unsupervised cross-domain adaptation for high-fidelity enhancement of underwater concrete crack imagery},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UCGM: Enhancing pseudo labels via uncertainty and cross-image gaussian mixture model for semi-supervised semantic segmentation. <em>ESWA</em>, <em>296</em>, 129120. (<a href='https://doi.org/10.1016/j.eswa.2025.129120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised semantic segmentation aims to leverage a large set of unlabeled images along with a limited number of labeled images to learn rich visual representations and achieve high-performance segmentation models. The key challenge in this task lies in obtaining high-quality pseudo labels to supervise the unlabeled images. Existing methods rely heavily on selecting pseudo labels form predictions with high confidence. However, due to confidence bias, these pseudo labels still contain errors. To address this issue, this paper proposes a pseudo label guiding refinement method for semi-supervised semantic segmentation using Uncertainty and Cross-Image Gaussian Mixture (UCGM). The motivation is inspired by the observation that high-incertitude pseudo labels are prone to be erroneous predictions and that features belonging to the same semantic category exhibit similar feature distributions. Specifically, we first construct the cross-image Gaussian mixture using both labeled and unlabeled images, leveraging the accurately supervised distribution of labeled features to refine the distribution of unlabeled features. This process allows the estimation of class-wise distributions predictions to refine pseudo labels. Furthermore, we assign uncertainty adaptive weights to initial pseudo labels to selectively retain more trustworthy ones for training, thereby mitigating the adverse impact of noises. Extensive experiments on the PASCAL VOC 2012 and Cityscapes datasets demonstrate that the proposed UCGM significantly enhances pseudo label quality and achieves state-of-the-art performance. The code is available at https://github.com/Wang-zhenyan/UCGM .},
  archive      = {J_ESWA},
  author       = {Zhenyan Wang and Zhenxue Chen and Chengyun Liu and Yaping Zhao and Jiazheng Wu and Mengyang Wang},
  doi          = {10.1016/j.eswa.2025.129120},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129120},
  shortjournal = {Expert Syst. Appl.},
  title        = {UCGM: Enhancing pseudo labels via uncertainty and cross-image gaussian mixture model for semi-supervised semantic segmentation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The new energy vehicles selection using complex T-spherical fuzzy cloud and an improved recognition model through group online reviews. <em>ESWA</em>, <em>296</em>, 129119. (<a href='https://doi.org/10.1016/j.eswa.2025.129119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of online reviews of the new energy vehicles from the e-commerce platforms not only support consumers to understand the advantages and disadvantages of vehicle-related attributes, but also provide an important reference for consumers’ purchase direction. In order to better provide consumers with the right choice of new energy vehicles through the online reviews from the e-commerce platforms, this paper proposes a complex T-spherical fuzzy cloud(CT-SFC) model based on the emotional value of online reviews and a review filtering mechanism related to this model to cope with these large number of online reviews. Firstly the internal emotional value of the online review and the competitiveness of the product in the time period of the review are used to construct the amplitude term and the phase term of the complex T-spherical fuzzy numbers. Secondly, considering the error in extracting emotional value, a new concept of complex T-spherical fuzzy cloud is defined and the relevant aggregation operator is also provided for the construction of subsequent decision model. Thirdly, based on the measurement definition of CT-SFC, the original consensus threshold calculation method is improved to deal with more complex environments and a filtering mechanism for online reviews is constructed to deal with inconsistent online reviews. Finally, we successfully apply the proposed model to the selection of new energy vehicles.},
  archive      = {J_ESWA},
  author       = {Yuanlong Su and Junjun Mao and Huayou Chen and Xiaodong Sun and Tao Wu},
  doi          = {10.1016/j.eswa.2025.129119},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129119},
  shortjournal = {Expert Syst. Appl.},
  title        = {The new energy vehicles selection using complex T-spherical fuzzy cloud and an improved recognition model through group online reviews},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Classified-RRT*: Node classification RRT*-based algorithm with improved solution performance and convergence rate. <em>ESWA</em>, <em>296</em>, 129118. (<a href='https://doi.org/10.1016/j.eswa.2025.129118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is essential for ensuring the safe and efficient operation of robots. Among various path planning algorithms, Rapidly-exploring Random Tree (RRT) stands out as a widely adopted sampling-based approach. While Optimal RRT (RRT*) provides asymptotic optimality, its suboptimal initial solutions and slow convergence rates hinder its practical applicability. Relevant studies have made notable contributions in areas such as sampling strategies and random tree extension. Nevertheless, current algorithms predominantly adhere to a traditional framework that uniformly processes new sampling nodes, leaving room for improvement in the efficiency of random tree expansion. To address these limitations, this study proposes Classified-RRT* (C-RRT*), an enhanced variant of RRT*. By classifying nodes based on their connectivity characteristics, customized procedures can be performed to improve the overall architecture and performance. To further optimize the random tree extension process, a single backtracking ChooseParent procedure and a sequential Rewire procedure are presented. Additionally, a random offset sampling method is introduced to improve the sampling distribution around obstacles. In large-obstacle and cluttered experimental environments, the proposed algorithm reduces the initial solution computation time by 53.15% and 63.08%, respectively, compared to the comparison algorithms. The path cost of optimal solution is decreased by 6.00% and 11.74%. Moreover, the computation time required to obtain a suboptimal solution (1.05 times the optimal solution) is reduced by 84.58% and 93.75%. These results demonstrate the effectiveness of proposed algorithm and its advantages in improving the solution performance and convergence rate.},
  archive      = {J_ESWA},
  author       = {Zhihua Xiong and Wenbin Hou and Changsheng Wang and Hao Chen},
  doi          = {10.1016/j.eswa.2025.129118},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129118},
  shortjournal = {Expert Syst. Appl.},
  title        = {Classified-RRT*: Node classification RRT*-based algorithm with improved solution performance and convergence rate},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event driven causal knowledge graphs for bottleneck root cause analysis in manufacturing systems. <em>ESWA</em>, <em>296</em>, 129117. (<a href='https://doi.org/10.1016/j.eswa.2025.129117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manufacturing systems, bottlenecks act as constraints that limit throughput and slow down the overall production process. While bottleneck detection is well-studied, clarifying their overlapping causes and propagation paths remains a significant challenge. Therefore, this paper introduces a causal knowledge graph of the bottleneck method (BCKG), combined with an event-driven approach, to identify root causes and determine propagation paths to bottlenecks. Firstly, an initial causal knowledge graph models dependencies and relationships by representing events related to the station as features and nodes. The graph captures how these events causally impact each other based on their process interactions. Next, a data-driven approach employs the overlapping duration of different events to filter out irrelevant relationships between features. Finally, a reverse depth-first search algorithm identifies potential causes and propagation paths, with the root cause determined using a modified PageRank algorithm based on ranking scores. Compared to several state-of-the-art benchmarks, the proposed method achieves an F-score of 94.46 %, indicating superior performance.},
  archive      = {J_ESWA},
  author       = {Weihong Cen and Chupeng Su and Gang Chen and Longhan Xie},
  doi          = {10.1016/j.eswa.2025.129117},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129117},
  shortjournal = {Expert Syst. Appl.},
  title        = {Event driven causal knowledge graphs for bottleneck root cause analysis in manufacturing systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive hypergraph and weighted classifier guided spectral learning for multi-label classification. <em>ESWA</em>, <em>296</em>, 129116. (<a href='https://doi.org/10.1016/j.eswa.2025.129116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting label correlations is an effective and widespread practice in solving Multi-Label Classification (MLC) problems. Owing to the ability to model high-order relations, hypergraphs have been successfully employed in MLC tasks to capture complex dependencies using spectral learning methods. Yet, some challenges in incorporating hypergraphs into solving MLC problems have not been tackled. First, not every correlation helps to improve the classification performance. A hypergraph is fixed once generated and has no supervision from classification results for its construction. Second, the class imbalance in hypergraph-based modeling will amplify the influence of class imbalance in the original task. To deal with these issues, we propose a novel framework named Adaptive Hypergraph and Weighted classifier guided Spectral Learning for multi-label classification (AHWSL) in this paper. Specifically, AHWSL adopts a hybrid hyperedge creation method and adaptively selects the scheme by which each label is involved in hyperedge creation. Meanwhile, adaptive weights are assigned to hyperedges for the between-class imbalance in spectral learning and examples for the one-vs-rest imbalance in classifier training. Comparative experiments on 20 benchmark datasets indicate that AHWSL is a competitive approach among nine state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Zeyu Teng and Min Huang and Peng Cao and Shanshan Tang and Xingwei Wang},
  doi          = {10.1016/j.eswa.2025.129116},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129116},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive hypergraph and weighted classifier guided spectral learning for multi-label classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning based face shape classification system with binary feature selection model. <em>ESWA</em>, <em>296</em>, 129115. (<a href='https://doi.org/10.1016/j.eswa.2025.129115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fast adaptive threshold based adaptive bilateral filter is used to process scarcities and denoise images during the pre-processing stage. Dlib’s 68-point face landmark detector is used to extract the most crucial features necessary for predicting face shapes, including distance, ratio, and angle. The chosen images are used to calculate three angles, ten ratios, and seven face distances. The ideal features are chosen using a binary emperor penguin (BEPO) optimization model with the accuracy objective function. The optimized deep gated recurrent convolutional networks (HoBDe-GCN) are used in the classification stage. To minimize the loss function and update the weight function, a bionic model known as the honey badger (HBA) is employed. The results are compared to state-of-the-art methods using variables such as accuracy, precision, F1-score, specificity, sensitivity, and also the kappa coefficient, Matthews correlation coefficient (MCC), and True positive rate (TPR). The performances were analyzed using two different datasets, face shape and men’s face dataset. The proposed model has an accuracy of 99.61485%, f1-score of 99.0162%, 98.7% of specificity, 98.99% of sensitivity, and a precision of 99.50758% for the face shape dataset. For the men face dataset, the proposed model can attain an accuracy of 99.6798%, precision of 98.9125%, f1-score of 99.46962, and sensitivity of 99.57521%. The proposed model archived the best values than other existing models.},
  archive      = {J_ESWA},
  author       = {Srinivas Adapa and Vamsidhar Enireddy},
  doi          = {10.1016/j.eswa.2025.129115},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129115},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep learning based face shape classification system with binary feature selection model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ERI-query graph miner: An algorithm to detect edge relaxed induced query graph in large dynamic communication networks. <em>ESWA</em>, <em>296</em>, 129114. (<a href='https://doi.org/10.1016/j.eswa.2025.129114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Query graph search is a technique used in information retrieval to access relevant information from large and complex databases or knowledge graphs. It involves representing the query as a graph and searching for matches within the database graph. Edge-relaxed query graph search is a variant of graph search algorithms that relaxes the constraints on edges during the search process. It offers a more flexible, adaptable, and efficient approach to exploring and analyzing graphs, and it is a valuable technique in various domains, including network analysis, information retrieval, and data mining. The proposed algorithm gives an efficient bitcode representation-based idea to detect edge relaxed induced subgraphs of the query graph in a large communication network. The search space of the problem is efficiently reduced with the help of bitcode representation concept. Searching induced subgraph can help to understand the organization, relationships, and functional patterns in complex systems such as social networks, biological networks, or transportation networks. Identifying induced subgraphs is an essential step in subgraph mining, which aims to discover interesting or frequent patterns in graph database. Communication networks based graph database has been used to illustrate the proposed algorithm. The experimental analysis ensures the efficiency of the proposed work. The proposed algorithm introduces a novel approach to subgraph matching by identifying Edge Relaxed Induced Query Graphs in large dynamic communication networks. Unlike existing methods that either focus solely on exact subgraph isomorphism or allow relaxation without preserving induced subgraph properties, this algorithm uniquely combines vertex-induced structural matching with controlled edge relaxation. This hybrid capability allows for flexible and meaningful pattern discovery even in noisy or incomplete graph data, where strict induced matching would otherwise fail. The algorithm’s ability to maintain structural integrity while tolerating minor edge variations makes it particularly well-suited for real-world, evolving network scenarios.},
  archive      = {J_ESWA},
  author       = {Nirmala Parisutham and Nadarajan Rethnasamy},
  doi          = {10.1016/j.eswa.2025.129114},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129114},
  shortjournal = {Expert Syst. Appl.},
  title        = {ERI-query graph miner: An algorithm to detect edge relaxed induced query graph in large dynamic communication networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Combining data-driven and model-driven methods to support digital-twin engineering design: A case study for the (Re)design optimization of a quadcopter. <em>ESWA</em>, <em>296</em>, 129113. (<a href='https://doi.org/10.1016/j.eswa.2025.129113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twins have emerged as one of the leading technologies in Industry 4.0. Their applications in manufacturing, agriculture, energy, and healthcare are gaining significant attention due to their diverse capabilities. Despite this growing interest, there is limited literature on applications of digital twins in engineering design and product optimization. To address this gap, this study aims to develop a digital twin framework for optimizing a specific component, using a case study of an Unmanned Aerial Vehicle (UAV) arm. The primary objective of this paper is to conceptualize and establish methodological steps to build a digital twin using diverse sources of data. In the process of developing the digital twin, different data-driven methods, such as neural network-based models, Dynamic Mode Decomposition (DMD), and Response Surface model (RSM), are evaluated based on different metrics. By using the developed digital twin, the study seeks to enhance the design for the UAV arm under varying working conditions. Results show how this digital twin enables design optimization, real-time monitoring, and performance optimization. Additionally, this study highlights the technical challenges and fundamental elements required to form a digital twin that assists in the engineering design process. Surrogate models are employed to mirror the physical behavior of a UAV arm within the simulation environment. A digital twin, designed with simulation data, is created to perform design optimization. This digital twin enables simulation-driven design and monitoring, aiming to optimize performance under varying conditions while reducing trial-and-error costs in engineering design and manufacturing. The findings confirm the effectiveness of the digital twin in optimizing designs.},
  archive      = {J_ESWA},
  author       = {Amirmohammad Daareyni and Aapo Ylä-Autio and Antti Martikkala and Hossein Mokhtarian and Iñigo Flores Ituarte},
  doi          = {10.1016/j.eswa.2025.129113},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129113},
  shortjournal = {Expert Syst. Appl.},
  title        = {Combining data-driven and model-driven methods to support digital-twin engineering design: A case study for the (Re)design optimization of a quadcopter},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel knowledge graph-based identification method for key quality characteristics of complex products. <em>ESWA</em>, <em>296</em>, 129112. (<a href='https://doi.org/10.1016/j.eswa.2025.129112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the manufacturing of complex products, companies have to set up numerous quality control points, leading to a surge in production costs. Therefore, identifying key quality characteristics (KQChs) that significantly impact product quality is crucial for enhancing the efficiency and depth of quality assurance. Traditional data management and information technology fall short in meeting the demands for precise control and intelligent data application. Quality data is vast and discrete, with intricate associations among quality characteristics (QChs), making it hard to clearly depict their formation process. Hence, we propose a knowledge graph-based method for identifying KQChs of complex products. Firstly, a quality characteristics ontology model (QChsOM) is established based on six correlations among QChs. Secondly, using quality texts as a corpus, a quality characteristics knowledge graph (QChsG) is constructed through named entity recognition and relation extraction considering various text structures. Thirdly, we design a weighted PageRank algorithm based on Jaccard similarity and node strength, considering node influence factors, wandering biases, and chain-in/out node strengths to efficiently measure important nodes. Based on the Pareto principle, critical nodes in the QChsG are identified as KQChs corresponding to their respective stages. Finally, the applicability of the proposed method is validated using the Reactor Pressure Vessel as an example. The results show that our method significantly outperform existing method in terms of identification performance and interpretability for identifying KQChs of complex products.},
  archive      = {J_ESWA},
  author       = {Peihan Wen and Tian Zhang and Yaping Hu and Lizhu Tao},
  doi          = {10.1016/j.eswa.2025.129112},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129112},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel knowledge graph-based identification method for key quality characteristics of complex products},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revolutionizing corruption dynamics: Integrating jury influence and fractional approaches with neural network and optimal control. <em>ESWA</em>, <em>296</em>, 129111. (<a href='https://doi.org/10.1016/j.eswa.2025.129111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corruption, a global problem, has a harmful effect that includes the deprivation of citizen rights, degradation of community faith in government institutions, disturbance of peace and security, misallocation of resources, and termination of employment chances. Although there have been numerous and varied attempts to address corruption, its enduring presence continues to pose a significant challenge in multiple countries. This research paper studies a compartmental mathematical model, that aims to clarify the dynamics of corruption transmission. The classification of population segments into five compartments is based on their intrinsic features, which enables monitoring the spread of corruption inside and across these segments. The reproduction number is calculated using advanced methodology to measure the potential for transmission. The stability of the model is examined, exhibiting both local and global asymptotic stability at the equilibrium point without corruption, as well as at the equilibrium point during the endemic state, based on the primary reproduction number. This approach is enhanced by utilizing neural networks to model and verify the intricate relationships associated with corruption dynamics. Moreover, the outcomes are verified by neural networks and tested with those obtained for the Atangana-Baleanu fractional model. Additionally, graphical illustrations are provided to depict the influence of the embedded parameters. Furthermore, the model is extended to investigate optimal control ways. Numerical simulations verify theoretical studies carried out with and without optimal control.},
  archive      = {J_ESWA},
  author       = {Aamir Farooq and Kamil Shah and Mohamed Anass El Yamani and Usman khan and Jamal Shah and Wen-Xiu Ma},
  doi          = {10.1016/j.eswa.2025.129111},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129111},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revolutionizing corruption dynamics: Integrating jury influence and fractional approaches with neural network and optimal control},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Breaking TSP local search barriers: Scalable multi-GPU parallelisation of 4-opt, 5-opt, 6-opt and hybrid variable λ-opt. <em>ESWA</em>, <em>296</em>, 129110. (<a href='https://doi.org/10.1016/j.eswa.2025.129110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 2-opt, 3-opt, 4-opt, 5-opt, and 6-opt are classical k -opt local search algorithms for the travelling salesman problem (TSP) in combinatorial optimisation. However, these algorithms exhibit two limitations. Firstly, serial execution of these algorithms results in polynomial time complexity, which imposes significant computational burdens for large-scale TSP instances. Secondly, k needs to be specified in advance. To address the first limitation, some researchers have exploited GPU parallelisation to develop GPU-parallel 2-opt and 3-opt algorithms. For the second limitation, some researchers have proposed variable λ -opt algorithms. Notably, the extant literature exhibits a paucity of research concerning the GPU-accelerated computation of 4-opt, 5-opt, 6-opt, and variable λ -opt methodologies. This paper presents parallel implementations of complete 4-opt, 5-opt, 6-opt, and variable λ -opt ( λ = 2 , 3 , 4 , 5 , 6 ) search algorithms, which are designed for execution across multiple GPUs. These parallel implementations adhere to data-parallel and support seamless deployment across an arbitrary number of GPUs. Additionally, this paper presents a serial algorithm that executes multiple variable λ -opt moves on the same TSP tour. The source code is publicly available, and evaluations of these GPU-parallel k-opt algorithms were conducted on standard TSP benchmark instances without incorporating nearest-neighbour information. Experimental tests on 12 TSP instances show that the proposed method exhibits the shortest computational time per iteration during complete 4-opt, 5-opt, 6-opt and variable λ -opt search applied to a global TSP tour while refining a near-optimal solution. For example, the single-GPU-parallel implementation of the complete 4-opt search runs over 1280 times faster than its serial counterpart (135.1 s vs > 48 h) for mu1979.tsp. This exceptional speedup leads to the fastest implementation method for optimising a brute-force TSP tour through variable complete λ -opt search applied to the global tour. For example, the single-GPU-parallel increasing variable λ -optimal ( λ = 2 , 3 , 4 ) method runs more than 58 times faster than its serial version (0.8312 h vs > 48 h). Moreover, given a sufficient number of GPUs, further computational acceleration can be achieved, enabling the determination of 5-optimal and 6-optimal TSP tours within acceptable timeframes.},
  archive      = {J_ESWA},
  author       = {Wen-Bao Qiao and Jean-Charles Créput and Nan Wang and Kun Meng and Abdelkhalek Mansouri},
  doi          = {10.1016/j.eswa.2025.129110},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129110},
  shortjournal = {Expert Syst. Appl.},
  title        = {Breaking TSP local search barriers: Scalable multi-GPU parallelisation of 4-opt, 5-opt, 6-opt and hybrid variable λ-opt},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). INN-based dual-generator adversarial contrastive learning network for multi-modal multi-label emotion recognition. <em>ESWA</em>, <em>296</em>, 129109. (<a href='https://doi.org/10.1016/j.eswa.2025.129109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal multi-label emotion recognition has become a prominent research area. However, the limitation of the current research is that the common and private feature encoders are deficient in modeling complex data distributions and solving data loss problems. Furthermore, the varying contributions of individual modalities to emotion recognition are frequently neglected. When contrastive learning is applied to multi-modal multi-label emotion recognition, the noise-positive samples will interfere with the model learning direction. To deal with these issues, we propose an INN-Based Dual-Generator Adversarial Contrastive Learning Network for Multi-modal Multi-label Emotion Recognition. Firstly, a dual-generator adversarial network based on the simple transformer and invertible neural networks is constructed. It enhances the model’s ability to capture the features of complex data distributions while avoiding loss of information. Secondly, a BERT-like adaptive weighted cross-modality attention fusion method is proposed, which computes attention weights and adds one softmax for each modality. Moreover, discrete multi-label weighted contrastive loss is established by computing label similarity metrics as contrastive weights to mitigate the impact of noisy samples. Extensive experiments conducted on the MOSEI and M 3 ED datasets demonstrate the effectiveness and superiority of our approach.},
  archive      = {J_ESWA},
  author       = {Fang’ai Liu and Yujuan Zhang and Xuqiang Zhuang and Xuejian Gao and Xiaohui Tian},
  doi          = {10.1016/j.eswa.2025.129109},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129109},
  shortjournal = {Expert Syst. Appl.},
  title        = {INN-based dual-generator adversarial contrastive learning network for multi-modal multi-label emotion recognition},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven IoT recommender system for enhancing energy efficient management in smart houses. <em>ESWA</em>, <em>296</em>, 129108. (<a href='https://doi.org/10.1016/j.eswa.2025.129108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the integration of solar power systems has seen substantial growth within smart houses. However, the inherent intermittency of solar irradiance introduces fluctuations in the available solar power, presenting a challenge for stable energy management. Developing and implementing precise recommendation systems based on solar power, energy market price, and weather forecasting methods become imperative in strategic planning and seamless energy management systems to address this issue effectively. This paper presents the A rtificial In T elligence-driven I oT RE comme NDE r E nergy System (ATIRENDEE) designed to enhance energy management in smart houses. Leveraging deep learning algorithms, a novel stacked ensemble model is developed to optimize energy consumption. Our results support the ATIRENDEE approach’s significant reduction in energy costs for smart homes, achieving an average monthly savings of over 45 % and reaching up to 68 % in specific cases. The multi-layered recommendation approach used enhances the efficiency and adaptability of the ATIRENDEE solution. By dynamically optimizing energy allocation among solar, battery, and grid sources, ATIRENDEE consistently outperformed static grid-based approaches, promoting cost-effective and sustainable energy use in eco-friendly smart houses or buildings.},
  archive      = {J_ESWA},
  author       = {Tiago Rodrigues and Joana Morgado and Márcia Barros and Alan Oliveira De Sá and José Cecílio},
  doi          = {10.1016/j.eswa.2025.129108},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129108},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven IoT recommender system for enhancing energy efficient management in smart houses},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). M2Metaphor: Leveraging multi-modal fusion and hierarchical contrastive learning for metaphoric insights. <em>ESWA</em>, <em>296</em>, 129107. (<a href='https://doi.org/10.1016/j.eswa.2025.129107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of social media platforms, people increasingly resort to combining images and texts to convey complex emotions and thoughts, where the use of metaphors is particularly common. These multi-modal expressions often contain profound, indirect messages, requiring a more deep-going level of understanding from the receiver. To address this challenge, we develop an advanced multi-modal fusion model focused on the identification and understanding of metaphors. Distinct from traditional uni-modal analyses, our model is dedicated to exploring and analyzing the interplay between images and texts, especially in the source and target domains of metaphors. Through this approach, we can more accurately capture and compare features across modalities, unveiling hidden meanings. Additionally, the model employs a strategy of hierarchical contrastive learning, enhancing the depth of understanding and analysis of multi-modal data. Through extensive experiments, it has been demonstrated that our model is effective in metaphor recognition and understanding in multi-modal contexts, showing significant improvements in the field of metaphor interpretation and providing a more comprehensive and accurate analysis of multi-modal metaphors.},
  archive      = {J_ESWA},
  author       = {Jingjie Zeng and Liang Yang and Ruiyang Jin and Yuanyuan Sun and Tiejun Xing and Hongfei Lin},
  doi          = {10.1016/j.eswa.2025.129107},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129107},
  shortjournal = {Expert Syst. Appl.},
  title        = {M2Metaphor: Leveraging multi-modal fusion and hierarchical contrastive learning for metaphoric insights},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved lightweight residual network model deployed on the edge device for the unsupervised cross-domain fault diagnosis. <em>ESWA</em>, <em>296</em>, 129106. (<a href='https://doi.org/10.1016/j.eswa.2025.129106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cross-domain fault diagnosis, samples usually lack labels because of different working conditions. Therefore, unsupervised deep transfer learning is more suitable than deep learning to tackle it. Moreover, deploying these methods on edge devices can reduce diagnostic latency. Thus, diagnostic methods of unsupervised deep transfer learning deployed on edge devices deserve attention from researchers. Due to high computational costs, reducing unnecessary model complexity while maintaining competitive performance for edge computing is a critical issue. To address the issue, this paper proposes an unsupervised transfer learning model based on an improved lightweight residual network, which achieves higher accuracy than complex models while significantly reducing parameters size, making it suitable for edge deployment. First, an improved lightweight residual network is proposed, which incorporates two novel types of residual blocks that utilize depthwise separable convolution and group normalization. Then, a new feature extraction network is introduced by combining the improved lightweight residual network with the Spatial and Channel Reconstruction Convolution (SCConv) module. Based on the proposed feature extraction network, an unsupervised cross-domain fault diagnosis model is constructed, incorporating Joint Maximum Mean Discrepancy (JMMD) and adversarial network loss for domain adaptation. Furthermore, two bearing datasets are utilized to validate the effectiveness of the proposed method and the improved model is deployed on an edge device to demonstrate its feasibility in practical applications. Experimental results show that the proposed method achieves higher accuracy than traditional complex models while maintaining fewer parameters and high computational efficiency, making it a practical solution for edge-based fault diagnosis.},
  archive      = {J_ESWA},
  author       = {Changbo He and Qi Meng and Xuefang Xu and Peng Chen and Pengfei Liang and Jiahui Cao},
  doi          = {10.1016/j.eswa.2025.129106},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129106},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved lightweight residual network model deployed on the edge device for the unsupervised cross-domain fault diagnosis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing thyroid nodule segmentation in thermal imaging with temporal sequences and advanced deep learning backbones. <em>ESWA</em>, <em>296</em>, 129105. (<a href='https://doi.org/10.1016/j.eswa.2025.129105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates methods to improve the segmentation of thyroid nodules in thermal imaging using deep learning models, with a focus on enhancing the Dice coefficient, a critical metric for model performance. We explore the integration of sequential image data through Long Short-Term Memory (LSTM) networks, hypothesizing that leveraging temporal features can significantly improve segmentation accuracy. Four novel deep learning models—U-Net with VGG16_A, VGG16_B, VGG19, and MobileNet backbones—were developed and evaluated. The research consisted of four studies: (1) analyzing the impact of sequence length (5, 10, and 20 images), which demonstrated a meaningful Dice improvement from 31.5 % to 36.6 % with longer sequences; (2) comparing feature-engineered versus raw data, revealing a tradeoff between sensitivity and precision; (3) assessing transfer learning approaches with VGG16 variants, where VGG16_B achieved a 4 % Dice improvement over VGG16_A; (4) exploring alternative backbones (VGG19 and MobileNet) without substantial performance gains; and (5) conducting ablation experiments across all models and compared single-frame and multi-frame LSTM inputs. Sensitivity analysis highlighted the importance of reducing false negatives for better segmentation accuracy. Despite GPU and dataset limitations, our results indicate that LSTM-based sequential models significantly enhance segmentation performance, offering potential advancements in early thyroid nodule diagnosis and management. Future work will focus on multi-input designs and external validation to ensure generalizability and clinical applicability.},
  archive      = {J_ESWA},
  author       = {Mehdi Etehadtavakol and Mahnaz Etehadtavakol and Eddie Y.K. Ng},
  doi          = {10.1016/j.eswa.2025.129105},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129105},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing thyroid nodule segmentation in thermal imaging with temporal sequences and advanced deep learning backbones},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inferring anti-viral drugs using nonnegative matrix factorization with self-paced learning and hypergraph regularization. <em>ESWA</em>, <em>296</em>, 129104. (<a href='https://doi.org/10.1016/j.eswa.2025.129104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viruses pose significant threats to global health, and the development of effective antiviral therapies is challenging because of the high costs and long timelines associated with drug development. Drug repurposing has emerged as a promising approach to accelerate treatment discovery. In this study, we introduce a novel framework for predicting virus–drug associations, termed Preprocessing–enhanced Self-Paced Learning and HyperGraph regularized Nonnegative Matrix Factorization (Pre–SPLHGNMF). The model integrates linear neighborhood similarity to enhance similarity fusion, and Gaussian processes to reduce the impact of false negatives. It employs hypergraph regularization to capture higher-order relationships in virus–drug, virus–virus, and drug–drug associations, improving the model’s ability to make reliable predictions. Self-paced learning further optimizes the model by iteratively introducing samples from simple to complex, thus enhancing robustness against noisy data, ensuring more accurate association predictions. The experimental results show that Pre-SPLHGNMF outperforms the other methods in 10-fold cross-validation, achieving AUCs of 0.8526 and 0.8629 on the HDVD and VDA datasets, respectively. These findings highlight the potential of Pre-SPLHGNMF to advance virus–drug association prediction and support the development of effective antiviral strategies.},
  archive      = {J_ESWA},
  author       = {Yong Tang and Zhongming Xie and Yuhan Fan and Kaiyang Zhong and Muhammet Deveci},
  doi          = {10.1016/j.eswa.2025.129104},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129104},
  shortjournal = {Expert Syst. Appl.},
  title        = {Inferring anti-viral drugs using nonnegative matrix factorization with self-paced learning and hypergraph regularization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM powered spatial enrichment of message sequence charts and its applications. <em>ESWA</em>, <em>296</em>, 129103. (<a href='https://doi.org/10.1016/j.eswa.2025.129103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Message Sequence Chart (MSC) is a visually comprehensible knowledge representation used for showing events of a narrative in their correct temporal order. However, to enable its use as a spatio-temporal knowledge representation, it needs to be enhanced with spatial knowledge present in the narrative. In this work, we aim at enriching MSCs with spatial knowledge about locations of the involved entities, using MSC’s condition construct , to enable them for downstream spatio-temporal applications. We propose two Large Language Model (LLM) based approaches for MSC construction, one based on few-shot in-context learning and another involving fine-tuning. Further, we propose a new task of motion reasoning, where an entity’s location is reasoned based on the last event it was part of and whether the event involved any motion causing change of the entity’s location. Similar as earlier, we develop a few-shot in-context learning approach and an LLM fine-tuning approach to solve the motion reasoning task and enable the spatial enrichment of the constructed MSCs. We report performance of the proposed approaches and also demonstrate the utility of the enrichment in two applications on image-based visualization and narrative gap finding.},
  archive      = {J_ESWA},
  author       = {Nitin Ramrakhiyani and Sachin Pawar and Girish Palshikar and Vasudeva Varma},
  doi          = {10.1016/j.eswa.2025.129103},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129103},
  shortjournal = {Expert Syst. Appl.},
  title        = {LLM powered spatial enrichment of message sequence charts and its applications},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Low-rank and synergy prompts for efficient multimodal glioma segmentation with missing modalities. <em>ESWA</em>, <em>296</em>, 129102. (<a href='https://doi.org/10.1016/j.eswa.2025.129102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors, particularly gliomas, pose significant challenges in neuroimaging due to their aggressive nature and diverse histological features. Accurate segmentation of gliomas is essential for effective diagnosis, treatment planning, and monitoring therapeutic responses. This paper addresses the limitations of multimodal imaging, which integrates various MRI sequences but often faces issues such as incomplete data due to patient movement or technical failures. However, in multimodal imaging which integrates various MRI sequences, incomplete imaging data often occur due to patient movement or technical failures, which can adversely affect segmentation algorithms. To address these issues, we propose a novel prompt learning framework designed for brain tumor segmentation in scenarios with missing modalities. Specifically, we introduce two types of prompts: a low-rank modality-specific prompt for intra-modal information enhancement and a synergy prompt for improved inter-modal communication. This combined prompting strategy effectively leverages available information to improve segmentation performance. Our approach not only facilitates the learning of complementary information in the presence of missing data but also demonstrates superior performance compared to state-of-the-art methods. Extensive experiments on the BraTS 2018 and BraTS 2020 datasets validate the effectiveness and efficiency of our method, with ablation studies providing further insights into its capabilities. Our contributions include an innovative prompt framework that significantly advances the field of brain tumor segmentation under challenging imaging conditions.},
  archive      = {J_ESWA},
  author       = {Yuzhe Li and Jiayi Yin and Jie Zhang and Bo Lin and Jie Sun},
  doi          = {10.1016/j.eswa.2025.129102},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129102},
  shortjournal = {Expert Syst. Appl.},
  title        = {Low-rank and synergy prompts for efficient multimodal glioma segmentation with missing modalities},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Latent-space adversarial training with post-aware calibration for defending large language models against jailbreak attacks. <em>ESWA</em>, <em>296</em>, 129101. (<a href='https://doi.org/10.1016/j.eswa.2025.129101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring safety alignment is a critical requirement for large language models (LLMs), particularly as they are increasingly deployed in real-world applications. Despite considerable advancements, LLMs remain vulnerable to jailbreak attacks that bypass safety measures and elicit harmful outputs. Adversarial training has shown potential as a defense but often leads to over-defense, where benign inputs are excessively refused, thereby compromising model usability. To tackle these dual challenges, we propose LATPC, a novel framework that integrates L atent-space A dversarial T raining with P ost-aware C alibration. LATPC selectively identifies safety-critical latent dimensions by contrasting harmful and benign queries, enabling mask-based refusal feature removal attacks followed by adversarial training. During inference, an efficient embedding-level calibration mechanism mitigates over-defense by aligning pseudo-harmful embeddings with their harmless counterparts. Experiments on representative jailbreak attack types show that LATPC achieves a superior balance between safety and utility compared to existing defense frameworks. Notably, it reduces attack success rate to 0 % on HumanJailbreaks and GPTFUZZER. Compared to the state-of-the-art adversarial training baseline, LATPC further reduces the over-refusal rate from 29.2 % to 26.2 %. Our code is publicly available at https://github.com/xinykou/Against_Jailbreak .},
  archive      = {J_ESWA},
  author       = {Xin Yi and Yue Li and Dongsheng Shi and Linlin Wang and Xiaoling Wang and Liang He},
  doi          = {10.1016/j.eswa.2025.129101},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129101},
  shortjournal = {Expert Syst. Appl.},
  title        = {Latent-space adversarial training with post-aware calibration for defending large language models against jailbreak attacks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical semantic alignment heterogeneous knowledge distillation model for smart agriculture crop leaf disease recognition. <em>ESWA</em>, <em>296</em>, 129100. (<a href='https://doi.org/10.1016/j.eswa.2025.129100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Focusing on the application requirements of automatic recognition of Crop Leaf Diseases (CLD) in smart agriculture, this study designs a novel Hierarchical Semantically Aligned Heterogeneous Knowledge Distillation (HSAH-KD) model, aiming to obtain a high-precision lightweight Convolutional Neural Network (CNN) that is more conducive to being deployed on Smart Agricultural Internet of Things (SAIoT) mobile terminals with limited storage and computing capabilities. Firstly, based on the CNN-Transformer dual-stream backbones, a Cross-Architecture Graph-Aware (CAGA) hybrid teacher network is designed, aiming to achieve cross-architecture and cross-level multi-scale feature fusion through graph structure interaction, thereby generating more discriminative feature representations. Then, we designed the Weight Sharing Dilated Partial Convolution (WSD-PConv) to construct a lightweight student network. Compared to standard convolutions, WSD-PConv not only has multi-scale perception ability, but also has lower computational complexity. Finally, a novel class affinity Wasserstein distance regularization KL (WDRKL) knowledge distillation function and a staircase multi-branch knowledge distillation strategy is designed, so the knowledge in the hybrid teacher network can be transferred to the pure CNN student network by a hierarchical manner, aiming to obtain a high-precision lightweight CNN for CLD recognition. Comparative experimental results based on three CLD datasets, i.e., Tomato-set, Strawberry-set, and Chilli-set, show that the student network after knowledge distillation achieves recognition accuracies of 97.95%, 97.14%, and 98.67%. In addition, to evaluate the model’s generalization ability in real-world agricultural scenarios, we constructed a cross-crop dataset, on which the model achieved an accuracy of 96.86%, and outperforms other state-of-the-art lightweight models, which can provide a very effective technical solution for the task of CLD recognition in SAIoT systems.},
  archive      = {J_ESWA},
  author       = {Daxiang Li and Jianing Sun and Ying Liu},
  doi          = {10.1016/j.eswa.2025.129100},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129100},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hierarchical semantic alignment heterogeneous knowledge distillation model for smart agriculture crop leaf disease recognition},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elective surgery scheduling with surgeon-patient classification and two-sided matching. <em>ESWA</em>, <em>296</em>, 129099. (<a href='https://doi.org/10.1016/j.eswa.2025.129099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating rooms (ORs) are key contributors to hospital revenue. Elective surgery within ORs can be scheduled in advance. Effective scheduling requires consideration of surgeons’ capabilities, as well as the characteristics and preferences of both surgeons and patients. This paper addresses an elective surgery scheduling problem that incorporates surgeon-patient classification and two-sided matching (CTM-ESS). First, we classify surgeons and patients: patient types are identified via feature data and machine learning, and surgeon types are provided by our partner hospital. Second, two-sided matching between surgeon and patient types is conducted on the basis of the classification. Third, we propose a data-driven optimization model that simultaneously minimizes the completion time for all patients (makespan) and the total overtime cost for all surgeons and ORs. Furthermore, an improved snake optimization algorithm (ISO) is developed to solve the multi-objective CTM-ESS problem. Finally, experimental studies validate the algorithm’s performance. The results demonstrate that the proposed scheduling scheme significantly reduces overtime costs, improves satisfaction among patients and surgeons, and enhances overall hospital efficiency.},
  archive      = {J_ESWA},
  author       = {Zhi Li and Shasha Guo and Xiantao Huang and Jun Xue and Hongjie Zhang and Guangxu Li},
  doi          = {10.1016/j.eswa.2025.129099},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129099},
  shortjournal = {Expert Syst. Appl.},
  title        = {Elective surgery scheduling with surgeon-patient classification and two-sided matching},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust optimization of bi-objective operating room scheduling considering anesthesiologist and patient satisfaction. <em>ESWA</em>, <em>296</em>, 129098. (<a href='https://doi.org/10.1016/j.eswa.2025.129098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating Room Scheduling (ORS) is a prominent topic in operations research, driven by its practical significance and scientific intricacies, and has garnered extensive attention in the literature. However, the critical role of anesthesiologists, an integral component of the ORS process, is frequently overlooked in existing studies. This study aims to address ORS from the dual perspective of balancing the satisfaction of both anesthesiologists and patients, quantified through anesthesiologists’ overtime and patients’ waiting time, respectively. We formulate a bi-objective β -robust optimization model that captures uncertainty in surgical durations and introduces significant nonlinear complexity. To solve this, we propose an Approximate Bi-objective Approach (ABA) based on the ϵ -constraint approach. Patient satisfaction is precisely optimized using an established branch-and-price algorithm, while an Approximate Branch-and-Bound (AB&B) algorithm is introduced to improve anesthesiologist satisfaction. This involves designing an approximate upper bounding scheme and implementing pruning strategies based on problem-specific properties to reduce the search space. Additionally, we incorporate a path relinking algorithm to generate high-quality initial solutions, effectively accelerating the solution process. We conduct a sensitivity analysis to evaluate ABA’s robustness and compare its solution front with that of the Non-dominated Sorting Genetic Algorithm II (NSGA-II) algorithm. Experimental results demonstrate that the ABA outperforms NSGA-II in comprehensive performance.},
  archive      = {J_ESWA},
  author       = {Debiao Li and Shan Chen and Yaling Wang and Zhe Wu and Chengbin Chu and Shixiang Zheng},
  doi          = {10.1016/j.eswa.2025.129098},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129098},
  shortjournal = {Expert Syst. Appl.},
  title        = {Robust optimization of bi-objective operating room scheduling considering anesthesiologist and patient satisfaction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating wavelet transform with deep learning for arctic sea ice concentration prediction. <em>ESWA</em>, <em>296</em>, 129097. (<a href='https://doi.org/10.1016/j.eswa.2025.129097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past several decades, the persistent decline in Arctic sea ice has heightened the need for accurate long-term forecasts to support urgent environmental protection and resource development efforts. While deep-learning-based models have shown promise for seasonal predictions, they often struggle to capture the intricate, multi-scale dynamics required for long-term sea ice concentration forecasting. In this study, we present WaveletNet, a novel deep learning framework that integrates wavelet transform to effectively decouple the complex spatiotemporal features of sea ice into the frequency and time domains. This decoupling enables the model to robustly capture long-term and multi-scale variations in sea ice dynamics. Our experimental results demonstrate that WaveletNet outperforms state-of-the-art dynamic and deep learning models, exhibiting superior reliabilityeven under extreme conditions. This work provides a promising new approach for advancing long-term sea ice forecasting using integrated wavelet-based deep learning techniques.},
  archive      = {J_ESWA},
  author       = {Mengjiao Qin and Yilin Zhu and Haoqi Gu},
  doi          = {10.1016/j.eswa.2025.129097},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129097},
  shortjournal = {Expert Syst. Appl.},
  title        = {Integrating wavelet transform with deep learning for arctic sea ice concentration prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling cybersecurity environment using lotka-volterra equations, and its stochastic analysis. <em>ESWA</em>, <em>296</em>, 129096. (<a href='https://doi.org/10.1016/j.eswa.2025.129096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional cybersecurity models often analyse vulnerabilities, cyberattacks, and security measures in isolation, neglecting their dynamic interdependencies and feedback mechanisms. Such approaches fail to capture emergent behaviours, struggle to model evolving threats in complex environments, and lack a holistic perspective, limiting their practical applicability. To address these shortcomings, this study introduces an ecological modelling framework using extended Lotka-Volterra (LV) equations, conceptualising vulnerabilities, attacks, and security hardening efforts as a three-component cyber-ecosystem. The approach integrates deterministic modelling of core interactions—such as growth, mitigation, and feedback mechanisms—with stochastic methods, including Stochastic Differential Equation (SDE), Agent-Based Modelling (ABM), and Monte Carlo Simulation (MCS), to address real-world uncertainties. Lyapunov stability analysis is employed to evaluate system resilience under perturbations. The framework extends classical predator–prey dynamics by incorporating security hardening as a regulatory mechanism interacting with both vulnerabilities and attacks. Simulations examine stability regimes across parameter configurations, while phase-space trajectories are analysed to identify behavioural patterns influenced by stochastic factors. Analytical methods assess critical thresholds in vulnerability growth rates and security deployment efficiency that govern equilibrium conditions. By adapting ecological principles to cybersecurity, this work highlights the challenges of managing interdependent system components. The analysis explores how coordinated mitigation strategies influence stability, with integrated deterministic-stochastic modelling offering a systems perspective on resilience. The model’s practical utility is exemplified through a hypothetical Smart Grid SCADA scenario, showcasing its ability to guide resource optimisation based on vulnerability and attack dynamics. This approach contributes a methodological framework for analysing cybersecurity ecosystems through quantitative stability metrics. It facilitates the evaluation of adaptive security architectures and resource allocation strategies, providing a robust bridge between theoretical modelling and practical cybersecurity challenges.},
  archive      = {J_ESWA},
  author       = {Sinan Atıcı and Gurkan Tuna},
  doi          = {10.1016/j.eswa.2025.129096},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129096},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modelling cybersecurity environment using lotka-volterra equations, and its stochastic analysis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interactive simulation on generalized large-scale scenarios with GNN. <em>ESWA</em>, <em>296</em>, 129095. (<a href='https://doi.org/10.1016/j.eswa.2025.129095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce computational resource consumption and reduce the requirements of large datasets for maintaining generalization, we propose a graph neural network (GNN) based interactive simulation framework for large-scale scenarios. First, we design a novel multi-level coarse-to-fine representation that compactly encodes the large-scale scenarios. Next, to approximate the mapping relationship between different levels, we introduce a trainable interpolation operator module. Finally, we develop a multi-level iterative network that propagates physical information coarse-to-fine, further lowering computational demands. We evaluate the proposed method on various scenarios with different scales. Experimental results show that our framework supports accurate interactive simulation in large-scale scenarios, reducing computational resource consumption by 27 % - 60 % and improving computational speed by 42 % − 61 % ( 143 − 187 FPS). Meanwhile, the collision metrics, RMSE, and R 2 results demonstrate that the proposed method achieves high interaction accuracy, simulation precision, and data-fitting quality. This approach demonstrates higher accuracy, enhanced generalization, faster runtime, and lower computational cost, making it applicable to interactive simulation in large-scale complex scenarios.},
  archive      = {J_ESWA},
  author       = {Xin Zhu and Xuanshuang Tang and Xiangyun Liao and Yinling Qian and Ziliang Feng and Qiong Wang},
  doi          = {10.1016/j.eswa.2025.129095},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129095},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interactive simulation on generalized large-scale scenarios with GNN},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EnCur: Curriculum-based in-context learning with structural encoding for code time complexity prediction. <em>ESWA</em>, <em>296</em>, 129094. (<a href='https://doi.org/10.1016/j.eswa.2025.129094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) demonstrate promising performance on numerous complex inference tasks such as domain-specific text classification, code generation, code translations, and math word problems (MWPs). Among these tasks, we explore the capabilities of LLMs in predicting time complexity of code snippets. This task requires the LLMs to comprehend and analyze both the context and structural properties such as loops and recursions of given code snippets deeply—a critical factor for accurate time complexity predictions. Unlike conventional state-of-the-art models fine-tuned for downstream tasks, which require large amounts of task-specific data and computational resources, we use In-Context Learning (ICL) approaches of LLMs to leverage their pre-trained knowledge. By utilizing various ICL prompts, including instruction-based, Chain-of-Thought (CoT), and Chain-of-Verification (CoVe) prompts, we avoid the limitations of fine-tuning, such as overfitting to specific tasks and the need for extensive retraining. To this end, we propose EnCur , a curriculum-like ICL strategy that incorporates with encoded structures of code snippets. Our strategy forms iterative prompts that accumulate the context of LLMs in a similar way that curriculum learning aims for. The empirical results and the analyses underscore the potential of LLMs, specifically GPT models, in accumulating knowledge, which then leads to better performance in code time complexity prediction. We provide empirical results of GPT-3.5, GPT-4o-mini, and GPT-4o, where EnCur enhances 3.0 % and 5.2 % in average performance over accuracy and F1 scores compared with baseline ICL techniques. Our implementation will be made publicly available at https://github.com/peer0/EnCur .},
  archive      = {J_ESWA},
  author       = {Joonghyuk Hahn and Aditi and Seung-Yeop Baik and Shinwoo Park and Sang-Ki Ko and Yo-Sub Han},
  doi          = {10.1016/j.eswa.2025.129094},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129094},
  shortjournal = {Expert Syst. Appl.},
  title        = {EnCur: Curriculum-based in-context learning with structural encoding for code time complexity prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The intelligent social event observer: Multi-source continuous event integration, discovery, and induction with LLMs. <em>ESWA</em>, <em>296</em>, 129093. (<a href='https://doi.org/10.1016/j.eswa.2025.129093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant redundant and fragmented data on social networks often hinders users from tracking the full development of events. Existing studies are weak in directly creating coherent narratives from incoming incremental data due to predefined event categories. To overcome these limitations, we propose the Intelligent S ocial E vent O bserver (SEO), a novel framework for integrating evolving events, detecting emerging events, and generating real-time event synopses on social networks. Specifically, SEO systematically transforms fragmented social data into structured event synopses through three stages. It begins with event integration using an adaptive window to adjust temporal coverage for the article stream collection dynamically. Then, during event detection, emerging events are identified by capturing the contextual relationship between incoming articles and historical events through a topic-driven attention mechanism. Afterward, SEO synthesizes coherent event synopses using an LLM-powered synopsis pool, where continuous updates core narratives by integrating emerging information. Finally, to rigorously evaluate the quality of incremental synopses, we construct 52k sample single-choice datasets for synopsis details and integrity assessment. Extensive experiments on two real-world datasets demonstrate that our method improves event classification accuracy and maintains factual consistency in generated synopses. Our code and data are publicly available at https://github.com/lambdarw/SEO .},
  archive      = {J_ESWA},
  author       = {Ruwen Zhang and Bo Liu and Jiuxin Cao and Hantao Zhao},
  doi          = {10.1016/j.eswa.2025.129093},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129093},
  shortjournal = {Expert Syst. Appl.},
  title        = {The intelligent social event observer: Multi-source continuous event integration, discovery, and induction with LLMs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SSRM: Efficient spectral reconstruction mamba with multiscale spectral-spatial correlation. <em>ESWA</em>, <em>296</em>, 129092. (<a href='https://doi.org/10.1016/j.eswa.2025.129092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral reconstruction is a data preprocessing step in spectral image applications that utilizes more economical 2D data to reconstruct 3D spectral information. Existing spectral reconstruction methods primarily focus on designing network architectures based on Convolutional Neural Networks (CNNs) and Transformers. However, CNN and Transformer-based methods still have notable shortcomings. Recently, the novel state-space model (Mamba) has attracted significant attention due to its nearly linear computational efficiency and exceptional performance. However, due to the limitations of its scanning algorithm, Mamba lacks the capability to effectively extract local and spectral features in spectral reconstruction tasks. In order to solve the existing problems, we propose an improved vision state-space model for the spectral reconstruction of RGB images. This model is a lightweight architecture with multiscale local feature extraction, global receptive fields, and linear computational complexity. It allows the model to focus on the correlations of spectral and spatial features of the image. We use dual-branch multiscale convolution as the shallow feature network of the model, and a U-shaped residual network composed of multiple improved state-space models forms the backbone. We improve the SS2D algorithm by optimizing the image scanning direction and introducing spectral-spatial correlation attention to guide the model’s reconstruction in spatial and spectral features. Our model shows a significant trade-off in accuracy-efficiency compared to SOTA in five evaluation metrics on three datasets (NTIRE2022, Harvard, CAVE), the MRAE was increased by 7.79 %, 1.55 % and 2.41 % respectively, while requiring only the minimal number of parameters and FLOPs, which is 0.607M and 28.67G.},
  archive      = {J_ESWA},
  author       = {Lina Yang and Zhiyuan Huang and Huafu Xu and Thomas Wu and Yifeng Tan and Yijun Chen and Yuanyan Tang},
  doi          = {10.1016/j.eswa.2025.129092},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129092},
  shortjournal = {Expert Syst. Appl.},
  title        = {SSRM: Efficient spectral reconstruction mamba with multiscale spectral-spatial correlation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MVim: A high-accuracy, lightweight neural network for real-time driver behavior recognition. <em>ESWA</em>, <em>296</em>, 129091. (<a href='https://doi.org/10.1016/j.eswa.2025.129091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver behavior is a crucial factor affecting road safety, and distracted actions often lead to frequent traffic accidents. To reduce such risks, deep learning models have been widely adopted for abnormal driving behavior detection. In real-world scenarios, these models are typically deployed on resource-constrained devices, where both high accuracy and real-time response are essential. Therefore, designing lightweight models with strong recognition performance is key to solving the problem of distracted driving. To address these challenges, we propose a lightweight neural network architecture named MVim, which aims to enhance both the accuracy and efficiency of driver behavior recognition. In this model, we design an Inverted Residual Attention Module (IRAM) to extract critical information while preserving fine-grained local features. In addition, we introduce the MobileVim module to fuse local details with global context, enabling the model to better understand the driving environment from visual data. MVim contains only 0.447 million parameters and achieves accuracy rates of 99.78 % on the State Farm Distracted Driver Detection dataset (SFD3) and 93.01 % on the American University in Cairo dataset (AUCv2), outperforming many current state-of-the-art methods. Moreover, we deployed MVim on an embedded device and achieved a processing speed of 56 frames per second, meeting the requirements for real-time monitoring in driver behavior recognition tasks.},
  archive      = {J_ESWA},
  author       = {Haibin Sun and Ning Feng},
  doi          = {10.1016/j.eswa.2025.129091},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129091},
  shortjournal = {Expert Syst. Appl.},
  title        = {MVim: A high-accuracy, lightweight neural network for real-time driver behavior recognition},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A noise-assistant network for tampering detection via inconspicuous feature enhancement and multi-perspective perception. <em>ESWA</em>, <em>296</em>, 129089. (<a href='https://doi.org/10.1016/j.eswa.2025.129089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to malicious tampering with digital images, neural networks are employed to detect tampering, thereby enhancing digital information security. The effectiveness of neural networks in tampering detection is profoundly influenced by the optimal utilization of fingerprint features within altered images. To enhance conspicuous noise remnants in forgery images, we propose a Noise-Assistant Network. The model acquires noise feature blocks in the feature extraction module containing FusionConv2D. The enhanced noise feature kernel is then employed to activate tampered feature representation in high-dimensional space. This activation takes place in both the feature enhancement module and the multi-perspective perception module, designed for the coarse and fine classification phases of tampering localization, respectively. Unlike introducing noise solely once within the neural network, our methodology involves introducing tampered noise information at distinct stages, achieving a cumulative enhancement effect. we create a synthetic tampering dataset, Syn-Pairs Dataset, containing positive and negative samples to amplify differences between tampered and non-tampered regions with similar semantic content. We use this dataset in the pre-training of the Noise-Assistant Network. Furthermore, the experiment using CASIA, COLUMBIA, NIST16, COVERAGE, DSO-1 and IMD databases yield outstanding results across various evaluation metrics, including AP series and F1. Notably, the A P 50 for DSO-1 reaches an impressive value of 0.867, indicating high performance in tampering detection.},
  archive      = {J_ESWA},
  author       = {Zhiyao Xie and Xiaochen Yuan and Chan-Tong Lam and Guoheng Huang and Nuno Lourenço},
  doi          = {10.1016/j.eswa.2025.129089},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129089},
  shortjournal = {Expert Syst. Appl.},
  title        = {A noise-assistant network for tampering detection via inconspicuous feature enhancement and multi-perspective perception},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-granularity semantic extraction and multi-task fusion for chinese medical entity normalization. <em>ESWA</em>, <em>296</em>, 129088. (<a href='https://doi.org/10.1016/j.eswa.2025.129088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Entity Normalization (MEN) aims to map informal clinical mentions to formal medical concepts in certain terminologies. Despite the rapid development of MEN research in English, Chinese MEN presents unique challenges, including (1) semantic confusion arising from missing word delimiters and compound terms, (2) limited annotated data with context-deficient texts, and (3) the multi-implication issue where a single mention may correspond to multiple formal concepts. In this study, we propose a novel Chinese MEN framework that integrates multi-granularity semantic extraction and multi-task fusion to tackle these challenges. First, we introduce a word-lattice structure to capture rich word-level semantics of Chinese entities while mitigating segmentation errors. Second, we employ a pre-trained medical language model to encode character-level semantics with reduced data reliance, enhanced by adversarial training for robust few-shot fine-tuning. Third, we utilize a multi-task fusion framework to jointly model implication number prediction and mention-concept matching, effectively addressing the multi-implication issue. By incorporating multi-similarity loss to guide online hard negative mining, the multi-task training process effectively captures discriminative features of ambiguous concepts. Our model is evaluated on clinical entity normalization datasets from the CHIP 2019 and 2020, achieving high accuracy of 91.54 % for procedures and 68.2 % for diagnoses, significantly surpassing other baseline methods. The suggested model is expected to disambiguate Chinese medical terms, providing a solid foundation for downstream clinical applications.},
  archive      = {J_ESWA},
  author       = {Wenhui Hou and Kai He and Rui Mao and Jianqiang Wang and Xiaokang Wang and Mengling Feng},
  doi          = {10.1016/j.eswa.2025.129088},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129088},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-granularity semantic extraction and multi-task fusion for chinese medical entity normalization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Label-based graph augmentation with metapath for graph anomaly detection. <em>ESWA</em>, <em>296</em>, 129087. (<a href='https://doi.org/10.1016/j.eswa.2025.129087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message-passing mechanism in GNNs could make the important characteristics for anomaly detection to become indistinguishable. How can we effectively obtain these characteristics even after message-passing for more effective graph anomaly detection? In this paper, we propose INFOREP, a framework for anomaly detection in attributed graphs. INFOREP consists of a novel graph sampling approach (INFOREP-S) and dual encoders. INFOREP-S enhances normality- and abnormality-specific information. The dual encoders effectively capture this enhanced information as well as complex interactions between normal and abnormal nodes. These processes allow us to grasp highly informative representations both locally and globally. INFOREP is (a) Accurate and fast: winning the highest average AUC and up to 20.1 × faster than state-of-the-art approaches, (b) Scalable: linear in sampling subgraphs in input graph, processing millions of edges within 2 seconds, (c) Interpretable: visually explaining node representations, and (d) Robust: providing performance guarantees of real-world benchmarks with varying hyperparameters. Extensive experiments on six real-world benchmarks show that INFOREP achieves the highest average AUC value and the best performance on most datasets. Moreover, its node representations are visually well-separated as it preserves the important features.},
  archive      = {J_ESWA},
  author       = {Hwan Kim and Junghoon Kim and Byung Suk Lee and Sungsu Lim},
  doi          = {10.1016/j.eswa.2025.129087},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129087},
  shortjournal = {Expert Syst. Appl.},
  title        = {Label-based graph augmentation with metapath for graph anomaly detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal recommender system using text-to-image generative models and adaptive learning. <em>ESWA</em>, <em>296</em>, 129086. (<a href='https://doi.org/10.1016/j.eswa.2025.129086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various successful approaches have been developed to enhance the performance of recommender systems by incorporating multi-modal data, such as item images and textual descriptions. However, adopting these algorithms in real-world scenarios is challenging, as images or textual descriptions are often unavailable. Moreover, in some cases, the provided images or descriptions may not accurately represent the item. We refer to such situations as missing data. In the fashion domain, visual information is crucial, as people are unlikely to buy clothing without seeing its design and appearance. Thus, we propose employing a text-to-image Generative Adversarial Network (GAN) to generate missing visual data from available textual descriptions, enabling a multi-modal recommender system that leverages both visual and textual information. We also introduce an adaptive feature importance learning mechanism to dynamically determine the weight of each multi-modal feature when calculating the preference score. We demonstrate the effectiveness of the proposed algorithm through extensive experiments on the publicly available Amazon review dataset.},
  archive      = {J_ESWA},
  author       = {Seongmin Kim and Seona Moon and Yeongseo Lim and Sang-Min Choi and Sang-Ki Ko},
  doi          = {10.1016/j.eswa.2025.129086},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129086},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-modal recommender system using text-to-image generative models and adaptive learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent docking control of autonomous underwater vehicles using deep reinforcement learning and a digital twin system. <em>ESWA</em>, <em>296</em>, 129085. (<a href='https://doi.org/10.1016/j.eswa.2025.129085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an intelligent docking control system for an autonomous underwater vehicle (AUV), integrating deep reinforcement learning (DRL) with a digital twin (DT) simulation platform. A You Only Look Once (YOLO) object detection model enables real-time visual recognition of the docking station, and the Deep Deterministic Policy Gradient (DDPG) algorithm governs depth and trajectory control under nonlinear hydrodynamic conditions. A customized digital twin system was developed using Python, MATLAB, and Unity to generate simulated sensor and image data for training the DDPG and image-based DDPG (I-DDPG) controllers. Compared to traditional and supervised control strategies, the proposed actor-critic DRL approach offers superior adaptability and continuous control for visual-based underwater docking. Experimental validations in a towing tank demonstrate that the trained controllers successfully transferred from simulation to reality, maintaining robustness across static and dynamic docking scenarios. The results validate the feasibility of combining DRL and digital twins for reliable, precise control in unstructured underwater environments, demonstrating the system’s potential in intelligent marine robotics applications.},
  archive      = {J_ESWA},
  author       = {Yu-Hsien Lin and Chen-Hao Chiang and Chao-Ming Yu and Joyce Yi-Tzu Huang},
  doi          = {10.1016/j.eswa.2025.129085},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129085},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent docking control of autonomous underwater vehicles using deep reinforcement learning and a digital twin system},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective swarm intelligence approach for bias mitigation in decision-making software. <em>ESWA</em>, <em>296</em>, 129084. (<a href='https://doi.org/10.1016/j.eswa.2025.129084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, many decisions, even decisions that affect people’s lives, are increasingly made by decision-making software. For this reason, it is really important to avoid decision-making software being biased, that is, it needs to assure fairness. As decision-making software is generally based on classification models, its bias can be mitigated in three different stages: pre-processing, in-processing, and post-processing. However, despite the importance of fairness on these models, there are very few proposals for the post-processing stage that are able to mitigate bias without reducing the original model’s accuracy. Therefore, this problem should be addressed as a multi-objective problem, optimizing at the same time both fairness and accuracy. Taking this into account, we propose a Multi-Objective Swarm Intelligence approach for BIas Mitigation (MOSIBIM), which combines dominance-based multi-objective optimization (with techniques such as Pareto fronts, niching, and reference points), population-based evolutionary computation, swarm intelligence, and convergence-stagnation differentiation. In order to analyze the improvements that this proposal produces over other approaches in the literature, its results on fairness and accuracy have been compared with the results obtained by other five approaches, optimizing different classification models and in six distinct real-life scenarios which have various types of bias. The results of MOSIBIM show great improvements on fairness in comparison with the other approaches, as it reaches improvement percentages of 91.7 % and, on average, the results are always in the range of 66.6 % to 76.6 % of improvement. Furthermore, the proposed approach has been able to improve the original model’s accuracy in all the studied cases.},
  archive      = {J_ESWA},
  author       = {Lucía Vega-Cruz and Miguel A. Vega-Rodríguez},
  doi          = {10.1016/j.eswa.2025.129084},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129084},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective swarm intelligence approach for bias mitigation in decision-making software},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automatic residue-to-binary converter circuit generation and simplification using hybrid cartesian genetic programming and simulated annealing. <em>ESWA</em>, <em>296</em>, 129083. (<a href='https://doi.org/10.1016/j.eswa.2025.129083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residue Number Systems (RNS) provide notable advantages in digital signal processing and error detection due to their inherent parallelism and fault tolerance. However, designing efficient reverse converters, particularly those based on the Chinese Remainder Theorem, remains a complex and labour-intensive. This paper presents an innovative automated methodology for developing simplified residue-to-binary converters by integrating Cartesian Genetic Programming (CGP) with Simulated Annealing (SA). The proposed approach employs a two-phase optimization framework. In the first phase, a hybrid CGP-SA algorithm generates module-level architectures by evolving computational structures using arithmetic and bitwise operations. Then, SA is then applied to optimize operator parameters, ensuring functional accuracy and enhanced efficiency. In the second phase, the high-level architecture is refined into an optimized gate-level design using adaptive evolutionary strategies to minimize latency, area, and power consumption. Simulation results demonstrate that the proposed framework consistently outperforms conventional handcrafted methods, offering improved computational efficiency, reduced hardware complexity, and greater design flexibility. This advancement provides a promising solution for practical, high-performance RNS reverse converter implementations.},
  archive      = {J_ESWA},
  author       = {Amir Dadashzadeh and Mehdi Hosseizadeh and Amir Sabbagh Molahosseini and Amir Sahafi},
  doi          = {10.1016/j.eswa.2025.129083},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129083},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automatic residue-to-binary converter circuit generation and simplification using hybrid cartesian genetic programming and simulated annealing},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inductive multiple clustering based on weakly-supervised salient representation learning. <em>ESWA</em>, <em>296</em>, 129082. (<a href='https://doi.org/10.1016/j.eswa.2025.129082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing recognition of data diversity has highlighted multiple clustering as a valuable approach for generating diverse clustering solutions. However, conventional methods often prioritize non-redundant clusterings across disjoint subspaces, potentially overlooking key data characteristics and limiting interpretability. In this paper, we propose an Inductive Multiple Clustering (IMC) framework designed to extract distinct and interpretable representations through weakly-supervised learning from diverse clustering perspectives. Specifically, IMC decomposes data objects into group-specific salient components using reconstruction and transformation matrices with low-rank and sparse regularization. To enhance diversity among clusters, an incoherent regularization minimizes similarities between group-specific transformations in a weakly-supervised manner. Unlike previous approaches, our framework emphasizes salient representations and integrates inductive learning into multiple clustering, facilitating comprehensive interpretations of clustering results. We employ the Alternating Direction Method of Multipliers (ADMM) to optimize IMC, leveraging resulting matrices for clustering diverse datasets. Experimental results on benchmark datasets demonstrate IMC’s superiority over existing methods, providing a comprehensive explanation of multiple clustering results and successful extension to unseen data clustering.},
  archive      = {J_ESWA},
  author       = {Wenjie Zhu and Wei Qi Yan},
  doi          = {10.1016/j.eswa.2025.129082},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129082},
  shortjournal = {Expert Syst. Appl.},
  title        = {Inductive multiple clustering based on weakly-supervised salient representation learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning approach to cloud resource optimization with response time distributions. <em>ESWA</em>, <em>296</em>, 129081. (<a href='https://doi.org/10.1016/j.eswa.2025.129081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing systems depend on elasticity to adapt resource allocation to fluctuating workload. Although traditional metrics effectively measure resource scaling, they fail to capture how these adjustments impact user-perceived service quality, which is a critical gap for providers and consumers alike. To bridge this gap, we introduce a novel performance metric that uses the probability distribution of task response times to complement the existing elasticity measures. This metric defines service quality as the likelihood that response times meet preset service-level objectives (SLOs) within a given timeframe. We developed a framework linking resource allocation, workload patterns, and this metric to optimize performance in various scenarios. We propose a decision-making algorithm to improve service quality without sacrificing cost efficiency. The experiments show that integrating this user-focused metric improves resource utilization by 23 % and reduces SLO violations by 31 % in the tested e-commerce workloads.},
  archive      = {J_ESWA},
  author       = {Liwen Chen and Chunmao Jiang and Qiaoping Zhong},
  doi          = {10.1016/j.eswa.2025.129081},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129081},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning approach to cloud resource optimization with response time distributions},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Strategies for retailers’ sales effort competition under random demand and manufacturer’s cost-sharing contract. <em>ESWA</em>, <em>296</em>, 129080. (<a href='https://doi.org/10.1016/j.eswa.2025.129080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers in manufacturing industries, like Manteswar Enterprise and Kusumgram Boutique Centre of the fashion industry, sell similar products at almost the same price. They make sales efforts (SEs) to expand demand by attracting customers and competing with each other. With these facts, we consider a two-echelon supply chain (SC) with one manufacturer and two retailers competing through SEs in a common market with stochastic demand selling two similar items at almost the same price. Here, retailers put their SEs to increase individual products’ sales. For the excess amounts at retailers due to stochastic demand, three cases are considered: excess product sold in the secondary market, buybacks by the manufacturer, and no salvage. Centralized, decentralized, and cost-sharing contract (CSC) models are formulated and solved using a game theoretic approach. SC members’ profits decrease with increased competition. High (low) competition reduces (increases) the surplus. The manufacturer can repurchase the excess at a salvage value higher than its marginal cost under some restrictions if required. CSC benefits all members under a restriction on the degree of competition. Numerical experiments support theoretical results. Sensitivity analyses against some parameters and some managerial decisions are presented.},
  archive      = {J_ESWA},
  author       = {Goutam Kumar Mandal and Manoranjan De and Pritha Das and Manoranjan Maiti},
  doi          = {10.1016/j.eswa.2025.129080},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129080},
  shortjournal = {Expert Syst. Appl.},
  title        = {Strategies for retailers’ sales effort competition under random demand and manufacturer’s cost-sharing contract},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Digital twin-empowered power consumption prediction for energy-intensive aluminum annealing furnaces. <em>ESWA</em>, <em>296</em>, 129079. (<a href='https://doi.org/10.1016/j.eswa.2025.129079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aluminum annealing furnace (AAF) is a large, energy-intensive industrial equipment widely used in manufacturing. Accurate prediction of its power consumption is crucial for optimizing energy management. However, conventional prediction methods often face challenges due to the furnace’s multi-day production cycles, coupled operating conditions, and complex thermal interactions. To overcome these challenges, this paper proposes a digital twin (DT)-based approach for high-fidelity power consumption prediction of AAFs. First, a DT-empowered prediction framework is proposed, which establishes a closed-loop interaction between physical entities and virtual models through four synergistic layers: physical equipment, data integration, DT simulation, and application services. Within this framework, detailed power consumption profiles are generated via DT simulations that replicate the AAF’s production process in advance, utilizing both the twin model and production data. The AAF DT model is developed using a CNN-BiLSTM-Attention network, effectively capturing the nonlinear dynamics of power consumption. Furthermore, an incremental learning strategy is implemented to continuously refine the model with increasing data, ensuring adaptability to varying production scenarios. Finally, a real-world case from an aluminum manufacturing facility is provided to validate the proposed approach. Experimental results demonstrate its superior performance, with all R 2 values exceeding 0.96, consistently outperforming other baseline models.},
  archive      = {J_ESWA},
  author       = {Hui Xiao and Bo Wang and Hong Zhou and Wenshan Hu and Guo-Ping. Liu},
  doi          = {10.1016/j.eswa.2025.129079},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129079},
  shortjournal = {Expert Syst. Appl.},
  title        = {Digital twin-empowered power consumption prediction for energy-intensive aluminum annealing furnaces},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weight vector selection methods by hypervolume maximization in the pareto front for single policy multi-objective reinforcement learning. <em>ESWA</em>, <em>296</em>, 129070. (<a href='https://doi.org/10.1016/j.eswa.2025.129070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively solving Multi-Objective Reinforcement Learning (MORL) problems is crucial in real-world applications, such as robotics and autonomous systems, where multiple conflicting objectives must be optimized. Single-Policy MORL (SPMORL), which relies on a single policy network, struggles to learn a diverse set of weight vectors that represent the importance of each objective. In contrast, Multi-Policy MORL (MPMORL) trains multiple policy networks to handle different weight vectors. However, this approach is computationally expensive and can be inefficient, as the networks may not share experiences during training, leading to redundant learning and slower convergence. In this paper, we propose a Weight Vector Selection (WVS) algorithm for SPMORL, enhancing its ability to explore the weight vector space efficiently using the polar coordinate system, the Jacobian matrix, and the ellipsoid function. The key idea of WVS is to provide a weight vector selection criterion that enables SPMORL to approximate the Pareto front more effectively while maintaining computational efficiency. We introduce three novel WVS algorithms: WVS-Polar, WVS-Jacob, and WVS-Ellip. Specifically, WVS-Polar employs the polar coordinate system to estimate the Pareto front, WVS-Jacob utilizes the Jacobian matrix and the derivative of the Pareto front, and WVS-Ellip determines the center of an ellipsoid based on nearby Pareto-optimal points. Integrated with SPMORL, these WVS algorithms iteratively perform two learning stages. First, the agent selects a target weight vector using its respective approximation method. Then, the agent optimizes the selected weight vector, collects the corresponding Pareto-optimal point, and updates the Pareto front. This approach enables SPMORL to efficiently learn multiple weight vectors while maintaining the benefits of using a single policy network. To evaluate the effectiveness of WVS-SPMORL, we conduct extensive experiments in both simulated and real-world environments. In OpenAI-MuJoCo simulations, WVS-SPMORL outperforms baseline SPMORL algorithms in Pareto front approximation. In real-world robot arm tasks, we integrate an offline Reinforcement Learning (RL) mechanism, demonstrating that WVS-SPMORL successfully learns and manages the entire Pareto front. As shown in the attached experimental video, our approach allows the agent to continuously improve its performance in both online RL simulations and offline RL experiments. These results confirm that WVS-SPMORL significantly enhances learning efficiency and performance in MORL.},
  archive      = {J_ESWA},
  author       = {Seonjae Lee and Myoung Hoon Lee and Jun Moon},
  doi          = {10.1016/j.eswa.2025.129070},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129070},
  shortjournal = {Expert Syst. Appl.},
  title        = {Weight vector selection methods by hypervolume maximization in the pareto front for single policy multi-objective reinforcement learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Medical waste transportation: A novel periodic reverse logistic design. <em>ESWA</em>, <em>296</em>, 129069. (<a href='https://doi.org/10.1016/j.eswa.2025.129069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare waste (HCW) comprises materials generated by healthcare activities, including used medical supplies, equipment, and related items. Improper management poses significant risks to public health and the environment. This study addresses the transportation of HCW from healthcare facilities within the context of reverse logistics, where waste is collected for safe treatment or disposal. To this end, we propose a new mixed-integer linear programming (MILP) model based on the Periodic Vehicle Routing Problem (PVRP). The model captures realistic operational constraints, including vehicle capacity, visit frequency, and compliance with World Health Organization guidelines requiring container cleaning and decontamination before reuse. Due to the NP-hardness of the problem, we introduce a heuristic method called Dynamic Tabu Solver (DTS), which extends the Tabu Search framework. The effectiveness of DTS is assessed through computational experiments on 109 benchmark instances. Results demonstrate that DTS significantly outperforms state-of-the-art methods, solving 5 out of 10 medium- and large-sized PVRP instances and achieving an average total travel cost of 6681.52, as well as an average improvement of -1.91 % over competing approaches. Finally, we carry out statistical tests, including Friedman and Wilcoxon analyses, which confirm the superiority of DTS in terms of solution quality. These results underscore the practical relevance and computational efficiency of the proposed approach in the context of HCW transportation planning.},
  archive      = {J_ESWA},
  author       = {Nasreddine Ouertani and Issam Nouaouri and Gilles Goncalves and Jean Christophe Nicolas},
  doi          = {10.1016/j.eswa.2025.129069},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129069},
  shortjournal = {Expert Syst. Appl.},
  title        = {Medical waste transportation: A novel periodic reverse logistic design},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fuzzy-CNN model with feature extraction from MACD-based trends for stock market movement forecasting. <em>ESWA</em>, <em>296</em>, 129068. (<a href='https://doi.org/10.1016/j.eswa.2025.129068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial time series forecasting is a crucial but challenging undertaking that is necessary for creating successful strategies. Reliable forecasting systems are vital for effective investment management and algorithmic trading. This necessity drives extensive research into methods for machine learning and statistics. In the literature, numerous studies have focused on predicting price direction in stock time series, with most aiming to forecast the price direction on the same day or the following day. However, there are relatively few studies that approach this prediction by segmenting the time series into smaller parts, and the application of fuzzy sets in this context remains largely unexplored. This study presents a new method for predicting the next day’s price direction, distinguishing it from previous research approaches. The approach involves identifying local trends in time series data, extracting features from these trends, converting these features into fuzzy values, and then prediction by using a deep learning method. The 40 stocks listed on BIST (Borsa Istanbul) and their daily closing values are included in the study over a ten-year period. The proposed method predicted the next day price direction as the average of 40 stocks with 79.04 % accuracy score.},
  archive      = {J_ESWA},
  author       = {İlyas Özdoğan and Oktay Yıldız and Fatih Emre Boran},
  doi          = {10.1016/j.eswa.2025.129068},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129068},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fuzzy-CNN model with feature extraction from MACD-based trends for stock market movement forecasting},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating the interactions between class overlap and class imbalance for software defect prediction. <em>ESWA</em>, <em>296</em>, 129067. (<a href='https://doi.org/10.1016/j.eswa.2025.129067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) can effectively assist in improving software quality. However, when both class imbalance and class overlap are present in the SDP dataset, classifiers tend to misclassify the minority class samples due to the dominance of majority class samples in the overlapping region. This is especially problematic as minority class samples are fewer and contain less information. Current methods for handling class imbalance and class overlap have limitations. Given that the impact of class imbalance and class overlap on SDP models differs, studying their interaction is more crucial than examining each individually. We believe further investigation is needed to enhance this understanding. Specifically, through an extensive case study on 230 diverse datasets, we analyze the interaction between class imbalance and class overlap and how their relationship affects the performance of SDP models. Our work shows: i) The median overlap ratio of overlapping instances in defective classes is close to 0.75, indicating that most defective instances cluster in the overlapping region, where class imbalance and class overlap interact within defective datasets; ii) Class imbalance and class overlap are negatively correlated, with most overlaps occurring in defective data points surrounded by many non-defective instances; iii) Higher overlap rates have a more significant impact on SDP model performance, especially for SVM, which is more sensitive to class overlap; iv) The effects of class imbalance and class overlap on SDP model performance differ across evaluation metrics, with class overlap affecting most commonly used performance metrics except recall; v) Removing class overlap or combining its removal with handling class imbalance improves model performance. We suggest that researchers should consider the ratio of class imbalance and class overlap, chosen model evaluation metrics, and the focus on model interpretability to determine appropriate strategies for addressing class overlap and class imbalance in datasets. Software defect prediction (SDP) performance is critically hampered by the interdependent challenges of class imbalance and class overlap, where minority defective instances cluster in overlapping regions. Our unprecedented analysis of 230 datasets provides novel insights into this interaction: i) A striking median of 75% of defective instances reside in overlapping hotspots, jointly hindered by imbalance and overlap; ii) Imbalance and overlap exhibit a significant negative correlation, with defective points typically surrounded by non-defective neighbors; iii) Overlap exerts a stronger detrimental impact than imbalance, particularly degrading SVM; iv) Effects are metric-specific—overlap impairs common metrics (e.g., F1, AUC) except Recall, while imbalance’s impact differs; v) Strategically removing overlap or combining removal with imbalance handling boosts overall performance, but induces key metric trade-offs (e.g., Remove improves AUC not Recall, SMOTE boosts Recall not AUC); vi) Crucially, rebalancing techniques (e.g., SMOTE) distort data distributions and shift feature importance, compromising interpretability by undermining ranking stability and fidelity. These findings demonstrate that effective SDP requires multidimensional trade-offs—considering the imbalance/overlap ratio, selecting goal-aligned metrics, and balancing performance gains against interpretability needs—providing essential practical guidance for optimizing real-world defect prediction strategies.},
  archive      = {J_ESWA},
  author       = {Ya Zhang and Ningzhong Liu and Yu Zhao and Jun Fan and Lina Gong},
  doi          = {10.1016/j.eswa.2025.129067},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129067},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating the interactions between class overlap and class imbalance for software defect prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Estimation of conditional average treatment effects on distributed confidential data. <em>ESWA</em>, <em>296</em>, 129066. (<a href='https://doi.org/10.1016/j.eswa.2025.129066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of conditional average treatment effects (CATEs) is an important topic in many scientific fields. CATEs can be estimated with high accuracy if data distributed across multiple parties are centralized. However, it is difficult to aggregate such data owing to confidentiality or privacy concerns. To address this issue, we propose data collaboration double machine learning, a method for estimating CATE models using privacy-preserving fusion data constructed from distributed sources, and evaluate its performance through simulations. We make three main contributions. First, our method enables estimation and testing of semi-parametric CATE models without iterative communication on distributed data, providing robustness to model mis-specification compared to parametric approaches. Second, it enables collaborative estimation across different time points and parties by accumulating a knowledge base. Third, our method performs as well as or better than existing methods in simulations using synthetic, semi-synthetic, and real-world datasets.},
  archive      = {J_ESWA},
  author       = {Yuji Kawamata and Ryoki Motai and Yukihiko Okada and Akira Imakura and Tetsuya Sakurai},
  doi          = {10.1016/j.eswa.2025.129066},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129066},
  shortjournal = {Expert Syst. Appl.},
  title        = {Estimation of conditional average treatment effects on distributed confidential data},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Empowering image restoration: A multi-attention approach. <em>ESWA</em>, <em>296</em>, 129065. (<a href='https://doi.org/10.1016/j.eswa.2025.129065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose DART ( Diverse Attention Fusion Restoration Transformer ), a unified image restoration framework that integrates multi-scale contextual cues-including long-range dependencies, local-global spatial patterns, and cross-dimensional information-to effectively address complex image degradations. While Transformer-based models have achieved strong results in image restoration, they often suffer from limited scalability and adaptability in real-world settings. DART mitigates these limitations by introducing a suite of attention mechanisms specifically designed for image restoration. It employs a windowed attention strategy to dynamically adjust receptive fields, enabling structural feature extraction at varying granularities. The proposed LongIR attention module extends spatial interaction across long sequences with linear complexity, while cross-dimensional attention, decoupled along feature and positional axes, facilitates more precise restoration of texture and structure. Extensive experiments across six standard image restoration tasks demonstrate that DART achieves consistent, state-of-the-art performance on multiple public benchmarks.},
  archive      = {J_ESWA},
  author       = {Juan Wen and Yawei Li and Chao Zhang and Weiyan Hou and Luc Van Gool and Radu Timofte},
  doi          = {10.1016/j.eswa.2025.129065},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129065},
  shortjournal = {Expert Syst. Appl.},
  title        = {Empowering image restoration: A multi-attention approach},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Greedy algorithms for the inverse center line location problem. <em>ESWA</em>, <em>296</em>, 129064. (<a href='https://doi.org/10.1016/j.eswa.2025.129064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The line location problem, as a particular case of the hyperplane location problem, is a pivotal issue in both location theory and data analysis. This research concentrates on the problem of determining the optimal location of lines (hyperplanes in R 2 ) from a view point of location science. Suppose there are n weighted demand points in the plane, with each point’s weight representing its importance. A straight line in the plane minimizing maximum weighted distances of demand points to the line is called center line facility. This paper deals with inverse form of the center line facility location problem using rectilinear and Euclidean norms in the plane. Our problem is defined as follows: Assuming that L is a given line in the plane, the aim is to modify parameters of the problem such as coordinates of the points or weight of the demand points at minimum total cost so that the line L becomes a center line facility. We propose two models and discuss their characteristics in details. Accordingly, we develop greedy algorithms to tackle these models under two scenarios: adjusting either the coordinates or the associated weights of the demand points. Finally, we present computational results and provide conclusions based on our findings.},
  archive      = {J_ESWA},
  author       = {Mehdi Golpayegani and Jafar Fathali},
  doi          = {10.1016/j.eswa.2025.129064},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129064},
  shortjournal = {Expert Syst. Appl.},
  title        = {Greedy algorithms for the inverse center line location problem},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fed-MSV: Client sampling optimization based on modified shapley value for federated learning. <em>ESWA</em>, <em>296</em>, 129063. (<a href='https://doi.org/10.1016/j.eswa.2025.129063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of federated learning (FL) is directly influenced by the quality of training datasets from different clients, so it is crucial to mitigate the negative impact of low-quality datasets on the global model. The existing dataset quality evaluation based on Shapley value is only applicable to scenarios where all clients participate in the entire training process of federated learning. However, participants in each round of federated learning are randomized, so it is a challenge to evaluate and compare the dataset qualities of different clients due to the significant differences in training difficulty across different rounds. To address this issue, we propose the concept of a modified Shapley value (MSV), which can reflect the influence of clients on the joint training of different combinations. Implementing a guided sampling policy for reducing computation costs, an improved federated learning algorithm with MSV-based Sampling (Fed-MSV) is designed, which improves the robustness and accuracy of the global model by dynamically updating the client sampling weight based on each client’s MSV. The proposed algorithm Fed-MSV effectively reduces the impact of low-quality datasets by decreasing their participation rate, and experimental results on the MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate that it outperforms existing similar algorithms in handling three types of low-quality data clients: free-riding clients, noise-adding clients, and erroneous-label clients.},
  archive      = {J_ESWA},
  author       = {Xiaohong Wu and Jie Zhang and Jie Tao and Yonggen Gu and Shigen Shen and Shui Yu},
  doi          = {10.1016/j.eswa.2025.129063},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129063},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fed-MSV: Client sampling optimization based on modified shapley value for federated learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DCMTL network: A double-contrast multi-task learning network for semi-supervised multi-source data classification. <em>ESWA</em>, <em>296</em>, 129062. (<a href='https://doi.org/10.1016/j.eswa.2025.129062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) has demonstrated remarkable success across various fields but is primarily limited to single data sources, which constrains its performance in complex multi-source scenarios with limited labeled data. To meet this challenge, we propose a novel double-contrast multi-task learning (DCMTL) network for semi-supervised multi-source data classification. Specifically, DCMTL considers each data source as an individual task and comprises two main modules: multi-source prototype contrastive learning (MPCL) and contrastive multi-task learning (CML). The MPCL module extends prototype contrastive learning (PCL) for multi-source settings, providing efficient feature representation. It leverages abundant multi-source unlabeled data for instance discrimination and semantic clustering, while also incorporates multi-source index information to assist model training. To effectively utilize limited labeled data, the CML defines an encoder-decoder multi-task learning (MTL) network to jointly learn knowledge across tasks. Meanwhile, it contrasts features across categories to enhance the feature compactness and obtain better classification boundaries. Moreover, the CML shares its encoder with the MPCL to improve the model’s performance by synergistic utilization of both labeled and unlabeled data. Extensive experiments on both image datasets and time series datasets show that our method significantly outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Yongjie Huang and Man Chen and Jun Chen and Zhisong Pan},
  doi          = {10.1016/j.eswa.2025.129062},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129062},
  shortjournal = {Expert Syst. Appl.},
  title        = {DCMTL network: A double-contrast multi-task learning network for semi-supervised multi-source data classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). From data to strategy: A public market framework for competitive intelligence. <em>ESWA</em>, <em>296</em>, 129061. (<a href='https://doi.org/10.1016/j.eswa.2025.129061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a dynamic, mathematically grounded, and fully data-driven framework for competitor analysis, index construction, and industry benchmarking—addressing fundamental limitations in traditional strategic approaches that rely on static classifications, internal disclosures, or proprietary data. Built entirely on publicly available financial signals—including firm-level equity prices, macroeconomic indicators, and sector ETFs—the framework replaces rigid taxonomies with a flexible, behaviorally revealed peer selection mechanism governed by coupled ordinary differential equations (ODEs) and speed-weighted Runge-Kutta integration. A stakeholder-aware thresholding scheme integrates strategic priorities without sacrificing analytical rigor. The resulting industry index is constructed using Self-Financing Hierarchical Risk Parity (SF-HRP), producing stable and interpretable portfolio weights. A Gram-Schmidt orthogonality ensures parsimony among macroeconomic factors (|ρ| < 0.05), enhancing robustness. Forecasting evaluations confirm that CNN-LSTM achieves superior performance (RMSE: 0.028, R 2 : 0.95), reducing error by over 80 % relative to baseline LSTM models, while WGANs capture tail risk distributions (R 2 : 0.75). Critically, the framework demonstrates that high correlation does not imply redundancy—validated through multiscale residual analysis, information-theoretic modeling, and geometric submanifold representations. At its core, this research introduces the signal-based strategic interaction model, a new theoretical paradigm that reframes financial performance as real-time strategic communication. It establishes a generalized, industry-agnostic system for dynamic competition management—scalable, transparent, and responsive to market shifts—empowering firms of all sizes to identify peers, track competitive positioning, and inform strategy with unprecedented precision and accessibility.},
  archive      = {J_ESWA},
  author       = {Tian Tian and Ricky Cooper and Athanasios Vasilakos and Jiahao Deng and Qingquan Zhang},
  doi          = {10.1016/j.eswa.2025.129061},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129061},
  shortjournal = {Expert Syst. Appl.},
  title        = {From data to strategy: A public market framework for competitive intelligence},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MT-TexTableX: A multitask learning approach to table-to-text generation. <em>ESWA</em>, <em>296</em>, 129060. (<a href='https://doi.org/10.1016/j.eswa.2025.129060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Table-to-Text (T2T) generation aims to convert structured data into coherent and faithful natural language descriptions, yet remains challenged by content selection, structural alignment, and factual consistency. We propose MT-TexTableX, a lightweight multitask learning framework that enhances T2T generation by integrating four auxiliary tasks: Content Selection, Table Reconstruction, Text-to-Table Generation, and Fact Verification. Unlike prior methods that address these challenges in isolation or rely on large-scale models, MT-TexTableX unifies them within a shared T5-base encoder–decoder, enabling joint optimization and inductive transfer. Content Selection focuses the model on salient cells, Table Reconstruction refines structural understanding, Text-to-Table Generation enforces bidirectional alignment, and Fact Verification mitigates hallucinations by promoting output faithfulness. Ablation results confirm that each task contributes to overall performance, with Fact Verification and Content Selection producing the largest BLEU gains. On the ToTTo benchmark, MT-TexTableX outperforms strong end-to-end baselines in the subtable setting and achieves the best reported results for full table mode, with BLEU, PARENT, and BLEURT scores of 40.9, 54.8, and 0.1465 on the test set. Additional comparisons with large language models such as GPT‑3.5, GPT‑4.1, LLaMA‑3, and Phi‑3, demonstrate that our lightweight model outperforms them across all evaluation metrics. Human evaluations further validate improvements in fluency and factual accuracy. These findings show that a well-structured multitask framework can deliver high-quality T2T generation without the need for large-scale models.},
  archive      = {J_ESWA},
  author       = {Parman Mohammadalizadeh and Leila Safari},
  doi          = {10.1016/j.eswa.2025.129060},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129060},
  shortjournal = {Expert Syst. Appl.},
  title        = {MT-TexTableX: A multitask learning approach to table-to-text generation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature disentanglement and cross-domain synthesis via federated style transfer for non-IID segmentation. <em>ESWA</em>, <em>296</em>, 129059. (<a href='https://doi.org/10.1016/j.eswa.2025.129059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning collaboratively trains machine learning models among different clients while keeping data privacy and has become the mainstream for breaking data silos. However, the non-independently and identically distribution (i.e., Non-IID) characteristic of different image domains among different clients reduces the benefits of federated learning and has become a bottleneck problem restricting the accuracy and generalization of federated models. In this work, a novel federated image segmentation method (FedST) based on style transfer is proposed, by using a denoising diffusion probabilistic model to achieve feature disentanglement and image synthesis of cross-domain image data between multiple clients. Thus, the method enables style feature sharing among clients while preserving structural features of image data, which effectively alleviates the influence of the Non-IID phenomenon. Experiments prove that our method achieves superior segmentation performance compared to state-of-art methods among four different Non-IID datasets in objective and subjective assessment.},
  archive      = {J_ESWA},
  author       = {Boyuan Ma and Yongfeng Chen and Jing Tan and Xiang Yin and Jing Qin and Haiyou Huang and Hao Wang and Weihua Xue and Xiaojuan Ban},
  doi          = {10.1016/j.eswa.2025.129059},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129059},
  shortjournal = {Expert Syst. Appl.},
  title        = {Feature disentanglement and cross-domain synthesis via federated style transfer for non-IID segmentation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDR-GCL: Toward imagined speech decoding in naturalistic BCI systems via brain dynamics representation enhanced graph contrastive learning. <em>ESWA</em>, <em>296</em>, 129058. (<a href='https://doi.org/10.1016/j.eswa.2025.129058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naturalistic brain-computer interface (BCI) aims to enable thought-driven interaction between brain and peripherals to enhance usability and promote adoption. Electroencephalogram (EEG)-based imagined speech decoding can directly translate mental intent into semantic commands for naturalistic BCI, and current decoding methods primarily leverage deep learning models. However, the small size of imagined speech datasets, coupled with intricate neural interactions among related brain regions, poses challenges to robust performance. Graph contrastive learning (GCL) addresses these challenges by constructing positive/negative contrastive samples, providing implicit topological supervision. Despite its potential, GCL has not yet been applied to imagined speech decoding, as dynamic, complex brain activity complicates the construction of discriminative negative representations. Moreover, current GCL methods treat all negatives equally, ignoring false negatives and the effect of imagined speech individual variability on negatives’ hardness. To tackle these issues, we propose a novel GCL method enhanced by brain dynamics representation (BDR-GCL), pioneering GCL’s application in EEG-based imagined speech decoding. Specifically, Brain Dynamics Representation (BDR) module generates more comprehensive imagined speech representations of negative samples by simultaneously learning EEG dynamics in brain region, connectivity, and network levels under the guidance of neuroscience prior knowledge. Considering the impact of hard/false negatives, we further design a Sample Attention Adjustment (SAA) strategy to evaluate negatives’ importance and introduce an attention contrastive loss via a weighting term. Experiments on two public datasets demonstrate that BDR-GCL achieves state-of-the-art performance. Visual analysis validates the crucial role of BDR and SAA in improving decoding and interpretability.},
  archive      = {J_ESWA},
  author       = {Yifan Niu and Ziyu Li and Li Yao and Xia Wu},
  doi          = {10.1016/j.eswa.2025.129058},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129058},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDR-GCL: Toward imagined speech decoding in naturalistic BCI systems via brain dynamics representation enhanced graph contrastive learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Capturing local and global information: Multi-view graph convolutional network via granular-ball computing and collaborative matrix. <em>ESWA</em>, <em>296</em>, 129057. (<a href='https://doi.org/10.1016/j.eswa.2025.129057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-view learning based on graph convolutional network (GCN), many studies focus on integrating information from different views to enhance model performance. Most of them primarily extract consistency information through feature fusion or topology fusion. However, this fusion mode overlooks local information within individual views, which inherently limits the model performance. To overcome this limitation, this paper proposes the multi-view Graph Convolutional Network via Granular-ball computing and Collaborative Matrix (GBCM-GCN), which consists of two modules: the granular-ball based topology construction module and collaborative matrix based convolution module. The former utilizes the boundary distance between granular-balls to construct high-quality topology based on both local and global connections. The latter leverages convolution kernels of different dimensions to extract local and global information of embedding representation during the convolution process, then utilizes learnable parameters to integrate them into a collaborative matrix. Furthermore, the collaborative matrix is shared across all views, which can enhance the consistency representation across different views. Finally, the experimental result show that GBCM-GCN outperforms existing multi-view semi-supervised classification methods.},
  archive      = {J_ESWA},
  author       = {Weijun Wang and Xibei Yang and Qinghua Zhang and Shuyin Xia and Jie Yang and Taihua Xu},
  doi          = {10.1016/j.eswa.2025.129057},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129057},
  shortjournal = {Expert Syst. Appl.},
  title        = {Capturing local and global information: Multi-view graph convolutional network via granular-ball computing and collaborative matrix},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advanced hybrid deep learning approach for automated OSCC classification using improved pattern-based features. <em>ESWA</em>, <em>296</em>, 129056. (<a href='https://doi.org/10.1016/j.eswa.2025.129056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral Squamous Cell Carcinoma (OSCC) is a prevalent and aggressive form of oral cancer, characterized by high morbidity and mortality rates. For better patient results and survival, an early and precise diagnosis is essential. Traditional diagnostic methods rely heavily on clinical expertise, which can introduce variability and potential errors. In this paper, a novel Deep Learning model-based Automated Classification method for Oral Squamous Cell Carcinoma (AC-OSCC-DL) is proposed. This study presents an advanced automated classification system for OSCC using the following comprehensive pipeline. The preprocessing step involves noise reduction using a Gaussian filter, while segmentation is done through Modified Cluster distance-based Balanced Iterative Reducing and Clustering using the Hierarchies (MCD-BIRCH) segmentation technique, which enhances the accuracy of identifying relevant regions within histopathological images. Feature extraction is performed by Visual Geometry Group Network with 16 layers (VGG-16) and Residual Network (ResNet) architectures, alongside statistical features and Modified Median Binary Patterns (MMBP), to capture a wide range of image characteristics. For classification, a hybrid model combining Collaborative Attention layer Assisted Bi-directional Long Short-Term Memory (CAA-Bi-LSTM) and Link Net models are employed to accurately categorize OSCC into different grades. The proposed system demonstrates enhanced performance by mitigating traditional limitations and offers a robust, automated approach to OSCC diagnosis, facilitating timely and precise treatment decisions. The CAA-Bi-LSTM + Link Net strategy achieved the highest accuracy of 0.986, an F-measure of 0.979, and a Precision of 0.989.},
  archive      = {J_ESWA},
  author       = {Anuradha Suresh Pandit and Vaibhav Vitthalrao Dixit},
  doi          = {10.1016/j.eswa.2025.129056},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129056},
  shortjournal = {Expert Syst. Appl.},
  title        = {Advanced hybrid deep learning approach for automated OSCC classification using improved pattern-based features},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating rail transport into the waste flow and processing chain for sustainable waste handling. <em>ESWA</em>, <em>296</em>, 129055. (<a href='https://doi.org/10.1016/j.eswa.2025.129055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern-day policies promote sustainable development and ubiquitous transition towards circular economy. In waste management, climate impacts may be mitigated by reducing waste production amounts, efficient waste processing and low-emission transport. While focusing on the latter, this research addresses integration of rail transport into existing waste flows and proposes a novel mixed integer programming model. The model’s design addresses important technical requirements and related conditions. The paper describes the trade-offs between the current operation of the transport network and the potential for intermodal approach to waste transportation. This framework is applied to a real example from a European Union country. It is concluded that the railway network configuration, the waste distribution density across the analyzed territory, and the distance from loading hubs from processing facilities play a significant role in the economic viability of rail transport. Among the specifics of rail transport, the model addresses route planning with passing through nodes twice, i.e., for unloading and reloading containers, as well as recommendation for reducing the loaded volumes at the last node on the route due to time–cost reasons.},
  archive      = {J_ESWA},
  author       = {Vlastimír Nevrlý and Yury Redutskiy and David Poul and Radovan Šomplák},
  doi          = {10.1016/j.eswa.2025.129055},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129055},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating rail transport into the waste flow and processing chain for sustainable waste handling},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expected attribution prior guided interpretable framework for machine fault diagnosis. <em>ESWA</em>, <em>296</em>, 129054. (<a href='https://doi.org/10.1016/j.eswa.2025.129054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expert-based and AI-based fault diagnosis methods have recently developed rapidly. Expert knowledge can be used to more accurately and qualitatively diagnose mechanical faults, while intelligent networks (IN) adaptively learn data correlations without expert input. However, the accuracy of IN’s learning and inference behaviors cannot be guaranteed without the expert’s diagnostic experience. Without the assistance of IN, experts also cannot handle the increasing volume of big data. This paper addresses this gap by proposing an Expected Attribution Prior-guided Interpretable Framework (EAP-IF) to bridge expert knowledge and IN. Inspired by Expert Diagnostic Logic (EDL), a Disentangle-From-Normal (DFM) architecture is introduced to extract fault information representation in signals. Meanwhile, an expected attribution prior loss is introduced to penalize the improper attribution during learning to guarantee the rightness of network learning and inference. To further interpret network decisions, the framework decodes logical decision rules into more understandable representations. Experiments demonstrate that EAP-IF generalizes EDL across different speeds, loads, and bearings, while also generating interpretable fault information for experts to analyze.},
  archive      = {J_ESWA},
  author       = {Jie Li and Junwei Gu and Yu Wang and Yanyang Zi and Mingquan Zhang and Haijun Zhang},
  doi          = {10.1016/j.eswa.2025.129054},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129054},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expected attribution prior guided interpretable framework for machine fault diagnosis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Real-time high-precision roll-pitch estimation of land-air vehicles using sensor fusion and improved discrete observers. <em>ESWA</em>, <em>296</em>, 129052. (<a href='https://doi.org/10.1016/j.eswa.2025.129052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roll-pitch estimation algorithms are widely used in modern devices such as GNSS-aided inertial navigation systems (GNSS/INS), attitude and heading reference systems (AHRS), and inertial measurement units (IMU). These algorithms provide real-time data for communication and mechatronic closed-loop systems, where fast and high-quality measurements are essential. This work proposes a strategy for achieving real-time, high-precision roll-pitch estimations for land and air applications by employing sensor fusion algorithms and enhanced discrete generalized proportional-integral (GPI) observers. Compared to other state-of-the-art algorithms, our strategy demonstrated superior performance. Experimental results highlight the effectiveness of recursiveness, active disturbance rejection (ADR), and optimal state estimation features. For rough environments, the algorithm is parametrized using a Bayesian Optimization strategy. The proposed algorithm can be utilized to generate input signals for onboard hard real-time systems, such as trajectory generators, target trackers, and stabilized platforms.},
  archive      = {J_ESWA},
  author       = {Edwards E. Sánchez R and Alberto J. Rosales S and Carlos J. Morales P and Armando A. Miranda G and Francisco J. Gallegos F},
  doi          = {10.1016/j.eswa.2025.129052},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129052},
  shortjournal = {Expert Syst. Appl.},
  title        = {Real-time high-precision roll-pitch estimation of land-air vehicles using sensor fusion and improved discrete observers},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Receptive field weighted representation and context enhancement for SAR ship detection. <em>ESWA</em>, <em>296</em>, 129051. (<a href='https://doi.org/10.1016/j.eswa.2025.129051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) ship detection plays an increasingly important role in marine transportation. The features of SAR ship extracted by the existing methods are not comprehensive enough to distinguish SAR ship, resulting in the low accuracy of SAR ship detection. To solve this problem, we propose a SAR ship detection method based on receptive field weighted representation (RFWR) and context enhancement, called RC-Det for short. The proposed method consists of three parts. First, multiple receptive fields are used to extract rich spatial features, and the weights of these features are dynamically assigned to achieve adaptive balancing between local details and global context, thereby enhancing the discriminative capability and robustness of the model. Second, the proposed context enhancement module (CEM) can combine the information of surrounding objects to enhance the expression ability of ship features and improve the recognition of ship features. Third, the classification and regression tasks are performed separately to avoid information loss. The CIoU regression loss is beneficial for obtaining more accurate prediction boxes. Extensive experiments are conducted on SSDD and SAR-Ship-Dataset to prove the effectiveness of our proposed method. The A P 0.5 of RC-Det on SSDD and SAR-Ship-Dataset is 96.21 % and 93.21 % respectively, which is the best result compared to other methods.The effectiveness of the proposed method is further verified.},
  archive      = {J_ESWA},
  author       = {Cheng Zha and Weidong Min and Qing Han and Qi Wang and Di Gai and Hongyue Xiang},
  doi          = {10.1016/j.eswa.2025.129051},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129051},
  shortjournal = {Expert Syst. Appl.},
  title        = {Receptive field weighted representation and context enhancement for SAR ship detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Natural language processing and text mining in transportation: Current status, challenges, and future roadmap. <em>ESWA</em>, <em>296</em>, 129050. (<a href='https://doi.org/10.1016/j.eswa.2025.129050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transportation sector is generating and accumulating an increasing amount of unstructured data from a variety of sources. As a result, Natural Language Processing (NLP) and text mining are becoming critical for their capability to automatically process and interpret human language in transportation research. However, there is a lack of a thorough review of existing research in this field, as well as a detailed guide on how to use these techniques in transportation studies. This paper offers an updated review of NLP and text mining techniques, including the latest developments in Large Language Models (LLMs), tailored for comprehensive transportation modeling across land, maritime, and aviation sectors. It highlights the data sources and methodologies used in previous studies, provides an analysis of word representation, sentiment analysis, external NLP toolkits, language diversity, and performance evaluation, and offers insights into performance analysis for transportation research. The paper concludes by outlining the current challenges and future directions for research in this area.},
  archive      = {J_ESWA},
  author       = {Xiaocai Zhang and Ruobin Gao and Zhe Xiao and Ke Wang and Tao Liu and Maohan Liang and Jianjia Zhang},
  doi          = {10.1016/j.eswa.2025.129050},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129050},
  shortjournal = {Expert Syst. Appl.},
  title        = {Natural language processing and text mining in transportation: Current status, challenges, and future roadmap},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A stable self-organized spatial pooling algorithm for hierarchical temporal memory. <em>ESWA</em>, <em>296</em>, 129049. (<a href='https://doi.org/10.1016/j.eswa.2025.129049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Temporal Memory (HTM) is an emerging neural network technology that is inspired by the structure and the working principles of the human neocortex. HTM uses a set of active columns to represent input data and inhibits frequently activated columns by a boosting mechanism. However, a fixed number of columns are typically used in learning and the boosting mechanism may cause an unstable input representation. To address these issues, we propose a stable self-organized spatial pooling algorithm for HTM, where the learning columns are self-organized according to the input, and the column loadability is introduced and used for stable column activation. The extensive experiments are carried out on both the synthetic and real-world datasets to evaluate the effectiveness of the proposed method. The results demonstrate that the proposed HTM can automatically choose the learning columns according to the input and keep stable feature representation. It outperforms the conventional HTM as well as LSTM in terms of prediction accuracy and training efficiency on the tested configurations and tasks.},
  archive      = {J_ESWA},
  author       = {Dejiao Niu and Xudong Wu and Tao Cai and Yuxuan Yang and Lei Li and Jie Jiang and Yuhan Chen},
  doi          = {10.1016/j.eswa.2025.129049},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129049},
  shortjournal = {Expert Syst. Appl.},
  title        = {A stable self-organized spatial pooling algorithm for hierarchical temporal memory},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced speaker-turn aware hierarchical model for automated classroom dialogue act classification. <em>ESWA</em>, <em>296</em>, 129047. (<a href='https://doi.org/10.1016/j.eswa.2025.129047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue act classification (DAC) is a pivotal task in natural language processing, providing deep insights into communication patterns. In classroom settings, analyzing dialogues and delivering timely feedback play a crucial role in improving teaching practices and fostering effective educational interactions. Traditional manual classroom observation is both costly and prone to bias, underscoring the need for automated dialogue analysis. However, recent automated classroom DAC often neglect the importance of speaker turns. To address this gap, we propose the Speaker-Turn Aware Hierarchical Model (SA-DAC), which leverages speaker embeddings to enrich contextual understanding and improve classification accuracy. We further introduce a new benchmark dataset, IRE-9, designed around the initiate-response-evaluate (IRE) encoding framework, to advance research in dialogue analysis. Comprehensive experiments demonstrate that SA-DAC surpasses state-of-the-art methods, delivering superior accuracy and scalability. Moreover, we develop an automated classroom analysis system powered by SA-DAC, which generates detailed, multi-dimensional reports to assist educators in improving their teaching strategies.},
  archive      = {J_ESWA},
  author       = {Linzhao Jia and Han Sun and Jialong Jiang and Xiaozhe Yang},
  doi          = {10.1016/j.eswa.2025.129047},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129047},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced speaker-turn aware hierarchical model for automated classroom dialogue act classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ESOD-YOLOv8: Small object detection enhanced with auto-disturbance rejection convolution. <em>ESWA</em>, <em>296</em>, 129046. (<a href='https://doi.org/10.1016/j.eswa.2025.129046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small objects are significantly disturbed by the background and prone to losing features during the sampling process. To address these problems, we propose an optimization method of YOLOv8 based on Auto-Disturbance Rejection Convolution (ADRConv). Firstly, we design a new ADRConv, which uses the quadratic central difference to extract small target features and combines ordinary convolution to represent the effective background. Subsequently, we construct a feature extraction selector within the YOLOv8 network, and the activation strategy function controls the difference operation to ensure a balanced representation of object features and background. ADRConv is also applied to enhance the feature fusion network of the YOLOv8 structure, addressing the challenge of feature loss associated with small objects. The experimental results show that compared with YOLOv8 benchmark algorithm and mainstream methods in recent years, the precision of this proposed method is increased by 4.3 % and 2.6 %, the recall rate is increased by 7.5 % and 0.9 %, and the average detection accuracy is improved by 3.9 % and 1.3 %, which effectively enhances the detection effect of small targets.},
  archive      = {J_ESWA},
  author       = {Zhenhua Yu and Huize Liang and Ou Ye and Yun Zhang},
  doi          = {10.1016/j.eswa.2025.129046},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129046},
  shortjournal = {Expert Syst. Appl.},
  title        = {ESOD-YOLOv8: Small object detection enhanced with auto-disturbance rejection convolution},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum metabolic avatar: A digital replica of metabolism enhanced by quantum algorithms. <em>ESWA</em>, <em>296</em>, 129045. (<a href='https://doi.org/10.1016/j.eswa.2025.129045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of quantum computing (QC) into predictive modeling represents a transformative advancement in machine learning, providing substantial improvements over traditional methods. This study compares classical Echo State Networks (ESN) with quantum Echo State Networks (qESN) for time-series forecasting, emphasizing the concept of a metabolic avatar—a dynamic data-driven model of individual metabolic processes. Utilizing time-series data from six distinct users, we assessed both models’ precision and adaptability through Root Mean Squared Error (RMSE). Our results demonstrate consistent superiority of qESN over classical ESN, highlighted by a 30% RMSE reduction during cross-validation (CV). Notably, qESN showed remarkable stability and accuracy even with limited training data, underscoring its effectiveness in data-sparse scenarios. Furthermore, we examined model performance in datasets containing outliers. QESN significantly outperformed classical ESN, achieving approximately 76% lower RMSE in CV and about 55% lower RMSE in walk-forward validation (WFV). This demonstrates qESN’s enhanced robustness and reduced susceptibility to overfitting. Crucially, our findings highlight the Quantum Metabolic Avatar’s (QMA) profound potential for personalized predictive analytics, essential for applications in personalized healthcare and customized wellness programs. The study strongly supports integrating quantum algorithms into predictive modeling, marking a pivotal advancement towards highly personalized and dynamic metabolic avatars.},
  archive      = {J_ESWA},
  author       = {A. Abeltino and C. Serantoni and M.M. De Giulio and A. Riente and S. Capezzone and R. Esposito and M. De Spirito and G. Maulucci},
  doi          = {10.1016/j.eswa.2025.129045},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129045},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum metabolic avatar: A digital replica of metabolism enhanced by quantum algorithms},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-driven multimodal fusion for image motion deblurring. <em>ESWA</em>, <em>296</em>, 129044. (<a href='https://doi.org/10.1016/j.eswa.2025.129044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional frame-based cameras are susceptible to non-uniform blurring in real-world scenarios due to their inherent “frame” imaging method. In contrast, bio-inspired event cameras can capture changes in pixel brightness similar to the human eye, recording motion changes in the scene with extremely high temporal resolution, effectively addressing the issue of motion blur. In this paper, we present an Event-Driven Multimodal Fusion (EDMF) deblurring network, which utilizes event data to remove blur and achieve clear, high-quality image restoration. To facilitate the fusion of the two modalities, we first design a Deep Spatio-temporal Event (DSE) voxel grid specifically for deblurring with event cameras, effectively leveraging event information. Our deblurring network initially extracts high-frequency information from images through frequency separation. It then employs a specially designed Event-Image multimodal High-frequency Enhancement (EIHE) module to integrate this information with event data, restoring sharp and clear edges in the images. Compared to other state-of-the-art methods, the proposed EDMF demonstrates outstanding performance, including exemplary visual quality and excellent preservation of fine texture details. The source code and dataset are openly accessible at https://github.com/ice-cream567/EDMF .},
  archive      = {J_ESWA},
  author       = {Guangsha Guo and Shilong Jing and Yuchen Zhao and Hengyi Lv and Yisa Zhang and Yang Feng},
  doi          = {10.1016/j.eswa.2025.129044},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129044},
  shortjournal = {Expert Syst. Appl.},
  title        = {Event-driven multimodal fusion for image motion deblurring},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature enrichment imitative reinforcement learning for high-frequency trading. <em>ESWA</em>, <em>296</em>, 129043. (<a href='https://doi.org/10.1016/j.eswa.2025.129043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) requires rapid, adaptive decision-making in volatile markets, yet balancing exploration (discovering new profitable strategies) and exploitation (capitalizing on known opportunities) remains challenging. We introduce a novel tIRDPG-LID, a twin-imitation recurrent deterministic policy gradient model that learns from imperfect demonstrations, to address partial observability and overestimation bias in feature-scarce HFT scenarios. Our approach enriches the feature space via feature interpolation to mitigate the scarcity typical in HFT, then uses a trajectory discrimination mechanism and dynamic weighting to integrate and filter imperfect demonstration data. The trajectory discrimination mechanism compares each demonstration’s performance to the agent’s current returns and only emphasizes those expert actions that yield a positive advantage. Simultaneously, twin critics with delayed actor updates stabilize training under high volatility, reducing estimation errors and excessive risk. We provide a rigorous theoretical framework based on data entropy, showing how enriched features improve agent performance under partially observable conditions. Empirical evaluations on large-scale CSI 300 (IF) and CSI 500 (IC) futures confirm that tIRDPG-LID statistically significantly outperforms standard baselines by consistently delivering higher returns and improved risk adjusted metrics. Beyond HFT, the ability of the method to fuse imperfect demonstrations, mitigate overestimation bias, and adapt in real time suggests a wider applicability in other domains where data are scarce or partially observed. By uniting twin critics, imitation learning, and feature-space enrichment under a formal theoretical lens, tIRDPG-LID not only provides a novel solution for Fintech practice, but also extends deep reinforcement learning techniques more generally.},
  archive      = {J_ESWA},
  author       = {Fei Han and Qinghua Ling and Sheng Lu and Henry Han},
  doi          = {10.1016/j.eswa.2025.129043},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129043},
  shortjournal = {Expert Syst. Appl.},
  title        = {Feature enrichment imitative reinforcement learning for high-frequency trading},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-level reinforcement learning based regulation strategy for dynamic operation of O2O service ecosystems. <em>ESWA</em>, <em>296</em>, 129042. (<a href='https://doi.org/10.1016/j.eswa.2025.129042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, traditional service systems are transforming into service ecosystems where numerous agents collaborate and operate jointly. As the complexity of service ecosystems increases, regulation strategies are introduced to optimize their overall performance. During the regulation process, the autonomy of the agents being regulated leads to a dynamic game situation between the regulation strategies and the regulated objects. However, existing regulation strategies overlook the aforementioned autonomy of regulated objects, which consequently leads to the failure of these strategies. To address this issue, this paper proposes a dynamic regulation strategy design approach based on two-level reinforcement learning. Firstly, decision-making networks are constructed to model the decision-making processes of regulation strategies and regulated objects. Subsequently, the dynamic game relationship between regulation strategies and regulated objects is modeled through two-level reinforcement learning. Finally, a computational experiment system is constructed based on real-world O2O (Online to Offline) food delivery platforms. Experiments show that the average individual efficiency and system efficiency of the experiment system are increased by 27.58 % and 31.55 % after applying the proposed regulation strategy.},
  archive      = {J_ESWA},
  author       = {Gang Wang and Xiaowei Liu and Yifan Shen and Deyu Zhou and Ming Zhang and Xiao Xue},
  doi          = {10.1016/j.eswa.2025.129042},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129042},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-level reinforcement learning based regulation strategy for dynamic operation of O2O service ecosystems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BoostCount: Diffusion-based position-sensitive adversarial purification for crowd counting. <em>ESWA</em>, <em>296</em>, 129041. (<a href='https://doi.org/10.1016/j.eswa.2025.129041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks on critical regions in dense crowd counting critically undermine model security. Current defenses struggle to precisely reconstruct sensitive areas without sacrificing image fidelity, and adversarial examples as generative conditions remain under-explored. To address the security threats posed by adversarial attacks targeting key regions in dense crowd counting, this paper proposes a conditional diffusion-based adversarial purification framework, named BoostCount. The developed BoostCount first employs a pre-trained counting network to generate dynamic masks, guiding position-sensitive adversarial attacks to concentrate perturbations in crowded regions. These adversarial examples then serve as conditional inputs to a diffusion model, for the first time validating their efficacy as generative conditions in crowd counting. The core design of BoostCount is to reformulate the adversarial defense for crowd counting to the image-to-image domain transition between clean samples and adversarial samples through progressive restoration to realize purification, where the perturbation patterns in sensitive regions provide crucial learning signals. Experiments demonstrate that the developed method significantly enhances robustness (at most − 465.00 MAE and − 549.92 RMSE) while preserving visual-semantic consistency. The developed framework offers a reliable adversarial purification solution for intelligent surveillance and related scenarios.},
  archive      = {J_ESWA},
  author       = {Yiru Du and Linya Huang and He Li and Weihang Kong},
  doi          = {10.1016/j.eswa.2025.129041},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129041},
  shortjournal = {Expert Syst. Appl.},
  title        = {BoostCount: Diffusion-based position-sensitive adversarial purification for crowd counting},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data protection and efficient transmission for smart healthcare: An RDHEI approach based on LZW compression and composite key mechanism. <em>ESWA</em>, <em>296</em>, 129040. (<a href='https://doi.org/10.1016/j.eswa.2025.129040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the swift advancements in the Internet of Medical Things (IoMT), medical personnel can effectively store, transmit and analyze patients’ electronic health records through telemedicine, but personal health data faces risks of loss, theft, and cyberattacks. Reversible Data Hiding (RDH) is a crucial method for information protection. To address challenges of existing hiding algorithms based on free space focusing on security and embedding capacity, the paper proposes a data security and efficient encryption model for smart healthcare, along with an innovative Reversible Data Hiding in Encrypted Image (RDHEI) scheme. This scheme first optimizes data embedding by customizing the edge-baseline differential image preprocessing method and combining it with the Lempel-Ziv-Welch (LZW) compression characteristics. Secondly, a composite key mechanism is introduced to embed private information and encrypt steganographic images respectively to solve the problem of insufficient security. In particular, the proposed scheme is lossless and can support selective synchronous recovery of data according to the receiver’s permissions. The proposed scheme achieves an average embedding capacity of up to 2.7 bpp, with a PSNR of Inf and an SSIM of 1 for the recovered images. The maximum information entropy reaches 7.9978, and the MSE is 18059.98. Experimental results demonstrate that the proposed strategy surpasses existing RDHEI approaches for improving embedding ability and security. Meanwhile, through faster embedding and encryption processing speeds, this model can be effectively applied to efficient transmission and secure storage of images in smart healthcare, providing strong support for the secure exchange of medical information.},
  archive      = {J_ESWA},
  author       = {Zhenlong Man and Shuping Li},
  doi          = {10.1016/j.eswa.2025.129040},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129040},
  shortjournal = {Expert Syst. Appl.},
  title        = {Data protection and efficient transmission for smart healthcare: An RDHEI approach based on LZW compression and composite key mechanism},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Illuminating the shadows: Enhanced low-light image via a retinex-based model with color equalization. <em>ESWA</em>, <em>296</em>, 129039. (<a href='https://doi.org/10.1016/j.eswa.2025.129039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lowlight images typically encounter low visibility and contrast as well as blurry details. However, most existing low-light image enhancement (LLIE) methods introduce observable color casts and unnatural-looking visibility. To address these challenges, we propose a feasible LLIE method, named RCE . Specifically, a feature hybridization attention module (FHAM) with over-lapping cross attention block and window-based self-attention strategy is developed to explore the semantic spatial relationship of pixels for generating artifact-free illumination and reflection components. We also carefully design a light enhancement module (LEM) and a denoising module (EM) to refine these two components. Meanwhile, we employ a carefully designed gate recurrent unit (GRU) and color equalization module (CEM) to balance light enhancement and color correction. Our RCE can generate comparable PSNR/SSIM/LPIPS scores for the LOL v1 and MIT-Adobe 5K datasets, whose scores are 24.74/0.8755/0.0946 and 24.91/0.9072/0.0429 respectively, benefiting from our carefully designs. Extensive experiments demonstrate that our RCE outperforms state-of-the-art methods in qualitatively and quantitatively assessments for LLIE task. Furthermore, our RCE shows the potential benefits to object detection in the lowlight condition.},
  archive      = {J_ESWA},
  author       = {Zhenbing Liu and Tao Fan and Weidong Zhang and Wenhao Wang and Jieyu Huang and Rushi Lan and Haoxiang Lu},
  doi          = {10.1016/j.eswa.2025.129039},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129039},
  shortjournal = {Expert Syst. Appl.},
  title        = {Illuminating the shadows: Enhanced low-light image via a retinex-based model with color equalization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Biologically inspired energy-balanced clustering routing optimization for wireless sensor networks. <em>ESWA</em>, <em>296</em>, 129038. (<a href='https://doi.org/10.1016/j.eswa.2025.129038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) face significant challenges because of the restricted energy of sensors and unreliable quality of service. The clustering routing problem demands energy-efficient solutions to balance the energy cost of nodes and enhance network performance. In this paper, a novel chaotic genetic artificial bee colony optimization-based energy-balanced clustering routing algorithm (CGABCO-ECRA) is proposed, which can effectively prolong the lifetime, reduce the transmission delay, enhance the throughput, and balance the energy cost of nodes in WSNs. Different from the existing clustering methods, such as GA, ABC, and GAPSO, a new chaos generator and a new genetic mutation operator in CGABCO-ECRA are designed, which can significantly improve the quality of solutions, raise the convergence speed and decrease the probability of the population falling into a local optimum. In addition, a new clustering routing model is designed, which accurately represents the communication scenarios of WSNs. Moreover, an objective function is devised, which considers four factors: intra-cluster distance, base station distance, transmission delay, and the remaining energy of nodes. Simulation experiments compare CGABCO-ECRA with LEACH, I-SEP, and OptGACHE in different scenarios to solve the clustering routing problem. Results indicate that CGABCO-ECRA outperforms these existing algorithms by at least 15.25 % in lifetime, 37.47 % in throughput, 17.57 % in delay, and effectively balances energy cost, respectively.},
  archive      = {J_ESWA},
  author       = {Mengying Xu and Yunxiao Zu and Jie Zhou and Yang Liu and Chaoqun Li},
  doi          = {10.1016/j.eswa.2025.129038},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129038},
  shortjournal = {Expert Syst. Appl.},
  title        = {Biologically inspired energy-balanced clustering routing optimization for wireless sensor networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Carbon emission quota allocation for 280 chinese cities: Integrating machine learning and DEA with regional heterogeneity. <em>ESWA</em>, <em>296</em>, 129036. (<a href='https://doi.org/10.1016/j.eswa.2025.129036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cities, as major contributors to global carbon emissions, play a pivotal role in achieving carbon-emission reduction and socioeconomic sustainability. Developing an equitable and effective Carbon Emission Quota Allocation (CEQA) approach at the urban level is essential for advancing global climate governance. In China, regional heterogeneity results in significant variations in carbon emissions across cities, necessitating the grouping of cities based on these differences before the allocation of Carbon Emission Quotas (CEQs). Thus, we combine machine learning with the Directional Distance Function (DDF) to assess urban technological differences, which define regional heterogeneity and serve as the foundation for grouping cities and evaluating their Carbon Emission Efficiency (CEE). CEQs are initially allocated to groups according to their levels of economic development and emission-reduction potential. We then apply an improved Data Envelopment Analysis-based Centralized Allocation (DEA-CA) model to reallocate CEQs within each group. We conduct a case study using data from 280 Chinese cities. The research results indicate that (1) grouping cities not only brings them closer to the technology frontier within their respective groups than to the global benchmark, but also reveals an overall economic gradient correlation across the cities, thereby confirming the validity of the grouping; (2) groups with lower performance can reduce emissions by sequentially improving according to separation variables, without altering external technological factors; and (3) the allocation appropriately balances historical emissions and reduction potential, with adjustments closely linked to historical emissions, economic development, and technological expenditures. This research represents a novel application of a machine learning-based endogenous grouping method to CEQA, yielding significant improvements in equity.},
  archive      = {J_ESWA},
  author       = {Rui Luo and Nengmin Wang},
  doi          = {10.1016/j.eswa.2025.129036},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129036},
  shortjournal = {Expert Syst. Appl.},
  title        = {Carbon emission quota allocation for 280 chinese cities: Integrating machine learning and DEA with regional heterogeneity},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EFT6D: An efficient fusion transformer network for 6D object pose estimation. <em>ESWA</em>, <em>296</em>, 129035. (<a href='https://doi.org/10.1016/j.eswa.2025.129035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, leveraging complementary multimodal information to estimate object poses from RGB-D images has gained widespread attention, demonstrating significant improvements in performance. Early methods primarily focus on the correspondence between RGB and depth images, extracting texture and geometric features separately and then simply concatenating them for fusion, which exacerbates the negative impact of redundant background and noise during multimodal fusion. To address these challenges, we introduce EFT6D, which harnesses semantic similarity across modalities to more effectively integrate globally augmented fused features. The additive attention mechanism we introduced eliminates the need for key-value interactions, reducing computational complexity and significantly improving model efficiency and performance. At the same time, we adopt an augmented shortcut connection to further improve the model performance. Experimental results on the LineMOD, Occlusion-LineMOD, and YCB-Video datasets show that EFT6D markedly improves pose estimation accuracy while maintaining real-time inference capabilities. Finally, we apply EFT6D to real-world object pose estimation and grasping experiments, demonstrating the effectiveness of our method.},
  archive      = {J_ESWA},
  author       = {Mingwei Zhang and Tao Xie and Yu Fang and Xizhe Zang and Jie Zhao and Xuehe Zhang},
  doi          = {10.1016/j.eswa.2025.129035},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129035},
  shortjournal = {Expert Syst. Appl.},
  title        = {EFT6D: An efficient fusion transformer network for 6D object pose estimation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained graph domain adaptation via instance contrastive learning. <em>ESWA</em>, <em>296</em>, 129034. (<a href='https://doi.org/10.1016/j.eswa.2025.129034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph domain adaptation (GDA) aims to transfer knowledge from labeled source graphs to unlabeled target graphs, enhancing model generalization across different graph domains. Most existing GDA methods focus on learning consistent graph representations by reducing the discrepancy across domains. However, these methods tend to facilitate only coarse-grained knowledge transfer and often sacrifice instance-level discrepancy across domains as well as discriminability within domains. To address these challenges, we propose a novel methodology named F ine- G rained G raph D omain A daptation (FGGDA). Our method designs a dual-scale shift node embedding module to mitigate data discrepancy across source and target domains caused by graph structural complexity, effectively enabling node embeddings. In addition, we propose an instance contrastive alignment strategy designed to facilitate fine-grained GDA. This strategy aims to minimize discrepancy within the same category and maximize discrepancy between different categories, so that nodes within the same category are tightly aligned, while nodes from different categories are clearly separated, irrespective of their domain origin. Comprehensive experiments on multiple real-world datasets show that FGGDA outperforms the latest baseline models, with relative ranging from 2.17% to 8.2% across eight cross-graph node classification tasks.},
  archive      = {J_ESWA},
  author       = {Shengyue Liu and Haijia Bi and Lu Liu and Niya Yang and Tao Peng},
  doi          = {10.1016/j.eswa.2025.129034},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129034},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained graph domain adaptation via instance contrastive learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Super-resolution reconstruction of side-scan sonar images based on texture consistency. <em>ESWA</em>, <em>296</em>, 129033. (<a href='https://doi.org/10.1016/j.eswa.2025.129033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influenced by the measurement mechanism, the marine environment, and other factors, side-scan sonar images often exhibit high noise levels and low resolution. This presents significant challenges for high-resolution underwater topography imaging and small-scale target detection. To address this, this paper proposes a super-resolution reconstruction method for side-scan sonar images based on a diffusion model and texture consistency. Firstly, based on the imaging mechanism of side-scan sonar, the seafloor reverberation model is introduced to establish the degradation mechanism for underwater acoustic images. Next, a feature bootstrap module is developed to integrate low-resolution image and texture features, projecting them into a potential semantic space. Finally, through multiple iterations of the diffusion model, guidance information at different scales is incorporated into the generation process. This enables the reconstruction of target contours, edge features, and high-frequency details at various iteration stages. As a result, texture-consistent, high-quality side-scan sonar images are obtained. Experimental results demonstrate that the proposed algorithm outperforms the comparison methods in both subjective visual effects and objective evaluation metrics. Among them, the FID scores reached 106.66, 117.27, and 148.41, respectively. In addition, we conducted SSS pipeline target segmentation experiments and large-area georeferenced image reconstruction experiments, further verifying the feasibility and effectiveness of the proposed method in practical tasks such as SSS target detection, large-area topographic surveys, and high-resolution imaging. The source code is available at: https://github.com/Yang-Code984/Sonar-super-resolution-main .},
  archive      = {J_ESWA},
  author       = {Zhiwei Yang and Jianhu Zhao and Xi Zhao and Chao Huang},
  doi          = {10.1016/j.eswa.2025.129033},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129033},
  shortjournal = {Expert Syst. Appl.},
  title        = {Super-resolution reconstruction of side-scan sonar images based on texture consistency},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximizing mutual information across knowledge graphs for robust entity alignment. <em>ESWA</em>, <em>296</em>, 129031. (<a href='https://doi.org/10.1016/j.eswa.2025.129031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs can enhance machine learning models with information about relations between entities, which is of interest in the development of artificial intelligence systems. Since a single KG is generally incomplete, entity alignment is an important task to improve the integrity of knowledge from different KGs. However, current methods mainly leverage the information stored in the single KG, obtaining the entity embeddings to compute their relatedness, regardless of the information transferred across different KGs. Actually, the semantic of the knowledge graphs is usually complementary in the task of entity alignment, which can contribute to the performance improvement. In this paper, we propose a novel method by maximizing mutual information (MI) across knowledge graphs for robust embedding learning and entity alignment. Specifically, we first learn the entity embeddings by aggregating its attribute or relational neighbors based on the attention mechanisms. Then we introduce a contrastive MI estimator that measures the dependency between KGs from their attribute and relational structure, respectively. By optimizing the estimator, we can maximize MI across KGs, enriching the semantic of the entities. Experimental results show that our proposal outperforms the state-of-the-art methods, and demonstrate its potential and robustness when dealing with the absence of attribute or relational neighbors.},
  archive      = {J_ESWA},
  author       = {Ao Gao and Mingda Li and Wei Liu and Zhengya Sun and Neng Wan},
  doi          = {10.1016/j.eswa.2025.129031},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129031},
  shortjournal = {Expert Syst. Appl.},
  title        = {Maximizing mutual information across knowledge graphs for robust entity alignment},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPANet: Curve-like structure segmentation based on dual-path attention network. <em>ESWA</em>, <em>296</em>, 129030. (<a href='https://doi.org/10.1016/j.eswa.2025.129030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curve-like structure segmentation has wide applications in computer vision, medical image analysis, and industrial fields. However, achieving complete segmentation of curve-like structures remains challenging due to complex background interference. Methods based on global features tend to ignore local details, while methods based on local features often fail to maintain topological correctness, resulting in fragmented segmentation results. In this work, we propose DPANet, a simple and powerful framework for segmenting curve-like structures. We design a Global Multi-branch Attention (GMBA) module that captures cross-dimensional interactive information to enhance segmentation accuracy in complex scenes. We develop a Local Multi-layer Convolution (LMLC) module that effectively preserves structural continuity through local detail extraction. Finally, we develop a Differential Feature Enhancement (DFE) module for compensating for the loss of multi-scale feature information, refining intermediate feature representations, and enhancing the network’s ability to capture fine-grained details and structural boundaries. We conducted qualitative and quantitative experiments on five datasets (Yarn Hairiness, DRIVE, XCAD, CrackTree200, and Crack500). The experimental results demonstrate that DPANet achieves superior performance in the segmentation task of complex curve-like structures, and effectively addresses the continuity issues in curve-like structures segmentation.},
  archive      = {J_ESWA},
  author       = {Pengsheng Song and Huanhuan Zhang and Junfeng Jing and Pengfei Li and Quan Pan},
  doi          = {10.1016/j.eswa.2025.129030},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129030},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPANet: Curve-like structure segmentation based on dual-path attention network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing energy efficiency in wireless sensor networks via predictive model for node status classification and coverage integrity using relational bi-level aggregation graph convolutional network. <em>ESWA</em>, <em>296</em>, 129029. (<a href='https://doi.org/10.1016/j.eswa.2025.129029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Wireless Sensor Networks (WSN), target coverage optimizes resources and energy but leave areas unmonitored, affecting coverage and reliability. This manuscript proposes WSN-NCS-RBAGCN, a predictive model designed to optimize energy efficiency and maintain coverage integrity in WSNs. The method classifies node status to improve energy efficiency, enhance network performance and ensure reliable communication while minimizing energy consumption. Initially, the data is gathered from the simulated network environment is fed into the preprocessing stage using an Implicit Unscented Particle Filter (IUPF), which removes noise and enhances the reliability of the data received from the sensor nodes. The preprocessed data is then input into a Relational Bi-level Aggregation Graph Convolutional Network (RBAGCN) to predict node status and classify nodes into active or sleep states to optimize energy use. The Mountain Gazelle Optimizer (MGO) is used to optimize RBAGCN parameters for efficient node status prediction. The effectiveness of WSN-NCS-RBAGCN is evaluated in Python. The proposed approach attained100% higher accuracy 100% higher F1 score and 0.08% low error rate when analysed to the existing methods such as Node Position Estimation based on Optimal Clustering and Detection of Coverage Hole in Wireless Sensor Networks using Hybrid Deep Reinforcement Learning (CH-WSN-HDRL), machine learning approach to predict k-coverage probability in wireless multihop networks considering boundary and shadowing effects (KC-WMN-GRNN) and Coverage Hole Aware Optimal Cluster-based Routing for Wireless Sensor Networks Assisted IoT using Hybrid Deep Recurrent Neural Network (WSN-IoT-HDRNN), the proposed method significantly improves energy efficiency, coverage integrity.},
  archive      = {J_ESWA},
  author       = {S.U. Suganthi and N. Umapathi and N. Venkateswaran and S. Rajarajan},
  doi          = {10.1016/j.eswa.2025.129029},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129029},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing energy efficiency in wireless sensor networks via predictive model for node status classification and coverage integrity using relational bi-level aggregation graph convolutional network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Augmentation-free dynamic graph contrastive learning based on transformers. <em>ESWA</em>, <em>296</em>, 129028. (<a href='https://doi.org/10.1016/j.eswa.2025.129028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on dynamic graph representation learning has garnered increasing attention due to the rich information embedded in dynamic graphs and their extensive real-world applications. Self-supervised learning, particularly graph contrastive learning, is emerging as a key approach for processing dynamic graph data. Existing graph contrastive learning methods predominantly rely on data augmentation to generate positive and negative samples from different perspectives. However, in dynamic graphs, where data structures and features evolve, traditional augmentation techniques may distort temporal dynamics, leading to graph structures or features that do not align with the actual evolutionary patterns at a given timestamp. This distortion compromises data integrity and hinders the model’s ability to learn accurate representations. To alleviate this problem, this paper introduces an A ugmentation- F ree d ynamic g raph c ontrastive learning framework (AFdgc) based on Transformers. The proposed model emphasizes contrastive learning by leveraging the original graph data, thereby mitigating noise and data degradation caused by augmentation processes. First, AFdgc encodes graph data using graph Transformers with a temporal attention mechanism. It dynamically adjusts the multi-scale patch size based on interaction frequency to capture dynamics at different time scales. Subsequently, positive samples are selected using a nearest-neighbor interaction frequency optimization approach to maintain dynamic diversity, and contrastive learning is performed by maximizing mutual information. Extensive experiments on benchmark datasets for dynamic link prediction demonstrate the superior performance of the proposed model compared to state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Mingrui Zhu and Liqing Qiu and Weidong Zhao},
  doi          = {10.1016/j.eswa.2025.129028},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129028},
  shortjournal = {Expert Syst. Appl.},
  title        = {Augmentation-free dynamic graph contrastive learning based on transformers},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantization-aware distributed deep reinforcement learning for dynamic multi-robot scheduling. <em>ESWA</em>, <em>296</em>, 129027. (<a href='https://doi.org/10.1016/j.eswa.2025.129027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent port logistics, container stevedoring operations confront escalating challenges in orchestrating fleets of robots, where real-time task scheduling must reconcile high-dimensional state spaces with stringent computational efficiency and dynamically evolving environments. Traditional approaches, categorized as exact methods and approximate metaheuristics, struggle to balance solution quality and real-time responsiveness as task complexity grows exponentially. While recent deep reinforcement learning (DRL) methods improve adaptability in dynamic settings, they suffer from high computational overhead and deployment latency, limiting their practicality in time-sensitive port operations. To address these limitations, this work proposes a distributed deep reinforcement learning (DDRL) framework. This framework leverages the independence between ports to perform action selection and decision-making in parallel, thereby alleviating computational pressure and enhancing operational efficiency. It is especially enhanced with a teammate collaboration model and a greedy MaxNextQ policy, which enables the network to identify and approach promising actions associated with increasing Q -values. To further enhance deployment efficiency, a quantization-aware training (QAT) method is introduced by adding pseudo-quantization nodes and thus reducing quantization-induced errors. The effectiveness of the proposed DDRL algorithm is validated through simulations under three distinct workload scenarios via varying the robot-to-port ratio. The simulation results demonstrate that, compared with centralized DRL approaches, the proposed approach achieves deployment rate improvements of 22.95%, 15.09%, and 23.37%, while simultaneously enhancing objective scores by 5.75%, 6.32%, and 7.05%.},
  archive      = {J_ESWA},
  author       = {Peng Song and Yichen Xiao and Kaixin Cui and Junzheng Wang and Dawei Shi},
  doi          = {10.1016/j.eswa.2025.129027},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129027},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantization-aware distributed deep reinforcement learning for dynamic multi-robot scheduling},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DECTUIL: Cross-social network user identity linkage via dynamic embedding and clustering model driven by three-way decision. <em>ESWA</em>, <em>296</em>, 129026. (<a href='https://doi.org/10.1016/j.eswa.2025.129026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User identity linkage (UIL) across social networks is a critical task for constructing unified user profiles and analyzing cross-platform behaviors, with applications in recommendation systems, user tracking, and sentiment analysis. However, existing UIL methods face significant limitations: classical embedding techniques struggle to adapt to the diverse ways user information is associated, while prediction models often rely on single-round outputs, leading to performance bottlenecks in complex scenarios. To address these challenges, this study propose the dynamic embedding and clustering model driven by three-way decision (DECTUIL), a novel unsupervised framework for cross-social-network UIL. DECTUIL introduces a dynamic embedding module, which uses semantic factors to adaptively choose between embedding functions. This design allows the model to capture literal, semantic, and thematic features effectively. Additionally, a vector smoothing algorithm minimizes information entropy to address attribute sparsity caused by inconsistent user information disclosure. Furthermore, DECTUIL innovatively integrates three-way decision theory with K -Means clustering, enabling iterative refinement of clustering results and achieving multi-round prediction capabilities. Extensive experiments on three real-world datasets demonstrate that DECTUIL significantly outperforms state-of-the-art unsupervised methods, improving hit-precision by 6.67 % to 20.25 %. Compared to fully trained supervised methods(using 70 % of the dataset), DECTUIL achieves improvements of 5.5 % to 15.5 % in hit-precision, highlighting its effectiveness and robustness in cross-platform user identity linkage tasks.},
  archive      = {J_ESWA},
  author       = {Yongqiang Peng and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.eswa.2025.129026},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129026},
  shortjournal = {Expert Syst. Appl.},
  title        = {DECTUIL: Cross-social network user identity linkage via dynamic embedding and clustering model driven by three-way decision},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing knowledge-based question answering with dense passage retrieval-based scaled momentum contrastive learning. <em>ESWA</em>, <em>296</em>, 129025. (<a href='https://doi.org/10.1016/j.eswa.2025.129025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-Based Question Answering (KBQA) systems use Knowledge Bases (KBs) to provide accurate and specific answers by querying data sources. Although the quality of the data in existing KBs is good, the coverage may be under-resourced or incomplete. This results in the low performance for the KBQA systems. On the other hand, the unstructured data has more coverage but suffers from a lack of quality. The unstructured text data is augmented with the existing KBs to improve the coverage of KBs. However, this approach is insufficient to address the performance-related challenges in the existing KBQA systems. In particular, the KBQA systems fall short of distinguishing between complex QA pairs, particularly cases with correct answers that are hard to recognize (hard-positives) and incorrect answers that closely resemble correct ones (hard-negatives). In order to effectively differentiate between hard contrastive pairs, we introduce a novel method that uses Dense passage retrieval along with the Normalized Temperature scaled screening-based Momentum Contrast (NT-sMoCo) learning approach. This method is applied to augmented datasets that utilize contrastive learning. We conducted experiments on the WebQuestionsSP (WebQSP) dataset using coverage levels of 30 %, 50 %, 70 %, and 100 % with various test queries. We obtained a Hits@1 of 50.3 %, 63.4 %, 69.7 %, 77.3 % and F 1 -scores of 33.1 %, 46.2 %, 60.4 %, 65.3 % for 30 %, 50 %, 70 %, and 100 % KB coverage, respectively. The results show a improvement of 7.9 % for Hits@1 and 8 %, for F 1 -scores across the KB coverage over the best existing model in the literature. We also performed experiments on the GrailQA dataset at 100 % KB and obtained EM (Exact Match) and F 1 -scores of 69.2 % and 75.1 %, respectively. The results show an improvement of 0.6 % for EM, and 0.9 % for F 1 -score respectively, over the existing models as per the literature. Therefore, the experimental results show that the proposed approach performs better in retrieving relevant answers than the existing KBQA approaches.},
  archive      = {J_ESWA},
  author       = {Sudarshan Yerragunta and Rajendra Prasath and G.N. Girish},
  doi          = {10.1016/j.eswa.2025.129025},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129025},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing knowledge-based question answering with dense passage retrieval-based scaled momentum contrastive learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Act-LLM: A whole-process chain for character-centric role-playing with large language models. <em>ESWA</em>, <em>296</em>, 129024. (<a href='https://doi.org/10.1016/j.eswa.2025.129024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models have revolutionized character role-playing by generating contextually rich text, yet existing approaches often overlook critical aspects of knowledge boundaries and memory integration. This paper introduces Act-LLM, a whole-process chain for character-centric role-playing, spanning from data construction to model training and interactive dialogue. First, we propose a semi-automated character data construction pipeline that systematically collects multi-dimensional character information through agent-assisted data collection and structured knowledge extraction, overcoming reliance on copyrighted materials. Second, our model training phase synergizes parameter-efficient fine-tuning with direct preference optimization to shape both personality traits and strict knowledge boundaries, ensuring characters respond consistently within historical or fictional constraints. Finally, the dialogue process integrates a dual-term memory mechanism: long-term memory retrieves biographical details from a structured database, while short-term memory maintains contextual coherence across interactions, dynamically updated via a planning module. Experiments demonstrate that Act-LLM achieves higher character consistency and fewer knowledge hallucinations compared to baseline methods, effectively balancing personality authenticity with cognitive plausibility.},
  archive      = {J_ESWA},
  author       = {Xiaoxu Han and Wanqing Zhao and Ziyu Guan and Jinye Peng},
  doi          = {10.1016/j.eswa.2025.129024},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129024},
  shortjournal = {Expert Syst. Appl.},
  title        = {Act-LLM: A whole-process chain for character-centric role-playing with large language models},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new method for bearing remaining useful life prediction based on dynamic wavelet and physical information constraints. <em>ESWA</em>, <em>296</em>, 129023. (<a href='https://doi.org/10.1016/j.eswa.2025.129023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of bearing remaining useful life (RUL) in mechanical systems represents a pivotal challenge for enabling reliable operational maintenance. In recent years, RUL prediction methods fusing physical mechanisms with deep learning have shown significant potential, but still exhibit significant limitations in terms of dynamic adaptation when dealing with strong nonlinear degradation feature extraction of bearings. In addition, model stability is not always guaranteed due to the lack of deeply fused physical information. To address these issues, this study introduces a hybrid RUL prediction framework that synergizes dynamic signal processing with physics-informed learning. Initially, a dynamically differentiable wavelet decomposition module is proposed, which supersedes conventional wavelet bases by implementing an adaptive filter bank architecture with dynamic parameter tuning, enabling multi-scale dynamic analysis of vibration signals. The module incorporates a dual-channel enhancement mechanism to amplify localized low-frequency features while integrating frequency-domain gated filtering to mitigate high-frequency noise interference. Subsequently, a bidirectional adaptive graph convolutional network is developed to model spatiotemporal interdependencies within multi-scale degradation features, employing learnable adjacency matrices to dynamically characterize evolving correlation patterns during bearing deterioration. Finally, a dual-constrained physical information loss function is introduced, which enhances the stability and accuracy of RUL prediction by integrating physical principles into model training. Experimental results on two publicly available datasets demonstrate the significant effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Jiayang Zhao and Deqiang He and Zhenzhen Jin and Xingwu Zhang and Jixu Zhou},
  doi          = {10.1016/j.eswa.2025.129023},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129023},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new method for bearing remaining useful life prediction based on dynamic wavelet and physical information constraints},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asynchronous security control for discrete singular piecewise homogeneous markov jump systems with incomplete transition probabilities and DoS attacks. <em>ESWA</em>, <em>296</em>, 129022. (<a href='https://doi.org/10.1016/j.eswa.2025.129022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the asynchronous security control problem is discussed for discrete singular piecewise homogeneous Markov jump systems (SPHMJSs) with incomplete transition probabilities (TPs) and denial-of-service (DoS) attacks. The TPs of the system are discussed to be a finite piecewise-homogeneous and a higher transition probability (HTP) matrix is used to govern the TPs of the system. Meanwhile, the asynchronization behavior between the system and the controller is characterized by a hidden Markov model (HMM), and the TPs of the system and the controller are not completely known. Moreover, aperiodic DoS attacks are considered. Firstly, some sufficient conditions are obtained to guarantee the system is exponentially admissible (EA) with desired performance. Secondly, a mode- and variation-dependent controller is designed by a novel approach. Finally, simulation results are presented to show the effectiveness of the design method.},
  archive      = {J_ESWA},
  author       = {Qian Zhang and Huaicheng Yan and Ping Qi and Biqing Wang},
  doi          = {10.1016/j.eswa.2025.129022},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129022},
  shortjournal = {Expert Syst. Appl.},
  title        = {Asynchronous security control for discrete singular piecewise homogeneous markov jump systems with incomplete transition probabilities and DoS attacks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved attack detection in IoT and IIoT networks using attention mechanisms in convolutional neural networks. <em>ESWA</em>, <em>296</em>, 129021. (<a href='https://doi.org/10.1016/j.eswa.2025.129021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of devices on the Internet of Things (IoT) and Industrial Internet of Things (IIoT) in consumer and industrial applications has introduced numerous cybersecurity challenges, with vulnerabilities to sophisticated attacks posing critical operational and financial risks. This study utilizes the latest Edge_IIoTset dataset, which contains data from IoT and IIoT environments, categorized into normal instances and 14 different types of cyberattack. To enhance attack detection accuracy, we propose a novel deep learning approach that integrates Convolutional Neural Network (CNN) architectures, ResNet50 and MobileNet, with a two-stage attention mechanism. The raw dataset is preprocessed by transforming numerical data into image representations through quantile transformation, enabling the extraction of spatial features. In the first stage, channel attention is used to prioritize the most informative feature channels. In the second stage, spatial attention is applied to the resultant feature channels to focus on important regions within these representations. By incorporating these attention mechanisms into ResNet50 and MobileNet, the models dynamically adapt to highlight critical attack patterns, improving sensitivity to diverse attack types. In addition, quantization techniques are employed to optimize model size, striking a balance between computational efficiency and detection performance. Experimental results reveal that our proposed approach significantly improves detection accuracy, demonstrating the effectiveness of attention-augmented deep learning in securing IoT and IIoT ecosystems against cyberattacks. Key metrics such as inference time, compression ratio, resource utilization, computational efficiency, and computational complexity demonstrate the scalability and suitability of the model for resource-constrained environments.},
  archive      = {J_ESWA},
  author       = {Basharat Ahmad and Yamin Li and Zhaoliang Wu and Sadaqat Ur Rehman and Yongfeng Huang},
  doi          = {10.1016/j.eswa.2025.129021},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129021},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved attack detection in IoT and IIoT networks using attention mechanisms in convolutional neural networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TransEHR: Alignment-free electronic health records continual learning across feature spaces. <em>ESWA</em>, <em>296</em>, 129020. (<a href='https://doi.org/10.1016/j.eswa.2025.129020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of new Electronic Health Records (EHR), incrementally updating predictive models becomes crucial for effective health monitoring. However, in real clinical scenarios, the feature space of EHRs may change over time, which poses a unique challenge to the transferability of predictive models when encountering unseen medical features. To tackle this issue, we propose TransEHR , a transferable EHR incremental learner across feature space. Initially, TransEHR divides EHR over time into binary groups composed of feature names and values, embedding time and binary groups separately. This embedding mechanism enables the model to accept variable-feature inputs, which solves the problem of feature space evolving for new EHR. Subsequently, to learn temporal information, a variant transformer with gating units is applied to the contextual representation of time and record embeddings. Furthermore, TransEHR designs a record-level self-supervised contrastive loss to capture the semantics within and across features for enhancing intra-patient semantic consistency and a patient-level supervised contrastive loss for mitigating inter-patient intra-class semantic bias and catastrophic forgetting problem faced in incremental learning. Experiments in supervised learning, feature incremental learning, and cross-feature transfer learning demonstrate that TransEHR outperforms state-of-the-art methods, providing accurate and stable predictions.},
  archive      = {J_ESWA},
  author       = {Xiongjun Zhao and Zhengyu Liu and Boya Ji and Peng Xi and Shaoliang Peng},
  doi          = {10.1016/j.eswa.2025.129020},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129020},
  shortjournal = {Expert Syst. Appl.},
  title        = {TransEHR: Alignment-free electronic health records continual learning across feature spaces},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anchor-based graph embedding and soft label learning for multi-label classification with missing label. <em>ESWA</em>, <em>296</em>, 129019. (<a href='https://doi.org/10.1016/j.eswa.2025.129019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite progress in multi-label learning, handling missing labels in weakly annotated data remains challenging. The graph-based method utilizes sample structure information to promote semantic reconstruction to recover missing labels, and it has achieved satisfactory performance. However, the existing graph-based soft label semantic reconstruction methods still have the following problems with missing label classification learning. Existing methods face two limitations: (a) the separate construction of instance similarity graphs and execution of classification tasks results in suboptimal similarity matrices for classification; (b) the high computational cost incurred by some adaptive k -connected graph learning methods when constructing k -nearest neighbor similarity matrices hinders their practical application. In addition, the complex label correlations further increase the difficulty of accurately predicting all possible labels. In this paper, we propose a joint bipartite graph and soft label learning for the multi-label missing label classification method. First, we obtain the anchor of the samples based on k -means clustering and construct a sparse bipartite graph similarity matrix with k -nearest neighbor connected components by using the anchor and the original samples as the weight of the bipartite graph. Second, sparse high-rank and high-order label correlation learning based on landmark selection is provided to obtain soft labels for the missing labels. Finally, learn multi-label classification and label correlations jointly in a unified framework with kernel techniques to solve the linear inseparability of the data. Experimental results on several real-world benchmark multi-label datasets demonstrate the competitiveness and effectiveness of our proposed method compared with the state-of-the-art approach.},
  archive      = {J_ESWA},
  author       = {Dawei Zhao and Hong Li and Yixiang Lu and De Zhu and Qingwei Gao},
  doi          = {10.1016/j.eswa.2025.129019},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129019},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anchor-based graph embedding and soft label learning for multi-label classification with missing label},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An attributed multiplex network enabled GNN-based stock predictor with observable and non-observable information. <em>ESWA</em>, <em>296</em>, 129018. (<a href='https://doi.org/10.1016/j.eswa.2025.129018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating spatial dependencies between stocks has emerged as a pivotal approach to augment the predictive performance of Graph Neural Network (GNN) based stock predictors. However, it seems that the performance of these methodologies appears to encounter a formidable bottleneck, which impedes their progression and constrains their practical application. First, the graph representation of stock relationships is limited by the restricted access to pertinent information, such as strategic adjustments by companies in response to fluctuations in the market. Even when stock information is available, its acquisition remains arduous. Another limitation corresponds to how efficiently the information is used for graph representation learning. Recently, most studies mainly focus on the exploration of local relationships between stocks from stock information rather than from the global perspective, as well as the strength evaluation of the impact. To confront these challenges, we introduce a unified attributed multiplex GNN for stock prediction which incorporates two innovative components. The first component involves a module used to explore relationships between stocks hidden in the non-observable stock market information based on a top- L graph representation learning mechanism. The second component is a GRU variant designed to capture the global impact of observable information on graph model construction by integrating both the decline effect and the lead-lag effect to simulate relationship dynamics. In theory, our unified framework can integrate any SOTA GNN model. Our empirical findings, derived from statistical tests based on both Chinese and American stock markets, demonstrate that the proposed model outperforms all baselines obtained from various GNN-based approaches, with accuracy enhancements ranging from 4.88 % to 7.38 % , and exhibits robust generalizability and reproducibility.},
  archive      = {J_ESWA},
  author       = {Zhipeng Liu and Peibo Duan and Qi Chu and Levin Kuhlmann and Changsheng Zhang and Wenwei Yue and Xuan Tang and Bin Zhang},
  doi          = {10.1016/j.eswa.2025.129018},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129018},
  shortjournal = {Expert Syst. Appl.},
  title        = {An attributed multiplex network enabled GNN-based stock predictor with observable and non-observable information},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Extracting structured sentiment quadruples by labeling boundary token pairs for aspect-based sentiment analysis. <em>ESWA</em>, <em>296</em>, 129017. (<a href='https://doi.org/10.1016/j.eswa.2025.129017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) provides accurate and in-depth information about users’ opinions. It has received considerable attention in recent years. Most existing research on ABSA targets extracting the aspect terms, opinion terms and sentiment polarities individually or the combinations of these roles. However, another key opinion role, i.e., opinion holder, has been ignored in these studies. The addition of an opinion holder greatly increases the complexity of the relationships between opinion roles and makes the ABSA task more challenging. In this work, we focus on extracting structured sentiment quadruples from unstructured texts. This forms a more complete picture of the sentiment information through the quadruple of the (opinion) holder, the aspect target term, the corresponding opinion term, and the expressed sentiment. We propose a boundary-sensitive token pair labeling framework (BTPL) for extracting different opinion roles and the corresponding relations in texts. This process can effectively identify the long-span roles and addresses the problem of role overlap between sentiment quadruples. Additionally, BTPL extracts four roles and their corresponding relations synchronously, which avoids error propagation encountered by existing ABSA pipeline methods. Moreover, based on syntactic dependency information, we use the conditional layer normalization module to generate high-quality representations for the candidate token pairs. We conduct extensive experiments on five public datasets to verify the proposed framework. Experimental results show that the proposed BTPL achieves state-of-the-art performances.},
  archive      = {J_ESWA},
  author       = {You Li and Shaocong Zhang and Yuming Lin and Yongdong Lin and Liang Chang},
  doi          = {10.1016/j.eswa.2025.129017},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129017},
  shortjournal = {Expert Syst. Appl.},
  title        = {Extracting structured sentiment quadruples by labeling boundary token pairs for aspect-based sentiment analysis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep neural network-aided radio frequency fingerprinting for identification of near field communication tags. <em>ESWA</em>, <em>296</em>, 129016. (<a href='https://doi.org/10.1016/j.eswa.2025.129016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop an identification scheme for near field communication (NFC) by making use of radio frequency (RF) fingerprinting which exploits the unique physical RF characteristics. In particular, we consider deep learning-based RF fingerprinting that is capable of extracting the characteristics of NFC tags autonomously from the RF signal that corresponds to one bit of data transmission. The proposed identification scheme is designed to identify not only the NFC tags that are considered during the training but also out-of-library NFC tags that were not seen during the training. To this end, three different types of deep neural network structures are devised: a fully-connected neural network, a convolutional neural network, and a recurrent neural network. We also develop an ensemble neural network and a multi-sample aggregation strategy in an attempt to further improve the classification accuracy of identification. To verify the performance of the proposed scheme, we implement a hardware testbed using an off-the-shelf NFC reader, a software-defined radio (SDR), and 50 NFC tags. A performance evaluation confirms that our proposed scheme can correctly identify not only the tags that are considered during the training but also out-of-library tags that have not been seen during the training with 99.6 % accuracy.},
  archive      = {J_ESWA},
  author       = {Woongsup Lee and Seon Yeob Baek},
  doi          = {10.1016/j.eswa.2025.129016},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129016},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep neural network-aided radio frequency fingerprinting for identification of near field communication tags},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained face personalisation using a text-guided multi-attribute embedded diffusion model. <em>ESWA</em>, <em>296</em>, 129015. (<a href='https://doi.org/10.1016/j.eswa.2025.129015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image face personalisation (T2I-FP) has become an active research topic driven by the recent success of large vision language models. State-of-the-art T2I-FP models such as DreamBooth, PhotoMaker, and Face2Diffusion, are capable of producing diverse high-fidelity photo-quality face images. In this paper, we investigate how to enhance the flexibility of customised faces with fine-grained controls from a text prompt while further improving face generation quality. Inspired by the intuitive observation that face variations are mainly due to several key attribute changes such as age, expression, or pose, we propose a multi-attribute embedded vision language model to achieve a better controllability for producing photos with fine-grained attributes from text prompts. In addition, our multi-attribute embeddings are effective in capturing finer granularity, thus further enhancing the model generation quality. Experimental results convincingly demonstrate that our proposed model offers superior performance, generating photos with higher fidelity and fine-grained attributes, compared to state-of-the-art T2I-FP models.},
  archive      = {J_ESWA},
  author       = {Jing Dong and Ping Xu and Qiang Zhang and Hui Fang and Gerald Schaefer and Rui Liu and Pengfei Yi and Xiaoyong Fang},
  doi          = {10.1016/j.eswa.2025.129015},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129015},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained face personalisation using a text-guided multi-attribute embedded diffusion model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage adaptive CAV control for mitigating congestion in mixed traffic environments using front-tracking method. <em>ESWA</em>, <em>296</em>, 129013. (<a href='https://doi.org/10.1016/j.eswa.2025.129013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While existing research has explored various traffic control strategies, the potential of moving bottleneck control for proactive congestion management remains underexplored, particularly in mixed traffic environments where Connected and Automated Vehicles (CAVs) and Human-Driven Vehicles (HDVs) coexist, introducing additional complexities to traffic flow operations. This study develops a two-stage control framework that integrates a mixed-traffic fundamental diagram model with the front tracking method to solve composite Riemann problems generated by moving bottlenecks. The framework combines Model Predictive Control (MPC) for control zone outflow optimization with moving bottleneck regulation to derive optimal vehicle speeds. Validation was carried out using real-world data from a five-lane highway weaving section in Antwerp, starting with calibration of the Cell Transmission Model (CTM) under the 0 % penetration rate of the CAV and extending over different penetration rates (20 %-80 %). The results demonstrate the effectiveness of the framework in the regulation of congestion density and lane-specific adaptation. The control strategy reduces the mean density and congestion fluctuations, increases travel speeds, and achieves higher efficiency at higher penetration rates, reducing the completion time of the control by 50 % while maintaining the stability of the system, thus demonstrating its practical viability in mixed traffic management.},
  archive      = {J_ESWA},
  author       = {Jiali Peng and Wei Shangguan and Junjie Chen and Cong Peng and Mohammad Ali Arman and Baigen Cai and Chris M.J. Tampére},
  doi          = {10.1016/j.eswa.2025.129013},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129013},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage adaptive CAV control for mitigating congestion in mixed traffic environments using front-tracking method},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An iterative greedy algorithm based on neighborhood search for energy-efficient scheduling of distributed permutation flowshop with sequence-dependent setup time. <em>ESWA</em>, <em>296</em>, 129012. (<a href='https://doi.org/10.1016/j.eswa.2025.129012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient utilization and emissions reduction have become increasingly important for modern industrial manufacturing. At the same time, many industries have adopted the multi-factory production mode due to rapid economic development. Therefore, this paper investigates the energy-efficient scheduling of a distributed permutation flow shop with sequence-dependent setup times (EEDPFSP/SDST) aiming to simultaneously minimize the total flowtime (TF) and total energy consumption (TEC). Firstly, the initial sequencing is determined according to the job’s completion time, and a multi-objective NEH_B heuristic with an inner-block swap operator (NEH_B IBSO ) is proposed. Secondly, an iterative greedy algorithm based on neighborhood search (IG BNS ) is proposed according to the problem characteristics. Two operators (inner-block swap, block-to-block swap) are designed to reduce the TF, the energy-saving operator is developed to diminish the TEC in the neighborhood search, and a self-adaptive local search strategy with Pareto front diagram judgment is introduced in IG BNS . Finally, through experimental comparisons based on 612 instances, the IG BNS algorithm is verified to outperform the other five famous multi-objective optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Quan Zhong and Yang Yu and Zixiang Li and Liangliang Sun and Yuyan Han and Natalja M. Matsveichuk and Yuri N. Sotskov},
  doi          = {10.1016/j.eswa.2025.129012},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129012},
  shortjournal = {Expert Syst. Appl.},
  title        = {An iterative greedy algorithm based on neighborhood search for energy-efficient scheduling of distributed permutation flowshop with sequence-dependent setup time},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Light and shadows of smart contract development with LLMs. <em>ESWA</em>, <em>296</em>, 129011. (<a href='https://doi.org/10.1016/j.eswa.2025.129011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contract development remains almost inaccessible to non-experts developers despite the growing adoption of blockchain technology across industries. This paper evaluates the potential of Large Language Models (LLMs) for automated smart contract generation from legal agreements. The work systematically assesses the capabilities of four leading commercial LLMs – gpt-4-turbo (OpenAI), claude-3.5-sonnet (Anthropic), mistral-large (MistralAI), and gemini-1.5-pro (Google) – across a diverse range of legal agreements with varying complexity. The evaluation framework consists of a in-depth evaluation of structured code patterns – typical to smart contracts – to provide nuanced insights into model performances. The results reveal a performance hierarchy with claude-3.5-sonnet and gpt-4-turbo consistently outperforming mistral-large and gemini-1.5-pro , particularly when handling complex agreements such as mortgage note agreement and property sales agreement. A nonlinear relationship has been observed between contract complexity and model performance, with even top-performing models showing significant degradation when processing intricate legal structures. Although achieving syntactic correctness has become increasingly feasible, ensuring functional completeness and security remains challenging, as evidenced by high-impact vulnerabilities detected across all generated smart contracts. This work contributes to the growing discourse on LLM applications in blockchain technology by providing empirical evidence of current capabilities and limitations, establishing a robust foundation for future research in AI-assisted smart contract development.},
  archive      = {J_ESWA},
  author       = {Emanuele Antonio Napoli and Noemi Romani and Valentina Gatteschi and Claudio Schifanella},
  doi          = {10.1016/j.eswa.2025.129011},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129011},
  shortjournal = {Expert Syst. Appl.},
  title        = {Light and shadows of smart contract development with LLMs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing the benefit of the doubt model through ‘Ensemble-DEA’: Achieving the sustainable development goals. <em>ESWA</em>, <em>296</em>, 129010. (<a href='https://doi.org/10.1016/j.eswa.2025.129010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative approach for constructing composite indicators by combining the Benefit of the Doubt method from Data Envelopment Analysis with ensemble techniques, i.e., ‘Ensemble-DEA’, with randomization in observations and variables selection. Our methodology mitigates the curse of dimensionality, which limits the effectiveness of traditional approaches when dealing with numerous indicators. By maintaining data integrity and improving robustness through an ensemble-based technique, our method delivers high-discriminatory power and clear rankings for Decision Making Units. Additionally, it enhances benchmarking capabilities by offering unit-specific peer comparisons. Our contributions therefore include the development of robust composite indicators and improved benchmarking insights, ensuring their reliability even in high-dimensional settings. We validate our approach using a real-world dataset containing 72 indicators aligned with Sustainable Development Goals for European Union countries. The results show that performance in meeting Sustainable Development Goals is correlated with the level of socioeconomic development and environmental consciousness. In particular, Scandinavian, Northern European and Benelux countries tend to perform best, while Eastern European countries lag in sustainability effectiveness. Furthermore, a comparative analysis against conventional methods underscores the advantages of our approach in managing complex datasets, specifically in terms of improvement in discriminatory power and benchmarking opportunities.},
  archive      = {J_ESWA},
  author       = {Juan Aparicio and Magdalena Kapelko and Juan F. Monge and José L. Zofío},
  doi          = {10.1016/j.eswa.2025.129010},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129010},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing the benefit of the doubt model through ‘Ensemble-DEA’: Achieving the sustainable development goals},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ist-SBiLSTM: Multi-level stacking ensemble approach using gravitational search algorithm and BiLSTM for accurate state of health prediction in lithium-ion batteries. <em>ESWA</em>, <em>296</em>, 129009. (<a href='https://doi.org/10.1016/j.eswa.2025.129009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate state of health (SOH) prediction is crucial for extending the lifespan of lithium-ion batteries (LIBs), as well as for improving the system reliability and economic efficiency. However, precise SOH prediction is challenging due to the capacity regeneration (CR) phenomenon. To overcome this challenge, a multi-level hybrid prediction method based on adaptive cascade optimization (Ist-SBiLSTM) is proposed in this paper. Initially, data cleaning is performed using the 3 σ -linear regression (LR) method to detect and correct outliers. Subsequently, the processed battery capacity data are decomposed using Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) to obtain several short-term fluctuations and a long-term decay trend. For the prediction phase, the proposed model, SBiLSTM, which integrates a Bidirectional Long Short-Term Memory (BiLSTM) with a sparse attention mechanism (SA), is applied to capture the long-term decay trends. An improved Stacking model, which selects the optimal base model combination freely using the Gravitational Search Algorithm (GSA), is used to predict short-term fluctuations. Finally, the predicted components are linearly summed and experiments are conducted on two representative public datasets to validate the effectiveness and generalizability of the proposed method. The results show that compared with the Stacking model using BiLSTM as the meta-learner, the Ist-SBiLSTM method proposed in this paper reduces the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) by 28.57 %, 53.33 %, and 53.73 %, respectively.},
  archive      = {J_ESWA},
  author       = {Jiawei Chen and Gang Liu and Yisheng Cao and Rujian Chen and Gang Xiao and Xingfei Zhang},
  doi          = {10.1016/j.eswa.2025.129009},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129009},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ist-SBiLSTM: Multi-level stacking ensemble approach using gravitational search algorithm and BiLSTM for accurate state of health prediction in lithium-ion batteries},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An energy-aware scheduling method for parallel tasks based on an adaptive differential evolution algorithm in a multi-cloud environment. <em>ESWA</em>, <em>296</em>, 129008. (<a href='https://doi.org/10.1016/j.eswa.2025.129008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing data and computing scale, the energy consumption of computing is increasing greatly. This study focuses on the scheduling problem of parallel tasks in a cloud environment. Most of the work models tasks according to DAG (Directed Acyclic Graph) and selects a working state based on DVFS (Dynamic Voltage Frequency Scaling) to reduce energy consumption and meet other QoSs (Quality of Services). In contrast to these works, we focus on the task in which parallelism cannot be changed during execution, and the task model supports slot time in a heterogeneous environment. In the paper, we propose a SAEADE (An Self-adaption Differential Evolution Energy-Aware Algorithm) to schedule resources, which considers the parallelism of tasks, the selection of resources, and their working states simultaneously. SAEADE initializes the data by the sine function. During crossover and mutation operations, SAEADE selects the strategy by a roulette algorithm among the three methods: (1) DE-Rand, (2) DE-current-to-best, and DE-rand-to-best. Simulations show that SAEADE performs well in terms of makespan, energy consumption, the number of completed tasks, and the number of completed instructions. Compared to the performance of PSO (Particle Swarm Optimization), SAEADE also has good performance in efficiency.},
  archive      = {J_ESWA},
  author       = {Qin Wang and Yongsheng Hao and Yue Xu and Tinhuai Ma and Xin Zhang},
  doi          = {10.1016/j.eswa.2025.129008},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129008},
  shortjournal = {Expert Syst. Appl.},
  title        = {An energy-aware scheduling method for parallel tasks based on an adaptive differential evolution algorithm in a multi-cloud environment},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DEPFSWNN: A data-driven efficient pruning feedforward small-world neural network as a virtual sensor for total phosphorus in wastewater treatment process. <em>ESWA</em>, <em>296</em>, 129007. (<a href='https://doi.org/10.1016/j.eswa.2025.129007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative method for measuring the total phosphorus (TP) concentration—an important indicator assessing eutrophication in water bodies, a virtual sensor can be deployable on-site and is economical and convenient for maintenance. However, due to the long biochemical reaction cycle and diverse biochemical reaction laws in the wastewater treatment process (WWTP), the system is characterized with high complexity and strong nonlinearity, which makes the accurate prediction of the TP concentration more challenging. To solve the problem, a data-driven efficient pruning feedforward small-world neural network (DEPFSWNN) is developed in this study. Firstly, a data-driven small-world neural network construction method is proposed to allow for the reuse of important original features by considering the strong correlation between auxiliary variables and the target TP. Secondly, an efficient pruning algorithm is designed based on density peak clustering to slim network structure by layer to avoid parameter redundancy. Simultaneously, an error compensation mechanism based on ridge regression is put forward and implemented after pruning, which enables the stability of network performance. Experimental results on a dataset from an actual WWTP demonstrate that DEPFSWNN improves the modeling accuracy for TP prediction in WWTP, and it is efficient with significantly shortened training time and the compacted structure.},
  archive      = {J_ESWA},
  author       = {Wenjing Li and Zhigang Li and Junfei Qiao},
  doi          = {10.1016/j.eswa.2025.129007},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129007},
  shortjournal = {Expert Syst. Appl.},
  title        = {DEPFSWNN: A data-driven efficient pruning feedforward small-world neural network as a virtual sensor for total phosphorus in wastewater treatment process},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mob-INC: An effective scheme for maize disease recognition based on deep networks. <em>ESWA</em>, <em>296</em>, 129006. (<a href='https://doi.org/10.1016/j.eswa.2025.129006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, the area under maize cultivation has increased due to its essential role in the food cycle for humans, livestock, and poultry. However, plant diseases pose a threat to food safety and can significantly reduce both the quality and quantity of agricultural products. Accurate and timely diagnosis of such diseases presents many challenges. This research proposes a novel approach based on a deep neural network to address these challenges. Due to the limited amount of available data, the transfer learning technique is employed using two well-known architectures. A new effective model is developed by combining pre-trained MobileNetV2 and Inception networks, chosen for their strong performance in object detection tasks. The convolutional layers of MobileNetV2 and the Inception modules are arranged in parallel in the early layers to extract crucial features. The model is trained and evaluated on the maize leaf subset of the publicly available PlantVillage dataset, which contains images of diseased and healthy plant leaves. Additionally, the class imbalance problem is addressed through a data augmentation strategy. The proposed method demonstrates superior performance compared to other state-of-the-art models published in recent years, achieving an accuracy of approximately 96.10 %. In summary, the experimental results validate the effectiveness and robustness of the proposed method in diagnosing plant leaf diseases.},
  archive      = {J_ESWA},
  author       = {Saeedeh Osouli and Behrouz Bolourian Haghighi and Ehsan Sadrossadat},
  doi          = {10.1016/j.eswa.2025.129006},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129006},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mob-INC: An effective scheme for maize disease recognition based on deep networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LAP-GAN: Label augmentation with perceptual loss for self-supervised text-to-image synthesis. <em>ESWA</em>, <em>296</em>, 129005. (<a href='https://doi.org/10.1016/j.eswa.2025.129005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) has demonstrated remarkable progress in generating realistic images from text descriptions. However, learning the complex data distributions across both text and image domains presents significant challenges, such as producing limited image variety. Previous works have addressed these challenges by incorporating self-supervision into text-to-image GANs approaches. Yet, a limitation of these approaches is that the auxiliary self-supervised tasks ignore the semantic information of the input text-image pairs during training, leading to goal inconsistency within the discriminator. To overcome this, we propose a novel text-to-image synthesis method, Label Augmented Perceptual Generative Adversarial Networks (LAP-GAN), which integrates label augmented discriminators and a perceptual loss mechanism. The label augmented discriminators augment the label for the self-supervised task to consider semantic information, thereby aligning the objectives of the image modeling and self-supervision tasks into a single, unified goal. Concurrently, the perceptual loss mechanism is integrated to leverage semantic high-level features, complementing self-supervision to refine the image synthesis process. The proposed LAP-GAN ultimately achieves high-quality image synthesis, representing a significant advancement in text-to-image generation using three benchmark datasets. The source code for the proposed LAP-GAN is available at: https://github.com/Jityan/lapgan .},
  archive      = {J_ESWA},
  author       = {Yong Xuan Tan and Jit Yan Lim and Kian Ming Lim and Chin Poo Lee},
  doi          = {10.1016/j.eswa.2025.129005},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129005},
  shortjournal = {Expert Syst. Appl.},
  title        = {LAP-GAN: Label augmentation with perceptual loss for self-supervised text-to-image synthesis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid literature review on handling imbalanced medical data: AI models and open issues. <em>ESWA</em>, <em>296</em>, 129004. (<a href='https://doi.org/10.1016/j.eswa.2025.129004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenging aspect of developing an AI model for the medical field is the imbalance in disease datasets owing to the disproportionate ratio of healthy to diseased cohorts. Although a wide range of imbalance handling techniques are available, an effective solution remains elusive. A systematic literature review (SLR) was conducted in this study to understand the current state of work and open issues that need to be addressed with research. An SLR was conducted with the following goals: 1. To identify current issues in the medical AI model because of an imbalanced dataset; 2. To summarise the medical dataset along with its available limitations in research; and 3. To empirically analyze the limitations of imbalanced dataset handling techniques in the medical AI model. Based on the Kitchenham guidelines, the current study spans six years between 2017 and 2023. Forest plot analysis was applied to understand the effect of data imbalance and its handling techniques for the AI model, presenting an overall pooled confidence interval(CI). The analysis indicates that applying an imbalance handling technique improves efficacy to low nineties, leaving scope for improvement. Analysis and consolidation of open issues are provided for improving imbalance handling techniques.},
  archive      = {J_ESWA},
  author       = {Kaikashan I. Siddavatam and Subhash K. Shinde},
  doi          = {10.1016/j.eswa.2025.129004},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129004},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid literature review on handling imbalanced medical data: AI models and open issues},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MedKit: Multi-level feature distillation with knowledge injection for radiology report generation. <em>ESWA</em>, <em>296</em>, 129003. (<a href='https://doi.org/10.1016/j.eswa.2025.129003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation automates the creation of clinically accurate and coherent paragraphs from medical images, reducing the heavy burden of report writing for radiologists. However, current research in this field still faces limitations and urgently requires breakthroughs in feature extraction of image knowledge and model fusion. In this paper, we propose a radiology report generation framework, MedKit, that integrates high information density knowledge fusion with multi-level task feature distillation. We leverage knowledge embedding fusion through a knowledge graph to reduce semantic hallucinations. Additionally, by employing feature extraction techniques within a multi-level task feature distillation architecture, comprehensive image feature information is provided for the primary task. For adapting 2D and 3D images, we propose different visual encoders respectively, which address the issue of inconsistent shapes in medical images. Finally, utilizing a multimodal large model framework enables the generated radiology report to closely approximate medical experts’ fluent expression. Our proposed model significantly outperformed the state-of-the-art model in the MIMIC-CXR dataset with a 20.1 % increase in the BLEU-4 score, from 0.134 to 0.161. We also achieved the best result on the private Liver-CT dataset. Our code is available at https://github.com/sujaly/MedKit .},
  archive      = {J_ESWA},
  author       = {Zhaoli Su and Hong Song and Yucong Lin and You Wu and Xutao Weng and Zhongxuan Mao and Bowen Liu and Hongxia Yin and Jian Yang},
  doi          = {10.1016/j.eswa.2025.129003},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129003},
  shortjournal = {Expert Syst. Appl.},
  title        = {MedKit: Multi-level feature distillation with knowledge injection for radiology report generation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improvement by introducing LBFGS idea into the adam optimizer for machine learning. <em>ESWA</em>, <em>296</em>, 129002. (<a href='https://doi.org/10.1016/j.eswa.2025.129002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, large-scale machine learning models have attracted much attention. The optimizer used in model training plays a vital role in the effectiveness and efficiency of model practice. Based on the commonly used classic Adam optimizer, this paper introduces the idea of LBFGS and proposes the LBFGS-Adam (LA) optimizer (algorithm). Theoretical analysis shows that compared with the classic Adam optimizer, the LA optimizer requires weaker assumptions to achieve the same convergence results, that is, the convergence is improved. Numerical experiments show that compared with the classical method, the LA optimizer has better average loss and average IOU performance when completing classification tasks, and has been applied in real-time image segmentation. In addition, the LA optimizer has also shown strong adaptability in problems in other fields such as natural language processing, reinforcement learning, molecular simulation, quantum chemistry, bioinformatics, etc., indicating that it has a wider range of cross-domain application potential.},
  archive      = {J_ESWA},
  author       = {Zhao Zhang and Gonglin Yuan and Zhenkai Qin and Qining Luo},
  doi          = {10.1016/j.eswa.2025.129002},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129002},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improvement by introducing LBFGS idea into the adam optimizer for machine learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stylometry recognizes human and LLM-generated texts in short samples. <em>ESWA</em>, <em>296</em>, 129001. (<a href='https://doi.org/10.1016/j.eswa.2025.129001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans, addressing issues of model attribution, intellectual property, and ethical AI use. Stylometry has been used extensively to characterise the style and attribute authorship of texts. By applying it to LLM-generated texts, we identify their emergent writing patterns. The paper involves creating a benchmark dataset based on Wikipedia, with (a) human-written term summaries, (b) texts generated purely by LLMs (GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text summarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods (Dipper, T5). The 10-sentence long texts were classified by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features that encode lexical, grammatical, syntactic, and punctuation patterns. The cross-validated results reached a performance of up to 0.87 Matthews correlation coefficient in the multiclass scenario with 7 classes, and accuracy between 0.79 and 1. in binary classification, with the particular example of Wikipedia and GPT-4 reaching up to 0.98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed features characteristic of the encyclopaedic text type, individual overused words, as well as a greater grammatical standardisation of LLMs with respect to human-written texts. These results show – crucially, in the context of the increasingly sophisticated LLMs – that it is possible to distinguish machine- from human-generated texts at least for a well-defined text type},
  archive      = {J_ESWA},
  author       = {Karol Przystalski and Jan K. Argasiński and Iwona Grabska-Gradzińska and Jeremi K. Ochab},
  doi          = {10.1016/j.eswa.2025.129001},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129001},
  shortjournal = {Expert Syst. Appl.},
  title        = {Stylometry recognizes human and LLM-generated texts in short samples},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A micro-expression recognition algorithm fusing visual information with textual semantics. <em>ESWA</em>, <em>296</em>, 129000. (<a href='https://doi.org/10.1016/j.eswa.2025.129000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In micro-expression research, the dependencies among Action Units (AUs) and their associated facial regions have provided valuable cues for feature extraction and have driven substantial progress. However, existing methods primarily rely on visual data and AU labels, which often fail to capture the nuances of facial movements. In contrast, semantic descriptions of AUs offer richer and more interpretable information about facial muscle behavior, yet remain underexplored in micro-expression analysis. In this study, we propose a novel framework that integrates visual information with AU textual semantics to enhance micro-expression analysis. Specifically, we construct detailed AU descriptions and introduce a semantic feature extraction module to capture inter-AU dependencies. To overcome the limitations of long-range inductive bias in local features within CNN models, we develop a region attention mechanism in the visual feature extraction module. Furthermore, a cross-modal attention mechanism is introduced to semantically align and fuse visual features with AU textual semantics at both global and local levels. Our model achieves strong performance, with accuracies of 79.27%, 82.45%, and 80.14% on the SMIC, CASMEII, and SAMM datasets, respectively. On a composite dataset, our method further achieves a UF1 of 0.8461 and a UAR of 0.8510, outperforming or matching state-of-the-art methods. Ablation studies and visualizations further validate the effectiveness and interpretability of our proposed approach.},
  archive      = {J_ESWA},
  author       = {Fengping Wang and Jie Li and Chun Qi and Lin Wang and Pan Wang},
  doi          = {10.1016/j.eswa.2025.129000},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {129000},
  shortjournal = {Expert Syst. Appl.},
  title        = {A micro-expression recognition algorithm fusing visual information with textual semantics},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Refining cell subpopulation identification and cell fate mapping using cell energy. <em>ESWA</em>, <em>296</em>, 128999. (<a href='https://doi.org/10.1016/j.eswa.2025.128999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite rapid advances in single-cell data analysis algorithms, the accurate and robust mapping of cell fate dynamics across diverse biological systems remains a challenge. Here, we introduce CellEnergy, a novel method capable of assigning a cell energy indicator based on Gene Local Network Energy (GLNE), suitable for quantitatively describing attractor states. Benchmarking against 8 other advanced models, CellEnergy demonstrates superior performance in quantifying cellular plasticity, assessing cell population heterogeneity, automatically detecting terminal cell states, and tracking the dynamics of cell fate transitions. Moreover, CellEnergy shows robustness in rare cells and high dropout ratio datasets, all while significantly reducing computational costs. CellEnergy quantitatively evaluates the heterogeneity of mouse embryonic stem cells and identifies a cell subpopulation that exhibits consistent high differentiation potential, defining 2-cell-like cells. For mouse pancreatic development, CellEnergy accurately identifies four terminal cell states, including the rare Delta cells, and profiles the local network energy change trends of relevant genes across different lineages. Applications of CellEnergy reveal the impact of small molecules on cell plasticity from an energy perspective in human chemical reprogramming data. We further demonstrate the utility of CellEnergy in identifying plasticity-associated genes implicated in the tumorigenesis and prognosis of head and neck squamous cell carcinoma and melanoma. CellEnergy characterizes key branching points in human hematopoietic lineage commitment and decodes the distinct regulatory dynamics of erythropoiesis and megakaryopoiesis.},
  archive      = {J_ESWA},
  author       = {Chunshen Long and Hanshuang Li and Zhifang Li and Jia Zhang and Qilemuge Xi and Yongchun Zuo},
  doi          = {10.1016/j.eswa.2025.128999},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128999},
  shortjournal = {Expert Syst. Appl.},
  title        = {Refining cell subpopulation identification and cell fate mapping using cell energy},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty-fetal head and pubic symphysis segmentation with enhanced multi-scale features and sparse visual graph attention. <em>ESWA</em>, <em>296</em>, 128998. (<a href='https://doi.org/10.1016/j.eswa.2025.128998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the fetal head and pubic symphysis in intrapartum ultrasound images are crucial for prognosis prediction and complication prevention during delivery. However, due to the poor quality of intrapartum ultrasound imaging, blurred object boundaries, and strong artifacts, manual segmentation is time-consuming and laborious even for experienced experts, and current deep learning methods lack expressiveness and transparency, resulting in obstetricians’ lack of confidence in the segmentation results. In this paper, we propose an uncertain segmentation method for fetal head and pubic symphysis in intrapartum ultrasound images, called IGT-Net. First, we introduce an improved Inception block in the encoder. Compared with traditional convolution operations, it helps the model obtain multi-scale features under different receptive fields while effectively reducing the amount of calculations. Second, we introduce a graph-based sparse attention method called Sparse Visual Graph Attention (SVGA). Compared with existing attention mechanisms, it is able to obtain the structure of the graph before inference. In addition, SVGA can avoid reshaping operations when performing graphics convolution to effectively reduce computational overhead. Then, in the decoder, we introduce the Neighborhood Attention Transformer (NAT). NAT can limit the self-attention range to adjacent pixels and adopt a sliding window mode to make the model achieve stronger time and space complexity. Finally, we use test-time augmentation to perturb the model input, evaluate the changes in the model for different inputs, and finally output an uncertainty measure. The effectiveness of our approach was validated through experiments on two datasets. Compared with existing methods, our model demonstrated competitive performance. The proposed model significantly improved automatic segmentation accuracy, reduced errors, and provided substantial support for ultrasound physicians in clinical settings. The source code is available at https://github.com/SakuraKong/IGT-Net .},
  archive      = {J_ESWA},
  author       = {Zhensen Chen and Zhanhong Ou and Yaosheng Lu and Víctor M. Campello and Jieyun Bai and Karim Lekadir},
  doi          = {10.1016/j.eswa.2025.128998},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128998},
  shortjournal = {Expert Syst. Appl.},
  title        = {Uncertainty-fetal head and pubic symphysis segmentation with enhanced multi-scale features and sparse visual graph attention},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expert system for non-technical loss detection in power distribution grids using particle swarm optimization and nested power flow integration. <em>ESWA</em>, <em>296</em>, 128997. (<a href='https://doi.org/10.1016/j.eswa.2025.128997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Technical Losses in power distribution grids, primarily caused by electricity theft and meter inaccuracies, pose a significant challenge to utility companies, impacting revenue and grid stability. This paper introduces a novel expert system integrating nested Power Flow analysis with swarm intelligence for accurate Non-Technical Losses detection and localization in distribution grids. The proposed system leverages smart meter data, grid topology, and substation transformer readings to formulate an optimization problem in which the Active Power and Reactive Power consumption of one or more consumers is estimated using Particle Swarm Optimization. A key feature of the system is its adaptability to various operational scenarios, such as grid size, topology uncertainty, and distributed energy resource penetration. Extensive experimental results confirm the effectiveness of the proposed NTL detection method. In simulated scenarios, the worst-case Mean Absolute Error for Active Power estimation is limited to 0.1391 kW, with a corresponding mean actual consumption of 1.004 kW. For Reactive Power, the Mean Absolute Error does not exceed 0.0175 kVAr, relative to a mean consumption of 0.1072 kVAr. When evaluated on real consumption data, the worst-case Mean Absolute Error for Active Power across all smart meters is 0.1028 kW, with a mean actual consumption of 5.1333 kW, while for Reactive Power the worst-case Mean Absolute Error reaches 0.1385 kVAr against a mean consumption of 2.3433 kVAr. Furthermore, in the specific case where real active and reactive consumption is zero the proposed method maintains Mean Absolute Error values of 0.8095 kW for Active power and 0.0944 kVAr for Reactive power, thus verifying its reliable performance in avoiding false positives.},
  archive      = {J_ESWA},
  author       = {Nikolaos-Antonios Livanos and Nikolaos Giamarelos and Alex Alexandridis and Elias N. Zois},
  doi          = {10.1016/j.eswa.2025.128997},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128997},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expert system for non-technical loss detection in power distribution grids using particle swarm optimization and nested power flow integration},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A design-guided industrial defect detection method with enhanced camouflaged defect identification. <em>ESWA</em>, <em>296</em>, 128996. (<a href='https://doi.org/10.1016/j.eswa.2025.128996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern industrial systems, deep learning methods are widely used for defect detection. However, the current detection paradigm primarily relies on feature differences among defects and normal areas, which makes it challenging to detect camouflaged defects that are actual defects but appear extremely similar to normal areas. Additionally, the diversity in sizes and categories of industrial defects further complicates the detection. To address these issues, we propose a Design-Guided Industrial Defect Detection (DIDD) method, which uses the design diagram of the sample as reference information to guide defect detection. Specifically, the features of both the sample and its design diagram are extracted by a weight-sharing CNN backbone and then compared through our proposed Multi-scale Difference Attention Module (MDAM), which integrates multi-scale pooling and spatial attention to highlight their discrepancies at multiple scales for camouflaged defect identification. Furthermore, we develop a Channel-wise Information Interaction Fusion Module (CIIF) to improve defect classification accuracy by enhancing the interaction of cross-layer features along the channel dimension. In addition, we propose a novel hybrid supervision strategy (HSS) that increases classification and localization supervision on object queries in the decoder through combining one-to-many supervision and one-to-one supervision, further enhancing detection performance. To validate the effectiveness of DIDD, a dataset (PCB-SCUT) containing PCB defect samples and their corresponding design diagrams is constructed, on which DIDD achieves a mean Average Precision (mAP) of 80.64 % at an Intersection over Union (IoU) threshold of 0.5 between prediction boxes and ground-truth bounding boxes.},
  archive      = {J_ESWA},
  author       = {Zican Hu and Jiaxiang Luo and Zixiang Hong and Jingyi Chen},
  doi          = {10.1016/j.eswa.2025.128996},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128996},
  shortjournal = {Expert Syst. Appl.},
  title        = {A design-guided industrial defect detection method with enhanced camouflaged defect identification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive self-supervised subspace clustering via KAN-based multi-view fusion. <em>ESWA</em>, <em>296</em>, 128995. (<a href='https://doi.org/10.1016/j.eswa.2025.128995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multi-view subspace clustering is an important unsupervised learning method, fuses heterogeneous multi-view data through deep neural networks to reveal the underlying data structure. However, existing methods often suffer from the following problems when dealing with complex data: (1) face dimensionality difficulties in high-dimensional data processing and rely on fixed coding methods; (2) lack a supervisory mechanism for high-confidence clustering information and rely on self-representation reconstruction constraints; (3) show insufficient synergy of cross-view information. To address these issues, we propose a method named contrastive self-supervised subspace clustering via KAN-based multi-view fusion (CSSCK). Specifically, we construct a parameterized activation function encoding layer to decompose high-dimensional mappings into univariate function combinations via the KAN theorem. Clustering labels are also utilized to guide the learning of each view feature expression to obtain enhanced features, and then the complementary information carried by enhanced features and original features is utilized to maintain the separateness and consistency among multiple views. Extensive experiments on five datasets spanning diverse scenarios (including high/low dimensions, large/small samples, and multi-view heterogeneous environments) demonstrate that CSSCK significantly outperforms both classical clustering algorithms and advanced deep multi-view approaches.},
  archive      = {J_ESWA},
  author       = {Er Wang and Siyu Chen and Lifan Peng and Xiaoqian Zhang and Yanchi Ou and Jiawei Peng},
  doi          = {10.1016/j.eswa.2025.128995},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128995},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive self-supervised subspace clustering via KAN-based multi-view fusion},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Object detection for autonomous vehicles under adverse weather conditions. <em>ESWA</em>, <em>296</em>, 128994. (<a href='https://doi.org/10.1016/j.eswa.2025.128994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving is a key technology for alleviating traffic congestion and improving travel experiences. The effectiveness of autonomous vehicles, however, depends on the stability of their perception systems, with object detection serving as a critical component. Adverse weather conditions and the dynamic traffic environments pose significant challenges to accurate acquisition of perception data, limiting progress in object detection techniques. This study provides a comprehensive survey of object detection methods under adverse weather conditions. It first examines the challenges introduced by various weather phenomena, such as rain, snow, fog, and varying light conditions, each of which can significantly impair the performance of detection systems. Furthermore, this study categorizes existing object detection models into three types: direct detection models, distributed models that incorporate image restoration (enhancement) prior to detection, and end-to-end models that integrate both image restoration and object detection. A detailed analysis of the strengths and weaknesses of each category is presented. Finally, the study identifies key challenges and emerging opportunities for future research in this domain.},
  archive      = {J_ESWA},
  author       = {Zhige Chen and Zhigang Zhang and Qizheng Su and Kai Yang and Yandong Wu and Lei He and Xiaolin Tang},
  doi          = {10.1016/j.eswa.2025.128994},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128994},
  shortjournal = {Expert Syst. Appl.},
  title        = {Object detection for autonomous vehicles under adverse weather conditions},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SDERIME: Enhanced RIME algorithm with sobol sequences and differential evolution for heavy calcium carbonate powder particle size distribution soft sensor model optimization. <em>ESWA</em>, <em>296</em>, 128993. (<a href='https://doi.org/10.1016/j.eswa.2025.128993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original RIME algorithm is regarded as an efficient meta -heuristic algorithm, it has limitations such as an imbalance between exploration and exploitation, local optimal sensitivity, and suboptimal convergence accuracy. To address these challenges, this paper proposes an enhanced RIME algorithm with Sobol sequences strategy and differential evolution (DE) strategy (SDERIME), which introduce the Sobol sequences strategy in the initialization stage of the RIME algorithm, the elite DE strategy in the hard-rime puncture mechanism, and combine the DE strategy after rime-searching process. In the CEC2017&2022 benchmark functions and 6 engineering problems test, by comparing with 14 other algorithms, the experimental results and statistical analysis proved that SDERIME is effective and efficient in various optimization tasks. And the application of SDERIME in the particle size distribution soft-sensing model of the heavy calcium carbonate (HCC) vertical roller mill (VRM) system has improved the prediction accuracy. These findings indicate that SDERIME has wide applicability and can be used as an advanced optimization technology in a variety of practical applications.},
  archive      = {J_ESWA},
  author       = {Shuai Zou and Maohui Peng and Jing Yang and Qing Feng and Mingyuan Dou and Fuchuan Huang and Lin Chen},
  doi          = {10.1016/j.eswa.2025.128993},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128993},
  shortjournal = {Expert Syst. Appl.},
  title        = {SDERIME: Enhanced RIME algorithm with sobol sequences and differential evolution for heavy calcium carbonate powder particle size distribution soft sensor model optimization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Double deep Q-network based multi-objective optimization for flexible job shop scheduling problem with heterogeneous automatic guided vehicles. <em>ESWA</em>, <em>296</em>, 128992. (<a href='https://doi.org/10.1016/j.eswa.2025.128992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly flexible automated manufacturing workshops, jobs need to be transported frequently between machines, so the limitations of transportation resources are receiving increasing attention. This paper investigates the flexible job shop scheduling problem with heterogeneous automatic guided vehicles (AGVs). A double deep Q-network (double DQN) based non-dominated sorting genetic algorithm II is proposed to minimize the makespan and total energy consumption. Firstly, an initialization strategy based on multiple heuristic methods is designed for better performance. Secondly, critical paths and blocks within the problem are identified using a disjunctive graph, from which six problem-driven local search operators are developed. Thirdly, double DQN is used to recommend the optimal local search operator. 13 features are selected to describe the current state of an individual, and the proposed operators are employed as actions. The effectiveness of the proposed algorithm is evaluated by comparing with four other advanced algorithms. Finally, a real world case is used to analyze the greater potential of heterogeneous AGVs compared with homogeneous AGVs in optimizing two objective values.},
  archive      = {J_ESWA},
  author       = {Rensheng Chen and Bin Wu},
  doi          = {10.1016/j.eswa.2025.128992},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128992},
  shortjournal = {Expert Syst. Appl.},
  title        = {Double deep Q-network based multi-objective optimization for flexible job shop scheduling problem with heterogeneous automatic guided vehicles},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flexible competitive weighted nonnegative representation method for classification. <em>ESWA</em>, <em>296</em>, 128991. (<a href='https://doi.org/10.1016/j.eswa.2025.128991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation based classification methods (RBCM) have gained considerable attention in the field of image classification. Nonnegative Representation based Classification (NRC) imposes a nonnegative constraint on the representation vector, which improves the representation power of homogeneous samples while suppressing that of heterogeneous samples, thus enhancing classification accuracy. However, NRC overlooks the necessity of distinct optimization weights for representation coefficients of different classes, and it fails to adequately consider the intrinsic relationship between representation and classification. To address these limitations, we propose a novel Flexible Competitive Weighted Nonnegative Representation (FCWNR) method. FCWNR introduces a competitive representation term and a class coefficient constraint term, which strengthen the connection between representation and classification while reducing the impact of coefficients associated with incorrect classes. Additionally, a key flexible factor is proposed and ingeniously embedded in both terms. This mechanism enforces penalties on class coefficients with weaker subspace representation capabilities, simultaneously intensifying the representation contribution of correct classes. Ultimately, FCWNR obtains a comprehensive enhancement in classification performance. Extensive experiments conducted on several challenging public image datasets demonstrate that FCWNR achieves superior classification performance. The source code will be made available on the author’s GitHub repository at https://github.com/li-zi-qi/FCWNR .},
  archive      = {J_ESWA},
  author       = {Ziqi Li and Hongcheng Song and Tingting Guo and Zhilin Chen and Yonghong Zhang and Jun Sun},
  doi          = {10.1016/j.eswa.2025.128991},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128991},
  shortjournal = {Expert Syst. Appl.},
  title        = {Flexible competitive weighted nonnegative representation method for classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting attributes and keywords for session-based recommendation with multi-view graph neural network. <em>ESWA</em>, <em>296</em>, 128990. (<a href='https://doi.org/10.1016/j.eswa.2025.128990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) aims to predict the next item of interest based on users’ short-term behaviors and has attracted increasing attention in recent years. However, existing methods often rely solely on user behaviors or integrating attribute information, but these methods may be insufficient when user behaviors are ambiguous or attributes are incomplete. To address these limitations, we propose a keyword and attribute-aware multi-view graph neural network (KAMVG) that constructs three distinct views, i.e., session view, attribute view, and keyword view. Specifically, the session view captures sequential item transitions to model contextual dependencies. The attribute view leverages heterogeneous graph structures enriched with semantic relationships, employing two attention mechanisms to effectively model relationships between sessions and items. The keyword view identifies shared intent across items within a session, effectively complementing attribute information. Finally, a multi-view fusion strategy integrates the information from all three views. Extensive experiments on three real-world datasets demonstrate that KAMVG consistently outperforms state-of-the-art baselines. Additionally, a case study of two randomly selected sessions provides intuitive insights into recommendation effectiveness of KAMVG.},
  archive      = {J_ESWA},
  author       = {Lei Chen and Xiaoping Zhu and Guixiang Zhu},
  doi          = {10.1016/j.eswa.2025.128990},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128990},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting attributes and keywords for session-based recommendation with multi-view graph neural network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cooperation dynamics on hypergraphs with punishment and Q-learning. <em>ESWA</em>, <em>296</em>, 128989. (<a href='https://doi.org/10.1016/j.eswa.2025.128989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Punishment has been proved to be a useful mechanism on pairwise interaction networks for promoting cooperation. However, these networks cannot effectively describe higher-order interactions in the multi-agent system, while hypergraph as a higher-order network has aroused extensive interests of researchers. Here, we study the evolutionary dynamics of spatial public goods game on uniform random hypergraphs with peer punishment mechanism. In that model, each agent chooses to become a cooperator, defector or punisher, and each punisher pay a cost to make each defector bear a fine. Different from the imitation rules in previous studies, we adopt self-regarding Q-learning algorithm to update agent’s strategy where agents take an action based on their historical experience to maximize their reward. Simulation results show that there is a moderate synergy factor can obtain the best result of the evolution of cooperation. For a certain relatively large synergy factor, there exists a combination of cost and fine to optimally promote cooperation. Furthermore, the theoretical analysis results are consistent with the simulation results.},
  archive      = {J_ESWA},
  author       = {Kuan Zou and Changwei Huang},
  doi          = {10.1016/j.eswa.2025.128989},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128989},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cooperation dynamics on hypergraphs with punishment and Q-learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Recurrent event-guided multimodal fusion for high dynamic range video reconstruction. <em>ESWA</em>, <em>296</em>, 128988. (<a href='https://doi.org/10.1016/j.eswa.2025.128988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional cameras, due to their limited dynamic range, often struggle with underexposure or overexposure in high-contrast scenes, resulting in the loss of critical details. Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) images is inherently an ill-posed problem, as recovering information in underexposed or overexposed regions presents significant challenges. Event cameras, inspired by biological vision, record brightness changes asynchronously in the form of “events”. This unique imaging mechanism endows event cameras with both higher temporal resolution and an extended dynamic range (exceeding 120 dB). The events encode complete visual signals, making them well-suited to address the limitations of LDR images captured by conventional cameras. In this paper, we propose an end-to-end Recurrent Event-Guided Multimodal Fusion HDR Video Reconstruction (REHDR) Framework to achieve efficient bimodal fusion for HDR reconstruction. Specifically, our model incorporates a recurrent network with dual encoders, which effectively leverages inter-frame information to mitigate flickering artifacts in video reconstruction. To address the complementary nature of the two modalities from different domains, we design a novel Adaptive Feature Modulation Fusion (AFMF) module to achieve seamless multimodal fusion of events and images. Additionally, we introduce a new Streaming Sampling and Augmentation Sequential Data Loading (SSASDL) method, providing a unified data loading framework for both single images and video image sequences. Furthermore, we construct the first large-scale, real-world, high-resolution dataset, RealHDR, to facilitate network training and evaluation. Experimental results demonstrate that our proposed model establishes a new technical benchmark in the field of HDR reconstruction. The source code and dataset are openly accessible at https://github.com/ice-cream567/REHDR .},
  archive      = {J_ESWA},
  author       = {Guangsha Guo and Ming Sun and Shilong Jing and Xianda Xu and Hechong Wang and Jialin Gu and Hengyi Lv and Yuchen Zhao},
  doi          = {10.1016/j.eswa.2025.128988},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128988},
  shortjournal = {Expert Syst. Appl.},
  title        = {Recurrent event-guided multimodal fusion for high dynamic range video reconstruction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Few-shot font generation via denoising diffusion and component-level fine-grained style. <em>ESWA</em>, <em>296</em>, 128987. (<a href='https://doi.org/10.1016/j.eswa.2025.128987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot font generation aims to create new fonts using a small number of style examples. It is increasingly gaining attention due to its significant reduction in labor costs. Existing methods rely on GAN-based image-to-image style-transfer frameworks, which are prone to training collapse and struggle to maintain consistency between character content and style. Moreover, they capture only the global style while overlooking fine-grained features of radicals, components, and strokes. To address these challenges, we propose a diffusion model-based image-to-image font generation method.We fully consider the component styles between content glyphs and reference glyphs, assigning appropriate fine-grained styles to content glyphs through a multi-character style aggregation module. Additionally, in order to better preserve the integrity of character structures during the denoising iteration process, we propose leveraging an offset-enhanced multi-head attention mechanism. This mechanism adaptively samples and embeds multi-scale glyph content features into the diffusion model. Comprehensive experiments demonstrate that our method outperforms existing font generation methods both qualitatively and quantitatively.},
  archive      = {J_ESWA},
  author       = {Yu Liu and Yang Ding and Fatimah Binti Khalid and Cunrui Wang and Lei Wang},
  doi          = {10.1016/j.eswa.2025.128987},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128987},
  shortjournal = {Expert Syst. Appl.},
  title        = {Few-shot font generation via denoising diffusion and component-level fine-grained style},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A learning-based co-evolution optimization framework for energy-aware distributed heterogeneous flexible flow shop lot-streaming scheduling problem. <em>ESWA</em>, <em>296</em>, 128986. (<a href='https://doi.org/10.1016/j.eswa.2025.128986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed heterogeneous flexible flow shop scheduling problem (DHFFSP) has been considered in the era of economic globalization. Meanwhile, in some actual production scenarios, some jobs are divided into multiple sub-lots to boost the efficiency of intelligent manufacturing systems. The complexity of the scheduling problem is increased by the inevitable multiple time constraints among the jobs. In addition, considering the energy consumption, the energy-aware distributed heterogeneous flexible flow shop lot-streaming scheduling problem (EADHFFLSP) with release times, sequence-dependent setup and transport times is studied in the context of green manufacturing, which conforms to the actual production scenario of aluminum industry in the non-ferrous metallurgical industry. A learning-based co-evolution optimization framework (LBCOF) is designed to address EADHFFLSP with the minimization objectives of the maximum completion time and total energy consumption. In LBCOF, the population is divided into a global population and a local population, which performs global search and local search operations, respectively. Three heuristic rules are devised to generate the initial population. In local search, eight single-factory knowledge-driven operators and ten multi-factory knowledge-driven operators are proposed to update local population. A learning-based selection mechanism with dueling double deep Q-network (Dueling DDQN) component is presented to pick the best local search operator for the local population. Two energy-saving strategies are developed to improve the local population. The experimental findings reveal that LBCOF exhibits superior performance compared to some state-of-the-art algorithms for addressing EADHFFLSP.},
  archive      = {J_ESWA},
  author       = {Fuqing Zhao and Fumin Yin and Jianlin Zhang and Tian Peng Xu},
  doi          = {10.1016/j.eswa.2025.128986},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128986},
  shortjournal = {Expert Syst. Appl.},
  title        = {A learning-based co-evolution optimization framework for energy-aware distributed heterogeneous flexible flow shop lot-streaming scheduling problem},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge-cloud deep learning computing for detecting heart failure with preserved ejection fraction on cardiac ultrasound. <em>ESWA</em>, <em>296</em>, 128985. (<a href='https://doi.org/10.1016/j.eswa.2025.128985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the global phenomenon of an aging population has garnered widespread attention, particularly with a marked rise in the incidence of heart failure. The significant surge in heart failure cases not only poses profound challenges to the global healthcare system but also imposes considerable emotional and financial burdens on families. In response to this escalating health concern, this study endeavors to amalgamate intelligent computing with advancements in medical diagnostics, introducing a deep learning computational framework based on edge-cloud computing tailored explicitly for precisely detecting heart failure. Beyond the theoretical proposition, this work has been implemented as a cross-platform system suitable for direct application in clinical environments. The system can predict whether a patient suffers from heart failure with preserved ejection fraction (HFpEF) by merely inputting echocardiographic images. The system synergistically harnesses the advantages of both cloud and edge computing: deep learning models are trained and compressed in a high-performance cloud environment and subsequently deployed at the edge for real-time inference. All the data used in this study were collected in collaboration with the Division of Cardiology, Department of Internal Medicine, MacKay Memorial Hospital in Taipei, Taiwan. The dataset comprises 501 patients with apical two-chamber (A2C) views and 507 patients with apical four-chamber (A4C) views for training left atrium (LA) and left ventricle (LV) detection/segmentation models, and 324 patients with A4C views for training right ventricle (RV) detection/segmentation models. In addition, the publicly available CAMUS dataset was used to evaluate LA and LV segmentation performance. In chamber detection, the misclassification rates for A2C and A4C views were less than 1%. LA, LV, and RV segmentation misclassification rates were 5%, 1%, and 33%, respectively. On the CAMUS dataset, the segmentation performance reached a Jaccard index of 85% for the LA and 78% for the LV. For the classification of HFpEF, both SVM and XGBoost classifiers achieved validation metrics exceeding 83%, including Precision, Sensitivity, Specificity, and F1-score. By integrating cloud-edge AI capabilities, our system demonstrates the potential for AI-driven clinical interventions in real-world settings, indicating that AI is not merely an auxiliary tool but a pivotal component in modern diagnostic strategies.},
  archive      = {J_ESWA},
  author       = {Tse-Hsien Lu and Wu-Chun Chung and Chung-Lieh Hung and Che-Lun Hung},
  doi          = {10.1016/j.eswa.2025.128985},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128985},
  shortjournal = {Expert Syst. Appl.},
  title        = {Edge-cloud deep learning computing for detecting heart failure with preserved ejection fraction on cardiac ultrasound},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fresh-products community group-buying delivery problem for heterogeneous customers. <em>ESWA</em>, <em>296</em>, 128984. (<a href='https://doi.org/10.1016/j.eswa.2025.128984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online community group-buying of fresh products has emerged as a popular model in urban e-commerce. This paper studies fresh products community group buying delivery problem of multiple commodities considering customer behavior. Compared with traditional fresh products e-commerce in which each customer is distributed individually, community group buying introduces a community leader to receive fresh products from distributors and residents in this community pick up their orders from this leader. The time gap between the distributor’s delivery to the community leader and the residents’ pick-up from the leader results in further deterioration of fresh products, which is the challenge in online community group-buying. We establish a distribution model considering deterioration of fresh products in refrigerated trucks and at the community leader’s location, in which three types of penalty costs are used to represent heterogeneous customer behaviors. Since different residents have separated delivery time windows, prioritizing delivery for which customers must be balanced. We design a memetic algorithm for this non-linear programming. A split algorithm considering multi-commodity delivery and time-varying arc costs is designed to improve the efficiency of memetic algorithm. Experiments show that the proposed method reduces total cost by an average of 13.18% compared to a commercial solver within a fixed time budget. The case study based on data from Beijing provides management insights. Specifically, delivery routes tend to prioritize communities with a higher concentration of retired residents, while increased customer diversity is associated with lower vehicle utilization rates.},
  archive      = {J_ESWA},
  author       = {Yankai Zhang and Kaiqi Zhao and Shiwei Liang and Na Liu and Shiyi Xu and Bin Yu and Wenxuan Shan},
  doi          = {10.1016/j.eswa.2025.128984},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128984},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fresh-products community group-buying delivery problem for heterogeneous customers},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDBA: Defending graph neural networks via attribute debiasing. <em>ESWA</em>, <em>296</em>, 128983. (<a href='https://doi.org/10.1016/j.eswa.2025.128983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable success due to their outstanding expressive ability, but they are easily susceptible to adversarial attacks. Existing research defends GNNs mainly by pruning potentially vulnerable edges or assigning more robust weights. However, they neglect the fact that nodes have biases towards their various attributes, that is, the importance of different attributes varies greatly. Since sensitive (i.e., important) attributes may cause similar nodes to be mistakenly regarded as dissimilar, leading to errors in node similarity assessment. By diminishing the bias of node attributes, we can conduct more accurate node similarity assessments for reasonable pruning and weight assignment. To this end, we propose a G NN adversarial D efender via de B iasing node A ttributes ( GDBA ). Specifically, we first propose a novel unbiased attribute-augmented personalized PageRank (PPR), which debiases the node attributes by adopting a new state transition mechanism. This method can consider high-order information to compute node similarity based on both graph topology and node attributes. Subsequently, we introduce an effective mutual information regularization mechanism to the GNNs, for debiasing the influence of sensitive attributes to learn more robust weights. Notably, GDBA can be seamlessly integrated into various GNN architectures, significantly enhancing their robustness against adversarial attacks. Finally, extensive experiments show that our proposal can effectively defend GNNs against adversarial attacks compared with state-of-the-art approaches. For reproducibility, our source codes are available at https://github.com/Painnb/GDBA .},
  archive      = {J_ESWA},
  author       = {Zhiqiu Ye and Longlong Lin and Jie Li and Tao Liu and Zeli Wang},
  doi          = {10.1016/j.eswa.2025.128983},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128983},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDBA: Defending graph neural networks via attribute debiasing},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Probabilistic adaptive learning for enhanced speech emotion recognition in the presence of noisy labels. <em>ESWA</em>, <em>296</em>, 128982. (<a href='https://doi.org/10.1016/j.eswa.2025.128982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise in the dataset reduces the performance of speech emotion recognition, which makes its real-world application more challenging. In this paper, our focus is on the impact of this noise in a multi-annotator setting. We propose a novel speech emotion recognition algorithm that leverages probability adaptive learning. This algorithm iteratively refines labels via momentum-based updates of model predictions for technical precision and adjusts the loss function in line with predicted probabilities, effectively filtering out samples impacted by label noise. Our comprehensive experiments across diverse scenarios on public datasets demonstrate the algorithm’s effectiveness in mitigating label noise, highlighting its robustness and adaptability.},
  archive      = {J_ESWA},
  author       = {Huijuan Zhao and Keji Han and Weibei Fan and Ning Ye and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.128982},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128982},
  shortjournal = {Expert Syst. Appl.},
  title        = {Probabilistic adaptive learning for enhanced speech emotion recognition in the presence of noisy labels},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simplifying the operation of hybrid ad-hoc sensor networks with neural networks as the sole data reconstruction method. <em>ESWA</em>, <em>296</em>, 128981. (<a href='https://doi.org/10.1016/j.eswa.2025.128981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid ad hoc sensor networks, which are known for their cost-effective sensors and opportunistic yet affordable management, are becoming increasingly popular. In such networks, in addition to data reconstruction, various different methods are used to address operational problems, such as failure of sensors, resilience against attacks, loss of calibration, etc. A combination of several methods may not always be practical or optimal. However, this research demonstrates that it is not only possible but also beneficial to use a single data reconstruction method instead, thus decreasing the operational cost. Artificial neural networks, and particularly the multi-layer perceptron, are proposed as a single method. Through simulations, nine scenarios are analyzed to demonstrate the fitness for purpose of this approach. The findings demonstrate that the multi-layer perceptron can not only be used as a sole data reconstruction method, but also consistently improves the quality of data reconstruction across all the scenarios tested here.},
  archive      = {J_ESWA},
  author       = {Piotr Cofta},
  doi          = {10.1016/j.eswa.2025.128981},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128981},
  shortjournal = {Expert Syst. Appl.},
  title        = {Simplifying the operation of hybrid ad-hoc sensor networks with neural networks as the sole data reconstruction method},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fragment-energy audio watermarking resilient to de-synchronization attacks. <em>ESWA</em>, <em>296</em>, 128980. (<a href='https://doi.org/10.1016/j.eswa.2025.128980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the domain of Industry 4.0, encompassing diverse sectors like the music industry, intellectual property violation poses a significant concern. Digital watermarking shows great promise as a technique to enforce intellectual property rights for audio signals. However, ensuring robustness against de-synchronization attacks remains a significant problem in audio watermarking. In this paper, we introduce a new and robust audio watermarking scheme that utilizes the time domain fragment energy relationship (TDFER) feature to resist both common and de-synchronization attacks. During the embedding process, the audio signal is first split into numerous segments, each of which will be subsequently further split into two fragments. Each watermark bit will be embedded into a pair of fragments by adjusting the energy relationship between the fragments. The specially designed adaptive modification window functions (AMWFs) are used to modify the audio signal smoothly without causing perceptible distortion at the fragment boundaries. In the decoding process, the embedded watermark will be retrieved by comparing the energies of the paired fragments in each segment. Theoretical analysis and empirical findings provide compelling evidence for the exceptional performance of our proposed scheme. In particular, under ± 20 % time-scale modification (TSM), our proposed scheme achieves a bit error rate of 0 %, demonstrating its strong robustness in practical scenarios.},
  archive      = {J_ESWA},
  author       = {Juan Zhao and Tianrui Zong and Iynkaran Natgunanathan and Yong Xiang and Xiangyu Song and Guang Hua and Longxiang Gao and Wanlei Zhou},
  doi          = {10.1016/j.eswa.2025.128980},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128980},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fragment-energy audio watermarking resilient to de-synchronization attacks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploratory analysis and prognostication of multimorbidity trajectories in middle-aged and elderly populations: A machine learning approach. <em>ESWA</em>, <em>296</em>, 128979. (<a href='https://doi.org/10.1016/j.eswa.2025.128979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimorbidity has become an increasingly severe public health challenge worldwide, severely impacting the health status and quality of life of middle-aged and elderly populations. Understanding the long-term trajectory of multimorbidity is essential for implementing personalized and proactive health management measures. This study, based on data from the China Health and Retirement Longitudinal Study (CHARLS), uses the Dynamic Time Warping-based K-means clustering algorithm (DTW-K-means) to analyze multimorbidity trajectories (MOTRs) in middle-aged and elderly populations. The study identified four distinct health trajectory subtypes: stable low-risk group, moderately stable group, progressively worsening group, and continuously deteriorating group, each of which is associated with a distinct level of mortality risk. Further external validation with data from the China Longitudinal Healthy Longevity Survey (CLHLS) confirmed the robustness and universality of the trajectory clustering model. The findings indicate that the DTW-K-means clustering method effectively captures the dynamic and complex features of multimorbidity, offering a solid theoretical foundation and actionable support for precision medicine and personalized health management.},
  archive      = {J_ESWA},
  author       = {Li Yao and Qiaoxing Li and Jiajia Yin and Dongliang Yang and Hainan Yang},
  doi          = {10.1016/j.eswa.2025.128979},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128979},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploratory analysis and prognostication of multimorbidity trajectories in middle-aged and elderly populations: A machine learning approach},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generative adversarial networks-enabled anomaly detection systems: A survey. <em>ESWA</em>, <em>296</em>, 128978. (<a href='https://doi.org/10.1016/j.eswa.2025.128978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly Detection (AD) is an important area of research because it helps identify outliers in data, enabling early detection of errors, fraud, and potential security breaches. Machine Learning (ML) can be utilized for distinct AD systems, and Generative Adversarial Networks (GANs) have emerged as a promising technique due to their ability to generate new data that closely resembles a given dataset, allowing for the creation of realistic images, videos, audio, text, and other types of synthetic data. This paper explores state-of-the-art approaches in AD using GANs. The paper starts by providing a comprehensive overview of ML techniques for AD, including supervised, unsupervised, and semi-supervised approaches. This survey also explores various AD approaches based on GANs and provides an application-based classification of GANs-based AD approaches in the Internet-of-Things (IoT), Industrial IoT, Digital Healthcare, Energy Management Systems, and Cellular Network domains. Moreover, the paper discusses several datasets used in evaluating the performance of GANs-based AD techniques such as BOT-IoT, TON-IoT, CIC-IoT, CIC-IDS, and NSL-KDD. These datasets serve as valuable resources for researchers and practitioners to develop and test AD systems, particularly in the context of IoT and network security. Furthermore, the paper discusses the challenges and limitations of GANs-based AD techniques and proposes future research directions to address these challenges.},
  archive      = {J_ESWA},
  author       = {Umer Saeed and Sana Ullah Jan and Jawad Ahmad and Syed Aziz Shah and Mohammed S. Alshehri and Yazeed Yasin Ghadi and Nikolaos Pitropakis and William J. Buchanan},
  doi          = {10.1016/j.eswa.2025.128978},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128978},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generative adversarial networks-enabled anomaly detection systems: A survey},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust deep dictionary learning via self-expression neighbor atom enhancement. <em>ESWA</em>, <em>296</em>, 128977. (<a href='https://doi.org/10.1016/j.eswa.2025.128977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary learning has been widely recognized as an effective method for processing high-dimensional and nonlinear data. Although graph structures have been widely adopted to enhance optimization in irregular data handling, existing approaches inadequately utilize local graph information, leading to suboptimal dictionary update. Consequently, the learned dictionary struggles to capture local details effectively, which can negatively impact the performance of classification tasks. To tackle this problem, this study proposes a method based on graph structure, dubbed Deep Neighbor Atom-enhanced Dictionary Learning (DNADL), designed to enhance the sensitivity of dictionaries to local structure. Our DNADL segments data into internally consistent neighborhood manifold module via clustering method and enhances dictionary atoms based on their self-expression relationships, where the self-expression relationships within generated manifolds reflect the intrinsic correlation of local data structures. Enhanced dictionary atoms exploit the similarities among neighboring data points, ensuring that the constructed dictionary effectively captures local structure features. Furthermore, this study introduces an adaptive graph learning module that dynamically updates graph representations, thereby facilitating the simultaneous optimization of dictionary learning and graph topology within an integrated framework. Comprehensive experimental results demonstrate that DNADL achieves state-of-the-art classification performance across multiple benchmark datasets, with accuracies of 99.23 % on Fashion-MNIST, 94.12 % on EMNIST, and 95.3 % on Oxford Flowers 102. By effectively capturing local structural features, DNADL surpasses existing methods by a significant margin of 0.98 % to 3.70 % in accuracy.},
  archive      = {J_ESWA},
  author       = {Heping Song and Yusen Qian and Sumet Mehta and Jianping Gou and Hongying Meng and Xiangjun Shen},
  doi          = {10.1016/j.eswa.2025.128977},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128977},
  shortjournal = {Expert Syst. Appl.},
  title        = {Robust deep dictionary learning via self-expression neighbor atom enhancement},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Immunizing over-smoothing: Dual-channel graph convolutional network. <em>ESWA</em>, <em>296</em>, 128976. (<a href='https://doi.org/10.1016/j.eswa.2025.128976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Network (GCN) has achieved significant success in exploring data from non-Euclidean spaces. However, most existing GCN-based models suffer from over-smoothing that leads to a dramatic performance decline as the number of network layers increases, resulting in restricted information propagation across node neighbors. To tackle this issue, some approaches attempt to drop edges or nodes to prevent indistinguishable representations after aggregating multi-hop information. Although these methods can partially alleviate over-smoothing, they inevitably lead to information loss. In light of this, we propose a novel framework DualGCN, which leverage two parallel channels to mitigate the semantic loss induced by previous dropout-based methods while further addressing over-smoothing. In specific, the model consists of two distinct but complementary subnetworks: a semantic GCN and a topological GCN, each incorporating a masking layer to prevent rapid convergence of node representations in deep GCNs. Meanwhile, to avoid the negative influence caused by the masking operation, hidden representations from the two subnetworks serve as residual connections to each other, and a collaborative loss is devised to guide the optimization of representations, ensuring the effective learning of discriminative features. Extensive experiments demonstrate that the proposed DualGCN effectively mitigates over-smoothing and outperforms multiple advanced competitors in semi-supervised node classification tasks across several public datasets.},
  archive      = {J_ESWA},
  author       = {Canyang Guo and Xianwei Guo and Sujia Huang and Yuchao Su and Daxin Zhu and Jianbing Xiahou},
  doi          = {10.1016/j.eswa.2025.128976},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128976},
  shortjournal = {Expert Syst. Appl.},
  title        = {Immunizing over-smoothing: Dual-channel graph convolutional network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable autoencoder integrating regression and classification trees for anomaly detection. <em>ESWA</em>, <em>296</em>, 128975. (<a href='https://doi.org/10.1016/j.eswa.2025.128975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainability in outlier detection is a crucial requirement in high-risk domains such as medicine and finance. As models increase complexity to improve accuracy, their interpretability is often hindered, creating a significant trade-off. Furthermore, the ability to handle both numerical and categorical attributes within the same model remains a challenge. To address this, we propose the Explainable Outlier Tree-based Encoder (EOTE), a novel anomaly detection model that integrates classification and regression trees within an autoencoder framework. EOTE generates human-readable explanations of outlier scores and can learn from mixed-attribute datasets. We evaluate EOTE against 12 leading anomaly detection algorithms across 110 datasets with mixed or single attribute type data. Our findings show that EOTE is one of the top-performing algorithms at detecting outliers in datasets with a single data type (numerical and nominal) and with mixed attribute data. Additionally, our proposal is able to provide explanations, making it suitable for use in high-risk applications.},
  archive      = {J_ESWA},
  author       = {Zoe Caballero-Dominguez and Raúl Monroy and Miguel Angel Medina-Pérez},
  doi          = {10.1016/j.eswa.2025.128975},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128975},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable autoencoder integrating regression and classification trees for anomaly detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPTrack: Dual-prompt guided network for visual object tracking. <em>ESWA</em>, <em>296</em>, 128974. (<a href='https://doi.org/10.1016/j.eswa.2025.128974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, prompt-based spatio-temporal trackers have achieved impressive advancements. However, these methods tend to incorporate only limited spatio-temporal information through prompts, such as recursive prompts or historical prompts, which fail to fully exploit spatio-temporal context information in video sequences, i.e., the instantaneous states of nearby frame and the consistent states of past frames. This oversight inhibits further performance improvement in complex scenes. To tackle this issue, we resort to prompt learning and present a dual-prompt guided visual tracking network (DPTrack), consisting of an instantaneous prompt network (IPN) and a spatio-temporal consistency prompt network (ST-CPN). Specifically, the IPN captures the appearance changes of the nearby frame to generate instantaneous prompt, which are directly involved in feature extraction and information interaction. The ST-CPN learns a set of learnable prompts to summarize the spatio-temporal consistency of previous frames, and then iteratively guides the search features to emphasize the target embedding. In this way, the dual-prompt exploits rich spatio-temporal cues, enhancing the adaptability and robustness of the tracker. Furthermore, we introduce a spatio-temporal pooling collection mechanism (SPC) to maintain consistency and adapt to the appearance changes. Extensive experiments on seven benchmarks prove that the proposed DPTrack achieves very promising tracking performance. Our DPTrack achieves 77.6 % AO on GOT-10k and 52.8 % AUC on LaSOT e x t . Notably, it obtains 73.9 % AUC, 81.8 % P, and 84.5 % P N o r m on LaSOT, 60.8 % EAO, 78.2 % A, and 89.3 % R on VOT2020, outperforming the remarkable trackers and demonstrating its superiority.},
  archive      = {J_ESWA},
  author       = {Kang Liu and Long Liu and Jiaqi Wang and Pingyan Hu and Yunhe Wang},
  doi          = {10.1016/j.eswa.2025.128974},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128974},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPTrack: Dual-prompt guided network for visual object tracking},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A conditional masked autoencoder network based on efficient multiple-head self-attention for characterizing heterogeneous reservoirs. <em>ESWA</em>, <em>296</em>, 128973. (<a href='https://doi.org/10.1016/j.eswa.2025.128973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditioning data such as wells, outcrops, and seismic data, stand as pivotal elements for the characterization of realistic and trustworthy reservoir structures and properties. It has been a longstanding challenge to establish geological models conforming to multiple-scale spatial features based on conditioning hard and/or soft data. To address the difficulties of conditional simulation and capturing complex multiple-scale spatial patterns in reservoir characterization, we propose a conditional masked autoencoder network for characterizing heterogeneous reservoirs based on an efficient multiple-head self-attention mechanism, which is named EMSA-CMAE. This method seamlessly integrates semantic inpainting from computer vision with reservoir characterization and facilitates the natural embedding of conditioning data within the masked autoencoder network. Moreover, the utilization of an efficient multiple-head self-attention (EMSA) module significantly reduces the computational overhead in EMSA-CMAE. We employ three sets of training images to verify the availability and robustness of EMSA-CMAE. In experiments, the masking ratio is set to 90 %, and statistical methods, such as histograms, RMSE, MDS maps, and variograms, are employed to measure attribute proportion, pixel error, and spatial heterogeneity of the realizations. The average RMSE across all three datasets is 0.17, and the comparative analysis reveals that the employing of the semantic repair strategy and the EMSA module enhances the ability of EMSA-CMAE to reproduce the spatial structures and properties of heterogeneous reservoirs.},
  archive      = {J_ESWA},
  author       = {Qiyu Chen and Ruihong Zhou and Dajie Chen and Zhesi Cui and Xiaogang Ma and Gang Liu},
  doi          = {10.1016/j.eswa.2025.128973},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128973},
  shortjournal = {Expert Syst. Appl.},
  title        = {A conditional masked autoencoder network based on efficient multiple-head self-attention for characterizing heterogeneous reservoirs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An alignment-error-free framework for end-to-end table recognition. <em>ESWA</em>, <em>296</em>, 128971. (<a href='https://doi.org/10.1016/j.eswa.2025.128971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The table recognition problem becomes the research hotspot in pattern recognition. Previous methods combine table structure recognition (TSR) with an optical character recognition (OCR) system to address this problem, in which the OCR system is used to recognize the textual contents of the table. However, the framework of these methods inevitably introduces alignment errors between the TSR and OCR results, thereby restricting performance. This paper proposes E2eTRNet, whose framework supports TSR and TCR in an end-to-end trainable manner without the need for any OCR systems. It can auto-align the TSR and table content recognition (TCR) results by collecting the cell semantic features in the structure decoder and triggering the content decoder to recognize text. As a result, this framework eliminates alignment errors and surpasses previous methods in performance. Moreover, we introduce a Visual Interaction Module (VIM) to normalize the attention mechanism of the sequence decoder using the visual features from the cell detection branch. In the experiment, E2eTRNet surpasses the state-of-the-art (SOTA) model in the table recognition task, and our framework outperforms the traditional one in all experimental settings. Moreover, specifically designed for table recognition, our model outperforms general-purpose large language models. Codes: https://github.com/MaxKinny/E2eTRNet},
  archive      = {J_ESWA},
  author       = {Fan Yang and Ling Deng and Zhiyong Gan and Shuangping Huang and Tianshui Chen},
  doi          = {10.1016/j.eswa.2025.128971},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128971},
  shortjournal = {Expert Syst. Appl.},
  title        = {An alignment-error-free framework for end-to-end table recognition},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A modified domain adversarial approach based on model and data-driven for bearing fault diagnosis. <em>ESWA</em>, <em>296</em>, 128970. (<a href='https://doi.org/10.1016/j.eswa.2025.128970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing fault diagnosis is essential for maintaining the reliability and stability of mechanical equipment. However, obtaining sufficient labeled data in real scenarios is high-risk and challenging, which limits the further application of traditional data-driven approaches. In this research, a novel model and data-driven approach called the modified domain adversarial neural network (MDANN) is developed for bearing fault identification. Specifically, a bearing dynamic model is established, so that the priori information on bearing failures can be acquired by finite element simulation. A data-driven MDANN model is then developed for feature extraction and cross domain transfer from simulated data to measured data. The attention module is introduced for feature weight reassignment, so that the priority of domain-invariant features is increased and negative transfer is suppressed. The improved loss function incorporating adaptive CORAL is designed to align both marginal and conditional distributions. Finally, the validity of the proposed MDANN is validated through two cases. The results demonstrate that the domain transfer capability of MDANN outperforms other methods in cross-domain tasks.},
  archive      = {J_ESWA},
  author       = {Ning Zhang and Zhaohui Qiao and Baosu Guo and Fenghe Wu and Junwei Fan},
  doi          = {10.1016/j.eswa.2025.128970},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128970},
  shortjournal = {Expert Syst. Appl.},
  title        = {A modified domain adversarial approach based on model and data-driven for bearing fault diagnosis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predicting lithium-ion battery health using attention mechanism with kolmogorov-arnold and physics-informed neural networks. <em>ESWA</em>, <em>296</em>, 128969. (<a href='https://doi.org/10.1016/j.eswa.2025.128969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of industries like electric vehicles has heightened the demand for high-performance lithium-ion batteries, driving innovations and posing challenges in state of health (SOH) prediction. Accurate SOH prediction is essential for maximizing battery lifespan and ensuring safety, enabling optimal recycling timing and promoting sustainable resource management. Existing prediction methods, primarily based on single parameters like voltage or current, lack physical constraints and fail to capture complex battery degradation patterns. The proposed novel physics-informed neural network (PINN) integrates an attention mechanism with Kolmogorov-Arnold networks (KAN) to capture the dynamic characteristics of battery degradation and enhancing SOH prediction. The health indicators used as input are extracted from experimental data during charge-discharge cycles. While KAN captures dynamic degradation characteristics, PINN incorporates physical constraints, improving prediction accuracy. Validated on a public dataset for lithium-ion battery degradation research, the proposed model achieves a mean absolute error (MAE) of 0.0056, mean absolute percentage error (MAPE) of 0.5949 %, and root mean square error (RMSE) of 0.0069. Compared to benchmark models, our approach shows a reduction of 32.5 % in MAE, 32.9 % in MAPE, and 34.9 % in RMSE. Furthermore, the proposed model achieved the coefficient of determination greater than 0.9282 on a dataset containing three different chemical compositions of lithium-ion batteries, indicating good applicability across various battery chemistries.},
  archive      = {J_ESWA},
  author       = {Congxin Wei and Haikuo Pang and Teng Huang and Zidong Quan and Zhifeng Qian},
  doi          = {10.1016/j.eswa.2025.128969},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128969},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predicting lithium-ion battery health using attention mechanism with kolmogorov-arnold and physics-informed neural networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IEBAKER: Improved remote sensing image-text retrieval framework via eliminate before align and keyword explicit reasoning. <em>ESWA</em>, <em>296</em>, 128968. (<a href='https://doi.org/10.1016/j.eswa.2025.128968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR), which aims at searching for the corresponding targets based on the given query. Among these efforts, the application of Foundation Models (FMs), such as CLIP, to the domain of remote sensing has yielded encouraging outcomes. However, existing FM based methodologies neglect the negative impact of weakly correlated sample pairs and fail to account for the key distinctions among remote sensing texts, leading to biased and superficial exploration of sample pairs. To address these challenges, we propose an approach named iEBAKER (an Improved Eliminate Before Align strategy with Keyword Explicit Reasoning framework) for RSITR. Specifically, we propose an innovative Eliminate Before Align (EBA) strategy to filter out the weakly correlated sample pairs, thereby mitigating their deviations from optimal embedding space during alignment.Further, two specific schemes are introduced from the perspective of whether local similarity and global similarity affect each other. On this basis, we introduce an alternative Sort After Reversed Retrieval (SAR) strategy, aims at optimizing the similarity matrix via reverse retrieval. Additionally, we incorporate a Keyword Explicit Reasoning (KER) module to facilitate the beneficial impact of subtle key concept distinctions. Without bells and whistles, our approach enables a direct transition from FM to RSITR task, eliminating the need for additional pretraining on remote sensing data. Extensive experiments conducted on three popular benchmark datasets demonstrate that our proposed iEBAKER method surpasses the state-of-the-art models while requiring less training data. Our source code will be released at https://github.com/zhangy0822/iEBAKER.},
  archive      = {J_ESWA},
  author       = {Yan Zhang and Zhong Ji and Changxu Meng and Yanwei Pang},
  doi          = {10.1016/j.eswa.2025.128968},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128968},
  shortjournal = {Expert Syst. Appl.},
  title        = {IEBAKER: Improved remote sensing image-text retrieval framework via eliminate before align and keyword explicit reasoning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AdvReal: Physical adversarial patch generation framework for security evaluation of object detection systems. <em>ESWA</em>, <em>296</em>, 128967. (<a href='https://doi.org/10.1016/j.eswa.2025.128967'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles are typical complex intelligent systems with artificial intelligence at their core. However, perception methods based on deep learning are extremely vulnerable to adversarial samples, resulting in security accidents. How to generate effective adversarial examples in the physical world and evaluate object detection systems is a huge challenge. In this study, we propose a unified joint adversarial training framework for both 2D and 3D domains, which simultaneously optimizes texture maps in 2D image and 3D mesh spaces to better address intra-class diversity and real-world environmental variations. The framework includes a novel realistic enhanced adversarial module, with time-space and relighting mapping pipeline that adjusts illumination consistency between adversarial patches and target garments under varied viewpoints. Building upon this, we develop a realism enhancement mechanism that incorporates non-rigid deformation modeling and texture remapping to ensure alignment with the human body’s non-rigid surfaces in 3D scenes. Extensive experiment results in digital and physical environments demonstrate that the adversarial textures generated by our method can effectively mislead the target detection model. Specifically, our method achieves an average attack success rate (ASR) of 70.13 % on YOLOv12 in physical scenarios, significantly outperforming existing methods such as T-SEA (21.65 %) and AdvTexture (19.70 %). Moreover, the proposed method maintains stable ASR across multiple viewpoints and distances, with an average attack success rate exceeding 90 % under both frontal and oblique views at a distance of 4 meters. This confirms the method’s strong robustness and transferability under multi-angle attacks, varying lighting conditions, and real-world distances. The demo video and code can be obtained at https://github.com/Huangyh98/AdvReal.git .},
  archive      = {J_ESWA},
  author       = {Yuanhao Huang and Yilong Ren and Jinlei Wang and Lujia Huo and Xuesong Bai and Jinchuan Zhang and Haiyang Yu},
  doi          = {10.1016/j.eswa.2025.128967},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128967},
  shortjournal = {Expert Syst. Appl.},
  title        = {AdvReal: Physical adversarial patch generation framework for security evaluation of object detection systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fidelity-preserving concept stylization with ST-LoRA and multimodal conditions. <em>ESWA</em>, <em>296</em>, 128966. (<a href='https://doi.org/10.1016/j.eswa.2025.128966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept personalization and image stylization have achieved prominent advancements owing to powerful text-to-image models. Nevertheless, several issues remain in concept stylization. First, overfitting to a concept during fine-tuning will degrade its stylization effect. Second, extracting style features with training-based methods may induce content leakage. Third, merging the learned weights of a concept-style pair makes it difficult to fuse these two elements. To overcome these challenges,we introduce Fidelity-Preserving Concept Stylization , a novel task that stylizes a concept while preserving its fidelity, and propose a method to achieve this effectively. To mitigate overfitting, we propose a two-stage optimization strategy. A S pecial T oken and a layer-wise LoRA adapter (ST-LoRA) are jointly optimized with customized timestep distributions, progressively capturing target concept features. To stylize the learned concept with high fidelity, we propose a training-free architecture guided by multimodal conditions. The style and concept features are first extracted from reference images by a pretrained image adapter. These image features together with text embedding are subsequently processed and projected into a shared space as multimodal conditions. We propose a dynamic feature fusion strategy to fuse concept and style features with minimal interference. Three strategies are introduced: element-wise subtraction, thresholding, and iterative stylization. These strategies are introduced to enhance the stylization effect. Our method maintains the balance between stylization effect and concept fidelity. Comprehensive experiments demonstrate the effectiveness of our method, outperforming other relevant methods in the results for the novel task.},
  archive      = {J_ESWA},
  author       = {Suoyu Zhang and Eric C.C. Tsang and Yong Wang and Jiaming Wu},
  doi          = {10.1016/j.eswa.2025.128966},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128966},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fidelity-preserving concept stylization with ST-LoRA and multimodal conditions},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised semantic segmentation with confidence-driven consistency learning. <em>ESWA</em>, <em>296</em>, 128965. (<a href='https://doi.org/10.1016/j.eswa.2025.128965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing consistency regularization based semi-supervised semantic segmentation methods prioritize ensuring prediction consistency for high-confidence pixels across different augmented views, neglecting the inter-class competition among high-confidence pixels and the training value of low-confidence pixels, which results in inefficient utilization of unlabeled data. Therefore, this paper proposes a C onfidence- D riven C onsistency L earning ( CDCL ) method to effectively exploit the potential of unlabeled data. Specifically, we first design a Residual Probabilities Rebalancing ( RPR ) strategy to mitigate the competition between the Top -1 class (with the highest probability) and confusing classes among high-confidence pixels, thereby preventing the model from learning erroneous biases. Furthermore, we propose a Negative Label Alignment ( NLA ) module to extract rich discriminative information from the class probability distribution predicted for low-confidence pixels. Extensive experiments on two benchmark datasets demonstrate that the proposed CDCL method achieves state-of-the-art performance without introducing excessive computational overhead. Especially, performance improvements of 1.51 % and 0.8 % mIoU are realized under the 1/8 (183) setting for PASCAL VOC 2012 and the 1/4 (744) setting for Cityscapes, respectively. The source code is accessible at https://github.com/YUCOCOCS/CDCL .},
  archive      = {J_ESWA},
  author       = {Fangqing Sheng and Ye Zhu and Lijiao Jin and Jianjian Yin},
  doi          = {10.1016/j.eswa.2025.128965},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128965},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semi-supervised semantic segmentation with confidence-driven consistency learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel EPI-guided network with progressive fusion for light field reconstruction. <em>ESWA</em>, <em>296</em>, 128964. (<a href='https://doi.org/10.1016/j.eswa.2025.128964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense light fields (LFs) hold significant potential in computer vision. However, since the existing LF acquisition devices struggle to capture high-quality dense LFs, researchers have proposed computational methods to reconstruct dense LFs from sparse LFs. Nevertheless, existing methods usually learn multiple features of the LF equally to achieve dense LF reconstruction while overlooking the discrepancies and correlations between different features. The specificity of epipolar plane images (EPIs) features as an important bridge between the LF spatial and angular information is worth exploring in depth. In this paper, we propose a novel EPI-guided network to emphasize differentiated learning of EPI features. The network extracts new guiding information from EPI global features and guides spatial and angular features to establish spatial-angular correlations of LF data effectively. We also introduce a progressive feature fusion strategy, which sequentially fuses the LF spatial, angular, and EPI features. This strategy fully explores the correlations between each pair of features and achieves differentiated learning among different features. The quantitative and qualitative experimental results demonstrate that our network achieves state-of-the-art reconstruction performance on large and small disparities datasets. Codes will be released at https://github.com/Baoshuai129/EGPFNet .},
  archive      = {J_ESWA},
  author       = {Baoshuai Wang and Yilei Chen and Xinpeng Huang and Ping An},
  doi          = {10.1016/j.eswa.2025.128964},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128964},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel EPI-guided network with progressive fusion for light field reconstruction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CM-PHI: Combining multi-hop attention graph neural network with sequence semantic analysis to predict phage-host interaction. <em>ESWA</em>, <em>296</em>, 128963. (<a href='https://doi.org/10.1016/j.eswa.2025.128963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of phage-host interactions (PHI) plays a crucial role in combating multi-resistant bacterial infections. The adsorption process mediated by phage tail proteins and host receptor-binding proteins represents the initial step of phage life cycle. However, traditional wet-lab experimental methods for identifying PHI are time-consuming, laborious-intensive and expensive. To address these challenges, we propose a novel deep learning framework named CM-PHI, which leverages a combination of multi-hop attention graph neural network (MHAGNN) and gated convolutional networks (GCNN) to predict PHI. Initially, we constructed a heterogeneous microbial network that centred on the proteins involved in the adsorption mechanisms. Then, the MHAGNN model is used to capture topology-level features, while GCNN encoded sequence-level information. These features are subsequently fused using a self-attention mechanism and trained through a dual-input fusion network (DIF-Net). Compared with various existing prediction methods, CM-PHI achieves superior accuracy and robustness. Moreover, case studies and molecular docking analyses (based on AlphaFold 3) further indicated the robustness and interpretability of our model. This study highlights the broad potential of CM-PHI to contribute to advancements in microbial ecology and therapeutic applications.},
  archive      = {J_ESWA},
  author       = {Jie Pan and Rui Wang and Weiping Ding and Yuechao Li and Zhuhong You and Qinghua Huang and Dawei Wei and Shiwei Wang and Yanmei Sun},
  doi          = {10.1016/j.eswa.2025.128963},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128963},
  shortjournal = {Expert Syst. Appl.},
  title        = {CM-PHI: Combining multi-hop attention graph neural network with sequence semantic analysis to predict phage-host interaction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-graph denoising and attention network for session-based recommendation. <em>ESWA</em>, <em>296</em>, 128962. (<a href='https://doi.org/10.1016/j.eswa.2025.128962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) has gained widespread research interest recently for its capability to predict the next item of interest to anonymous users by analyzing the limited behavior sequence within their sessions. Recent methods often rely on graph neural networks for SBR while introducing item transitions from other sessions to enhance item representations within the current session. However, these methods still have limitations in effective information propagation and noise interference reduction, as well as in adaptively adjusting the importance of different representations based on varying session characteristics. In response to these limitations, this paper introduces a new model, D ual- G raph D enoising and A ttention N etwork (DG-DAN). This model consists of three main components: (1) an intent-semantics dual attention mechanism component, which alleviates the impact of overemphasizing local similarity between nodes in graph attention networks and improves session intent awareness; (2) an adaptive edge denoising component, which reduces noise interference in cross-session collaborative information; and (3) a session-aware gating network, which adaptively adjusts the importance of local and global representations based on session characteristics. The comparison with eighteen state-of-the-art methods on four real datasets indicates the effectiveness and advantages of DG-DAN in SBR tasks.},
  archive      = {J_ESWA},
  author       = {Lianghua Peng and Bilian Chen and Yue Wang and Langcai Cao},
  doi          = {10.1016/j.eswa.2025.128962},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128962},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-graph denoising and attention network for session-based recommendation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable and efficient multi-scale spatio-temporal neural network for traffic flow forecasting. <em>ESWA</em>, <em>296</em>, 128961. (<a href='https://doi.org/10.1016/j.eswa.2025.128961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning based traffic flow forecasting models can effectively learn the complex spatio-temporal dependencies in the traffic network and have become the most widely used traffic flow forecasting architecture in recent years. However, these models have two significant challenges: (1) most of them ignore multi-scale temporal characteristics in traffic sequences; (2) they lack interpretability of traffic flow forecasting. To address the above issues, we propose an interpretable spatio-temporal traffic flow forecasting model with M ulti-scale S patio- T emporal N eural N etworks, named MSTNN. Specifically, It first divides original traffic sequences into several patches with different scales to preserve diverse temporal features. Secondly, due to the Kolmogorov Arnold Networks (KAN) have stronger interpretability than existing neural networks by using nonlinear parameter matrix, we design two kinds of advanced variants of KANs in MSTNN, namely S patial A ttention aware KAN (SA-KAN) and T emporal C hannel M ixed KAN (TCM-KAN), to enable them to capture spatial structure features and temporal sequence features in traffic data respectively while enhancing the forecasting interpretability. Finally, a fusion module is proposed to aggregate multi-scale temporal features to preserve the multi-scale information. Extensive experiments are conducted to validate the effectiveness of MSTNN and it achieves performance improvement ranging from 0.11 % to 12.65 % on three metrics. The results prove that our MSTNN is effective and interpretable.},
  archive      = {J_ESWA},
  author       = {Wenzhu Zhao and Guan Yuan and Yanmei Zhang and Xiao Liu and Shang Liu and Lei Zhang},
  doi          = {10.1016/j.eswa.2025.128961},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128961},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable and efficient multi-scale spatio-temporal neural network for traffic flow forecasting},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial spiral tube multi-roller bending: Accurate axial prediction utilizing AWPSO-FECAM-LSTM framework. <em>ESWA</em>, <em>296</em>, 128960. (<a href='https://doi.org/10.1016/j.eswa.2025.128960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-roller bending (MRB) process, characterized by its high stability and flexible mold adaptability, is widely employed in the bending forming of spatial metal tubes (such as spatial spiral tubes (SSTs)). However, due to the fewer mold constraints of the already bent-formed section, the bent tube exhibits irregular axial springback, resulting in uncontrollable axial deviations. To improve forming accuracy, this study proposes a novel AWPSO-FECAM-LSTM framework that predicts the axis coordinates of the SSTs formed with MRB. The framework incorporates two prediction modes: the Angle-Regulation-Based (ARB) model, which predicts points based on the same angle, and the Segment-Regulation-Based (SRB) model, which predicts points based on the same segment. The FECAM module extracts frequency-domain features, thereby enhancing the model’s ability to capture both temporal and frequency characteristics. Meanwhile, AWPSO optimizes hyperparameters using time-decay inertia weights and adaptive acceleration coefficients. Validated through bending experiments and finite element (FE) simulations, the model achieves a mean absolute percentage error (MAPE) of 0.98% and a mean squared error (MSE) of 0.000042, outperforming baseline models such as PSO-LSTM and vanilla LSTM. The ARB and SRB models collectively enable precise prediction of tube axis coordinates, with progressive prediction modes effectively reducing error accumulation. This framework demonstrates significant potential for real-time compensation in digital twin applications, advancing high-precision manufacturing of spatial metal tubes.},
  archive      = {J_ESWA},
  author       = {Zili Wang and Yonglin Tao and Shuyou Zhang and Xiaojian Liu and Yaochen Lin and Liangyou Li and Jianrong Tan and Zheyi Li},
  doi          = {10.1016/j.eswa.2025.128960},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128960},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial spiral tube multi-roller bending: Accurate axial prediction utilizing AWPSO-FECAM-LSTM framework},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DRFIR: A dimensionality reduction framework for all-in-one image restoration in spatial and frequency domains. <em>ESWA</em>, <em>296</em>, 128959. (<a href='https://doi.org/10.1016/j.eswa.2025.128959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, which is critical in various domains. The field has increasingly focused on all-in-one solutions that use a single model to address various types of degradation, enhancing generalization capabilities. Many existing approaches leverage different mechanisms to extract high-dimensional features from the spatial domain for encoding degradations. However, high-dimensional features contain noise and redundant information that can depress restoration performance. Moreover, both spatial and frequency domains include distinct information related to different degradation types. Based on these observations, we introduce a novel all-in-one image restoration framework called DRFIR, which utilizes dimensionality reduction technology to effectively harness both spatial and frequency domain information. Specifically, our approach first obtains low-dimensional embeddings from spatial and frequency domains via a dimensionality reduction block based on contrastive learning. Additionally, a novel fusion module is developed to integrate spatial and frequency embeddings with image features to enhance restoration quality. Extensive experimental results demonstrate that our DRFIR model achieves promising restoration performance on a range of benchmark datasets while improving downstream tasks.},
  archive      = {J_ESWA},
  author       = {Mingyu Liu and Yuning Cui and Xin Liu and Leah Strand and Huilin Yin and Alois Knoll},
  doi          = {10.1016/j.eswa.2025.128959},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128959},
  shortjournal = {Expert Syst. Appl.},
  title        = {DRFIR: A dimensionality reduction framework for all-in-one image restoration in spatial and frequency domains},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parallelized derivation algorithm for anomaly detection in internet of things environments. <em>ESWA</em>, <em>296</em>, 128958. (<a href='https://doi.org/10.1016/j.eswa.2025.128958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of the Internet of Things (IoT) has revolutionized user experiences but also raised concerns about security and privacy. To effectively safeguard against such cyber-threats, there is a need for approaches that can efficiently understand the usages of users’ IoT devices, applications, and data to better detect suspicious activities and protect users’ sensitive information within specific contexts. The semantic modeling capabilities of Knowledge Base System (KBS), make them well-suited for addressing these issues. From a semantics point of view, an anomaly in KBS can be modeled by a fragment of rules that can lead to inconsistencies inside the logical framework. Therefore, we map the anomaly detection problem to the inconsistency checkingproblem in KBS. As consistency checking is a hard problem, we introduce in this paper a new computational approach that reduces the complexity of the reasoning process by taking into account, in the logical modeling, theintrinsic idiosyncrasies of the application domain. We first introduce an algorithm for Knowledge Base (KB) rewriting into a context-based KB. Then, we detail our Lightweight Contextual Derivation Algorithm (LCDA) for inconsistency checking in KBS. Further, we propose an improvement of LCDA by adding parallelization, in ParallelLCDA (PLCDA), to accelerate the derivation process. We implemented and tested our algorithms in a practical use case in a smart home to demonstrate their effectiveness in the cybersecurity domain. Based on the obtained results, LCDA and PLCDA yield promising results in terms of response time in comparison with the regular logical chasing derivation approach.},
  archive      = {J_ESWA},
  author       = {Abdul Qadir Khan and Nouredine Tamani and Saad El Jaouhari},
  doi          = {10.1016/j.eswa.2025.128958},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128958},
  shortjournal = {Expert Syst. Appl.},
  title        = {Parallelized derivation algorithm for anomaly detection in internet of things environments},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-fidelity mural inpainting via progressive reconstruction and damage-aware adaptation. <em>ESWA</em>, <em>296</em>, 128957. (<a href='https://doi.org/10.1016/j.eswa.2025.128957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision techniques have revolutionized digital mural inpainting. However, single-stage networks often yield suboptimal results with blurred textures and structural distortion, while existing progressive strategies struggle to effectively balance local and global information. To address these limitations, we propose a novel generative adversarial model that progressively reconstructs mural details by adaptively integrating multi-scale local features and global context based on damage severity. We first obtain initial coarse results using an encoder-decoder network. Then, a mask-guided network adaptively extracts and fuses local features according to damage levels. Next, multi-level residual learning further refines details at different scales. Finally, a global network captures overall artistic characteristics using an optimized Transformer-UNet architecture. In this way, our method harmonizes detailed local restoration with the preservation of overall artistic integrity throughout the progressive inpainting process. Extensive experiments on multiple mural datasets demonstrate that our method achieves state-of-the-art performance in terms of texture clarity and structural coherence. We release the source code at https://github.com/Kk01Qq/Mural-Inpainting .},
  archive      = {J_ESWA},
  author       = {Shuyi Qu and Qingqing Kang and Zhe Yu and Shenglin Peng and Jun Wang and Qiyao Hu and Xianlin Peng and Jinye Peng},
  doi          = {10.1016/j.eswa.2025.128957},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128957},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-fidelity mural inpainting via progressive reconstruction and damage-aware adaptation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Polarization-enhanced GFNet for glint-influenced water surface object segmentation. <em>ESWA</em>, <em>296</em>, 128956. (<a href='https://doi.org/10.1016/j.eswa.2025.128956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Polarization-Enhanced glint-free network (GFNet) for the segmentation of shallow water, slow and small targets on the water surface is presented in this study, with a focus on overcoming the sun glint interference. Our approach integrates the polarization imaging features – degree of linear polarization (DOLP), angle of polarization (AOP), and parallel polarization radiance (PPR)—to enhance the detection and segmentation of Unmanned Underwater Vehicles (UUVs). The GFNet component is designed to mitigate sun glint effects, while the correlation-driven feature decomposition fusion (CDDFuse) network adeptly fuses the enhanced images, distinguishing the low-frequency from high-frequency features for improved segmentation. Post-fusion image processing using KNet and FastSCNN segmentation models achieved the mean intersection over union (mIoU) scores of 86.39 and 70.47, respectively, showcasing substantial improvements in UUV segmentation accuracy. The significance of this study lies in its potential to revolutionize underwater surveillance and monitoring, providing a robust solution for accurate UUV detection and segmentation even under the most challenging lighting conditions, thus paving the way for enhanced maritime safety and operational efficiency.},
  archive      = {J_ESWA},
  author       = {Tianfeng Pan and Xianqiang He and Yan Bai and Palanisamy Shanmugam and Teng Li and Fang Gong},
  doi          = {10.1016/j.eswa.2025.128956},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128956},
  shortjournal = {Expert Syst. Appl.},
  title        = {Polarization-enhanced GFNet for glint-influenced water surface object segmentation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing supply chain operations using advanced time-series mixer models for demand forecasting and inventory under uncertain demand. <em>ESWA</em>, <em>296</em>, 128955. (<a href='https://doi.org/10.1016/j.eswa.2025.128955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective inventory management in the presence of uncertain demand necessitates forecasting models that strike a balance between accuracy and cost efficiency. This study introduces an approach that incorporates Reversible Instance Normalization (RevIN) with Time-Series Mixer (TSMixer), referred to as RevIN-TSMixer, a transformer-based model built on the Multi-Layer Perceptron Mixer architecture, leveraging Multi-Layer Perceptron (MLP) across temporal and feature dimensions. The proposed approach is evaluated in two scenarios: error optimization, aimed at minimizing forecasting errors, and total cost optimization, emphasizing practical cost-effectiveness. The results demonstrate that RevIN-TSMixer consistently outperforms the standard TSMixer model. These advancements are credited to RevIN’s ability to address data shifts and improve adaptability to fluctuating demand patterns. To further improve supply chain management, the study integrates a probabilistic inventory model under a continuous review ( r , q ) inventory policy with the proposed forecasting model. This integration includes safety stock calculations, reorder point determination, and comprehensive cost analyses, reducing shortages, and optimizing inventory strategies. Validated through experimental scenarios, the proposed framework highlights the synergy between accurate forecasting and adaptive inventory management. By demonstrating robust forecast accuracy and significant cost reductions, RevIN-TSMixer establishes a state-of-the-art solution for supply chain optimization under uncertain demand conditions.},
  archive      = {J_ESWA},
  author       = {Thi Ngoc Anh Nguyen and Thi Xuan Hoa Nguyen and Ngoc Thang Tran and Thi Ha Nguyen and Phuong Anh Nguyen and Hai Anh Vu},
  doi          = {10.1016/j.eswa.2025.128955},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128955},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing supply chain operations using advanced time-series mixer models for demand forecasting and inventory under uncertain demand},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond aversion – Principles of appropriate algorithmic decision-making in human resource management. <em>ESWA</em>, <em>296</em>, 128954. (<a href='https://doi.org/10.1016/j.eswa.2025.128954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As algorithmic decision-making (ADM) becomes increasingly embedded in human resource management (HRM), concerns such as a lack of fairness and accountability raise urgent questions about its appropriateness. This study addresses the need for ADM evaluation by developing a coherent framework of principles grounded in the task-technology fit approach. It elaborates a balanced triad of nine indispensable ADM principles—methodical (veracity, accuracy, validity), managerial (relevancy, quality, efficiency), and ethical (fairness, accountability, transparency)—and validates them through a systematic literature review of 126 ADM artifacts in HRM. The analysis reveals a troubling lack of attention to ethical and managerial dimensions, while even methodical aspects are often neglected—with the notable exception of accuracy. Building on these findings, the study outlines a forward-looking agenda to operationalize, calibrate, implement, evaluate, and codify ADM principles, ultimately promoting responsible, appropriate ADM in HRM that reflects an evaluative stance beyond mere aversion.},
  archive      = {J_ESWA},
  author       = {Stefan Strohmeier and Mathias Becker and Ellen Scheer-Weller},
  doi          = {10.1016/j.eswa.2025.128954},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128954},
  shortjournal = {Expert Syst. Appl.},
  title        = {Beyond aversion – Principles of appropriate algorithmic decision-making in human resource management},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on conceptual design process model based on function association. <em>ESWA</em>, <em>296</em>, 128953. (<a href='https://doi.org/10.1016/j.eswa.2025.128953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasingly stringent user requirements and growing product complexity, lack of function frequently arise during the conceptual design phase due to ambiguous user needs and designers’ limited expertise. These issues lead to insufficient design resource acquisition and an influx of suboptimal solutions. To address these challenges, this study proposes a conceptual design process model based on function association and develops an auxiliary system (FAS-A, Function Association System Based on Apriori Algorithm) to systematically infer and supplement missing functions, thereby enhancing design completeness and rationality. Firstly, the functional requirements that the product should possess are identified through user needs analysis. Next, the patent set from the source system is retrieved based on the overall functional requirements, utilizing Natural Language Processing (NLP) techniques to extract functional and structural information. Once again, the extracted functional statement information is subjected to normalization, and the Apriori algorithm is applied to build a function association model. Then, based on the clarified functional requirements, a functionality association system based on the Apriori algorithm is applied to identify missing functionalities and retrieve design resources.},
  archive      = {J_ESWA},
  author       = {Zifan Ma and Peng Zhang and Zeyuan Ren and Hongxiang Wang and Chuankai Zhang},
  doi          = {10.1016/j.eswa.2025.128953},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128953},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on conceptual design process model based on function association},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Development and validation of interpretable machine learning models for photovoltaic panel temperature prediction. <em>ESWA</em>, <em>296</em>, 128952. (<a href='https://doi.org/10.1016/j.eswa.2025.128952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of photovoltaic (PV) panel temperature is critical for optimizing the design, operation, and maintenance of PV systems. Although many steady-state and machine learning (ML) models have been proposed to characterize the relationship between meteorological elements and panel temperature, achieving a balance between prediction accuracy, interpretability, and extrapolation capability remains a challenge. Therefore, this study attempts to construct a PV panel temperature prediction framework that integrates feature engineering and interpretable ML techniques. A feature selection method combining Pearson correlation coefficient, Shapley additive explanations, and extreme gradient boosting quantitatively evaluates the correlation of meteorological elements and their contributions to temperature prediction. Furthermore, two symbolic regression methods based on genetic programming and multi-population evolutionary algorithms are employed to develop explicit models with concise expressions and excellent performance. Two experimental datasets are from a utility-scale PV plant and a commercial rooftop PV system, with sizes of 19383 × 6 and 4503 × 6, respectively. Experimental results show that the proposed method can accurately and reliably predict the operating temperature of different panels, achieving R 2 of 0.981 and 0.961. Comparative analyses highlight the superior accuracy, interpretability, and broad applicability of the proposed models. This work provides valuable insights for panel temperature prediction, interpretable ML model development, and PV system management.},
  archive      = {J_ESWA},
  author       = {Bo Ren and Qianggang Wang and Niancheng Zhou and Saad Mekhilef},
  doi          = {10.1016/j.eswa.2025.128952},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128952},
  shortjournal = {Expert Syst. Appl.},
  title        = {Development and validation of interpretable machine learning models for photovoltaic panel temperature prediction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Local search-based approach for cardinality constrained portfolio selection problem. <em>ESWA</em>, <em>296</em>, 128950. (<a href='https://doi.org/10.1016/j.eswa.2025.128950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial investments are a prominent research topic, and they are resolved by suggesting methods that give higher profits for low-risk levels. Portfolio management is one of these investment problems addressed in literature by several contributions. Starting from Markowitz’s Mean-Variance portfolio selection model to diverse variants, including hard real-world constraints. Seeking realistic formulations, especially asset limitations, falls into the NP-hard category of problems with computational complexity due to high-dimensional data and non-convex optimization. In this work, a new resolution approach treats the cardinality-constrained variant of the Markowitz portfolio selection model. This approach begins with considering the original single-objective formulation of the model, without the aversion to risk parameter. The suggested method is composed of a selection procedure that satisfies the cardinality constraints, followed by a local search-based algorithm to determine the proportions of investment. A computational experiment is conducted on famous benchmarks to observe individual performance and the quality of efficient portfolios. The experimentation resulted in interesting portfolios with promising performance metrics and improvement perspectives.},
  archive      = {J_ESWA},
  author       = {Zahra Bouzeria and Larbi Asli and Belkacem Brahmi},
  doi          = {10.1016/j.eswa.2025.128950},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128950},
  shortjournal = {Expert Syst. Appl.},
  title        = {Local search-based approach for cardinality constrained portfolio selection problem},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A real-time speech interaction analytics framework for group activities using SNA and LLM techniques. <em>ESWA</em>, <em>296</em>, 128948. (<a href='https://doi.org/10.1016/j.eswa.2025.128948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current digital era, analyzing the dynamics of interaction in groups presents challenges in fields such as education, the business sector, and healthcare. The lack of integrated tools that monitor and evaluate discursive and social interactions in real-time makes it difficult to understand the flow of collaboration, the formation of effective teams, or the monitoring of social cognitive processes. In this article, we present a framework designed to analyze speech interactions in group activities by combining Social Network Analysis (SNA) and Large Language Models (LLM). Naira enables the real-time capture, processing, and analysis of speech interaction data, providing tools to evaluate discursive effectiveness and collaborative dynamics. The framework’s components are detailed in its different stages, and application cases are explored in educational, business, and healthcare contexts. A proof of concept in an educational environment proves the versatility and potential of the proposal to improve the understanding and optimization of group processes. Integrating SNA and LLM offers a comprehensive perspective combining validated and interpretable techniques to analyze attribute and relational variables with advanced and current artificial intelligence techniques. The framework’s main innovation lies in its ability to fuse the quantitative structural analysis of SNA with the semantic and qualitative content analysis of LLMs, offering a novel perspective that overcomes the limitations of each technique in isolation.},
  archive      = {J_ESWA},
  author       = {Diego Monsalves and Fabián Riquelme and Hector Cornide-Reyes},
  doi          = {10.1016/j.eswa.2025.128948},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128948},
  shortjournal = {Expert Syst. Appl.},
  title        = {A real-time speech interaction analytics framework for group activities using SNA and LLM techniques},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AIoT image analysis for real-time dispatching of shipyard transport devices: A focus on trailers. <em>ESWA</em>, <em>296</em>, 128947. (<a href='https://doi.org/10.1016/j.eswa.2025.128947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the shipbuilding industry, the Future of Shipyard (FOS) represents a new paradigm driven by data collection, analysis, and prediction. Among various logistics operations, trailer dispatching remains inefficient due to schedules being fixed days or even weeks in advance. To address this issue, we propose an AIoT-based wireless system that enables real-time trailer status monitoring by transmitting image data, GPS information, edge device status, and AI inference results. The proposed system integrates edge computers, wireless communication, centralized servers, and a deep learning model tailored for binary classification. The trailer’s complex operational status is decomposed into two tasks: (1) detecting location and movement via GPS, and (2) classifying loading status of ship components using image analysis. To classify the loading status from images, we evaluated five deep learning models-ResNet, VGG, EfficientNet, ViT, and VAN-based on accuracy and F1 score. Among them, the VGG model achieved the best performance, with 97.35 % accuracy and a 96.9 % F1 score, demonstrating its suitability for real-world deployment. To enhance model robustness in harsh industrial environments and varying device installation positions, we applied geometric augmentation and validated its effectiveness through additional experiments. Based on this AIoT wireless system, we introduce an innovative dispatch process that replaces manual, experience-based decision-making with data-driven intelligence. This leads to reductions in labor costs and process time, offering meaningful improvements for shipyard operations. The proposed framework also serves as a scalable reference for AIoT applications across broader industrial domains.},
  archive      = {J_ESWA},
  author       = {Youngjun Choo and Sunghoon Lim and Yonghyun Kim and Yeojoon Park and Yonghoon Oh and Changyob Lee and Wonjun Yun and Namhun Kim},
  doi          = {10.1016/j.eswa.2025.128947},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128947},
  shortjournal = {Expert Syst. Appl.},
  title        = {AIoT image analysis for real-time dispatching of shipyard transport devices: A focus on trailers},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging model explainability and fine-grained cutmix augmentation for robust detection of apricot diseases in UAV images. <em>ESWA</em>, <em>296</em>, 128946. (<a href='https://doi.org/10.1016/j.eswa.2025.128946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apricots (Prunus Armeniaca) are valuable stone fruits cultivated worldwide in temperate regions, generating $500 million in annual exports. However, disease and pests significantly threaten apricot production, impacting quality and yield. Brown rot and shot hole are the two major diseases affecting apricot yield worldwide. Early detection and targeted management strategies are critical to prevent their spread. Unfortunately, the lack of diverse labeled datasets hinders the performance of deep learning models for in-field disease detection. In this regard, we propose an innovative approach that leverages deep convolutional generative adversarial networks (DCGAN) and model-guided Cutmix (MGC) data augmentation to synthesize images of diseased apricots. The proposed synthesis process is driven by counterexamples, which are samples that the model fails to detect correctly. The use of DCGAN for background and conditional DCGAN for foreground generation allows fine-grained control over the synthesis of new samples. Further, the MGC uses SHapley Additive exPlanations of the object detection model to analyze its weaknesses and guide on-demand sample generation by replicating the counterexample’s label distribution, aspect ratio, scale, and brightness/contrast. This expands and diversifies our custom apricot disease dataset, initially containing 1500 images. This addresses dataset imbalances and exposes the model to a dynamically augmented dataset, iteratively improving its performance. The proposed method was extensively evaluated on images of healthy and diseased apricots captured by unmanned aerial vehicles in different environmental conditions. MGC outperformed traditional augmentation methods with even smaller dataset, achieving 4 % better mean average precision (mAP) score with Apricot-3K dataset. Additionally, the proposed method achieved 1–4 % improvements in mAP with many state-of-the-art object detection models when trained using the proposed framework on the Apricot-10K augmented dataset.},
  archive      = {J_ESWA},
  author       = {Jamil Ahmad and Wail Gueaieb and Abdulmotaleb El Saddik and Giulia De Masi and Fakhri Karray},
  doi          = {10.1016/j.eswa.2025.128946},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128946},
  shortjournal = {Expert Syst. Appl.},
  title        = {Leveraging model explainability and fine-grained cutmix augmentation for robust detection of apricot diseases in UAV images},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An AI-optimized strategy for intelligent risk mapping of islamic and conventional sustainable markets: Assessing the enduring dynamics of technological risk spillovers. <em>ESWA</em>, <em>296</em>, 128945. (<a href='https://doi.org/10.1016/j.eswa.2025.128945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the lasting impact of industries influenced by Robotic-Artificial Intelligence-Cloud (RAIC) technologies on risk management in both conventional and Islamic sustainable markets, employing a novel AI-driven framework. By utilizing the Quantile-based Total Connectedness Index (QTCI) to gauge market interconnectedness and Long Short-Term Memory (LSTM) neural networks to evaluate risk persistence, the research investigates how sectors such as autonomous vehicles, cybersecurity, cleantech, and future payments influence financial stability across different market conditions (bull, bear, and normal). The findings reveal divergent risk dynamics: Islamic markets are more sensitive to technological disruptions, particularly in robotics and cybersecurity, while conventional markets show more stable integration with sectors like smart grids and space technologies. Cleantech shows a tendency to coincide with decreased market volatility during bear markets, while future payments demonstrate widespread interconnectedness across all market conditions. AI-driven analysis highlights those Islamic markets excel in risk mitigation during stable conditions but conventional markets exhibit greater adaptability in the face of change. The QTCI-LSTM hybrid approach identifies differences in risk persistence, showing that technologies like genetic engineering and nanotechnology have transient effects in Islamic markets but more enduring roles in conventional markets. The study offers policy recommendations for sector-specific strategies, advocating for enhanced resilience in volatile sectors during bull markets, prioritizing cleantech during downturns, and encouraging cross-market collaboration. This work contributes to sustainable finance literature by integrating AI-powered persistence analysis with traditional risk metrics. The findings offer insights for policymakers managing technological integration in evolving markets.},
  archive      = {J_ESWA},
  author       = {Mahdi Ghaemi Asl},
  doi          = {10.1016/j.eswa.2025.128945},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128945},
  shortjournal = {Expert Syst. Appl.},
  title        = {An AI-optimized strategy for intelligent risk mapping of islamic and conventional sustainable markets: Assessing the enduring dynamics of technological risk spillovers},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identifying influential vertices with top-K largest temporal katz centralities in a streaming graph using constant memory. <em>ESWA</em>, <em>296</em>, 128943. (<a href='https://doi.org/10.1016/j.eswa.2025.128943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph theory, Katz centrality is a widely used measure to quantify the influence of a vertex within a network. Unlike simple degree centrality, it considers not only immediate neighbors but also multi-hop directed paths, weighting them by length and inter-hop time delays to reflect indirect influence. Traditional computation assumes a non-temporal graph, where edges lack timestamps, and computes using recursive multiplication of the graph’s adjacency matrix. However, this approach becomes impractical for graphs with billions of vertices due to high time/memory demands, and it overlooks the temporal information available on edges. By contrast, we focus on the problem of processing a streaming temporal graph , where edges are timestamped and arrive sequentially at a central analyzer. We want to online estimate the temporal Katz centrality of each vertex, and identify the top- K influential vertices with the largest Katz centralities. To solve this problem, we propose two solutions: TAS-TKC and ATAS-TKC. Both algorithms are designed to operate with a small constant-memory footprint, but ATAS-TKC builds on TAS-TKC to further improve performance. TAS-TKC avoids memory growth with the number of vertices by using a time-adaptive Count-Min sketch that allows all vertices to share memory for centrality estimation. It also maintains the top- K influential vertices using a min-heap-based tracker updated on each edge arrival. Additionally, ATAS-TKC enhances this design in two key ways: First, it achieves O ( 1 ) lookup time for the top- K vertex tracker by augmenting the min-heap with an auxiliary hash table. Second, it improves estimation accuracy by placing the top- K tracker as a prefilter before the sketch. In the prefilter, the top- K influential vertices are allocated dedicated memory and bypass the sketch entirely, avoiding estimation errors caused by memory sharing. For these two proposed solutions, we have conducted extensive evaluation based on real-world graph datasets. The results show that the average estimation error for all vertices is smaller than 4 % and the identification precision for the top- K vertices can be larger than 97 % when given only 400 KB memory to process a million-vertex graph dataset.},
  archive      = {J_ESWA},
  author       = {Jiaming Zhang and Qingjun Xiao and Jun Ma and Liukun He and Qifan Zhang and Guang Cheng},
  doi          = {10.1016/j.eswa.2025.128943},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128943},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identifying influential vertices with top-K largest temporal katz centralities in a streaming graph using constant memory},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing crop yield prediction with R2U-net-AgriFocus: A deep learning architecture with leveraging satellite imagery and agro-environmental data. <em>ESWA</em>, <em>296</em>, 128942. (<a href='https://doi.org/10.1016/j.eswa.2025.128942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop yield forecasting is very important for agricultural planning and resource management. This paper presents an innovative approach called R2U-Net-AgriFocus to improve crop productivity forecasting by integrating satellite images and agro-environmental data through a hybrid deep learning architecture. The methodology consists of four main steps. Data pre-processing includes atmospheric correction of satellite images, Histogram Equalization (HE) techniques, and a rotational focus-based recurrent residual U-Net ( R 2 U-Net). Farm count data were cleaned, outliers were removed, and missing values were imputed by mean imputation. Feature extraction uses a pre-trained Convolutional Neural Network (CNN) model (VGG16) to extract spatial features from satellite images and obtain crop health indices and texture patterns using Gabor filters. Field-specific characteristics are derived from digital data, including historical production trends, soil nutrient levels, and weather data. The Hybrid Hippo-Pufferfish Algorithm (HHPA) is proposed for feature selection to improve model performance. Finally, a DL architecture, R2U-Net-AgriFocus, combines a modified CNN with Convolutional Self-Attention (CSA) inputs and dense blocks, followed by a Gated Recurrent Unit with Recurrent Neural Network (GRU-ResUnit). CSA models dynamically learn the importance of image features, while dense blocks improve feature reuse. GRU-ResUnit detects long-term dependencies in temporal agricultural data, providing faster training times than traditional Long Short-Term Memory LSTM networks. This method shows significant results in crop yield prediction using the complementary power of agricultural and recurrent neural networks, providing a comprehensive framework for agricultural decision support systems. As such, future work will explore other variations of the proposed model that will be lightweight and suitable for use in resource-constrained agricultural settings in the real world.},
  archive      = {J_ESWA},
  author       = {Sushopti Dashrath Gawade and Ashok Bhansali and Swati Chopade and Umesh Kulkarni},
  doi          = {10.1016/j.eswa.2025.128942},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128942},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing crop yield prediction with R2U-net-AgriFocus: A deep learning architecture with leveraging satellite imagery and agro-environmental data},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A similarity-based semi-supervised algorithm for labeling unlabeled text data. <em>ESWA</em>, <em>296</em>, 128941. (<a href='https://doi.org/10.1016/j.eswa.2025.128941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel, non-iterative semi-supervised learning algorithm that leverages cosine similarity between document vectors and class mean vectors to label unlabeled text data automatically. The proposed method supports multiple vectorization techniques, including CountVectorizer, TF-IDF, and Doc2Vec, and is classifier-agnostic, enabling compatibility with both traditional and deep learning models such as KNN, Multinomial Naïve Bayes, SGDClassifier, Logistic Regression, Feedforward Neural Networks (FNN), and Convolutional Neural Networks (CNN). Extensive experiments conducted on benchmark datasets (BBC, Inshorts, 20-newsgroups) demonstrate: (1) achieving 96.88% accuracy on BBC, 93.59% on Inshorts, and 92.49% on 20-newsgroups with only 30% labeled data, thereby reducing manual labeling effort by over 99%; (2) TF-IDF consistently outperforms CountVectorizer and Doc2Vec by 3–12 percentages in accuracy across most experimental settings; and (3) Logistic Regression and FNN achieve the best performance among the classifiers. The method offers a practical, resource-efficient solution for real-world text classification by bridging labeled-unlabeled data gaps without iterative retraining.},
  archive      = {J_ESWA},
  author       = {Kirankumar Singh Potshangbam and Kshetrimayum Nareshkumar Singh},
  doi          = {10.1016/j.eswa.2025.128941},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128941},
  shortjournal = {Expert Syst. Appl.},
  title        = {A similarity-based semi-supervised algorithm for labeling unlabeled text data},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UAV fault diagnosis based on collaborative sharing of generic and task-oriented features. <em>ESWA</em>, <em>296</em>, 128940. (<a href='https://doi.org/10.1016/j.eswa.2025.128940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the expansion of Unmanned Aerial Vehicle (UAV) application scenarios and the increasing mission complexity, more stringent requirements have been put forward for its system reliability. Deep learning-based fault diagnosis brings new opportunities for UAV reliability improvement. However, in practical applications, deep diagnosis models are often limited by insufficient sample size. In addition, real-world scenarios often require multiple fault diagnosis tasks to be handled simultaneously, while most of the existing models can only handle a single diagnosis task. Therefore, this paper proposes a UAV fault diagnosis method based on the Collaborative Sharing of Generic and Task-Oriented Features (CSGTOF), which aims to address the problem of multiple fault diagnosis tasks with small samples. CSGTOF consists of a Generic Feature Sharing Network (GFSN) and multiple Task-Specific Networks (TSNs). The GFSN aims to learn global common features for all tasks, which can serve as a common information base for multiple tasks. TSNs, on the other hand, focus on the unique requirements of each task, extracting task-related detailed features, and achieving information exchange between them through a shared matrix. This design enables each task to share generic knowledge while drawing on detailed knowledge from each other, thereby significantly improving the performance of fault diagnosis under small-sample conditions. Furthermore, this paper introduces an attention mechanism module and a dynamic weighted average optimization strategy to automatically select key features and dynamically adjust the optimization weights between tasks. Finally, extensive experimental results based on real and simulated flight cases show that CSGTOF outperforms existing methods in fault diagnosis in small-sample multi-task environments, with up to 31.29% improvement over the baseline, and meets real-time requirements.},
  archive      = {J_ESWA},
  author       = {Yizong Zhang and Shaobo Li and Yanying Gu and Qiuchen He and Peng Zhou and Ansi Zhang},
  doi          = {10.1016/j.eswa.2025.128940},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128940},
  shortjournal = {Expert Syst. Appl.},
  title        = {UAV fault diagnosis based on collaborative sharing of generic and task-oriented features},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contribution of the ratio scale of expert judgments in the analytic hierarchy process. <em>ESWA</em>, <em>296</em>, 128938. (<a href='https://doi.org/10.1016/j.eswa.2025.128938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pairwise comparison ratio scale that the Analytic Hierarchy Process (AHP) acquires a central role because it allows the incorporation of intangible information through expert judgments. Existing literature has been shown that preference results are sensitive to the scale used in ratio judgments. This paper applies the Intentional Bounded Rationality Methodology (IBRM) to study the performance of the most used AHP ratio scales in the literature. By adapting the AHP ratio scales to the IBRM, several scenarios are proposed based on the distribution of the latent performance of the alternatives for two different problems. In problem 1, it is assumed that the AHP comparison judgements are numerical and known to the expert, while in problem 2, the AHP comparison judgements are described linguistically without the expert being aware of their transformation into numerical values. Problem 1 is used to answer the following research question (1) which among a set of seven different ratio scales used in literature favor AHP expected performance?, while Problem 2 is used to answer the following research question (2) how much the expected performance in AHP deteriorates when the expert is only guided by verbal judgments? The expected performance of each of the considered ratio scales is obtained in each scenario for different levels of expertise of a decision-maker. For the first problem, the balanced scale and the power scale show the best and worst expected performances, respectively. Problem 2 compares these two scales and the results show their performance differences are below 8%, which is interpreted as a stability property of AHP with respect to scale changes. Finally, it is also shown that no matter which ratio scale is used, the requirement of the consistency property in AHP contributes positively to the expected performance.},
  archive      = {J_ESWA},
  author       = {Carlos Sáenz-Royo and Francisco Chiclana},
  doi          = {10.1016/j.eswa.2025.128938},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128938},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contribution of the ratio scale of expert judgments in the analytic hierarchy process},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and privacy-preserved link prediction via condensed graphs. <em>ESWA</em>, <em>296</em>, 128937. (<a href='https://doi.org/10.1016/j.eswa.2025.128937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction plays a vital role in uncovering hidden relationships within complex networks, enabling applications such as identifying potential customers and products. However, this task faces critical challenges, including growing concerns over data privacy and the substantial computational and storage costs associated with large-scale networks. Condensed graphs, which are significantly smaller yet retain essential structural information, have emerged as a promising solution for preserving data utility while enhancing privacy. Despite this potential, existing methods like HyDRO rely on random node selection strategies designed primarily for node classification, overlooking connectivity patterns crucial for effective link prediction. Moreover, these methods lack rigorous evaluations of privacy risks associated with nodes and links in the condensed graphs—an essential consideration for sensitive real-world networks, where privacy concerns far exceed those of public datasets such as citation graphs. To address these limitations, we introduce HyDRO + , a novel graph condensation method guided by algebraic Jaccard similarity. By leveraging local connectivity patterns, HyDRO + generates structurally-aware condensed graphs that preserve link information more effectively. We further introduce a comprehensive evaluation framework that rigorously assesses both node- and link-level privacy leakage. Extensive experiments on four real-world networks demonstrate that HyDRO + consistently outperforms state-of-the-art methods—and even the original networks—in balancing link prediction accuracy and privacy preservation. Notably, it achieves nearly 20 × faster training and reduces storage requirements by a factor of 452 on the Computers dataset. This work represents the first attempt to use condensed graphs for privacy-preserving link prediction in real-world complex networks, offering a practical and scalable solution for secure information sharing in large-scale networks. The code is available at https://github.com/ifm-mag/HyDRO_PLUS .},
  archive      = {J_ESWA},
  author       = {Yunbo Long and Liming Xu and Alexandra Brintrup},
  doi          = {10.1016/j.eswa.2025.128937},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128937},
  shortjournal = {Expert Syst. Appl.},
  title        = {Efficient and privacy-preserved link prediction via condensed graphs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Combined myocardial motion and texture characterisation methods for the phenotyping of scarred myocardium. <em>ESWA</em>, <em>296</em>, 128936. (<a href='https://doi.org/10.1016/j.eswa.2025.128936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appearance of myocardial scars often signals the aggravation and deterioration of cardiovascular diseases. Accurate phenotyping of scarred myocardium is critically important for the personalized diagnosis and treatment of patients with cardiovascular diseases. However, existing phenotyping methods can not effectively capture cardiac motion and texture dependencies, resulting in insufficient performance. In this paper, we propose a novel dual-branch deep learning method for the phenotyping of scarred myocardium in non-contrast enhanced MR images, by jointly modeling myocardial motion and texture contexts. For the motion branch, we introduce a simple and efficient strategy to quantify myocardial motion, characterizing inter-frame and intra-frame motion variations at different angles. In addition, we propose a variant of the deep Mamba network designed to accurately capture long-range myocardial motion dependencies both circumferentially around the myocardial ring and across the temporal dimension. For the texture branch, we propose a novel Swin-Mamba texture network, which blends the strengths of the Swin-Transformer and Mamba architectures to capture both short-range and long-range texture feature dependencies. This approach effectively extracts local and global texture features of the myocardial scar. Finally, we fuse myocardial motion features and texture features at various depths within the network to jointly characterize the abnormal features of scarred myocardium, thereby achieving accurate and robust scarred myocardium phenotyping. Our method achieved an accuracy of 0.969 and an AUC of 0.956 on the ACDC dataset, and an accuracy of 0.942 and an AUC of 0.951 on the CMRD dataset. These results demonstrate the effectiveness of the proposed approach and its potential for clinical application.},
  archive      = {J_ESWA},
  author       = {Yaming Wang and Daiguo Yang and Cailing Pu and Xiaowei Ruan and Xi Hu and Chengjin Yu and Dongsheng Ruan and Mingfeng Jiang and Hongjie Hu and Huafeng Liu},
  doi          = {10.1016/j.eswa.2025.128936},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128936},
  shortjournal = {Expert Syst. Appl.},
  title        = {Combined myocardial motion and texture characterisation methods for the phenotyping of scarred myocardium},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessment of reaching laws for linear and nonlinear sliding surfaces: Improving performance of pipe crack sealing manipulator. <em>ESWA</em>, <em>296</em>, 128935. (<a href='https://doi.org/10.1016/j.eswa.2025.128935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the control of a tree-type pipe crack sealing manipulator (PCSM) with five specialized branches, designed to seal cracks inside the concrete pipes. This PCSM has the ability to navigate in vertical and horizontal pipes for crack repair tasks. A CAD model of the pipe with target crack and PCSM has been modelled in SolidWorks, and conclusive data of the crack has been further exported in Simulink for precise control. Observation and simulation studies in SolidWorks reveal that only the fifth branch of the PCSM successfully and effectively executes crack repair over substantial lengths. Furthermore, the repair of the crack has been assured for the branch of the PCSM. However, the accurate trajectory tracking in pipe crack sealing tasks is challenging due to model uncertainties and disturbances in confined environments. Sliding mode control (SMC) with various reaching laws for linear and nonlinear sliding surfaces has been examined to counter these challenges. The research investigated the efficacy of nine SMC reaching laws. These reaching laws are based on recent advancements in SMC. The novelty of this work uniquely compares nine reaching laws on both linear and nonlinear surfaces, where only CPRL (constant plus proportional rate reaching law) has previously been explored in nonlinear cases. Simulation-based evaluation using a SolidWorks-modeled PCSM and trajectory control in Simulink, incorporating mass uncertainty (+5 %) and joint disturbances equal to 40 % of the mean torque, demonstrates that nonlinear sliding surfaces consistently outperform linear ones in terms of tracking accuracy and disturbance rejection. Among the nine tested reaching laws on nonlinear surfaces, FTSMRL (novel fast terminal sliding mode reaching law), TSMRL (terminal sliding mode reaching law), and NSMRL (new sliding mode reaching law) demonstrated significantly lower tracking errors compared to the others, with the rms error of these three laws are comparable. The control efforts of FTSMRL and TSMRL were moderately high and chattering is very high compared to NSMRL. Therefore, NSMRL is proposed as the most suitable reaching law in this study due to its balanced performance, minimal chattering and control effort, as well reliable tracking accuracy. Furthermore, the study also calculated the reaching times for each law and confirmed their asymptotic stability using the Lyapunov stability criterion, demonstrating the efficacy of SMC in enhancing PCSM control.},
  archive      = {J_ESWA},
  author       = {Santosh Kumar and S.K. Dwivedy},
  doi          = {10.1016/j.eswa.2025.128935},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128935},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessment of reaching laws for linear and nonlinear sliding surfaces: Improving performance of pipe crack sealing manipulator},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Context-interaction transformer for insulator semantic segmentation in infrared images. <em>ESWA</em>, <em>296</em>, 128934. (<a href='https://doi.org/10.1016/j.eswa.2025.128934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insulators, as one of the key components of transmission lines (TLs), isolate conductors from the ground and prevent current leakage. Semantic segmentation of UAV-captured infrared images enables insulator temperature detection, identifying overheating issues. However, low resolution, blurred edges, and complex backgrounds in these images hinder segmentation algorithms. In response, this paper proposes a semantic segmentation method for insulators in TL infrared images based on a Context-Interaction Transformer (CI Transformer). The proposed method incorporates a novel Context-aware Transformer designed to learn diverse contextual information about insulators and achieve context information interaction across different receptive fields through multiple iterations. To adapt the model for semantic segmentation of various types of insulators in complex scenarios, the attention matrix of the CI Transformer calculates a boundary loss to emphasize edge information during context interaction. And the integration of Group Instance Whitening Loss enhances the representational capacity of the backbone network. Furthermore, we publicly release our TL insulator infrared image dataset, containing 3055 annotated images. Experimental results on this dataset demonstrate that our model accurately segments insulators and outperforms mainstream semantic segmentation methods in evaluation metrics. Notably, in experiments using ResNet101 as the backbone, our model achieves an IoU of 90.82 %, representing a 1.44 % improvement over the second-best method. The related code and dataset are available at https://github.com/AHU-psy/CI_Transformer .},
  archive      = {J_ESWA},
  author       = {Siyuan Peng and Dawei Zhao and Qingwei Gao and Yixiang Lu and Wenli Huang},
  doi          = {10.1016/j.eswa.2025.128934},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128934},
  shortjournal = {Expert Syst. Appl.},
  title        = {Context-interaction transformer for insulator semantic segmentation in infrared images},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven analysis of usage-feature interactions for new product design. <em>ESWA</em>, <em>296</em>, 128932. (<a href='https://doi.org/10.1016/j.eswa.2025.128932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven design has gained much attention with the rise of big data technologies and the availability of user-generated data. Previous research utilizing user data offered various design implications and ideas for new product development. However, most studies primarily focused on product features with little consideration of product usage, a significant factor in new product design. Moreover, while it is important in design practice to prioritize features in terms of usage, the interaction between usage and feature has rarely been investigated. To address the above limitation, this study proposes a new methodology that quantifies the interactions between product features and usages. The method consists of three stages. First, it analyzes customer sentiments toward product features and usages. Second, the method trains a neural network model that predicts customer satisfaction based on these sentiments. Then the method calculates the impact of each input factor by SHapley Additive exPlanations (SHAP). In the final stage, the impact values are further analyzed by a new function, Effect Measurement based on Covariance Analysis (EMCA), to quantify the interactions of feature and usage factors. The proposed methodology was initially tested on synthetic datasets for validation and then applied to real-world datasets. The result provides numeric values for product usage-feature interaction, which can help companies devise proper strategies for new product development.},
  archive      = {J_ESWA},
  author       = {Seyoung Park and Harrison Kim},
  doi          = {10.1016/j.eswa.2025.128932},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128932},
  shortjournal = {Expert Syst. Appl.},
  title        = {Data-driven analysis of usage-feature interactions for new product design},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CFARMS: A clustered federated learning framework with recursive model selection. <em>ESWA</em>, <em>296</em>, 128931. (<a href='https://doi.org/10.1016/j.eswa.2025.128931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning, originally devised to train a single global model over diverse client populations while upholding data privacy, faces challenges due to variations in data distributions among clients. The learning and generalization performance of the global model tends to be suboptimal. To address this, we propose CFARMS (Clustered Federated Learning Algorithm with Recursive Model Selection), a novel framework that effectively enhances model learning within clusters. CFARMS employs an iterative process to cluster clients, primarily leveraging gradients from the loss function of each client’s local training. Moreover, in instances of a tie, CFARMS also considers clients’ local model losses to inform clustering decisions. In contrast to existing frameworks, CFARMS produces highly personalized cluster-specific models, mitigating challenges in global model generalization. Additionally, it significantly reduces communication costs within the federated learning network by recursively refining the number of local models per client and updating the cluster models periodically. During training, CFARMS uniquely facilitates decentralized search for the most optimal model for each client. Extensive experimental evaluations on benchmark image and tabular datasets with non-convex models demonstrate the proposed framework’s superior performance. It achieved higher prediction accuracy and a remarkable reduction in communication bottleneck, exceeding 80 % and 49 % respectively, compared to state-of-the-art federated learning frameworks, including IFCA, FedProx and FedAvg. It is worth mentioning that the proposed framework exhibits faster convergence and effective scalability to a higher number of models and clients.},
  archive      = {J_ESWA},
  author       = {Ebenezer Nanor and Bernard M․ Cobbinah and Qinli Yang and Junming Shao and Nan Meng and Jason Cheung and Philip K․ Adjei and Leo Wang},
  doi          = {10.1016/j.eswa.2025.128931},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128931},
  shortjournal = {Expert Syst. Appl.},
  title        = {CFARMS: A clustered federated learning framework with recursive model selection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving post-training structured pruning via two-stage reconstruction. <em>ESWA</em>, <em>296</em>, 128930. (<a href='https://doi.org/10.1016/j.eswa.2025.128930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured pruning reduces inference costs by removing structured parameters from neural networks. However, most pruning approaches rely on lengthy retraining procedures to restore performance, rendering them impractical in many real-world settings where computational constraints prohibit extensive retraining. Existing post-training pruning methods that can restore performance within minutes mainly focuses on unstructured pruning, which performs poorly when combined with structured pruning. The information loss caused by structured pruning makes the model accuracy challenging to recover in the post-training setting. To address this issue, we introduce a two-stage activation reconstruction strategy to recover model accuracy. The first phase aggregates information into the remaining components before pruning. The second phase models the layer-wise cumulative error and calibrates the layer output discrepancy between the pruned and original models to reconstruct the activation signal. Experiments demonstrate that our method achieves significant improvements over post-training pruning methods and matches the performance of retraining-based approaches. With access to about 0.2 % samples from the ImageNet training set, our method achieves a 1.73 × reduction in FLOPs, while maintaining 72.58 % accuracy with ResNet-50. Notably, our method recovers the accuracy of pruned networks within a few minutes, which is orders of magnitude faster than retraining-based techniques.},
  archive      = {J_ESWA},
  author       = {Chenhao Li and Lin Li and Zhibin Zhang and Qiang Qiu and Jiafeng Guo and Xueqi Cheng},
  doi          = {10.1016/j.eswa.2025.128930},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128930},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improving post-training structured pruning via two-stage reconstruction},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shrinking for success: Multimodal dimensionality reduction for sustainable recommender systems. <em>ESWA</em>, <em>296</em>, 128929. (<a href='https://doi.org/10.1016/j.eswa.2025.128929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal item representations are widely used in modern recommender systems to capture various aspects of items. However, the high dimensionality of these representations poses challenges in terms of computational efficiency and resource usage. In this paper, we propose a fusion method, named MDR , based on attention bottlenecks to obtain condensed multimodal item representations. Our approach, intersecting dimensionality reduction and information fusion, leverages a Transformer autoencoder architecture to learn a compact item representation that preserves the salient information from the original high-dimensional features. We evaluate the impact of the condensed representations on the recommendation performance and resource consumption of a set of recommendation algorithms using the Cornac framework. Experiments on four datasets show that the condensed item representations produced by our fusion method enable the recommender algorithms to achieve comparable or even improved recommendation performance compared to the original, high-dimensional representations. Moreover, using the condensed representations significantly reduces training time, RAM Memory usage, and GPU utilization. These findings highlight the potential of our approach to enhance the efficiency and sustainability of multimodal recommender systems without compromising their effectiveness.},
  archive      = {J_ESWA},
  author       = {Angelo Geninatti Cossatin and Noemi Mauro},
  doi          = {10.1016/j.eswa.2025.128929},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128929},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shrinking for success: Multimodal dimensionality reduction for sustainable recommender systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Content suppression mechanisms-based recommendation systems. <em>ESWA</em>, <em>296</em>, 128928. (<a href='https://doi.org/10.1016/j.eswa.2025.128928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems enhance user experiences but often lead to information filter bubbles and reduced content diversity. To address these issues, this paper introduces a novel recommendation system based on Content Suppression Mechanisms, centered around Restrain Gated Recurrent Units (RGRU). The core innovation lies in a suppression function that dynamically adjusts the likelihood of recommending items based on their similarity to previously viewed content. This approach effectively mitigates the repetition of similar items andpromotes diversity within recommendation lists. Furthermore, we introduce a novel evaluation metric, the External and Intra-List Similarity ( E & I L S ), designed to assess both the internal diversity of recommended items and their deviation from previous interactions of users. This metric improves upon existing diversity metrics by addressing systemic diversity and variations among user groups.Validation across KuaiRec, ml_25m, and MRM datasets demonstrates that our approach maintains high precision while significantly enhancing recommendation diversity. This dual improvement facilitates multi-perspective content exploration, mitigating information cocoons and elevating user experience.},
  archive      = {J_ESWA},
  author       = {Haifeng Yang and Ran Zhang and Jianghui Cai and Jie Wang and Yupeng Wang and Yating Li and Yaling Xun and Xujun Zhao},
  doi          = {10.1016/j.eswa.2025.128928},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128928},
  shortjournal = {Expert Syst. Appl.},
  title        = {Content suppression mechanisms-based recommendation systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-DTIL: An EEG-based dynamic task-incremental learning method for decoding ADL-oriented motor imagery pairs. <em>ESWA</em>, <em>296</em>, 128927. (<a href='https://doi.org/10.1016/j.eswa.2025.128927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with strokes are likely to suffer from dyskinesia and lose their ability to perform activities of daily living (ADL). Motor neurorehabilitation can be gradually realized by continuously learning ADL-oriented motor imagery (MI) pairs with opposite directions, and an electroencephalography (EEG)-based brain-computer interface (BCI) is an effective solution. However, decoding the undetermined streams of MI pairs remains a great challenge for maintaining the balance between new and old tasks. Thus, an EEG-based dynamic task-incremental learning method, called EEG-DTIL, is proposed for decoding progressively incoming MI pairs. Based on the wavelet packet transform, all of the reconstructed subband signals are applied to extract global-view spatial features (GSF) via the regularized common spatial pattern, and the preferred parts are used to capture local-view spatial features (LSF) via tangent space mapping from the Riemannian space. Multiview spatial features (MvSF) are obtained after performing fusion and dimensionality reduction on the GSF and LSF. Inspired by the broad learning system (BLS), a series of personalized sub-BLSs are created in the same order as the inflowing MI pairs and used to construct a residual-based stacked BLS (R-SBLS). Moreover, a dynamic weight consolidation block (DWC) is developed to remember more learned knowledge by controlling the key output weights to be updated within a low error range. Finally, R-SBLS and DWC are combined in parallel, forming a dynamic incremental learning network (DRI-Net). On public and self-collected datasets, EEG-DTIL achieves incremental decoding accuracies of 70.53% and 71.80% for task streams with two and three MI pairs, respectively. The experimental results demonstrate that EEG-DTIL is significantly superior to the related methods, exhibiting better plasticity for new MI pairs, retainability for old MI pairs, and robustness to MI pair sequences.},
  archive      = {J_ESWA},
  author       = {Yufei Yang and Mingai Li and Fubiao Huang},
  doi          = {10.1016/j.eswa.2025.128927},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128927},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG-DTIL: An EEG-based dynamic task-incremental learning method for decoding ADL-oriented motor imagery pairs},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Machine learning and hybrid intelligence for wind energy optimization: A comprehensive state-of-the-art review. <em>ESWA</em>, <em>296</em>, 128926. (<a href='https://doi.org/10.1016/j.eswa.2025.128926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind energy plays a pivotal role in the global transition toward sustainable energy. However, its intermittent and stochastic nature presents challenges in achieving optimal performance, reliability, and seamless grid integration. Recent advances in machine intelligence—including machine learning (ML), deep learning (DL), and reinforcement learning (RL)—offer powerful tools to address these challenges across forecasting, control, maintenance, and diagnostics. This systematic review provides a comprehensive evaluation of how machine intelligence has contributed to the optimization of wind energy systems. These techniques have been applied to enhance turbine-level performance, reduce power losses, predict faults, and maximize energy yield under uncertain and dynamic conditions. Particular emphasis is placed on hybrid models that combine data-driven algorithms with physical dynamics and domain heuristics, enabling real-time, predictive, and autonomous wind farm operations. Furthermore, the study critically examines integration barriers such as noisy SCADA data, regulatory compliance, computational costs, and sustainability trade-offs. The findings highlight that multi-objective optimization—balancing energy production, system resilience, and cost efficiency—is central to the most successful implementations. Hybrid frameworks, explainable artificial intelligence (AI), edge computing, and transfer learning are identified as key enablers for scalable deployment. This review offers a comprehensive roadmap for the application of machine intelligence in advancing wind energy optimization and provides actionable insights for researchers, engineers, and policymakers committed to developing intelligent, adaptive, and sustainable wind power infrastructures.},
  archive      = {J_ESWA},
  author       = {Ashutosh Kumar Dubey and Abhishek Kumar and Isaac Segovia Ramírez and Fausto Pedro García Márquez},
  doi          = {10.1016/j.eswa.2025.128926},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128926},
  shortjournal = {Expert Syst. Appl.},
  title        = {Machine learning and hybrid intelligence for wind energy optimization: A comprehensive state-of-the-art review},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic routing algorithm of CapsNet for drift prognosis. <em>ESWA</em>, <em>296</em>, 128925. (<a href='https://doi.org/10.1016/j.eswa.2025.128925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data stream mining, detecting significant changes in a data stream is called drift detection. Detecting drift before it starts is an important problem, but there is very limited research. We call it “drift prognosis”. Many existing drift detection methods only report a drift after it has occurred. This paper tackles this challenge, taking advantage of Capsule Networks (CapsNets), a recent deep-learning architecture. CapsNets can encapsulate the properties of features. We propose a novel dynamic routing algorithm for drift prognosis, named DR-DD, which can transform between capsule layers to capture subtle changes, indicating a potential drift. Compared to 11 drift detection methods in the literature, our DR-DD algorithm is the only one that can pre-diagnose a drift, before it occurs.},
  archive      = {J_ESWA},
  author       = {Borong Lin and Nanlin Jin and John R. Woodward},
  doi          = {10.1016/j.eswa.2025.128925},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128925},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic routing algorithm of CapsNet for drift prognosis},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMEF-SSCT: A novel multidimensional and multi-level comprehensive evaluation framework for software supply chain threats. <em>ESWA</em>, <em>296</em>, 128924. (<a href='https://doi.org/10.1016/j.eswa.2025.128924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The software supply chain is currently facing a significant security challenge due to the rapid development of the software industry and the frequent occurrence of supply chain threat events, and the complex supply chain has led to an infinite expansion of the attack surface. However, existing research lacks a comprehensive quantitative assessment of potential threats. We propose a multi-dimensional and multi-level comprehensive assessment method for the first time, based on an indicator matrix and a large number of event texts, an assessment framework of “Technique and Impact” is constructed. The Analytic Hierarchy Process (AHP) method is also adjusted to quantify the weights of the multilevel indicators and accurately score the threats. The proposed framework has been validated through an in-depth analysis of real software supply chain events. It has been found to be effective in 81.67 % of real software supply chain events. Compared to classical qualitative and quantitative methods, the proposed method demonstrates an improvement of 15 %.},
  archive      = {J_ESWA},
  author       = {Maoyang Wang and Qin Luo and Peng Wu and Hongdi Zheng},
  doi          = {10.1016/j.eswa.2025.128924},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128924},
  shortjournal = {Expert Syst. Appl.},
  title        = {MMEF-SSCT: A novel multidimensional and multi-level comprehensive evaluation framework for software supply chain threats},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GIRMSF-global information reconstruction and multi-scale feature sharpening framework for knowledge graph embedding. <em>ESWA</em>, <em>296</em>, 128923. (<a href='https://doi.org/10.1016/j.eswa.2025.128923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary research, Knowledge Graph Embedding (KGE) is recognized as an effective technique for prediction tasks in structured data. However, current KGE models face three major limitations in global–local modeling: (1) high complexity of information extraction models, (2) inadequate utilization of relation embeddings, and (3) absence of a feature sharpening mechanism to enhance global–local features. To address these issues, this paper proposes a global information reconstruction and multi-scale feature sharpening framework (GIRMSF). First, GIRMSF introduces an entity-relation semantic reconstruction module (GSR), which reconstructs a semantic information matrix composed of entities and relations using multi-layer dilated convolution, thereby capturing features with contextual and logical association. Second, a multi-scale feature capture module (MSC) is designed to extract semantic information from multiple perspectives. Finally, the framework proposes a group normalization-based information sharpening module (GNS), which standardizes and thresholds multi-scale features to salient information while suppressing redundancy. Extensive experiments on 7 benchmark datasets of varying scales demonstrate that GIRMSF significantly outperforms existing methods and exhibits strong generalization capabilities across diverse scenarios.},
  archive      = {J_ESWA},
  author       = {Lin Lin and Shiwei Suo and Song Fu and Lizheng Zu and Sihao Zhang and Yikun Liu},
  doi          = {10.1016/j.eswa.2025.128923},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128923},
  shortjournal = {Expert Syst. Appl.},
  title        = {GIRMSF-global information reconstruction and multi-scale feature sharpening framework for knowledge graph embedding},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Strongly correlated nodes and confidence feedbacks based CNN and transformer combined multi-person pose estimation. <em>ESWA</em>, <em>296</em>, 128922. (<a href='https://doi.org/10.1016/j.eswa.2025.128922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-person scenes, localizing character joints is a challenging task due to occlusion and complex human interactions. Especially in predicting invisible joints, deep networks cannot extract valid information from occluded inputs. Besides, Transformer-based algorithms with the highest accuracy are sensitive to image size, leading to rapidly increased computational costs with higher-resolution images. Moreover, existing algorithms often lack an evaluation feedback mechanism, resulting in unreliable outputs. To tackle these issues, this paper proposes the Strongly Correlated Nodes and Confidence Feedbacks based CNN and Transformer combined multi-person pose estimation (SCNCF). Firstly, to address the Transformer’s sensitivity to input size, SCNCF constructs a CNN-based feature extraction network to screen valid inputs. It filters out a few image blocks containing specific joints as Transformer’s input, significantly reducing the computational load. Secondly, to better predict invisible joints, SCNCF learns node associations from the large pre-training dataset. By aligning strongly correlated nodes according to the similarity matrix, a robust pose model is established. The positions of the occluded joints can be directly derived from the model, thus minimizing accuracy loss from inaccurate poses. Lastly, to make up for the missing validation feedback mechanism, SCNCF introduces a confidence scoring method. The candidate’s joints are initially scored according to their probabilities, and the scores decline if their probabilities are close to neighbors. Joints with excessively low scores are fed back into the network and treated as invisible. When reprocessing them, only strongly correlated nodes with sufficient scores are used. This avoids introducing excessive precision errors. Iteratively applying the procedure ensures that the network avoids generating low-quality solutions. On COCO-val 2017, CrowdPose, and OCHuman-val dataset, SCNCF shows a significant improvement in the average precision of up to 5.3 % compared with classical algorithms such as Simple Baseline and HRnet, as well as cutting-edge algorithms such as HRNeXt and Sapiens. The recall rate is also steadily improved by about 2 %, which fully proves the effectiveness and advantages of SCNCF.},
  archive      = {J_ESWA},
  author       = {Jianghai He and Ronghua Shang and Ting Wu and Chi Wang and Yangyang Li},
  doi          = {10.1016/j.eswa.2025.128922},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128922},
  shortjournal = {Expert Syst. Appl.},
  title        = {Strongly correlated nodes and confidence feedbacks based CNN and transformer combined multi-person pose estimation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical agent architecture-based large-scale AGV cluster real-time motion collaboration control in dynamic and complex production environments. <em>ESWA</em>, <em>296</em>, 128921. (<a href='https://doi.org/10.1016/j.eswa.2025.128921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated guided vehicles (AGVs) are key components of intelligent manufacturing workshops, which can greatly improve production efficiency and reduce costs. However, a large-scale AGV cluster often encounters problems such as poor performance of real-time path planning, conflicts, and deadlocks in dynamic and complex production environments, resulting in low logistics efficiency. To address those issues, this study proposes a hierarchical agent architecture-based large-scale AGV cluster real-time motion collaboration control method. The low-level AGV agents plan paths, while the upper-level intersection agents coordinate the motions of the AGV agents to avoid conflicts and deadlocks. First, a multi-granularity topological map model is established, the nominal path length is formulated, and double turning penalty factors are introduced. Additionally, an improved A* algorithm is presented to elevate the path planning and transportation efficiency of the AGV cluster. Second, the motion strategies of the AGV cluster under multiple intersection patterns are designed to eliminate conflicts. Furthermore, a Markov decision process model for double-main crossroad agents is established. The crossroad-oriented multi-agent deep deterministic policy gradient (CRMADDPG) algorithm is utilized to optimize each double-main crossroad agent, achieving efficient transportation of the AGV cluster. Next, a multi-angle and multi-factor crossroad similarity assessment model is established, and a knowledge transfer method based on pre-training and fine-tuning is proposed to accelerate the learning of double-main crossroad control knowledge in new heterogeneous production environments and avoid the waste of existing knowledge. Finally, the effectiveness and superiority of the proposed methods are verified based on multiple benchmarks and real-world cases.},
  archive      = {J_ESWA},
  author       = {Zhuo Zhou and Liyun Xu and Liqiang Liao and Minghai Yuan and Gang Shang and Zhun Xu},
  doi          = {10.1016/j.eswa.2025.128921},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128921},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hierarchical agent architecture-based large-scale AGV cluster real-time motion collaboration control in dynamic and complex production environments},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A blockchain empowered federated differentiable search index framework for secure information collaboration. <em>ESWA</em>, <em>296</em>, 128919. (<a href='https://doi.org/10.1016/j.eswa.2025.128919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and reliable information collaboration is essential for prompt response and effective decision-making in emergency management. Current solutions face significant challenges in cross-domain data retrieval and sharing, including data fragmentation, lack of unified indexing mechanisms, and insufficient privacy protection. This paper proposes a Federated Differentiable Search Index (FeDSI) framework to address these challenges., FeDSI integrates generative retrieval, federated learning, and blockchain technology into a unified architecture to support secure, decentralized, and privacy-preserving data collaboration. The core innovation lies in adopting a differentiable search index—a learnable document indexing mechanism optimized via backpropagation—which enables semantic-based document identification directly from user queries. The model is collaboratively trained across multiple organizations using federated learning, with blockchain smart contracts ensuring transparency and verifiability of the training and retrieval processes. Experimental results on the NQ320K benchmark show that FeDSI outperforms classical sparse and dense retrieval baselines, and achieves competitive performance compared to state-of-the-art generative retrieval models, achieving a Recall@10 of 85.40 and an MRR@100 of 72.69. These findings demonstrate the effectiveness of FeDSI in supporting secure, efficient, and collaborative information retrieval in complex emergency data environments.},
  archive      = {J_ESWA},
  author       = {Qi Wang and Yi Liu},
  doi          = {10.1016/j.eswa.2025.128919},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128919},
  shortjournal = {Expert Syst. Appl.},
  title        = {A blockchain empowered federated differentiable search index framework for secure information collaboration},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SMOMCCS: Minimum compact coverage oversampling approach for imbalanced data classification. <em>ESWA</em>, <em>296</em>, 128918. (<a href='https://doi.org/10.1016/j.eswa.2025.128918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification faces significant challenges as conventional SMOTE methods compromise the minority class sub-cluster preservation under small disjuncts and class overlaps. To address the limitation, we propose SMOMCCS, a minimum compact coverage sphere oversampling framework that constructs geometrically optimized minority subspaces through three innovations: density-driven identification of the minority class sub-clusters via adaptive kernel density estimation, compact coverage spheres with radius optimization constrained by Coverage Factor (CF), and angular similarity-controlled sample synthesis within subspaces. The enhanced SMOMCCS-NaN variant incorporates parameter-free natural neighbor analysis for noise filtration through verification of neighborhood label consistency, effectively sharpening class boundaries. Extensive experiments on 44 UCI/KEEL data sets demonstrate that the proposed SMOMCCS and SMOMCCS-NaN achieve a higher average G-mean, F-measure, and AUC in 63.6 % of the data sets compared to state-of-the-art SMOTE variants. Statistical validation using Wilcoxon signed-rank tests ( p < . 05 ) confirms significant improvements over eight baseline methods.},
  archive      = {J_ESWA},
  author       = {Leifu Gao and Mengyao Zhang and Shijie Zhao},
  doi          = {10.1016/j.eswa.2025.128918},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128918},
  shortjournal = {Expert Syst. Appl.},
  title        = {SMOMCCS: Minimum compact coverage oversampling approach for imbalanced data classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large-model-based smart agent for time series anomaly detection in power systems. <em>ESWA</em>, <em>296</em>, 128917. (<a href='https://doi.org/10.1016/j.eswa.2025.128917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in time series is critical to ensure the safe and stable operation in power systems. Existing methods face dual challenges of data scarcity and limited interpretability. To address this, we propose a novel large-model-based series-detection development framework named SLEP, leveraging the powerful pre-trained knowledge transfer capabilities of large models to mitigate data scarcity and their natural language understanding/generation abilities to enhance the interpretability of anomalies. Additionally, we introduced a brand-new prompt design template called BRIDOR introduced to further control the interaction quality with the large model. This work represents the first attempt to apply large models to anomaly detection for electric time series data. Extensive experiments on the high-dimensional, multivariate, and data-sparse real-world cases, demonstrate the superior performance of our proposed method. This validates the framework’s robustness and pioneers a new paradigm for trustworthy artificial intelligence technology in related fields.},
  archive      = {J_ESWA},
  author       = {Bingrui Wang and Yuan Zhou and Leijiao Ge and Sun-Yuan Kung},
  doi          = {10.1016/j.eswa.2025.128917},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128917},
  shortjournal = {Expert Syst. Appl.},
  title        = {Large-model-based smart agent for time series anomaly detection in power systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated learning-based spectrum and energy efficiency enhancement in HAP-assisted LEO satellite communication. <em>ESWA</em>, <em>296</em>, 128916. (<a href='https://doi.org/10.1016/j.eswa.2025.128916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of low Earth orbit (LEO) satellites and high-altitude platforms (HAPs) into next-generation satellite networks enables high-speed connectivity and broad coverage. Maximizing spectrum efficiency (SE) and energy efficiency (EE) is essential for ensuring sustainable and high-throughput communication in LEO-HAP systems. Yet, the inherent dynamics of satellite movement, adjustable HAP positions, and geographically dispersed ground users (GUs) introduce substantial complexity into resource management. Addressing these challenges requires solving a complex, large-scale optimization problem involving joint control of transmit power, beamforming centers, user associations, and HAP placement. To solve this problem, we propose Fed-DAC, a federated learning-based Deep Actor-Critic algorithm that enables decentralized parallel training, thereby improving scalability and reducing computational overhead, to maximize the minimum SE and EE across all GUs. Simulation results show that Fed-DAC achieves approximately 50 % faster convergence than single-agent DAC and exhibits 20 % greater convergence stability compared to FedProx-DAC, while preserving optimality. Evaluations conducted across nine major cities in South Korea confirm Fed-DAC’s significant performance over conventional iterative and static baseline methods.},
  archive      = {J_ESWA},
  author       = {Vitou That and Sengly Muy and Jung-Ryun Lee},
  doi          = {10.1016/j.eswa.2025.128916},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128916},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated learning-based spectrum and energy efficiency enhancement in HAP-assisted LEO satellite communication},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic multi-objective optimization using historical evolutionary learning with global alignment local descriptor matching and collaborative guidance. <em>ESWA</em>, <em>296</em>, 128915. (<a href='https://doi.org/10.1016/j.eswa.2025.128915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems involve conflicting objectives that evolve over time, necessitating algorithms capable of efficiently tracking the dynamic Pareto optimal set and preserving solution diversity. To address this, the paper proposes a framework for dynamic multi-objective optimization algorithms based on Historical Evolutionary Learning (EHEL). The framework employs four strategies: using global alignment and local descriptor matching to improve the accuracy of historical individual searches; adopting a multi-history experience collaborative guidance strategy to integrate historical information and enhance the reliability of evolutionary direction; introducing a dynamic quadratic correction strategy to revise less-potential solutions; and proposing a shrinking boundary strategy to preserve directional information and enhance boundary exploration capability. Experiments on the CEC 2018 benchmark test set show that EHEL exhibits superior optimization capabilities across various dynamic environments, significantly enhancing convergence diversity and solution quality compared to existing algorithms. This research provides a robust and adaptive solution strategy for dynamic multi-objective optimization by effectively integrating historical experience with adaptive mechanisms.},
  archive      = {J_ESWA},
  author       = {Kaiquan Guan and Haibin Ouyang and Steven Li and Gaige Wang and Nagwan Abdel Samee and Essam H. Houssein},
  doi          = {10.1016/j.eswa.2025.128915},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128915},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic multi-objective optimization using historical evolutionary learning with global alignment local descriptor matching and collaborative guidance},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discrete zeroing neural dynamic with noise tolerance for image deblurring. <em>ESWA</em>, <em>296</em>, 128914. (<a href='https://doi.org/10.1016/j.eswa.2025.128914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for high-quality images continues to grow, image deblurring has become a fundamental challenge in computer vision. Although numerous effective deblurring methods have been proposed, one critical area remains largely unexplored: the interference caused by environmental noise. It is well known that noise can perturb solution systems, leading to instability or even collapse. Current mainstream methods, such as deep learning-based approaches, struggle to address such perturbations effectively. Additionally, these methods require large datasets for training and optimization, which incur significant computational cost and time. Without sufficient data, their robustness and deblurring performance are greatly limited. To address these challenges, we consider an alternative approach: a learning-free neural network, called neural dynamic. Our method employs a dynamic solving mechanism capable of addressing potential static optimization problems, while its integral term enhances noise resistance. To further adapt this framework for practical engineering applications, we developed a Taylor expansion-based discretization scheme called Taylor-type 6-instant Noise-Tolerance Zeroing neural Dynamic (T6NTZD). This model not only improves noise resistance but also achieves lightweight design and real-time processing. By introducing this approach, we aim to fill a significant gap in the field of image deblurring. Finally, through a detailed theoretical analysis from a continuous perspective and a comprehensive comparison with 12 neural dynamics models, the superiority of this method is clearly demonstrated. The key advantages of our model are summarized as follows: strong robustness, lightweight design, and the elimination of the need for data-intensive learning.},
  archive      = {J_ESWA},
  author       = {Cong Lin and Fenghao Zhuang and Jiahao Li and Chengze Jiang and Yuanyuan Wu},
  doi          = {10.1016/j.eswa.2025.128914},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128914},
  shortjournal = {Expert Syst. Appl.},
  title        = {Discrete zeroing neural dynamic with noise tolerance for image deblurring},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An intelligent wireless sensing algorithm for complex cross-domain scenarios based on DB-FA-YoLov6. <em>ESWA</em>, <em>296</em>, 128912. (<a href='https://doi.org/10.1016/j.eswa.2025.128912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensing technology can identify human motion via feature information from WiFi signals. The popularity of smartphones, wearable devices, and other smart devices has increased the use of wireless sensing in fields such as smart homes, smart healthcare, human–computer interaction, and autonomous vehicles. However, the mobile communication environment is complex and dynamic which makes wireless sensing challenging. The issues include low model sensing accuracy, poor scene generalization ability, and high environmental dependence. Therefore, this paper proposes a cross-domain intelligent wireless sensing algorithm based on a double branch frequency attention mechanism Yolov6 network called DB-FA-YoLov6. This integrates a Yolov6 neural network, frequency attention module, and residual module to provide efficient extraction of signal features and enhance model generalization. The goal is to reduce the effect of the environment on sensing tasks and improve robustness, portability, and cross-domain accuracy. The DB-FA-YOLOv6 model integrates two types of residual modules, BasicBlock and Bottleneck. It replaces the large modules in the Yolov6 network model with lightweight structures, which can decrease the number of parameters, improve the efficiency of model training and testing, and reduce the complexity. Compared with current sensing algorithms such as Vision Transformer Network for Multiple Vision Tasks (ViT-MVT), Environment Independent (EI), and Joint Adversarial Domain Adaptation (JADA), the proposed DB-FA-YOLOv6 algorithm has better sensing accuracy, sensing efficiency, and cross-domain performance. For the in-domain scenario, the proposed algorithm achieves improvements of 10.0 % in sensing accuracy and 10.1 % in sensing efficiency. The sensing accuracy of the proposed algorithm in cross-domain scenarios, namely location and orientation, is improved by 10.5 % and 9.7 %, and the sensing efficiency is improved by 7.0 % and 52.1 %, respectively.},
  archive      = {J_ESWA},
  author       = {Lingwei Xu and Haiyang Sun and Kai Wang and Gaofeng Nie and Zhe Chen and T. Aaron Gulliver},
  doi          = {10.1016/j.eswa.2025.128912},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128912},
  shortjournal = {Expert Syst. Appl.},
  title        = {An intelligent wireless sensing algorithm for complex cross-domain scenarios based on DB-FA-YoLov6},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Insights into the impact of visual and textual information on investment decision-making: A multimodal business plan analysis via deep representation learning. <em>ESWA</em>, <em>296</em>, 128911. (<a href='https://doi.org/10.1016/j.eswa.2025.128911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business plans (BPs) serve as crucial communication tools between entrepreneurs and investors, but there is controversy in existing research regarding the actual impact of BP’s quality on investment decision. To investigate how the visual and textual features of BP impact investors’ investment decisions, we develop a flexible computational framework to represent the visual and textual information in business plans and design a series of indicators to measure the corresponding information quality. Specifically, we propose three quality indicators, namely V B P , T B P , and I B P , based on the deep representations of the BP’s visual feature, text information, and brief introduction. Through Logit Regression analysis of 4597 business plans and their corresponding 42,533 decision-making samples from an online investment platform, we find BP’s quality significantly influences initial investment decisions. Visual quality and textual introduction quality exhibit significant effects (p < 0.05). We also reveal the moderating effects of investor risk preferences. Our computational modeling and empirical evidence provide key insight into decision mechanisms. This is the first investigation that utilizes deep pre-trained models to comprehensively model BP’s multimodal features within the investment decision-making domain. The proposed quality indicators can enable scalable, unbiased evaluation to address the evolving needs of decision-makers in an increasingly complex and data-rich environment.},
  archive      = {J_ESWA},
  author       = {Weikang Yuan and Tianqianin Lin and Zhuoren Jiang and Song Wang},
  doi          = {10.1016/j.eswa.2025.128911},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128911},
  shortjournal = {Expert Syst. Appl.},
  title        = {Insights into the impact of visual and textual information on investment decision-making: A multimodal business plan analysis via deep representation learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). NASNet with african vulture optimization for detecting diabetic retinopathy stages in retinal fundus images. <em>ESWA</em>, <em>296</em>, 128910. (<a href='https://doi.org/10.1016/j.eswa.2025.128910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes retinopathy is a disorder that damages the retinal blood vessels and leads to severe vision problems. Even for experts, it can be difficult to recognize a disease in its initial stage and its diagnosis seems to be time-consuming. It is difficult to increase accuracy and decrease time complexity using conventional detection techniques like Inception v3 and Xception. Neural Architecture Search Network was proposed as a solution to these issues in order to identify the exact stage of diabetic retinopathy. Initially, input retinal images are gathered, and then preprocessed the input images by utilizing anisotropic diffusion, CLAHE (Contrast Limited Adaptive Histogram Equalization) as well as high boost filtering. Noise from the input image is removed using an anisotropic diffusion technique. Utilizing CLAHE, the image’s brightness is increased, and using high boost filtering, the image’s edges are sharpened. Following that, the preprocessed image is segmented by using a No New U-Net (NNU-Net). NNU-Net was used to predict surface mesh distances, enhancing segmentation performance through extensive data augmentation techniques. Finally, the Neural Architecture Search Network (NASNet) classifier is utilized on the segmented image to predict the stages of diabetic retinopathy. African vulture optimization is used to optimally select the hyperparameter such as batch size that is used to enhance the accuracy of the classifier. An analysis of the proposed method’s simulation results indicates that it achieves 97.4% accuracy, 2.56 error, 90.4% precision, as well as 98.4% specificity. Consequently, Compared to other existing techniques, the proposed methodology performs better. This prediction approach enhances the quality of life for patients by predicting diabetic retinopathy disease at an early stage.},
  archive      = {J_ESWA},
  author       = {J. Sasidevi and A. Sathish and S. Vatchala and M. Nallusamy},
  doi          = {10.1016/j.eswa.2025.128910},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128910},
  shortjournal = {Expert Syst. Appl.},
  title        = {NASNet with african vulture optimization for detecting diabetic retinopathy stages in retinal fundus images},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of neural network segmentation and validation on plant specimen images of korean violaceae. <em>ESWA</em>, <em>296</em>, 128909. (<a href='https://doi.org/10.1016/j.eswa.2025.128909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate plant identification is crucial for biodiversity research, yet manual classification remains time-consuming and requires specialized expertise. To overcome these challenges automated identification technologies are increasingly being developed. A key step in this process is the precise segmentation of plant materials from plant specimen images; however, existing approaches often struggle to separate plant material from non-plant components such as labels, barcodes, stamps, and rulers. To address this problem, we propose integrating Multi Receptive Field (MRF) blocks into a U-Net framework, enabling robust multi-scale feature extraction from plant bodies of varying sizes in digitized specimens. We conduct extensive experiments on a dataset of 14,939 plant specimen images from 36 species of Viola (Violaceae), comparing the performance of eleven segmentation models, including ten state-of-the-art methods and our approach. The proposed model achieved superior performance with a mean Intersection over Union of 0.8531, Dice coefficient of 0.9123, and pixel accuracy of 0.9920. Through ablation studies, we established that incorporating six different kernel sizes in the MRF block yields optimal segmentation results. By effectively addressing the complexities inherent in herbarium images-such as varying plant scales and the presence of non-plant elements–our model establishes a strong foundation for automated plant identification. This study advances digital herbarium analysis and highlights the potential of specialized neural network architectures in botanical research.},
  archive      = {J_ESWA},
  author       = {Sujeong Han and Hyeonji Moon and Sanghyuck Lee and A-Seong Moon and Min-Kyung Sung and Jeongwon Lee and Sangtae Kim and Jaesung Lee},
  doi          = {10.1016/j.eswa.2025.128909},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128909},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of neural network segmentation and validation on plant specimen images of korean violaceae},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A TODIM-based cubic quasirung orthopair fuzzy MCGDM model for evaluating 5G network providers using minkowski distance and entropy measures. <em>ESWA</em>, <em>296</em>, 128908. (<a href='https://doi.org/10.1016/j.eswa.2025.128908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world decision-making environments, multiple experts often evaluate complex alternatives under uncertainty, vagueness, and inconsistent linguistic expressions. To address these challenges, this paper presents a novel multicriteria group decision-making (MCGDM) approach grounded in cubic ( p , q ) - quasirung orthopair fuzzy sets ( C ( p , q ) Q O F ) sets, integrating Minkowski-based distance measures and entropy-based weighting strategies. First, new operational laws for C ( p , q ) Q O F S s are developed, offering enhanced modeling flexibility and preserving both interval-valued and crisp fuzzy information. A Minkowski-type distance measure tailored for C ( p , q ) Q O F numbers is proposed to evaluate similarity between expert assessments. Furthermore, a robust entropy measure is introduced to objectively derive criteria weights without prior knowledge. These theoretical advancements are embedded into an extended TODIM framework that accounts for decision-makers’ behavioral preferences and non-linear perceptions of gains and losses. The proposed method is applied to a real-world case study on 5G network provider selection for smart manufacturing, considering 10 alternatives and 15 criteria evaluated by multiple experts. The performance of the proposed method is validated through a rigorous validity test including transitivity, decomposition, and robustness. The results demonstrate that the proposed model maintains stable rankings across varying parameters, adapts dynamically to different linguistic scales, and significantly improves interpretability and realism in decision support. Comparative analyses with recent Minkowski-based q - ROF and C q ROFS models, reveal that the proposed approach achieves 5.3 % higher decision accuracy, greater ranking stability, and enhanced adaptability to external factors. Unlike prior methods, it supports dual-parameter flexibility, captures expert variability, and integrates both interval-valued and crisp fuzzy data in a unified framework. These results confirm the proposed C ( p , q ) Q O F -TODIM model as a powerful and versatile decision-making tool, particularly suitable for applications involving uncertain, multi-expert evaluations in emerging domains such as Industry 4.0, sustainable technology, and digital infrastructure planning.},
  archive      = {J_ESWA},
  author       = {Yongxin Li and Muhammad Rahim and Faiz Muhammad Khan and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.eswa.2025.128908},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128908},
  shortjournal = {Expert Syst. Appl.},
  title        = {A TODIM-based cubic quasirung orthopair fuzzy MCGDM model for evaluating 5G network providers using minkowski distance and entropy measures},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diagnostic performance of artefact-reduced cone-beam CT images using a generative adversarial neural network. <em>ESWA</em>, <em>296</em>, 128907. (<a href='https://doi.org/10.1016/j.eswa.2025.128907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial neural networks (GAN) have been demonstrating efficacy in increasing the quality of tomographic images. However, there is a lack of information about its effectiveness in cone-beam CT (CBCT). This study evaluated the performance of GAN in reducing CBCT artefacts. A phantom was custom-made with a mandible covered with Mix-D. Forty teeth were endodontically instrumented and inserted in mandibular sockets. CBCT scans were obtained with a field-of-view of 5 × 5 cm, 90kVp, 3 mA, 0.08 mm voxel size and 9 s. All scans were repeated after enabling metal artefact reduction (MAR). Two conditions with high-density materials were simulated and additional scans were performed. GAN was tailored to use the acquired raw images for validation, training and testing. Structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), mean absolute error (MAE) and root mean square error (RMSE) were calculated. Then, all the images were reconstructed and noise and signal-to-noise ratio (SNR) were measured in the cervical, middle and apical third of the second left premolar root. Also, assessments of the diagnostic confidence, artefact interference and dental and bone preservation were performed by four observers. All the conditions were compared using ANOVA two-way (α = 0,05) and Wilcoxon signed rank test. The corrected images showed significantly higher SSIM and PSNR, lower MAE and RMSE, lower noise, higher SNR, higher diagnostic confidence, lower artefact interference and high dental and bone preservation. The CBCT images with MAR and higher presence of high-density materials showed significantly lower noise values. The developed neural network has promising performance to increase the image quality of CBCT raw and reconstructed images.},
  archive      = {J_ESWA},
  author       = {Amanda Pelegrin Candemil and Hugo Gabrielidis and Filippo Gatti and Benjamin Salmon and Matheus L. Oliveira and Jardel Francisco Mazzi-Chaves and Elsa Vennat and Manoel Damião Sousa-Neto},
  doi          = {10.1016/j.eswa.2025.128907},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128907},
  shortjournal = {Expert Syst. Appl.},
  title        = {Diagnostic performance of artefact-reduced cone-beam CT images using a generative adversarial neural network},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BOOST: Out-of-distribution-informed adaptive sampling for bias mitigation in stylistic convolutional neural networks. <em>ESWA</em>, <em>296</em>, 128905. (<a href='https://doi.org/10.1016/j.eswa.2025.128905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasive issue of bias in AI presents a significant challenge to painting classification, and is getting more serious as these systems become increasingly integrated into tasks like art curation and restoration. Biases, often arising from imbalanced datasets where certain artistic styles dominate, compromise the fairness and accuracy of model predictions, i.e., classifiers are less accurate on rarely seen paintings. While prior research has made strides in improving classification performance, it has largely overlooked the critical need to address these underlying biases, that is, when dealing with out-of-distribution (OOD) data. Our insight highlights the necessity of a more robust approach to bias mitigation in AI models for art classification on biased training data. We propose a novel OOD-informed model bias adaptive sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It addresses these challenges by dynamically adjusting temperature scaling and sampling probabilities, thereby promoting a more equitable representation of all classes. We evaluate our proposed approach to the KaoKore and PACS datasets, focusing on the model’s ability to reduce class-wise bias. We further propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to assess class-wise separation and per-class bias reduction. Our method demonstrates the ability to balance high performance with fairness, making it a robust solution for unbiasing AI models in the art domain.},
  archive      = {J_ESWA},
  author       = {Mridula Vijendran and Shuang Chen and Jingjing Deng and Hubert P.H. Shum},
  doi          = {10.1016/j.eswa.2025.128905},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128905},
  shortjournal = {Expert Syst. Appl.},
  title        = {BOOST: Out-of-distribution-informed adaptive sampling for bias mitigation in stylistic convolutional neural networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust approach to text similarity detection with LSTM networks based on embedding and attention synergy. <em>ESWA</em>, <em>296</em>, 128904. (<a href='https://doi.org/10.1016/j.eswa.2025.128904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity detection in text is critical in Natural Language Processing (NLP), especially for applications like duplicate question detection (DQP). In this work, we propose an enhanced approach that leverages Bidirectional Long Short Term Memory (Bi-LSTM) networks integrated with attention mechanisms to effectively capture contextual dependencies and semantic similarity. Unlike traditional LSTM models, our method utilizes multiple pre-trained embeddings-GloVe, FastText, and Paragram, which enrich the semantic representation of text. The attention layer dynamically emphasizes the most relevant parts of input sequences, allowing the model to focus on critical semantic features. We further address class imbalance using data resampling techniques such as SMOTE, ADASYN, and SMOTE-Tomek, improving the model’s robustness. Evaluation on the Quora dataset demonstrates that our model significantly outperforms baseline methods, achieving 95.64 % accuracy and a 97.68 % F1-score. These results validate the effectiveness of our integrated Bi-LSTM and attention-based architecture in accurately identifying semantically similar question pairs. In addition, the source code for the proposed approach is available at the following Code .},
  archive      = {J_ESWA},
  author       = {Muhammad Faseeh and Tahira Amin and Naeem Iqbal and Hamad Shahid Hussain and Salman Ahmad and Muhammad Afzaal},
  doi          = {10.1016/j.eswa.2025.128904},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128904},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust approach to text similarity detection with LSTM networks based on embedding and attention synergy},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FlotSegNet: A lightweight attention-based 3D encoder architecture for efficient segmentation of floating river debris in multi-spectral satellite imagery. <em>ESWA</em>, <em>296</em>, 128903. (<a href='https://doi.org/10.1016/j.eswa.2025.128903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floating debris has been a constant concern globally, which disfigures the river’s aesthetics and causes health hazards to humans and aquatic life. To remedy this, deep learning-based methods have received significant attention from researchers for the identification of floating river debris using remote sensing satellite images. However, the conventional deep learning-based methods perform poorly in unknown locations with varied natures of waste with complex feature semantics. Thus, an effective combination of advanced deep learning architectures, data augmentation techniques, transfer learning, and careful dataset curation is often necessary. Further, the existing deep models for floating debris identification are designed for triple channel color images and are not suitable for multi-spectral satellite imagery with poor spatial resolutions. To overcome this, a novel Attention-based 3-dimensional model has been developed for efficient segmentation of floating river debris. The model presents a blend of the symmetry and efficiency of a 3-dimensional Encoder-based U-Net with the better-memorizing capacity of attention-based transformers. The model utilizes self-attention calculated along the twelve considered bands to best capture the versatile spectral profile of composite waste. Moreover, a novel labeled segmentation-specific dataset comprising satellite imagery of rivers from across the world with assured locations and types of debris has been prepared. The developed model has been utilized to detect the specific locations of the river debris and distinguish them as water, aquatic hyacinth, and waste using open-source Sentinel-2 satellite imagery. The proposed model achieves a Jaccard similarity, precision, recall, and mean average precision of 0.914, 0.951, 0.952, and 0.950, respectively.},
  archive      = {J_ESWA},
  author       = {Kamakhya Bansal and Ashish Kumar Tripathi},
  doi          = {10.1016/j.eswa.2025.128903},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128903},
  shortjournal = {Expert Syst. Appl.},
  title        = {FlotSegNet: A lightweight attention-based 3D encoder architecture for efficient segmentation of floating river debris in multi-spectral satellite imagery},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). X-GAD: Explainable graph-level anomaly detection via inter-graph anomalies. <em>ESWA</em>, <em>296</em>, 128902. (<a href='https://doi.org/10.1016/j.eswa.2025.128902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-level anomaly detection (GLAD) aims to identify anomalous graphs that deviate significantly from the majority in terms of structure or attributes. However, most existing methods treat graphs as independent entities and neglect the potential value of inter-graph information, which limits their detection performance and explainability. While some recent approaches incorporate inter-graph information, they rely mainly on consistency modeling and fail to explicitly extract inter-graph anomalies, thus providing limited explainability. To address these challenges, we propose an e X plainable G raph-level A nomaly D etection (X-GAD) framework, which explicitly learns and utilizes inter-graph anomalies to enhance both detection performance and explainability. Here, inter-graph anomalies refer to anomaly patterns identified by comparing multiple graphs, rather than analyzing each graph in isolation. Specifically, we design an Inter-graph Anomaly Awareness module based on optimal transport theory, which leverages the Wasserstein Distance and Gromov-Wasserstein Distance to learn inter-graph anomalies. Furthermore, we introduce an Anomaly Fusion Learner module to effectively incorporate the learned inter-graph anomalies into the detection process from both local and global perspectives, thereby improving detection performance. Extensive experiments on four real-world benchmark datasets demonstrate that X-GAD outperforms state-of-the-art GLAD methods and reveals explicit inter-graph anomalies that provide explainable insights for practical anomaly analysis.},
  archive      = {J_ESWA},
  author       = {Xinqiu Zhang and Wei Qin and Tairan Huang and Jianliang Gao},
  doi          = {10.1016/j.eswa.2025.128902},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128902},
  shortjournal = {Expert Syst. Appl.},
  title        = {X-GAD: Explainable graph-level anomaly detection via inter-graph anomalies},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ETTracker: A fund tracking framework for anti-money laundering on ethereum. <em>ESWA</em>, <em>296</em>, 128900. (<a href='https://doi.org/10.1016/j.eswa.2025.128900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and cross-border features of Ethereum’s decentralized finance platform create significant challenges for anti-money laundering (AML) efforts, particularly in tracking illicit fund flows involving service providers such as exchanges, mixers, and decentralized protocols. Existing AML solutions rely primarily on transaction-level heuristics, which terminate tracking at service providers and high-degree addresses, leaving major laundering paths uninvestigated and key service providers unrecognized. To address these limitations, we present ETH-Token Tracker (ETTracker), a novel taint analysis-based framework that enables comprehensive fund flow tracking for AML on Ethereum. ETTracker introduces: (1) Unified Multi-edge Directed Graphs (UMDG), supporting graph-level tracking across service providers during internal transfers; (2) a Service Provider Label Dataset (SP-Dataset) with over 1.22 million categorized addresses, enabling labeled service provider identification in the money laundering path; and (3) a Service Provider Detector Graph Neural Network (SPD-GNN), trained to identify unlabeled service providers and reduce irrelevant transaction noise. Extensive experiments on 11 real-world money laundering cases demonstrate that SPD-GNN achieves a 98.7 % F1-score in service provider identification, outperforming existing models by 1.3 %. ETTracker detects significantly more laundering addresses than state-of-the-art methods, with the largest case achieving a 153-fold increase. ETTracker also tracks 2804 cross-service provider laundering paths and identifies 1001 previously unlabeled service providers, improving the coverage and accuracy of AML investigations.},
  archive      = {J_ESWA},
  author       = {Changhao Wu and Junwei Xu and Kai Wang and Weili Han and Hongfeng Chai},
  doi          = {10.1016/j.eswa.2025.128900},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128900},
  shortjournal = {Expert Syst. Appl.},
  title        = {ETTracker: A fund tracking framework for anti-money laundering on ethereum},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multi-task robust architecture search for network intrusion detection. <em>ESWA</em>, <em>296</em>, 128899. (<a href='https://doi.org/10.1016/j.eswa.2025.128899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Intrusion Detection (NID) becomes a key technology for ensuring network security. Recent researchers have proposed various NID systems based on neural networks. However, these networks require expensive expert knowledge for manual design, which is tedious and time-consuming. Moreover, they easily suffer from adversarial attacks, which limits their application in safety-critical scenarios. To alleviate the above problems, this paper proposes an evolutionary multi-task robust architecture search method, called EMR-NID, which can automatically design robust architectures for NID systems. First, we design an architecture transfer update strategy that achieves information sharing and knowledge transfer between different tasks. Then, we develop an architecture performance correction strategy that enhances the efficiency of robust search and strengthens NID’s defense capability. Finally, our EMR-NID method is validated on three well-known NID datasets, i.e., NSL-KDD, UNSW-NB15, and Edge-IIoTset. The experimental results show that EMR-NID can outperform some state-of-the-art NID methods in terms of clean and robust accuracy under multiple scenarios.},
  archive      = {J_ESWA},
  author       = {Yeming Yang and Zhihao Liu and Ka-Chun Wong and Qiuzhen Lin and Jianping Luo and Jianqiang Li},
  doi          = {10.1016/j.eswa.2025.128899},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128899},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multi-task robust architecture search for network intrusion detection},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CATNet: Coordinate-aware transformer for all-in-one image restoration. <em>ESWA</em>, <em>296</em>, 128896. (<a href='https://doi.org/10.1016/j.eswa.2025.128896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {All-in-One image restoration has gained prominence by addressing diverse degradations within a single model. Although Transformer-based methods incorporate positional information for image restoration under varying weather conditions, the embedding of this information remains superficial. The models failing to focus more on the challenging, degraded parts of the image. Additionally, these methods tend to lose edge features and local details during downsampling. To address these issues, we propose CATNet, a transformer net based on the Coordinate-Aware Attention Block (CAAB) and Hierarchical Feature Restoration Module (HFRM). CAAB aims to enhance spatial positional information with latent positional features, improving the ablity of model to recover local details and achieve better decoupling capabilities. Specifically, CAAB implements a dual-branch architecture. The first branch leverages the Implicit Spatial Representation Block to refine and augment latent positional features across images with varying types of degradation, thereby enhancing the model’s capacity to concentrate more effectively on complex restoration areas within the input image. Concurrently, the second branch facilitates the uninterrupted transmission of essential feature information throughout the model. HFRM is proposed to address the issue of losing edge features and local details during downsampling, it compensates for the loss of detail features during downsampling and establishes a feature information flow equipped with multi-scale feature extraction capabilities for image restoration tasks. Experiments demonstrate that our approach achieves state-of-the-art performance on different image restoration datasets.},
  archive      = {J_ESWA},
  author       = {Junling He and Yang Zhao and Wenting Li and Ziyang Chen and Yao Xiao and Bingshu Wang and Yongjun Zhang},
  doi          = {10.1016/j.eswa.2025.128896},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128896},
  shortjournal = {Expert Syst. Appl.},
  title        = {CATNet: Coordinate-aware transformer for all-in-one image restoration},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FlexiD-fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model. <em>ESWA</em>, <em>296</em>, 128895. (<a href='https://doi.org/10.1016/j.eswa.2025.128895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different modalities of medical images provide unique physiological and anatomical information for diseases. Multi-modal medical image fusion integrates useful information from different complementary medical images with different modalities, producing a fused image that comprehensively and objectively reflects lesion characteristics to assist doctors in clinical diagnosis. However, existing fusion methods can only handle a fixed number of modality inputs, such as accepting only two-modal or tri-modal inputs, and cannot directly process varying input quantities, which hinders their application in clinical settings. To tackle this issue, we introduce FlexiD-Fuse, a diffusion-based image fusion network designed to accommodate flexible quantities of input modalities. It can end-to-end process two-modal and tri-modal medical image fusion under the same weight. FlexiD-Fuse transforms the diffusion fusion problem, which supports only fixed-condition inputs, into a maximum likelihood estimation problem based on the diffusion process and hierarchical Bayesian modeling. By incorporating the Expectation-Maximization algorithm into the diffusion sampling iteration process, FlexiD-Fuse can generate high-quality fused images with cross-modal information from source images, independently of the number of input images. We compared the latest two-modal and tri-modal medical image fusion methods, tested them on Harvard datasets, and evaluated them using nine popular metrics. The experimental results show that our method achieves the best performance in medical image fusion with varying inputs. Meanwhile, we conducted extensive extension experiments on infrared and visible image fusion, multi-exposure image fusion, and multi-focus image fusion tasks with arbitrary numbers, and compared them with the perspective state-of-the-art (SOTA) methods. The results of the extension experiments consistently demonstrate the effectiveness and superiority of our method. The code is available at https://github.com/XylonXu01/FlexiD-Fuse .},
  archive      = {J_ESWA},
  author       = {Yushen Xu and Xiaosong Li and Yuchun Wang and Xiaoqi Cheng and Huafeng Li and Haishu Tan},
  doi          = {10.1016/j.eswa.2025.128895},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128895},
  shortjournal = {Expert Syst. Appl.},
  title        = {FlexiD-fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive spectral-frequency-spatial guidance network for hyperspectral image dehazing. <em>ESWA</em>, <em>296</em>, 128891. (<a href='https://doi.org/10.1016/j.eswa.2025.128891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSIs) encompass dozens or even hundreds of spectral bands which pose challenges for HSI dehazing. Although great progress has been made, current HSI dehazing methods cannot achieve satisfactory performance. In this paper, we comprehensively analyze this problem and propose a two-step dehazing network PSGNet, which progressively performs HSI dehazing by using the guidance information in spectral, frequency and spatial domains. In the first step, we exploit spectral grouping together with a learnable physical model as spectral guidance to progressively perform dehazing from infrared to visible bands. Meanwhile, we analyze the haze-sensitivity properties of amplitude and phase components, and introduce frequency-domain reconstruction and cross-group fusion blocks to enhance the image quality. In the second step, we leverage the well-designed RGB dehazing networks as spatial guidance for HSI dehazing. Finally, we establish an HSI simulation dataset, consisting of 590 pairs of clear and hazy HSIs, to promote the research in this field. The experimental results demonstrate the superiority of PSGNet over the state-of-the-art methods on both simulated and real HSI datasets. The code and dataset will be made publicly available at https://github.com/stc-cqupt/HDD .},
  archive      = {J_ESWA},
  author       = {Qianru Liu and Tiecheng Song and Kaizhao Zhang and Yin Liu and Anyong Qin and Feng Yang and Chenqiang Gao},
  doi          = {10.1016/j.eswa.2025.128891},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128891},
  shortjournal = {Expert Syst. Appl.},
  title        = {Progressive spectral-frequency-spatial guidance network for hyperspectral image dehazing},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). General machine learning models for interpreting and predicting efficiency degradation in organic solar cells. <em>ESWA</em>, <em>296</em>, 128890. (<a href='https://doi.org/10.1016/j.eswa.2025.128890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) energy plays a key role in addressing the growing global energy demand. Organic solar cells (OSCs) represent a promising alternative to silicon-based PVs due to their low cost, lightweight, and sustainable production. Despite achieving power conversion efficiencies (PCEs) over 20 %, OSCs still face challenges in stability and efficiency. Recent advances in manufacturing, artificial intelligence and machine learning (ML) achieve optimized and screened OSCs for greater sustainability and commercial viability, thus potentially reducing costs while ensuring stable and long term performance. This work presents optimal ML models to represent the temporal degradation on the PCE of polymeric OSCs with structure ITO/PEDOT:PSS/P3HT:PCBM/Al. First, we generated a database with 166 entries with measurements of 5 OSCs, and up to 7 variables regarding the manufacturing and environmental conditions for more than 180 days. Then, we relied on a software framework that provides a conglomeration of automated ML protocols that execute sequentially against our database by simply command-line interface. This easily permits hyper-optimizing the ML models through exhaustive benchmarking so that optimal models are obtained. The accuracy for predicting PCE over time reaches values of the coefficient determination widely exceeding 0.90, whereas the root mean squared error, sum of squared error, and mean absolute error are significantly low. Additionally, we assessed the predictive ability of the models using an unseen OSC as an external set. For comparative purposes, classical Bayesian regression fitting are also presented, which only perform sufficiently for univariate cases of single OSCs.},
  archive      = {J_ESWA},
  author       = {David Valiente and Fernando Rodríguez-Mas and Juan V. Alegre-Requena and David Dalmau and María Flores and Juan C. Ferrer},
  doi          = {10.1016/j.eswa.2025.128890},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128890},
  shortjournal = {Expert Syst. Appl.},
  title        = {General machine learning models for interpreting and predicting efficiency degradation in organic solar cells},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). One-step temporal subspace clustering with structured sparsity and indicator graph-laplacian regularization. <em>ESWA</em>, <em>296</em>, 128889. (<a href='https://doi.org/10.1016/j.eswa.2025.128889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering (SC) is a powerful technique for effectively segmenting data residing in multiple subspaces. However, traditional SC methods often fall short in accurately clustering temporal data due to their limited ability to capture temporal dependencies. These methods typically adopt a two-step framework: first, an affinity matrix is learned from the data; second, spectral clustering is performed using the affinity matrix to construct the indicator matrix for achieving the final segmentation. This disjointed process neglects the interdependence between the affinity matrix and the cluster assignments, and hence fails to fully exploit the temporal smoothness inherent in sequential data, where neighboring samples are usually similar. To address these limitations, we propose a novel one-step temporal subspace clustering method that integrates Structured Sparsity and Indicator graph-Laplacian regularization, termed SSIL. Our approach improves upon existing temporal SC techniques in two key aspects. First, we introduce a temporal Indicator Graph-Laplacian (IL) regularization directly on the indicator matrix, which promotes temporal smoothness and enhances alignment between the clustering result and ground truth. Second, we incorporate Structured Sparsity (SS) to jointly learn the affinity and indicator matrices within a unified optimization framework. We further develop an efficient optimization algorithm to alternatingly solve the affinity and indicator matrices. Extensive experiments on six benchmark datasets, particularly on motion capture data, demonstrate the effectiveness of our method and its superior performance compared to several state-of-the-art approaches.},
  archive      = {J_ESWA},
  author       = {Wenyu Hu and Huiying Huang and Tinghua Wang},
  doi          = {10.1016/j.eswa.2025.128889},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128889},
  shortjournal = {Expert Syst. Appl.},
  title        = {One-step temporal subspace clustering with structured sparsity and indicator graph-laplacian regularization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-condition milling cutter wear prediction based on split-channel information re-fusion and domain adaptation. <em>ESWA</em>, <em>296</em>, 128888. (<a href='https://doi.org/10.1016/j.eswa.2025.128888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate tool wear prediction is crucial for ensuring superior quality and operational efficiency in cutting processes, avoiding part defects, and minimizing economic losses. However, due to variations in cutting parameters such as cutting speed, feed rate, and depth of cut under different working conditions, the collected sensor signals (e.g., current, acceleration, acoustic emission) exhibit significant differences in amplitude, spectral density, and temporal feature distribution. This results in a distribution shift of the signal data, making it difficult for traditional models to generalize across multiple working conditions and leading to a notable decline in prediction performance. As a result, traditional models struggle to adapt to these changes and fail to capture wear patterns under diverse conditions, leading to low prediction accuracy across varying working scenarios. Therefore, a multi-condition wear prediction method for the milling cutter is proposed in this paper. This method is based on split-channel information re-fusion and domain adaptation, utilizing cutting signal and machining process data. A split-channel information re-fusion module is proposed to align the spatial wear feature distribution across different working conditions. The module first separates the multidimensional cutting signal and processes data along channel directions. Then, different convolutions for heterogeneous feature extraction are applied, and the multidimensional correlated features along the channels are fused for re-extraction. This process ensures that the diverse working condition features are fully captured and aligned. Moreover, the Mamba is improved due to the inconsistent distribution of temporal wear features under different working conditions. Furthermore, the GLMamba is constructed to fuse global–local attention in parallel configuration with selective state space models (SSMs). The loss of local information during the global compression of the selective SSMs is avoided by updating global information with local information features, ensuring accurate temporal feature extraction and alignment. The Maximum Mean Discrepancy (MMD) algorithm is utilized to quantify the distributional differences between domains in the fully connected layer, aligning feature distributions between the source and target domains. Experimental results on the NASA and Nanjing University of Aeronautics and Astronautics (NUAA) datasets demonstrate that the proposed method achieves significant performance advantages under various working conditions. Specifically, the average RMSE and MAE on the NASA dataset are reduced to 0.0311  mm and 0.0253  mm, respectively, while on the NUAA dataset they are reduced to 0.0058  mm and 0.00425  mm, outperforming several mainstream benchmark models. This study provides a novel solution for predicting milling cutter wear under various working conditions.},
  archive      = {J_ESWA},
  author       = {Wujun Yu and Hongfei Zhan and Rui Wang and Junhe Yu and Dewen Kong and Guojun Huang},
  doi          = {10.1016/j.eswa.2025.128888},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128888},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-condition milling cutter wear prediction based on split-channel information re-fusion and domain adaptation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed semi-supervised learning for hot-rolled strip flatness pattern recognition based on FixMatch method. <em>ESWA</em>, <em>296</em>, 128885. (<a href='https://doi.org/10.1016/j.eswa.2025.128885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flatness is one of the most critical quality indicators for strips. Strip flatness pattern recognition (SFPR) is a key aspect of hot-rolled strip production, providing the basis for precise quality control. However, constructing an accurate and adaptable SFPR data-driven model is a significant challenge for intelligent product quality control because of the complexity of data features, the low utilization of unlabeled data due to high labeling costs, and the imbalanced distribution of sample data. To address these challenges, this paper proposes an SFPR framework that combines semi-supervised learning (SSL) and physics-informed neural networks (PINN). First, to tackle the complexity of data features, a flatness pattern feature extraction method guided by hot-rolling physical information is developed. Second, to enhance the learning and generalization capabilities of the classifier with a limited amount of labeled data, an SSL model based on FixMatch is constructed for SFPR. Additionally, to further enhance the performance and interpretability, the PINN method is integrated into the SSL model. Numerous ablation experiments demonstrate the effectiveness of the method proposed in this paper. Compared to other supervised learning and purely SSL classifiers, the SSL model guided by physical information performs better in terms of accuracy and adaptability. This demonstrates the advantage of integrating domain knowledge into SSL frameworks. By incorporating physical information and SSL methods, this paper solves the current challenges faced by SFPR, which is significant for the precise control of strip quality.},
  archive      = {J_ESWA},
  author       = {Fenjia Wang and Anrui He and Chao Liu and Wendan Xiao and Yong Song and Changke Chen and Yi Qiang},
  doi          = {10.1016/j.eswa.2025.128885},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128885},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed semi-supervised learning for hot-rolled strip flatness pattern recognition based on FixMatch method},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced medical image analysis using hybrid henry gas solubility optimization algorithm with optimized AdaBoost stacked neural networks. <em>ESWA</em>, <em>296</em>, 128882. (<a href='https://doi.org/10.1016/j.eswa.2025.128882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image analysis is essential in modern healthcare, as it allows for the extraction of clinically valuable information from various imaging modalities such as X-rays, magnetic resonance imaging (MRI), computed tomography (CT), ultrasound, and positron emission tomography (PET). Each modality provides unique diagnostic insights for disease detection, monitoring, and treatment planning. Various Artificial intelligence approaches have been implemented for precise medical image analysis, yet they face key challenges, including overfitting, poor generalization to unseen data, and high computational demands. To address these limitations, this study proposes a novel deep learning framework that integrates Hybrid Henry Gas Solubility Optimization with Adaptive Boosting Stacked Gated Recurrent Unit-Recurrent Neural Network to improve medical image classification across multiple modalities. The Stacked Gated Recurrent Unit (GRU) Recurrent Neural Network is developed to improve the capacity of the model to capture complex features and patterns within medical images from different imaging modalities. By stacking multiple layers of Gated Recurrent Units, the network captures both low-level and high-level spatial–temporal dependencies within the image data. The proposed study introduces a Hybrid Henry Gas Solubility Optimization algorithm for optimization that incorporates multiple metaheuristic strategies, including the Sooty Tern Optimization Algorithm, Jaya, Owl Search Algorithm, and Butterfly Optimization Algorithm within a dynamic reward-penalty framework to improve global search capability and avoid local minima. Further, the Adaptive Boosting strategy is implemented to strengthen model robustness by aggregating weak learners and focusing on difficult-to-classify samples, mitigating class imbalance issues. The proposed framework is evaluated using medical image datasets from three imaging modalities, such as brain MRI, chest X-ray, and lung CT scans. The simulation results confirm that the proposed mechanism attains superior diagnostic performance across multiple imaging modalities and consistently outperforms existing methods in detecting critical diseases such as brain tumors, pneumonia, and lung cancer.},
  archive      = {J_ESWA},
  author       = {Karuppiah SP and Anita Rose JT and Subasini CA and Sangeetha Francelin Vinnarasi F},
  doi          = {10.1016/j.eswa.2025.128882},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128882},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced medical image analysis using hybrid henry gas solubility optimization algorithm with optimized AdaBoost stacked neural networks},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scalar projective synchronization for uncertain T-S fuzzy systems with unified control fluctuation: Implementation to quadruple-tank process model. <em>ESWA</em>, <em>296</em>, 128878. (<a href='https://doi.org/10.1016/j.eswa.2025.128878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work intends to the study of the energy-based performances of the Takagi-Sugeno (T-S) fuzzy systems in the presence of parameter uncertainties and non-linear function. This type of fuzzy system refers to an extension of the T-S fuzzy systems, where non-linear terms are directly incorporated into the outcome of the fuzzy rules. The major motive of this study is to examine the scalar projective synchronization criterion of robust master and slave systems via unified control fluctuation, specifically, non-fragility control. In contrast to the current literature, both norm-bounded additive and multiplicative uncertainties are considered in the non-fragile robust state-feedback controller. The sufficient conditions for robust extended dissipative performance of the T-S fuzzy system are derived by utilizing a projective synchronization approach under state feedback controllers with non-fragility and by linearizing the integral terms obtained from the augmented Lyapunov-Krasovskii functional. Finally, numerical examples counting with fuzzified quadruple-tank process system model have been conducted through MATLAB software to demonstrate the importance and efficacy of the given theoretical results.},
  archive      = {J_ESWA},
  author       = {R. Elavarasi and B. Adhira and G. Nagamani and Van Thanh Huynh},
  doi          = {10.1016/j.eswa.2025.128878},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128878},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scalar projective synchronization for uncertain T-S fuzzy systems with unified control fluctuation: Implementation to quadruple-tank process model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A generalized neural solver based on LLM-guided heuristic evoluation framework for solving diverse variants of vehicle routing problems. <em>ESWA</em>, <em>296</em>, 128876. (<a href='https://doi.org/10.1016/j.eswa.2025.128876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Routing Problems (VRPs) are key combinatorial optimization challenges with broad applications in logistics. While neural solvers based on attention mechanisms offer promising results, they require retraining for each VRP variant, limiting scalability. Existing expert-designed and LLM-based heuristic methods often suffer from limited exploration ability and premature convergence. We propose the Unified VRP Neural Solver (UNS), an LLM-enabled framework that dynamically adjusts attention scores by generating variant-specific heuristics without requiring retraining of neural model parameters. At its core, the LLM-Guided Heuristic Evolution (LHE) algorithm, which is inspired by population-based Differential Evolution (DE) frameworks, iteratively refines heuristics through Mutation, Global Crossover, and Local Crossover to enhance diversity and avoid local optima. Extensive experiments across 16 VRP variants show that LHE outperforms state-of-the-art neural solvers and LLM-based approaches. The similarity analysis of heuristic populations reveals that LHE maintains higher diversity and avoids premature convergence. Additional evaluations on CVRP and TSP, along with ablation studies, validate the effectiveness and generalizability of LHE.},
  archive      = {J_ESWA},
  author       = {Minyan Chi and Wei Pang and Xuan Wu and Peng Zhao and YuanShu Li and Tianfang Wang and Junjie Qian and Yubin Xiao and Liupu Wang and You Zhou},
  doi          = {10.1016/j.eswa.2025.128876},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128876},
  shortjournal = {Expert Syst. Appl.},
  title        = {A generalized neural solver based on LLM-guided heuristic evoluation framework for solving diverse variants of vehicle routing problems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic sanctioning mechanism for cooperative multi-agent systems. <em>ESWA</em>, <em>296</em>, 128873. (<a href='https://doi.org/10.1016/j.eswa.2025.128873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordinating multi-agent systems to accomplish complex tasks presents a profound and unprecedented challenge, introducing significant uncertainty into the operational framework of collective artificial intelligence. Addressing this formidable challenge requires collective actions of cooperation and concerted efforts on a global scale. However, progress in addressing this challenge through voluntary contributions has been regrettably slow, highlighting the need for the participation of robust sanctioning mechanisms to drive meaningful change. Here, we propose a dynamic sanctioning framework that relies on adjusting between positive and negative incentives based on the collective status of the population. We show that the transition of sanctioning institutions from punitive measures to rewarding mechanisms can effectively sustain a high level of cooperation, even when the risk of collective action failure is low. The threshold at which sanctioning institutions choose to switch incentives plays a crucial role in shaping evolutionary outcomes. Moreover, we provide further evidence that the success of the reward mechanism is based on the presence of self-interested altruism, in which the implementing authority also benefits from the incentives.},
  archive      = {J_ESWA},
  author       = {Linjie Liu and Lichen Wang and Weiyan Niu and Shijia Hua},
  doi          = {10.1016/j.eswa.2025.128873},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128873},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic sanctioning mechanism for cooperative multi-agent systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Relevant subspace search for outlier detection on massive data. <em>ESWA</em>, <em>296</em>, 128870. (<a href='https://doi.org/10.1016/j.eswa.2025.128870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an important task in the field of data mining, which has wide applications in real life. Since subspace outlier detection attracts widespread attention for its ability to effectively identify outliers in high-dimensional data, a series of subspace search algorithms for outlier detection are proposed to identify subspaces that reveal outliers. However, it is found that the existing algorithms often lose their effectiveness when processing massive data due to large memory consumption. Additionally, they struggle to achieve high-quality results because of the lack of strong pruning. In this paper, a novel algorithm RSLSH (Relevant Subspace Search based on Locality Sensitive Hashing) is presented to mine relevant subspaces for outlier detection on massive data. RSLSH applies a pre-computed disk-resident attribute list structure and LSH slice set to divide the huge database into small partitions. An adaptive relevance attribute acquisition method using LSH slices is employed to significantly reduce the search space for candidate subspaces. Within the depth-first subspace generation approach, a memory-resident attribute list structure is designed to reduce the I/O cost when calculating subspace correlations. Moreover, an update strategy for the memory-resident structure based on MFU is devised to enhance data reusability. The extensive experimental results show that RSLSH can discover relevant subspaces for outlier detection on massive data efficiently.},
  archive      = {J_ESWA},
  author       = {Qianhui Xu and Xixian Han and Xiaolong Wan and Hongzhi Wang},
  doi          = {10.1016/j.eswa.2025.128870},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128870},
  shortjournal = {Expert Syst. Appl.},
  title        = {Relevant subspace search for outlier detection on massive data},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D-PV: Enhancing PV power prediction by modeling spatial uncertainty under dynamic shading conditions. <em>ESWA</em>, <em>296</em>, 128869. (<a href='https://doi.org/10.1016/j.eswa.2025.128869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Earth’s revolution and geographic variability introduce spatial uncertainty in photovoltaic (PV) systems. Subtle spatial variations give rise to dynamic shading conditions (DSC), which disrupt power prediction over time. Existing models often neglect to capture the effects of spatial uncertainty, and consequently struggle to address the DSC in PV systems. This paper presents a 3D-PV framework, which introduces a deblurring 3D reconstruction technique to produce spatial representations, preserving details of PV panels and their surrounding environment. Further, shadow variation matrices are constructed by the proposed ComputeShader-based shadow calculation algorithm, serving as a spatio-temporal representation to bridge the obtained spatial representations and dynamic shading variations. Building on the spatio-temporal representations, 3D-PV performs semantic fusion of shadow dynamics and irradiance signals, enabling temporally consistent power prediction under DSC. Experimental results, including ablation studies, demonstrate that precise spatial modeling effectively captures and simulates accurate shadow patterns over time. In particular, 3D-PV outperforms state-of-the-art prediction methods, achieving a 23.95 % reduction in mean squared error (MSE) for prediction accuracy. These results highlight the benefits of explicitly modeling spatial uncertainty and dynamically fusing spatio-temporal representations with irradiance signals under DSC, enabling accurate prediction of PV power.},
  archive      = {J_ESWA},
  author       = {Fengze Li and Dou Hong and Jieming Ma and Zhongbei Tian and Hai-Ning Liang and Jiawei Guo and Kangshi Wang},
  doi          = {10.1016/j.eswa.2025.128869},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128869},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D-PV: Enhancing PV power prediction by modeling spatial uncertainty under dynamic shading conditions},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IHQGAN: A lightweight invertible hybrid quantum-classical generative adversarial networks for unsupervised image-to-image translation. <em>ESWA</em>, <em>296</em>, 128865. (<a href='https://doi.org/10.1016/j.eswa.2025.128865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the intrinsic properties of quantum computing to enhance machine learning has shown promise, with quantum generative adversarial networks (QGANs) demonstrating benefits in data generation. However, the application of QGANs to unsupervised image-to-image (I2I) translation remains unexplored. Moreover, classical neural networks often suffer from large parameter spaces, posing challenges for GAN-based I2I methods. To address these limitations, this study introduces quantum computation for unsupervised I2I translation. The natural alignment between this task’s approximate reversibility and quantum computation’s reversibility provides a theoretical foundation for enabling parameter sharing in the model, thereby reducing parameter scale. Furthermore, quantum models offer potential parameter efficiency advantages compared to parameter-dense classical networks. Building upon these advantages, we propose iHQGAN, a lightweight invertible hybrid quantum-classical model for unsupervised I2I translation. Specifically, iHQGAN employs two mutually approximately reversible quantum generators with shared parameters, effectively reducing the parameter scale. To ensure content consistency between generated and source images, each quantum generator is paired with an assisted classical neural network (ACNN), enforcing a unidirectional cycle consistency constraint between them. Simulation experiments were conducted on 23 sub-datasets across three tasks. Qualitative and quantitative assessments indicate that iHQGAN effectively performs unsupervised I2I translation with excellent generalization and can outperform classical methods that use low-complexity CNN-based generators. Additionally, iHQGAN, as with classical reversible methods, reduces the parameter scale of classical irreversible methods via a reversible mechanism. This study presents the first versatile quantum solution for unsupervised I2I translation, extending the scope of QGANs research beyond basic image generation within the visual domain and providing a quantum approach to decrease the parameters of GAN-based unsupervised I2I translation methods.},
  archive      = {J_ESWA},
  author       = {Xue Yang and Rigui Zhou and Shizheng Jia and Yaochong Li and Jicheng Yan and Zhengyu Long and Wenyu Guo and Fuhui Xiong and Wenshan Xu},
  doi          = {10.1016/j.eswa.2025.128865},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128865},
  shortjournal = {Expert Syst. Appl.},
  title        = {IHQGAN: A lightweight invertible hybrid quantum-classical generative adversarial networks for unsupervised image-to-image translation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatially adaptive representation of facial meshes for face video super-resolution. <em>ESWA</em>, <em>296</em>, 128864. (<a href='https://doi.org/10.1016/j.eswa.2025.128864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Video Super-Resolution (FVSR) aims to generate high-resolution face videos from low-resolution ones by leveraging relationships among multiple frames, with significant applications in restoring old films and enhancing facial features in surveillance. Existing methods perform global motion trend analysis when dynamically resolving images; however, when applied to face targets, they fail to adequately capture the intricate details of the face, resulting in unsatisfactory super-resolution of the facial region. To address this issue, we segment the face into many triangular blocks to generate a face mesh representation that better represents the facial features and thus mitigates the effect of redundant background. In addition, we employ a spatially adaptive separable convolutional kernel to align different facial temporal meshes according to pose variations, providing enhanced complementary information for subsequent super-resolution processing. Finally, we fuse the aligned features in different propagation directions to generate the output HR image. The experimental results show that this method can capture more facial details. In the comparison with the most advanced baseline, in the recovery of low-quality face videos, we can at least increase PSNR and SSIM by 1.01 % and 0.45 % respectively, and reduce LPIPS by 21.15 %.},
  archive      = {J_ESWA},
  author       = {Shangchen Cai and Xin Ding and Jing Fang and Qiong Liu and You Yang},
  doi          = {10.1016/j.eswa.2025.128864},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128864},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatially adaptive representation of facial meshes for face video super-resolution},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Events enhance crude oil price risk measurement: Embedding breakpoints in GARCH-VaR. <em>ESWA</em>, <em>296</em>, 128863. (<a href='https://doi.org/10.1016/j.eswa.2025.128863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The international oil market is complex, and the oil price fluctuation is always non-linear and chaotic. As the frequency of uncertain events rises and the interconnectedness among markets strengthens, structural breakpoints on behalf of uncertain events become increasingly prevalent, and their impact on structural changes in time series continues to grow. To accurately capture the market volatility, structural breakpoints are becoming important factors that need to be taken into consideration. This study developed a comprehensive framework for time series volatility and risk assessment incorporated with breakpoints. We presented an objective approach for identifying the number and location of structural breakpoints based on Wasserstein distance. Then extended the GARCH-VaR models by introducing the breakpoints as dummy variables to analyze the volatility of the conditional variance. Compared with the conventional models, the breakpoints-based GARCH-VaR model performs better, which can reduce the failure rate and improves the accuracy of the risk measure. The WTI and Brent oil price from January 2005 to January 2024 were used in the empirical study. During the period, major incidents such as economic crises, geopolitical conflicts, and large-scale public health events occurred. The results showed that there are 12 breakpoints in WTI oil price time series and 17 in Brent oil price time series which are related to the major historical events that have impacted the oil market. This demonstrates the necessity of considering breakpoints and the importance of detecting breakpoints accurately. We conducted a powerful test in the empirical research, through comparative analysis of the risk measurement failure rates in different GARCH-VaR models before and after incorporating breakpoints, the effectiveness and robustness of the extended model are validated.},
  archive      = {J_ESWA},
  author       = {Lei Cheng and Lu-Tao Zhao and Qi-Yu Gu and Zhao-Ting Liu and Zhao-Yuan Li},
  doi          = {10.1016/j.eswa.2025.128863},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128863},
  shortjournal = {Expert Syst. Appl.},
  title        = {Events enhance crude oil price risk measurement: Embedding breakpoints in GARCH-VaR},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). E2MISeg: Enhancing edge-aware 3D medical image segmentation via feature progressive co-aggregation. <em>ESWA</em>, <em>296</em>, 128861. (<a href='https://doi.org/10.1016/j.eswa.2025.128861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D segmentation is critically essential in the clinical medical field, which aids physicians in locating lesions and assists in clinical decision-making. The unique properties of organ and tumour images with large-scale variations and low-edge pixel-level contrast make clear segment edges difficult. Facing these problems, we propose an Enhancing Edge-aware Medical Image Seg mentation (E2MISeg) for smooth segmentation in boundary ambiguity. Firstly, we propose the Multi-level Feature Group Aggregation (MFGA) module to enhance the accuracy of edge voxel classification through the boundary clue of lesion tissue and background. Secondly, to minimize the influence of background noise on the model’s sensitivity to the foreground, the Hybrid Feature Representation (HFR) block utilizes an interactive CNN and Transformer to deeply mine the lesion area and edge texture features while providing more clues for the MFGA module. Finally, we introduce the Scale-Sensitive (SS) loss function that dynamically adjusts the weights assigned to targets based on segmentation errors, with these weights guiding the network to focus on regions where segmentation edges are unclear. Furthermore, we retrospectively collated the Mantle Cell Lymphoma PET Imaging Diagnosis (MCLID) dataset of 176 patients from multiple central hospitals, which enhances our algorithm’s robustness against complex clinical data. The extensive experimental results on three public challenge datasets and the MCLID clinical dataset demonstrate our approach, which outperforms the state-of-the-art methods. Further analysis shows that our components work together to achieve smooth edge segmentation, which is of great significance for accurate clinical diagnosis and prognosis analysis. The Code available at: https://github.com/SoloTillDawn/E2MISeg},
  archive      = {J_ESWA},
  author       = {Lincen Jiang and Wenpin Xu and Xinyuan Zheng and Zitong Zhang and Zekun Jiang and Chong Jiang and Yanli Chen and Yimu Ji and Shangdong Liu and Jianwei Liu and Jingyan Xu},
  doi          = {10.1016/j.eswa.2025.128861},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128861},
  shortjournal = {Expert Syst. Appl.},
  title        = {E2MISeg: Enhancing edge-aware 3D medical image segmentation via feature progressive co-aggregation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-scene hyperspectral image classification based on cross-domain feature extraction and category decision collaborative optimization. <em>ESWA</em>, <em>296</em>, 128842. (<a href='https://doi.org/10.1016/j.eswa.2025.128842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-scene hyperspectral image classification aims to enable the model to complete the classification of unlabeled target domain data by learning from labeled source domain data. Aiming at the problem that most current cross-scene hyperspectral image classification algorithms do not fully consider the cross-domain feature representation and category decision boundary optimization, a cross-domain Feature Extraction and Category Decision collaborative optimization (FECD) network is proposed. First, an adaptive feature discovery based on dynamic masks is designed. In this mechanism, the dynamically scaled masks are applied to the 3D representation of source and target domain data to generate an informative feature space and enhance the cross-scene discrimination potential of the model. Second, a dual-stream convolutional cross-domain feature extraction based on Mamba stream and ViT stream is constructed. Long sequence modeling and convolutional attention mechanisms are used to capture cross-domain spectral features between pixel, and self-attention mechanisms and multi-scale convolution are used to excavate cross-domain space patterns of pixel. Finally, a category decision based on the co-optimization of dual-stream classifiers is implemented. The spectral and spatial boundaries learned by the dual streams are fused to optimize the category decision. Therefore, the risk of false labeling is avoided while obtaining more accurate category boundaries. Compared with seven state-of-the-art algorithms on three widely used datasets, FECD obtains better categorization results on three categorization metrics: OA, AA, and Kappa.},
  archive      = {J_ESWA},
  author       = {Chi Wang and Ronghua Shang and Yangyang Li and Jie Feng and Songhua Xu},
  doi          = {10.1016/j.eswa.2025.128842},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128842},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-scene hyperspectral image classification based on cross-domain feature extraction and category decision collaborative optimization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Capsule networks for intelligent fault diagnosis: A roadmap of recent advancements and challenges. <em>ESWA</em>, <em>296</em>, 128814. (<a href='https://doi.org/10.1016/j.eswa.2025.128814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the backdrop of the rapid development of intelligent fault diagnosis (IFD) technology, Capsule Networks (CapsNets), owing to their ability to preserve spatial hierarchical information and enhance interpretability, have emerged as a promising alternative to traditional convolutional neural networks (CNNs) and thus become a research hotspot in the field of IFD. However, there is currently a lack of systematic reviews on the application status and challenges of CapsNets in IFD. To bridge this gap, this paper views the literature published in the Web of Science Core Collection from January 2018 to June 2025 and conducts an analysis of CapsNets from three dimensions, namely theory, application fields, and model improvements. The findings show that CapsNets are primarily applied in mechanical fault diagnosis (MFD) (75.2%, with bearing faults accounting for 35.6%) and electrical equipment (16.8%), while their applications in energy, healthcare, and other fields remain limited. Existing studies have improved the model by enhancing training sample quality, optimizing network architectures, and strengthening interpretability. Nevertheless, several challenges persist, including low training efficiency, poor sample quality, insufficient model accuracy and robustness, inefficient dynamic routing mechanisms, and weak interpretability depth. Looking ahead, the development of CapsNets in IFD can focus on six directions: lightweight and efficient algorithm design; multimodal data fusion and cross-domain transfer learning; enhancement of anti-noise ability and robustness; compound fault decoupling and interpretability enhancement; edge computing and embedded deployment and integration with digital twins. This paper provides systematic guidance for the application and research of CapsNets in IFD.},
  archive      = {J_ESWA},
  author       = {Yang Dalian and Zou Junjun and Long Hui},
  doi          = {10.1016/j.eswa.2025.128814},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128814},
  shortjournal = {Expert Syst. Appl.},
  title        = {Capsule networks for intelligent fault diagnosis: A roadmap of recent advancements and challenges},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond noise: A BERT-enhanced framework for intelligent product optimization via online review analytics. <em>ESWA</em>, <em>296</em>, 128812. (<a href='https://doi.org/10.1016/j.eswa.2025.128812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews provide valuable insights into customer preference and product attributes (PAs), enabling companies to formulate effective product improvement strategies. In addition to PAs, however, reviews often contain noise, such as information about logistics and marketing strategies. While managing this noise is crucial to improving PA extraction and categorization accuracy and efficiency, existing studies have largely overlooked or handled noise inadequately. To address this gap, this study proposes a hybrid AI-driven framework for identifying and categorizing PAs while filtering out noise from online reviews. First, we use bidirectional encoder representations from transformers (BERT) to identify informative reviews (i.e., those containing at least one PA). Then, we integrate latent Dirichlet allocation and Word2Vec to extract irrelevant information, aiming to isolate noise and extract PAs from the reviews. Furthermore, we categorize PAs using importance-performance analysis (IPA) and IPA-GAP1. In this process, the importance of attributes is calculated by fitting the relationship between customer sentiment toward attributes and customer satisfaction using random forest, and customer sentiments are determined using BERT-based sentiment analysis. Additionally, we use importance–performance competitor analysis to assess attribute performance and importance across different products. Finally, we propose an Improvement Priority Score (IPS), which integrates attribute importance, performance, and competitive performance gap to provide companies with actionable insights for product optimization under limited resources. The proposed framework is validated through a case study using phone reviews from JD.com .},
  archive      = {J_ESWA},
  author       = {Liangxing Shi and Xiaoyuan Wang and Yingdong He and Zhen He},
  doi          = {10.1016/j.eswa.2025.128812},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128812},
  shortjournal = {Expert Syst. Appl.},
  title        = {Beyond noise: A BERT-enhanced framework for intelligent product optimization via online review analytics},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Medical image segmentation model for complex boundary features: Large kernel deformable convolution and gated feature preservation. <em>ESWA</em>, <em>296</em>, 128801. (<a href='https://doi.org/10.1016/j.eswa.2025.128801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays a vital role in clinical diagnosis but is frequently constrained by challenges such as insufficient multi-scale feature fusion, difficulties in extracting complex boundaries and suboptimal integration of deep and shallow semantic information. To tackle these issues, this study proposes the Cascaded Gated Large Kernel Deformable Network (CGLKNet). The network employs a U-shaped pyramid encoder-decoder architecture, utilizing a pre-trained MaxVit module as the encoder to extract multi-level features. It introduces a Deformable Large Kernel Efficient Module (DLEM) in the decoder to expand the receptive field and enhance the modeling of complex boundaries. Additionally, a Hierarchical Gated Boundary Feature Fusion Module (GBM), cascaded with the decoder, optimizes the fusion of global and local features through a dynamic gating mechanism while improving the transmission of deep and shallow information via cross-scale interactions. Experimental results on four public datasets ISIC2016, CVC-ClinicDB, GLAS, and BUSI demonstrate that CGLKNet achieves IOU scores of 88.39 %, 91.05 %, 87.92 % and 72.52 %, respectively, surpassing existing advanced models and exhibiting superior segmentation accuracy and robustness. Our code is available at https://github.com/HUCONGG/-CGLKNet .},
  archive      = {J_ESWA},
  author       = {Cong Hu and Zhengpeng Li and Jun Hu and Kunyang Wu and Bin Yang and Jiansheng Wu and Yuanyuan Zhang},
  doi          = {10.1016/j.eswa.2025.128801},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128801},
  shortjournal = {Expert Syst. Appl.},
  title        = {Medical image segmentation model for complex boundary features: Large kernel deformable convolution and gated feature preservation},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A theoretical review on solving algebra problems. <em>ESWA</em>, <em>296</em>, 128789. (<a href='https://doi.org/10.1016/j.eswa.2025.128789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving algebra problems (APs) continues to attract significant research interest as evidenced by the large number of algorithms and theories proposed over the past decade. Despite these important research contributions, however, the body of work remains incomplete in terms of theoretical justification and scope. The current contribution intends to fill the gap by developing a review framework that aims to lay a theoretical base, create an evaluation scheme, and extend the scope of the investigation. This paper first develops the State Transform Theory (STT), which emphasizes that the problem-solving algorithms are structured according to states and transforms unlike the understanding that underlies traditional surveys which merely emphasize the progress of transforms. The STT, thus, lays the theoretical basis for a new framework for reviewing algorithms. This new construct accommodates the relation-centric algorithms for solving both word and diagrammatic algebra problems. The latter not only highlights the necessity of introducing new states but also allows revelation of contributions of individual algorithms - obscured in prior reviews without this approach. A review of AP solving algorithms (2014 to date) is subsequently enhanced by applying the STT specifically designed to analyze individual and collective algorithms for states and transforms. Furthermore, the State Transform Analysis (STA) is a core function in the identification of progress in terms of states and transforms. Thirdly, the Perspective Confusion Comparison (PCC) is developed to extend the application of STA to add capabilities for systematic and individual evaluation of transforms, algorithms, and approaches. This is a new evaluation method of being different from other methods that can do more in-depth evaluation for decomposed algorithms for solving problems with multiple types of inputs. Finally, this work identifies several research directions by extracting benefit from theoretical reviews. This work significantly contributes to the advancement of AP-solving by providing the mechanism for identifying and understanding the key contributors to building high-performance problem-solving algorithms at the three levels of transform, algorithm, and approach.},
  archive      = {J_ESWA},
  author       = {Xinguo Yu and Weina Cheng and Chuanzhi Yang and Ting Zhang},
  doi          = {10.1016/j.eswa.2025.128789},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128789},
  shortjournal = {Expert Syst. Appl.},
  title        = {A theoretical review on solving algebra problems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A personalized active learning strategy with enhanced user satisfaction for recommender systems. <em>ESWA</em>, <em>296</em>, 128765. (<a href='https://doi.org/10.1016/j.eswa.2025.128765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lacking of interaction data, generating effective recommendations for new users has been a challenging task known as the user cold-start problem. Active learning strategies are widely used to address this by collecting user preferences through recommendation-rating rounds. Typically, the active learning phase ends after a fixed number of ratings, which may not be optimal. This rigid setting can result in premature exits or user fatigue. Observing disadvantages of such a rigid setting, this paper designs a dynamic and personalized strategy, in which not only the recommended items, but also the length of the active learning phase. The phase ends based on the system’s knowledge of the user evaluated by rating prediction. Extensive experiments on different datasets show that, the proposed Profile Length Confirming Strategy (PLCS) can effectively shorten the active learning phase (profile length) for various algorithms. For instance, on the Coat dataset, our method achieves accuracy comparable to that of the fixed approach, while reducing the number of interaction rounds by at least 3 for 58.47 % of new users. Moreover, a new metric, Variance Via Prediction (VP) , is also proposed for selecting seed items during the active learning phase, which outperforms the widely-adopted entropy-based metric by 5.6 % in accuracy and 0.9 % in efficiency on the Coat dataset. The proposed PLCS strategies can be stably applied to a variety of active learning algorithms, enhancing new users’ experience for recommender systems in different contexts.},
  archive      = {J_ESWA},
  author       = {Siwei Qian and Jie Wang and Shengjie Zhao},
  doi          = {10.1016/j.eswa.2025.128765},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128765},
  shortjournal = {Expert Syst. Appl.},
  title        = {A personalized active learning strategy with enhanced user satisfaction for recommender systems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Turbo-IRL: Enhancing multi-agent systems using turbo decoding-inspired deep maximum entropy inverse reinforcement learning. <em>ESWA</em>, <em>296</em>, 128754. (<a href='https://doi.org/10.1016/j.eswa.2025.128754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse Reinforcement Learning (IRL) involves analyzing expert agents’ behavior to uncover the rationality behind their actions, with applications in robotics, autonomous systems, gaming, and the animation industry. Conventional Multi-Agent IRL (MA-IRL) approaches typically assume either fully cooperative or fully independent agent objectives. However, real-world scenarios often involve partially aligned goals comprising both shared andagent-specific components. To address this complexity, we propose Turbo-IRL, a novel, parallelizable MA-IRL framework that extends Deep Maximum Entropy IRL with an iterative information exchange mechanism inspired by Turbo Decoding (TD) in coding theory. Turbo-IRL consists of multiple agent-specific IRL modules, each leveraging deep neural networks to recover complex reward structures. Through iterative communication, agents refine their estimates of shared rewards while concurrently discovering individualized reward components. This information exchange mechanism allowsthem to benefit from others’ trajectories, which convey partial information about their common goals. This is particularly advantageous for under-trained agents with a small number of trajectories in unbalanced scenarios. Our simulations across multiple scenarios with different levels of overlap and similarity between agents’ reward functions show a considerable gain for the proposed Turbo-IRL framework compared to the benchmark Deep IRL method. Specifically, we achieve about 50 % and 44 % improvement in terms of MSE in recovering the true reward function for similarity levels 75 % and 25 %, utilizing the same number of total trajectories. Conversely, our method achieves equivalent performance utilizing much fewer (about 44 % for a 3-agent system). Furthermore, on the standard MPE simple_spread benchmark, Turbo-IRL achieves the lowest MAE of 1.04 in episode return, outperforming several state-of-the-art baselines, including MA-GAIL, MA-AIRL, Behavior Cloning, and MIFQ (38 % to 87 % improvement) – underscoring its efficacy, scalability, and generalization capability in complex multi-agent environments with partially shared objectives.},
  archive      = {J_ESWA},
  author       = {Niloufar Mehrabi and Sayed Pedram Haeri Boroujeni and Abolfazl Razi},
  doi          = {10.1016/j.eswa.2025.128754},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128754},
  shortjournal = {Expert Syst. Appl.},
  title        = {Turbo-IRL: Enhancing multi-agent systems using turbo decoding-inspired deep maximum entropy inverse reinforcement learning},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel deep reinforcement learning framework based on digital twins for dynamic job shop scheduling problems. <em>ESWA</em>, <em>296</em>, 128708. (<a href='https://doi.org/10.1016/j.eswa.2025.128708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing diversity of product demands, the complexity of production scheduling planning has also been continuously escalating. Existing scheduling models exhibit significant deviations from actual production systems, making it challenging to directly apply scheduling algorithms to practical systems. High-fidelity digital twin (DT) models offer the capability to faithfully replicate production processes, providing effective means for training and validating scheduling algorithms. In this context, we propose a dynamic scheduling framework, DT-DRL, based on DT for deep reinforcement learning (DRL) applications in real production scheduling. Firstly, we employ DT technology to model actual production lines, effectively addressing the issue of model completeness. Secondly, we utilize the Double Deep Q-Network (DDQN) algorithm for offline training, followed by online decision-making, effectively addressing the challenge of real-time dynamic scheduling. Lastly, experimental training and validation are conducted using historical order and equipment data from the water heater inner tank welding production line. The experimental results demonstrate the robustness of our model.},
  archive      = {J_ESWA},
  author       = {Wenquan Zhang and Zhaoxian Peng and Fei Zhao and Bo Feng and Xuesong Mei},
  doi          = {10.1016/j.eswa.2025.128708},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128708},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel deep reinforcement learning framework based on digital twins for dynamic job shop scheduling problems},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clinically validated depression dataset aligned with DSM-5 criteria for major depressive disorder (MDD). <em>ESWA</em>, <em>296</em>, 128691. (<a href='https://doi.org/10.1016/j.eswa.2025.128691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2021, over half of American adults reported experiencing depressive symptoms following COVID-19 infection. Left untreated, depression can significantly elevate the risk of harmful behaviors, including substance abuse, which in turn may damage relationships, hinder workplace performance, and impair recovery from serious illnesses. To support early diagnosis and intervention, this study introduces EmoDep (Emotion-related to Depression), a clinically aligned, annotated dataset for depression detection that captures nine core symptoms of major depressive disorder (MDD) and their corresponding intensity levels. We curated this dataset by collecting user-generated posts and comments from the Reddit community r/depression between January 2010 and December 2019, and systematically refined it based on the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5) criteria. With assistance from mental health professionals, we constructed a symptom-specific lexical dictionary reflecting the nine MDD criteria. To annotate intensity, we employed the Best-Worst Scaling (BWS) technique and further applied data augmentation strategies to ensure comprehensive coverage. Overall, the EmoDep dataset provides a reliable textual resource for multi-label classification of depressive symptoms and their severity, facilitating improved detection of depression-related expressions in online platforms.},
  archive      = {J_ESWA},
  author       = {Jaedong Oh and Jooyoung Lim and Hayoung Oh},
  doi          = {10.1016/j.eswa.2025.128691},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128691},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clinically validated depression dataset aligned with DSM-5 criteria for major depressive disorder (MDD)},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A pattern-based and multi-objective architecture for selecting optimal compositions of web services. <em>ESWA</em>, <em>296</em>, 128674. (<a href='https://doi.org/10.1016/j.eswa.2025.128674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The composition of web services performs a complicated service using its interacting single services, each with a few QoS (quality of service) features. Many compositions exist that perform the same complex service but with different QoS features whose near-optimal ones should be selected. Before the selection, the compositions’ QoS s based on summarizing the composition patterns should be calculated. Many methods have been presented for the compositions’ QoS s calculation and near-optimal composition selection. However, in summarizing they considered: (1) not all kinds of patterns in compositions, (2) not formal-based pattern definitions, and (3) not high-performance method. To address these issues and to present an effective method over related studies for composition selection, we suggest a Pattern-based and multi-objective architecture ( PBMOA ). We applied our approach to four real-world web-based service-oriented systems using a dataset of 2507 candidates and evaluated results. We then compared the solutions derived from eight related studies with the solutions derived from our architecture in terms of features and a few performance metrics. Additionally, we demonstrated the generality of the results in terms of features by utilizing statistical tests. Our solutions (near-optimal compositions) outperform related studies’ solutions by an average of 79 percent, according to the coverage ratio performance indicator.},
  archive      = {J_ESWA},
  author       = {Narjes Zahiri and Seyed Morteza Babamir},
  doi          = {10.1016/j.eswa.2025.128674},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128674},
  shortjournal = {Expert Syst. Appl.},
  title        = {A pattern-based and multi-objective architecture for selecting optimal compositions of web services},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sparse low-rank retargeted stochastic configuration networks for multiclass classification. <em>ESWA</em>, <em>296</em>, 128652. (<a href='https://doi.org/10.1016/j.eswa.2025.128652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Configuration Networks (SCNs) are a type of randomized learner models that assign hidden parameters stochastically under an innovative supervisory mechanism, with output weights determined via the least squares method. For regression tasks, SCNs can achieve excellent performance by progressively minimizing the squared error between the predicted and actual target values through the incremental addition of hidden nodes to the network. However, the strategy of fitting input features to a rigid zero–one label matrix constrains the performance of SCNs in classification problems. To address this limitation, we propose a Sparse Low-Rank Retargeted Stochastic Configuration Network (SLRR-SCN) designed specifically for multiclass classification. In this study, retargeted least squares regression (ReLSR) is for the first time integrated into the SCNs framework to obtain a retargeted regression matrix with a large-margin constraint, ensuring precise classification of individual data points. Furthermore, SLRR-SCN imposes sparse and low-rank constraints on the output weights and the predicted label matrix for each class, facilitating the learning of a more compact and discriminative transformation. The Alternating Direction Method of Multipliers (ADMM) is employed to efficiently solve the associated optimization problem, and we provide a theoretical proof of its convergence. Extensive simulations and analyses conducted on benchmark classification and image recognition datasets demonstrate that SLRR-SCN significantly outperforms traditional SCNs in terms of classification accuracy.},
  archive      = {J_ESWA},
  author       = {Yang Wang and Guangchuan Liu and Chenglong Zhang and Yilong He and Yingsong Sun},
  doi          = {10.1016/j.eswa.2025.128652},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128652},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sparse low-rank retargeted stochastic configuration networks for multiclass classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Financial cost optimization of urban water resource scheduling using genetic algorithms: A metaheuristic approach. <em>ESWA</em>, <em>296</em>, 128617. (<a href='https://doi.org/10.1016/j.eswa.2025.128617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban water resource scheduling presents a complex optimization challenge, encompassing supply–demand balance, cost efficiency, conservation, and environmental sustainability. This study proposes a financial cost optimization model utilizing a genetic algorithm—an evolutionary metaheuristic technique situated within the broader domain of artificial intelligence—to effectively address these challenges. The model integrates critical variables such as reservoir storage capacity, water plant operational strategies, and both direct and indirect financial cost components. Through iterative processes including population initialization, fitness evaluation, selection, crossover, and mutation, the genetic algorithm identifies an optimal scheduling scheme that minimizes financial costs while ensuring water supply safety and resource efficiency. A case study demonstrates that infrastructure construction costs can be reduced to 4.23 million, with improved water consumption outcomes across domestic, industrial, agricultural, and ecological domains. Comparative results indicate that the genetic algorithm outperforms other AI-related optimization methods such as support vector machines and particle swarm optimization, particularly in financial cost reduction and operational performance. Although genetic algorithms are a subclass of artificial intelligence techniques, this study is confined to their specific application and does not incorporate or evaluate other AI methodologies. Accordingly, the conclusions drawn reflect only the effectiveness of genetic algorithms in optimizing the financial costs of urban water resource scheduling.},
  archive      = {J_ESWA},
  author       = {Qingyun Chen},
  doi          = {10.1016/j.eswa.2025.128617},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128617},
  shortjournal = {Expert Syst. Appl.},
  title        = {Financial cost optimization of urban water resource scheduling using genetic algorithms: A metaheuristic approach},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weight stability intervals for multi-criteria decision analysis using the weighted sum model. <em>ESWA</em>, <em>296</em>, 128460. (<a href='https://doi.org/10.1016/j.eswa.2025.128460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria decision analysis (MCDA), or multi-criteria decision making (MCDM) encompasses a wide set of mathematical methods to compare alternatives whilst considering multiple criteria and the relative importance (weight) of each criterion or the allowable trade-off between criteria. MCDA/MCDM may be implemented in a decision support system to aid decision makers compare multiple alternatives. A key consideration in any MCDA is the sensitivity of the results obtained to alterations of the criteria weights used. Prior methods to determine the weight stability interval ( WSI , the range of values for individual weights for which the ranking of alternatives will not change) include the manual alteration of criteria weights, the use of different sets of criteria weights in a form of scenario analysis, or the process of iteratively searching for the maximum and minimum allowable alterations to individual criteria weights to determine the weight stability interval. The first contribution of this paper is the development of a novel method for determining precise weight stability intervals which does not rely on enumeration or simulation for use with the weighted sum model (WSM, based on the L 1 Minkowski norm), one of the most widely used aggregation methods within MCDA. The second contribution of this work is the use of these WSI s to identify the most sensitive weight(s) based on a Pareto dominance approach whilst considering both the allowable increase and decrease in criteria weights. The above points are demonstrated and applied in an analysis of several alternatives for renewable energy (biogas) production.},
  archive      = {J_ESWA},
  author       = {Richard O’Shea and Peter Deeney and Evangelos Triantaphyllou and Luis Diaz-Balteiro and S. Armagan Tarim},
  doi          = {10.1016/j.eswa.2025.128460},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Weight stability intervals for multi-criteria decision analysis using the weighted sum model},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FLPC: Fusing language and point cloud for 3D object classification. <em>ESWA</em>, <em>296</em>, 128430. (<a href='https://doi.org/10.1016/j.eswa.2025.128430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study enhances the accuracy of point cloud classification by introducing novel fusion architecture that fuses language with point cloud, drawing inspiration from recent advancements in multimodal fusion. Conventional neural networks depend extensively on images as intermediaries between language and point clouds, a methodology that lacks robustness and undermines accuracy. To tackle this, we propose FLPC, a groundbreaking fusion method for point cloud classification that integrates semantic information from textual descriptions with geometric features extracted from point cloud data using an attention mechanism. Our approach leverages a pre-trained model to extract both geometric and semantic features from the input data. These features are subsequently integrated through a classifier module, which is designed to effectively utilize the two types of visual features to enhance classification performance. Within the classifier module, three distinct fusion attention architectures (CFA, SFA, PFA) are proposed. This innovative design, which combines point cloud features with language features, results in a significant improvement in overall performance. A comprehensive set of extensive experiments reveals that both CFA and SFA showcase competitive performance. Significantly, PFA not only markedly outperforms the previous multimodal classification baseline model but also eclipses traditional unimodal classification models, achieving state-of-the-art accuracy. Specifically, on the ModelNet40 benchmark, the proposed FLPC method elevates the performance of PointMLP by approximately 1.5 %. Correspondingly, on the ScanObjectNN benchmark, it surpasses PointMLP by 8.7 %. These results underscore the efficacy of FLPC in leveraging multimodal information for 3D classification tasks, setting a new benchmark in the field.},
  archive      = {J_ESWA},
  author       = {Xiaozheng Gan and Chengtian Song and Jili Li and Lizhi Pan and Keyu Xu},
  doi          = {10.1016/j.eswa.2025.128430},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128430},
  shortjournal = {Expert Syst. Appl.},
  title        = {FLPC: Fusing language and point cloud for 3D object classification},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dubins-RRT* motion planning algorithm considering curvature-constrained path optimization. <em>ESWA</em>, <em>296</em>, 128390. (<a href='https://doi.org/10.1016/j.eswa.2025.128390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion planning problem of Dubins vehicles has long been a significant challenge in the field of mobile robots. However, the randomness in the sampling of angles at waypoints often leads to unnecessary curvature in the paths. This paper improves the sampling and collision detection algorithms of the existing Dubins-RRT* by incorporating the characteristics of Dubins paths. To avoid collision during path optimization, the concept of safety radius enlargement is introduced. Subsequently, the basic solution of the 3-point Dubins problem is extended to the curvature-constrained shortest-path problem, and the necessary conditions for achieving an optimal solution are provided. Given the complexity of solving the existing 3-point Dubins problem, three fundamental forms are presented, along with a direct root-finding approach for solving the problem. Following this, a curvature-constrained path optimization algorithm (CCPOA) is designed, and the modified Dubins-RRT* (MDR) algorithm is integrated into a motion planning algorithm for Dubins vehicles. Finally, simulation results demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jianan Wang and Changyu Bi and Fuxiang Liu and Jiayuan Shan},
  doi          = {10.1016/j.eswa.2025.128390},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128390},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dubins-RRT* motion planning algorithm considering curvature-constrained path optimization},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Audio-visual occlusion-robust gender recognition and age estimation approach based on multi-task cross-modal attention. <em>ESWA</em>, <em>296</em>, 127473. (<a href='https://doi.org/10.1016/j.eswa.2025.127473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gender recognition and age estimation are essential tasks within soft biometric systems, where identifying these characteristics supports a wide range of applications. In real-world scenarios, challenges such as partial facial occlusion complicate these tasks by obscuring crucial voice and facial characteristics. These challenges highlight the importance of development of robust and efficient approaches for gender recognition and age estimation. In this study, we develop a novel audio-visual Occlusion-Robust GENder recognition and AGE estimation (ORAGEN) approach. The proposed approach is based on intermediate features of unimodal transformer-based models and two Multi-Task Cross-Modal Attention (MTCMA) blocks, which predict gender, age, and protective mask type using voice and facial characteristics. We conduct detailed cross-corpus experiments on the TIMIT, aGender, CommonVoice, LAGENDA, IMDB-Clean, AFEW, VoxCeleb2, and BRAVE-MASKS corpora. The proposed unimodal models outperform State-of-the-Art approaches for gender recognition and age estimation. We investigate the impact of various protective mask types on the performance of audio-visual gender recognition and age estimation. The results show that the current large-scale data are still insufficient for a robust gender recognition and age estimation in partial facial occlusion conditions. On the Test subset of the VoxCeleb2 corpus, the proposed approach showed Unweighted Average Recall (UAR) of 99.51%, Mean Absolute Error (MAE) of 5.42, and UAR of 100% for gender recognition, age estimation, and protective mask type recognition, respectively, while on the Test subset of the BRAVE-MASKS corpus, it showed UAR=96.63%, MAE=7.52, and UAR=95.87%, for the same tasks. These results indicate that using data of people wearing protective masks, as well as including the protective mask type recognition task, yields performance gains on all tasks considered. ORAGEN can be integrated into the OCEAN-AI framework for optimizing Human Resources processes, as well as into expert systems with practical applications in various domains including forensics, healthcare, and industrial safety. We make the source code publicly available at https://smil-spcras.github.io/ORAGEN/ .},
  archive      = {J_ESWA},
  author       = {Maxim Markitantov and Elena Ryumina and Alexey Karpov},
  doi          = {10.1016/j.eswa.2025.127473},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {127473},
  shortjournal = {Expert Syst. Appl.},
  title        = {Audio-visual occlusion-robust gender recognition and age estimation approach based on multi-task cross-modal attention},
  volume       = {296},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An ILS-VND approach to dynamic pricing of perishable products. <em>ESWA</em>, <em>295</em>, 128949. (<a href='https://doi.org/10.1016/j.eswa.2025.128949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of setting prices of a perishable product whose demand decreases over time due to its perishable character and its price elasticity. It considers a discrete-time, deterministic model whose decision variables are the order quantity and the dynamic pricing policy (modelled as a series of discrete discounts in specific periods). Given the combinatorial structure of the problem and its non-linear nature, a hybrid Iterated Local Search (ILS) + Variable Neighborhood Descent (VND) metaheuristic approach is proposed. The initial solution for the search is computed using a heuristic which generally finds a good starting solution. The proposed approach is rather flexible and can accommodate many different scenarios. In particular, it has been validated on two scenarios: one involving a two-day horizon, with 1 h unit time and 12 h open/12 h closed cycle, and another one that considers a 48-day horizon, with 6 h unit time and 12/6 h open cycle. The results show that, in both cases, the proposed metaheuristic outperforms Simulated Annealing (SA), achieves a slight improvement over the heuristic, and reaches the optimal solution (verified through complete enumeration) while maintaining low computational costs. It has also been shown that profit increases of almost 20 %, compared to the no-discount policy.},
  archive      = {J_ESWA},
  author       = {Gabriel Villa and B. Adenso-Díaz and S. Lozano},
  doi          = {10.1016/j.eswa.2025.128949},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128949},
  shortjournal = {Expert Syst. Appl.},
  title        = {An ILS-VND approach to dynamic pricing of perishable products},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lightweight dongba character recognition: A novel and simple baseline. <em>ESWA</em>, <em>295</em>, 128944. (<a href='https://doi.org/10.1016/j.eswa.2025.128944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dongba ancient books are listed as “World Memory Heritage” by UNESCO, which reflects its important status and significant impact on the study of world languages. Due to the lack of artificial prior knowledge, identifying Dongba characters with machines has become an important task in the field of historical and cultural protection. Existing methods generally construct complex network structures with numerous parameters to continuously improve the model performance. However, the huge memory consumption makes these models unsuitable for deployment in practical application scenarios. To fill this gap, we propose a novel lightweight information guidance network (LIGNet) for Dongba character recognition, aiming to make a better trade-off between network capacity and recognition accuracy. First, we propose a novel Lightweight Inverted Residual (LIR) block and a novel Lightweight Hybrid Attention (LHAtt) module. They ensure that the network maintains a low capacity level. Second, since the reduction of network parameters leads to limited representational capacity, we further propose a novel Forward Information Guidance (FIG) unit. This independent unit forms an auxiliary branch of the network, which strengthens the information transfer process of character features within the whole network. Extensive experimental results show that our LIGNet can favorably outperform existing methods on public benchmark datasets. Our code and models will be made available at https://github.com/DrChen215/LIGNet.},
  archive      = {J_ESWA},
  author       = {Zheng Chen and Jianyu Yue and Xiaojun Bi},
  doi          = {10.1016/j.eswa.2025.128944},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128944},
  shortjournal = {Expert Syst. Appl.},
  title        = {Lightweight dongba character recognition: A novel and simple baseline},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fetal ultrasound four-chamber view editing synthesis via denoising diffusion model. <em>ESWA</em>, <em>295</em>, 128939. (<a href='https://doi.org/10.1016/j.eswa.2025.128939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound (US) imaging is an essential, cost-effective, and radiation-free technique for prenatal evaluations, especially in detecting congenital heart defects (CHDs). The precise acquisition of standardized four-chamber (FC) views is vital for accurate diagnosis but is often hindered by the operator’s expertise and the scarcity of high-quality training data. Current methodologies, including traditional affine transformations and generative adversarial networks, frequently fail to maintain structural fidelity and style consistency, thus limiting their clinical applicability. To overcome these limitations, we propose a novel approach employing denoising diffusion models for the editing synthesis of fetal US FC views, leading to high-quality outputs with improved sample diversity. Our proposed model decomposes the complex task into manageable forward and backward denoising steps, integrating external guidance from semantic and sketch maps facilitating targeted local edits while maintaining accurate textures and anatomical details. We further introduce a cross-attention style-consistent diffusion block, which enhances anatomical accuracy by modeling intricate relationships between original sub-views and their semantic and sketch features. Additionally, a decoupled classifier-free guidance mechanism isincorporated during sampling to optimize the alignment between input conditions and generated outputs. Our findings indicate substantial advancements in view fidelity and coherence, effectively addressing the shortcomings of existing models. This work contributes to early CHD diagnosis and bolsters clinical training resources, advancing the role of AI in medical imaging. Code is available at https://github.com/QiaoSiBo/FVEDM .},
  archive      = {J_ESWA},
  author       = {Sibo Qiao and Mengru Huang and Gang Luo and Wenjing Yin and Hengxiao Li and Min Wang and Zhihan Lyu},
  doi          = {10.1016/j.eswa.2025.128939},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128939},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fetal ultrasound four-chamber view editing synthesis via denoising diffusion model},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Satellite-inspired deep semantic mining for classifying contractual risk clauses. <em>ESWA</em>, <em>295</em>, 128933. (<a href='https://doi.org/10.1016/j.eswa.2025.128933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In construction engineering, automating the categorization of contractual risk clauses is essential to streamlining the risk assessment process and improving the effectiveness of project oversight work. Thus, this study was developed to integrate two advanced architectural frameworks, namely Bidirectional Encoder Representations from Transformers (BERT) and Bidirectional Gated Recurrent Unit (BiGRU), for text classification with a specific focus on classifying contractual risk clauses in construction specifications. BERT excels at capturing contextualized word embeddings, while BiGRU has demonstrated exceptional expertise in modeling sequential patterns. The fused model was proposed to enhance classification accuracy and overall performance by combining their respective strengths. Moreover, the Artificial Satellite Search Algorithm (ASSA) was fused with BERT and BiGRU to create the ASSA-BERT-BiGRU model. The ASSA is used in the model to fine-tune the hyperparameters to ensure optimal model performance. The effectiveness of the proposed model was subsequently assessed using performance metrics, including precision, recall, and F1 score. The results, including an F1 score of 0.9059, demonstrate that the proposed model classifies risk clause categories with exceptional proficiency and significantly better than several widely used machine learning models. Finally, this research contributes significantly to the domain of text classification within the construction engineering field, offering invaluable insights into risk analysis and project management automation.},
  archive      = {J_ESWA},
  author       = {Min-Yuan Cheng and Quoc-Tuan Vu and Husni Mubarok},
  doi          = {10.1016/j.eswa.2025.128933},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128933},
  shortjournal = {Expert Syst. Appl.},
  title        = {Satellite-inspired deep semantic mining for classifying contractual risk clauses},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive review on data-level methods for imbalanced data classification. <em>ESWA</em>, <em>295</em>, 128920. (<a href='https://doi.org/10.1016/j.eswa.2025.128920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the most important tasks in machine learning and data mining. Most of the classifiers are designed for data sets with equally distributed samples among the classes. Therefore, they encounter a problem with classifying imbalanced data in which one or more classes have much fewer samples than the others. Imbalanced data sets are prevalent in the real-world, so addressing this issue is of utmost importance. There have been many methods suggested to solve this problem showing promising results, a category of which is data-level methods being popular for their flexibility. In this paper, our goal is to review data-level methods comprehensively and categorize them from different perspectives. Also, to simplify doing future research in this field, most of the available benchmark imbalanced data sets, software, and toolboxes are introduced. Finally, existing challenges and future works are elaborated.},
  archive      = {J_ESWA},
  author       = {Bahareh Nikpour and Farshad Rahmati and Behzad Mirzaei and Hossein Nezamabadi-pour},
  doi          = {10.1016/j.eswa.2025.128920},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128920},
  shortjournal = {Expert Syst. Appl.},
  title        = {A comprehensive review on data-level methods for imbalanced data classification},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced goal direction and remodeling of population distributions multimodal multi-objective evolutionary algorithm. <em>ESWA</em>, <em>295</em>, 128913. (<a href='https://doi.org/10.1016/j.eswa.2025.128913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multimodal multi-objective optimization problems (MMOPs) have become a prominent research focus in the field of computational evolution, increasing the demands on the performance of multimodal multi-objective evolutionary algorithms (MMOEAs). To evaluate the merits of MMOEA, it is usually necessary to satisfy the following three key criteria: (1) good convergence, (2) the ability to find more equivalent Pareto solutions (PSs), and (3) a uniform population distribution in the decision space and objective space. However, most current algorithms fail to satisfy all the above criteria simultaneously when facing challenges such as search tasks of varying difficulty and uneven allocation of computational resources. To address these challenges, this paper proposes an enhanced goal direction and remodeling of population distributions multimodal multi-objective evolutionary algorithm (MMOEA-EGR). The algorithm dynamically selects evolutionary stages through reinforcement learning, flexibly guiding the population to evolve under the guidance of the objectives of each stage, thus promoting efficient collaboration among the stages in the whole optimization process. Meanwhile, the algorithm adopts a remodeling population distribution strategy to enhance the evolutionary efficiency while optimizing the diversity of the decision space. Experimental results show that MMOEA-EGR outperforms several mainstream multimodal multi-objective evolutionary algorithms on several MMOPs standard test sets.},
  archive      = {J_ESWA},
  author       = {Hangyu Liu and Shaobo Deng and Kexing Li and Hui Shi and Min Li},
  doi          = {10.1016/j.eswa.2025.128913},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128913},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced goal direction and remodeling of population distributions multimodal multi-objective evolutionary algorithm},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A real-time FPGA-based radiation noise suppression and detection method with comparative analysis against deep learning techniques. <em>ESWA</em>, <em>295</em>, 128906. (<a href='https://doi.org/10.1016/j.eswa.2025.128906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The safe operation of nuclear facilities and the demand for real-time radiation monitoring have continued to increase. Active Pixel Sensor based nuclear radiation imaging technology has attracted significant attention due to its low power consumption and high integration capability. However, in high-radiation environments, APS devices are susceptible to interference from high-energy particle impacts, generating random high-amplitude noise that severely degrades video quality and reduces dose rate measurement accuracy. To address this issue, this paper proposes a real-time radiation noise suppression and dose detection method that combines time-domain minimum-value substitution with spatial median filtering with two-dimensional wavelet decomposition, implemented on a parallel FPGA architecture. The proposed method fully exploits the multi-stage pipelining and parallel processing capabilities of FPGAs to efficiently suppress radiation-induced noise in APS image streams and extract residual dose information at multiple scales. Experiments conducted using a 60 Co gamma-ray source on both a video test chart and a real-world scenario demonstrate that the method improves the peak signal-to-noise ratio by an average of approximately 11 dB after denoising, significantly outperforming Gaussian and low-pass filtering, and achieving comparable results to deep learning approaches such as DnCNN and Vision Transformer. Moreover, the hardware implementation does not require power-hungry GPUs, ensuring real-time performance for embedded applications. Further wavelet decomposition and pixel value fitting analyses confirm excellent linear correlation for dose rate estimation, with the Daubechies wavelet diagonal component achieving an R 2 as high as 0.99624. Overall, the proposed approach offers a low-power, high-efficiency engineering solution for real-time APS video denoising and dose detection in nuclear environments, providing a solid technical foundation for building FPGA-based intelligent nuclear radiation monitoring expert systems.},
  archive      = {J_ESWA},
  author       = {Shoulong Xu and Zhixiong Hou and Cuiyue Wei and Youjun Huang and Shuliang Zou and Pengfei Li and Qingyang Wei},
  doi          = {10.1016/j.eswa.2025.128906},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128906},
  shortjournal = {Expert Syst. Appl.},
  title        = {A real-time FPGA-based radiation noise suppression and detection method with comparative analysis against deep learning techniques},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable feature modeling for robust color watermarking in the quaternion framework. <em>ESWA</em>, <em>295</em>, 128901. (<a href='https://doi.org/10.1016/j.eswa.2025.128901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper systematically investigates the application of four quaternion matrix decompositions in blind color image watermarking. Two new forms of quaternion Givens transformation are proposed to overcome the difficulty of constructing numerical features in matrix decomposition for carrying watermarks, while further improving the efficiency and accuracy of computation. Next, four quaternion matrix decomposition algorithms are proposed based on quaternion Givens transformation, and their numerical features are specifically analyzed and matched with suitable watermarking mechanisms. As a result, four robust watermarking algorithms are proposed, while real structure-preserving arithmetic architectures are introduced to improve algorithm efficiency. Additionally, an image correction method is proposed to align the screenshot with the watermarked image geometrically, enhancing watermark extraction. Experimental outcomes reveal that, in comparison with other algorithms, the quaternion representation has a better reconstruction ability, the two new forms of the quaternion Givens transformation are also better in terms of efficiency and accuracy as well, and the four proposed color image watermarking algorithms show more satisfactory invisibility and robustness.},
  archive      = {J_ESWA},
  author       = {Yong Chen and Zhigang Jia and Hao Peng and Yaxin Peng and Yan Peng},
  doi          = {10.1016/j.eswa.2025.128901},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128901},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable feature modeling for robust color watermarking in the quaternion framework},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning and fusing the rasterized and serialized point cloud for 3D semantic segmentation in railway scenes. <em>ESWA</em>, <em>295</em>, 128897. (<a href='https://doi.org/10.1016/j.eswa.2025.128897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR are pivotal for environmental perception in autonomous train operations, particularly in forward-facing obstacle detection. However, existing LiDAR-based point cloud semantic segmentation (PCSS) methodologies are predominantly designed for highway and urban road scenes, with limited exploration in railway scenes. To address challenges associated with sparse and dynamically varying of long-distance point clouds in PCSS of railway scene, we propose the rasterized and serialized point cloud learning and fusion Network (RSP-Net). The RSP-Net employs an encoder-decoder architecture, initially processing point clouds via voxel-based rasterization and Z-order curve serialization techniques. These processed data are then fed into an encoder comprising multiple multi-view point cloud learning and fusion modules (MPM) alongside downsampling module for feature extraction. Each MPM incorporates three components: (1) a bidirectional recurrent attention block for serialized point cloud feature extraction, (2) a sparse spatial feature extraction block for rasterized data processing, and (3) a multi-view feature fusion block that fuses outputs from the preceding modules. High-level semantic features extracted by the encoder are subsequently reconstructed through a decoder containing feature reconstruction and upsampling modules to generate PCSS results. To validate the proposed method, we constructed a LiDAR PCSS database for railway scene, named RailPoints. This database contains 300 annotated frames of railway point clouds, comprising over 3 million individual points across 30 km of track. Experimental evaluations on RailPoints demonstrate that our method significantly outperforms state-of-the-art methods in railway scene PCSS tasks. Furthermore, benchmark testing on nuScenes and SemanticKITTI datasets confirms strong generalization capabilities across road scene PCSS tasks. The RailPoints database and code are available at https://github.com/completezealous/RailPoints.git .},
  archive      = {J_ESWA},
  author       = {Ning Sun and Kai Li and Jixin Liu and Lei Chai and Cong Wu},
  doi          = {10.1016/j.eswa.2025.128897},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128897},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning and fusing the rasterized and serialized point cloud for 3D semantic segmentation in railway scenes},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model predictive control of port-city scenarios based on traffic simulation and efficient sampling design. <em>ESWA</em>, <em>295</em>, 128894. (<a href='https://doi.org/10.1016/j.eswa.2025.128894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint occupation of urban road infrastructures by logistic flows and general mobility traffic, typical of contexts in which a port is located within a city, is a known source of unwanted externalities such as congestion and pollution. In this paper we propose a model-predictive control scheme aimed at maximizing the throughput of vehicles into the zone where the two kinds of traffic interact, thus mitigating the impact of negative phenomena, as well as increasing the overall economic benefit of the port-city system. In order to provide the detailed representation of the network dynamics required by the predictive controller, we define a model supported by micro-simulation of the port-city area. Then, since the direct application of micro-simulation is not feasibile in real-time, we resort to a surrogate data-driven approximation to be used by the controller. To this purpose, we define a principled sampling design scheme aimed at yielding a suitable training set for the surrogate model, and provide a theoretical analysis on the conditions to guarantee an efficient covering of the relevant sets. A simulation case study involving the port-city context of Genova in north-west Italy is presented, in order to showcase the advantages of the proposed sampling scheme and the performance of the model-predictive controller as well.},
  archive      = {J_ESWA},
  author       = {Cristiano Cervellera and Danilo Macciò},
  doi          = {10.1016/j.eswa.2025.128894},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128894},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model predictive control of port-city scenarios based on traffic simulation and efficient sampling design},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Frequency domain complex-valued convolutional neural network. <em>ESWA</em>, <em>295</em>, 128893. (<a href='https://doi.org/10.1016/j.eswa.2025.128893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex-valued convolutional neural networks have demonstrated promising results in reducing space, time, and computational complexity compared to real-valued models, particularly in signal and image processing. Despite their strong representational capacity and theoretical benefits, complex-valued CNNs remain limited due to theabsence of simplified theoretical and practical formulations for fully complex-valued building blocks. Existing studies often depend on fast Fourier transforms (FFT/IFFT) for domain transitions between layers due to the lack of well-established complex-valued activation functions or filter parameters initialization. Additionally, many earlier works adapt complex versions of the real-valued activation functions in a split-type manner, which might distort phase information and weaken generalization. To overcome these challenges, we propose a lightweight fully complex-valued residual CNN that operates entirely on complex data in the frequency domain. Our design simplifies fully complex building blocks and introduces a Log-Magnitude activation function that preserves phase information, outperforming traditional complex ReLU variants and the Cardioid activation function. Experimental validation across diverse multi-modal datasets, including MNIST, SVHN, MIT-BIH Arrhythmia, PTB Diagnostic ECG, DIAT- μ RadHAR , and DIAT- μ SAT , demonstrates the superior performance of our fully complex-valued CNNs over real-valued models.},
  archive      = {J_ESWA},
  author       = {Mainak Chakraborty and Masood Aryapoor and Masoud Daneshtalab},
  doi          = {10.1016/j.eswa.2025.128893},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128893},
  shortjournal = {Expert Syst. Appl.},
  title        = {Frequency domain complex-valued convolutional neural network},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Environmental sustainability and mobility impacts of connected and autonomous vehicles at urban highways. <em>ESWA</em>, <em>295</em>, 128892. (<a href='https://doi.org/10.1016/j.eswa.2025.128892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalation issue of traffic congestion caused by growing travel demand and nearly stagnant infrastructure supply profoundly influenced transportation system performances. The emerging Connected and Autonomous Vehicles (CAVs) provide transformative solutions to mitigate fuel consumption, Greenhouse Gas (GHG) and pollutant emissions. To foster a deeper understanding of how CAVs can improve freeway mobility and sustainability, this research employs calibrated car-following models to assess the environmental and mobility impacts of CAVs at varying Market Penetration Rates (MPRs). The traffic simulation incorporates a metaheuristic algorithm to calibrate the parameters for Human Driven Vehicles (HDVs). Evaluations are conducted in a mixed traffic environment through various scenarios. Results indicate that increasing MPRs of CAVs reduces fuel consumption of mixed traffic flow. The CO 2 emissions can be reduced by up to 8.2% for HDVs and 13.8% for CAVs. Simultaneously, an overall improvement in average travel time (9.9%), time loss (55.78%), and average speed (11%) can be reached respectively. This study further demonstrates the nuanced impacts of the development and deployment stages of CAVs on sustainability and mobility under different automation levels. Sensitivity analysis under different operating speeds highlights the significant effect of MPRs on average speed, while different gas emissions exhibit various changes in pattern. This investigation provides valuable insights for traffic engineers and decision-makers, enhancing a more thorough comprehension of the transformative potential of CAV technology in promoting environmentally friendly and sustainable transportation.},
  archive      = {J_ESWA},
  author       = {Chengying Hua and Wei (David) Fan and Wei Hua and Shuichao Zhang},
  doi          = {10.1016/j.eswa.2025.128892},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128892},
  shortjournal = {Expert Syst. Appl.},
  title        = {Environmental sustainability and mobility impacts of connected and autonomous vehicles at urban highways},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiplex graph prompt collaboration for open-set social event detection. <em>ESWA</em>, <em>295</em>, 128887. (<a href='https://doi.org/10.1016/j.eswa.2025.128887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social event detection (SED) aims to detect event types from social media messages that reflect group behavior and public concerns. Owing to the dynamic evolution nature of social media, newly occurred messages may belong to unseen event types. Recently emerged open-set SED methods introduce graph neural networks (GNN) for feature encoding and iteratively retrain model parameters via the learned pseudo-labels to adapt to new, unknown events. However, retraining the entire model with these noisy pseudo-labels inevitably causes overfitting and risk erasing information learned from known events. In this paper, we propose a novel framework to tackle the open-set SED problem by leveraging the advantages of graph prompt learning (GPL) in its fast adaptation to new data with minimal parameter modifications, termed M ultiplex G raph P rompt C ollaboration (MGPC for short). Specifically, MGPC introduces three types of graph prompts to adapt a pre-trained GNN model from old to new message graphs quickly without extensive retraining. To address the distribution shifts issue in node content, graph structures, and temporal context as new data emerges, we introduce a graph adaptation prompt and a temporal prompt, which manage information flow from old to new graphs under evolving temporal context. We further introduce a prototypical-based supervised training loss with a lightweight event embedding prompt, which facilitates quick adaptation to new event class distributions while retaining previously learned information with minimal parameter changes. These adopted prompts are fine-tuned using pseudo-labels generated according to the entropy-based uncertainty scores concerning the known classes, supplemented by an unsupervised contrastive learning component to improve inter-class discrimination for unknown events. Extensive experiments on real-world benchmarks demonstrate the effectiveness of the proposed MGPC framework in comparison to existing SED methods.},
  archive      = {J_ESWA},
  author       = {Xiuqin Liang and Jiazhen Chen and Sichao Fu and Wuli Wang and Mingbin Feng and Tony S. Wirjanto and Qinmu Peng and Baodi Liu and Weihua Ou},
  doi          = {10.1016/j.eswa.2025.128887},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128887},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multiplex graph prompt collaboration for open-set social event detection},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Susceptible-infected diffusion of food safety opinion dissemination: Infrastructure-driven spread and behavior-embedded substance. <em>ESWA</em>, <em>295</em>, 128886. (<a href='https://doi.org/10.1016/j.eswa.2025.128886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how food safety information disseminates across three structurally distinct Chinese social media platforms, Weibo, TikTok, and Xiaohongshu (XHS), during crisis events. Rather than serving as neutral transmission channels, these platforms are conceptualized as dynamic Information Service Systems (ISS), in which algorithmic infrastructures and content substances co-produce public meaning, emotional salience, and trust dynamics. Drawing on the Substance–Infrastructure (S-I) model, specifically Type II logic, where infrastructure drives substance, we theorize that technical mechanisms such as feed algorithms, trending systems, and visibility logics interact with semantic features like emotional tone, media modality, and narrative framing to shape the velocity, reach, and epistemic reliability of crisis communication. Employing a mixed-methods design that combines temporal Exponential Random Graph Models (ERGM), Susceptible-Infected (SI) diffusion simulations, and BERT-based sentiment analysis, we identify how different network structures, decentralized, centralized, and hybrid, interact with conformity, homophily, and neophilia to produce platform-specific information ecologies. TikTok’s architecture enables high-speed virality with minimal deliberative anchoring, limiting the platform’s ability to support trust repair; XHS facilitates high-affinity trust ecosystems led by key opinion leaders, but is vulnerable to echo chambers and insular misinformation; Weibo, with its hybrid infrastructure, supports rapid escalation and multi-directional discourse, but suffers from volatility in trust due to inconsistent epistemic control. These distinct affordances explain the asymmetric amplification of food safety narratives and the divergent trajectories of public trust, consolidation, polarization, or collapse, across platforms. As a contribution, the study introduces the Integrated Design and Operation Management (IDOM) framework, which positions platforms as reflexive control systems that must adapt to real-time signals of uncertainty and trust decay. It further underscores the need for resilient public governance that aligns institutional interventions with platform-specific logics and user cognitive baselines, advocating for a coordinated socio-technical ecosystem capable of sustaining trustworthy, inclusive, and responsive food safety communication in the digital era.},
  archive      = {J_ESWA},
  author       = {Xinyue Hao and Dapeng Dong and Chang Liu and Emrah Demir and Samuel Fosso Wamba},
  doi          = {10.1016/j.eswa.2025.128886},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128886},
  shortjournal = {Expert Syst. Appl.},
  title        = {Susceptible-infected diffusion of food safety opinion dissemination: Infrastructure-driven spread and behavior-embedded substance},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards screening of children students with autism spectrum disorder based on executive functions with serious game and machine learning approaches. <em>ESWA</em>, <em>295</em>, 128884. (<a href='https://doi.org/10.1016/j.eswa.2025.128884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educators face challenges in accommodating children with Autism Spectrum Disorder (ASD), particularly those without a definitive clinical diagnosis. Full-day schools provide a convenient setting to implement ASD screening techniques. Children diagnosed with ASD can receive customized interventions, allowing educators to customize teaching to individual needs and promote inclusive education. However, screening methods must seamlessly integrate into the educational environment, ensuring they are noninvasive and engaging. This study proposes a Serious Game (SG) tablet application that combines user requirements for inclusive design with Machine Learning (ML) techniques for screening analysis, offering a playful tool for ASD screening. This tablet application includes three classical games designed to analyze executive functions (EF) in children. We recruited three inclusive education teachers to supervise 12 children aged between 3 and 6 years old, including 6 with ASD and 6 typically developing children. The teachers also facilitated the children’s use of our tablet application. Over three months, children completed 640 game matches, and preprocessing these matches resulted in a comprehensive dataset. We compared seven well-known and commonly used ML approaches: Random Forest (RF), Multilayer Perceptron (MLP), K-Nearest Neighbor (KNN), Logistic Regression (LR), Deep Learning (DL), Support Vector Machine (SVM), and Naive Bayes (NB). According to our results, the RF model performed best with an accuracy of 96 %. Our study sheds light on the integration of playful approaches based on SG and ML techniques in educational environments, laying the groundwork for future research and practical applications to screen for suspected ASD among children in school settings.},
  archive      = {J_ESWA},
  author       = {Sara Raquel Araujo Leal Martins and Franciely Alves de Souza and Lucas Candeia Teixeira and Bruna Roberta Araujo Leal and Diego Marconi Pinheiro Ferreira Silva and Carlo Marcelo Revoredo da Silva},
  doi          = {10.1016/j.eswa.2025.128884},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128884},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards screening of children students with autism spectrum disorder based on executive functions with serious game and machine learning approaches},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust fuzzy cluster validity index based on local distances. <em>ESWA</em>, <em>295</em>, 128883. (<a href='https://doi.org/10.1016/j.eswa.2025.128883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is difficult to appropriately determine the cluster number in the absence of a priori knowledge. For diverse application contexts, a number of fuzzy cluster validity indices (CVIs) have been developed. They might function admirably in certain circumstances but poorly in others. In reality, clusters could have peculiar shapes and varying sizes/densities that aren’t known beforehand. It is meaningful to develop a reliable fuzzy CVI that can perform well in various conditions without being specifically designed for a particular set of circumstances. Using the knowledge of neighborhood distances as inspiration, a new membership degree model was developed. Instead of modeling the distance to each cluster center, the new membership degree model focuses on the distance of the observation to the closest point in each group. The novel method is more resistant to data sets with strange shapes, varied sizes (densities), and outliers than the conventional membership degree model. Thus, the gap between clusters and the compactness inside the cluster are modified. As a result, the RFCV fuzzy CVI was proposed. In comparison to the standard CVIs, extensive simulation tests demonstrate that the proposed RFCV is effective in a wide range of scenarios, including clusters with irregular geometries and varying densities.},
  archive      = {J_ESWA},
  author       = {Bin Yan and Zheng Xie},
  doi          = {10.1016/j.eswa.2025.128883},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128883},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust fuzzy cluster validity index based on local distances},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A genetic programming hyper-heuristic with whale optimization algorithm for the dynamic resource-constrained multi-project scheduling problems. <em>ESWA</em>, <em>295</em>, 128881. (<a href='https://doi.org/10.1016/j.eswa.2025.128881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-constrained multi-project scheduling problem (RCMPSP) often treats resource transfer time as a fixed parameter, neglecting its real-world variability. However, in high-end electronic equipment assembly and testing, resource transfer time is dynamically influenced by factors such as kit completion rates. This paper studies a dynamic RCMPSP with adjustable resource transfer times based on kit completion rates (DRCMPSP-RT&MK). While traditional genetic programming hyper-heuristic (GPHH) algorithms struggle with large-scale problems, we propose an enhanced algorithm, GPHH-WOA, which integrates the whale optimization algorithm (WOA) into GPHH and incorporates dynamic task and resource-transfer attributes into its rule-optimization process. To validate the algorithm’s effectiveness, we first compare the proposed method against six heuristic task-priority rules with static attributes. Second, we benchmark it against two existing GPHH variants and their surrogate-assisted versions. Experiments on three self-generated datasets of varying scales demonstrate that the proposed method significantly improves solution quality, with greater advantages as problem complexity increases. The results confirm the algorithm’s feasibility and effectiveness for large-scale DRCMPSP-RT&MK in dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yutong Chao and Cunbo Zhuang and Haoxin Guo and Jianhua Liu},
  doi          = {10.1016/j.eswa.2025.128881},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128881},
  shortjournal = {Expert Syst. Appl.},
  title        = {A genetic programming hyper-heuristic with whale optimization algorithm for the dynamic resource-constrained multi-project scheduling problems},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Software operating system supplier encroachment strategy considering compatibility differences in the smart connected products supply chain. <em>ESWA</em>, <em>295</em>, 128880. (<a href='https://doi.org/10.1016/j.eswa.2025.128880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preference for products with smartness and connectivity is becoming increasingly prevalent among consumersand businesses, which are called smart connected products (SCP). We focus on compatibility arising from the connection of products and conduct a study based on two software operating system (OS) suppliers who provide different compatible OS for manufacturer. In this study, we portray multiple types of consumers and differentiateproducts, and examine the baseline model without encroachment(model N), singularity supplier encroachment model S, and non-singularity supplier encroachment model E. Through analysis, we obtain the following significant conclusions. Firstly, non-singularity supplier exhibits stronger willingness to engage in strategic collaboration with manufacturer when entering on competitive markets, capturing multihoming consumers even at reduced price thresholds compared to singularity supplier. In addition, suppliers in model E compete more aggressively in the multihoming consumer market than in model S. Secondly, supplier encroachment with a large loyalty premium leads to a win-win situation and Pareto optimality. On the contrary, supplier encroachment can always hurt the profits of competing suppliers with a small loyalty premium. Thirdly, a smaller cost-value ratio is required for supplier encroachment, but if the proportion of compatible loyalists is smaller than that of preferred loyalists, a smaller loyalty premium is sufficient to compensate for the cost disadvantage. Finally, we conduct extensions to further verify the robustness of the conclusions.},
  archive      = {J_ESWA},
  author       = {Kai Li and Aowen Ma and Nenggui Zhao and Tao Zhou},
  doi          = {10.1016/j.eswa.2025.128880},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128880},
  shortjournal = {Expert Syst. Appl.},
  title        = {Software operating system supplier encroachment strategy considering compatibility differences in the smart connected products supply chain},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy mean-variance-skewness portfolio model driven by dynamic risk and return. <em>ESWA</em>, <em>295</em>, 128879. (<a href='https://doi.org/10.1016/j.eswa.2025.128879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the selection of a multi-objective investment portfolio under uncertainty, capturing investors’ varying risk attitudes (optimism, pessimism, indifference) using fuzzy numbers. We propose three multi-period fuzzy portfolio models based on a fuzzy mean-variance-skewness (MVS) framework, with trapezoidal fuzzy numbers representing uncertain returns. These dynamic models adjust constraints and objectives based on prior periods’ outcomes, reflecting evolving risk-return preferences. A hybrid algorithm combining fuzzy logic and Genetic Algorithm (GA) optimizes the models, handling multi-objective fuzzy uncertainty effectively. Skewness is incorporated to refine return distributions, aligning with investor preferences. Empirical analysis using the China Securities 300 Index shows the fuzzy MVS model outperforms traditional models, especially in asymmetric markets. Out-of-sample testing with the FTSE 100 Index confirms skewness’s value in non-normal markets. This study offers insights for diverse investors and advances behavioral portfolio selection under uncertainty.},
  archive      = {J_ESWA},
  author       = {Yu Zhou and Chun Yan and Xiangrong Wang},
  doi          = {10.1016/j.eswa.2025.128879},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128879},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fuzzy mean-variance-skewness portfolio model driven by dynamic risk and return},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hermite-inspired deterministic augmentation of autoregressive–moving-average and generalized autoregressive conditional heteroskedasticity models for enhanced signal generation in volatile financial markets. <em>ESWA</em>, <em>295</em>, 128877. (<a href='https://doi.org/10.1016/j.eswa.2025.128877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the persistent challenge of modeling directional signal structure under volatile and non-Gaussian market conditions, contexts in which classical autoregressive–moving-average and generalized autoregressive conditional heteroskedasticity (ARMA-GARCH) frameworks often struggle to adapt. In response, we propose a Hermite-inspired deterministic augmentation to the volatility equation of GARCH-type models and evaluate its signal structure relative to a heavy-tailed benchmark. Specifically, we introduce a Non-Linear Polynomial Function (NLPF), defined with a Hurst-like exponent and polynomial scaling terms, and then embed it within a continually optimized ARMA-GARCH architecture that recalibrates model parameters over a rolling window using only historical information, enabling structural adaptation to evolving market conditions. To isolate the informational value of the NLPF, we construct two dynamic systems: (i) System 1, which incorporates the NLPF into an ARMA-GARCH model with normally distributed innovations, and (ii) System 2, a conventional ARMA-GARCH model with residuals drawn from a skewed generalized error distribution (SGED). Both systems are evaluated using contemporaneous signal-return alignment to assess the internal coherence and directional informativeness of each model’s output. Empirical tests across six structurally diverse assets, including cryptocurrencies, commodities, emerging-market currencies, and high-volatility equities, demonstrate that the NLPF-enhanced model consistently produces superior directional alignment and more stable cumulative return trajectories relative to System 2 and a buy-and-hold baseline. These findings underscore the value of structurally grounded volatility augmentation using deterministic Hermite-inspired functions.},
  archive      = {J_ESWA},
  author       = {Cristiana Tudor and Robert Sova},
  doi          = {10.1016/j.eswa.2025.128877},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128877},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hermite-inspired deterministic augmentation of autoregressive–moving-average and generalized autoregressive conditional heteroskedasticity models for enhanced signal generation in volatile financial markets},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Manufacturer vs. KOL: A comparative study of decision-making in live streaming e-commerce with consumers’ anticipated regret. <em>ESWA</em>, <em>295</em>, 128875. (<a href='https://doi.org/10.1016/j.eswa.2025.128875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of live streaming e-commerce, traditional retail is being gradually replaced by more interactive and real-time selling channels, that offer attractive pricing and have become a key strategy for manufacturer. However, the impact of consumers’ anticipated regret on decision-making within live streaming e-commerce remains insufficiently explored. This study introduces a novel analytical framework based on anticipated regret theory to analyze its effects on the live streaming supply chain. Demand functions for both retail and live streaming products are derived, and a game-theoretic framework incorporating both centralized and decentralized decision-making structures is developed, aiming to analyze the Manufacturer Self-operated (MSO) and Key Opinion Leader (KOL) live streaming models. To validate the proposed models, both theoretical analysis and numerical simulations are conducted to explore the effects of anticipated regret on key operational variables, including pricing strategies, market demand, and firm profitability. Furthermore, a revenue-sharing contract is proposed that optimizes the performance of live streaming e-commerce supply chains by offering managerial insights into pricing strategies, live streaming tactics, and revenue allocation mechanisms, thereby contributing to the sustainable development of live streaming e-commerce. The results reveal three findings: (1) Consumers’ anticipated regret leads to reductions in retail, wholesale, and live prices. (2) Both live streaming service quality and KOL characteristic exhibits threshold effects on pricing and demand. (3) A properly designed revenue-sharing contract improves supply chain coordination and increases profit for both the manufacturer and retailer.},
  archive      = {J_ESWA},
  author       = {Nian Zhang and Zheyu He and Jinyu Wu},
  doi          = {10.1016/j.eswa.2025.128875},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128875},
  shortjournal = {Expert Syst. Appl.},
  title        = {Manufacturer vs. KOL: A comparative study of decision-making in live streaming e-commerce with consumers’ anticipated regret},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive length-variation based evolutionary multitasking algorithm for feature selection of high-dimensional classification. <em>ESWA</em>, <em>295</em>, 128874. (<a href='https://doi.org/10.1016/j.eswa.2025.128874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) has recently gained attention as a promising and efficient paradigm for feature selection (FS) in high-dimensional classification problems. However, most existing EMT-based FS approaches rely on fixed-length coding schemes, which force the algorithm to search within the large original feature space. This often leads to increased computational complexity and reduced search efficiency. To overcome these limitations, this paper proposes a novel EMT-based algorithm with an adaptive length variation mechanism, called EMT-ALV. The proposed method introduces a competitive swarm optimizer (CSO) framework tailored for multitasking FS. Specifically, a multitasking construction strategy based on relevance and adaptive threshold is first used to dynamically generate two complementary subtasks: one focusing on a promising feature pool and the other on a global feature pool. The CSO framework enables effective knowledge transfer between these subtasks, improving the overall selection process. Furthermore, an adaptive length variation mechanism is incorporated into the evolutionary process, consisting of two key components: (1) a Gaussian distribution-based variable-length initialization scheme, which enhances the diversity and quality of the initial population; and (2) an adaptive length variation scheme that refines the particle lengths throughout evolution, promoting faster convergence and improved search performance. Extensive experiments conducted on 14 high-dimensional datasets demonstrate that EMT-ALV consistently outperforms several state-of-the-art FS algorithms, achieving better classification accuracy with relatively reduced computation time.},
  archive      = {J_ESWA},
  author       = {Lingjie Li and Yuze Zhang and Zhijiao Xiao and Qiuzhen Lin and Xin Wang and Xiuqiang He and Ming Zhong},
  doi          = {10.1016/j.eswa.2025.128874},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128874},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive length-variation based evolutionary multitasking algorithm for feature selection of high-dimensional classification},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-embedded graph representation learning for document-level relation extraction. <em>ESWA</em>, <em>295</em>, 128872. (<a href='https://doi.org/10.1016/j.eswa.2025.128872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to identify the relations between entities in a document, which serves as a fundamental task in natural language processing. In DocRE, there inherently exists strong prior knowledge, for example, individuals and organizations tend to exhibit a “membership” relation rather than a “separation” relation. Leveraging this knowledge can effectively confine the model’s prediction space and highlight potential relations between entities. However, existing DocRE works primarily focus on designing sophisticated models to implicitly encode document features, inadvertently neglecting this informative prior knowledge, which might lead to suboptimal performance. In this work, we assume that the prior knowledge can be effectively represented by statistical co-occurrence correlations between entity types and relations. Based on this premise, we propose a novel algorithm called Knowledge-Embedded Graph Representation Learning (KEGRL), which enhances the representation of entity features through this statistical prior knowledge. Specifically, we calculate the statistical co-occurrence correlations existing between entity types and relations. These correlations are then ingeniously encapsulated within weighted edge-oriented heterogeneous graphs, where nodes correspond to entities and relations. Every entity node is connected to all relation nodes, and their edges symbolize the statistical correlations between entities and relations. Across these graphs, the entity features propagate under the guidance of statistical correlations, during which the statistical knowledge is injected into the entity features to enhance their distinctiveness. Extensive experiments on multiple baseline models and datasets consistently demonstrate that integrating KEGRL significantly enhances the performance of DocRE models. The code is available at https://github.com/MrDreamQ/KEGRL .},
  archive      = {J_ESWA},
  author       = {Jinglin Liang and Yutao Qin and Shuangping Huang and Yunqing Hu and Xinwu Liu and Huiyuan Zhang and Tianshui Chen},
  doi          = {10.1016/j.eswa.2025.128872},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128872},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge-embedded graph representation learning for document-level relation extraction},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mining neural connectivity via spatiotemporal features of neural calcium activity data. <em>ESWA</em>, <em>295</em>, 128871. (<a href='https://doi.org/10.1016/j.eswa.2025.128871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing the mesoscopic brain connectome is key to understanding the principles of biological neural connectivity, thereby shedding light on how brain functions emerge. However, biological brains typically contain hundreds of millions of neurons and synapses, making large-scale reconstruction difficult using traditional techniques such as tracer labeling and microscopic imaging. So far, only a few model organisms with simple nervous systems, such as C. elegans and zebrafish, have had their connectome reconstructed. Here, we propose a novel method that combines graph neural networks (GNN) with long short-term memory (LSTM) networks to mine spatiotemporal features from neural calcium activity data. The features uniquely characterize neurons and synapses, enabling the prediction of neural connectivity. To validate the effectiveness of the method, we performed multiple whole-brain calcium imaging experiments on C. elegans and collected a large number of calcium activity data to create several datasets. Experiments on these datasets show that the method can reliably predict the connections of local neural circuits in C. elegans , achieving an average accuracy of approximately 0.75, outperforming existing methods. It is anticipated to offer a simpler and data-driven approach for reconstructing connectome in more complex nervous systems.},
  archive      = {J_ESWA},
  author       = {Ye Yuan and Yuheng Du and Wentao Wen and Kuankuan Xin and Hongjiang Liu and Amin Zhang and Shiyan Yang and Zhaoyu Li and Tao Fang and Jian Liu},
  doi          = {10.1016/j.eswa.2025.128871},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128871},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mining neural connectivity via spatiotemporal features of neural calcium activity data},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Objective black-litterman views through deep learning: A novel hybrid model for enhanced portfolio returns. <em>ESWA</em>, <em>295</em>, 128868. (<a href='https://doi.org/10.1016/j.eswa.2025.128868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Black-Litterman Model is a sophisticated approach to portfolio optimization that integrates investor views with market data. However, the model’s effectiveness is highly dependent on the quality of its inputs and is often challenged by subjective or biased views. Recent advancements in deep learning have enabled the generation of more objective, data-driven views, significantly enhancing the model’s accuracy and reliability. In this study, we propose a novel CGL-BL Model, which employs a hybrid deep learning approach—CEEMDAN-GLSTM-LSTM (CGL)—to generate investor views. The CGL model leverages the CEEMDAN algorithm for return-based time series decomposition, a Genetic Algorithm-optimized LSTM network to enhance prediction accuracy, and an additional LSTM network for nonlinear aggregation of prediction results. The proposed CGL-BL model was evaluated on both the SSE 50 Index in China and the DJIA in the United States. Empirical results show that the proposed CGL-BL model outperforms all benchmark portfolios in terms of excess return, Sharpe ratio, and maximum drawdown when applied with a short-term rebalancing strategy on the SSE 50 Index and a medium-to-long-term strategy on the DJIA, demonstrating strong potential for practical application in financial markets.},
  archive      = {J_ESWA},
  author       = {Xianran Su and Ke Lu and Jerome Yen},
  doi          = {10.1016/j.eswa.2025.128868},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128868},
  shortjournal = {Expert Syst. Appl.},
  title        = {Objective black-litterman views through deep learning: A novel hybrid model for enhanced portfolio returns},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing market-making strategies: A multi-objective reinforcement learning approach with pareto fronts. <em>ESWA</em>, <em>295</em>, 128867. (<a href='https://doi.org/10.1016/j.eswa.2025.128867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial markets are complex ecosystems with multiple participants where market makers (MM) play a crucial role in providing liquidity. They improve market efficiency and stability while reducing price volatility. In this operation, MMs strike a balance between maximizing profitability and minimizing inventory levels. This paper first formulates the market-making problem as a pure multi-objective reinforcement learning task and then introduces M 3 ORL (Market-Maker based on Multi-Objective RL), an approach that handles competing objectives independently rather than combining them into a single reward function. Traditionally, multi-objective problems like this one have been approached with reinforcement learning (RL) as a single-objective framework by combining both goals into a parameterized function. M 3 O R L is a pure multi-objective MM agent based on deep RL to simultaneously optimize both objectives independently. In the proposed solution, the MM agent vectorizes both sub-goals instead of aggregating them, utilizing two different pairs of neural networks: one pair for inventory management and another pair for profitability. The utilization of a multi-objective MM instead of a single objective allows for visualizing the Pareto front and analyzing the trade-offs between objectives. This approach offers advantages over traditional reward engineering-based methods, which are discussed in detail. We compare our approach to classic alternatives based on reward engineering and demonstrate its effectiveness in balancing profitability and inventory control. Additionally, we evaluate our method using well-known multi-objective metrics such as hypervolume, the sparsity of solutions, and the number of undominated solutions, showcasing its superior performance when compared to the rest of reward engineering techniques. Moreover, we demonstrate that this approach is promising in addressing diverse financial challenges beyond market-making. The ability to simultaneously optimize multiple objectives using RL and Pareto fronts opens up new possibilities for tackling complex problems in the financial domain.},
  archive      = {J_ESWA},
  author       = {Óscar Fernández Vicente and Javier García and Fernando Fernández},
  doi          = {10.1016/j.eswa.2025.128867},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128867},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing market-making strategies: A multi-objective reinforcement learning approach with pareto fronts},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Non-uniform spiking touch sensor for classification of movement patterns using neural networks. <em>ESWA</em>, <em>295</em>, 128866. (<a href='https://doi.org/10.1016/j.eswa.2025.128866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we show that machine intelligence is capable of performing the classification of a continuous movement pattern over a touch sensor surface. We propose a new capacitive touch sensor design with a dielectric with non-uniform electrical permittivity. A sensor of that kind, connected to a signal conditioning circuit, generates a spiking signal that encodes spatial information. The sensor behaves similarly to a slowly-adapting type I (SA-I) first-order tactile neuron that provides tactile information to a human neural system. The significance of our research is that, unlike other approaches, we do not use a sensor array, just a single sensor that encodes the movement patterns into a time series. We demonstrate how to select the artificial neural network (ANN) architecture, prepare a training dataset and train the network to achieve over 97 % accuracy in recognising the movement patterns related to the writing of Arabic numerals. The development of the touch sensor working with an ANN described in this work might find potential applications with future human machine interaction (HMI) interfaces.},
  archive      = {J_ESWA},
  author       = {Michał Markiewicz and Szymon Janusz and Ireneusz Brzozowski},
  doi          = {10.1016/j.eswa.2025.128866},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128866},
  shortjournal = {Expert Syst. Appl.},
  title        = {Non-uniform spiking touch sensor for classification of movement patterns using neural networks},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing the neutrosophic fuzzy-AHP based soil quality index for sugar beet: A comparative study of multi-class logistic regression, random forest, and one-against-all support vector machine models. <em>ESWA</em>, <em>295</em>, 128862. (<a href='https://doi.org/10.1016/j.eswa.2025.128862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen a marked increase in the number of studies being conducted on the quality of agricultural soil. This is attributable to three key factors. Firstly, there is growing recognition of the importance of sustainable agriculture. Secondly, there is a decreasing availability of agricultural lands due to urbanisation and population growth. Thirdly, there are negative environmental consequences resulting from these factors. The primary objective of this study was to assess the soil quality index (SQI) for sugar beet cultivation under semi-arid ecological conditions. To this end, the Neutrosophic Fuzzy-AHP and Standard Scoring Function (SSF) methods were employed. Furthermore, the performance of the multi-class logistic regression (multi-class LR), random forest (RF), and one-against-all-support vector machine (OAA-SVM) models was evaluated in predicting both the linear and non-linear SQIs. Moreover, the SQI assessment entailed the calculation of spectral vegetation indices, including the Normalised Difference Vegetation Index (NDVI) and the Red Edge-Optimised Soil Adjusted Vegetation Index (RE-OSAVI). A statistical comparison was then conducted between the results and the data obtained from the high-resolution Sentinel-2A image dated 19th July 2021. This analysis utilised the NDVI and RE-OSAVI vegetation indices within the designated research area. The findings indicated that NDVI, with an r 2 value of 0.634, yielded the most favourable outcomes for the cultivation of sugar beets when considering the non-linear SQI results (p < 0.001). The prediction models in the present study were evaluated using four metrics as Matthews correlation coefficient (MCC), accuracy rate, recall, precision, and F1-score. Furthermore, Receiver Operating Characteristic (ROC) and confusion matrix were also applied for evaluation purposes. The results indicate that RF outperformed both multi-class LR and OAA-SVM in predicting both the linear and the non-linear SQI for sugar beet cultivation, demonstrating significantly higher values on MCC (0.97, 0.99), accuracy rate (0.98, 0.99), recall (0.99, 0.98), precision (0.99, 0.98), and F1-score (0.99, 0.98). These results significantly enhance our understanding of soil quality dynamics. The efficacy of the multi-class RF model in enhancing SQI predictions is of considerable significance for the informed decision-making process in agricultural and soil management practice.},
  archive      = {J_ESWA},
  author       = {Nurhan Mutlu and Orhan Dengiz and Nursaç Serda Kaya and Fikret Saygın and Sena Pacci and Salih Demirkaya and Abdurrahman Ay and Alper Mutlu and Burcu Arslan and Yalçın Kaya and Bülent Başaran and Mustafa Bozdağ and Erhan Özer and Erdem Çini},
  doi          = {10.1016/j.eswa.2025.128862},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128862},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing the neutrosophic fuzzy-AHP based soil quality index for sugar beet: A comparative study of multi-class logistic regression, random forest, and one-against-all support vector machine models},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed multi-agent reinforcement learning via interactive relationship construction and behavior prediction for confrontation scenario. <em>ESWA</em>, <em>295</em>, 128860. (<a href='https://doi.org/10.1016/j.eswa.2025.128860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confrontation is an extensively investigated topic in multi-agent research, yet learning effective confrontation policies in dynamic environments remains a fundamental challenging task. Focusing on this issue, this paper simulates group predation behavior in the animal kingdom and constructs a multi-agent confrontation system based on the predator-prey mode. To achieve policy learning in the dynamic confrontation environment, we propose a distributed multi-agent reinforcement learning algorithm with decentralized training and decentralized execution, enabling agents to optimize policies solely based on the state information from the observation subsystem. To handle the non-stationarity of the observation subsystem, an interactive relationship model for the observation subsystem is constructed based on graph attention mechanisms, which makes the policy pay more attention to the important stationary information in the observation state. Moreover, we design a conditional variational autoencoder-based behavior prediction module to improve the agents’ understanding of the evolution rules of dynamic environment entities. The advantages of our algorithm are validated within the constructed predator-prey confrontation system, and the results indicate that our algorithm outperforms the existing state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Jian Xiao and Guohui Yuan and Zhuoran Wang},
  doi          = {10.1016/j.eswa.2025.128860},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128860},
  shortjournal = {Expert Syst. Appl.},
  title        = {Distributed multi-agent reinforcement learning via interactive relationship construction and behavior prediction for confrontation scenario},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SSPFusion: A semantic structure-preserving approach for multi-modality image fusion. <em>ESWA</em>, <em>295</em>, 128859. (<a href='https://doi.org/10.1016/j.eswa.2025.128859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing learning-based multi-modality image fusion (MMIF) methods suffer from significant structure inconsistency due to their inappropriate usage of structural features at the semantic level. To alleviate these issues, we propose a semantic structure-preserving fusion approach for MMIF, namely SSPFusion. At first, we design a structural feature extractor (SFE) to extract the prominent structural features from multiple input images. Concurrently, we introduce a transformation function with Sobel operator to generate self-supervised structural signals in these extracted features. Subsequently, we design a multi-scale structure-preserving fusion (SPF) module, guided by the generated structural signals, to merge the structural features of input images. This process ensures the preservation of semantic structure consistency between the resultant fusion image and the input images. Through the synergy of these two robust modules of SFE and SPF, our method can generate high-quality fusion images and demonstrate good generalization ability. Experimental results, on both infrared-visible image fusion and medical image fusion tasks, demonstrate that our method outperforms nine state-of-the-art methods in terms of both qualitative and quantitative evaluations. The code is publicly available at https://github.com/QiaoYang-CV/SSPFUSION .},
  archive      = {J_ESWA},
  author       = {Qiao Yang and Yu Zhang and Yutong Chen and Jian Zhang and Shunli Zhang},
  doi          = {10.1016/j.eswa.2025.128859},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128859},
  shortjournal = {Expert Syst. Appl.},
  title        = {SSPFusion: A semantic structure-preserving approach for multi-modality image fusion},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An effective expectation-maximization algorithm for two-layer mixture model of gaussian process functional regressions via variational inference. <em>ESWA</em>, <em>295</em>, 128858. (<a href='https://doi.org/10.1016/j.eswa.2025.128858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-layer mixture of Gaussian process functional regressions (TMGPFR) is an effective statistical learning framework for non-stationary curve clustering. However, the existing parameter learning algorithms for TMGPFRs exhibit critical trade-offs: the Markov Chain Monte Carlo expectation-maximization (MCMC EM) algorithm achieves high accuracy but incurs prohibitive computational cost, while the classification expectation-maximization (CEM) algorithm is efficient but often inaccurate in the presence of highly correlated samples. In this paper, we propose a variational inference (VI) CEM algorithm for TMGPFRs to address these limitations. The VI CEM algorithm fundamentally enhances the CEM framework by variationalizing its expectation-step, where a mean-field variational approximation is applied to the posterior distribution of latent variables and the expectation is computed by maximizing the evidence lower bound. Theoretically, the VI CEM algorithm offers a principled balance between efficiency and accuracy. Experiments on synthetic and real-world datasets demonstrate that the VI CEM algorithm achieves similar accuracy to the MCMC EM algorithm at a substantially lower computational cost, and significantly outperforms the CEM algorithm in accuracy.},
  archive      = {J_ESWA},
  author       = {Yurong Xie and Di Wu and Zhe Qiang},
  doi          = {10.1016/j.eswa.2025.128858},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128858},
  shortjournal = {Expert Syst. Appl.},
  title        = {An effective expectation-maximization algorithm for two-layer mixture model of gaussian process functional regressions via variational inference},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal context-aware consistency alignment for vision-language tasks. <em>ESWA</em>, <em>295</em>, 128857. (<a href='https://doi.org/10.1016/j.eswa.2025.128857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal context-aware consistency alignment is essential for vision-language tasks. However, existing methods struggle to model intra-modal contextual structures, hindering the effective integration of hierarchical information and long-range dependencies. These limitations compromise the consistency and robustness of cross-modal alignment, particularly in complex scenarios such as multi-step reasoning and semantically ambiguous expressions. To address these challenges, we propose the Multimodal Context-aware Consistency Alignment (MCCA) framework, which alleviates key bottlenecks in cross-modal semantic alignment. MCCA enhances the language encoder with context-aware mechanisms to capture multi-level linguistic semantics and incorporates both relative and absolute positional encodings into the visual encoder to generate spatially-aware visual representations. Building on these enriched representations, we propose two complementary alignment strategies. The first leverages a Gaussian radial basis function kernel to capture nonlinear semantic associations between linguistic tokens and image regions in high-dimensional space. The second adopts an adaptive Jaccard similarity to dynamically form semantic sets across modalities, enabling alignment to adapt to the actual distribution of text-image pairs and improving robustness and generalization. Extensive experiments on five benchmark datasets for visual question answering and visual grounding demonstrate that MCCA achieves state-of-the-art performance, with 72.08 % accuracy on VQA 2.0 and 99.33 % on CLEVR, validating its effectiveness in enhancing cross-modal semantic consistency. The code is available at: https://github.com/shenxiang-vqa/MCCAV .},
  archive      = {J_ESWA},
  author       = {Xiang Shen and Dezhi Han and Chin-Chen Chang and Yangshuyi Xu and Chongqing Chen},
  doi          = {10.1016/j.eswa.2025.128857},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128857},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal context-aware consistency alignment for vision-language tasks},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical reinforcement learning with attention-driven multi-actor A2C and shared critic for fleet management. <em>ESWA</em>, <em>295</em>, 128856. (<a href='https://doi.org/10.1016/j.eswa.2025.128856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of large-scale ride-hailing platforms has greatly enhanced the convenience of people’s daily commutes. However, the dynamic and complex nature of traffic environments and the randomness of passenger demand pose significant challenges for real-time and efficient fleet management. Rule-based approaches and reinforcement learning methods are commonly employed to address such tasks, but they often struggle to handle large-scale and highly dynamic environmental information and typically generate only a single strategy. In complex and variable urban transportation systems, different areas require distinct relocation strategies due to variations in population density, area types (e.g., hotels, hospitals, entertainment venues), and time periods (morning, noon, evening, midnight). In this paper, we propose a Hierarchical Multi-Agent Reinforcement Learning framework with Attention-Driven Multi-Actor and Shared Critic (HMA2C), formulated as a Markov Decision Process (MDP) to generate optimal strategies for different regions. HMA2C divides the dispatching process into two blocks: the manager control block and the worker control block. The manager control block selects the appropriate actor network for a given region, while the worker control block generates specific dispatching strategies. Additionally, to enhance the stability of model training, we use the average of two estimation networks in the critic network to evaluate the current state value. Finally, experiments conducted on a real-world dataset demonstrate that our proposed method outperforms state-of-the-art approaches.},
  archive      = {J_ESWA},
  author       = {Xiaohui Huang and Xiaoji Cheng and Nan Jiang and Wei Liu and Ying Yu},
  doi          = {10.1016/j.eswa.2025.128856},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128856},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hierarchical reinforcement learning with attention-driven multi-actor A2C and shared critic for fleet management},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-task learning for unified aspect identification in text reviews. <em>ESWA</em>, <em>295</em>, 128855. (<a href='https://doi.org/10.1016/j.eswa.2025.128855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect identification is a key component of aspect-based sentiment analysis (ABSA), enabling granular insights into customer feedback by identifying attributes discussed in text. This process involves two tasks: explicit aspect identification, where aspects are directly mentioned (e.g., “battery life”), and implicit aspect prediction, where aspects are inferred from context (e.g., “performance” implied by “fast”). Existing approaches often treat these tasks independently, using sequence labeling for explicit tagging and masked language modeling (MLM) for implicit prediction. However, this separation leads to inefficiencies and fails to leverage the shared contextual representations between tasks. This paper proposes a novel multi-task learning framework that unifies explicit and implicit aspect identification into a single model. The framework uses a BERT-based backbone with two task-specific heads: a token classification head for explicit tagging and an MLM head for implicit prediction. By sharing representations, the model enhances contextual understanding and reduces computational redundancy. The training process optimizes a combined loss function that balances the two tasks, enabling complementary learning. The model was evaluated on the multiple datasets from different domains, achieving better F1-score and accuracy for explicit tagging and implicit prediction, outperforming baseline models such as BiLSTM-CRF and standalone BERT models. The framework effectively identified multi-token explicit aspects and accurately predicted implicit aspects in most cases. This study demonstrates the potential of multi-task learning for unified aspect identification, offering a scalable and efficient solution. The proposed approach sets the stage for further advancements in fine-grained text analysis and practical applications in customer feedback systems.},
  archive      = {J_ESWA},
  author       = {Akshay Chauhan and Pradeep Kumar},
  doi          = {10.1016/j.eswa.2025.128855},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128855},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-task learning for unified aspect identification in text reviews},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Actively masked reasoning over knowledge graphs for fault diagnosis under insufficient information condition. <em>ESWA</em>, <em>295</em>, 128854. (<a href='https://doi.org/10.1016/j.eswa.2025.128854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs are a well-established problem solving method in artificial intelligence, and their application to fault diagnosis can effectively improve emergency response capability of the industrial system. However,the numerical differences between confounding cases under different causes are too subtle to represent. Besides, fault phenomena often contain irrelevant information that can mislead the diagnosis results. Furthermore, fault information is usually insufficient in the actual reasoning process. To address the above obstacles, this paper proposes an actively masked reasoning method over knowledge graphs. It mimics the thinking process of experts: continuously learning and accumulating knowledge, making rational decisions when encountering problems, and overcoming the limitations of data-driven methods. It contains several key innovations: (1) extracting the experience from historical fault cases into the knowledge graph using deep learning methods, enabling intelligent management of massive fault texts.; (2) proposing a knowledge representation framework based on self-supervised contrastive learning to highlight the subtle numerical differences between fault cases, which enhances the sensitivity to confounding fault phenomena ; and (3) incorporating novel masked strategies to actively learn the most important knowledge and conceal irrelevant information during the reasoning process, and significantly enhances the diagnosis model’s insight. The proposed method is evaluated on actual fault case data from the power industry. The experimental results show that it outperforms the state-of-the-art (SOTA) methods with an accuracy of 93.58 % and maintains high accuracy even under insufficient information condition, while demonstrating good robustness and explainability.},
  archive      = {J_ESWA},
  author       = {Xiang Li and Runhai Jiao and Changyu Zhou and Chengyang Li and Boxu Yan and Ruifan Li},
  doi          = {10.1016/j.eswa.2025.128854},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128854},
  shortjournal = {Expert Syst. Appl.},
  title        = {Actively masked reasoning over knowledge graphs for fault diagnosis under insufficient information condition},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-phase transformer for remote sensing image super-resolution. <em>ESWA</em>, <em>295</em>, 128853. (<a href='https://doi.org/10.1016/j.eswa.2025.128853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing images have become a critical instrument in diverse applications such as environmental monitoring. Moreover, remote sensing images exhibit a critical phenomenon: the recurrence of similar visual patterns across distant locations. However, these images frequently suffer from low-resolution limitations due to hardware constraints and adverse imaging conditions. Current Transformer-based methods have achieved significant advancements in remote sensing super-resolution tasks, attributed to their capability to capture long-range dependencies and aggregate features globally. However, the current Transformers face two critical challenges in high-resolution image restoration: (1) Redundant token representations due to the irrelevance of most tokens. (2) Inefficient global feature extraction with limited reduced computational effort. To address these limitations, we propose the Multi-phase Transformer (MPT) for remote sensing image super-resolution, which adaptively mitigates irrelevant token interference and effectively extracts spatial features with long-range dependencies under low computational overhead. Specifically, the Sparse Self-Attention (S-SA) in the Sparse Transformer block (STB) utilizes the top-k sparse operation to identify crucial tokens. This mechanism retains vital inter-image feature dependencies while ensuring computational efficiency, thereby resolving the first challenge. Then, the Dense Self-Attention (D-SA) in the Dense Transformer block (DTB) utilizes the Iterative Aggregation Module (IAM) to aggregate input features into fixed maps. This design captures spatial context and transfers global information via cross-attention while maintaining minimal computational complexity, effectively solving the second challenge. To improve the representation of multi-scale features in Multi-phase Transformer blocks, the Multi-dimensional Feature Fusion Module (MFFM) investigates multi-scale correlations within input feature maps and facilitates enhanced cross-resolution interactions. Extensive experiments illustrate that our MPT surpasses current cutting-edge methods, including CNN and Transformer architectures, in both qualitative and quantitative evaluations. In short, MPT surpasses the cutting-edge CAT method by 0.19 dB in average PSNR while requiring only 60.13 % computational resources and 67.38 % parameters.},
  archive      = {J_ESWA},
  author       = {Tao Hu and Zijie Chen and Qingqiang Zeng and Yingfang Zhang and Jiexin Zheng and Mingyi Wang and Jianqing Li},
  doi          = {10.1016/j.eswa.2025.128853},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128853},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-phase transformer for remote sensing image super-resolution},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond transfer learning: Attention-enhanced deep learning framework for multiclass gastrointestinal disease classification. <em>ESWA</em>, <em>295</em>, 128852. (<a href='https://doi.org/10.1016/j.eswa.2025.128852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gastrointestinal (GI) diseases pose a significant global health burden. Therefore, early and accurate diagnosis is paramount for effective clinical intervention. While deep learning (DL) has shown promise in automating GI disease classification, existing approaches often rely on conventional transfer learning (TL) methods that employ pretrained convolutional neural networks (CNN) either as standalone classifiers, ensemble components, or fixed feature extractors for subsequent feature selection and classification stages. These fragmented and generic pipelines suffer from several limitations, including limited adaptability to domain-specific features, increased computational complexity, and reduced clinical interpretability. To address these challenges, we propose a novel end-to-end DL framework, called Inception-Residual-Attention-DenseNet201 (IRA-DenseNet201), that redefines TL by embedding a DenseNet201 backbone within a unified task-specific architecture. The proposed framework encompasses multiscale Inception modules, residual bottleneck blocks, and a comparative study of five advanced attention mechanisms to dynamically refine feature representations. A global context block is appended to enhance semantic coherence, while gradient-weighted class activation mapping is employed to provide visual explanations of the model predictions. IRA-DenseNet201 achieved classification accuracy of 94.67 % on the Kvasir dataset. Squeeze and excitation mechanism delivered the best performance in GI disease classification. Comparative experiments revealed that the proposed model consistently outperformed conventional CNN architectures in GI detection. Unlike traditional pipelines, our approach bridges the gap between the simplicity of single pretrained models and the complexity of ensemble or multi-phase frameworks, offering a clinically viable solution for automated GI disease diagnosis. This work sets a new direction for adaptive and explainable TL in medical image analysis.},
  archive      = {J_ESWA},
  author       = {Mohamed Hosny and Ibrahim A. Elgendy and Mousa Ahmad Albashrawi},
  doi          = {10.1016/j.eswa.2025.128852},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128852},
  shortjournal = {Expert Syst. Appl.},
  title        = {Beyond transfer learning: Attention-enhanced deep learning framework for multiclass gastrointestinal disease classification},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal transport-based transfer learning with incomplete data: Bridging the gap across omains. <em>ESWA</em>, <em>295</em>, 128851. (<a href='https://doi.org/10.1016/j.eswa.2025.128851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning, as a forefront direction in the field of statistical machine learning, aims to transfer knowledge from one domain to another to enhance model performance and address the scarcity of knowledge in the target domain. However, real-world data is often affected by missing values, posing additional challenges to transfer learning. To overcome this issue, we propose an innovative approach utilizing optimal transport for transfer learning (OT-TL) with missing data. Through simulation experiments, we validate the discernibility of transferable sources by OT-TL under various scenarios involving different source domain quantities and types of missing data. Additionally, our method adapts dynamically to allocate importance weights for different source domains, achieving favorable transfer effects. Comparative studies with different missing data imputation methods demonstrate the excellence of our proposed approach. In empirical evaluations, our method exhibits strong performance in both regression and classification tasks, as evidenced by studies on datasets related to fat content measurement and UCI Arrhythmia classification. Exploring the application of optimal transport theory in transfer learning addresses the crucial issue of achieving knowledge transfer in the presence of data missing challenges. This research provides a novel avenue for tackling transfer learning in practical problem-solving and opens up additional possibilities for real-world applications of cross-domain knowledge transfer.},
  archive      = {J_ESWA},
  author       = {Minmin Zhan and Yunquan Song and Fanyun Meng},
  doi          = {10.1016/j.eswa.2025.128851},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128851},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal transport-based transfer learning with incomplete data: Bridging the gap across omains},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMT-SNN: Markovian decision and multi-threshold spike delivery integrated adaptive spiking neural network for tactile object recognition. <em>ESWA</em>, <em>295</em>, 128850. (<a href='https://doi.org/10.1016/j.eswa.2025.128850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile object recognition represents a significant research direction within the field of robotic perception. Traditional frame-based tactile object recognition methods encounter limitations when applied to event-driven tactile data, especially under rapid dynamic change conditions. In contrast, spiking neural networks (SNNs) demonstrate higher efficiency when processing event-driven tactile data streams. However, the parameter update strategies employed by the existing SNN models typically rely on fixed learning strategies and regularization parameters, which may lead to slow convergence or entrapment in local optima when handling complex, variable tactile signals. Moreover, the current SNN models for tactile recognition often utilize single-neuron firing mechanisms, which restricts their overall neuronal expression capacities. To address these issues, we propose the MMT-SNN method, which leverages Markov decision process (MDP) principles to dynamically adjust the parameter update strategies of SNNs, thereby enhancing the accuracy and efficiency of object recognition. Additionally, a multi-threshold firing mechanism is employed to attain improved gradient propagation and increased neuronal expressiveness within the network. Experimental results demonstrate that MMT-SNN significantly outperforms the state-of-the-art approaches, achieving a 12.50% performance improvement over the classic TactileSGNet approach on the Containers-v0 dataset and a 3.61% improvement on the Objects-v0 dataset.},
  archive      = {J_ESWA},
  author       = {Jing Yang and Zukun Yu and Changfu Zhang and Shaobo Li and Lin Li and Zhidong Su and Yixiong Feng},
  doi          = {10.1016/j.eswa.2025.128850},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128850},
  shortjournal = {Expert Syst. Appl.},
  title        = {MMT-SNN: Markovian decision and multi-threshold spike delivery integrated adaptive spiking neural network for tactile object recognition},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced prediction of NBA players’ salaries using hybrid ensemble models and multi-objective optimization techniques based on the 2022–23 season dataset. <em>ESWA</em>, <em>295</em>, 128849. (<a href='https://doi.org/10.1016/j.eswa.2025.128849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basketball is a popular sport played globally, featuring 2 teams scoring by shooting a ball through hoops. Its evolution led to the formation of leagues like the National Basketball Association (NBA), with precursor leagues like the National Basketball League (NBL) and Basketball Association of America (BAA) merging to establish it. The sport has seen significant milestones, including its Olympic debut in 1904 and the introduction of innovations like the 3-point line by the American Basketball Association (ABA). The NBA is widely regarded as the premier professional basketball league globally due to its consistent production of some of the greatest players in the sport’s history. NBA free agency begins July 1, allowing teams to negotiate contracts until July 7. Teams aim to fill roster needs within salary cap limits, while players prioritize factors like contract value, location, and playing time. Negotiations involve assessing player performance and stats, but determining fair compensation remains subjective and varies by team. In this study, the objective is to develop a systematic approach utilizing frequently recorded metrics for NBA players to determine a player’s yearly salary in a manner that optimally reflects their prospective impact on team performance. The dataset for this study included 49 feature data for 467 NBA players. Game performance, shooting, rebounding, playmaking, and so on were factors influencing the salary of players. This dataset underwent preprocessing and K-fold cross-validation to assess the generalization performance of the prediction models, including Extreme Gradient Boosting (XGB), Random Forest Regression (RFR), and Multilayer Perceptron (MLP). Then, Feature selection techniques by 2 multi-objective optimizers of multi-objective artificial Vultures Optimization Algorithm (MOAVOA) and Multi-Objective Equilibrium Optimizer (MOEO) and the TOPSIS decision-making method helped in identifying the most informative and relevant features in the case of salary prediction, reducing dimensionality and potentially improving model interpretability and efficiency. Also, hybrid predictors and ensemble prediction framework (based on Dempster Shaffer Theory) were utilized as strong estimators, and finally Shapley Additive Explanations (SHAP) and Analysis of Variance (ANOVA) methods were utilized for examining the predictor’s sensitivity to prediction factors. The comparison of estimation accuracy between the models (based on testing the total data) indicates that the XGAV hybrid model demonstrates superior performance in predicting the income of basketball players, with R M S E and R 2 values of 1.15 million dollars and 0.990, respectively.},
  archive      = {J_ESWA},
  author       = {Ziqi Xu and Zitong Xu},
  doi          = {10.1016/j.eswa.2025.128849},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128849},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced prediction of NBA players’ salaries using hybrid ensemble models and multi-objective optimization techniques based on the 2022–23 season dataset},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A network fairness consensus model considering opinion retention utility. <em>ESWA</em>, <em>295</em>, 128848. (<a href='https://doi.org/10.1016/j.eswa.2025.128848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent interactions among decision-makers (DMs) in social network group decision-making (SNGDM) intensified their fairness concerns. In the consensus-reaching process of SNGDM, prior research assumes that DMs hold fairness concern for all others in social networks and only focuses on opinion compensation. However, it ignores that DMs in social networks mainly have fairness concern with those they are connected to in social-comparisons, as well as the impact of opinion reservation on the perceived fairness utility in self-comparisons. To address these two issues, this paper redefines fairness measurement in social networks and incorporates opinion retention into DMs’ fairness utility, aiming to analyze consensus fairness considering DMs’ network fairness concern in SNGDM. First, we propose the network fairness concern coefficient based on trust and opinion relationships to measure the different levels of DMs’ fairness concern for others. Then, taking into account the DM’s dual fairness concerns about opinion compensation and opinion retention, the fairness utility function is constructed based on the network fairness coefficient. Accordingly, a maximum fairness utility network consensus model is proposed. Finally, the validity of the proposed model is confirmed by the application example of enterprises’ initial carbon quota allocation. The results show that: (1) The network fairness concern coefficient enables personalized fairness assessment, and (2) Incorporating opinion retention in the fairness utility function mitigates limitations of compensation-focused fairness measures, offering a more holistic framework.},
  archive      = {J_ESWA},
  author       = {Dong Cheng and Fen Liang and Yong Wu},
  doi          = {10.1016/j.eswa.2025.128848},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128848},
  shortjournal = {Expert Syst. Appl.},
  title        = {A network fairness consensus model considering opinion retention utility},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge compensation for event argument extraction via AMR-guided dynamic probability gain. <em>ESWA</em>, <em>295</em>, 128846. (<a href='https://doi.org/10.1016/j.eswa.2025.128846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event argument extraction (EAE) aims to capture all argument roles and corresponding text spans for the given event type. Existing works introduce Abstract Meaning Representation (AMR) information in the form of graphs or dense vectors to model global features and capture long-distance dependencies. However, such implicit exploitation ignores that AMR, as a more fundamental semantic parsing task, can already provide key clues and candidate arguments for EAE, and tends to achieve sub-optimal results. In this paper, we propose an AMR-constrained decoding model (AMCODE), which constructs dynamic probability gain based on the underlying AMR information to constrain the decoding, explicitly leveraging the prior argument clues to capture argument dependencies and thus achieving knowledge compensation from the AMR parsing task. Specifically, we first design a novel AMR-derived entity retrieval algorithm to mine valid entities from the AMR graph and then propose an implicit feature fusion module to interact the prior entities with the argument roles. Furthermore, we design role-specific dynamic gains to adjust the output distribution, explicitly constraining the model to consider candidate AMR entities to populate the target argument role during the decoding. Extensive experiments on the ACE05, RAMS, and WIKIEVENTS datasets demonstrate the superiority of AMCODE over other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Song He and Wenli Du and Xin Peng and Zhangpeng Wei and Xin Li},
  doi          = {10.1016/j.eswa.2025.128846},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128846},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge compensation for event argument extraction via AMR-guided dynamic probability gain},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New perspectives on multivariate time series forecasting: Lightweight networks combined with multi-scale hybrid state space models. <em>ESWA</em>, <em>295</em>, 128845. (<a href='https://doi.org/10.1016/j.eswa.2025.128845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, applications such as industrial energy planning and urban transport planning require forecasting future trends from historical data. Due to the significance and complexity of these issues, there is an urgent need for robust prediction algorithms that can handle long-term time series forecasting. In recent years, transformer-based algorithms have emerged and demonstrated great potential. However, their computational costs are substantial, leading to inefficiency. A lightweight module called LSM is proposed to enhance the accuracy of Long-term Time Series Forecasting (LTSF). This model exhibits linear scalability and low computational costs. By effectively combining deep learning models with a hybrid state space model architecture, it efficiently captures dependencies at different scales within patches to predict global and local contexts accurately. Additionally, to further improve algorithm performance and computational efficiency, this model adopts a “strong encoder-light decoder” architecture design. Experimental results on 8 benchmark datasets demonstrate that LSM performs exceptionally well in long sequence prediction tasks by exhibiting strong robustness and effectiveness compared to State-Of-The-Art approaches (SOTA). Moreover, LSM significantly enhances accuracy while reducing computational requirements. Code availability: https://github.com/hao-fei-hub/LSM/ .},
  archive      = {J_ESWA},
  author       = {Fei Hao and Junhai Qiu and Xiaofeng Zhang and Yepeng Liu and Hua Wang and Yujuan Sun and Pengbin Zhang},
  doi          = {10.1016/j.eswa.2025.128845},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128845},
  shortjournal = {Expert Syst. Appl.},
  title        = {New perspectives on multivariate time series forecasting: Lightweight networks combined with multi-scale hybrid state space models},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing stock price forecasting: A hybrid approach using fuzziness and automated machine learning. <em>ESWA</em>, <em>295</em>, 128844. (<a href='https://doi.org/10.1016/j.eswa.2025.128844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting, particularly in the domain of stock prices, is a significant challenge but benefits from the availability of openly accessible data. Our work focuses mainly on (although not limited to) univariate time series forecasting of monthly or daily stock prices, predicting one step ahead. We developed an innovative pipeline that combines fuzzification with Automated Machine Learning, achieving improved forecasting performance. Unlike previous literature, we revise the binomial Fuzzy Time Series and machine learning algorithm, including a classification task (formally motivating it), and involving unused features of fuzzy sets. Thanks to the type of aggregation of the fuzzified data, the approach has the potential to preserve interpretability, unlike most machine learning based approaches. Using several financial datasets, in addition to preliminary experiments on chaotic time series, we found evidence of significantly improved performance in most cases. This study contributes to further understanding of the intersection between fuzzy logic and Automated Machine Learning, particularly in the context of time series forecasting, offering a promising direction for future research.},
  archive      = {J_ESWA},
  author       = {Jan Timko and Radwa El Shawi and Stefania Tomasiello},
  doi          = {10.1016/j.eswa.2025.128844},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128844},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimizing stock price forecasting: A hybrid approach using fuzziness and automated machine learning},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ARMLF: Anomalous region representation learning for multi-exposure fused light field image quality assessment. <em>ESWA</em>, <em>295</em>, 128843. (<a href='https://doi.org/10.1016/j.eswa.2025.128843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Exposure Fused Light Field Images (MEF-LFIs) can capture scene information within a large dynamic range, as well as the direction and intensity of light, thereby exhibiting a more nuanced representation of details. However, in dynamic scenes, the dynamic range enhancement techniques based on Multi-Exposure Fusion (MEF) are prone to generating ghost artifacts and color shifts, which adversely affect spatial quality and angular consistency of MEF-LFIs, limiting their practical applications. Therefore, it is crucial to develop a reliable quality metric to monitor the quality of MEF-LFIs and facilitate the optimization of MEF algorithms. To address this issue, this paper proposes an anomalous region representation learning-based MEF-LFI quality assessment metric, termed as ARMLF. Specifically, motivated by the human visual perception, the anomalous regions are first detected by identifying the ghost artifacts and/or color shifts in MEF-LFI. Then, a frequency domain decoupling module is designed to extract local visual features from both anomalous and non-anomalous regions, enabling effective characterization of perceptual degradations. Subsequently, a 3D structural representation based on tensor decomposition is constructed to capture the high-dimensional spatial-angular correlations inherent of MEF-LFI. Based on this representation, a spatial-angular information integration module is designed to extract global spatial-angular features from the representation. Finally, a quality prediction module aggregates the extracted features to predict the final quality score of MEF-LFI. The experimental results demonstrate that the proposed ARMLF metric outperforms the state-of-the-art quality metrics and is also more consistent with the human visual system.},
  archive      = {J_ESWA},
  author       = {Guanglong Liao and Gangyi Jiang and Linwei Zhu and Yeyao Chen and Yueli Cui and Ting Luo and Haiyong Xu},
  doi          = {10.1016/j.eswa.2025.128843},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128843},
  shortjournal = {Expert Syst. Appl.},
  title        = {ARMLF: Anomalous region representation learning for multi-exposure fused light field image quality assessment},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous graph knowledge tracing with novel contrastive view and meta-path contexts. <em>ESWA</em>, <em>295</em>, 128840. (<a href='https://doi.org/10.1016/j.eswa.2025.128840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing aims to track the evolution of knowledge state based on student’s historical learning records to predict future performance, which has become a key part of intelligent tutoring systems. Existing methods typically model the learning process based on structural relationships between questions or skills, but the extraction of multi-granularity heterogeneous features from sparse learning records has not been sufficiently explored. In this paper, we propose a heterogeneous graph knowledge tracing method (HCMKT) with novel contrastive view and meta-path contexts to solve the above problem. Specifically, we employ meta-paths to construct coarse and fine-grained views, capturing higher-order interaction features among questions. Then, to learn high-quality question representations, we construct contrastive view between the coarse and fine-grained views with an elaborate negative sample selection mechanism. Additionally, diverse question-answer interaction representations are input into the LSTM network for state modeling. Finally, we integrate coarse and fine-grained modeling processes using online knowledge distillation to enhance model robustness. Extensive experiments conducted on four datasets demonstrate the rationality and effectiveness of HCMKT.},
  archive      = {J_ESWA},
  author       = {Jie Liu and Zheng Guan and Xue Wang and Zhijun Yang},
  doi          = {10.1016/j.eswa.2025.128840},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128840},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous graph knowledge tracing with novel contrastive view and meta-path contexts},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-scale graph tide model with enhanced graph structure learning and spatiotemporal decoupling for load forecasting. <em>ESWA</em>, <em>295</em>, 128839. (<a href='https://doi.org/10.1016/j.eswa.2025.128839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term load forecasting (STLF) is crucial for the stability of the power system. The STLF relies significantly on extracting intricate and essential spatiotemporal features from load datasets. However, current forecasting models face multiple limitations. These include the construction of graph structures with suboptimal quality, caused by excessive sensitivity of these models to outliers and feature degradation. Additionally, these models neglect the inherent periodic patterns within the load data and fail to effectively decouple spatial dependencies from temporal features. To address these shortcomings, this study proposes a novel multi-scale graph tide model (MSGT) to improve the accuracy of the STLF. First, a new graph structure learning method is proposed to address the suboptimal quality of constructed graph structures by leveraging similarity algorithms and the Gumbel Softmax sampling strategy, respectively. Second, a new multi-scale time granularity input is proposed to facilitate the MSGT to capture the inherent periodic patterns within the load data. Third, a new decoupling mechanism is proposed to enhance the MSGT’s ability to separate spatial dependencies from temporal features. Extensive experimental results demonstrate that the MSGT outperforms mainstream models in terms of robustness and real-time performance.},
  archive      = {J_ESWA},
  author       = {Wenyue Liu and Xiaoling Huang and Shan Ji and Dongping Zhang and Shuai Zhang},
  doi          = {10.1016/j.eswa.2025.128839},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128839},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-scale graph tide model with enhanced graph structure learning and spatiotemporal decoupling for load forecasting},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Biomedical relation extraction based on a cascade binary tagging framework with varied decoders. <em>ESWA</em>, <em>295</em>, 128838. (<a href='https://doi.org/10.1016/j.eswa.2025.128838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting biomedical relational triples from unstructured medical texts is critical for constructing reasonable medical knowledge graphs. Due to domain-specific terminology and numerous overlapping relational triples, traditional relation extraction approaches are difficult to handle Chinese medical texts. In that case, cascading binary tagging framework (CasREL) is adopted to solve the overlapping relational triples by decomposing relation extraction into subject extraction and relational object extraction tasks. However, original CasREL overlooks task-specific characteristics and uses simplistic feature processing in the decoding stage. This work proposes the CasREL with varied decoders called CasREL-V to address the differences in two subtasks and improve the calculation of the subject features in CasREL. The introduced task-specific decoders with relative position information effectivly capture the contextual dependencies unique to each subtask and the designed subject feature module enhances object identification by encoding comprehensive subject representations. CasREL-V is validated on public dataset CMeIE and achieves 5.3 higher than CasREL in micro-F1 score. The performance of CasREL-V is also better than other relation extraction models.},
  archive      = {J_ESWA},
  author       = {Wenqi Zhu and Yinghua Fu},
  doi          = {10.1016/j.eswa.2025.128838},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128838},
  shortjournal = {Expert Syst. Appl.},
  title        = {Biomedical relation extraction based on a cascade binary tagging framework with varied decoders},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CFFormer: Cross CNN-transformer channel attention and spatial feature fusion for improved segmentation of heterogeneous medical images. <em>ESWA</em>, <em>295</em>, 128835. (<a href='https://doi.org/10.1016/j.eswa.2025.128835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays an important role in computer-aided diagnosis. Existing methods mainly utilize spatial attention to highlight the region of interest. However, due to limitations of medical imaging devices, medical images exhibit significant heterogeneity, posing challenges for segmentation. Ultrasound images, for instance, often suffer from speckle noise, low resolution, and poor contrast between target tissues and background, which may lead to inaccurate boundary delineation. To address these challenges caused by heterogeneous image quality, we propose a hybrid CNN-Transformer model, called CFFormer, which leverages effective channel feature extraction to enhance the model’s ability to accurately identify tissue regions by capturing rich contextual information. The proposed architecture contains two key components: the Cross Feature Channel Attention (CFCA) module and the X-Spatial Feature Fusion (XFF) module. The model incorporates dual encoders, with the CNN encoder focusing on capturing local features and the Transformer encoder modeling global features. The CFCA module filters and facilitates interactions between the channel features from the two encoders, while the XFF module effectively reduces the significant semantic information differences in spatial features, enabling a smooth and cohesive spatial feature fusion. We evaluate our model across eight datasets covering five modalities to test its generalization capability. Experimental results demonstrate that our model outperforms current state-of-the-art methods and maintains accurate tissue region segmentation across heterogeneous medical image datasets. The code is available at https://github.com/JiaxuanFelix/CFFormer .},
  archive      = {J_ESWA},
  author       = {Jiaxuan Li and Qing Xu and Xiangjian He and Ziyu Liu and Daokun Zhang and Ruili Wang and Rong Qu and Guoping Qiu},
  doi          = {10.1016/j.eswa.2025.128835},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128835},
  shortjournal = {Expert Syst. Appl.},
  title        = {CFFormer: Cross CNN-transformer channel attention and spatial feature fusion for improved segmentation of heterogeneous medical images},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Task-driven attention attack: An enhanced adversarial framework for long text. <em>ESWA</em>, <em>295</em>, 128834. (<a href='https://doi.org/10.1016/j.eswa.2025.128834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) is a core AI technology for understanding and generating human language, with broad real-world applications. However, NLP systems are vulnerable to adversarial attacks-even minimal perturbations can successfully mislead classifiers, resulting in incorrect predictions. Researchers have consequently developed advanced attack strategies to generate adversarial examples, aiming to enhance model robustness via adversarial training. Although current methods have achieved remarkable success in short-text applications, they exhibit significant limitations when handling longer, more complex textual inputs. Additionally, most approaches do not take into account the task-specific features that influence modeling behavior. This paper presents a novel framework, called Task-Driven Attention Attack (TDAA), for addressing the adversarial attacks on long textual content. TDAA dynamically integrates contextual semantics with task-specific features to generate optimized attention weights. Our methodology incorporates three core components: (1) an adaptive mechanism for optimal length threshold determination, (2) a backward elimination algorithm for non-essential sentence removal, and (3) an attention-augmented salience metric (TDAA-Score) for word-level importance evaluation. Experimental results demonstrate that conventional attack strategies show significantly degraded performance on long-text samples compared to TDAA. Through experiments across IMDB, 20NewsGroup, and FakeNews datasets, TDAA achieves superior attack success rates (34.7 % over baselines) and computational efficiency, establishing it as an effective solution for long-text adversarial challenges.},
  archive      = {J_ESWA},
  author       = {Qilu Xu and Jianxin Bi and Jingyuan Liu},
  doi          = {10.1016/j.eswa.2025.128834},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128834},
  shortjournal = {Expert Syst. Appl.},
  title        = {Task-driven attention attack: An enhanced adversarial framework for long text},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning on edge and cloud for intelligent monitoring and decision making in artificial pancreas. <em>ESWA</em>, <em>295</em>, 128833. (<a href='https://doi.org/10.1016/j.eswa.2025.128833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a chronic condition marked by disrupted glucose homeostasis that can raise mortality and cause organ damage. To lessen the stress of manually checking glucose levels, continuous glucose monitoring (CGM) sensors have been developed. Another important aspect of diabetes management is determining the optimal insulin dosage, which will curb hyperglycaemia but should not lead to hypoglycaemia. Hence, choosing the correct dosage becomes crucial. Extensive research in recent years has led to the development of artificial pancreas (AP) for effective management of diabetes. However, the present AP systems’ ability to offer thorough insights for diabetes management is constrained by the absence of automatic integration of personalized physiological data such as physical activity (PA) levels, meal information automatically with CGM levels, and insulin dosage. This makes usage of artificial pancreas cumbersome for the patients. In this review, methods for automatic incorporation of physiological parameters are discussed. This is followed by a discussion of the impact of automatic incorporation of these inputs on the improvement of functionality. With increasing usage of wearable physical activity monitoring devices, the tracking of physical activity has become easier and encouraging for accurate glucose forecasting. In this paper, technologies that can be utilised for automatic activity monitoring in artificial pancreas are also presented in conjunction with deep learning methods to enable seemless personalisation on the Edge.},
  archive      = {J_ESWA},
  author       = {Deepjyoti Kalita and Hrishita Sharma and Khalid B. Mirza},
  doi          = {10.1016/j.eswa.2025.128833},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128833},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep learning on edge and cloud for intelligent monitoring and decision making in artificial pancreas},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-population evolutionary algorithm based on constraint grouping for constrained multiobjective optimization problems. <em>ESWA</em>, <em>295</em>, 128830. (<a href='https://doi.org/10.1016/j.eswa.2025.128830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) are widely existed in the real-world applications and difficult to be solved due to the existence of multiple conflicting objectives and constraints. In the last few years, it has become a trend to design simple and effective helper problems to help solve the original CMOPs. However, most of the existing algorithms design auxiliary problems without considering the relationship between individual constraints and perform limited on solving different types of problems. To remedy this issue, a multi-population evolutionary algorithm based on constraint grouping, termed as CGMEA, is proposed. CGMEA creates independent populations to evolve single constraints in the first stage and analyzes the relationship between these populations. To fully utilize the relationship between single constraints, a constraints grouping method and an auxiliary population competition mechanism are proposed, respectively, to group the independent populations and allocate specific tasks for different groups. By designing more effective auxiliary populations evolutionary behavior, the diversity of both offspring generation and environmental selection are improved. Finally, the proposed algorithm and other six state-of-the-art algorithms are compared in detail on standard test suites and real-world applications. The results show the effectiveness of the proposed CGMEA.},
  archive      = {J_ESWA},
  author       = {Dezheng Zhang and Lingjun Wang and Kangjia Qiao and Kunjie Yu and Yumeng Li},
  doi          = {10.1016/j.eswa.2025.128830},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128830},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-population evolutionary algorithm based on constraint grouping for constrained multiobjective optimization problems},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corporate ESG rating prediction based on XGBoost-SHAP interpretable machine learning model. <em>ESWA</em>, <em>295</em>, 128809. (<a href='https://doi.org/10.1016/j.eswa.2025.128809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of corporate ESG ratings is of paramount importance in augmenting the scientific rigor and precision of ESG investment decisions and steering corporate management of ESG-related risks. While machine learning methodologies have been extensively utilized in forecasting corporate behavior, their deployment in corporate ESG ratings remains relatively nascent and is often criticized for a lack of interpretability. This study develops a predictive model for corporate ESG ratings using an XGBoost algorithm enhanced with SHAP interpretability. The methodological framework incorporates SMOTE-ENN for handling class imbalance and a comprehensive optimization approach utilizing 3-fold cross-validation and randomized hyperparameter search. The model incorporates a comprehensive set of 15 indicators spanning four critical dimensions—financial performance, environmental impact, social responsibility, and corporate governance, using a dataset of Chinese A-share listed companies from 2013 to 2022. The model’s predictive efficacy is subsequently elucidated, revealing that the XGBoost-SHAP framework achieves an accuracy and precision rate of 91.0% and 90.7%, respectively, with an F1-score and AUC value of 90.1% and 0.977, outperforming comparative models. The analysis underscores the significant influence of financial and non-financial factors on ESG rating predictions, with financial attributes exerting a relatively more pronounced impact than individual non-financial metrics. Tailored to the diverse objectives of ESG investors, this research further delineates a level definition model and a risk identification model, achieving predictive accuracies of 92.4% and 97.7%, respectively. The insights from this study furnish ESG investors with a robust foundation for enhancing investment outcomes and offer strategic guidance for corporations aiming to elevate their ESG performance.},
  archive      = {J_ESWA},
  author       = {Jianfeng Zhang and Zexin Zhao},
  doi          = {10.1016/j.eswa.2025.128809},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128809},
  shortjournal = {Expert Syst. Appl.},
  title        = {Corporate ESG rating prediction based on XGBoost-SHAP interpretable machine learning model},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Granular computing-based fuzzy deep neural network for long-tailed fault diagnosis: Design and analysis. <em>ESWA</em>, <em>295</em>, 128806. (<a href='https://doi.org/10.1016/j.eswa.2025.128806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real industrial settings, fault occurrences are typically infrequent, resulting in a significant imbalance between fault and normal samples – a phenomenon characterized as a long-tailed data distribution. Conventional deep learning approaches tend to overlook minority fault modes, thereby degrading fault diagnosis (FD) performance. To address this challenge, in this paper, a granule computing-based fuzzy deep neural network (GC-FDNN) model is proposed. The model incorporates a multi-view data augmentation unit that synthesizes additional fault samples through diverse strategies including noise injection and scale transformation, forming an augmented dataset that mitigates fault modes’ imbalance. Subsequently, the model employs a fuzzy feature information distillation unit to process this augmented dataset, extracting robust, compact, and representative fuzzy fault features through a novel architecture of sequentially stacked feature transformation blocks–each containing a fuzzy learning layer paired with a distillation layer–that systematically mitigates the uncertainty introduced through the data augmentation process while preserving discriminative fault characteristics. The final unit, an adaptive multi-faceted granular classifier with a Takagi-Sugeno-Kang structure, completes the mapping from the fault features to specific fault modes. This unit employs a multi-faceted granular performance loss metric to reshape fault features into fault mode-specific local neighborhood structures in hypersphere information granule (HSIG) form. The model can be optimized in end-to-end way. The main contribution of this work lies in the development of a two-stage feature refinement mechanism that integrates deep learning-based feature extraction with granular computing-based knowledge reasoning. In comparison with latest long-tailed FD methods, the proposed mechanism enhances the extraction of discriminative fault features in long-tailed scenarios by precisely characterizing cross-modality feature structures through granular embedding. Comparative analyses based on three industrial processes demonstrate that our method achieves superior performance in long-tailed FD.},
  archive      = {J_ESWA},
  author       = {Meng-Wei Li and Zhen-Sheng Zang and Wei Lu and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.128806},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128806},
  shortjournal = {Expert Syst. Appl.},
  title        = {Granular computing-based fuzzy deep neural network for long-tailed fault diagnosis: Design and analysis},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal transport path optimization of hazmat under uncertain demand in hub-and-spoke networks. <em>ESWA</em>, <em>295</em>, 128804. (<a href='https://doi.org/10.1016/j.eswa.2025.128804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multi-modal transportation is an effective method to realize the safe and efficient hazmat transportation. This study presents a multi-modal hazmat transportation model on a hub-and-spoke network to enhance safety and efficiency. Accounting for hazmat demand uncertainty, we develop a mixed-integer bi-objective optimization model to minimize costs and risks, leveraging uncertainty theory to manage variable unpredictability. We develop a non-dominated sorting genetic algorithm with node clustering and local reinforcement (C-NSGA-II) to solve the model, and validate on an 18-hub-node network. The analysis shows how demand valuation and hub numbers affect costs and risks, allowing decision-makers to select optimal hub locations based on risk tolerance, thus improving hazmat transportation outcomes.},
  archive      = {J_ESWA},
  author       = {Huo Chai and Wei Han and Kaikai Dong and Cunjie Dai and Xiaoyan Jia and Liumeng Yang and Ruichun He},
  doi          = {10.1016/j.eswa.2025.128804},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128804},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-modal transport path optimization of hazmat under uncertain demand in hub-and-spoke networks},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Application of a sampling and clustering-based heuristic search algorithm to find an efficient staff configuration in an emergency department. <em>ESWA</em>, <em>295</em>, 128803. (<a href='https://doi.org/10.1016/j.eswa.2025.128803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency Departments (EDs) are among the most complex areas in healthcare, requiring immediate medical attention for acute and urgent conditions. Optimizing staff configurations to reduce patient Length of Stay (LoS) and improve operational efficiency poses a significant challenge due to the combinatorial and high-dimensional nature of the problem. To identify the most effective staff configuration, we propose a heuristic optimization strategy that is based on the Montecarlo Clustering Search Algorithm (MCSA), which efficiently explores the multidimensional solution space. MCSA leverages an agent-based simulation (ABM) model that evaluates each proposed staff configuration under realistic operational conditions, providing Key Performance Indicator (KPI) feedback values related to each proposed staff configuration. Through this strategy, we explore staff configurations capable of handling patient volumes with varying acuity levels in an ED to optimize the LoS KPI. Results demonstrate that our methodology is capable to find a solution as a staff configuration that reduces LoS compared to a baseline, offering a computationally efficient and practical tool for decision-makers. We identified solutions by exploring less than 1% of the total search space, demonstrating the efficiency of the proposed approach in addressing complex optimization problems. This approach supports informed planning in healthcare environments while maintaining system feasibility and scalability.},
  archive      = {J_ESWA},
  author       = {Maria Harita and Alvaro Wong and Dolores Rexachs and Emilio Luque and Eva Bruballa and Francisco Epelde},
  doi          = {10.1016/j.eswa.2025.128803},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128803},
  shortjournal = {Expert Syst. Appl.},
  title        = {Application of a sampling and clustering-based heuristic search algorithm to find an efficient staff configuration in an emergency department},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting fine-grained classification: A dual-branch method for noise-resilient and global-local discriminative learning. <em>ESWA</em>, <em>295</em>, 128802. (<a href='https://doi.org/10.1016/j.eswa.2025.128802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing fine-grained visual classification (FGVC) methods tend to leverage object localization or attention-based approaches to distinguish discriminative regions. However, these methods exacerbate class confusion under complex background noise, and excessive feature extraction may suppress the expression of fine-grained information. Additionally, the inherent contradiction of self-attention in Vision Transformer (ViT) lies in the conflict between the noise generalization brought by the global receptive field and the sparsity of local features. Therefore, supplementing fine-grained local features can effectively enhance the self-attention’s focus on discriminative features, thereby suppressing background noise. From these perspectives, we propose DAH-Trans, a novel parallel dual-branch fusion architecture based on ViT and Convolutional Neural Network (CNN) in this field for the first time. It effectively complements fine-grained semantic information through multi-scale local features and dynamically integrates complementary information at different levels to mine the salient features of objects. Furthermore, three modules are designed: Spatial Aware Channel Reduction Convolution (SACRC), Spatial Local-feature Enhancement Attention (SLEA), and Dynamic Region Focuser Module (DRFM). SACRC introduces a spatial channel reconstruction unit to optimize feature representations while minimizing redundant features and noise. SLEA employs a channel grouping strategy, standardizes feature parameters, and dynamically applies a pixel-level weight matrix to strengthen spatial features. DRFM fuses multi-level feature maps with weighted attention, leveraging information entropy to identify and prioritize the most critical and sensitive regions for improved discrimination. We conduct extensive experiments on three widely used datasets, and the results demonstrate that our method achieves competitive performance in FGVC tasks.},
  archive      = {J_ESWA},
  author       = {Hongju Yang and Huiming He and Yao Li and Fuyuan Cao},
  doi          = {10.1016/j.eswa.2025.128802},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128802},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revisiting fine-grained classification: A dual-branch method for noise-resilient and global-local discriminative learning},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust hyperchaotic system-controlled color image encryption with triangular fractals and alternating channel vectors. <em>ESWA</em>, <em>295</em>, 128800. (<a href='https://doi.org/10.1016/j.eswa.2025.128800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaotic systems exhibit exceptional sensitivity to initial conditions, rendering them unpredictable and thus particularly suitable for the stringent requirements of color image encryption. In this study, a novel two-dimensional chaotic system is developed by multiplying two arbitrary coupling modes, each of which integrates a sine or cosine mapping function with logarithmic and sigmoidal activation functions. Comprehensive comparisons using largest Lyapunov exponent, sample entropy, permutation entropy, correlation dimension, and Kolmogorov entropy as metrics confirmed that the four derived hyperchaotic mappings displayed enhanced chaotic behavior and stability. To elevate color image security, we propose for the first time a color image encryption algorithm based on one of the developed hyperchaotic mappings, which incorporates triangular fractal permutations and alternating channel vector diffusion. In the permutation stage, the inherent irregularity of the fractal used for pixel scrambling considerably decreases pixel correlations within an image. This approach requires only two chaotic values and one iteration to identify the control parameters for fractal operations, substantially minimizing the encryption time for color images. During image diffusion, a single pixel alteration affects corresponding pixels across three planes simultaneously, thereby further enhancing encryption security. A series of experiments demonstrated that the proposed chaotic color image encryption technique, evaluated comprehensively using multiple criteria, outperforms existing methods in this domain. Specifically, it can withstand various types of attacks, and its number of pixel change rate (NPCR) and unified average change intensity (UACI) results under differential attacks are 99.6096 % and 33.4650 %, respectively, which are closer to the ideal benchmarks compared to those of peer algorithms.},
  archive      = {J_ESWA},
  author       = {Fei Yan and Zhenhao Liu and Witold Pedrycz and Kaoru Hirota},
  doi          = {10.1016/j.eswa.2025.128800},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128800},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust hyperchaotic system-controlled color image encryption with triangular fractals and alternating channel vectors},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disturbed optimal power flow with renewable source and static synchronous compensator. <em>ESWA</em>, <em>295</em>, 128799. (<a href='https://doi.org/10.1016/j.eswa.2025.128799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the share of renewable energy sources increases in modern power systems, the inherent variability of these sources leads to more significant fluctuations in power load. This increased variability introduces additionalchallenges for the stability and reliability of the system. Therefore, to better model real-world power systems, this paper proposes the bus-level disturbed optimal power flow (D-OPF) problem, considering both renewable energy sources and Static Synchronous Compensators (STATCOMs). In addition, to address the uncertainties introduced by renewable energy sources and load fluctuations, this paper proposes an Enhanced Quadratic Interpolation Optimization (EQIO) algorithm. The EQIO algorithm integrates Tent chaotic mapping, Survival-of-the-Fittest selection, and dynamic opposition-based learning to improve convergence and solution accuracy under uncertain conditions. The effectiveness of the proposed EQIO algorithm is validated on the CEC2017 benchmark functions and further tested on the IEEE 30-bus and 118-bus systems under disturbed scenarios. Experimental results show that EQIO achieves Friedman Ranks of 1.1750 and 1.0733 for the 30-bus and 118-bus systems, respectively, and obtains the optimal solution in 90.08 % of all disturbed scenario tests. These outcomes demonstrate the superiority of EQIO over other algorithms in solving the D-OPF problem.},
  archive      = {J_ESWA},
  author       = {Kaijie Xu and Xiaochen Zhang and Shengchen Liao and Lin Qiu},
  doi          = {10.1016/j.eswa.2025.128799},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128799},
  shortjournal = {Expert Syst. Appl.},
  title        = {Disturbed optimal power flow with renewable source and static synchronous compensator},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rumor detection and propagation on social networks: A survey. <em>ESWA</em>, <em>295</em>, 128798. (<a href='https://doi.org/10.1016/j.eswa.2025.128798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accessibility to the Internet has increasingly become easy and widespread in recent years. The number of social networks with diverse functionalities grows every year. These platforms attract millions of members eager to make new friends and stay updated on the latest news. However, deceptive activities, often called information pollution, aim to mislead users. Rumors are part of information pollution that consider information with doubtful authenticity. The widespread dissemination of rumors has caused a global threat on social networks. In this regard, the research related to rumor detection on social networks has drawn wide attention. In the recent decade, many studies have been conducted to identify and prevent rumors from the content of web information. Researchers have proposed various approaches for detecting rumors, leveraging statistical analysis and machine learning methods. In this paper, we review the latest methods and their performance on benchmark datasets. Additionally, we categorize models proposed for understanding rumor propagation and review recent studies in this field. Finally, we remark on the challenges and open issues, offering insights into potential future research directions.},
  archive      = {J_ESWA},
  author       = {Mohammad Ziari and Nasrollah Moghaddam Charkari},
  doi          = {10.1016/j.eswa.2025.128798},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128798},
  shortjournal = {Expert Syst. Appl.},
  title        = {Rumor detection and propagation on social networks: A survey},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FAIERDet: Fuzzy-based adaptive image enhancement for real-time traffic sign detection and recognition under varying light conditions. <em>ESWA</em>, <em>295</em>, 128795. (<a href='https://doi.org/10.1016/j.eswa.2025.128795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent vehicle safety relies on the Traffic Sign Detection and Recognition (TSDR) system. The real-world varying light affects the visibility of traffic signs and emphasizes the necessity of a robust TSDR. Existing solutions face challenges in effectively balancing accuracy and inference time for such challenges. The proposed work introduces an adaptive framework integrating preprocessing and enhancement modules with the existing detection network. The preprocessing module employs a Fuzzy Inference System (FIS) to evaluate the illumination channel and calculate the image’s exposure quality. Low-light images are directed to enhancement depending on the exposure quality, while good-light images are passed to the detection network directly. The enhancement module improves image brightness while preserving color details through illumination adjustment using the proposed Adjustment Factor Prediction Convolutional Neural Network (AFPCNN). Finally, YOLOv8 is used for TSDR from the image. The results entail accuracy comparisons of simulated low-light images using three publicly available datasets: the German Traffic Sign Detection Benchmark (GTSDB), the Tsinghua-Tencent 100K (TT100K), and the Mapillary Traffic Sign Dataset (MTSD). The proposed enhancement module improves Recall and mean Average Precision on randomly dark images by 10–18 % and 5–9 % across the benchmark datasets. Furthermore, the proposed framework enhances the detection accuracy by 1–2 % by adaptively selecting only low-light images for enhancement instead of enhancing all images from varying light conditions.},
  archive      = {J_ESWA},
  author       = {Priyanka Choudhary and Somnath Dey},
  doi          = {10.1016/j.eswa.2025.128795},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128795},
  shortjournal = {Expert Syst. Appl.},
  title        = {FAIERDet: Fuzzy-based adaptive image enhancement for real-time traffic sign detection and recognition under varying light conditions},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-task learning for inertia effects estimation in construction engineering equipment considering time delay. <em>ESWA</em>, <em>295</em>, 128787. (<a href='https://doi.org/10.1016/j.eswa.2025.128787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To quantify the “inertia effects” in construction engineering equipment and explore the inertial coupling between subsystems, an inertia effects estimation method based on time scale is proposed. In this study, a multi-task learning model integrating Stacked Auto-Encoders (SAE), Convolutional Neural Network (CNN), and other modules is constructed. Further, by employing an Adaptive Parameter Energy Valley Optimization (AP-EVO) algorithm, the empirical expression of the inertial response time containing the contribution factor of the subsystems is derived. The results indicate that: (1) Through the multi-task learning model, the estimation of the inertial response time of the electric subsystem, hydraulic subsystem, mechanical subsystem, and whole equipment is realized, where the R 2 reaches 0.9942, 0.9759, 0.9888, and 0.9911, respectively. (2) The inertia contribution factors of electric, hydraulic, and mechanical (EHM) subsystems are decoupled to 0.1265, 0.8350, and 0.6985, respectively, where 89.2 % of samples have an error less than 10 s under the decoupled inertia expression. The main contribution of this study is to propose a measurement framework of inertia effects based on time-scale, providing a feasible path for inertia cognition and exploration of construction engineering equipment.},
  archive      = {J_ESWA},
  author       = {Yongsheng Li and Limao Zhang},
  doi          = {10.1016/j.eswa.2025.128787},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128787},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-task learning for inertia effects estimation in construction engineering equipment considering time delay},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on signal filtering techniques in trend-following strategies with LSTM integration. <em>ESWA</em>, <em>295</em>, 128785. (<a href='https://doi.org/10.1016/j.eswa.2025.128785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative trading is a strategy that relies on mathematical and statistical models to identify market transactions. In this domain, trading strategies are typically classified into two main types: trend-following and contrarian trading. Trend-following strategies involve trading when market trends are apparent and are generally characterized by a lower win rate. This study proposes a fundamental trend-following strategy aimed at capturing significant upward trends in the futures market. Accurate entry signals are crucial for the successful execution of this strategy. Therefore, this study applies Long Short-Term Memory (LSTM) neural networks to analyze input features and filter entry signals. Four different index futures were selected as the primary experimental targets to verify the effectiveness and stability of the proposed trading mechanism and model. Compared to five other machine learning models, the LSTM model utilized in this work achieved superior results in evaluation metrics such as accuracy, precision, recall, and F1 score. Across all targets, accuracy exceeded 85 %, while precision surpassed 80 % in most cases. The findings of this study indicate that employing LSTM for entry signal filtering in trend-following scaling strategies is an effective approach. This not only helps reduce trading days but also enhances investment returns and success rates, making the trading strategy more robust and reliable.},
  archive      = {J_ESWA},
  author       = {Jimmy Ming-Tai Wu and Yi-Chun Cheng and Sheng-Chi Luo and Ju-Fang Yen and Mu-En Wu},
  doi          = {10.1016/j.eswa.2025.128785},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128785},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on signal filtering techniques in trend-following strategies with LSTM integration},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D semantic image synthesis with geometric and semantic consistency. <em>ESWA</em>, <em>295</em>, 128782. (<a href='https://doi.org/10.1016/j.eswa.2025.128782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic image synthesis generates photo-realistic and view-consistent images from a single semantic mask, which typically requires skills that apply to many practical applications like image generation, editing, and data augmentation. Existing methods for semantic image synthesis primarily focus on image reconstruction for the same view of the input, leading to artifacts when generating images from different views. To alleviate this, we propose a novel framework employing a learning-based 3D GAN inversion, which enables the generation of 3D-aware RGB images and corresponding semantic masks from a 2D single-view semantic mask. We present a Semantic Component-guided Normalization ResNet block, allowing our encoder to capture semantic representations and reflect them to the output images. To ensure semantic consistency across different views, we introduce a semantic decoder that produces an auxiliary-view semantic mask. This mask serves as a pseudo-input for learning 3D properties. Furthermore, we incorporate a 3D geometric prior that encourages the model to produce high-fidelity images from various viewpoints. Experimental results demonstrate that our method outperforms state-of-the-art 3D-aware semantic image synthesis methods.},
  archive      = {J_ESWA},
  author       = {Jihyun Kim and Changjae Oh and Hoseok Do and Sunghwan Choi and Kwanghoon Sohn},
  doi          = {10.1016/j.eswa.2025.128782},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128782},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D semantic image synthesis with geometric and semantic consistency},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A three-stage model for infrared small target detection with spatial and semantic feature fusion. <em>ESWA</em>, <em>295</em>, 128776. (<a href='https://doi.org/10.1016/j.eswa.2025.128776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning enhances infrared small target detection performance, but substantial challenges persist due to the extremely small target size. In mainstream encoder-decoder networks, downsampling operations cause small targets to lose spatial information and potentially become obscured in the background, leading to missed detections. To tackle this issue, the proposed three-stage model integrates the encoder-decoder architecture with an upsampling-free subnetwork to fuse spatial and semantic information, thereby enabling accurate small target detection. The first two stages focus on extracting precise semantic features through a Patch-based Multi-scale Feature Enhancement Module (PMFEM), which effectively captures target features at different scales. The final stage employs a specially designed sub-network without upsampling to prevent spatial information loss that typically occurs in traditional downsampling processes. This sub-network incorporates the Cross-feature Fusion Block (CFB) combined with 2D Selective Scan (SS2D) to effectively preserve spatial information while fully utilizing high-level semantic features. Experimental results on the SIRST, NUDT-SIRST, and IRSTD-1k datasets show that the model outperforms most state-of-the-art methods, specifically achieving IoU scores of 79.04 % on SIRST, 81.57 % on NUDT-SIRST, and 64.76 % on IRSTD-1k. The implementation code is available at: https://github.com/ELOESZHANG/TSNet .},
  archive      = {J_ESWA},
  author       = {Sixiang Ji and Haofei Zhang and Jingmin Zhang and Chun Fei and Xiaoyang Wang and Juanxiu Liu and Ping Zhang},
  doi          = {10.1016/j.eswa.2025.128776},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128776},
  shortjournal = {Expert Syst. Appl.},
  title        = {A three-stage model for infrared small target detection with spatial and semantic feature fusion},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive skip-review attention-based networks for intracranial aneurysm segmentation from three-dimensional rotational angiography. <em>ESWA</em>, <em>295</em>, 128775. (<a href='https://doi.org/10.1016/j.eswa.2025.128775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant progress has been made in enhancing the efficacy of automatic intracranial aneurysm (IA) segmentation through deep learning technologies. Prior research indicates that the attention mechanism of repeatedly reviewing several frames with obvious IA features can improve the segmentation performance from sequences of three-dimensional rotational angiography (3D-RA) images. However, it leads to intensification of redundant information interference and an increase in input dimensions. Also, IA features with different obvious degrees are unreasonably assigned the same weight. We present an adaptive skip-review attention-based network. It is enabled by a pre-detection module as the encoder to select several frames with obvious IAs, an adaptive IA feature enhancement module to reduce redundant information and feature dimension, a skip-review attention module to repeatedly insert the enhanced obvious IA features into the original sequence and a decoder to complete IA segmentation. A self-constructed clinical 3D-RA dataset comprising images from 300 patients with IAs is used for network training and testing. The results show that the proposed method significantly outperforms the state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Yan Zhao and Xinke Liu and Hui Li and Yu Zhou and Jianhua Zhang},
  doi          = {10.1016/j.eswa.2025.128775},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128775},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive skip-review attention-based networks for intracranial aneurysm segmentation from three-dimensional rotational angiography},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Causal-inspired learning-based method for unbiased pest recognition. <em>ESWA</em>, <em>295</em>, 128774. (<a href='https://doi.org/10.1016/j.eswa.2025.128774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based pest recognition technologies have demonstrated excellent potential in modern agriculture, especially in plant protection, significantly advancing the development of smart agriculture. However, it heavily depends on the i.i.d. (identical and independent distribution) assumption, leading to significant performance drop when encountering out-of-distribution (OOD) data. To address this issue, we propose a causal-inspired learning-based (CL) framework for reconstructing original data to achieve causal intervention. Specifically, we design a causal feature separation module to extract low-dimensional causal features from the input data to capture local pest-related features. We then introduce a causal-inspired data-reconstruction module to generate the reconstructed data by combining the low-dimensional causal features with diverse backgrounds under the guidance of scene prompt. Moreover, an unbiased data-constraint module is proposed to optimize the reconstructed data using the object-scene distance metric (OSDM) strategy, which aims to ensure object consistency and scene diversity. Finally, a novel pest OOD dataset was established, named the Pest-OOD dataset, by reconstructing the IP102 dataset and collecting data online using web crawling techniques to evaluate performance comprehensively. Experimental results demonstrate that our method significantly improves performance, achieving state-of-the-art accuracy of 86.68 % on three domain generalization benchmarks without modifying the network architecture. Moreover, our unbiased pest recognition method exhibits strong robustness to OOD data.},
  archive      = {J_ESWA},
  author       = {Zhaoting Liu and Ji Jin and Yanming Zhang and Shifeng Dong and Yan Zhang and Chuanwen Lin and Yue Teng},
  doi          = {10.1016/j.eswa.2025.128774},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128774},
  shortjournal = {Expert Syst. Appl.},
  title        = {Causal-inspired learning-based method for unbiased pest recognition},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LAPNet: A lightweight adaptive patch network for measuring water cut in oil-water two-phase flow. <em>ESWA</em>, <em>295</em>, 128772. (<a href='https://doi.org/10.1016/j.eswa.2025.128772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring oil-water two-phase flow under high water-cut conditions remains challenging due to complex flow regimes, nonlinear dynamics, and noise sensitivity. To address these issues, this paper proposes LAPNet, a lightweight adaptive-patch network that dynamically balances fine-grained temporal feature extraction and computational efficiency. LAPNet employs a two-stage adaptive optimization strategy to determine the optimal patch length, integrating a DPMixer module for short-term local spatiotemporal features and a scaled temporal self-attention (STSA) module for long-term global dependencies. Experimental validation using a double-helix microwave sensor (DHMS) shows that LAPNet achieves the lowest mean squared error (MSE) of 1.67 × 10 − 4 , mean absolute error (MAE) of 1.18 × 10 − 2 , and mean absolute percentage error (MAPE) of 1.54 %, while attaining the highest coefficient of determination ( R 2 ) of 97.38 % among all evaluated models. It outperforms both traditional methods and state-of-the-art deep learning models such as PatchTST, SRSM-Transformer, and Crossformer. Compared to the best-performing baseline (SRSM-Transformer), LAPNet reduces MSE by 39.5 %, MAPE by 40.3 %, and improves R 2 from 95.89 % to 97.38 %, demonstrating a clear quantitative advantage. Ablation studies confirm the complementary strengths of the DPMixer and STSA blocks, while patch-length analysis highlights the benefits of adaptive patch division in capturing nonlinear dynamics. These results demonstrate that LAPNet is accurate, robust to noise, and efficient, making it well-suited for real-time water cut measurement in oil-water two-phase flow.},
  archive      = {J_ESWA},
  author       = {Hanqing Chen and Mengyu Li and Wei Li and Bang Zhou and Zhiqiang Zhao and Ruiqi Wang and Weidong Cao and Jun Liu and Zhongke Gao},
  doi          = {10.1016/j.eswa.2025.128772},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128772},
  shortjournal = {Expert Syst. Appl.},
  title        = {LAPNet: A lightweight adaptive patch network for measuring water cut in oil-water two-phase flow},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ensuring secure conversational commerce: Anomaly detection in chatbot interactions. <em>ESWA</em>, <em>295</em>, 128769. (<a href='https://doi.org/10.1016/j.eswa.2025.128769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of conversational commerce and the use of chatbots in e-commerce transactions, ensuring secure interactions between customers and chatbots has become a critical concern. Artificial communication systems known as chatbots are gaining popularity, but not all security concerns associated with them have been fully addressed. People utilise chatbots for various activities, including shopping, banking, meal delivery, healthcare, cars, etc. Despite the benefits that conversational AI brings, it also poses additional security risks and presents serious challenges that must be addressed. As the field continues to evolve and expand, it is crucial for the conversational AI community to remain vigilant of any potential vulnerabilities in existing architectures and to proactively address them to prevent attackers from exploiting them. This research paper presents a novel approach to improving the security of chatbot interactions using anomaly detection techniques. By analysing the patterns and behaviours of chatbot interactions, We proposed an ensemble learning model called Forest Light Ensemble (FLE), using machine learning, which can detect and flag potentially malicious activities in chatbot using Ensemble learning-based chatbot security detection framework(EL - CSDF), such as phishing attempts, malware attempts, spam attempts, fraudulent transactions and defacement attempts. The ISCX-URL2016 dataset demonstrates the attacks that can quickly happen in the chatbot. After using machine learning classifiers and the Forest Light Ensemble method, we got the precision for all these attempts, in which the highest accuracy is 98 %. AI and chatbots have become increasingly prevalent in various domains, including e-commerce transactions. However, with this rise comes the need for increased attention to the security concerns associated with them.},
  archive      = {J_ESWA},
  author       = {Amardeep Kumar and Danish Ali Khan and Ruhul Amin},
  doi          = {10.1016/j.eswa.2025.128769},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128769},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ensuring secure conversational commerce: Anomaly detection in chatbot interactions},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid CORELAP-association rules and fuzzy AHP framework for plant layout optimization in the para rubber plywood industry. <em>ESWA</em>, <em>295</em>, 128766. (<a href='https://doi.org/10.1016/j.eswa.2025.128766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses key limitations of traditional plant layout methods by proposing a novel hybrid framework that integrates CORELAP, association rule mining, and fuzzy AHP. In the para rubber plywood industry, conventional approaches often fall short due to their reliance on subjective closeness ratings and limited ability to incorporate real-world logistics data or multi-criteria decision-making. To overcome these challenges, this research enhances CORELAP by employing association rule mining (via the FP-Growth algorithm) to extract actual transportation patterns between departments. These data-driven relationships replace conventional relationship charts, resulting in more realistic layout sequences. Six alternative layouts are developed using SLP, ALDEP1, ALDEP2, CORELAP, and two CORELAP-AR scenarios. Fuzzy AHP is then used to evaluate these layouts based on seven criteria: material flow, movement distance, operational ease, transportation cost, safety, energy consumption, and inventory management. Expert assessments confirm the robustness of the rankings (Kendall’s W = 0.984), with the CORELAP-AR ( Scenario 2) layout achieving the highest overall score. The selected layout yields a 39.68 % reduction in material handling distances, saves approximately USD 6,210.50 in annual fuel costs, and reduces carbon emissions proportionally. This modular, scalable framework significantly improves logistics efficiency and sustainability, and it can be extended with simulation tools and real-time data for adaptive industrial facility planning.},
  archive      = {J_ESWA},
  author       = {Duligar Saisud and Wanatchapong Kongkaew},
  doi          = {10.1016/j.eswa.2025.128766},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128766},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid CORELAP-association rules and fuzzy AHP framework for plant layout optimization in the para rubber plywood industry},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised boundary-aware medical image segmentation via symmetric boundary-foreground collaboration. <em>ESWA</em>, <em>295</em>, 128764. (<a href='https://doi.org/10.1016/j.eswa.2025.128764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of labeled data, semi-supervised segmentation learning has gained significant attention. However, accurate predictions of hard-to-identify boundaries in medical images remains challenging, especially when learning from unlabeled data. To address this issue, we propose a semi-supervised boundary-aware medical image segmentation method Via S ymmetric B oundary- F oreground C ollaboration (SBFC). Specifically, SBFC framwork constructs a symmetric dual-task segmentation (SDTS) network containing two symmetric segmentation models, each consisting of a dual-task U-shaped net with one encoder and two task-specific decoders for foreground and boundary segmentation. Using the predicted foreground, boundary probability maps and segmentation and derived boundary labels, a novel compound optimization objective function is proposed. This function integrates Cross-Task Consistency Regularization (CTCR) and Cross-Model Consistency Regularization (CMCR) for unlabeled data with supervised optimization for labeled data. Comprehensive experiments conducted on five public medical image datasets show that our method outperforms state-of-the-art comparative methods in terms of multiple consensus segmentation and boundary evaluation metrics.},
  archive      = {J_ESWA},
  author       = {Xibin Jia and Wang Zhang and Luo Wang and Chuanxu Yang and Xunjie Yin and Hao Jia and Yiming Zheng and Zhenghan Yang and Dawei Yang and Min Hong and Hui Xu},
  doi          = {10.1016/j.eswa.2025.128764},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128764},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semi-supervised boundary-aware medical image segmentation via symmetric boundary-foreground collaboration},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ColonOOD: A complete pipeline for optical diagnosis of colorectal polyps integrating out-of-distribution detection and uncertainty quantification. <em>ESWA</em>, <em>295</em>, 128756. (<a href='https://doi.org/10.1016/j.eswa.2025.128756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising prevalence of colorectal cancer necessitates early and accurate optical diagnosis of colorectal polyps. Despite advances in Computer-Aided Diagnosis (CAD) systems, challenges like data variability and inconsistent clinical performance hinder their widespread use. To address these limitations, we propose ColonOOD, an integrated CAD system for polyp localization, uncertainty-aware polyp classification, and Out-of-Distribution (OOD) polyp detection during colonoscopy. ColonOOD ensures robust classification of adenomatous, hyperplastic, and OOD polyps while providing calibrated uncertainty scores to support clinical decisions. Extensive evaluations across four medical centers and two public datasets demonstrate ColonOOD’s strong performance, achieving up to 79.69 % classification and 75.53 % OOD detection accuracy. This system offers reliable insights for endoscopists, marking a significant step toward broader clinical adoption of automated diagnostic tools in colorectal cancer care.},
  archive      = {J_ESWA},
  author       = {Sehyun Park and Dongheon Lee and Ji Young Lee and Jaeyoung Chun and Ji Young Chang and Eunsu Baek and Eun Hyo Jin and Hyung-Sin Kim},
  doi          = {10.1016/j.eswa.2025.128756},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128756},
  shortjournal = {Expert Syst. Appl.},
  title        = {ColonOOD: A complete pipeline for optical diagnosis of colorectal polyps integrating out-of-distribution detection and uncertainty quantification},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Iterative model pruning with sparsity learning for infrared rotary-wing UAV detection. <em>ESWA</em>, <em>295</em>, 128755. (<a href='https://doi.org/10.1016/j.eswa.2025.128755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring security is a critical requirement for production in smart factories. Unauthorized rotary-wing unmanned aerial vehicle (UAV) poses significant threats, as they may be used for surveillance, data theft, or even industrial sabotage. Thus, detecting these drones in a timely manner is crucial for safeguarding factory operations, while this conflicts with the ways to improve detection accuracy for complex tasks through the existing deep learning models built on stacked multi-layer architectures and advanced network designs. The computational and storage demands increase significantly with tack complexity, and typical network pruning face significant limitations in improving inference efficiency and reducing computational costs when applied to models with complex branching, nonlinear connections, and cross-layer dependencies. In this paper, we propose a model pruning approach specifically designed for infrared rotary-wing UAV detection, called Iterative Model Pruning with Sparsity Learning (IMPSL), to address these three issues. Our approach integrates dynamic pruning rate adjustment with sparsity learning, enabling the model to adaptively optimize its structure throughout the pruning process based on varying task demands. To validate the effectiveness of IMPSL, we introduce a specialized infrared dataset for UAV detection. Extensive experiments confirm the effectiveness of our method, demonstrating significant improvements in inference speed.},
  archive      = {J_ESWA},
  author       = {Hongkang Tao and Zan Yang and Jiansheng Liu and Haobo Qiu and Xinyu Li and Liang Gao},
  doi          = {10.1016/j.eswa.2025.128755},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128755},
  shortjournal = {Expert Syst. Appl.},
  title        = {Iterative model pruning with sparsity learning for infrared rotary-wing UAV detection},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical temporal sequence segmentation for weakly supervised video anomaly detection. <em>ESWA</em>, <em>295</em>, 128753. (<a href='https://doi.org/10.1016/j.eswa.2025.128753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal detection and localization of anomalies with weak labels is challenging due to the limited availability of labeled data and the dynamic nature of anomalies. To address these challenges, we introduce a novel Hierarchical Temporal Sequence Segmentation (HiTESS) approach that enhances anomaly detection and localization by leveraging multi-level temporal segmentation. Our method begins by segmenting the video into progressively smaller temporal units, enabling the model to capture anomalies at varying scales. The core contribution of our approach is the hierarchical selection of temporal segments, where multi-level scoring aggregates predictions across different time scales. While Bidirectional LSTMs and Multi-Head Attention refine temporal features, the hierarchical aggregation of predictions significantly enhances anomaly detection accuracy. This hierarchical analysis not only improves feature representation but also enhances the detection accuracy of subtle anomalies that might be overlooked in traditional methods. Experimental results demonstrate that the HiTESS method outperforms existing approaches by 1.32 % AUC and 4.8 % AP on the UCF-Crime and XD-Violence datasets, respectively, highlighting its effectiveness in utilizing aggregated features at varied temporal levels for capturing and localizing anomalies in video sequences.},
  archive      = {J_ESWA},
  author       = {Nuku Atta Kordzo Abiew and Lijian Gao and Qirong Mao},
  doi          = {10.1016/j.eswa.2025.128753},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128753},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hierarchical temporal sequence segmentation for weakly supervised video anomaly detection},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable oceanic cooling site selection using integrated probabilistic learning and many-objective optimization. <em>ESWA</em>, <em>295</em>, 128749. (<a href='https://doi.org/10.1016/j.eswa.2025.128749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate subsurface ocean temperature forecasting is essential for effective site selection in Seawater Air Conditioning (SWAC) systems, as it directly influences energy efficiency and operational stability. This study introduces an integrated framework combining a novel Probabilistic Deep Autoencoder (PDAE) for temperature forecasting with a Many-Objective Optimization (MaOO) approach to identify optimal seawater extraction sites. The PDAE model predicts current and future subsurface temperatures up to two months ahead, utilizing remote sensing data from the current month and the two preceding months. The model is optimized using Gaussian Process-Based Bayesian Optimization (GP-BO), achieving high accuracy with a RMSE of 1.046 °C on the test set and reliable Uncertainty Quantification (UQ). Calibration focuses on refining prediction intervals to improve alignment with observed data, ensuring consistent and robust forecasts. The MaOO framework considers four objectives: minimizing temperature, forecast uncertainty, extraction depth, and distance to urban centers. Using optimization algorithms, including NSGA-II, NSGA-III, AGE-MOEA, and AGE-MOEA-II, the study identifies well-distributed Pareto-optimal solutions, offering diverse trade-offs for SWAC deployment. Among these, NSGA-III demonstrates superior performance in balancing computational efficiency and solution diversity. The combined approach supports sustainable SWAC deployment by offering actionable insights into site selection, addressing both technical and environmental challenges.},
  archive      = {J_ESWA},
  author       = {Mohammad Mehdi Hoseini Karani and Saleh Al-Saadi and Mohammad Reza Nikoo and Ghazi Al-Rawas},
  doi          = {10.1016/j.eswa.2025.128749},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128749},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainable oceanic cooling site selection using integrated probabilistic learning and many-objective optimization},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep semantic center-guided hashing for multi-label cross-modal retrieval. <em>ESWA</em>, <em>295</em>, 128747. (<a href='https://doi.org/10.1016/j.eswa.2025.128747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing has garnered significant interest in both industry and academia due to its advantages in reducing storage costs and improving retrieval efficiency. Most existing point-wise cross-modal hashing methods randomly initialize centers for each category, which restricts their capacity to encode category-level semantic knowledge. As a result, they struggle to model inter-category relationships effectively, leading to suboptimal hash centers. To address this limitation, we propose a novel method called Deep Semantic Center-Guided Hashing (DSCGH). The key idea is to incorporate semantic priors derived from category supervision into hash center generation. Specifically, we leverage classifier weights to construct semantic-preserving and discriminative centers, ensuring alignment with category meanings. Moreover, we design a multi-label center loss to model complex multi-label correlations across modalities, encouraging binary codes to align with their relevant hash centers while repelling others. To further improve code quality, we suggest a discrete bit-uncorrelation constraint to reduce bit redundancy. Extensive experimental results on three benchmark datasets demonstrate that the DSCGH approach significantly outperforms existing baseline methods in multi-label cross-modal retrieval. The source code is publicly available at: https://github.com/QinLab-WFU/DSCGH .},
  archive      = {J_ESWA},
  author       = {Xinzheng Sui and Lei Wu and Yadong Huo and Qibing Qin and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.128747},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128747},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep semantic center-guided hashing for multi-label cross-modal retrieval},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deeply understanding features to achieve efficient remote sensing image classification. <em>ESWA</em>, <em>295</em>, 128743. (<a href='https://doi.org/10.1016/j.eswa.2025.128743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prominence of remote sensing applications has heightened the importance of image classification. However, the global nature of these images and the need to preserve intricate details often lead to methods that enhance classification accuracy at the cost of increased model complexity and computational demands. To address this, we propose DUF-Net, a 2D convolutional neural network (CNN) that balances operational efficiency with improved feature extraction accuracy for remote sensing images. DUF-Net integrates two key modules: Character Refinement (CR) and Weight Mapping (WM). CR optimizes spatial feature distribution by overcoming convolutional limitations and enriches image detail representation. WM dynamically redistributes channel and spatial semantic information through interactive fusion of multi-channel and multi-scale features. Results on RESIC45, UC Merced, and RSSCN7 datasets demonstrate DUF-Net’s great feature sampling and matching capabilities, highlighting the advantages of 2D CNNs in feature computation.},
  archive      = {J_ESWA},
  author       = {Shilin Chen and Xingwang Wang and Xiaohui Wei and Yafeng Sun and Kun Yang},
  doi          = {10.1016/j.eswa.2025.128743},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128743},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deeply understanding features to achieve efficient remote sensing image classification},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Many-objective optimization of harmonic-polluted power distribution network based on fuzzy ranking. <em>ESWA</em>, <em>295</em>, 128702. (<a href='https://doi.org/10.1016/j.eswa.2025.128702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfiguring power distribution networks under harmonic load conditions presents a complex many-objective optimization challenge, where most objectives conflict. In high-dimensional objective spaces, population-based algorithms relying on Pareto dominance experience reduced selection pressure, limiting their reconfiguration effectiveness. To address this limitation, this paper introduces a fuzzy extension of Pareto dominance that enables more flexible comparison among solutions. By incorporating a tunable superiority threshold and nested dominance conditions between two individuals, the proposed method enhances selection pressure while maintaining compatibility with Pareto dominance. This adaptive approach allows for finer discrimination among mutually non-dominant solutions throughout the optimization process. The fuzzy dominance mechanism was embedded into two optimization algorithms-MOEAIGDNS and ToP-and evaluated using standard DTLZ and MaF benchmark problems and two customized distribution network scenarios with harmonic loads. Performance was measured using Hypervolume and Spacing indicators and statistically validated with the Mann-Whitney U test. Experimental results demonstrate that the proposed fuzzy dominance approach significantly improves optimization performance. Notably, ToP showed improvements in 84 % of the cases based on Spacing, while MOEAIGDNS achieved superior Hypervolume results in 100 % of the cases. Moreover, statistical analysis revealed that MOEAIGDNS with fuzzy dominance failed in only 2 % of all tests, underscoring the method’s robustness. These results highlight the potential of fuzzy dominance to enhance many-objective optimization in complex, real-world applications.},
  archive      = {J_ESWA},
  author       = {Mahdi Soltani-Nejad and Sayed Mohammad Mousavi Gazafrudi and Hossein Nezamabadi-Pour},
  doi          = {10.1016/j.eswa.2025.128702},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128702},
  shortjournal = {Expert Syst. Appl.},
  title        = {Many-objective optimization of harmonic-polluted power distribution network based on fuzzy ranking},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). In the beginning was the word: LLM-VaR and LLM-ES. <em>ESWA</em>, <em>295</em>, 128676. (<a href='https://doi.org/10.1016/j.eswa.2025.128676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces LLM-VaR and LLM-ES , novel risk estimation metrics that utilize general-purpose large language models (LLMs) for the forecasting tasks of Value at Risk (VaR) and Expected Shortfall (ES) in a zero-shot setting. Building on the input encoding mechanism of the LLMTime framework, we extend its application by defining new financial risk measures and performing an empirical evaluation of three generations of GPT models, GPT-3.5, GPT-4 and GPT-4o, versus advanced benchmark models such as GARCH with Student innovations and EWMA with Dynamic Conditional Score (DCS). Financial time series are encoded as numerical strings, allowing for model-free inference without requiring retraining. Results show that LLMs perform well when short rolling windows are used, particularly in volatile markets like cryptocurrencies. GPT-3.5 frequently outperforms or matches the performance of newer models, raising questions about model complexity, alignment, and biases. In contrast, performance deteriorates with longer windows, where the econometric models prove more reliable. Our findings demonstrate the potential of general-purpose LLMs as adaptive tools for short-horizon financial risk assessment and contribute a first-of-its-kind benchmark for LLM-based VaR/ES estimation.},
  archive      = {J_ESWA},
  author       = {Daniel Traian Pele and Vlad Bolovăneanu and Min-Bin Lin and Rui Ren and Andrei Theodor Ginavar and Bruno Spilak and Alexandru-Victor Andrei and Filip-Mihai Toma and Stefan Lessmann and Wolfgang Karl Härdle},
  doi          = {10.1016/j.eswa.2025.128676},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128676},
  shortjournal = {Expert Syst. Appl.},
  title        = {In the beginning was the word: LLM-VaR and LLM-ES},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Urban-scale point cloud semantic segmentation via integrated mixed-scale and long-range interactions. <em>ESWA</em>, <em>295</em>, 128666. (<a href='https://doi.org/10.1016/j.eswa.2025.128666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud semantic segmentation is essential for understanding complex urban-scale scenes, with applications in urban planning, intelligent transportation, and infrastructure management. However, existing methods struggle with large-scale urban scenes due to the significant variation in object sizes, complex structures, and data volumes, often neglecting small-scale objects. These methods face challenges in capturing the features of small-scale objects and propagating them effectively through the network due to a lack of cross-scale feature interaction. To address these issues, we propose a novel urban point cloud segmentation network that integrates multi-scale and long-range interactions. Our network introduces a Mixed-Scale Channel Interaction (MSCI) module to generate scale-aware query features by performing channel-wise grouping fusion of different scale features. Through grouped convolution, the network learns the scale information of each point and generates a scale-aware attention map. This attention map enhances the scale representation of features, allowing the network to focus more effectively on critical scale features, thereby improving attention to small-scale objects while maintaining semantic consistency for large-scale objects. The bidirectional KNN-Transformer module uses scale-aware query features as a bridge, employing K-nearest neighbor neighborhood selection and a local cross-attention mechanism to achieve long-range contextual fusion of local and multi-scale features, enabling dynamic interaction between encoder, decoder, and multi-scale features. Experimental results show that the proposed method achieves mIOU scores of 65.5 %, 84.0 %, and 61.4 % on urban-scale datasets such as SansetUrban, Toronto3D, and WHU-ALS, respectively, which demonstrates the potential of Mixed-Scale Long-Range Network (MSLR-Net) in handling complex, multi-scale urban point cloud data for improved semantic segmentation.},
  archive      = {J_ESWA},
  author       = {Zhenzhen Song and Zheng Liu and Yongyang Xu and Mingqiang Guo and Liang Wu and Heng Liu},
  doi          = {10.1016/j.eswa.2025.128666},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Urban-scale point cloud semantic segmentation via integrated mixed-scale and long-range interactions},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anomaly detection method for satellite networks based on genetic optimization federated learning. <em>ESWA</em>, <em>295</em>, 128627. (<a href='https://doi.org/10.1016/j.eswa.2025.128627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite networks are integral to global communications, however, they are increasingly targeted by sophisticated cyber-attacks due to their open-channel nature. Existing machine learning-based anomaly detection methods often fail to jointly model the spatial and temporal dependencies in traffic data, while traditional federated learning approaches suffer from inefficient client selection and privacy vulnerabilities. To address these challenges, this paper proposes FLOGA-AD, a novel federated anomaly detection framework for satellite networks, enhanced with a genetic algorithm for intelligent client selection. The model integrates a hybrid deep learning architecture that combines Convolutional Vision Transformer (CvT) for spatial feature extraction and Long Short-Term Memory (LSTM) for temporal modeling. To ensure both performance and privacy, the system incorporates Differential Privacy and Secure Aggregation during model updates. Extensive experimental evaluations conducted on the UNSW-NB15 and STIN datasets demonstrate that FLOGA-AD achieves performance improvements of 3 % and 5 %, respectively, over the state-of-the-art deep federated detection framework (DFL-TD). The proposed method effectively enhances anomaly detection accuracy while maintaining rigorous privacy guarantees and significantly reducing both communication bandwidth and computational resource requirements.},
  archive      = {J_ESWA},
  author       = {Zhimin Wang and Jinhui Cao and Xiaoqiang Di},
  doi          = {10.1016/j.eswa.2025.128627},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anomaly detection method for satellite networks based on genetic optimization federated learning},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The dialects gap: A multi-task learning approach for enhancing hate speech detection in arabic dialects. <em>ESWA</em>, <em>295</em>, 128584. (<a href='https://doi.org/10.1016/j.eswa.2025.128584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech is a complex and often debated concept within Arabic dialects. Handling and detecting hate speech in Arabic poses unique challenges due to the diverse dialects that exhibit several linguistic variations, whether in meaning or context. Previous studies have often used multiple Arabic dialects combined within a single corpus without specifying the dialects used, which is problematic because it can lead to misidentification of hateful and non-hateful contexts related to a particular dialect. This research therefore aims to address the challenge of dialectal variation ambiguity, which has led to polarity misidentification in previous studies that often fail to distinguish between contexts or terms that have the same form and carry different meanings across different Arabic dialects. In this paper, we propose a multi-task learning approach built upon transformer architecture to bridge this gap in hate speech detection across Arabic dialects. Using publicly available datasets from various dialects, the proposed model is designed to identify and distinguish subtle hate speech patterns and use shared representation knowledge across five Arabic dialects: Egyptian, Saudi, Levant, Gulf, and Algerian. To the best of our knowledge, it is the first model to simultaneously address multiple dialects and recognize hate speech by using the distinctive characteristics of each dialect. Our findings show that the proposed model makes a significant contribution to advancing hate speech detection in the Arabic language, surpassing single-task models. It achieved F1 scores of 0.98, 0.84, 0.85, 0.76, and 0.80 for the respective dialects of Egyptian, Levant, Saudi, Algerian, and Gulf, representing overall improvements of 14% compared to previous research. These results showcase the effectiveness of our approach, demonstrating not only high performance but also an accurate understanding of dialect-specific hate speech.},
  archive      = {J_ESWA},
  author       = {Mahmoud Mohamed Abdelsamie and Shahira Shaaban Azab and Hesham A. Hefny},
  doi          = {10.1016/j.eswa.2025.128584},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128584},
  shortjournal = {Expert Syst. Appl.},
  title        = {The dialects gap: A multi-task learning approach for enhancing hate speech detection in arabic dialects},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sequential three-way decision with adaptive thresholds and its applications in two binary classifiers. <em>ESWA</em>, <em>295</em>, 128194. (<a href='https://doi.org/10.1016/j.eswa.2025.128194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper proposes a new formal model of sequential three-way decision (S3WD) that captures the sequential trisecting decision process on unlabeled hybrid information tables. Based on relatively quantitative evaluation method, the proposed S3WD has a multilevel and dynamic-clustering structure with adaptive thresholds in each level. We build the theoretical foundation of S3WD through the probabilities of each object’s being in the sequential positive, negative and boundary regions. Two binary classifiers, namely the sequential three-way classifier based on positive region and the one based on negative region, are constructed by concisely combining classical rough set with S3WD where the former conducts concept analysis on labeled training set and the latter conducts sequential decisions on unlabeled testing set. Experiments on real data verify the validity of the algorithm proposed in this paper, explore the relationship between the related parameter and classification accuracy, and show the superior performance of the proposed classifiers for binary classification tasks. Therefore, our approach enriches the theoretical contents of S3WD and has a promising application in binary classification in machine learning.},
  archive      = {J_ESWA},
  author       = {Wenyan Xu and Shanshan Ai and Hailong Yang},
  doi          = {10.1016/j.eswa.2025.128194},
  journal      = {Expert Systems with Applications},
  month        = {1},
  pages        = {128194},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sequential three-way decision with adaptive thresholds and its applications in two binary classifiers},
  volume       = {295},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
