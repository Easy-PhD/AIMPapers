<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KBS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kbs">KBS - 1703</h2>
<ul>
<li><details>
<summary>
(2025). BGICR: Bootstrap-guided iterative clustering refinement for enhanced high-dimensional psychological data analysis. <em>KBS</em>, <em>330</em>, 114724. (<a href='https://doi.org/10.1016/j.knosys.2025.114724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional psychological data poses challenges due to noise, overlap, and projection distortion. This study presents Bootstrap-Guided Iterative Clustering Refinement (BGICR), a new framework developed to improve clustering in reduced-dimensional spaces. The proposed method uses silhouette-guided filtering and bootstrap sampling to iteratively remove ambiguous points through structural denoising, and it monitors validation scores until convergence. We used real-world psychological assessment data and applied four dimensionality reduction techniques: t-distributed stochastic neighbour embedding, uniform manifold approximation and projection, isometric mapping, and kernel principal component analysis. Results showed that BGICR consistently outperformed conventional clustering pipelines, with uniform manifold approximation and projection yielding the most distinct and well-separated clusters. Through adaptive iterations, the refinement improved the silhouette score to 0.7405, reduced the Davies–Bouldin index to 0.3914, increased the Calinski–Harabasz score to 3755.08, and achieved a Dunn index of 0.7689. Additional validation on synthetic data (Two-Moons) and biomedical datasets (LC25000 histopathological images) confirmed improved clustering quality with stable convergence and efficient runtime. Taken together, these results establish BGICR as a statistically grounded, noise-sensitive, and generalizable method for high-dimensional data analysis across psychological, synthetic, and biomedical domains.},
  archive      = {J_KBS},
  author       = {Khoula Al. Abri and Manjit Singh Sidhu and Faridah Hani Mohamed Salleh},
  doi          = {10.1016/j.knosys.2025.114724},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114724},
  shortjournal = {Knowl. Based Syst.},
  title        = {BGICR: Bootstrap-guided iterative clustering refinement for enhanced high-dimensional psychological data analysis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple yet effective difficulty-aware bucketed fine-tuning strategy for LLM-based recommendation. <em>KBS</em>, <em>330</em>, 114655. (<a href='https://doi.org/10.1016/j.knosys.2025.114655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems have been widely researched and applied in the industry. Recently, with the advancement of large language models (LLMs), there has been much research on LLM-based recommendation models (LLM-RMs), yielding outstanding performance compared with traditional recommendation models. In many LLM-RMs, supervised fine-tuning plays a pivotal role in enhancing model performance. However, existing research primarily focuses on enriching the information of the fine-tuning data, to enable LLMs to learn specific capabilities effectively. In this paper, we study the fine-tuning for LLM-RMs from a different perspective. Specifically, we propose a Difficulty-aware Bucketed Fine-tuning (DBF) strategy to replace the random sampling approach commonly used in existing research. The main philosophy of the proposed DBF strategy is to fine-tune an LLM from easy samples to difficult samples, which simulates the progressive learning process of humans. First, we propose a metric to measure the difficulty of fine-tuning samples based on three aspects: category entropy, category consistency, and category similarity. Based on the proposed metric, we design the bucketed tuning strategy that considers both intra-bucket and inter-bucket difficulty. In addition, we propose a Coarse-to-fine-grained Prompting LLM-based Recommendation Model, CP4Rec, which adopts a two-step reasoning process for making recommendations. We conduct extensive experiments on four real-world benchmark datasets, and results demonstrate that CP4Rec, fine-tuned with the proposed DBF strategy, outperforms the state-of-the-art LLM-RMs across these datasets. Experimental results also highlight the importance of using the buckets in the fine-tuning process to prevent performance degradation. The implementation code is available at https://anonymous.4open.science/r/CP4Rec1 .},
  archive      = {J_KBS},
  author       = {Qianyang Zhu and Bo Yang and Wei Liu and Jiajin Wu},
  doi          = {10.1016/j.knosys.2025.114655},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114655},
  shortjournal = {Knowl. Based Syst.},
  title        = {A simple yet effective difficulty-aware bucketed fine-tuning strategy for LLM-based recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing security in IoT-based photovoltaic monitoring with hybrid key management and deep learning optimized routing. <em>KBS</em>, <em>330</em>, 114652. (<a href='https://doi.org/10.1016/j.knosys.2025.114652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modern power infrastructure faces significant challenges in ensuring reliable and efficient electricity delivery amid rapidly increasing demand across various sectors. This research proposes an Internet of Things (IoT)-based smart grid system integrating Shuffled Frog Leaping Algorithm Optimized Recurrent Neural Network (SFLA-RNN) routing protocol to find the shortest route to reach end user, with Hybrid Paillier Improved Blow Fish (HPIBF) algorithm for key management, adding an extra degree of data protection. The system’s operational status is visualized using the Adafruit IoT dashboard. The validation of developed system is examined using NS2 software and the outcomes reveals superior results with improved Packet Delivery Ratio (PDR) of 98.95%, reduced consumption of energy to 0.024 mJ (100 nodes), longer network lifetime up to 3881 rounds (500 nodes) and minimized latency to 1.6–4.1 s compared to state of art topologies. Moreover, the proposed HPIBF approach achieves encryption and decryption times of 15 ms and 0.35 ms, respectively, outperforming existing algorithms. This confirms that the proposed research on IoT-based monitoring systems lowers operating expenses by improving energy efficiency through the reduction of power loss during transmission and distribution.},
  archive      = {J_KBS},
  author       = {P. Saranya and R. Rajesh},
  doi          = {10.1016/j.knosys.2025.114652},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114652},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing security in IoT-based photovoltaic monitoring with hybrid key management and deep learning optimized routing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained label propagation via density-based prototype matching for cross-subject EEG emotion recognition. <em>KBS</em>, <em>330</em>, 114650. (<a href='https://doi.org/10.1016/j.knosys.2025.114650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalography (EEG) signals has become a prominent research focus in affective computing. However, challenges such as individual differences and label noise have significantly impeded the generalization and accuracy of models. To address these challenges, this study proposes a novel fine-grained label propagation framework based on Density-Based Prototype Matching (DBPM). By leveraging density-based clustering to capture fine-grained subdomain structures, the framework enables robust prototype matching and reliable label propagation across domains. Furthermore, a Sequential Multi-Source Training Strategy is devised to progressively incorporate multiple source domains, thereby ensuring stable one-to-one prototype matching and mitigating inter-source interference. Extensive experiments are conducted on two publicly available EEG emotion datasets (SEED and SEED-IV) under a leave-one-subject-out cross-validation evaluation protocol. The results demonstrate that the proposed DBPM achieves state-of-the-art performance, offering a promising solution for addressing individual differences and label noise in EEG emotion recognition. The source code is publicly available at: https://github.com/qwangwl/DBPM},
  archive      = {J_KBS},
  author       = {Qiang Wang and Liying Yang and Qian Zhang and Jingtao Du and Yumeng Ye},
  doi          = {10.1016/j.knosys.2025.114650},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114650},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained label propagation via density-based prototype matching for cross-subject EEG emotion recognition},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Not all patches are crucial to image recognition: Window patch clustering attention for transformers. <em>KBS</em>, <em>330</em>, 114647. (<a href='https://doi.org/10.1016/j.knosys.2025.114647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (VIT) effectively captures global and local image features by connecting and facilitating information transfer between image patches, making it an essential tool in computer vision. However, its computational cost has been a major limiting factor for its application. To reduce the computational cost introduced by the attention mechanism in the transformer architecture, researchers have explored two approaches: reducing the number of patches involved in the computation and innovating attention mechanisms. Although these methods have improved efficiency, they require manual preprocessing and additional model training compared to VIT, which limits their flexibility. In this work, we propose an adaptive attention pattern for vision transformers that is easily implemented within transformer architecture, and we designed a novel window transformer architecture for various vision tasks without any preprocessing or additional model training. Our method can determine which patches participate in self-attention calculations based on the similarity of image patches in multidimensional space, thereby reducing the computational cost of these calculations. Experimental results show that our method is more effective, with fewer patches involved in the attention calculation compared to the window attention architectures that do not incorporate the proposed attention block. Furthermore, to better understand the relationship between the transformer architecture and the input patches, we investigated the impact of different patches in images on the performance of transformer-based networks. We found that for typical window transformer architecture networks, only a subset of patches is crucial for accurate object recognition, while other patches primarily contribute to the confidence of the predictions.},
  archive      = {J_KBS},
  author       = {Ruoyu Wu and Yue Wang and Dongguang Li and Jintao Liu},
  doi          = {10.1016/j.knosys.2025.114647},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114647},
  shortjournal = {Knowl. Based Syst.},
  title        = {Not all patches are crucial to image recognition: Window patch clustering attention for transformers},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse risk estimation and consistency-regulated unsupervised framework for efficient medical image denoising. <em>KBS</em>, <em>330</em>, 114646. (<a href='https://doi.org/10.1016/j.knosys.2025.114646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a high-efficiency unsupervised denoising framework designed for Gaussian noise reduction in medical imaging. The proposed model extends the deep image prior (DIP) model by replacing the conventional mean squared error (MSE) data fidelity term with an L1-norm-based Stein’s unbiased risk estimator (SURE). Due to the non-differentiability of the L1-norm, the model utilizes an L1-based Monte Carlo estimate to approximate the divergence term. The network takes observed noisy images as input, without requiring any ground-truth references. This study focuses on reconfiguring the SURE framework, representing more than a simple change in the error metric. It corresponds to a structural refinement in the formulation of unbiased risk estimation. The design retains fine structural details and substantially accelerates convergence compared to traditional MSE-SURE. Additionally, a dual path consistency-based stopping mechanism is introduced to prevent overfitting. Two identical DIP networks are trained in parallel with independently perturbed inputs. Although both target the same noisy image, their distinct trajectories are expected to converge only on meaningful structures. Training is halted once the SSIM between the two outputs begins to decrease after reaching a peak, indicating that the model is starting to overfit the noise. This unsupervised criterion provides a reliable and adaptive stopping rule without requiring clean references. Experimental results show that the model yields an average improvement of 9.3 % in PSNR and 20.9 % in SSIM over DIP. It also achieves peak performance with only one-tenth of the processing time required by DIP, demonstrating both high efficiency and effective denoising capability.},
  archive      = {J_KBS},
  author       = {Cheng Zhang and Kin Sam Yen},
  doi          = {10.1016/j.knosys.2025.114646},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114646},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sparse risk estimation and consistency-regulated unsupervised framework for efficient medical image denoising},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven deep learning approaches for computer vision tasks: A survey. <em>KBS</em>, <em>330</em>, 114645. (<a href='https://doi.org/10.1016/j.knosys.2025.114645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid artificial intelligence aims to integrate data-driven techniques with knowledge-based systems, offering a promising avenue to enhance artificial intelligence systems accuracy, interoperability, and explainability. Within this domain, neuro-symbolic artificial intelligence represents a sub-field focusing on merging specifically deep neural networks with knowledge-based systems for improved effectiveness. This paper provides a comprehensive overview of recent advancements in the field, specifically focusing on knowledge-driven training approaches for computer vision tasks where knowledge-based systems are deeply integrated into the deep neural networks training process. This integration takes advantage of structured domain knowledge to guide feature extraction. It improves robustness against noisy and incomplete data, allows more reliable and interpretable decision-making mechanisms, and facilitates better generalization in diverse and complex scenarios. These enhancements ultimately improve the overall performance of the neural networks. The presented approaches in this survey are categorized based on the integration level of knowledge within deep neural networks, including input integration, intermediate-level integration, and integration into the loss function. Additionally, the methodologies are sub-categorized based on the knowledge representation extracted from the knowledge-based systems before integration into the deep learning model. The integration methodology for each approach is highlighted to provide a comprehensive comparison between the different contributions. Through a survey of the literature, this paper identifies gaps in understanding the collaboration of knowledge-based systems and deep neural networks in the computer vision field. State-of-the-art approaches are analyzed and compared, evaluating their methodologies, integration knowledge strategy, and application domain. Our work also highlights the strengths and weaknesses of the approaches, discusses the challenges, and provides a critical review of their effectiveness. The paper concludes by exploring potential improvements and outlines future research directions to advance the integration of knowledge-based systems and deep neural networks.},
  archive      = {J_KBS},
  author       = {Fatima Ezzahra Benkirane and Nathan Crombez and Vincent Hilaire and Yassine Ruichek},
  doi          = {10.1016/j.knosys.2025.114645},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114645},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-driven deep learning approaches for computer vision tasks: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task SAR image processing via GAN-based unsupervised manipulation. <em>KBS</em>, <em>330</em>, 114644. (<a href='https://doi.org/10.1016/j.knosys.2025.114644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have shown tremendous potential in synthesizing realistic SAR images by learning patterns from data distribution. Some GANs can achieve image editing by introducing latent codes, demonstrating significant promise in SAR image processing. Compared to traditional SAR image processing methods, editing based on latent space is entirely unsupervised, allowing image processing to be conducted without any label. Additionally, the information extracted from the data is more interpretable. This paper proposes a novel SAR image processing framework called GAN-based Unsupervised Editing (GUE), aiming to address the following two issues: (1) disentangling semantic directions in GANs’ latent space and finding meaningful directions; (2) establishing a comprehensive SAR image processing framework. In the implementation of GUE, we decompose the entangled semantic directions in GANs’ latent space by training a carefully designed network. Moreover, it allows us to accomplish multiple SAR image processing tasks (including despeckling, auxiliary identification, and rotation editing) in a single training process without any form of supervision. Extensive experiments validate the effectiveness of our method.},
  archive      = {J_KBS},
  author       = {Xuran Hu and Mingzhe Zhu and Ziqiang Xu and Zhenpeng Feng and Haitao Yang and Ljubiša Stanković},
  doi          = {10.1016/j.knosys.2025.114644},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114644},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-task SAR image processing via GAN-based unsupervised manipulation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structured guided diffusion models for industrial defect image generation. <em>KBS</em>, <em>330</em>, 114642. (<a href='https://doi.org/10.1016/j.knosys.2025.114642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial defect images exhibit distinct characteristics from natural images, including severe class imbalance and structured similarity and diversity. Current defect image generation methods often lack fine-grained control over defect elements and suffer from limited diversity. This paper presents the Structured Guided Diffusion Model (Structured-GDM) for generating high-quality defect images with independent control over three structured elements: normal backgrounds, defect classes, and defect shapes. Controllability enables the generation of high-diversity defect images by preserving normal background outlines with detailed variation, specifying defect classes and shapes, and guiding the generation of reasonable (single or combined) defects using prior or expert knowledge. The structured architecture separates the training and use of elemental diffusion, classification, and segmentation models in a building-block manner, offering improved flexibility and maintainability. Additionally, a multiple-class training scheme is proposed to train overall models for one-for-all multiple-class defect generation, which exploits the inter-class similarity of defects and simplifies implementation. Extensive experiments on multiple MVTec and NEU-DET demonstrate that the method achieves superior performance in both image quality metrics and down-stream tasks, while maintaining high diversity and structured controllability.},
  archive      = {J_KBS},
  author       = {Yulai Xie and Xiaoning Pi and Yang Zhang and Fang Ren},
  doi          = {10.1016/j.knosys.2025.114642},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114642},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structured guided diffusion models for industrial defect image generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight image super-resolution with tokenized dynamic embedding network. <em>KBS</em>, <em>330</em>, 114640. (<a href='https://doi.org/10.1016/j.knosys.2025.114640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution is a crucial task in computer vision, aiming to reconstruct high-resolution images from low-resolution counterparts. Despite the remarkable progress of deep learning-based methods, existing approaches often face challenges in balancing reconstruction quality, computational efficiency, and model compactness. In this paper, we propose a novel tokenized dynamic embedding network, which integrates adaptive feature tokenization and dynamic embedding mechanisms to enhance super-resolution performance while maintaining efficiency. Specifically, we employ an adaptive feature tokenization strategy to selectively extract essential tokens, reducing computational complexity while preserving key image details. Additionally, we introduce a dynamic context embedding attention module for efficient long-range dependency modeling and a dual-perspective feature integration module for integrating spatial and contextual information, ensuring both fine-grained textures and global consistency. Extensive experiments on benchmark datasets demonstrate that our method outperforms state-of-the-art lightweight models in terms of objective metrics and perceptual quality, while maintaining a compact and efficient design suitable for real-world applications. The source code is available at https://github.com/zxycs/TDEN .},
  archive      = {J_KBS},
  author       = {Xiangyuan Zhu and Xuchong Liu and Zheng Wu},
  doi          = {10.1016/j.knosys.2025.114640},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114640},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lightweight image super-resolution with tokenized dynamic embedding network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-frequency aware network for camouflaged object detection with octave-transformer. <em>KBS</em>, <em>330</em>, 114638. (<a href='https://doi.org/10.1016/j.knosys.2025.114638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to identify objects that are fully blended into their surrounding environments. Current mainstream COD methods primarily focus on pixel-level optimization using convolutional neural networks (CNNs), without sufficiently addressing the significance of frequency interactions between candidate targets and noisy backgrounds, which are crucial for obtaining accurate edge and localization information. This paper explores the integration of multi-frequency features, and constructs a cross-frequency aware network (CFANet). The proposed network utilizes precisely learned deep-layer low-frequency features to guide other layers, achieving coarse localization. To further refine segmentation, the network employs both Transformer and CNN structures to facilitate the interaction and optimization of high- and low-frequency features at local and global levels. The model adopts a localization-guided decoder structure (LGS) that allows deep-layer low-frequency features to play a key role in guiding localization. The discussion module (DM) comprises three feature extraction experts, who engage in a teacher-student learning framework to derive more accurate deep-layer low-frequency features. In the Octave-Transformer module (OTM), the high- and low-frequency fused features based on octave convolution (OctConv) and Transformer deeply mine semantic features and detailed information. Compared to 33 existing state-of-the-art COD methods, the proposed network achieves overall superior performance across four benchmark datasets. Additionally, the network demonstrates excellent performance in other downstream tasks, such as polyp segmentation, surface defect detection. Our code is available at https://github.com/wkkwll-df/CFANet .},
  archive      = {J_KBS},
  author       = {Feng Dong and Jinchao Zhu and Hongpeng Wang},
  doi          = {10.1016/j.knosys.2025.114638},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114638},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-frequency aware network for camouflaged object detection with octave-transformer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-rank corrected multi-head self attention for image super resolution. <em>KBS</em>, <em>330</em>, 114637. (<a href='https://doi.org/10.1016/j.knosys.2025.114637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Transformer-based methods have shown impressive performance in image super resolution (SR) tasks, by exploiting multi-head self attention (MSA) to capture long-range dependencies between pixels. Unfortunately, there is a low-rank bottleneck in existing Transformer-based SR methods, which limits SR performance. We demonstrate that this is because the attention map in MSA is restricted to using more non-zero singular values to make stable representation. Increasing the projection dimension of MSA can eliminate the low-rank bottleneck, but results in overwhelming computational burden. Furthermore, we observe that the attention maps of different heads in MSA exhibit both information redundancy and complementarity. Based on these findings, we propose High-Rank Corrected Multi-Head Self-Attention (HR-MSA) to capture precise dependency information by high-rank attention maps without introducing additional computational burden. Our HR-MSA first utilizes the complete information of each pixel to compute an unabridged high-rank dependency. Then it independently applies linear corrections to different heads and achieves a high-rank weighted pixel information. Building around HR-MSA, we design a new architecture called High-Rank Attention for Super Resolution (HiRA-SR). Specifically, We develop Focusing Block (FB) to divert local pixel information from the HR-MSA module and introduce Residual Multi-Head Contextual Block (RMCB) to integrate global information through non-local attention. Experiments demonstrate that our HR-MSA can replace MSA and achieve efficient and effective improvements across various state-of-the-art SR methods. With parameters and FLOPs similar to SwinIR-light, our HiRA-SR sets a new state-of-the-art for lightweight image super-resolution. Our code will be available at: https://github.com/yyexplorerNB/HiRA-SR .},
  archive      = {J_KBS},
  author       = {Ying Yuan and Zihao Ren and Yajun Qiu and Bin Sun and Shihao Kou and Caiwen Jiang and Tianliang Zhang},
  doi          = {10.1016/j.knosys.2025.114637},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114637},
  shortjournal = {Knowl. Based Syst.},
  title        = {High-rank corrected multi-head self attention for image super resolution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PricoMS: Prior-coordinated multiscale synthesis network for self-supervised–aided vessel segmentation in intravascular ultrasound image amidst label scarcity. <em>KBS</em>, <em>330</em>, 114636. (<a href='https://doi.org/10.1016/j.knosys.2025.114636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intravascular ultrasound (IVUS) imaging is invaluable in aiding diagnosis and intervention of coronary artery disease. However its use is limited because of the increased time needed to segment the IVUS images and accurately quantify plaque burden, and lesion severity. To overcome this limitation we present a prior-coordinated multiscale synthesis network (PricoMS) for segmenting IVUS images under the condition of label scarcity. This network integrates a prior coherence paradigm (PCP), which enhances structural synthesis by maintaining consistency across scales, and a hierarchical contextual synthesis (HCS) module, which facilitates the integration of contextual information for better spatial understanding. To address the challenge of label scarcity in IVUS data, a prior encoder repeatedly utilizes unlabeled IVUS images for training, providing prior features of the images for segmentation tasks. Additionally, this network employs an adaptive morphological fusion-contextual space encoding (AMF-CSE) module to capture multi-scale and contextual data, thereby bolstering the modelâ€ ™s capability to discern intricate vascular features even in challenging areas with suboptimal quality and imaging artifacts such as electronic noise, speckle noise, motion artifacts, and acoustic scattering. PricoMS exhibits robust performance, achieving a Dice score of 95.2% for detecting the lumen border and 84.0% for detecting the external elastic membrane (EEM) border, surpassing many existing techniques. The source code is publicly accessible at: https://github.com/IMOP-lab/PricoMS-Pytorch .},
  archive      = {J_KBS},
  author       = {Xingru Huang and Huawei Wang and Shuaibin Chen and Shaowei Jiang and Retesh Bajaj and Nathan Angelo Lecaros Yap and Murat Cap and Xiaoshuai Zhang and Xingwei He and Anantharaman Ramasamy and Ryo Torii and Jouke Dijkstra and Huiyu Zhou and Christos V. Bourantas and Qianni Zhang},
  doi          = {10.1016/j.knosys.2025.114636},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114636},
  shortjournal = {Knowl. Based Syst.},
  title        = {PricoMS: Prior-coordinated multiscale synthesis network for self-supervised–aided vessel segmentation in intravascular ultrasound image amidst label scarcity},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-generated content in cross-domain applications: Research trends, challenges and propositions. <em>KBS</em>, <em>330</em>, 114634. (<a href='https://doi.org/10.1016/j.knosys.2025.114634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the capability to generate different forms of content, including text, images, videos, and other modalities, which can achieve a quality similar to content created by humans. As a result, AIGC is now widely applied across various domains such as digital marketing, education, and public health, and has shown promising results by enhancing content creation efficiency and improving information delivery. However, there are few studies that explore the latest progress and emerging challenges of AIGC across different domains. To bridge this gap, this paper brings together 16 scholars from multiple disciplines to provide a cross-domain perspective on the trends and challenges of AIGC. Specifically, the contributions of this paper are threefold: (1) It first provides a broader overview of AIGC, spanning the training techniques of Generative AI, detection methods, and both the spread and use of AI-generated content across digital platforms. (2) It then introduces the societal impacts of AIGC across diverse domains, along with a review of existing methods employed in these contexts. (3) Finally, it discusses the key technical challenges and presents research propositions to guide future work. Through these contributions, this vision paper seeks to offer readers a cross-domain perspective on AIGC, providing insights into its current research trends, ongoing challenges, and future directions.},
  archive      = {J_KBS},
  author       = {Jianxin Li and Liang Qu and Taotao Cai and Zhixue Zhao and Nur Al Hasan Haldar and Aneesh Krishna and Xiangjie Kong and Flavio Romero Macau and Tanmoy Chakraborty and Aniket Deroy and Binshan Lin and Karen Blackmore and Nasimul Noman and Jingxian Cheng and Ningning Cui and Jianliang Xu},
  doi          = {10.1016/j.knosys.2025.114634},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114634},
  shortjournal = {Knowl. Based Syst.},
  title        = {AI-generated content in cross-domain applications: Research trends, challenges and propositions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LQMF-RD: A lightweight quantum-driven multi-modal fusion framework for rumor detection. <em>KBS</em>, <em>330</em>, 114633. (<a href='https://doi.org/10.1016/j.knosys.2025.114633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, automated rumor detection has garnered significant attention. Despite notable progress in multi-modal modeling for social media rumor detection, two major challenges remain: (1) the dynamic characteristics of social networks during the propagation process are often overlooked; (2) multi-modal features (such as text, images, and propagation graphs), are often poorly aligned and lead to redundant model parameters. To address these issues, we propose LQMF-RD, a lightweight quantum-driven multi-modal feature fusion framework for rumor detection. First, to capture the dynamic nature of rumor propagation, we design a Dynamic Graph Network (DGN) that leverages the spatiotemporal characteristics of propagation graph, effectively capturing both neighborhood dependencies and temporal evolution among nodes. Then, we employ amplitude encoding to project the extracted multi-modal features into a [ log 2 N ] -dimensional quantum state space. Finally, we construct a Lightweight Quantum-driven Multi-modal Fusion Network (LQMFN), which enables deep interaction and fusion of multi-modal features through quantum convolution and pooling operations. LQMFN updates only 0.01M parameters, substantially reducing computational complexity and storage overhead. Experimental results show that LQMF-RD not only delivers superior performance on rumor detection tasks, but also achieves high computational efficiency and strong robustness to quantum noise.},
  archive      = {J_KBS},
  author       = {Keliang Jia and Fanxu Meng and Ziwen Chen and Mengyao Du and Jing Liang},
  doi          = {10.1016/j.knosys.2025.114633},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114633},
  shortjournal = {Knowl. Based Syst.},
  title        = {LQMF-RD: A lightweight quantum-driven multi-modal fusion framework for rumor detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CGC-GS: Cross geometric cues constrained gaussian splatting. <em>KBS</em>, <em>330</em>, 114630. (<a href='https://doi.org/10.1016/j.knosys.2025.114630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planarized Gaussian representation, such as 2DGS, has shown great potential for geometry reconstruction. However, due to the lack of accurate geometric cues to evaluate the topology results and provide immediate feedback to the optimizer, they all fail to reconstruct the detailed geometry while maintaining high quality RGB rendering. This paper introduces the cross geometric cues that mixes the proposed scale-invariant monocular depth, confidence map-controlled normal prior and multi-view regularization consists of projection and photometric consistency to form the crossed constrain and evaluation of local topology in each optimization iteration, which results in more detailed geometric representation and perspective consistency. Moreover, a global density control strategy is proposed to correct the split standard and promote the homogeneous distribution of Gaussians in the whole scene, which benefits the high-frequency extraction ability and the removal of inappropriately large Gaussians. In experiments, the proposed method outperforms the baseline on overfitting and three datasets and achieves competitive results compared to other state-of-the-art (SOTA) methods. The relevant code will be be published at https://github.com/Zerui-Yu/CGC-GS .},
  archive      = {J_KBS},
  author       = {Zerui Yu and Zhidong Chen and Zhiheng Zhou and Hongkun Cao},
  doi          = {10.1016/j.knosys.2025.114630},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114630},
  shortjournal = {Knowl. Based Syst.},
  title        = {CGC-GS: Cross geometric cues constrained gaussian splatting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep concept subspace embedding for multi-view clustering. <em>KBS</em>, <em>330</em>, 114629. (<a href='https://doi.org/10.1016/j.knosys.2025.114629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multi-view clustering methods based on subspace learning have garnered increasing attention when dealing with high-dimensional data. However, traditional subspace learning methods mainly focus on the consistency between views, and cannot fully explore the deep semantic information, hierarchical structure, and non-linear correlations in the original data. To this end, we propose a novel deep concept subspace embedding (DCSE) method for multi-view clustering. In DCSE, (1) the deep concept factorization is employed to explore the deep semantic and hierarchical information within the raw data; (2) the manifold regularization is applied to the deep representation matrix of each layer to preserve local fine-grained geometric structures; (3) the centric graph regularization is applied to the deep representation matrix of the final layer to capture complex nonlinear structures; (4) the tensor subspaces are utilized to capture higher-order information. Finally, extensive experiments on eight real-world datasets underscore the effectiveness and superior performance of the proposed DCSE method. The code of DCSE is released at https://github.com/GuanghaoDu/DCSE .},
  archive      = {J_KBS},
  author       = {Guanghao Du and Peng Song and Beihua Yang},
  doi          = {10.1016/j.knosys.2025.114629},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114629},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep concept subspace embedding for multi-view clustering},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced magnetic resonance imaging feature extraction for precise brain tumor classification using dual deep convolutional networks. <em>KBS</em>, <em>330</em>, 114628. (<a href='https://doi.org/10.1016/j.knosys.2025.114628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise and reliable classification of brain tumors is a critical prerequisite for effective medical diagnostics and the development of targeted treatment strategies. The complex and diverse structures of brain tumors such as their texture, size, and appearance pose significant challenges for deep learning models, often reducing their accuracy in identifying tumors from magnetic resonance imaging scans. To tackle this challenge, we introduce the Dual Deep Convolutional Brain Tumor Network, which combines a pre-trained Visual Geometry Group 19 model with a custom-designed Convolutional Neural Network to extract both fine-grained and high-level tumor features. By combining these complementary feature sets, the model enhances classification accuracy and robustness, providing a comprehensive understanding of the complex brain tumor landscape. The model’s effectiveness was validated through 10-fold cross-validation using the Kaggle brain tumor classification dataset, encompassing glioma, no tumor, meningioma, and pituitary categories. Experimental findings reveal that our model surpasses existing techniques, attaining 98.81 % accuracy, 97.69 % precision, 97.75 % recall, 99.18 % specificity, and an F1-score of 97.70 %. These results confirm that the integrated model provides a reliable and accurate solution for brain tumor classification, with significant implications for clinical diagnostics and treatment planning.},
  archive      = {J_KBS},
  author       = {Denis Bernard and Constantino Msigwa and Jaeseok Yun},
  doi          = {10.1016/j.knosys.2025.114628},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114628},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced magnetic resonance imaging feature extraction for precise brain tumor classification using dual deep convolutional networks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinated LLM multi-agent systems for collaborative question-answer generation. <em>KBS</em>, <em>330</em>, 114627. (<a href='https://doi.org/10.1016/j.knosys.2025.114627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) excel at generating coherent and human-like questions and answers (QAs) across various topics, which can be utilized in various applications. However, their performance may be limited in domain-specific knowledge outside their training data, potentially resulting in low context recall or factual inconsistencies. This is particularly true in highly technical or specialized domains that require deep comprehension and reasoning beyond surface-level content. To address this, we propose C ollective I ntentional R eading through R eflection and R efinement ( CIR3 ), a novel multi-agent framework that leverages collective intelligence for high quality Question-Answer Generation (QAG) from domain-specific documents. CIR3 employs a transactive reasoning mechanism to facilitate efficient communication and information flow among agents. This enables for in-depth document analysis and the generation of comprehensive and faithful QAs. Additionally, multi-perspective assessment ensures that QAs are evaluated from various viewpoints, enhancing their quality and relevance. A balanced collective convergence process is employed to ensure that the agents reach a consensus on the generated QAs, preventing inconsistencies and improving overall coherence. Our experiments indicate a substantial level of alignment between the CIR3-generated QAs and corresponding documents, while improving comprehensiveness by 23 % and faithfulness by 17 % compared to strong baseline approaches. Code and data are available at https://github.com/anonym-nlp-ai/cirrr .},
  archive      = {J_KBS},
  author       = {Sami Saadaoui and Eduardo Alonso},
  doi          = {10.1016/j.knosys.2025.114627},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114627},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coordinated LLM multi-agent systems for collaborative question-answer generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical matching using autoencoders-canonical correlation analysis, kernel canonical correlation analysis and multi-output multilayer perceptron. <em>KBS</em>, <em>330</em>, 114626. (<a href='https://doi.org/10.1016/j.knosys.2025.114626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lot of data are gathered every day, whether via surveys or other sources. For many people, the need for variables from different data sources is a key factor and leads to the need of methods to combine them. A recognized practice to combine data sets in this field is statistical matching. In this paper, we investigate and extend to statistical matching an Autoencoders-Canonical Correlation Analysis (A-CCA). A-CCA is an extension of KCCA, that reduces the need for kernels, with the added benefit of a dimensionality reduction. It can be regarded as an extension of Deep Canonical Correlation Analysis (DCCA), providing enhanced flexibility that makes it well suited for statistical matching. This method is designed to deal with various variable types, sampling weights and incompatibilities among categorical variables. We compare the performance of this method with other methods based on Kernel Canonical Correlation Analysis (KCCA) or Multi-output Multilayer Perceptron (MMLP), using 2017 Belgian Statistics on Income and Living Conditions (SILC). We divide this data set in two parts and we act as if they were coming from two different sources.},
  archive      = {J_KBS},
  author       = {Hugues Annoye and Alessandro Beretta and Cédric Heuchenne},
  doi          = {10.1016/j.knosys.2025.114626},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114626},
  shortjournal = {Knowl. Based Syst.},
  title        = {Statistical matching using autoencoders-canonical correlation analysis, kernel canonical correlation analysis and multi-output multilayer perceptron},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triple-view graph clustering network based on high-confidence contrastive learning strategy. <em>KBS</em>, <em>330</em>, 114625. (<a href='https://doi.org/10.1016/j.knosys.2025.114625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent contrastive deep clustering models have seen considerable success. However, many of these approaches often focus on distinguishing between nodes in two views for contrastive learning, which can pose significant difficulties when handling complex noisy nodes. Furthermore, numerous deep clustering models do not have a dependable framework for choosing positive and negative sample pairs. To tackle these challenges, we introduce the Triple-View Graph Clustering Network with a High-Confidence Contrastive Learning Strategy (TGCN-HCC). This model comprises two primary components. The first is a Triple-View fusion network that features parameter-shared Siamese encoders and a graph attention network, which produces semantically rich fused embeddings by combining embeddings from the three views. The second component is a self-supervised clustering module that utilizes high-confidence pseudo label screening. This module incorporates a loss function that uses high-confidence pseudo label to enhance the clustering process. Comprehensive experiments on five datasets indicate that our proposed model surpasses other clustering models in performance.},
  archive      = {J_KBS},
  author       = {Shifei Ding and Zhe Li and Xiao Xu and Lili Guo and Ling Ding},
  doi          = {10.1016/j.knosys.2025.114625},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114625},
  shortjournal = {Knowl. Based Syst.},
  title        = {Triple-view graph clustering network based on high-confidence contrastive learning strategy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSPCNF-net: Multi-scale parallel cross-neighborhood fusion network for medical image segmentation. <em>KBS</em>, <em>330</em>, 114624. (<a href='https://doi.org/10.1016/j.knosys.2025.114624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based architectures have emerged to deal with inherent limitations of CNNs in catching long-range dependencies for image analysis tasks. However, these approaches generally struggle to process both global and local context information simultaneously. Therefore, the paper establishes a novel dual encoder-decoder framework termed M ulti- S cale P arallel C ross- N eighborhood F usion Net work (MSPCNF-Net). It develops a dual-branch network to leverage CNN and Transformer components for acquiring local and global features at multiple scales. For optimizing this feature fusion from these dual-branch encoders, two specialized modules are designed, including the Bidirectional Window Perception Attention (BWPA) module and the Bidirectional Cross Attention (BCA) module. In addition, a Neighborhood Spatial Attention (NSA) module incorporating Gumbel-softmax is implemented by proximal pixels, which facilitates the processing of fine-grained local information and emphasizes key features with lower computational demands. Experiments are performed on four datasets with three distinct tasks including abdominal organ, cardiac organ, and retinal vessel segmentation, which indicate that MSPCNF-Net attains superior effectiveness compared to current well-known methods.},
  archive      = {J_KBS},
  author       = {Yugen Yi and Yu Duan and Xuan Wu and Hong Li and Siwei Luo and Jiangyan Dai and Xinping Rao and Yirui Jiang and Wei Zhou},
  doi          = {10.1016/j.knosys.2025.114624},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114624},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSPCNF-net: Multi-scale parallel cross-neighborhood fusion network for medical image segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operating condition invariant representation learning for machine prognostics. <em>KBS</em>, <em>330</em>, 114623. (<a href='https://doi.org/10.1016/j.knosys.2025.114623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring (CM) data can readily become complex as machines undergo continuous variations in operating conditions. This complexity poses a significant challenge to learning discriminative health-state representations. A standard solution to it is to incorporate operational parameters into learning framework, but doing so can be costly and often infeasible if such data are not available in practice. To this end, we propose a novel framework for learning health-state representations that are inherently invariant to changes in operating conditions-without relying on operational parameters. The core principle of our Operating Condition-Invariant Representation (OCIR) model is rooted in the intuition that learning to disentangle a factor of variation in data naturally leads to learning to encode representations that are invariant to the disentangled factor. We adopt an unsupervised generative model to disentangle operating condition factors at the observation level, thereby inducing invariance at the sequence level. Simultaneously, we leverage the generative model as a source of self-supervision and train a predictive model alongside it by enforcing cycle consistency in the transformation of knowledge between the two models. Experimental results demonstrate that the health-state representations learned through OCIR are highly competitive with those learned using operational parameters, while significantly outperforming methods that do not utilize such information. Additionally, we introduce a novel method for construction of virtually stationary trajectories directly from the raw CM data subject to varying operating conditions.},
  archive      = {J_KBS},
  author       = {Minjung Kim and Yusuke Hioka and Michael Witbrock},
  doi          = {10.1016/j.knosys.2025.114623},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114623},
  shortjournal = {Knowl. Based Syst.},
  title        = {Operating condition invariant representation learning for machine prognostics},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and incentivized federated learning for resilient telemedicine diagnostics. <em>KBS</em>, <em>330</em>, 114622. (<a href='https://doi.org/10.1016/j.knosys.2025.114622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telemedicine-based diabetic retinopathy (DR) screening requires solutions that ensure privacy, scalability, fairness, and auditability across distributed healthcare environments. This paper introduces a novel serverless federated learning (FL) framework that integrates deep learning (DL), secure multi-party computation (SMPC), blockchain (Hyperledger Fabric), the InterPlanetary File System (IPFS), and the Synthetic Minority Over-sampling Technique (SMOTE) to achieve accurate and privacy-preserving DR detection. Unlike traditional FL systems that rely on centralized aggregators, our design leverages blockchain for secure model orchestration, client incentives, and dynamic participation, while SMPC ensures data confidentiality without the utility loss associated with noise-based techniques like differential privacy (DP). Adaptive aggregation addresses client unavailability, and a robust on-chain statistical filter with drift detection mitigates model poisoning and concept drift. Experimental evaluation on the APTOS 2019 dataset (3,662 images, five-class classification) demonstrates state-of-the-art performance, achieving 90–92 % accuracy across 2–10 clients. Our approach significantly outperforms FL-BC-SMPC (92.50 % vs. 70.88 %, +21.62 %) and FL-BC-SMPC-DP (92.80 % vs. 52.18 %, +40.62 %, p < 0.001 ), with SMOTE improving minority class recall by 12 % and blockchain-driven incentives raising F1-score to 68.90 %. Additionally, blockchain supports 18.9 transactions per second with a maximum latency of 2.5 seconds, while IPFS reduces per-round storage from 64 GB to 100 KB (6.573 s/write), enabling efficient scalability. Compared to centralized benchmarks (e.g., FedCNN: 98 %, RSG-Net: 99.36 %), our framework offers a trade-off of 5–7 % in accuracy for substantial gains in privacy, decentralization, and regulatory compliance (GDPR/HIPAA). This work sets a new direction for secure, scalable, and equitable AI-driven diagnostics in global healthcare.},
  archive      = {J_KBS},
  author       = {Omar Dib},
  doi          = {10.1016/j.knosys.2025.114622},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114622},
  shortjournal = {Knowl. Based Syst.},
  title        = {Secure and incentivized federated learning for resilient telemedicine diagnostics},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging LIME explainability and gustafson-kessel fuzzy clustering for resume grouping and text summarization. <em>KBS</em>, <em>330</em>, 114621. (<a href='https://doi.org/10.1016/j.knosys.2025.114621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years a very large number of classification methods have been developed, which are now being referred to as “classical machine learning”. However, a noticeable gap remains in research linking unsupervised learning techniques with explainable artificial intelligence (XAI) methods. In this study, we address this gap by proposing a novel method to enhance the interpretability of unsupervised learning, particularly for textual data. We integrate XAI techniques with the Gustafson-Kessel (GK) fuzzy clustering algorithm to enhance the capture of semantic relationships in text, in particular, resumes for employment. Our approach leverages the light-weight Sentence-BERT model to generate contextual embeddings, that offer a deeper semantic understanding of resume data. These embeddings provide richer representations compared to traditional textual feature extraction methods. Similar resumes are clustered using the GK fuzzy clustering algorithm to identify common patterns across resumes. Subsequently, informative summaries are used for employment purposes, enhancing resume categorization and job matching. The GK algorithm, was chosen over others as it is especially effective at handling complex structures as compared to other clustering methods. In clustering practice, an evaluation of clustering quality is generally performed. In this work, we conduct statistical analysis, ablation studies, and assess performance using various clustering metrics. We also incorporate Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) to interpret the cluster memberships of individual resumes, thereby enhancing the transparency and trustworthiness of the clustering process. Our approach, when applied correctly, provides potential employers with clear and interpretable insights into how resumes are grouped. We present results on a resume data set that were summarized by our proposed method. The effective and interpretable clustering is shown in comparison with other clustering methods. The outcome is expected to improve the processing efficiency of applicant profiles and is helpful to human resource management.},
  archive      = {J_KBS},
  author       = {Ravi Mudavath and Atul Negi},
  doi          = {10.1016/j.knosys.2025.114621},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114621},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging LIME explainability and gustafson-kessel fuzzy clustering for resume grouping and text summarization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KDP-MHL: Key data point-aware multi-scale hypergraph learning framework for multivariate time series classification. <em>KBS</em>, <em>330</em>, 114620. (<a href='https://doi.org/10.1016/j.knosys.2025.114620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series Classification faces inherent challenges due to complex high-order temporal correlations among data points and redundant data that obscure discriminative patterns. Existing methods primarily focus on modeling local or pairwise interactions while ignoring the distinction between informative and redundant data points. To capture informative high-order relationships underlying multi-scale temporal patterns, we propose the Key Data Point-Aware Multi-Scale Hypergraph Learning Framework (KDP-MHL) with an encoder-decoder architecture based on hypergraph neural networks. Throughout the framework, we develop a Local-Enhanced Dynamic Hypergraph Propagation Layer that extracts local-enhanced node features for each data point and obtains multi-scale high-order temporal associations by constructing dynamic hypergraphs among multiple nodes. To reduce redundancy, a Key Data Point-Aware Module is designed in the encoder to calculate node importance based on high-order attribute features and retain the key data points. In the decoder, a Multiple Class Tokens Representation method is introduced to guide high-order interactions between multiple class tokens and key data point features through hypergraph structure, further aggregating class-specific information from selected key data points, thereby improving the representation capability. Extensive experiments on 24 UEA datasets demonstrate that our method achieves superior performance compared to state-of-the-art approaches, with 3% improvement in average accuracy.},
  archive      = {J_KBS},
  author       = {Nan Ma and Jiacheng Guo and Yajue Yang and Shuling Li and Zehao Wang and Yiheng Han},
  doi          = {10.1016/j.knosys.2025.114620},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114620},
  shortjournal = {Knowl. Based Syst.},
  title        = {KDP-MHL: Key data point-aware multi-scale hypergraph learning framework for multivariate time series classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining independent and joint spatial-angular information learning for light field image super-resolution. <em>KBS</em>, <em>330</em>, 114619. (<a href='https://doi.org/10.1016/j.knosys.2025.114619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light Field (LF) imaging can simultaneously record spatial and angular information of light rays, playing a significant role in applications such as digital refocusing and 3D reconstruction. Unfortunately, limited by the sensor size, LF images suffer from low spatial resolution while maintaining high angular sampling. Fully exploiting the inherent spatial-angular information of LF images is the key to achieving high-fidelity LF spatial super-resolution. However, current methods are not comprehensive enough in learning the spatial-angular information of LF images, which hinders the improvement of super-resolution performance. To this end, this study effectively combines independent and joint spatial-angular information learning through systematic domain partitioning, domain-specific modeling strategies, and novel modules designed for the characteristics of LF data. Specifically, a spatial dependency modeler and an angular dependency modeler are first designed to achieve spatial-angular independent learning, thus facilitating refined spatial and angular features extraction. Secondly, a sub-LF transformer and an epipolar plane image transformer are constructed to jointly learn spatial-angular correlations to achieve a more complete feature space exploration. Finally, a conditional feature generator and a condition-guided fusion module are introduced to adaptively fuse intermediate LF features according to the input content. The above three components constitute the basic spatial-angular information learning module. By stacking multiple basic modules, the proposed method can effectively exploit the intrinsic high-dimensional information of LF images, thereby reconstructing high-quality super-resolved LF images. Extensive experimental results on five benchmark datasets show that the proposed method outperforms the state-of-the-art methods in both objective quality and subjective visual aspects. Our code will be released in https://github.com/blackdajie/LF-CIJSANet .},
  archive      = {J_KBS},
  author       = {Dezhang Ke and Yeyao Chen and Chongchong Jin and Haiyong Xu and Zhidi Jiang and Ting Luo and Gangyi Jiang},
  doi          = {10.1016/j.knosys.2025.114619},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114619},
  shortjournal = {Knowl. Based Syst.},
  title        = {Combining independent and joint spatial-angular information learning for light field image super-resolution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamically interactable framework with dual-channel security: GAN-based speech steganography for concealed dialogues. <em>KBS</em>, <em>330</em>, 114618. (<a href='https://doi.org/10.1016/j.knosys.2025.114618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography is a technique that conceals secret messages in carriers to conceal communication behaviors. This paper builds a novel framework of spoken dialogue steganography to enhance the dynamic interaction process by hiding the communicator’s dialogues in other dialogues. In this framework, the dialogues of A and B will hide the dialogues of C and D. The cover speech of A and B is resistant to both main-channel and side-channel steganalysis. Furthermore, a speech steganography method using a GAN-based vocoder is proposed to be adaptable to different types of covers, which is called DialogStego . The method embeds the Mel spectrogram of the secret speech in the cover Mel spectrogram and generates high-quality stego speech using the vocoder. A specially designed decoder is utilized to extract the Mel spectrogram of the secret speech and reconstruct the secret speech with a pre-trained vocoder. Experimental results on typical vocoders HiFi-GAN and iSTFTNet show that generated stego speech and extracted secret speech achieve superior performance on quality and intelligibility. Moreover, security on side-channel steganalysis about content logic correctness and speaker consistency of the cover speech has been achieved. Security on main-channel steganalysis, which fails to distinguish stego speech from cover speech, has also been manifested for the proposed method. Additionally, the proposed method has been proven to hold a larger embedding capacity and faster efficiency than recently proposed baseline methods.},
  archive      = {J_KBS},
  author       = {Xiaoyi Ge and Xiongwei Zhang and Yihao Li and Meng Sun},
  doi          = {10.1016/j.knosys.2025.114618},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114618},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dynamically interactable framework with dual-channel security: GAN-based speech steganography for concealed dialogues},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JTA: Joint networks with tailored attention for speech depression detection. <em>KBS</em>, <em>330</em>, 114617. (<a href='https://doi.org/10.1016/j.knosys.2025.114617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, a prevalent mental disorder affecting approximately 5 % of adults globally, presents two critical yet under-addressed challenges in speech-based detection. The primary depressive speech features exhibit sporadic distribution and are inherently challenging to detect because patients often exhibit intermittent reticence, significantly impeding models’ ability to reliably extract clinically relevant features. The second critical challenge lies in depression severity assessment, i.e., the distinction between different levels of depression is unclear, and the detection of depression alone does not meet realistic medical needs. To address these challenges, we propose Joint Networks with Tailored Attention (JTA), i.e., a Spectrogram-Based model with Tailored Attention (STA), a pre-trained model (WavLM), and a Transactive Attention-based feature Fusion module (TAF). Specifically, we employ log-Mel spectrograms as STA inputs, introducing a Tailored Attention module ( T A 1 ) to suppress non-informative components while focusing on depression features. TAF hierarchically integrates representations from WavLM and STA through its Transactive Attention ( T A 2 ). Experiments on five challenge datasets (i.e., BioCAS2024, D 4 , DAIC-WOZ, E-DAIC, and D-vlog) illustrate the superior performance of JTA compared to SOTA methods in depression detection and depression level detection tasks. We perform interpretability analysis on JTA to visualize high-impact biomarkers, enabling clinicians to understand and validate model decisions more precisely.},
  archive      = {J_KBS},
  author       = {Xin-Heng Li and Zhen-Tao Liu and Chen-Ling Liu and Bao-Liang Zhong and Jing Chen and Jinhua She and Kaoru Hirota},
  doi          = {10.1016/j.knosys.2025.114617},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114617},
  shortjournal = {Knowl. Based Syst.},
  title        = {JTA: Joint networks with tailored attention for speech depression detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-discipline cold-start knowledge tracing via overlapping entities and contrastive learning. <em>KBS</em>, <em>330</em>, 114616. (<a href='https://doi.org/10.1016/j.knosys.2025.114616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing is one of the key tasks of major personalized education platforms. It captures changes in students’ knowledge states and predicts their future performance by exploring their practical activities in their current discipline. Most existing knowledge tracing methods model students’ knowledge state in a single discipline, due to knowledge feature gap among different disciplines, these models are not domain-adaptive, and often encounter cold-start bottlenecks when assessing students’ performance in new disciplines. To overcome this hurdle, we propose a cross-disciplinary framework for cold-start knowledge tracing, called OCLCKT. We adopt parallel parameter-independent discipline knowledge state retrievers to extract overlapping students’ source and target discipline knowledge states, and utilize cross-discipline mapping networks to learn the transfer relationship between source and target knowledge states. Meanwhile, to alleviate the negative transfer effect, we design a pre-training network with a feature complementation method to obtain more robust knowledge states. In addition, discipline-level contrastive learning methods are designed to collaboratively cross-domain loss in constraining and optimizing the model, thereby more accurately capturing and modeling cross-discipline knowledge state transfer relationships. Finally, we conducted extensive experiments on several large-scale real-world datasets. The framework’s performance is effectively demonstrated in multiple cold-start educational scenarios.},
  archive      = {J_KBS},
  author       = {Yulong Deng and Zheng Guan and Min He and Xue Wang and Jie Liu and Zheng Li and Zhijun Yang},
  doi          = {10.1016/j.knosys.2025.114616},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114616},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-discipline cold-start knowledge tracing via overlapping entities and contrastive learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNGT: Ultrasound nasogastric tube dataset for medical image analysis. <em>KBS</em>, <em>330</em>, 114615. (<a href='https://doi.org/10.1016/j.knosys.2025.114615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel ultrasound nasogastric tube (UNGT) dataset to address the lack of public nasogastric tube datasets. The UNGT dataset includes 493 images gathered from 110 patients with an average image resolution of approximately 879 × 583. Four structures, encompassing the liver, stomach, tube, and pancreas, are precisely annotated. Besides, we propose a semi-supervised adaptive-weighting aggregation medical segmenter to address data limitation and imbalance concurrently. The introduced adaptive weighting approach tackles the severe unbalanced challenge by regulating the loss across varying categories as training proceeds. The presented multiscale attention aggregation block bolsters the feature representation by integrating local and global contextual information. With these, the proposed AAMS can emphasize sparse or small structures and feature enhanced representation ability. We perform extensive segmentation experiments on our UNGT dataset, and the results show that AAMS outperforms existing state-of-the-art approaches to varying extents. In addition, we conduct comprehensive classification experiments across varying state-of-the-art methods and compare their performance. The dataset and code are available at https://github.com/NUS-Tim/UNGT .},
  archive      = {J_KBS},
  author       = {Zhaoshan Liu and Chau Hung Lee and Qiujie Lv and Nicole Kessa Wee and Lei Shen},
  doi          = {10.1016/j.knosys.2025.114615},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114615},
  shortjournal = {Knowl. Based Syst.},
  title        = {UNGT: Ultrasound nasogastric tube dataset for medical image analysis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-scale quadratic convolutional network for bearing fault diagnosis: Handling noisy conditions. <em>KBS</em>, <em>330</em>, 114614. (<a href='https://doi.org/10.1016/j.knosys.2025.114614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent advances in deep learning-based fault diagnosis, it is challenging to build a reliable fault diagnosis model for rolling bearings under noisy conditions. Rolling bearing vibration signals are frequently corrupted by various types of noises, which poses significant challenges for accurate fault feature extraction and degrades diagnostic performance. This paper proposes a multi-scale hybrid information fusion method based on a quadratic embedded-attention convolutional network (MSHQAN) for bearing fault diagnosis. Specifically, a multi-scale feature extraction (MFE) module is proposed to extract representative features from the vibration signals. In the MFE module, a quadratic mixed layer is introduced to model the complex nonlinear relationships and multi-scale features in the vibration signal. Furthermore, a spatial-refined feature unit is put forward to refine the features extracted by the quadratic mixed unit to obtain discriminative spatial features. Additionally, a hybrid feature weight fusion module is proposed to achieve optimal fusion of cross-scale hybrid features via an adaptive weight allocation strategy. Moreover, a quadratic mixed-convolutional pooling module is developed to further strengthen the discriminative representation of fault-related features through in-depth refinement. To enhance model interpretability, a Grad-CAM++ method is employed to identify fault-related regions under noisy conditions. Experimental results validate the effectiveness of the proposed MSHQAN on two public bearing datasets.},
  archive      = {J_KBS},
  author       = {Chuanbo Wen and Jiehao Zhang and Zidong Wang and Weibo Liu and Junjie Yang},
  doi          = {10.1016/j.knosys.2025.114614},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114614},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel multi-scale quadratic convolutional network for bearing fault diagnosis: Handling noisy conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient backtrack temporal difference deep reinforcement learning. <em>KBS</em>, <em>330</em>, 114613. (<a href='https://doi.org/10.1016/j.knosys.2025.114613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning algorithms often require large amounts of training data, particularly in robotic control tasks. To address this limitation, we propose a sample-efficient backtrack temporal difference learning method that enhances target state-action ( Q ) value estimation. The proposed method dynamically prioritizes transitions based on their proximity to terminal states using backtrack sampling weights. This prioritization mechanism yields more accurate target Q -values, thereby improving the overall Q -value estimation precision. Furthermore, our analysis uncovers a novel link between curriculum learning and Bellman equation optimization. The proposed method is versatile, applicable to both discrete and continuous action spaces, and readily integrable with off-policy actor-critic algorithms. Extensive experiments show that the proposed method considerably reduces Q -value approximation errors and outperforms baselines across diverse benchmarks, achieving a 28 % performance improvement in four discrete action-space tasks and a 78 % gain in four continuous control tasks.},
  archive      = {J_KBS},
  author       = {Qi Liu and Pengbin Chen and Ke Lin and Kaidong Zhao and Jinliang Ding and Yanjie Li},
  doi          = {10.1016/j.knosys.2025.114613},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114613},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sample-efficient backtrack temporal difference deep reinforcement learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScDD: ScRNA-seq dataset distillation in latent codes with single-step conditional diffusion generator. <em>KBS</em>, <em>330</em>, 114610. (<a href='https://doi.org/10.1016/j.knosys.2025.114610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of millions of human cells across organs, diseases, developmental stages and perturbations . However, the original scRNA-seq datasets are redundant and have an ever-increasing data scale, which pose significant challenges for cross-platform data sharing and scalable foundation model construction. To address this, we propose novel dataset distillation technology in scRNA-seq analysis tasks to distill/condense the original scRNA-seq dataset into a synthetic, smaller and discriminative dataset. Unfortunately, the synthetic datasets distilled by existing dataset distillation methods have inferior cross-architecture generalization and inter-class discriminability. In light of this, (1) We propose scDD, a scRNA-seq dataset distillation framework in latent codes, which distills the original dataset information into a compact latent space, and generates a synthetic dataset with cross-architecture generalization by avoiding direct disruption to gene expression values. Then, (2) We propose a single-step conditional diffusion generator named SCDG within the scDD framework, through high-fidelity generation and category-condition guidance of the generator, SCDG ensures that the generated synthetic dataset retains scRNA-seq data characteristics and inter-class discriminability. Finally, we propose a comprehensive and robust benchmark to evaluate the performance of scRNA-seq dataset distillation in different data analysis tasks. It is validated that our proposed method can achieve 7.61 % absolute and 15.70 % relative improvement over previous state-of-the-art methods on average across task. In particular, our method also achieves an average 26.51 % absolute improvement in cross-architecture generalization.},
  archive      = {J_KBS},
  author       = {Zhen Yu and Jianan Han and Yang Liu and Qingchao Chen},
  doi          = {10.1016/j.knosys.2025.114610},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114610},
  shortjournal = {Knowl. Based Syst.},
  title        = {ScDD: ScRNA-seq dataset distillation in latent codes with single-step conditional diffusion generator},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KGMV-net: Knowledge-guided multi-view network for audio-visual dysarthria severity assessment. <em>KBS</em>, <em>330</em>, 114609. (<a href='https://doi.org/10.1016/j.knosys.2025.114609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic assessment of dysarthria faces major challenges owing to the variability in neurological damage and clinical manifestations among patients. To address these issues, we propose KGMV-Net, a Knowledge-Guided Multi-View Network for automated audio-visual dysarthria assessment. KGMV-Net integrates pathological domain knowledge with multi-view deep representations across acoustic and visual modalities. Specifically, we introduce a feature fusion framework that extracts and combines dysarthria-relevant cues from different spatiotemporal perspectives. In the visual modality, the Knowledge Guided Appearance-Motion (KGAM) module incorporates clinical priors to partition speech into four functional phases, enabling the modeling of articulatory dynamics through Persistence of Appearance (PA) flow and identification of structural asymmetries in critical facial regions. In the audio modality, the Inter-Layer Multi-Scale Fusion (IMSF) module is built on a ResNet backbone and enhanced with Attentional Feature Fusion (AFF) to capture speech characteristics across multiple temporal and spectral scales. Cross-modal coherence is reinforced through the adaptive layer normalization (AdaLN)-based Cross Fusion (ALCF) module, which employs a dual-branch cross-attention mechanism with AdaLN to project heterogeneous features into a unified semantic space. Evaluations on the MSDM dataset show that KGMV-Net achieves state-of-the-art accuracy in predicting dysarthria severity, significantly surpassing existing benchmarks. These findings support KGMV-Net as a reliable, interpretable, and scalable framework for the objective clinical assessment of dysarthria.},
  archive      = {J_KBS},
  author       = {Xiaokang Liu and Yudong Yang and Guorong Xu and Xiaoxia Du and Rongfeng Su and Nan Yan and Lan Wang},
  doi          = {10.1016/j.knosys.2025.114609},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114609},
  shortjournal = {Knowl. Based Syst.},
  title        = {KGMV-net: Knowledge-guided multi-view network for audio-visual dysarthria severity assessment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair path explanations for heterogeneous link prediction from a community perspective. <em>KBS</em>, <em>330</em>, 114608. (<a href='https://doi.org/10.1016/j.knosys.2025.114608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current GNN interpretation models for heterogeneous link prediction struggle to ensure fairness in the quality of the interpretations generated. Links across different communities are called cross-links, while links within the same community are called internal-links. Cross-links play an essential role in breaking information cocooning and maintaining graph connectivity. However, there are usually more internal-links than cross-links in real networks. This data bias will be introduced initially, leading to unfair GNN interpretations. Although this problem is widespread, few studies have attempted to solve it. To address this, we attempt to formally define the problem of fair explainability between internal-links and cross-links in heterogeneous graph neural networks for link prediction. To solve this problem, we propose a F air Graph Neural Network Exp lanation for heterogeneous link prediction from a Com munity perspective ( FExpCom ). First, a preprocessing operation is performed to filter edges and create a reduced graph, thereby eliminating noise. Then, the fair objective is introduced to learn a graph mask for edge weighting, which enhances the influence of cross-links while diminishing that of internal-links through adaptively modifying the importance of edges based on community strength. Finally, obtained fair paths on the learned graph mask are used to explain heterogeneous link prediction. Qualitative and quantitative results across five heterogeneous datasets indicate that our method can effectively reduce interpretation bias between internal and cross-links. Our code is available at: https://github.com/wenyhsmile/FExp .},
  archive      = {J_KBS},
  author       = {Yanhong Wen and Yuhua Li and Yao Wu and Yixiong Zou and Yujie Zhu and Quan Fu and Ruixuan Li},
  doi          = {10.1016/j.knosys.2025.114608},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114608},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fair path explanations for heterogeneous link prediction from a community perspective},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RPPG-TFCL: Time-frequency consistency learning for robust remote physiological measurement. <em>KBS</em>, <em>330</em>, 114607. (<a href='https://doi.org/10.1016/j.knosys.2025.114607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) enables non-contact estimation of physiological signals from facial videos by capturing subtle skin color variations. However, existing frameworks fail to preserve two critical properties of physiological signals: temporal directionality, which reflects the asymmetric nature of systolic and diastolic phases, and waveform fidelity, which is essential for reliable cardiovascular monitoring. To address these challenges, we propose a unified Time-Frequency Consistency Learning framework, named rPPG-TFCL, which incorporates physiologically grounded priors at both the architectural and regularization levels. In particular, a Time-Reversal Consistency Strategy (TRCS) is proposed to enforce predictive symmetry between forward and reversed video sequences, thereby aligning the model with the inherent reversibility of cardiovascular dynamics. In parallel, a Hierarchical Spatio-Temporal Transformer (HSTT) is designed, in which the Discrete Wavelet Transform (DWT) is embedded into a multi-scale attention architecture to decouple low- and high-frequency components, enabling the model to capture subtle hemodynamic fluctuations across temporal and spectral resolutions. Furthermore, we introduce a time-reversal consistency loss to quantify reversibility in predictions and a frequency-domain consistency constraint based on Top-K spectral energy alignment. These strategies synergistically optimize the temporal and frequency-domain behavior of the model, resulting in improved prediction stability and enhanced spectral fidelity. Extensive experiments on three public datasets (UBFC-rPPG, PURE, and MMPD) demonstrate that the proposed method outperforms existing approaches in both periodicity modeling and high-fidelity waveform reconstruction, facilitating more robust and interpretable rPPG-based physiological monitoring.},
  archive      = {J_KBS},
  author       = {Ziyi Zhao and Kailing Guo and Fang Liu and Xiaofen Xing and Lin Wang and Xiangmin Xu and Zhanpeng Jin},
  doi          = {10.1016/j.knosys.2025.114607},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114607},
  shortjournal = {Knowl. Based Syst.},
  title        = {RPPG-TFCL: Time-frequency consistency learning for robust remote physiological measurement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing feature interaction for improved generalization in few-shot metal surface defect segmentation. <em>KBS</em>, <em>330</em>, 114606. (<a href='https://doi.org/10.1016/j.knosys.2025.114606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal surface defect segmentation enables detailed inspections of industrial components, making it vital for industrial production and quality control. However, current deep convolutional neural network-based methods are often trained on large-scale annotated data and cannot be generalized to unseen defect types. This hinders their real-world applicability when defect categories are scarce and dynamic. To address these limitations, a novel few-shot segmentation framework named Enhancing Feature Interaction Network (EFINet) is designed to create a class-agnostic model with minimal training data and generalize to unseen defect categories. To mitigate the high intra-class variations between defect samples, the Prior-guided Bidirectional Feature Interaction module first performs optimized feature interaction to enhance feature representation using support-query correlations and dual prior masks. Then, to address significant scale variation within a single image, the Context-aware Attention-guided Feature Aggregation module effectively aggregates contextual and attentional information, improving the ability of the model to segment defects of varying sizes. Additionally, to alleviate information loss during global pooling, particularly for defect samples with complex characteristics, a Prototype-Loss Compensation module is introduced to generate a compensatory prototype and provide auxiliary loss. Extensive experiments on the FSSD-12 and Surface Defects-4 i benchmarks demonstrate that EFINet achieves state-of-the-art performance in various experimental settings. The code will be available at https://github.com/Hai-Jun-Yan/EFINet .},
  archive      = {J_KBS},
  author       = {Haijun Yan and Zili Zhang and Tao Peng and Xinrong Hu and Jun Zhang and Shuhan Qi},
  doi          = {10.1016/j.knosys.2025.114606},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114606},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing feature interaction for improved generalization in few-shot metal surface defect segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale feature fusion network with temporal dynamic graphs for small-sample FW-UAV fault diagnosis. <em>KBS</em>, <em>330</em>, 114605. (<a href='https://doi.org/10.1016/j.knosys.2025.114605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive application of fixed-wing unmanned aerial vehicles, accurate fault diagnosis becomes crucial for flight safety and system reliability. Traditional fault diagnosis methods often require large datasets that are difficult to obtain in practice. To address this, we start with the spatio-temporal correlation characteristics and multi-dimensional heterogeneity of UAV flight data, and propose a multi-scale feature fusion with temporal dynamic graph network (MFFTD) that enables efficient fault diagnosis using limited UAV flight data. In the spatial dimension, a multi-scale residual convolutional design captures feature representations at various levels. Furthermore, the global temporal dynamic graph models the topological dependencies between the feature representations. In addition, we introduce long short-term memory networks to capture long-term dependencies in the temporal dimension. For cross-domain joint learning in both the temporal and spatial dimensions, we propose a multi-head feature fusion module based on mutual information to address the issue of heterogeneity imbalance between feature representations. Experiments on four public datasets demonstrated that MFFTD improves the detection accuracy by eight percentage points compared to the latest models under the 90 small-sample settings of multi-class tasks and significantly enhances the generalization capability, offering superior decision support for UAV fault diagnosis. The code and data will be available at https://github.com/17992/MFFTD .},
  archive      = {J_KBS},
  author       = {Guanjun Li and Haoyu Gui and Jianguang Lu and Xianghong Tang and Xiaoyu Gao},
  doi          = {10.1016/j.knosys.2025.114605},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114605},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-scale feature fusion network with temporal dynamic graphs for small-sample FW-UAV fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bearing fault diagnosis based on multimodal knowledge graphs under few-shot samples. <em>KBS</em>, <em>330</em>, 114604. (<a href='https://doi.org/10.1016/j.knosys.2025.114604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional bearing fault diagnosis methods face challenges in capturing complex relationships and semantic connections between fault modes due to limited fault samples. To address this, we propose a novel Multimodal Knowledge Graph Extrapolation Network (MKGEN). Key components include: The feature fusion module effectively combines multi-modal information from different sensors with the structural information of the knowledge graph, providing more comprehensive feature representation under few-shot conditions and overcoming the limitations of single-modality processing. The node information aggregation module enhances the model’s understanding of fault mode semantics by learning complex node associations. The relation learning module uncovers latent correlations between fault modes in few-shot scenarios, thereby improving diagnostic accuracy. Additionally, the uncertainty optimization module enhances the model’s robustness under complex working conditions, while the manifold function decoder improves performance in high-dimensional spaces through precise feature decoding. Overall, the proposed model excels in few-shot learning, demonstrating strong generalization across devices and conditions. It adapts quickly to new tasks, predicts unseen entities, and effectively handles complex, high-dimensional features. Experimental results confirm its superior performance in few-shot and transfer tasks.},
  archive      = {J_KBS},
  author       = {Cheng Peng and Yanyan Sheng and Weihua Gui and Zhaohui Tang and Longxin Zhang and Xinpan Yuan},
  doi          = {10.1016/j.knosys.2025.114604},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114604},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bearing fault diagnosis based on multimodal knowledge graphs under few-shot samples},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tropical cyclone intensity prediction using optimized vision transformer dynamic graph convolutional network. <em>KBS</em>, <em>330</em>, 114603. (<a href='https://doi.org/10.1016/j.knosys.2025.114603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tropical cyclones (TC) cause formidable risks to the coastal populations and their industries due to powerful winds and heavy rainfall. Coastal regions are essential to economies reliant on sectors that suffer severe impacts from frequent tropical cyclone occurrences. Recent strides in ML-DL have enabled the utilization of meteorological satellite images for precise tropical cyclone intensity prediction, offering invaluable insights for disaster mitigation efforts. In this paper, Tropical Cyclone Intensity Prediction using an Optimized Vision Transformer Dynamic Graph Convolutional Network (TC-IP-VTDGCN) is proposed. The satellite images are collected for tropical cyclone from the MERRA-2 product and Regional Specialized Meteorological Centre (RSMC). Initially, the input satellite images are preprocessed using the Pseudolinear Maximum Correntropy Kalman Filter (PLMCKF) for resizing and augmenting the satellite images. Feature extraction is done by Spectral Graph Fractional Fourier Transform (SGFFT) to extract the relevant features such as cloud patterns, temperature gradients and wind speed. Then, the Vision Transformer Dynamic Graph Convolutional Network (VTDGCN) is used for predicting tropical cyclone intensity. The Dynamic Hunting Leadership Optimization (DHLO) is proposed in this work to improve the weight parameter of VTDGCN, which accurately predicts the tropical cyclone intensity. The proposed TC-IP-VTDGCN is evaluated under some metrics like, Accuracy, Precision, Recall, Mean Absolute Error (MAE), Root Mean Square error (RMSE) and Mean Absolute Percentage Error (MAPE). The proposed TC-IP-VTDGCN method provides 32.52 %, 35.65 %, and 36.82 % higher accuracy; 35.66 %, 32.73 %, and 31.43 % higher precision; 34.73 %, 32.96 %, 31.74 % less MAE compared with existing models respectively.},
  archive      = {J_KBS},
  author       = {Subba Rao Katragadda},
  doi          = {10.1016/j.knosys.2025.114603},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114603},
  shortjournal = {Knowl. Based Syst.},
  title        = {Tropical cyclone intensity prediction using optimized vision transformer dynamic graph convolutional network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-augmented contrastive clustering for time series data. <em>KBS</em>, <em>330</em>, 114602. (<a href='https://doi.org/10.1016/j.knosys.2025.114602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent emergence of time series contrastive clustering methods can be categorized into two classes. The first class uses contrastive learning for universal representations, which can be effective in various downstream tasks, but overlooks important categorical information and clustering objectives, leading to unsuitable models. The second class incorporates contrastive learning into clustering objectives but fails to fully explore potential connections and structures between time series data. To this end, we propose the “Time Series Graph-augmented Contrastive Clustering (TSGCC) method”, a graph-augmented contrastive learning framework aiming to create cluster-friendly features and assignments by iteratively optimizing contrastive loss. The method uses a weighted KNN graph to build positive and negative sample pairs, projecting the instances into a feature space with the dimensionality number of clusters. Experimental results demonstrate that TSGCC outperforms 18 advanced time-series clustering methods on the 36 representatives out of the 128 UCR benchmarks, achieving the best clustering results on 12 datasets, with the highest average rank (3.22) of RI and the second-highest average rank (3.89) of NMI among 18 clustering methods. We further compared our method with recent approaches on the entire set of 128 UCR datasets, demonstrating our method’s broad applicability and effectiveness. The code is available at https://github.com/zololululu/TSGCC .},
  archive      = {J_KBS},
  author       = {Qin Zhang and Zhuoluo Liang and Alladoumbaye Ngueilbaye and Han Liu and Hong Zhou and Joshua Zhexue Huang},
  doi          = {10.1016/j.knosys.2025.114602},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114602},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph-augmented contrastive clustering for time series data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated causal structure learning with missing data. <em>KBS</em>, <em>330</em>, 114601. (<a href='https://doi.org/10.1016/j.knosys.2025.114601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated causal structure learning (CSL) is an emerging research direction that aims to discover causal relationships from decentralized data across multiple clients, while preserving data privacy. Existing federated CSL algorithms primarily focus on complete datasets and often overlook data-quality issues, such as missing data, which are common in real-world scenarios. Moreover, client diversity can destabilize federated CSL, and this challenge is further worsened by missing data. To address these issues, we propose FedImpCSL, a novel federated CSL method, for effectively handling missing data. Our approach consists of two key components: (1) a local-to-global missing data imputation strategy that reconstructs imputed and accurate datasets from missing samples, and (2) a dynamic client weighting and weighted aggregation strategy to address inter-client differences, enhancing the CSL accuracy without utilizing each client’s original data. We demonstrate the effectiveness of FedImpCSL through comprehensive experiments on various types of datasets, showing its superior performance over existing federated CSL methods in handling missing data scenarios.},
  archive      = {J_KBS},
  author       = {Jiaqi Shi and Xiaoling Huang and Xianjie Guo and Kui Yu and Chengxiang Hu and Peng Zhou},
  doi          = {10.1016/j.knosys.2025.114601},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114601},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated causal structure learning with missing data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGD-font: Style and glyph decoupling for one-shot font generation. <em>KBS</em>, <em>330</em>, 114600. (<a href='https://doi.org/10.1016/j.knosys.2025.114600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic font generation aims to generate a complete font library by learning the font style from reference samples. Font generation is challenging because it needs to generate a set of sheer quantity of characters with consistent style and complicated structures of glyphs with limited reference font images, especially when the character or font style is unseen during training. In this paper, we propose a glyph control-based diffusion model for one-shot font generation. Specifically, we employ a style encoder to extract multi-scale style features and incorporate them into the reverse denoising steps of the diffusion model via cross-attention-based style fusion blocks. Decoupling style and glyph enables the combination of arbitrary styles and glyphs in font creation and allows users to generate fonts with unseen styles and unseen glyphs. In the inference stage, we introduce a multi-condition sampling strategy to effectively align the desired style and target glyph. Comprehensive experiments and a user study show that our framework surpasses existing approaches for both seen and unseen fonts. We further demonstrate its capability for style interpolation and cross-lingual font generation. The code is available at https://github.com/ChenSiyi1/SGD-Font .},
  archive      = {J_KBS},
  author       = {Zhenhua Li and Siyi Chen and Dong Liang},
  doi          = {10.1016/j.knosys.2025.114600},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114600},
  shortjournal = {Knowl. Based Syst.},
  title        = {SGD-font: Style and glyph decoupling for one-shot font generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving ground-truth data for evaluating additive feature attribution in regression models with additive CBR and CQV. <em>KBS</em>, <em>330</em>, 114599. (<a href='https://doi.org/10.1016/j.knosys.2025.114599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable artificial intelligence (XAI) methods produce information outputs based on a target artificial intelligence model to be explained. The most popular information output is produced by XAI methods of the category feature attribution, which produce the relative contribution of each input feature in a local instance. These relative contributions indicate how important each input feature is in a decision; this type of information is expected to provide explanatory value to users. In real-world regression tasks, feature attribution methods are crucial for comprehending model predictions. However, robust evaluation of such methods remains challenging due to a lack of ground-truth data and widely accepted evaluation metrics, such as accuracy for classification or mean absolute error for regression. This paper proposes a novel approach for generating synthetic, privacy-preserving ground-truth datasets for regression problems that retain original feature behaviour, enabling rigorous feature attribution evaluation without compromising sensitive information. We introduce additive case-based reasoning (AddCBR) as a model-aligned and interpretable baseline to benchmark additive feature attribution methods. This work also demonstrates the first use of the coefficient of quartile variation (CQV) as a statistical measure to quantify the consistency and stability of feature attribution methods. Altogether, these contributions form a comprehensive evaluation methodology for objectively assessing and comparing feature attribution methods in regression models. By providing a controlled evaluation pipeline with reliable baselines and metrics, this work addresses the current lack of consensus and benchmarking in XAI evaluation for regression models.},
  archive      = {J_KBS},
  author       = {Mir Riyanul Islam and Rosina O. Weber and Mobyen Uddin Ahmed and Shahina Begum},
  doi          = {10.1016/j.knosys.2025.114599},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114599},
  shortjournal = {Knowl. Based Syst.},
  title        = {Privacy-preserving ground-truth data for evaluating additive feature attribution in regression models with additive CBR and CQV},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view enhanced truck re-identification. <em>KBS</em>, <em>330</em>, 114598. (<a href='https://doi.org/10.1016/j.knosys.2025.114598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck Re-identification (ReID) is pivotal for efficient intelligent transportation systems, yet it faces significant challenges beyond those of general vehicle or person ReID due to the extreme diversity and complex structures of trucks, which render existing methods inadequate. Multi-view Truck ReID (MVT-ReID) is a promising solution, but its advancement is currently hampered by two primary limitations: the lack of a dedicated, high-quality benchmark dataset and the absence of methods designed to handle the inherent redundancy and feature entanglement in multi-view data. To bridge this gap, this paper makes two main contributions. First, we release MV-TI, the first large-scale, real-world MVT-ReID dataset with 70,479 images and four challenging retrieval tasks. Second, we propose DAG-UMB, a novel unsupervised framework featuring a Delayed Attention Integration (DAI) strategy and a Multi-Memory Bank (MMB). The DAI strategy defers attention activation until after the initial unstable training phase, learning a stable feature foundation to avoid misleading noise. The MMB then disentangles the learning of global-invariant and view-specific features, a key limitation of prior approaches. Extensive experiments on our proposed MV-TI benchmark demonstrate that DAG-UMB achieves state-of-the-art performance, significantly outperforming existing methods, setting a new foundation for future research and application in multi-view truck ReID.The MV-TI dataset and DAG-UMB code have been made publicly available at https://github.com/maybeextra/DAG-UMB .},
  archive      = {J_KBS},
  author       = {Xue-Yan Wang and Run-Sen Xia and Qiang Lv and Si-Bao Chen and Jin Tang},
  doi          = {10.1016/j.knosys.2025.114598},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114598},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view enhanced truck re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal image generation and fusion through content-style hybrid disentanglement. <em>KBS</em>, <em>330</em>, 114597. (<a href='https://doi.org/10.1016/j.knosys.2025.114597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image fusion and cross-modal translation are fundamental yet challenging tasks in computer vision, with their performance directly impacting downstream applications. Existing approaches typically treat these tasks independently, developing specialized models that fail to exploit the intrinsic relationships between different modalities. This limitation not only restricts model generalizability but also hinders further performance improvements. In this paper, we propose a joint optimization framework for image generation and fusion. Specifically, we generalize multimodal image tasks as the fusion and transformation of cross-modal features, and design a hybrid task training strategy. At the data level, we introduce a self-supervised and mutual-supervised hybrid mechanism for content-style feature decoupling, which achieves superior feature separation through stepwise training on intra-modal and cross-modal data. At the model level, we construct a triple-branch decoupling head along with fusion and transformation modules to ensure synchronous and efficient execution of dual tasks. Our method not only breaks through the single task limitation of the model, but also innovatively introduces mixed supervision into multimodal processing. We conduct comprehensive experiments covering four modalities fusion tasks on seven popular datasets. Extensive experimental results demonstrate that our method achieves superior performance on two tasks as compared of the respective state-of-the-art methods, and show impressive cross-task generalization capability.},
  archive      = {J_KBS},
  author       = {Xu Cao and Huanxin Zou and Jun Li and Hao Chen and Xinyi Ying and Shitian He and Yingqian Wang and Liyuan Pan},
  doi          = {10.1016/j.knosys.2025.114597},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114597},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal image generation and fusion through content-style hybrid disentanglement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaCloze: A schema-guided automated building metadata model generation system via information extraction. <em>KBS</em>, <em>330</em>, 114596. (<a href='https://doi.org/10.1016/j.knosys.2025.114596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of data-driven building applications is hindered by the extensive manual effort required to preprocess building metadata. This preprocessing is critical for translating the raw, building-specific metadata of physical entities (e.g., chillers, AHUs) into a standardized schema (e.g., Brick) that applications can interpret. The diversity of building metadata conventions across buildings makes automation difficult, creating a significant bottleneck. In this paper, we formalize the automation of building metadata generation as a text analysis problem and address it through information extraction, a paradigm to systematically transform unstructured metadata into structured representations. We define three distinct problem variants to encompass key application scenarios. Our analysis of real-world metadata reveals unique technical challenges, including corpus denoising, coreference resolution, and disambiguation. To overcome these, we present MetaCloze, a novel system that implements tailored solutions for each challenge. Evaluated across six real buildings, MetaCloze achieves a state-of-the-art strict accuracy of 97.5 % in automated entity recognition and relation extraction, demonstrating its potential to eliminate a major barrier in smart building application development.},
  archive      = {J_KBS},
  author       = {Fang He and Jiaqi Fan and Yang Deng and Xiaoyang Zhang and Dan Wang},
  doi          = {10.1016/j.knosys.2025.114596},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114596},
  shortjournal = {Knowl. Based Syst.},
  title        = {MetaCloze: A schema-guided automated building metadata model generation system via information extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral video object tracking with cross-modal spectral complementary and memory prompt network. <em>KBS</em>, <em>330</em>, 114595. (<a href='https://doi.org/10.1016/j.knosys.2025.114595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral videos contain rich spectral, spatial, and temporal information, enabling trackers to operate efficiently even in challenging scenarios. However, existing hyperspectral trackers often suffer from scarcity of training data, insufficient utilization of spectral information, and suboptimal temporal condition mining. To address these issues, we propose a novel hyperspectral tracker with cross-modal spectral complementary and memory prompt network, termed HCSMP. To achieve spectral complementarity in feature fusion, we design a cross-modal prompt network (CPN) that employs the spectral complementary adapter (SCA) to generate adaptive weights based on modality differences for cross-modal spectral prompt learning. The advantage of CPN is its ability to significantly improve the efficiency of spectral information utilization. In addition, we introduce a memory prompt network (MPN) to incorporate temporal conditions. MPN generates memory prompts containing historical features through the encoder and enhances spatial-spectral representations using channel-spatial progressive attention (CSPA), followed by a decoder that queries and retrieves the target features. The advantage of MPN is that model can achieve robust target state modeling from historical frame information. Extensive experiments demonstrate that HCSMP delivers highly satisfactory tracking performance compared with state-of-the-art (SOTA) methods, particularly under scale variation and occlusion challenges.},
  archive      = {J_KBS},
  author       = {Wenhao Jiang and Dong Zhao and Chen Wang and Xin Yu and Pattathal V. Arun and Yuta Asano and Pei Xiang and Huixin Zhou},
  doi          = {10.1016/j.knosys.2025.114595},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114595},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hyperspectral video object tracking with cross-modal spectral complementary and memory prompt network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RUST: Residual U-shaped transformer to approximate taylor expansion for image denoising. <em>KBS</em>, <em>330</em>, 114593. (<a href='https://doi.org/10.1016/j.knosys.2025.114593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has proven its powerful ability in feature representation, to utilize such gift and provide a feasible theoretical interpretation of constructing an image denoising network, this paper presents a residual U-shaped transformer (RUST) to approximate the Taylor expansion for noise removal. To be specific, we first provide a detailed analysis of the relationship between the Taylor expansion approximation theory and the image denoising model and the adjacent derivative layers. Second, we develop a deformable convolution spatial attention network, termed as LSANet, to estimate the base layer and a U-shaped transformer to transfer as many rich multi-scale details from the noisy images to the estimated results as possible to calculate the derivative. Finally, their outputs contribute to the approximation solution of the Taylor expansion. In the experiments, the selection of network parameters is first tested and discussed to verify their effectiveness. Thereafter, quantitative and qualitative experimental results on seven synthetic datasets are compared, demonstrating that our proposed RUST can produce more competitive denoising performance with richer details than the state-of-the-art (SOTA) denoising approaches. Subsequently, these SOTA methods are applied to real-life noisy images, by which the generated results validate that the developed RUST model has a more powerful generalization capability. Additionally, experimental results on the rainy DID-MDN dataset further verify that our RUST also performs well on rain removal and is suitable for extensive applications.},
  archive      = {J_KBS},
  author       = {Zhenghua Huang and Yang Yang and Jin Liu and Chuan Liu and Yu Shi and Yaozong Zhang and Qian Li},
  doi          = {10.1016/j.knosys.2025.114593},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114593},
  shortjournal = {Knowl. Based Syst.},
  title        = {RUST: Residual U-shaped transformer to approximate taylor expansion for image denoising},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fight fire with fire: A heterogeneous graph neural network fairness framework based on heterogeneous neutralization information pre-propagation. <em>KBS</em>, <em>330</em>, 114591. (<a href='https://doi.org/10.1016/j.knosys.2025.114591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although heterogeneous information networks (HINs) enable fine-grained modeling, their heterogeneous graph neural network (HGNN) implementations may yield biased predictions in human-centric applications. In this work, we revisit the problem of bias in HINs and fairness-enhancing methods for HGNNs, and propose the concept of self-limiting heterogeneous bias information. Accordingly, we introduce FairBubble, a general framework to promote fairness in HGNNs. FairBubble automatically identifies neutralizing information from the heterogeneous neighbors of target-type nodes and utilizes a hypergraph convolution-based pre-propagation mechanism to mitigate bias. The framework constructs fairness-promoting hyperrelations, enabling the dilution of biased information prior to standard message propagation in the target HGNN. Importantly, FairBubble is plug-and-play, requires no manual metapath engineering, and is broadly applicable across different HGNN architectures and application scenarios, thus demonstrating strong generalizability. Spectral analysis confirms that hypergraph convolution-based pre-propagation effectively neutralizes bias in HINs. Experiments on three public HIN benchmarks show that FairBubble achieves superior performance in both fairness and utility metrics compared to state-of-the-art HGNN fairness approaches.},
  archive      = {J_KBS},
  author       = {Siyu Li and Jin Yang and Yong Hu and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.114591},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114591},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fight fire with fire: A heterogeneous graph neural network fairness framework based on heterogeneous neutralization information pre-propagation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-robot consistent formation control based on novel leader-follower model and optimization motion planning approach. <em>KBS</em>, <em>330</em>, 114590. (<a href='https://doi.org/10.1016/j.knosys.2025.114590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning and formation control are of great significance for improving the efficiency of robot collaboration. In practical applications, traditional algorithms are complex due to the complexity and immediacy of real scenes. Optimization algorithms with their problem independence and easy scalability, can effectively solve the difficulties encountered in multi-robot path planning and formation control. However, current optimization algorithms generally have problems such as being easily trapped in local optimality and incomplete algorithm exploration. To better solve the problems of significant path trajectory error and poor formation adaptability in the collaborative formation of multi-robot systems. Based on Crayfish Optimization Algorithm (COA), this paper introduces three strategies that effectively improve the optimization effect of the COA, and proposes a hybrid algorithm suitable for collaborative formation of multi-robot systems (SCCOA). We design a novel hierarchical leader-follower formation framework and prove the stability of the formation control model. The proposed SCCOA was combined with the framework to use to adjust and parallel control the trajectory, speed, and other related factors of the leader and follower to realize the formation control system to achieve the goal of multi-robot collaborative formation. To verify the effectiveness of the SCCOA in path planning and formation control systems, SCCOA was compared with 11 excellent algorithms in experiments, and various evaluation indicators were established by analyzing various coefficients in multi-robot path planning and formation control. Results showed that SCCOA ranked first in all metrics, demonstrating the excellent performance of the SCCOA in solving multi-robot path planning and formation control problems.},
  archive      = {J_KBS},
  author       = {Liguo Yao and Xiaoyang Yuan and Guanghui Li and Yao Lu and Taihua Zhang},
  doi          = {10.1016/j.knosys.2025.114590},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114590},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-robot consistent formation control based on novel leader-follower model and optimization motion planning approach},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep fusion of feature and topology via neural attention for multilayer community detection. <em>KBS</em>, <em>330</em>, 114589. (<a href='https://doi.org/10.1016/j.knosys.2025.114589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection, as a core task for understanding and analyzing the structure and function of complex network systems, holds self-evident significance and has become the spotlight. However, current community detection methods are typically designed for single-layer static networks, which neither adequately capture complex interlayer association patterns nor characterize the dynamic evolutionary processes of communities within multilayer structures. Therefore, how to efficiently execute community detection for multilayer networks remains challenging. To this end, in this paper, we propose an innovative Multilayer Network Community Detection framework (ML-KNCDA), which employs a neural graph attention architecture that integrates node attributes, interlayer dependencies, and topology-aware similarity through differentiable learning. Specifically, first, the multi-head graph attention mechanism dynamically fuses feature embeddings and topological neighborhoods using trainable similarity kernels, enabling adaptive weighting of cross-layer relationships. In addition, to enhance the performance, we propose an across-layer neural message passing module that propagates layer-specific patterns while preserving community cohesion through topology-aware contrastive regularization. Our experiments, conducted across seven task datasets, demonstrate that ML-KNCDA significantly outperforms three SOTA methods in quality metrics (modularity and NMI).},
  archive      = {J_KBS},
  author       = {X. Li and J. Feng and Z. Zhang and N. Cui and H. Bai and W. Yu and Neal Xiong},
  doi          = {10.1016/j.knosys.2025.114589},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114589},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep fusion of feature and topology via neural attention for multilayer community detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient-based federated bayesian optimization. <em>KBS</em>, <em>330</em>, 114588. (<a href='https://doi.org/10.1016/j.knosys.2025.114588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) has evolved from traditional single-agent optimization to multi-agent collaborative optimization, known as federated BO, aiming to solve global optimization tasks such as federated hyperparameter tuning. Existing research on federated BO shares weight vectors sampled from Gaussian processes, approximated using random Fourier features, with a server for information aggregation. This line of approach helps protect the privacy of agents but may limit the performance of the algorithm. Unlike existing federated BO approaches, we propose to cluster each agent according to its characteristics, and transmit the gradients of acquisition functions between the server and agents for information aggregation. This allows for a more accurate representation of the overall landscape of the global acquisition function without explicitly constructing it. Moreover, we design a two-stage mechanism to infill the next query input based on the aggregated gradients. Specifically, multiple promising solutions are first suggested based on the aggregated gradients. Then, each agent further selects the one with the best local acquisition function value as the newly infilled solution for real function evaluation. The resulting gradient-based federated BO, termed FGBO, has demonstrated to be very competitive in tackling a set of benchmark functions and real-world problems in a privacy-preserving way.},
  archive      = {J_KBS},
  author       = {Lin Yang and Junhua Gu and Qiqi Liu and Zhigang Zhao and Yunhe Wang and Yaochu Jin},
  doi          = {10.1016/j.knosys.2025.114588},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114588},
  shortjournal = {Knowl. Based Syst.},
  title        = {Gradient-based federated bayesian optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MASC-net: Modality-aware skip connection network for adaptive feature selection in high-fidelity medical image translation. <em>KBS</em>, <em>330</em>, 114587. (<a href='https://doi.org/10.1016/j.knosys.2025.114587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image-to-image translation seeks to synthesize missing modalities for complementary diagnostic information, but existing methods often fail to preserve fine anatomical details, leading to structural loss or blur. Conventional skip connections in encoder-decoder architectures, although effective in detail preservation, often introduce semantic conflicts between source-domain encoder features and target-domain decoder features, thereby degrading generation quality. To address this issue, we propose the Modality-Aware Skip Connection Network (MASC-Net), which integrates a modality-aware attention module into the skip connections. This module adaptively suppresses redundant, irrelevant, and even potentially misleading encoder features, dynamically adjusting the information flow according to the contextual requirements of the decoder, thereby alleviating semantic inconsistencies. In addition, we design a Dual-Branch Feature Fusion Module, which employs advanced feature extraction techniques to simultaneously capture fine-grained local details and global semantic representations at multiple resolutions. This design not only ensures structural consistency but also effectively emphasizes critical pathological features. Experimental results on the BraTS2023 and MRXFDG datasets demonstrate that our method excels in generating anatomical details and exhibits strong generalizability across similar tasks.},
  archive      = {J_KBS},
  author       = {Jiaqing Tao and Zewen Liu and Mingming Ma and Jing Qin and Feng Liu and Xiaoke Hao},
  doi          = {10.1016/j.knosys.2025.114587},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114587},
  shortjournal = {Knowl. Based Syst.},
  title        = {MASC-net: Modality-aware skip connection network for adaptive feature selection in high-fidelity medical image translation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonlocal superpatch-based reweighted low-rank representation method for hyperspectral unmixing. <em>KBS</em>, <em>330</em>, 114586. (<a href='https://doi.org/10.1016/j.knosys.2025.114586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More attention has been paid to spatial information in the process of exploring better hyperspectral unmixing (HU) methods for hyperspectral image (HSI). However, most spatial-regularization-based HU methods only consider the spatial context relationship of adjacent regions in an HSI, ignoring the use of information between non-adjacent ones. To this end, we propose a novel HU method named nonlocal superpatch-based reweighted low-rank and total variation sparse unmixing (NLSPRLR-TV), which uses both local and nonlocal spatial information of HSI. Unlike some previous nonlocal methods using the patch, the nonlocal homogeneous regions obtained by our method can be well consistent with the visual edge. Concretely, a superpixel-based patch called SuperPatch is firstly constructed to exploit local spatial redundancy. Then, several similar superpatches are searched in the whole HSI to form a nonlocal superpatch matrix by the SuperPatchMatch method, so that the nonlocal spatial redundancy is exploited. Finally, the proposed method imposes the collaborative sparse and TV regularizations on the whole abundance matrix, and a reweighted low-rank regularization for each superpatch matrix, to obtain the estimated abundance images. Extensive experimental results on simulated and real datasets demonstrate that the proposed NLSPRLR-TV method outperforms several state-of-the-art HU methods.},
  archive      = {J_KBS},
  author       = {Yizhe Zhao and Maoguo Gong and Xiangming Jiang and Tao Zhan and Fenlong Jiang},
  doi          = {10.1016/j.knosys.2025.114586},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114586},
  shortjournal = {Knowl. Based Syst.},
  title        = {A nonlocal superpatch-based reweighted low-rank representation method for hyperspectral unmixing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decorrelated adaptive simple graph representation learning for next POI recommendation. <em>KBS</em>, <em>330</em>, 114585. (<a href='https://doi.org/10.1016/j.knosys.2025.114585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Point-of-Interest (POI) recommendation plays a pivotal role in social network services. Its objective is to predict the POI a user is most likely to visit next based on their historical visit patterns. Existing methods often rely on predefined graphs to establish relationships between POIs, with only a few studies delving into adaptive graph approaches. Adaptive graph representation learning can reveal more insightful graph structures, enabling graph neural networks to learn more significant adjacency relationships during propagation. However, existing research on adaptive graphs remains at a relatively preliminary stage. In this paper, we propose a Decorrelated Adaptive Simple Graph Representation-enhanced Attention Network (DASGRAN) for next POI recommendation task. DASGRAN adopts a more straightforward approach to graph structure learning, which not only reduces the dependency on domain knowledge but also alleviates issues of over-smoothing and over-correlation. Furthermore, we explore the interplay between self-attention mechanisms and adaptive graph learning, incorporating new extensions and regularization techniques. These enhancements allow the extended self-attention method to capture user preferences more effectively. Results from four real-world datasets demonstrate that our method overall surpasses existing state-of-the-art baselines in performance.},
  archive      = {J_KBS},
  author       = {Yanhong Li and Shijie Wang and Xuan Li and Zixi Li and Longyu Wu and Wei Tian and Guoliang Li},
  doi          = {10.1016/j.knosys.2025.114585},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114585},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decorrelated adaptive simple graph representation learning for next POI recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifier ensemble based source-free domain adaptation for time series classification. <em>KBS</em>, <em>330</em>, 114584. (<a href='https://doi.org/10.1016/j.knosys.2025.114584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free domain adaptation (SFDA) enables adaptation to an unlabeled target domain without requiring access to source data. Existing SFDA methods can be broadly categorized into fixed classifier-based and learnable classifier-based approaches. Fixed classifier-based methods transfer a pre-trained model from the source to the target domain while keeping classifier parameters fixed. In contrast, learnable classifier-based methods dynamically adjust classifier parameters during adaptation. Fixed classifier-based methods perform well when the distribution discrepancy between domains is small but struggle with larger domain shifts. Meanwhile, learnable classifier-based methods effectively address distribution discrepancies by optimizing classifier parameters. For time series classification tasks, domain discrepancies are often larger and more intricate, leading to severe performance degradation in existing domain adaptation methods. To address this issue, we propose a novel classifier ensemble-based source-free domain adaptation (CE-SFDA) framework to mitigate domain shift in time series classification. The proposed framework adapts the classification model to the target domain while preserving source domain knowledge. Specifically, we design an classifier ensemble-based pseudo-label generation method to improve pseudo-label reliability. Additionally, we introduce a memory-aware knowledge distillation method to capture both global and local structures within the target domain. Furthermore, an information entropy-based self-supervised learning strategy is employed to align source and target domain distributions. We conduct extensive experiments on four real-world time-series domain adaptation datasets. Experimental results demonstrate that the proposed CE-SFDA framework is simple and effective, achieving superior performance over state-of-the-art methods. The code is publicly available at https://github.com/WangdongZhao99/CE-SFDA .},
  archive      = {J_KBS},
  author       = {Ercheng Pei and Wangdong Zhao and Zhanxuan Hu and Lang He and Hailong Ning and Haifeng Chen},
  doi          = {10.1016/j.knosys.2025.114584},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114584},
  shortjournal = {Knowl. Based Syst.},
  title        = {Classifier ensemble based source-free domain adaptation for time series classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete graph learning via data and representation-level interaction. <em>KBS</em>, <em>330</em>, 114583. (<a href='https://doi.org/10.1016/j.knosys.2025.114583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data is a fundamental resource for many modern applications. However, graph models may struggle when faced with incomplete data, such as incomplete structure or attributes. Despite partly solving the incomplete problem by modeling attributes and structure with a decoupled framework, existing methods ignore their interaction that may exploit the complementarity between attributes and structure, resulting in limited performance. In this work, we propose an interactive framework for incomplete graph learning on both the data and representation levels. Concretely, we design a data-level interactive completion approach that combines a decoupled preliminary completion with a fundamental interaction function realized by graph convolutional networks, effectively leveraging the complementarity between the completions of node attributes and graph structure to enhance incomplete graph completion. Then, we propose a representation-level interactive learning module with multi-view contrastive learning to handle representation-level interactions, generating better graph node representations and improving the performance of downstream tasks. Extensive experiments on eight benchmark datasets demonstrate the effectiveness of our methods in handling incomplete graphs, consistently outperforming existing state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Dezhi Liu and Richong Zhang and Junfan Chen and Fanshuang Kong and Jaein Kim},
  doi          = {10.1016/j.knosys.2025.114583},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114583},
  shortjournal = {Knowl. Based Syst.},
  title        = {Incomplete graph learning via data and representation-level interaction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global attention residual graph contrastive learning network-based mechanical fault diagnosis under multi-domain scenarios. <em>KBS</em>, <em>330</em>, 114582. (<a href='https://doi.org/10.1016/j.knosys.2025.114582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source domain adaptation-based fault diagnosis methods have received some satisfactory achievements. Nevertheless, some of them ignore domain distribution difference and intra correlation hidden in multi-source domain information, it might lead to poor fault diagnosis performance. To address these challenges, a novel global attention residual graph contrastive learning network (GAGCN) is proposed for fault diagnosis of rotating machinery by using multi-domain knowledge graph. In this method, a global attention residual network is constructed to extract global features from multi-domain information. And, a knowledge graph is created to describe similarity relationships between different global features. Then, a self-reinforced graph contrastive learning network is developed to dynamically generate and adaptively select knowledge graph, while global feature types in knowledge graph are determined. In addition, a relationship alignment loss is designed to enhance intra-class consistency and inter-class differences of global features. The effectiveness of the proposed method is verified by a self-built propulsion shaft system, reduction gears and CWRU bearing dataset. Experimental results show the superiority and robustness of the GAGCN method compared to other existing methods under multi-domain scenarios.},
  archive      = {J_KBS},
  author       = {Qiming Shu and Jun Wu and Lixiang Wang and Shutong Yang and Zongzhen Ye},
  doi          = {10.1016/j.knosys.2025.114582},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114582},
  shortjournal = {Knowl. Based Syst.},
  title        = {Global attention residual graph contrastive learning network-based mechanical fault diagnosis under multi-domain scenarios},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of model-based ensemble learning for accurate diabetic retinopathy grading. <em>KBS</em>, <em>330</em>, 114581. (<a href='https://doi.org/10.1016/j.knosys.2025.114581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a common and severe ocular complication in patients with diabetes that can lead to blindness. Early diagnosis and timely intervention are essential for effective management of DR. In clinical settings, both binary classification (presence or absence of DR) and multiclass severity grading are critical for informed decision-making. However, manual grading is time-consuming and requires specialized expertise from ophthalmologists, emphasizing the need for automated solutions to enhance efficiency and support clinical practice. This study compared the DR grading performance between transformer-based and traditional convolutional neural network-based models. Aggregating the strengths of diverse models, the bag of model (BoM) approach with the majority voting strategy was adopted to enhance classification efficiency. The transformer-based models generally outperformed the convolutional neural network-based models. The data-efficient image transformer model exhibited the best performance in grading DR on the basis of complex fundus images. The experimental results indicate that using the BoM approach with transformer-based models, alongside knowledge distillation and the majority voting strategy, markedly enhances the accuracy and stability of DR grading.},
  archive      = {J_KBS},
  author       = {Huang-Chia Shih and Yu-Chang Cheng and Chia-Shiang Chen and Tzu-Lun Huang and Syu-Siang Wang},
  doi          = {10.1016/j.knosys.2025.114581},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114581},
  shortjournal = {Knowl. Based Syst.},
  title        = {Analysis of model-based ensemble learning for accurate diabetic retinopathy grading},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum entropy structural encoding for graph neural networks. <em>KBS</em>, <em>330</em>, 114580. (<a href='https://doi.org/10.1016/j.knosys.2025.114580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural encoding (SE) can improve the expressive power of Graph Neural Networks (GNNs). However, current SE methods have limited expressive power because they have limitations in capturing (1) node subgraphs, (2) global position of nodes, and (3) global structure of the graph. To tackle this challenge, we propose a Quantum Entropy Structural Encoding (QESE) for GNNs. For limitations (1) and (3), we employ quantum entropy on node subgraphs and the whole graph to recognize highly similar structures. For limitation (2), we apply quantum entropy on complement parts of node subgraphs for locating node positions. Then, we obtain QESE by integrating quantum entropies of these three parts through the Holevo χ quantity. Notably, we prove that QESE always captures structural distinction in node subgraphs and the whole graph, and the Holevo χ quantity empowers QESE to represent global position of nodes. We theoretically show that QESE distinguishes strongly regular graphs that 3-WL fails to, and has the potential to be more powerful than k -WL ( k >3). We adopt a plug-and-play approach to inject QESE with existing GNNs, and further design an approximated version to reduce computational complexity. Experimental results show that QESE uplifts the expressive power of GNNs beyond 3-WL and indeed captures node subgraphs. Furthermore, QESE improves the performance of various GNNs in graph learning tasks and also surpasses other SE methods.},
  archive      = {J_KBS},
  author       = {Feng Ding and Yingbo Wang and Shuo Yu and Yanming Shen},
  doi          = {10.1016/j.knosys.2025.114580},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114580},
  shortjournal = {Knowl. Based Syst.},
  title        = {Quantum entropy structural encoding for graph neural networks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D mesh colorization from a single image via geometry prior modulation. <em>KBS</em>, <em>330</em>, 114578. (<a href='https://doi.org/10.1016/j.knosys.2025.114578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel framework for colorizing 3D meshes from a single RGB image, utilizing a triplane-based representation that integrates both geometric and image features. Unlike traditional texture mapping or view-dependent neural rendering approaches, our method directly predicts per-vertex colors without requiring camera pose information. To capture geometric context, we extract features from an uncolored mesh using a point-based encoder and project them onto three orthogonal planes, aligning them with the image space. Simultaneously, semantic features are extracted from the input image using a vision transformer. These image features are decoded into a triplane representation using a transformer-based decoder, where mesh features modulate the attention and feed-forward mechanisms, enriching the representation with geometric and appearance cues. Each mesh vertex then samples the refined triplane via bilinear interpolation to obtain a descriptive feature, which is decoded into a view-independent RGB color. The model is trained using a combination of 2D photometric loss computed from renderings of the predicted and ground-truth colored meshes, and a 3D vertex color loss. At inference, the method operates using a single RGB image and an uncolored mesh, without requiring camera pose, generating a colored mesh in under one second. Experiments on standard benchmarks demonstrate that our approach produces high-quality and consistent per-vertex colorization, outperforming existing single-view methods in both visual fidelity and generalization.},
  archive      = {J_KBS},
  author       = {Rama Bastola Neupane and Kan Li and Zhuqing Mao},
  doi          = {10.1016/j.knosys.2025.114578},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114578},
  shortjournal = {Knowl. Based Syst.},
  title        = {3D mesh colorization from a single image via geometry prior modulation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-RIL: A hopf-based robot imitation learning framework for modular antenna structure assembly. <em>KBS</em>, <em>330</em>, 114576. (<a href='https://doi.org/10.1016/j.knosys.2025.114576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address common challenges in on-orbit assembly of modular antenna structures—such as complex trajectory planning, poor skill generalization, and low system intelligence—this paper proposes a Hopf-based robot imitation learning (H-RIL) framework, which consists of three stages: demonstration, skill learning, and skill generalization. In the demonstration stage, modular assembly trajectories are recorded via kinesthetic teaching. In the learning stage, an adaptive oscillatory primitive (AOP) is introduced. A “segmentation–learning–stitching” strategy is adopted, whereby the continuous trajectory is divided into multiple subsegments, each modeled by an individual AOP. A tunable exponential window function is used to ensure smooth stitching between sub-trajectories. In the generalization stage, a “local adjustment with neighborhood coordination” strategy is proposed, enabling adaptation of trajectory endpoints and shapes by adjusting the parameters of corresponding AOPs. To validate the proposed method, a robotic assembly platform was developed for modular unit transportation and insertion tasks. Ablation studies confirmed the effectiveness of each component within the H-RIL framework. Comparative experiments with two recent imitation learning methods in the insertion task showed average error reductions of 83.79% and 91.69%, respectively. The trained robot successfully executed assembly operations at multiple target positions, demonstrating the potential of the proposed framework for future applications in on-orbit assembly of modular structures.},
  archive      = {J_KBS},
  author       = {Yulin Zhang and Tuanjie Li and Yuming Ning and Ziang Li and Lixiang Ban and Yan Zhang and Xiangyuan Li},
  doi          = {10.1016/j.knosys.2025.114576},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114576},
  shortjournal = {Knowl. Based Syst.},
  title        = {H-RIL: A hopf-based robot imitation learning framework for modular antenna structure assembly},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIARec: Adaptive intent-aware augmentation for graph contrastive learning recommendation method. <em>KBS</em>, <em>330</em>, 114575. (<a href='https://doi.org/10.1016/j.knosys.2025.114575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL) has recently emerged as a powerful paradigm for recommendation systems.However,its practical adoption is hindered by two critical challenges: (a) The representational capacity and interpretability of recommendation models; (b) The inherent flaws of data augmentation strategies in intent decoupling learning, which often introduce misleading self-supervised signals due to noise. To address these issues, we propose a novel framework that integrates adaptive augmentation with intent-aware modeling to improve the challenge (a), called AIARec. Our approach addresses the sparsity of implicit feedback in bipartite graphs by introducing a Gaussian distribution-based graph generation strategy for robust node feature encoding. Furthermore, we design an adaptive feature-level noise perturbation mechanism, governed by an embedding table, which judiciously guides the reconstruction of the bipartite graph using latent intent information. This mechanism not only mitigates excessive noise perturbation but also accentuates the intrinsic intention features of users and items, thereby strengthening the challenge (b). To further refine the learned representations, we develop a two-domain aware graph contrastive learning framework that optimizes the consistency and uniformity of node embeddings across multiple domains. Extensive experiments on real datasets (e.g., Yelp, Amazon-Book) show that AIARec outperforms 16 state-of-the-art baselines (e.g., BIGCF, LightGCN) on Recall and NDCG in four metrics (recall, NDCG, etc.). By explicitly modeling user-item interactions through interpretable intent factors, AIARec advances both the performance and explainability of GCL-based recommender systems, offering a principled solution to noisy augmentation and sparse interaction challenges.},
  archive      = {J_KBS},
  author       = {Xiaoyang Liu and Guiling Wen and Asgarali Bouyer and Giacomo Fiumara and Pasquale De Meo},
  doi          = {10.1016/j.knosys.2025.114575},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114575},
  shortjournal = {Knowl. Based Syst.},
  title        = {AIARec: Adaptive intent-aware augmentation for graph contrastive learning recommendation method},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised reservoir computing for multivariate denoising of severely contaminated signals. <em>KBS</em>, <em>330</em>, 114574. (<a href='https://doi.org/10.1016/j.knosys.2025.114574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interdependence and high dimensionality of multivariate signals present significant challenges for denoising, as conventional univariate methods often struggle to capture the complex interactions between variables. A successful approach must consider not only the multivariate dependencies of the desired signal but also the multivariate dependencies of the interfering noise. In our previous research, we introduced a method using machine learning to extract the maximum portion of “predictable information” from univariate signal. We extend this approach to multivariate signals with a key innovation: an interference calibration matrix that incorporates directional noise intensities back into signal reconstruction. The method applies PCA to the noise covariance matrix to identify noise variance in each principal direction, then assigns directional weights based on signal-to-noise ratios to improve reconstruction accuracy. The method works successfully for various multivariate signals, including chaotic signals and highly oscillating sinusoidal signals which are corrupted by spatially correlated intensive Gaussian/non-Gaussian noise. It consistently outperforms other existing multivariate denoising methods by 3-6 dB across a wide range of scenarios including real-world data.},
  archive      = {J_KBS},
  author       = {Jaesung Choi and Pilwon Kim},
  doi          = {10.1016/j.knosys.2025.114574},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114574},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unsupervised reservoir computing for multivariate denoising of severely contaminated signals},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Objectness scan for efficient vision mamba. <em>KBS</em>, <em>330</em>, 114573. (<a href='https://doi.org/10.1016/j.knosys.2025.114573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba has made its debut in several visual tasks, but a more effective scanning strategy is still needed to unfold visual data into logical one-dimensional token sequences, ensuring spatial continuity and semantic structures. In this paper, an objectness scanning strategy with a dual-attention mechanism is proposed for efficient vision Mamba. Visual data is unfolded according to its objectness. The produced one-dimensional token sequences maintain visual spatial continuity while exhibiting a clear semantic structure, akin to the syntactic structures of natural language, owing to three built-in linguistic characteristics—the dependency distance minimization, the primacy effect, and high accessibility. A multi-scale foreground proposer is also proposed as an essential component to evaluate the objectness of tokens. It mitigates interference from non-object information and prevents the attenuation of semantic information by a parallel enhancement modulation mechanism. By incorporating the objectness scanning strategy, the proposed vision Mamba model, ObjM, demonstrates significant superiority in accurately and efficiently identifying foreground objects. On both camouflaged object detection and salient object detection, it delivers improved performance while achieving an average reduction of 31.04 % in computational cost and 56.90 % in parameter count by merely replacing the backbones of several state-of-the-art camouflaged object detection models. On the MSCOCO multi-object detection and instance segmentation task, it also consumes fewer computational resources. Codes are available at https://github.com/kaiopen/objm .},
  archive      = {J_KBS},
  author       = {Kai Zhang and Xia Yuan and Chunxia Zhao},
  doi          = {10.1016/j.knosys.2025.114573},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114573},
  shortjournal = {Knowl. Based Syst.},
  title        = {Objectness scan for efficient vision mamba},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement via self-degradation-aware and semantic-perceptual guidance networks. <em>KBS</em>, <em>330</em>, 114571. (<a href='https://doi.org/10.1016/j.knosys.2025.114571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images in real-world scenarios often exhibit varying degrees of degradation, ranging from slight to extreme darkness. However, existing low-light image enhancement methods employ a one-size-fits-all enhancement strategy, resulting in either over-enhancement or insufficient enhancement of the enhanced images. Additionally, many existing techniques rely solely on direct end-to-end mapping from low to normal light conditions, neglecting the importance of structural and contextual guidance during enhancement. To overcome these limitations, we propose SDA-Net, a self-degradation-aware enhancement framework that dynamically adapts enhancement strategies to varying low-light conditions. Our method introduces two key components: (1) a Contrastive-Based Degradation Feature Extractor, which learns discriminative representations of degradation, enabling adaptive enhancement tailored to degradation features. This degradation-aware approach enhances stability and performance in different low-light scenarios. (2) a Semantic-Perceptual Guidance Network, which generates intermediate visual representations to amplify inputs. These representations serve as prior knowledge to enhance the images, enabling sharper edge reconstruction, effective noise suppression, and the preservation of natural illumination. Extensive experiments demonstrate that SDA-Net outperforms state-of-the-art methods on benchmark datasets, showing superior robustness in real-world scenarios with complex degradation patterns. Our source code is available: https://github.com/bartani/SDA-Net},
  archive      = {J_KBS},
  author       = {Omed Sedeeq Ahmad and Sarbast Ahmed Anjuman and Sarhang Sulaiman Bakr and Ako Bartani},
  doi          = {10.1016/j.knosys.2025.114571},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114571},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-light image enhancement via self-degradation-aware and semantic-perceptual guidance networks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mamba with multi-frequency perception for image super-resolution. <em>KBS</em>, <em>330</em>, 114570. (<a href='https://doi.org/10.1016/j.knosys.2025.114570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) focuses on reconstructing a high-resolution (HR) image from a low-resolution (LR) input, aiming to restore fine details and improve perceptual quality. Recently, Mamba has shown promise for SR, owing to its efficient sequential modeling capability. However, existing Mamba-based approaches often neglect the joint impact of remote-distance information decay and insufficient local information dependencies. To address this issue, we propose MFPMamba, a novel image SR method designed to enhance both the global and local feature representation capabilities of Mamba. Specifically, a multi-frequency decoupling perception module (MFDP) is introduced to augment Mamba with frequency-domain information. In this module, features are decomposed into low- and high-frequency components via the wavelet transform, and specialized decoupled convolutions are employed to effectively process each component. In addition, a multi-domain adaptive fusion module (MDAF) is developed to facilitate the integration of spatial-domain features encoded by Mamba and frequency-domain features encoded by MFDP. The channel weights are adaptively determined through the uniform quantification of features across different domains. Extensive experiments show that state-of-the-art performance is achieved. In the ×4 task, our method improves the PSNR by 0.16 and 0.25 dB on the Urban100 and Manga109 datasets, respectively, over the baseline, and reduces the memory consumption by 12 %. These results demonstrate the effectiveness of multi-frequency perception in assisting Mamba to achieve image SR.},
  archive      = {J_KBS},
  author       = {Huimin Yang and Jingzhong Xiao and Ji Zhang and Xuchuan Zhou and Yuxing Liu},
  doi          = {10.1016/j.knosys.2025.114570},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114570},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mamba with multi-frequency perception for image super-resolution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine multimodal prototype network for few-shot multimodal relation extraction. <em>KBS</em>, <em>330</em>, 114569. (<a href='https://doi.org/10.1016/j.knosys.2025.114569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal relation extraction (MRE) aims to identify textual entity relations in free text with incorporated images. The majority of methods for MRE rely heavily on a large number of manually annotated samples, and their performance drops sharply when the available labeled data is insufficient. However, annotating data in many expert domains is knowledge-intensive and time-consuming, necessitating significant labeling efforts. Inspired by the success of meta-learning in various methods, several studies have applied few-shot learning to the MRE task for reducing labeling efforts. Nevertheless, existing few-shot multimodal relation extraction methods typically rely on shallow features from text and image modalities, neglecting the latent relation-label-aware cues in multimodal data. Besides, they struggle to capture fine-grained multimodal interactions aligned with entity semantics. These limitations hinder the models from effectively focusing on the most informative parts in text-image pairs, while simultaneously restricting their capability to reason in complex multimodal scenarios. To overcome these shortcomings, we propose a C oarse-to-fine M ultimodal P rototype Net work (CMPNet) that learns hierarchical multimodal features to solve the few-shot multimodal relation extraction task. More specifically, our model captures multimodal features through a cross-attention module in a gated way, while obtaining semantic-aware representations with two guided modules. One module guided by relation-label semantics is designed to align prototype with the semantic characteristics of relations. Another one captures multimodal features associated with entities, guiding the model to concentrate on text and visual information closely tied to the entities. Extensive experiments on two benchmark datasets demonstrate that CMPNet outperforms the previous baseline models under different few-shot settings, confirming the effectiveness of our model.},
  archive      = {J_KBS},
  author       = {Haoze Zhu and Baohang Zhou and Ziyu Lu and Xuhui Sui and Yu Zhao and Ying Zhang and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.114569},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114569},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coarse-to-fine multimodal prototype network for few-shot multimodal relation extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ray-decomposed and gradient-constrained NeRF for few-shot view synthesis under low-light conditions. <em>KBS</em>, <em>330</em>, 114568. (<a href='https://doi.org/10.1016/j.knosys.2025.114568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have shown impressive performance in novel view synthesis, providing high-quality visual results for 3D reconstruction. However, existing NeRF-based methods often fail under extreme low-light conditions with sparse-view inputs, suffering from color distortion and degraded visual quality due to inaccurate illumination modeling and overfitting to limited views. To address these challenges, we propose R-GNeRF, a novel framework that leverages ray decomposition and gradient constraint. Specifically, we decompose sampled rays into reflective and illumination components, each modeled by an independent MLP in an unsupervised manner. A gradient constraint guides the network to learn physically plausible illumination fields, allowing the synthesis of novel views under normal lighting using only the reflective component. In addition, we introduce a view-consistency annealing strategy that adaptively adjusts the sampling sphere radius based on projection consistency across views, mitigating overfitting and improving reconstruction of fine details in few-shot synthesis. To evaluate performance under extreme low-light, we construct the 3L-P dataset using a multi-pixel photon counter (MPPC) at illuminance levels of 10 − 3 and 10 − 4 lux, providing challenging low-light images. Extensive experiments demonstrate that R-GNeRF consistently outperforms existing methods in low-light few-shot novel view synthesis, achieving higher visual fidelity and accurate depth reconstruction while maintaining efficient rendering.},
  archive      = {J_KBS},
  author       = {Feng Wang and Liju Yin and Yiming Qin and Xiaoning Gao and Xiangyu Tang and Hui Zhou},
  doi          = {10.1016/j.knosys.2025.114568},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114568},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ray-decomposed and gradient-constrained NeRF for few-shot view synthesis under low-light conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning spatial-channel feature refiners via wavelet-based linear mixed basis for low-light image enhancement. <em>KBS</em>, <em>330</em>, 114567. (<a href='https://doi.org/10.1016/j.knosys.2025.114567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When images are captured in low-light conditions, they may suffer from color deviation and loss of texture details. Additionally, they may also be susceptible to noise. To solve these problems, we learn spatial-channel feature refiners via wavelet-based linear mixed basis (SCFR-WLMB). Specifically, we adopt a novel wavelet-based linear mixed basis (WLMB) instead of a single wavelet basis for wavelet transform. To the best of our knowledge, this is the first time that this approach has been applied to low-light image enhancement. The WLMB takes advantage of various wavelets to better capture the color information and texture details in the image, thereby reducing the color deviation and enhancing the recovery of texture details. We also design a rhombic-grid crossed spatial feature enhancement block (RGC-SFEB), which firstly refines the input features into rich and redundant information through thresholding and then enhances the interaction between these two types of information in a rhombic-grid crossed way to increase the diversity of information. The RGC-SFEB is more likely to identify and correct errors introduced by noise, and help to resist the interference of noise. We conduct extensive experiments to validate our design and demonstrate on seven benchmark datasets that it achieves state-of-the-art (SOTA) methods both quantitatively and qualitatively. Our code will be publicly available at https://github.com/csust7zhangjm/SCFR-WLMB .},
  archive      = {J_KBS},
  author       = {Jianming Zhang and Jia Jiang and Zhijian Feng and Jin Wang},
  doi          = {10.1016/j.knosys.2025.114567},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114567},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning spatial-channel feature refiners via wavelet-based linear mixed basis for low-light image enhancement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is it genuine or fake? analyzing e-commerce reviews using large language models. <em>KBS</em>, <em>330</em>, 114556. (<a href='https://doi.org/10.1016/j.knosys.2025.114556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread acceptance of online platforms has brought user-generated reviews to the forefront as a determinant of consumer decision-making, particularly in sectors such as hospitality and e-commerce. However, the growing prevalence of fake and misleading reviews poses significant challenges, often confusing consumers and undermining the credibility of online platforms. This research proposes a transformer-based framework for fake review detection using Large Language Models, achieving an overall classification accuracy of 90.50%. The contextual capacity of transformer-based architectures enables the model to effectively resolve ambiguity between genuine and deceptive user reviews. The objective of this research is twofold: to strengthen consumer trust and to preserve the reputation of online businesses. Performance benchmarks were established through comprehensive evaluations against multiple baseline algorithms on real-world e-commerce review datasets. Finally, the effects of deceptive reviews on strategic customer experience management are discussed, and directions toward scalable and real-time review verification systems are suggested. The obtained results show how well LLMs successfully capture the fine-grained linguistic patterns behind opinion spam and provide a strong method for automatic review authenticity verification in intelligent decision support systems. The datasets and experimental framework are available in the GitHub Repository.},
  archive      = {J_KBS},
  author       = {Siddharth Bhangale and Pradeep Kumar Roy},
  doi          = {10.1016/j.knosys.2025.114556},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114556},
  shortjournal = {Knowl. Based Syst.},
  title        = {Is it genuine or fake? analyzing e-commerce reviews using large language models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient method for maximal erasable itemset mining in incremental databases. <em>KBS</em>, <em>330</em>, 114555. (<a href='https://doi.org/10.1016/j.knosys.2025.114555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining maximal erasable itemsets has recently attracted significant research attention due to its importance in various fields. It is particularly valuable in manufacturing for identifying and eliminating unprofitable or low-profit products, thereby reducing costs and optimizing production processes. However, current methods are inefficient for incremental databases; they require high storage and must re-scan the entire dataset or require revalidating large candidate sets when new data is added, leading to significant computational overhead. This paper proposes IMEL, a novel method to efficiently mine maximal erasable itemsets from incremental databases. IMEL utilizes two new data structures, the ICEI-List and the ICEP-List, which significantly reduce storage by maintaining only a single representative item in each list for both the original database and incoming data increments. Additionally, an indexed search space reduction technique embedded within the ICEI-List and ICEP-List structures accelerates processing time and minimizes unnecessary comparisons. Experimental results demonstrate that the IMEL algorithm improves mining time and storage efficiency on sparse and dense incremental datasets.},
  archive      = {J_KBS},
  author       = {Linh Nguyen and Giang Nguyen and De-Thu Huynh and Bao Huynh},
  doi          = {10.1016/j.knosys.2025.114555},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114555},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient method for maximal erasable itemset mining in incremental databases},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICCR-diff: Identity-preserving and controllable craniofacial reconstruction with diffusion models. <em>KBS</em>, <em>330</em>, 114554. (<a href='https://doi.org/10.1016/j.knosys.2025.114554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Craniofacial reconstruction predicts craniofacial features from skull morphology to reconstruct the craniofacial surface. Although previous methods have achieved promising performance, they face three critical limitations: insufficient image quality, poor identity preservation, and difficulties with conditional control. To overcome these challenges, we propose a novel diffusion-based craniofacial reconstruction method that preserves identity across domain transfer. Our approach incorporates multiple modules to separately manage multimodal information including skull data, landmarks, texture features, and biometric information, yielding high-fidelity results under various constraints. Furthermore, by enabling flexible modification of biometric information through standardized text prompts, our method achieves fine-grained control while maintaining individual identity characteristics. Extensive experimental results demonstrate that our method outperforms existing approaches in image quality and identity retrieval, showcasing exceptional robustness, strong identity preservation, and enhanced editability. Our code is available at: https://github.com/mqzhang2024/ICCR .},
  archive      = {J_KBS},
  author       = {Mingqin Zhang and Hongjie Wu and Zhengqing Zang and Jian Wang and Chaoqun Niu and Yuan Li and Jiancheng Lv},
  doi          = {10.1016/j.knosys.2025.114554},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114554},
  shortjournal = {Knowl. Based Syst.},
  title        = {ICCR-diff: Identity-preserving and controllable craniofacial reconstruction with diffusion models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature projection and grouped contrastive learning for text-to-image person re-identification. <em>KBS</em>, <em>330</em>, 114553. (<a href='https://doi.org/10.1016/j.knosys.2025.114553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image Person Re-Identification (TIReID) is a core task in cross-modal person re-identification, aiming to retrieve target pedestrian images through textual descriptions. Existing methods primarily enhance retrieval performance by aligning cross-modal features through the fusion of global and local text-image representations. However, limitations persist in inadequate fine-grained feature extraction and overreliance on the hardest negative samples in loss computation. To address these challenges, we propose the Dynamic Feature Projection with Grouped Contrastive Learning framework (DFP-GCL). First, we employ a max-attention strategy to select representative local features from both text and images. These features are processed via two parallel pathways: a Multilayer Perceptron (MLP) extracts nonlinear fine-grained features; Dynamic Feature Projection (DFP) generates linear fine-grained features. The outputs are then fused by summation to produce enhanced fine-grained representations. Notably, in the local feature selection stage, a novel weighted-median adaptive filtering strategy driven by token frequency distribution is proposed, replacing conventional static empirical ratio settings. To further strengthen feature alignment, Grouped Contrastive Learning (GCL) is designed, which dynamically partitions negative samples into three groups: hard-dominated, semi-hard-dominated, and easy-dominated, based on similarity score gaps with positive samples. Each group is assigned distinct margin constants to enable targeted decision boundary adjustment, effectively balancing the influence of diverse negative sample groups during training. Experimental results demonstrate that our approach significantly improves text-to-image retrieval accuracy. Specifically, on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets, Rank-1 accuracy outperforms the method of Qin et al. [1] by 1.12 %, 0.68 %, and 1.85 %, respectively. The code is available at: https://github.com/DylanHurst/DG .},
  archive      = {J_KBS},
  author       = {Shun He and Canlong Zhang and Xiaochun Lu and Zhixin Li and Zhiwen Wang},
  doi          = {10.1016/j.knosys.2025.114553},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114553},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic feature projection and grouped contrastive learning for text-to-image person re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MgHiSal: MLLM-guided hierarchical semantic alignment for multimodal knowledge graph completion. <em>KBS</em>, <em>330</em>, 114552. (<a href='https://doi.org/10.1016/j.knosys.2025.114552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Knowledge Graph Completion (MMKGC) aims to improve link prediction and empower downstream applications like intelligent question answering, reasoning, and recommendation by integrating multimodal information. However, existing methods commonly face semantic fragmentation between visual and textual modalities. This issue largely stems from the reliance on pre-trained vision models, which often struggle to model deep entity semantics, resulting in noisy visual features and the neglect of key semantic information. To address this, we propose MgHiSal, an MLLM-guided Hierarchical Semantic Alignment framework for MMKGC. MgHiSal first generates context-aware visual descriptions by conditioning MLLM generation on existing entity text, ensuring low-noise, relevant representations for initial semantic alignment. The framework then utilizes a hierarchical gated attention mechanism that progressively unifies multimodal representations by dynamically selecting and optimizing key cross-modal features via regularization. Finally, a neighbor-aware module enhances entity representations by aggregating multimodal neighbor information. Experiments on DB15K and MKG-W show MgHiSal significantly improves MRR by approximately 13.1 % and 12.5 % over respective runner-ups. The source code is publicly available at https://github.com/wyZhang016/MgHiSal .},
  archive      = {J_KBS},
  author       = {Jie Chen and Wuyang Zhang and Shu Zhao and Yunxia Yin},
  doi          = {10.1016/j.knosys.2025.114552},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114552},
  shortjournal = {Knowl. Based Syst.},
  title        = {MgHiSal: MLLM-guided hierarchical semantic alignment for multimodal knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing deep clustering through the synergy of contrastive learning and capsule-GAN. <em>KBS</em>, <em>330</em>, 114551. (<a href='https://doi.org/10.1016/j.knosys.2025.114551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a collaborative deep clustering framework that synergistically integrates contrastive learning with a capsule-based GAN. Specifically, the framework first generates augmented image variants via employing multi-resolution cropping and rotation on real images. Both original and augmented images are processed through a clustering network, where mutual learning between data instances promotes consistent cluster label assignments. Then these labels are transformed into one-hot encoded vectors and combined with random latent variables to drive a capsule-based generator, which synthesizes high-fidelity images. A capsule-based discriminator evaluates real and synthetic images, providing informative gradient feedback to iteratively enhance the generator’s output quality. Following this, synthetic and real images are grouped into clusters using a one-vs-rest strategy. Images assigned to the same cluster are considered as positive pairs, while those from different clusters are as negative pairs. These pairwise relationships are leveraged within a contrastive learning framework to improve the model’s ability to learn discriminative, cluster-friendly representations. Experimental results on several image datasets, including MNIST, Fashion-MNIST, CIFAR-10, STL-10, ImageNet-10, and ImageNet-Dog, have demonstrated that our method consistently outperforms state-of-the-art deep clustering approaches in terms of clustering accuracy and normalized mutual information (NMI). An ablation study further confirms the effectiveness of each component and highlights their collective contribution to clustering performance improvement. Overall, this work establishes a foundation for unified representation learning and clustering through the interplay of adversarial training and contrastive optimization.},
  archive      = {J_KBS},
  author       = {Wenming Cao and Zhongfan Zhang and Man Li and Zhiwen Yu},
  doi          = {10.1016/j.knosys.2025.114551},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114551},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing deep clustering through the synergy of contrastive learning and capsule-GAN},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention focus network for few-shot skeleton-based action recognition. <em>KBS</em>, <em>330</em>, 114549. (<a href='https://doi.org/10.1016/j.knosys.2025.114549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition is a challenging yet practically significant problem that involves developing a model capable of learning discriminative features from a small number of labeled samples to recognize new action categories. Current methods typically infer spatial relationships either within or across skeletons to learn action representations, but this often results in features with insufficient discriminability and ineffective attention to critical body parts. To address these limitations, we propose DAF-Net, a novel framework that employs focal attention to jointly model intra-skeleton and inter-skeleton relationships, enhancing discriminative feature learning in few-shot skeleton-based action recognition. Unlike traditional methods that focus solely on intra-skeleton dependencies or inter-skeleton structures, DAF-Net dynamically integrates both components via focal attention, enhancing key body part representation and refining features, particularly in data-scarce conditions. Furthermore, DAF-Net incorporates an enhanced prototype generation strategy, optimizing class prototype formation via cosine similarity weighting to further improve feature discriminability in multi-shot scenarios. In temporal matching, cosine similarity evaluates local feature similarity within skeleton sequences, capturing directional variations of specific joints over time. Extensive experiments on three benchmark datasets (NTU-T, NTU-S, and Kinetics-skeleton) confirm significant performance gains, validating the effectiveness of DAF-Net.},
  archive      = {J_KBS},
  author       = {Jie Liu and Chongben Tao and Zhongwei Shen and Cong Wu and Tianyang Xu and Xizhao Luo and Feng Cao and Zhen Gao and Zufeng Zhang and Sai Xu},
  doi          = {10.1016/j.knosys.2025.114549},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114549},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual attention focus network for few-shot skeleton-based action recognition},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation. <em>KBS</em>, <em>330</em>, 114548. (<a href='https://doi.org/10.1016/j.knosys.2025.114548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbes are microorganisms with biological molecules and have significant therapeutic potential for treating diseases, underscoring the need for computational methods to screen microbes targeting disease-associated drugs. However, the computational methods often consider node embedding or structure features between microbes and drugs, and have a severe class imbalance problem inherent in sparse association data. In this work, we proposed a heterogeneous graph collaborative representation learning model that combines the merits of attentive fusion and reciprocal distillation for drug-related microbe prediction. First, we constructed the heterogeneous biological information and meta-path-induced graphs of microbes and drugs. Then, a topological structure feature encoder is devised to extract complex topological and semantic interaction patterns from heterogeneous biological graphs with microbes and drugs, while an efficient transformer concurrently extracts discriminative semantic and structural information based on the graph position information of nodes. Next, a reciprocal distillation schema is developed to mitigate the adverse effects of the data imbalance problem, and enable the distribution consistency of the model between topological and semantic information extraction. Moreover, we devised a dual collaborative feature fusion schema that combines graph topological and dual meta-path-based semantic features to obtain the discriminative features of microbes and drugs. Through reciprocal distillation, an efficient optimization function focuses on hard-to-classify samples of drug-related microbes via discriminative features. Extensive experiments demonstrate that our model could deal with the association sparsity problem and extract more semantics and structure. Meanwhile, case studies indicate that our model could discover reliable candidate microbes associated with a special drug.},
  archive      = {J_KBS},
  author       = {Yanbu Guo and Quanming Guo and Shengli Song and Yihan Wang and Jinde Cao},
  doi          = {10.1016/j.knosys.2025.114548},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114548},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring non-negativity for improved manifold embedding: Application to t-SNE. <em>KBS</em>, <em>330</em>, 114547. (<a href='https://doi.org/10.1016/j.knosys.2025.114547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing inspiration from Non-negative Matrix Factorization (NMF), this paper explores the potential of incorporating non-negativity constraints into embedding techniques, with a focus on t-SNE as an application. Specifically, we investigate the following questions: Can enforcing non-negativity in the embedding space enhance interpretability and improve the quality of embedded data? By prioritizing non-negativity, can embedding methods achieve better performance and more meaningful representations? Additionally, does enforcing non-negativity in the embedded space help preserve both the local and global structure of data in the manifold, leading to more accurate and interpretable embeddings? In this work, we could show both objectively and subjectively how enforcing t-SNE to leverage the non-negativity of the data addresses the raised questions. To achieve this, we introduced a novel approach to transforming the additive update rule of the gradient descent used by t-SNE to a multiplicative counterpart to enforce the non-negativity in the embedded space. However, grappling with full non-negativity in the gradient descent formula presents challenges, prompting our focus solely on the ( y i − y j ) term, resulting in a semi-non-negative t-SNE algorithm, shortly named SN-tSNE. Nevertheless, experimental findings substantiate the significant impact of the proposed update rule on the performance and efficacy of the SN-tSNE algorithm. Furthermore, additional experiments are performed to compare SN-tSNE with its precursor t-SNE, as well as the competitive embedding technique UMAP, alongside other relevant embedding and dimensionality reduction models like NMF. The source code of SN-tSNE is available on GitHub ( https://github.com/M-Allaoui/SN-tSNE.git ).},
  archive      = {J_KBS},
  author       = {Mebarka Allaoui and Rachid Hedjam and Khadra Bouanane and Mohand Saïd Allili and Mohammed Lamine Kherfi and Samir Brahim Belhaouari},
  doi          = {10.1016/j.knosys.2025.114547},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114547},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploring non-negativity for improved manifold embedding: Application to t-SNE},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vision transformer-based hybrid neural architecture for automated handwritten bangla character recognition and braille conversion. <em>KBS</em>, <em>330</em>, 114546. (<a href='https://doi.org/10.1016/j.knosys.2025.114546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of technology has led to notable changes in the current educational system. Nevertheless, there are still relatively few assisting aids that can help in teaching individuals with disabilities, such as those who are blind or visually impaired. An effective teaching strategy for those who are blind or visually impaired is braille. Although it has been digitized to produce an electronic version, handwritten characters are not considered in those versions. Studies on English character recognition have shown high accuracy, which is not the case with Bangla character recognition. We present an automated system that converts handwritten Bangla characters to braille using novel hybrid deep neural network architectures. Our approach begins with a Character Quality Assessment Framework (CQAF), which employs adaptive thresholds and comprehensive quality metrics designed explicitly for Bangla script characteristics. Building upon this foundation, we present two architectures. HybridNet-L represents our initial multi-stream design, while HybridNet-S is a redesigned lightweight variant that reduces parameters and achieves superior accuracy, making it the primary contribution of this work. To complete the system, we implement a comprehensive accessibility solution featuring real-time braille hardware interface and text-to-speech capabilities. The model effectively processes all 84 Bangla character classes including vowels, consonants, numerics, and compound characters. Extensive evaluation against seven baseline models demonstrates that our HybridNet-S achieves superior performance with 95.80% validation accuracy while maintaining computational efficiency suitable for embedded deployment. Statistical validation and ablation studies confirm the robustness and effectiveness of our multi-stream architecture for practical assistive technology applications.},
  archive      = {J_KBS},
  author       = {Touseef Saleh Bin Ahmed and Tawhidur Rahman and Shammo Biswas and Saifur Rahman Sabuj and Mohammed Belal Bhuian and Mohammad Ali Moni and Md Ashraful Alam},
  doi          = {10.1016/j.knosys.2025.114546},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114546},
  shortjournal = {Knowl. Based Syst.},
  title        = {A vision transformer-based hybrid neural architecture for automated handwritten bangla character recognition and braille conversion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A winner effect based approach for multimodal review helpfulness prediction with deep learning algorithm. <em>KBS</em>, <em>330</em>, 114545. (<a href='https://doi.org/10.1016/j.knosys.2025.114545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of multimodal online reviews, integrating texts and images, presents opportunities and poses challenges for predicting review helpfulness, which is crucial for supporting consumer decision-making. Despite growing research, persistent contradictions regarding both textual and visual features have intensified the need to identify decisive factors among reviews. This study addresses this gap by developing a neuroscientific computation framework that integrates the winner effect—a cognitive mechanism wherein dominant stimuli hierarchically shape decision-making processes—into a Winner Effect-Enhanced Attention Mechanism (WE-EAM). The proposed deep learning framework dynamically amplifies discriminative multimodal features through a novel win-increase and lose-decrease self-attention mechanism. Based on an evaluation of 30,000 Yelp restaurant reviews, three key insights emerged: 1) the proposed method of WE-EAM deep learning framework achieves 88.72 % accuracy in multimodal helpfulness prediction, outperforming state-of-the-art models by 4.45 % in late-fusion scenario. 2) Late fusion strategy in latent space outperformed early and hybrid fusion strategies across single- and multi-head attention configurations, especially the winner effect ratio achieving 0.5. Therefore, late fusion strategy leveraging the winner effect is the superior approach for mining discriminative multimodal representations. 3) Visualization analyses confirm that the model overemphasizes initial review segments where core sentiments are expressed. These findings advance computational modeling through two actionable strategies that bridge cognitive neuroscience and machine learning: both late compositing of text and image features into WE-EAM deep learning framework and highlighting early-segment content may enhance review helpfulness prediction.},
  archive      = {J_KBS},
  author       = {Donghui Yang and Mingyang Zhang and Yongbo Ni and Siyuan Xu and Kehui Zhu},
  doi          = {10.1016/j.knosys.2025.114545},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114545},
  shortjournal = {Knowl. Based Syst.},
  title        = {A winner effect based approach for multimodal review helpfulness prediction with deep learning algorithm},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced smart farming system based multi-anchor space-aware temporal convolutional neural networks in internet-of-things. <em>KBS</em>, <em>330</em>, 114544. (<a href='https://doi.org/10.1016/j.knosys.2025.114544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is an important to the economic growth of a country. Farmers possess until recently employed standard farming methods. Accurate farming helps boost output by accurately identifying the actions that must be taken at the right time. Precision farming includes forecasting the weather, evaluating the soil, suggesting crops to grow, and figuring out the fertilizer the crops require. In this paper, an Advanced Smart Farming System based Multi-anchor Space-aware Temporal Convolutional Neural Networks in Internet-of-Things (ASFS-MSTCNN-IoT) is proposed. Initially, the input data is taken from Indian Agriculture Dataset. Then, the input data is pre-processed utilizingCompact Maximal Correntropy-derived Error State Kalman Filter (CMCESKF)which is used to remove the outliers from the input data. The pre-processed data are given into Deep Kernel Principal Component Analysis (DKPCA)which reduces the high dimensionality of the data. Generally, MSTCNN does not show any adaption of optimization methods for finding the optimal parameters to ensure exactforecastof crop yield. Black-Winged Kite Algorithm (BWKA) is proposed in this work to optimize the weight parameter of MSTCNN classifier, which predicts the crop yield precisely. The ASFS-MSTCNN-IoT approach is implemented and analyzed with the help of performance metrics like Mean Absolute Error (MAE), Mean Square Error (MSE), Mean Absolute Percentage Error (MAPE), R 2 and Root Mean Square Error (RMSE) is evaluated. Performance of the ASFS-MSTCNN-IoT approach attains17.85%, 25.82%, 32.64% lower Mean Absolute Error, 25.43%, 19.94%, 31.68% lower Mean Absolute Percentage Error and 18.59%, 25.64% and 31.89% higher R 2 with existing methods respectively.},
  archive      = {J_KBS},
  author       = {M Shanmathi and Kumar S Praveen},
  doi          = {10.1016/j.knosys.2025.114544},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114544},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced smart farming system based multi-anchor space-aware temporal convolutional neural networks in internet-of-things},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm. <em>KBS</em>, <em>330</em>, 114543. (<a href='https://doi.org/10.1016/j.knosys.2025.114543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendations for optimal pick-up points significantly enhance service efficiency, reduce economic and temporal costs, and alleviate traffic congestion. However, spatiotemporal imbalance between ride-hailing supply and passenger demand presents significant challenges. Current models often overlook critical influencing factors such as passenger satisfaction, travel environment, and travel cost factors. Moreover, solution algorithms, including exact algorithms and heuristics, struggle to achieve global optimality and computational efficiency in large-scale scenarios. This study introduces a comprehensive mathematical model that incorporates four key influencing factors: passenger walking distance, passenger waiting time, traffic conditions, and estimated ride-hailing fare. The solution approach consists of a novel pick-up point evaluation algorithm and an incentive-based adaptive Kuhn-Munkres matching algorithm. The evaluation algorithm employs a multi-modal decision tree structure, enhanced by deep learning techniques to improve the accuracy of pick-up point evaluations. The matching algorithm features a multi-scenario adaptive mechanism that dynamically adjusts edge weights and selects optimal edges for augmentation under various conditions and strategies, thereby ensuring globally optimal matching of passengers and pick-up points. Extensive experiments on large-scale real-world datasets validate the superior performance of the evaluation and matching algorithms, especially in handling large-scale instances. The developed model and algorithms assist ride-hailing platforms in optimizing operations, enhancing service quality, increasing profitability, and improving cost management.},
  archive      = {J_KBS},
  author       = {Yuhan Guo and Rushi Zhu and Wenhua Li and Youssef Boulaksil and Hamid Allaoui},
  doi          = {10.1016/j.knosys.2025.114543},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114543},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-modal document distillation with energy-weighted supervision. <em>KBS</em>, <em>330</em>, 114542. (<a href='https://doi.org/10.1016/j.knosys.2025.114542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large multi-modal document models (e.g. LayoutLMv3) grow increasingly complex, knowledge distillation (KD) has become essential for practical deployment. EnergyKD enhances conventional logit-based KD by adjusting temperature per sample using energy scores. However, it still misleads students when teacher predictions are incorrect on high energy (i.e. low confidence) inputs. Although High-Energy Data Augmentation (HE- DA) is introduced to address this issue, it adds significant training overhead. In this work, we propose Energy-Weighted Supervision (EWS), a general-purpose supervision augmentation framework that builds upon an energy-based sample stratification mechanism. EWS dynamically adjusts the balance between hard-label and soft-label losses according to each sample’s energy score, thereby increasing the likelihood that the student model receives accurate and corrective supervision, without requiring additional data augmentation or training overhead. Our experiments demonstrate that EWS effectively improves the performance of various KD methods. On the harder FUNSD benchmark, EWS yields the largest gains (+2.35 F1), while on CORD and SROIE the improvements are smaller but consistently positive (up to +0.84 and +0.11 F1, respectively), confirming broad applicability across KD paradigms. Especially, when applied to EnergyKD, EWS addresses its core limitation, namely, the misleading influence of sharpened teacher outputs on high energy samples, by allocating greater weight to hard-label signals. Conversely, for low energy samples, EWS preserves soft-label emphasis to fully exploit the teacher’s informative predictions. Compared to conventional logit-based KD, EnergyKD, and even HE-DA, our energy-guided loss modulation approach consistently improves student performance across multiple documents understanding benchmarks, without additional training cost. To the best of our knowledge, this is the first framework in multi-modal document distillation that simultaneously integrates energy-aware temperature scaling and dynamic supervision weighting, offering a promising direction for future research and deployment on resource-limited devices.},
  archive      = {J_KBS},
  author       = {Jen-Chun Chang and Chia-Cheng Lee and Chung-Fu Lu and Victor R.L. Shen},
  doi          = {10.1016/j.knosys.2025.114542},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114542},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing multi-modal document distillation with energy-weighted supervision},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSDC-net: Robust self-supervised dynamic collaboration network for infrared and visible image fusion. <em>KBS</em>, <em>330</em>, 114541. (<a href='https://doi.org/10.1016/j.knosys.2025.114541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to integrate complementary information from distinct sensors, yielding fused results that outperform the capabilities of either individual modality alone. Due to inherent modality bias, conventional fusion-reconstruction frameworks often struggle to effectively prioritize the representation of critical shared regions and diverse heterogeneous areas, while also showing deficiencies in shallow feature interactions. To address these challenges, we propose a robust self-supervised dynamic collaboration network (RSDC-Net), which adaptively and comprehensively selects complementary cues from both infrared and visible modalities. Specifically, we introduce a steady-state contrastive autoencoder that leverages a multi-task self-supervised strategy to enhance the robust representation of key shared cues in the mixed information flow. This strategy promotes deep cross-modal modeling of global dependencies across sources, thereby achieving semantic consistency. Furthermore, we design a latent inter-modal focus-guided module that integrates a bilateral transposed attention mechanism with a dynamic selection component to refine local-level heterogeneous cue allocation under the guidance of mutual global dependencies. Notably, a gated feed-forward unit is incorporated to filter outlier information flows across modalities. Quantitative results on the MSRS, TNO, and M3FD datasets demonstrate that RSDC-Net achieves the best performance on most of the eight evaluation metrics. Meanwhile, it also exhibits superior performance in qualitative visual assessments on these datasets as well as under challenging scenarios.},
  archive      = {J_KBS},
  author       = {Yun Li and Ningyuan Zhao and Xue Yang and Liping Luo and Peiguang Jing},
  doi          = {10.1016/j.knosys.2025.114541},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114541},
  shortjournal = {Knowl. Based Syst.},
  title        = {RSDC-net: Robust self-supervised dynamic collaboration network for infrared and visible image fusion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding. <em>KBS</em>, <em>330</em>, 114540. (<a href='https://doi.org/10.1016/j.knosys.2025.114540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery electroencephalography (MI-EEG) decoding is a crucial component of brain-computer interface (BCI) systems, serving as a valuable tool for motor function rehabilitation and fundamental neuroscience research. However, the strong nonlinearity and non-stationarity of MI-EEG signals make achieving high-precision decoding a challenging task. Current deep learning methods primarily extract the spatiotemporal features of MI-EEG signals while neglecting their potential association with spectral-topological features, thereby limiting the ability to integrate multidimensional information. To address these limitations, this paper proposes a Topology-Aware Multiscale Feature Fusion network (TA-MFF network) for MI-EEG signal decoding. Specifically, we designed a Spectral-Topological Data Analysis-Processing (S-TDA-P) module that leverages persistent homology features to analyze the spatial topological relationships between EEG electrodes and the persistent patterns of neural activity. Then, the Inter Spectral Recursive Attention (ISRA) mechanism is employed to model the correlations between different frequency bands, enhancing critical spectral features while suppressing irrelevant noise. Finally, the Spectral-Topological and Spatio-Temporal Feature Fusion (SS-FF) Unit is employed to progressively integrate topological, spectral, and spatiotemporal features, capturing dependencies across different domains. The experimental results show that the classification accuracy of the proposed model in BCIC-IV-2a, BCIC-IV-2b, and BCIC-III-Iva is 85.87 %, 90.2 %, and 80.5 %, respectively, outperforming the most advanced methods.},
  archive      = {J_KBS},
  author       = {Chaowen Shen and Akio Namiki},
  doi          = {10.1016/j.knosys.2025.114540},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114540},
  shortjournal = {Knowl. Based Syst.},
  title        = {A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DriveFL: A dynamic reputation incentive mechanism for federated learning in dense internet of vehicles. <em>KBS</em>, <em>330</em>, 114539. (<a href='https://doi.org/10.1016/j.knosys.2025.114539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables devices to use data locally for model training and thus has received significant attention for protecting data privacy in the Internet of Vehicles (IoV). However, rational vehicles are reluctant to contribute their data to participate in training without compensation, necessitating the implementation of effective incentive algorithms to motivate vehicles to participate in training. Nevertheless, unlike incentives in other domains, the IoV has the following challenges for the design of incentive systems. First, the large number of vehicles in a dense IoT imposes a huge communication burden and pressure on computational efficiency. Second, road data used by vehicles for training may be affected by factors such as damaged sensors or harsh environments, resulting in changes in data quality. Third, intermittent participation issues are caused by the vehicle’s mobility. To address these issues, we propose DriveFL: A Dynamic Reputation Incentive Mechanism for Federated Learning in Dense Internet of Vehicles. Specifically, we employ gradient compression techniques to reduce communication costs. Subsequently, we design a similarity-based gradient compression quality assessment method capable of evaluating the quality of vehicle data in real time. Then, we develop a dynamic reputation incentive mechanism that quantifies quality assessment records and integrates reverse auction theory, which can attract vehicles with higher data quality from those that intermittently participate in training, thereby enhancing model training quality under constrained communication costs and budget limitations. Theoretical analysis demonstrates that our mechanism satisfies computational efficiency, individual rationality, budget feasibility, and truthfulness. Simulation experiments confirm the effectiveness of our approach.},
  archive      = {J_KBS},
  author       = {Xin Chang and Lixin Liu and Jingyu Wang and Jinling Yu and Xiaolin Zhang},
  doi          = {10.1016/j.knosys.2025.114539},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114539},
  shortjournal = {Knowl. Based Syst.},
  title        = {DriveFL: A dynamic reputation incentive mechanism for federated learning in dense internet of vehicles},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PFI-fuse: Parallel frequency-invertible adversarial network for infrared and visible image fusion. <em>KBS</em>, <em>330</em>, 114538. (<a href='https://doi.org/10.1016/j.knosys.2025.114538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion integrates complementary information from multimodal sensors into a single informative representation, thereby enhancing scene perception and promoting applications in computer vision tasks. Despite recent advances, existing generative adversarial network (GAN)-based methods continue to face significant challenges, including entangled holistic feature processing, inefficient frequency separation, and substantial computational overhead. To address these issues, we propose a parallel frequency-invertible adversarial network for infrared and visible image fusion, termed PFI-Fuse. Operating in the wavelet domain, PFI-Fuse employs a divide-and-conquer strategy to process different frequency subbands in parallel, allowing the model to better capture both global structures and fine-grained textures. More importantly, we introduce a frequency-invertible generator, which incorporates invertible neural blocks to ensure that critical frequency information is preserved throughout the fusion process, ensuring minimal information loss. Furthermore, we introduce a wavelet modulation loss, which dynamically adjusts subband contributions during adversarial training. This adaptive loss encourages the network to balance structural preservation, texture detail enhancement, and intensity consistency across all frequency components. Extensive experiments on different benchmarks and downstream applications demonstrate that PFI-Fuse consistently outperforms existing state-of-the-art methods in both quantitative metrics and visual quality, while also achieving superior computational efficiency. The source code will be available at: https://github.com/Zhuoqun-Zhang/PFI-Fuse .},
  archive      = {J_KBS},
  author       = {Zhuoqun Zhang and Xin Wang and Zhishe Wang and Jiawei Xu and Fengbao Yang},
  doi          = {10.1016/j.knosys.2025.114538},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114538},
  shortjournal = {Knowl. Based Syst.},
  title        = {PFI-fuse: Parallel frequency-invertible adversarial network for infrared and visible image fusion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient cluster-guided key timestamp discovery for temporal knowledge graph completion. <em>KBS</em>, <em>330</em>, 114537. (<a href='https://doi.org/10.1016/j.knosys.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) completion aims to infer the missing links from the numerous historical facts. Accurate evolutionary representations of entities from each recent KG snapshot are fundamental for TKG completion. Recent research has focused on incorporating the fixed lengths of KG sequences as well as the timestamps information, resulting in lacking flexible judgment on “time lag” issue. To address the issue, we propose CutTKG, an efficient C luster-g u ided key t imestamps discovery method with contrastive learning for TKG completion. Specifically, we first attempt to identify the most relevant historical facts within the key timestamps by utilizing an efficient clustering method for the associated relations. Then, we propose a multi-view representation learning method to learn the representations of entities from the divided related-history view and unrelated-history view. Finally, we design a contrastive learning strategy to alleviate the negative impact of irrelevant facts and further make the CutTKG primarily focus on the most relevant facts. Extensive experiments demonstrate that our CutTKG model achieves new state-of-the-art results on four benchmark datasets.},
  archive      = {J_KBS},
  author       = {Yao Xiao and Guangyou Zhou and Zhiwen Xie and Jin Liu and Jimmy Xiangji Huang},
  doi          = {10.1016/j.knosys.2025.114537},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient cluster-guided key timestamp discovery for temporal knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward more effective bag-of-functions architectures: Exploring initialization and sparse parameter representation. <em>KBS</em>, <em>330</em>, 114536. (<a href='https://doi.org/10.1016/j.knosys.2025.114536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series datasets often present complex temporal patterns that challenge both feature extraction and interpretability. The Bag-of-Functions (BoF) architecture has emerged as a promising approach to model such data by capturing diverse dynamics through functional components. However, its effectiveness is constrained by limitations in both interpretability and training stability. In this work, we address these challenges by introducing two complementary contributions: a regularization strategy that promotes sparse and interpretable parameter representations, and a tailored initialization scheme based on the Kaiming method adapted to the properties of BoF models. Our proposed initialization ensures improved convergence behavior and training stability, while the regularization enhances the clarity and semantic interpretability of the learned components. Evaluations on synthetic and real-world time series datasets demonstrate that these improvements preserve model performance and generalize well across varying signal complexities. Together, these strategies provide a more robust and interpretable foundation for Bag-of-Functions architectures in time series decomposition tasks.},
  archive      = {J_KBS},
  author       = {David Orlando Salazar Torres and Diyar Altinses and Andreas Schwung},
  doi          = {10.1016/j.knosys.2025.114536},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114536},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward more effective bag-of-functions architectures: Exploring initialization and sparse parameter representation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective embedding for deep learning. <em>KBS</em>, <em>330</em>, 114535. (<a href='https://doi.org/10.1016/j.knosys.2025.114535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy for many deep learning architectures while significantly reducing training times. Across multiple datasets, selective embedding consistently improves test accuracy by 20 to 30 percent compared to traditional single-channel loading strategies, while also matching or exceeding the performance of parallel multi-source loading methods. Importantly, these gains are achieved while significantly reducing training times, demonstrating both efficiency and scalability across simple and complex architectures. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.},
  archive      = {J_KBS},
  author       = {Mert Sehri and Zehui Hua and Francisco de Assis Boldt and Patrick Dumond},
  doi          = {10.1016/j.knosys.2025.114535},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Selective embedding for deep learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting. <em>KBS</em>, <em>330</em>, 114533. (<a href='https://doi.org/10.1016/j.knosys.2025.114533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is a crucial task for the Intelligent Transportation System (ITS). A promising research direction for improving traffic prediction is to learn dynamic graph structures incorporating the hidden dependencies from the training sequence data. However, existing works optimize these dynamic graph structures only for the training data, regarding them as static when testing with new input sequences. This constrains the forecasting model’s ability to address potential discrepancies between training and testing sequences, which may arise from unforeseen changes in the traffic environment. To address this challenge, we propose a new encoder-decoder framework for traffic forecasting, S equence-aware Adaptive Graph Convolutional Recurrent Networks ( SAGCRN ). The encoder augments an input sequence by exploiting spatio-temporal contexts and traffic pattern storage. Then, the decoder adaptively learns a new graph structure reflecting the augmented input sequence and uses it for prediction. To further enhance the sequence-specialized graph structure, SAGCRN optimizes the stored traffic patterns to be more discriminative. We demonstrate the superior performance of SAGCRN on three real-world benchmark datasets, comparing it with nine baseline models. The additional sensitivity and qualitative analyses substantiate the effectiveness of our model. For reproducibility, the source code is available at https://github.com/gooriiie/SAGCRN .},
  archive      = {J_KBS},
  author       = {Seunghoon Han and Hyewon Lee and Daniel Y. Lee and Sung-Soo Kim and Susik Yoon and Sungsu Lim},
  doi          = {10.1016/j.knosys.2025.114533},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114533},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection. <em>KBS</em>, <em>330</em>, 114532. (<a href='https://doi.org/10.1016/j.knosys.2025.114532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous species have evolved camouflage through morphological adaptations that mimic environmental colors and textures, posing significant challenges for visual detection systems. Current camouflaged object detection (COD) methods remain limited in simulating biological visual mechanisms due to inadequate multi-stage cognitive modeling and weak biological correspondence in neural computations. To address these limitations, a parallel visual perception network (NSNPVPNet) based on nonlinear spiking neural P (NSNP) systems is proposed, simulating biological visual processes through three core modules: scene perception, cognitive reasoning, and decision inference module. A bio-inspired convolutional block reconstructed through NSNP systems enhances biological-computational mapping relationships. Experimental evaluations across four benchmark datasets demonstrate superior performance over twenty state-of-the-art COD methods, achieving average metric improvements of 3.2% ( S m ), 2.5% ( a E m ), 5.4% ( F β w ), and 1.2% ( M ). These advancements validate NSNP systems’ potential in COD applications and pioneer new bio-inspired approaches for bionic visual computing. The implementation is available at: https://github.com/Williamzhounan/NSNPVPNet .},
  archive      = {J_KBS},
  author       = {Nan Zhou and Hong Peng and Zhicai Liu},
  doi          = {10.1016/j.knosys.2025.114532},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114532},
  shortjournal = {Knowl. Based Syst.},
  title        = {The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot hyperspectral image classification with mamba and manifold convolution fusion network. <em>KBS</em>, <em>330</em>, 114531. (<a href='https://doi.org/10.1016/j.knosys.2025.114531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient modeling of global-local features is crucial for hyperspectral image (HSI) classification. The mamba network demonstrates strong capability in capturing global dependencies in HSI classification tasks, primarily utilizing a state-space model to extract first-order statistical features of spectral-spatial information in euclidean space, providing an initial representation of data characteristics. However, under few-shot conditions, fully exploiting effective features from limited samples and overcoming challenges such as class overlap and feature space sparsity caused by the insufficient extraction of second-order statistical features in riemannian space remain major research challenges. Therefore, we propose a dual branch manifold convolution-mamba network (DBMCMamba) for HSI classification. Specifically, it adaptively fuses forward and backward information through the vision mamba (Vim) block and utilizes the S6 module to extract global information, thereby enhancing global feature extraction capability. Meanwhile, the manifold convolution module extracts first-order statistical features of spectral-spatial information through convolutional layers and learns second-order statistics via the SPD manifold to strengthen DBMCMamba’s local feature representation under few-shot conditions. Finally, global and local features are fused for classification, effectively improving the accuracy and performance of HSI classification. On the Indian Pines, Pavia University, HongHu, and HanChuan datasets, DBMCMamba achieved classification accuracies of 95.23 %, 95.80 %, 95.58 %, and 94.93 %, respectively. Experimental results show that DBMCMamba demonstrates significant performance improvements compared to the state-of-the-art classification models. The code will be available online at https://github.com/ASDFFGG121EAA/DBMCMamba .},
  archive      = {J_KBS},
  author       = {Heling Cao and Yanlong Guo and Yonghe Chu and Yun Wang and Junyi Duan and Peng Li},
  doi          = {10.1016/j.knosys.2025.114531},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114531},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot hyperspectral image classification with mamba and manifold convolution fusion network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ICD classification with semantic embedding rectification and long-tail refinement. <em>KBS</em>, <em>330</em>, 114530. (<a href='https://doi.org/10.1016/j.knosys.2025.114530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic International Classification of Diseases (ICD) coding is essential for healthcare systems, enabling accurate clinical documentation and decision-making. However, existing models struggle with two critical challenges: (1) semantic misalignment between clinical texts and ICD codes, leading to inaccurate label representations, and (2) long-tail label distribution, where low-frequency ICD codes suffer from poor generalization. To address these issues, we propose RoSimTail-ICD , an innovative framework that incorporates two newly developed modules: Semantic Space Discrepancy Correction (SSDC) and Multi-stage Adaptive Tail Refinement (MATR). SSDC enhances the alignment between clinical text embeddings and ICD label representations, mitigating semantic drift and improving prediction robustness. MATR dynamically refines tail label learning by progressively adjusting label segmentation and training dynamics, ensuring sufficient representation learning for rare labels. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that RoSimTail-ICD consistently outperforms state-of-the-art models. These results demonstrate the effectiveness of our approach in tackling both semantic inconsistency and long-tail label imbalance, paving the way for more accurate and robust automated ICD coding.},
  archive      = {J_KBS},
  author       = {Yuhao Wu and Yifan Wu and Wei Fan and Min Li},
  doi          = {10.1016/j.knosys.2025.114530},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114530},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing ICD classification with semantic embedding rectification and long-tail refinement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPMFF-net: A training-free unified framework for point cloud classification and segmentation. <em>KBS</em>, <em>330</em>, 114529. (<a href='https://doi.org/10.1016/j.knosys.2025.114529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parametric networks have shown promise for understanding point clouds due to their training-free nature and low computational cost. However, existing methods such as Point-NN and Seg-NN underutilize geometric and frequency information. Although these methods demonstrate superior accuracy, we found that the potential features of point clouds can still be explored in depth. In this work, we revisit non-parametric networks and propose the Non-Parametric Multi-scale Feature Fusion Network (NPMFF-Net), a model designed to unify spatial and frequency information in point cloud analysis, featuring training-free components. The key is Plücker coordinates Encoding and Fourier Feature Mapping, combining geometric information with high-frequency features. We propose a non-parametric attention module to integrate contextual information and k-adaptive normal pooling to aggregate multi-scale features. Extensive experiments on the ModelNet10/40, ScanObjectNN, ShapeNetPart, S3DIS, and ScanNet datasets demonstrate the superiority of NPMFF-Net in point classification and segmentation tasks. We surpass Point-NN by 8.2 % OA and Seg-NN by 5.8 % OA on ModelNet40 for classification, while also achieving a 2.7 % improvement in mean IoU over Point-NN on ShapeNetPart for part segmentation.},
  archive      = {J_KBS},
  author       = {Hualong Zeng and Haijiang Zhu and Huaiyuan Yu and Mengting Liu and Ning An},
  doi          = {10.1016/j.knosys.2025.114529},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114529},
  shortjournal = {Knowl. Based Syst.},
  title        = {NPMFF-net: A training-free unified framework for point cloud classification and segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical reinforcement learning for dynamic collision avoidance of autonomous ships under uncertain scenarios. <em>KBS</em>, <em>330</em>, 114528. (<a href='https://doi.org/10.1016/j.knosys.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous ships hold substantial potential for enhancing navigational safety, improving collision avoidance efficiency, and increasing adaptability in complex maritime environments, thereby presenting broad prospects for intelligent shipping. This paper introduces a dynamic collision avoidance control method based on a hierarchical reinforcement learning framework for autonomous ships. By integrating high-level global intent planning with low-level fine-grained rudder control, the proposed approach markedly enhances the interpretability, stability, and behavioral consistency of the learned policy. Furthermore, a multidimensional uncertainty modeling mechanism is incorporated during training, systematically accounting for variations in initial states and obstacle behavior patterns, which effectively strengthens policy adaptability and generalization under uncertain conditions. To validate the method, simulations are conducted in representative encounter scenarios as well as in omnidirectional dynamic obstacle tests. A comprehensive evaluation is carried out using multiple control performance metrics, environmental adaptability analysis, policy consistency assessment, and equivalent energy consumption comparisons. The results confirm that the proposed approach achieves stable and reliable intelligent collision avoidance control in highly dynamic environments, offering a feasible and scalable solution for high-performance collision avoidance in intelligent maritime navigation.},
  archive      = {J_KBS},
  author       = {Sijin Yu and Yunbo Li and Jiaye Gong},
  doi          = {10.1016/j.knosys.2025.114528},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical reinforcement learning for dynamic collision avoidance of autonomous ships under uncertain scenarios},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering novel scientific insights with a synergistic GNN-LLM framework. <em>KBS</em>, <em>330</em>, 114527. (<a href='https://doi.org/10.1016/j.knosys.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of scientific literature demands intelligent systems capable of uncovering emerging knowledge associations and fostering creativity. While graph neural networks (GNNs) excel at modeling literature structures, their static temporal modeling and lack of semantic awareness limit the discovery of interpretable signals. Conversely, large language models (LLMs) offer deep semantic reasoning but struggle to find non-obvious, structurally-grounded patterns without structured input. To address these limitations, this paper proposes a multi-stage GNN-LLM framework that integrates structural pattern recognition and semantic interpretation for scientific knowledge discovery. The framework begins with a Semantic-Enhanced Temporal Graph Network (SE-TGN), which embeds paper-level semantic information into an event-based temporal GNN to identify emerging keyword associations. These structurally grounded candidates are refined through the Contextual Re-ranking and Evaluation Framework (CREF), which leverages LLM capabilities to assess contextual novelty and relevance. Finally, the Generative Interpretation and Contextualization (GIC) produces human-readable explanations and research prompts to support innovation. Experiments in two scientific domains demonstrate the effectiveness of the framework in discovering semantically rich, contextually grounded, and forward-looking knowledge associations, illustrating its potential to support interpretable and creativity-driven scientific exploration.},
  archive      = {J_KBS},
  author       = {Qingqing Wang and Derui Lyu and Qiuju Chen},
  doi          = {10.1016/j.knosys.2025.114527},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncovering novel scientific insights with a synergistic GNN-LLM framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TreeQA: Enhanced LLM-RAG with logic tree reasoning for reliable and interpretable multi-hop question answering. <em>KBS</em>, <em>330</em>, 114526. (<a href='https://doi.org/10.1016/j.knosys.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Hop Question Answering (MHQA), crucial for complex information retrieval, remains challenging for current Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems, which often suffer from hallucination, reliance on incomplete knowledge, and opaque reasoning processes. Existing RAG methods, while beneficial, still struggle with the intricacies of multi-step inference and ensuring verifiable accuracy. This research introduces TreeQA, a novel framework designed to significantly enhance the reliability and interpretability of LLM-RAG systems in MHQA tasks. TreeQA addresses these limitations by decomposing complex multi-hop questions into a hierarchical logic tree of simpler, verifiable sub-questions, integrating evidence from both structured knowledge bases (e.g., Wikidata) and unstructured text (e.g., Wikipedia), and employing an iterative, evidence-based validation and self-correction mechanism at each reasoning step to dynamically rectify errors and prevent their accumulation. Extensive experiments on four benchmark datasets (WebQSP, QALD-en, AdvHotpotQA, and 2WikiMultiHopQA) demonstrate TreeQA’s superior performance, achieving Hit@1 scores of 87 %, 57 %, 53 %, and 59 %, respectively, representing improvements of 4 %-12 % over state-of-the-art LLM-RAG methods. These findings highlight the significant impact of structured, verifiable reasoning pathways in developing more robust, accurate, and interpretable knowledge-intensive AI systems, thereby enhancing the practical utility of LLMs in complex reasoning scenarios. Our code is publicly available at https://github.com/ACMISLab/TreeQA .},
  archive      = {J_KBS},
  author       = {Xiangrui Zhang and Fuyong Zhao and Yutian Liu and Panfeng Chen and Yanhao Wang and Xiaohua Wang and Dan Ma and Huarong Xu and Mei Chen and Hui Li},
  doi          = {10.1016/j.knosys.2025.114526},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Knowl. Based Syst.},
  title        = {TreeQA: Enhanced LLM-RAG with logic tree reasoning for reliable and interpretable multi-hop question answering},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-aligned knowledge self-distillation framework for visible-infrared cross-modal person re-identification. <em>KBS</em>, <em>330</em>, 114525. (<a href='https://doi.org/10.1016/j.knosys.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) significantly enhances identity retrieval across different illumination conditions by matching visible and infrared modalities. However, existing contrastive-learning-based approaches predominantly focus on cross-modal feature alignment, thus undermining model reliability in complex scenarios. To address this challenge, we introduce a Dual Alignment Knowledge Distillation (DAKD) framework that leverages comprehensive self-distillation at both instance and class levels. Our framework incorporates a temperature-modulated alignment strategy, capturing rich modality-invariant generalities as well as modality-specific discriminative details. Additionally, we propose a confidence-based selective masking mechanism that guides the distillation towards confident and informative teacher predictions. To further enhance robustness against modality discrepancies and intra-class variations, we develop a dedicated augmentation technique, CutSwap, which exchanges image channels to simulate realistic cross-modality variations. Extensive experiments on the benchmark SYSU-MM01 and RegDB datasets demonstrate superior performance compared to other state-of-the-art methods, achieving rank-1 accuracies of 76.31 % and 94.83 %, respectively and validating the efficacy of DAKD in maintaining robust cross-modal alignment while preserving essential identity-specific discriminative information.},
  archive      = {J_KBS},
  author       = {Siyuan Deng and Kunhao Yuan and Gerald Schaefer and Shihua Zhou and George Vogiatzis and Yifan Wang and Hui Fang},
  doi          = {10.1016/j.knosys.2025.114525},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-aligned knowledge self-distillation framework for visible-infrared cross-modal person re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis. <em>KBS</em>, <em>330</em>, 114524. (<a href='https://doi.org/10.1016/j.knosys.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical diagnosis is critical in clinical decision-making, typically requiring a continuous and evolving process that includes primary, differential, and final diagnoses. However, most existing clinical diagnostic tasks are single-step processes, which do not align with the complex multi-step diagnostic procedures found in real clinical scenarios. In this paper, we propose MSDiagnosis, a Chinese multi-step clinical diagnostic benchmark consisting of 2225 cases from 12 departments, covering primary, differential, and final diagnosis tasks. Conventional approaches often rely on large language models (LLMs) to perform these tasks sequentially, which can lead to error propagation. To address this, we propose a two-stage diagnostic framework consisting of a forward inference module and a backward reasoning and refinement module. This framework is applied at each diagnostic stage to effectively mitigate error propagation across steps. The forward module retrieves similar cases to assist the LLM in generating an initial diagnosis. In the backward inference and refinement module, we first perform backward inference to infer the diagnostic criteria associated with the initially identified potential diseases. These criteria are then compared with the patient’s records to identify and eliminate possible misdiagnoses. Finally, the diagnostic conclusion is further refined and confirmed. Based on the MSDiagnosis, we evaluate medical LLMs (e.g., OpenBioLLM, PULSE, and Apollo2), general LLMs (e.g., DeepSeek-V3, OpenAI-O1, and GLM4), and our proposed framework. Experimental results show that our framework achieves state-of-the-art performance, demonstrating its effectiveness in multi-step diagnostic tasks. We also provide a detailed analysis and suggest future research directions for this task. Our code and data are publicly available at https://github.com/nlper-hou/MSDiagnosis .},
  archive      = {J_KBS},
  author       = {Ruihui Hou and Shencheng Chen and Yongqi Fan and Guangya Yu and Lifeng Zhu and Jing Sun and Jingping Liu and Tong Ruan},
  doi          = {10.1016/j.knosys.2025.114524},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe and effective post-fine-tuning alignment in large language models. <em>KBS</em>, <em>330</em>, 114523. (<a href='https://doi.org/10.1016/j.knosys.2025.114523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning is critical to customizing Large Language Models (LLMs) in various applications, but it inevitably disrupts the safety alignment of the models. Current alignment methods tackle harmful fine-tuning challenges but frequently compromise model usefulness, resulting in unsatisfactory downstream task performance. To address this issue, we propose a S afe and E ffective post-fine-tuning A lignment ( SEA ) from a knowledge disentanglement perspective. SEA introduces a novel two-level pruning process that surgically removes harmful functionalities. We first propose a differential importance score to isolate harmful pathways at the parameter level, and then introduce a module-wise analysis to protect entangled modules, thereby robustly balancing safety and utility. Experimental results on Llama2, Gemma and Mistral demonstrate that SEA effectively mitigates safety risks while maintaining optimal fine-tuning accuracy. This work provides a practical solution to the safety-performance dilemma associated with harmful fine-tuning of LLMs.},
  archive      = {J_KBS},
  author       = {Minrui Jiang and Yuning Yang and Xiurui Xie and Pei Ke and Guisong Liu},
  doi          = {10.1016/j.knosys.2025.114523},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114523},
  shortjournal = {Knowl. Based Syst.},
  title        = {Safe and effective post-fine-tuning alignment in large language models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward customized model discrepancies in personalized federated learning on non-IID data. <em>KBS</em>, <em>330</em>, 114522. (<a href='https://doi.org/10.1016/j.knosys.2025.114522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a traditional framework comprising a central server and multiple local clients. In FL, a shared global model is trained for resource-constrained computing devices while preserving data privacy. However, in certain practical applications, the shared global model may exhibit poor inference performance in local clients owing to nonindependent and nonidentically distributed (non-IID) characteristics of data. To address this issue, researchers have proposed personalized FL (PFL), which involves learning a customized model for each client to mitigate the impact of weight divergences when the training datasets are non-IID. Unfortunately, existing studies fail to reveal the inherent connection between model discrepancies and non-IID data. Herein, we focus on demonstrating the relationship between weight divergences among customized models and non-IID data, and we provide a proposition to reveal the root cause of such divergences. Additionally, based on our theoretical analysis, we introduce two novel personalized FL methods, namely, PFL with neighbor clients (PFedNC) and PFL with neighbor layers (PFedNL), to address the issue of non-IID data scenarios. Theoretical convergence analysis and extensive experiments indicate that our proposed methods outperform state-of-the-art personalized algorithms in non-IID scenarios. Specifically, PFedNC achieves up to 4 % improvement in customized model accuracy, while PFedNL yields 8 %–10 % gains over multiple baselines.},
  archive      = {J_KBS},
  author       = {Fengrui Hao and Taihang Zhi and Tianlong Gu and Xuguang Bao},
  doi          = {10.1016/j.knosys.2025.114522},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114522},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward customized model discrepancies in personalized federated learning on non-IID data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs. <em>KBS</em>, <em>330</em>, 114521. (<a href='https://doi.org/10.1016/j.knosys.2025.114521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node Importance Estimation (NIE) is a task that quantifies the importance of nodes in a graph. Recent research has investigated to exploit various information from Knowledge Graphs (KGs) to estimate node importance scores. However, the semantic information in KGs could be insufficient, missing, and inaccurate, which would limit the performance of existing NIE models. To address these issues, we leverage Large Language Models (LLMs) for semantic augmentation thanks to the LLMs’ extra knowledge and ability of integrating knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered Node Importance Estimation (LENIE) method to enhance the semantic information in KGs for better supporting NIE tasks. To our best knowledge, this is the first work incorporating LLMs into NIE. Specifically, LENIE employs a novel clustering-based triplet sampling strategy to extract diverse knowledge of a node sampled from the given KG. After that, LENIE adopts the node-specific adaptive prompts to integrate the sampled triplets and the original node descriptions, which are then fed into LLMs for generating richer and more precise augmented node descriptions. These augmented descriptions finally initialize node embeddings for boosting the downstream NIE model performance. Extensive experiments demonstrate LENIE’s effectiveness in addressing semantic deficiencies in KGs, enabling more informative semantic augmentation and enhancing existing NIE models to achieve the state-of-the-art performance. The source code of LENIE is freely available at https://github.com/XinyuLin-FZ/LENIE .},
  archive      = {J_KBS},
  author       = {Xinyu Lin and Tianyu Zhang and Chengbin Hou and Jinbao Wang and Jianye Xue and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114521},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114521},
  shortjournal = {Knowl. Based Syst.},
  title        = {Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models enhanced graph neural architecture search for quadratic unconstrained binary optimization. <em>KBS</em>, <em>330</em>, 114520. (<a href='https://doi.org/10.1016/j.knosys.2025.114520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadratic unconstrained binary optimization (QUBO) refers to a subclass of unconstrained combinatorial optimization problems where the objective is to optimize a quadratic polynomial function over a set of binary variables without any explicit constraint. Recently, graph neural networks (GNNs) have been applied to solve QUBO problems by describing a QUBO problem as a graph and then learning the representation of the graph using GNNs. However, the performance of these GNNs is often unsatisfactory due to improper manual settings of the parameters of graph neural architectures. In this paper, we propose a new graph neural architecture search model (GNAS) to solve the QUBO problems ( GNAS4QUBO for short). The idea is to develop a graph neural architecture search (GNAS) model based on reinforcement learning to find the best GNNs to learn the representation of the QUBO graph. Moreover, we improve the GNAS model with large language models (LLMs) by designing a new set of GNAS4QUBO prompts to generate the best GNNs under QUBO evaluation feedback and fine-tuning the LLM using LoRA based on new graph neural architectures. The experimental evaluation indicates that the proposed method outperforms existing GNN-based models on multiple QUBO benchmark problems. In particular, the results reveal substantial improvement with respect to cut-size metric and the accuracy score in benchmark tasks, such as maximum cut, set covering, combinatorial auction , and maximum independent set . The codes are available online at https://github.com/Embrasse-moi1/GNAS4QUBO .},
  archive      = {J_KBS},
  author       = {Peng Zhang and Junxian Wu and Hong Yang and Chuan Zhou and Zhihong Tian},
  doi          = {10.1016/j.knosys.2025.114520},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114520},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language models enhanced graph neural architecture search for quadratic unconstrained binary optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework. <em>KBS</em>, <em>330</em>, 114519. (<a href='https://doi.org/10.1016/j.knosys.2025.114519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, single-frame infrared small target (SIRST) detection technology has attracted widespread attention. Different from most existing deep learning-based methods that focus on improving network architectures, we propose a feature-enhanced and sensitivity-tunable (FEST) framework, which is compatible with existing SIRST detection networks and further enhances their detection performance. The FEST framework improves the model’s robustness from two aspects: feature enhancement and target confidence regulation. For feature enhancement, we employ a multi-scale fusion strategy to improve the model’s perception to multi-scale features of multi-size targets, and design an edge enhancement difficulty mining (EEDM) loss to guide the network to continuously focus on challenging target regions and edge features during training. For target confidence regulation, an adjustable sensitivity (AS) strategy is proposed for network post-processing. This strategy enhances the model’s adaptability in complex scenarios and significantly improves the detection rate of infrared small targets while maintaining segmentation accuracy. Extensive experimental results show that our FEST framework can effectively enhance the performance of existing SIRST detection networks. The code is available at https://github.com/YuChuang1205/FEST-Framework .},
  archive      = {J_KBS},
  author       = {Jinmiao Zhao and Zelin Shi and Chuang Yu and Yunpeng Liu and Yimain Dai},
  doi          = {10.1016/j.knosys.2025.114519},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114519},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing. <em>KBS</em>, <em>330</em>, 114518. (<a href='https://doi.org/10.1016/j.knosys.2025.114518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern IoT applications, managing large volumes of unstructured data securely and efficiently is a growing challenge, especially within blockchain-enabled edge computing environments. Traditional data storage and retrieval methods often fall short in terms of error detection, indexing efficiency, and secure data handling. To address these limitations, this research proposes a secure and intelligent distributor framework for the storage and retrieval of unstructured data using a blockchain-supported edge computing model. The system architecture is composed of three layers, such as the IoT network layer for data collection, the blockchain-based edge computing layer for secure data handling, and the cloud layer for scalable storage. The proposed framework introduces a novel indexing mechanism, the Optimal Cluster Inverted Index (OCII), which is computed using a newly designed Taylor Fire Hawk Optimizer (Taylor FHO), which is the hybridization of the Taylor series and Fire Hawk Optimizer (FHO). The data handling framework involves five key processes, like KeyGeneration, OCII Generation, AuthGen, Check, and Dynamics, ensuring secure indexing, authentication, and data validation. Experimental evaluation demonstrates that the Taylor FHO achieves a better precision of 86.067%, recall of 87.080%, F-measure of 87.748%, and indexing time of 0.401 sec. This research provides a scalable and secure solution for real-time unstructured data processing in IoT systems.},
  archive      = {J_KBS},
  author       = {S. Premkumar and S. Sivakumar and TS. Arthi and N. Partheeban},
  doi          = {10.1016/j.knosys.2025.114518},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114518},
  shortjournal = {Knowl. Based Syst.},
  title        = {Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploitability prediction of vulnerabilities based on heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114517. (<a href='https://doi.org/10.1016/j.knosys.2025.114517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability exploitability prediction is the process predicting the likelihood of being exploited in real attacks by the assessment of known software vulnerabilities. Many methods have been proposed to solve the problem of exploitability prediction. However, they generally suffer from two problems. First, they only extract features from a single vulnerability, ignoring the impact of associated vulnerabilities. Second, they usually adopt simple methods (such as concatenation) to aggregate different information, which may overlook important relationships between features. In this paper, we propose a novel exploitability prediction method based on heterogeneous graphs, called ExPreHet. First, ExPreHet defines nodes and edges to construct a heterogeneous graph. Following a series of preprocessing steps, ExPreHet generates multiple attribute vectors for each node. By implementing a restart random walk strategy, ExPreHet ensures that each node can sample all categories of neighboring nodes and group them by node category. Then, ExPreHet aggregates all the attributes of each node to generate the content vector, and each category of neighboring nodes of this node to generate a category vector. After that, the content vector and all the category vectors are aggregated to generate the final representation of the node. Finally, these final representations are input into random forest (RF) for training the classifier. To effectively assess ExPreHet, this paper conducts experiments on a dataset, which contains 66,877 vulnerabilities. The experimental results show that ExPreHet achieves 83.24 %, 83.22 %, 83.28 %, 83.25 %, and 83.24 % in terms of accuracy, precision, recall, F1-score, and area under curve (AUC), respectively. ExPreHet performs significantly better than the baseline methods.},
  archive      = {J_KBS},
  author       = {Guo Xu and Xin Chen and Xinxin Cai and Dongjin Yu},
  doi          = {10.1016/j.knosys.2025.114517},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114517},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploitability prediction of vulnerabilities based on heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep cognitive network for battlefield situation awareness in wargaming. <em>KBS</em>, <em>330</em>, 114516. (<a href='https://doi.org/10.1016/j.knosys.2025.114516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an innovative approach to supporting wargaming, computer-based wargames have been well received by military researchers. The battlefield situation in wargames is complex and rapidly evolving, and analysing a single scenario is insufficient to capture the full scope of the battlefield. To address the challenge of identifying trends in situational changes, this study proposes a value network model for battlefield situational awareness in wargaming based on deep learning techniques. Focusing on the Army Tactical Wargame as the research object, this study analyses key elements of battlefield situations using feature engineering methods. It introduces a hierarchical, grid-based model for representing battlefield situation features within wargames and develops a value tagging system that integrates system scores with distance-based rewards. A convolutional neural network-based value network model for situational awareness is then constructed, and the influence of key battlefield characteristics on the model is examined. Experimental results demonstrate that the proposed value network can more accurately predict the situation value at each stage of the wargame. The prediction accuracy exhibits a hump-shaped trend from the beginning to the end of the simulation. During the attack phase, the prediction accuracy exceeds 70 %, reaching a peak of 72.98 %. These findings offer a reliable new method for supporting agents in situation recognition and intelligent decision-making.},
  archive      = {J_KBS},
  author       = {Chenhui Pan and Yong Xian and Peiyang Ma and Leliang Ren and Wancheng Ni},
  doi          = {10.1016/j.knosys.2025.114516},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114516},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel deep cognitive network for battlefield situation awareness in wargaming},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight completion with high-order semantic attributes for heterogeneous sparse attribute graph learning. <em>KBS</em>, <em>330</em>, 114515. (<a href='https://doi.org/10.1016/j.knosys.2025.114515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph neural networks (HGNNs) have been widely applied in real-world scenarios. Due to various uncontrollable factors, many heterogeneous graphs suffer from attribute sparsity, which can be effectively addressed by HGNNs with attribute completion (HGNNs-AC). However, current HGNNs-AC still encounter significant challenges. (i) In the completion module, the lack of dynamic learning of higher-order semantic importance causes the completion effect to fall short. (ii) Lack of collaborative interaction and effective aggregation among completed attributes hinders the overall completion performance. (iii) Low efficiency is caused by another heterogeneous graph neural network retraining after attribute completion, which is particularly obvious on large-scale datasets. To address these challenges, we propose Lightweight Completion with High-order Semantic Attributes (LC-HSA) for heterogeneous sparse attribute graph learning, which dynamically learns two weights of multiple meta-path subgraphs to complete sparse attributes. The proposed model includes four modules: (i) A module for constructing meta-path subgraphs captures higher-order meta-path subgraphs’ semantic information. (ii) A lightweight completion module leverages an innovative lightweight graph attribute completion network to dynamically learn two weights of multiple meta-path subgraphs, achieving sparse attribute completion. (iii) We introduce an interaction aggregation module that facilitates collaborative interaction and effective aggregation among the completed attributes. (iv) The lightweight classification module increases the model’s overall efficiency. Extensive experiments on three benchmarks demonstrate that LC-HSA outperforms the state-of-the-art HGNNs-AC models on the node classification task. Our code is available at: https://github.com/HeteroMind/LC-HSA1 .},
  archive      = {J_KBS},
  author       = {Yuanjun Yang and Weihua Ou and Yunshun Wu and Jiamin Chen and Hao Tian and Jianping Gou and Zhonghua Liu and Bineng Zhong},
  doi          = {10.1016/j.knosys.2025.114515},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114515},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lightweight completion with high-order semantic attributes for heterogeneous sparse attribute graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization. <em>KBS</em>, <em>330</em>, 114514. (<a href='https://doi.org/10.1016/j.knosys.2025.114514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern autonomous driving systems rely heavily on deep learning-based perception models for object detection; yet, their computational and energy demands remain critical bottlenecks. The existing adaptive-perception strategies often lack the ability to dynamically balance the detection accuracy and energy consumption, in real-time, particularly under varying environmental conditions. To address this challenge, we first construct a large-scale autonomous driving dataset based on the CARLA simulator. Then, we propose a novel metric—the balanced efficiency index—to annotate each image with the most suitable you-only-look-once version 8 (YOLOv8) model size (i.e., n, s, m, l, or x). This index is governed by two critical parameters, which are efficiently optimized using our proposed constrained stochastic DIviding RECTangles (DIRECT) algorithm. Finally, we propose a lightweight dynamic mixed receptive field transformer (DynaMixFormer), which is trained using the labelled dataset, to select the appropriate YOLOv8 model adaptively. Our results show that: (1) the constrained stochastic DIRECT algorithm determines cost-effective parameters with very limited simulation overhead; (2) DynaMixFormer achieves a high classification accuracy of 96.56 % with only 0.017 M parameters, outperforming the state-of-the-art image-classification networks; and (3) the well-trained DynaMixFormer effectively extracts real-time contextual features, such as traffic density, weather conditions, and road complexity, to intelligently select the optimal model from various YOLOv8 variants. Extensive simulations demonstrate that our approach achieves up to 70.20 % reduction in the energy consumption, compared to the static deployment of the YOLOv8x model, with only a marginal decrease of approximately 2 % in the mean average precision. Taking China as an example, this translates to an estimated energy saving of 2.73 × 10 14 W. This work not only advances energy-efficient autonomous perception but also provides a generalizable framework for adaptive model selection in resource-constrained edge-computing systems. For ease of comprehension, some key nomenclature used in this paper are summarized in Table 1.},
  archive      = {J_KBS},
  author       = {Yanzhan Chen and Fan Yu and Qian Zhang and Mahardhika Pratama},
  doi          = {10.1016/j.knosys.2025.114514},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data. <em>KBS</em>, <em>330</em>, 114513. (<a href='https://doi.org/10.1016/j.knosys.2025.114513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Neural Machine Translation (NMT) has recently achieved remarkable performance improvements, it still faces challenges in domain adaptation. Previous research has focused on mitigating this issue by integrating translation knowledge from bilingual domain data. However, the limited availability of bilingual translation resources has constrained these methods in real world application. To address this inadequacy, solutions based on monolingual data, such as back-translation, have been proposed. Nevertheless, these methods often incur additional training costs due to the necessity of training reverse models to generate pseudo data. In light of this, we propose Pseudo- k NN-MT, which does not require additional training. This method creates pseudo-bilingual data pairs by retrieving semantically similar sentences from target language data and subsequently builds the k NN datastore. To effectively reduce the noise introduced by the pseudo-data, we incorporate cross-lingual retrieval distances into the k NN probability construction process. Experiments in both high-resource and low-resource machine translation scenarios across multiple domains demonstrate that our method significantly improves the domain adaptation capabilities of NMT in both settings, yielding average improvements of 6.08 and 7.70 SacreBLEU points and 0.66 and 1.62 COMET scores on the multi-domain dataset, respectively.},
  archive      = {J_KBS},
  author       = {Abudurexiti Reheman and Yingfeng Luo and Junhao Ruan and Hongyu Liu and Tong Xiao and Jingbo Zhu},
  doi          = {10.1016/j.knosys.2025.114513},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114513},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design. <em>KBS</em>, <em>330</em>, 114512. (<a href='https://doi.org/10.1016/j.knosys.2025.114512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfiguration of networks and distributed generation (DG) together leads to better performance of a network. To ensure system enactment, it is therefore necessary to determine appropriate size and placement of DG. However, there is a huge solution search space for sizing and situating of demand generation with Network Reconfiguration (NR), which makes it a complicated problem. Throughout the optimization process, removing these non-radial choices adds computational burden and lead to a local optimal solution. To reduce complexity of searching, Modified Chaotic Particle Swarm Optimization (MCPSO) algorithm is adopted to obtain a near optimal solution of designing, sizing, and placing the network with improved voltage profiles and minimized power loss. It introduces a combination of chaotic inertia adaptation, uniform initialization and a stochastic personal learning strategy contributing to improved search diversity and convergence stability. For the purpose of demonstrating efficacy of a simultaneous approach taking changeable power factor, the proposed approach is assessed using IEEE-33 and 69 bus using MATLAB. The findings demonstrate that discretizing reconfiguration search space implemented by encoding the network configuration as a discrete set of switching states prevents MCPSO from getting trapped in local optimums. On contrasting with conventional Particle Swarm Optimization (PSO), the proposed MCPSO algorithm results in active and reactive power loss reduction of 27.78 % and 76.36 % respectively for 33 bus system and 6.67 % and 25.5 % respectively for 69 bus system. The outcomes reveal that suggested algorithm provides optimal solution contrasted to state of art approaches.},
  archive      = {J_KBS},
  author       = {K. Dharani Sree and P. Karpagavalli},
  doi          = {10.1016/j.knosys.2025.114512},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114512},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion models with self-conditioning guidance for multivariate time series anomaly detection. <em>KBS</em>, <em>330</em>, 114511. (<a href='https://doi.org/10.1016/j.knosys.2025.114511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in multivariate time series data collected from industrial systems is crucial for intelligent operations and maintenance. Most existing methods leverage deep neural networks to learn normal patterns for reconstructing input data, where anomalies exhibit higher reconstruction errors. However, due to the overly powerful feature extraction and generation capabilities of these models for time series, they tend to reconstruct anomalies well, leading to high false negative rates. To address this problem, we propose a novel time series Diffusion model with Self-Conditioning guidance for Anomaly Detection (DSCAD), which utilizes self-conditional control to effectively suppress the reconstruction of anomalies without affecting the original input. We introduce a self-conditioning guidance strategy that extracts coarse-grained features from intermediate results during the diffusion process as target vectors to guide the reconstruction toward generating expected normal data. Moreover, to capture long-term trends and periodic patterns in time series, we employ a Transformer as the denoising module during the reverse process. Furthermore, we introduce a novel detection criterion based on the target vectors to amplify normal-abnormal distinguishability of anomaly scores, thereby improving the detection performance. Extensive experiments conducted on five publicly available datasets demonstrate that DSCAD achieves an average F1 score of 95.23 %, outperforming other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yushi Li and Zhenyu Wen and Ziwen Chen and Jie Mei and Mengxue Lin and Ming Zhu},
  doi          = {10.1016/j.knosys.2025.114511},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114511},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion models with self-conditioning guidance for multivariate time series anomaly detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-view discrete clustering with unified graph learning. <em>KBS</em>, <em>330</em>, 114510. (<a href='https://doi.org/10.1016/j.knosys.2025.114510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based multi-view clustering (GMVC) has garnered significant attention due to its ability to overcome sample space shape constraints. However, existing GMVC methods encounter two major challenges: (1) Their effectiveness diminishes because they solely rely on sample-constructed graphs and the two-stage mismatch caused by additional discretization; (2) Their robustness deteriorates substantially when applied to real-world datasets that contain complex noise. To address these limitations, we propose a robust multi-view discrete clustering model with unified graph learning (RCUGL). This model integrates richer graph structural information and accommodates complex noise clustering tasks. Specifically, we incorporated low-rank approximation graphs reconstructed from spectral embeddings and graphs constructed by samples into a unified graph to provide enriched structural insights. Subsequently, within the framework of the correntropy, discrete spectral analysis was performed directly on the unified graph to derive cluster assignments. Given the non-convex and discrete nature of the proposed RCUGL model, we developed a half-quadratic-based coordinate descent optimisation algorithm to ensure rapid and reliable convergence. Extensive experiments demonstrate that RCUGL substantially improves clustering effectiveness, comparable to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiaqi Nie and Rankun Chen and Jingxiang Huang and Ben Yang and Xuetao Zhang},
  doi          = {10.1016/j.knosys.2025.114510},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114510},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust multi-view discrete clustering with unified graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDbDa: Prompt-tuned dual-branch framework for unsupervised domain adaptation. <em>KBS</em>, <em>330</em>, 114509. (<a href='https://doi.org/10.1016/j.knosys.2025.114509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale vision-language models demonstrate excellent performance on downstream tasks. However, they face challenges in unsupervised domain adaptation, particularly when domain shifts and semantic loss occur. Although existing prompt learning methods can decouple task-specific semantics from general knowledge, they face two main issues: (i) ineffective coordination between task-specific and general knowledge, leading to poor class discriminability, and (ii) inability to adequately address the domain shift. To address these challenges, we propose PDbDa, a prompt-tuned dual-branch framework for unsupervised domain adaptation that jointly optimizes learnable prompt vectors. PDbDa introduces two key innovations: (i) a foundation branch with a prompt knowledge constraint to regularize task-specific and pretrained knowledge, addressing class discriminability, and (ii) an adaptation branch with a domain-aware feature tuning block to align source and target domain features, mitigating the domain shift. These two branches function synergistically, improving model accuracy and training efficiency. The experimental results on the Office-Home, VisDA-2017, and DomainNet datasets indicate that PDbDa outperforms conventional prompt tuning and UDA methods by an average of 2.2 %-3 %.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Yurui Zhao and Mingwen Shao and Hong Liang},
  doi          = {10.1016/j.knosys.2025.114509},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114509},
  shortjournal = {Knowl. Based Syst.},
  title        = {PDbDa: Prompt-tuned dual-branch framework for unsupervised domain adaptation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>330</em>, 114508. (<a href='https://doi.org/10.1016/j.knosys.2025.114508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge of multi-modal data, how to effectively and efficiently find similar information has become an urgent and important need. Among the existing solutions, unsupervised cross-modal hashing can learn from unlabeled data and provide fast and satisfactory retrieval performance, making it a viable solution. However, existing unsupervised cross-modal hashing methods often inadequately model intricate cross-modal semantic relationships. To bridge this gap, this paper proposes a novel Hypergraph-based CLIP Hashing (HCH). Specifically, HCH utilizes the large-scale visual-language pre-trained model CLIP to extract visual and textual features, and employs a cross-modal Transformer to further enhance semantic fusion among these features. Then, to fully capture the semantic relevance among multi-modal data, we construct a semantic-enhanced similarity matrix and design a mean-based weighting scheme to adjust this matrix. Additionally, we compose a hypergraph convolutional network to further explore high-order semantic information within the input data, leading to more compact and high-quality hash codes. To substantiate HCH’s efficacy, we conducted experiments on three commonly used datasets, confirming its superiority over leading baselines.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Jia-Rui Zhao and Xiao-Qian Liu and Yu-Wei Zhan and Zhen-Duo Chen and Xin Luo and Xin-Shun Xu},
  doi          = {10.1016/j.knosys.2025.114508},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114508},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph. <em>KBS</em>, <em>330</em>, 114507. (<a href='https://doi.org/10.1016/j.knosys.2025.114507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models are used in more applications, a key problem has become clear: their numerical embeddings are hard to interpret because it is unclear how each part of the vector relates to real-world meanings in specific fields. The prevailing embedding methods are inadequate in their current state, as they are unable to effectively bridge the gap between mathematical representations and human-understandable knowledge structures. The present study proposes a novel framework that explicitly links ontology classes to specific embedding dimensions through a dual-component architecture combining a text encoder that produces the target embedding dimensions with domain knowledge graphs. The Area Under the Interpretability Curve (AUIC) metric is introduced as a means to systematically evaluate model-alignment with ontological concepts. The analysis reveals that targeted dimensional mapping enables direct interpretation of individual vector components through ontological terms. The practical applications of this framework are illustrated through case studies in biomedical contexts, demonstrating enhanced model transparency without compromising performance. This approach establishes a measurable pathway for reconciling statistical language representations with structured domain knowledge, particularly benefiting fields requiring precise concept alignment like biomedicine. The implementation is publicly available at: https://github.com/Mellandd/DEIBO .},
  archive      = {J_KBS},
  author       = {Jose L. Mellina-Andreu and Alejandro Cisterna-García and Juan A. Botía},
  doi          = {10.1016/j.knosys.2025.114507},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient network intrusion detection model based on beta mixture models. <em>KBS</em>, <em>330</em>, 114506. (<a href='https://doi.org/10.1016/j.knosys.2025.114506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer networks and network applications, ensuring network security has become a critical concern and has garnered significant attention from both academia and industry. Network intrusion detection (NID) plays a pivotal role in safeguarding cybersecurity and maintaining system stability. Most existing NID approaches rely on traditional machine learning (ML) or deep learning (DL) techniques to identify threats and potential attacks based on network traffic data. However, these methods often suffer from high computational complexity and large model sizes, which significantly impede their deployment in resource-constrained environments such as the Internet of Things (IoT), edge computing infrastructures, and wireless sensor networks. In this study, we propose an efficient NID framework based on the Beta Mixture Model (BMM) classifier. The proposed method integrates the BMM with the recently introduced Extended Stochastic Variational Inference (ESVI) framework to effectively characterize both normal and intrusive behavior patterns. The ESVI framework enables simultaneous parameter estimation and model complexity control in a principled and computationally efficient manner. Experimental evaluations show that, compared to NID methods utilizing established finite mixture models, traditional ML, or state-of-the-art DL techniques, our approach substantially reduces computational overhead while achieving comparable detection performance.},
  archive      = {J_KBS},
  author       = {Yuping Lai and Zidong Wang and Ziqing Lin and Yuhan Cao and Zihao Li and Qing Ye},
  doi          = {10.1016/j.knosys.2025.114506},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114506},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient network intrusion detection model based on beta mixture models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-induced dual-channel tokenized graph learning. <em>KBS</em>, <em>330</em>, 114505. (<a href='https://doi.org/10.1016/j.knosys.2025.114505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown impressive performance in graph representation learning, but they struggle with capturing long-range dependencies and suffer from limited expressive power. While sequence models offer promising potential for global context modeling and high-order interaction learning in graph domains, their direct application faces critical challenges: structural semantics are inevitably distorted when permutation-invariant graph topologies are forcibly linearized into ordered sequences. In this paper, we introduce the H ierarchy- I nduced Dual-Channel T okenized G raph O perator (HITGO), a novel token-based graph learning framework that explicitly integrates structural semantics into expressive multi-granular token sequences, which are then efficiently modeled through a hybrid backbone. Specifically, HITGO employs recursive graph coarsening to construct a multi-level graph hierarchy, and leverages Hierarchy2Token to generate complementary token sequences for each node that capture nuanced structural details and long-range dependencies from both local neighborhoods and global contexts. Building upon these sequences, HITGO implements a Transformer-Mamba Dual-Channel Architecture: the Transformer channel handles shorter, coarse-grained sequences for structural abstraction, while the Mamba channel efficiently processes longer, fine-grained sequences using state-space modeling for effective long-range capture. This granularity-aware allocation strategically matches architectural strengths to token properties, enabling near-linear complexity while preserving permutation-equivariance. Experiments demonstrate HITGO’s superiority over state-of-the-art GNNs and Graph Transformers (GTs) on real-world datasets, validating its effectiveness in capturing complex graph structures while scaling efficiently.},
  archive      = {J_KBS},
  author       = {Huiwen Bai and Lizhong Ding and Guoren Wang and Ye Yuan and Junyu Zhang and Yuwan Yang and Lianpeng Qiao},
  doi          = {10.1016/j.knosys.2025.114505},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114505},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchy-induced dual-channel tokenized graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic learning in the PAC framework: A new perspective. <em>KBS</em>, <em>330</em>, 114504. (<a href='https://doi.org/10.1016/j.knosys.2025.114504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monotone learning describes learning processes in which expected error consistently decreases as the amount of training data increases. However, recent studies challenge this conventional wisdom, revealing significant gaps in the understanding of generalization in machine learning. Addressing these gaps is crucial for advancing the theoretical foundations of the field. In this work, we utilize Probably Approximately Correct (PAC) learning theory to construct a theoretical error distribution that approximates a learning algorithm’s actual performance. We rigorously prove that this theoretical distribution exhibits monotonicity as sample sizes increase. We identify two scenarios under which deterministic algorithms based on Empirical Risk Minimization (ERM) are monotone: (1) the hypothesis space is finite, or (2) the hypothesis space has finite VC-dimension. Experiments on three classical learning problems validate our findings by demonstrating that the monotonicity of the algorithms’ generalization error is guaranteed, as its theoretical error upper bound monotonically converges to the minimum generalization error.},
  archive      = {J_KBS},
  author       = {Ming Li and Chenyi Zhang and Qin Li},
  doi          = {10.1016/j.knosys.2025.114504},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114504},
  shortjournal = {Knowl. Based Syst.},
  title        = {Monotonic learning in the PAC framework: A new perspective},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification. <em>KBS</em>, <em>330</em>, 114503. (<a href='https://doi.org/10.1016/j.knosys.2025.114503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current outbreak of monkeypox (mpox) presents challenges for timely and accurate diagnosis due to the disease’s diverse and unusual skin lesion patterns. Traditional deep learning models, such as Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), struggle with these irregular features because they rely on rigid, grid-based methods. To address this, we introduce the Truncated MobileNetV2 Sparse Vision Graph Attention (TMSVGA) model. TMSVGA combines components of MobileNetV2, which focuses on identifying smaller details, with a Sparse Vision Graph Attention block enhanced by a Squeeze-and-Excitation (SE) mechanism to improve channel-wise attention. This approach enhances the understanding of complex and long-distance relationships, emphasizing diagnostically significant regions and improving classification precision. We optimized TMSVGA using the Optuna framework for automated hyperparameter tuning. Additionally, Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-Agnostic Explanations (LIME) provided interpretable visualizations, highlighting influential regions in decision-making. The TMSVGA model was validated on the Monkeypox Skin Images Dataset (MSID), achieving 96.79 % accuracy, 96.90 % precision, 95.34 % recall, 96.08 % F1-score, and 95.37% Matthews Correlation Coefficient (MCC). These results demonstrate that TMSVGA outperforms existing models, particularly in handling irregular lesion patterns. By achieving high diagnostic accuracy and precision, our study showcases the potential of Vision Graph Neural Networks (ViGNNs) in advancing medical image analysis for diseases with non-uniform spatial patterns. Furthermore, the lightweight architecture of TMSVGA ensures suitability for mobile and resource-constrained diagnostic applications.},
  archive      = {J_KBS},
  author       = {Mehdhar S.A.M. Al-Gaashani and Abduljabbar S. Ba Mahel and Ammar Muthanna},
  doi          = {10.1016/j.knosys.2025.114503},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114503},
  shortjournal = {Knowl. Based Syst.},
  title        = {Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity facial aesthetic evaluation model based on image-text modality. <em>KBS</em>, <em>330</em>, 114502. (<a href='https://doi.org/10.1016/j.knosys.2025.114502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Beauty Prediction (FBP) is an emerging research direction at the intersection of artificial intelligence and aesthetics, which has attracted increasing attention in recent years. However, most existing methods rely solely on unimodal data and fail to comprehensively capture the multi-dimensional information of facial aesthetics. To address this challenge, we propose a multigranularity facial aesthetic evaluation model based on image-text modality (ITM-MGFA). By incorporating multi-granularity cognitive theory into the FBP task, the model effectively integrates both coarse-grained and fine-grained aesthetic features extracted from the CLIP encoder through a multigranularity representation module, a task-oriented dynamic alignment module, and a hierarchical interaction optimization module. This facilitates deep cross-modal interaction and fusion, significantly enhancing the model’s capability to model complex aesthetic attributes. Experimental results demonstrate that ITM-MGFA, leveraging the fusion of cross-modal information, achieves higher accuracy in facial aesthetic assessment task compared to traditional unimodal methods, offering a new direction for FBP research. Furthermore, the model can be applied in various scenarios, such as: simulation postoperative assessment of personalized cosmetic surgery in the medical aesthetics; selection of optimal facial aesthetic enhancement solutions on social media; and recommendation of matching solutions in cosmetic recommendation.},
  archive      = {J_KBS},
  author       = {Huanyu Chen and Yong Wang and Weisheng Li and Bin Xiao},
  doi          = {10.1016/j.knosys.2025.114502},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114502},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-granularity facial aesthetic evaluation model based on image-text modality},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments. <em>KBS</em>, <em>330</em>, 114501. (<a href='https://doi.org/10.1016/j.knosys.2025.114501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking plays a critical role in airborne autonomous systems, supporting applications such as disaster response, agricultural monitoring, and military surveillance. However, existing tracking methods often exhibit poor generalization in real-world deployments due to domain shifts between the training and target environments. We propose DGTrack, a novel single-source domain generalization framework for UAV visual tracking. DGTrack integrates a Frequency-Aware Learning (FAL) module that separates and adaptively modulates low- and high-frequency components to reduce stylistic interference while enhancing content representation. In addition, a Target-Aligned Augmentation (TAA) module is introduced to improve source domain diversity through multi-level transformations and to align predictions between original and augmented frames by maximizing mutual information. Extensive experiments on the UAVDT and VisDrone2019 datasets demonstrate that DGTrack achieves superior generalization to unseen domains and consistently outperforms state-of-the-art UAV trackers in single-source settings.},
  archive      = {J_KBS},
  author       = {Erfeng Liu and Xinde Li and Heqing Li and Guoliang Wu and Tao Shen},
  doi          = {10.1016/j.knosys.2025.114501},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114501},
  shortjournal = {Knowl. Based Syst.},
  title        = {A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data. <em>KBS</em>, <em>330</em>, 114500. (<a href='https://doi.org/10.1016/j.knosys.2025.114500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a feature-augmented multivariate LSTM model for real-time Forex market forecasting. By incorporating engineered financial indicators—such as Close_Change, RSI, and gold price—alongside traditional OHLCV data, the model captures nonlinear temporal dynamics and macro-financial interactions. A sliding window approach structures input sequences for a stacked LSTM network optimized for short-term prediction. Experimental results on major currency pairs demonstrate that the proposed model outperforms baseline LSTM, GRU, and classical machine learning methods in RMSE, MAE, and MAPE metrics. Statistical validation using the Wilcoxon signed-rank test confirms the improvements are significant. The model's robustness under volatility stress and noisy inputs highlights its practical relevance for real-time decision-making. Potential extensions include incorporating news-based sentiment and multimodal signals to enhance adaptability.},
  archive      = {J_KBS},
  author       = {Duong Thi Kim Chi and Ho Ngoc Trung Kien and Thanh Q. Nguyen},
  doi          = {10.1016/j.knosys.2025.114500},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114500},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-based heterogenous graph attention network for multi-class fake news detection. <em>KBS</em>, <em>330</em>, 114499. (<a href='https://doi.org/10.1016/j.knosys.2025.114499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A promising tool for addressing fake news detection is Graph Neural Networks (GNNs). However, most existing GNN-based methods rely on binary classification, categorizing news as either real or fake. Additionally, traditional GNN models use a static neighborhood for each node, making them susceptible to issues like over-squashing. In this paper, we introduce a novel model named Decision-based Heterogeneous Graph Attention Network (DHGAT) for fake news detection in a semi-supervised setting. DHGAT effectively addresses the limitations of traditional GNNs by dynamically optimizing and selecting the neighborhood type for each node in every layer. It represents news data as a heterogeneous graph where nodes (news items) are connected by various types of edges. The architecture of DHGAT consists of a decision network that determines the optimal neighborhood type and a representation network that updates node embeddings based on this selection. As a result, each node learns an optimal and task-specific computational graph, enhancing both the accuracy and efficiency of the fake news detection process. We evaluate DHGAT on the LIAR dataset, a large and challenging dataset for multi-class fake news detection, which includes news items categorized into six classes. Our results demonstrate that DHGAT outperforms existing methods, improving accuracy by approximately 4% and showing robustness with limited labeled data.},
  archive      = {J_KBS},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.knosys.2025.114499},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114499},
  shortjournal = {Knowl. Based Syst.},
  title        = {A decision-based heterogenous graph attention network for multi-class fake news detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement. <em>KBS</em>, <em>330</em>, 114498. (<a href='https://doi.org/10.1016/j.knosys.2025.114498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth perception is fundamental for numerous computer vision applications, yet depth maps acquired from commodity sensors often suffer from artifacts and inaccuracies, necessitating effective enhancement techniques. Polarization imaging, capturing rich geometric cues robust to illumination variations, offers a promising modality to guide this process. However, effectively integrating these cues within learning-based depth enhancement frameworks remains challenging. Existing methods often overlook the inherent representational gap between depth and polarization features and employ context-agnostic fusion mechanisms, incapable of generating prompts adaptive to cross-modal relationships and local context. To address these limitations, we propose a novel Rectified and Context-Aware Polarization Prompting (ReCAP 2 ) framework for depth enhancement models. The ReCAP 2 first performs initial feature rectification across both channel and spatial dimensions to bridge the modality gap. Subsequently, it generates fine-grained polarization prompts by leveraging dual-level context: utilizing cross-modal context ensures the prompts encode pertinent inter-modality relationships, while processing spatial neighborhood context yields prompts spatially tailored to regional content. Consequently, these dual-context aware prompts provide precise, adaptive guidance for the foundation model, facilitating more robust depth enhancement. Extensive experiments demonstrate the effectiveness of our method. On the multi-modal HAMMER dataset, our method shows superior accuracy and robustness across diverse sensor types in indoor scenes under both full fine-tuning and prompt tuning settings. Furthermore, cross-domain evaluations on the challenging CroMo dataset validate its strong generalization to outdoor environments.},
  archive      = {J_KBS},
  author       = {Zhenyu Liu and Jiatong Xu and Daxin Liu and Qide Wang and Jin Cheng and Jianrong Tan},
  doi          = {10.1016/j.knosys.2025.114498},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114498},
  shortjournal = {Knowl. Based Syst.},
  title        = {ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-generalized token linking in vision foundation models for semantic segmentation. <em>KBS</em>, <em>330</em>, 114497. (<a href='https://doi.org/10.1016/j.knosys.2025.114497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[S U M M A R Y] Vision Foundation Models (VFMs) achieve remarkable performance compared with traditional methods based on convolutional neural networks and vision transformer networks in Domain-Generalized Semantic Segmentation (DGSS). These VFM-based DGSS methods focus on adopting efficient parameter fine-tuning strategies that use a set of learnable tokens to fine-tune VFMs to the downstream DGSS task, yet struggle to mine domain-invariant information from VFMs since the backbone of VFMs is frozen during the fine-tuning stage. To address this issue, a Domain-Generalized Token Linking (DGTL) approach is proposed to mine domain-invariant information from VFMs for improving the performance in unseen target domains, which contains a Text-guided Dual Token Linking (TDTL) module and a Text-guided Distribution Normalization (TDN) strategy. For the TDTL module, first, a set of learnable tokens is linked to the text embeddings for building the relations between the learnable tokens and text embeddings, which is beneficial for learning domain-invariant tokens since the text embeddings generated from the CLIP model are domain-invariant. Second, the feature-level and mask-level linking strategies are proposed to link the learned domain-invariant tokens to the features and masks to guide the mining of domain-invariant information from the VFM. For the TDN strategy, the pairwise similarity between the predictive masks associated with the learnable tokens and the text embeddings is utilized to explicitly align the semantic distribution of visual features in the learnable tokens with the text embeddings. Extensive experiments demonstrate that the DGTL approach achieves superior performance to recent methods across multiple DGSS benchmarks. The code is released on GitHub: https://github.com/seabearlmx/DGTL .},
  archive      = {J_KBS},
  author       = {Muxin Liao and Jiayang Wang and Hong Deng and Yingqiong Peng and Hua Yin and Yinglong Wang and Guoguang Hua},
  doi          = {10.1016/j.knosys.2025.114497},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114497},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-generalized token linking in vision foundation models for semantic segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive exploration for few-shot incremental learning. <em>KBS</em>, <em>330</em>, 114496. (<a href='https://doi.org/10.1016/j.knosys.2025.114496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) poses a challenging problem in computer vision, where conventional deep models suffer from catastrophic forgetting and overfitting to novel classes. Inspired by the dynamic learning processes observed in human cognition when adapting to unfamiliar scenarios, we propose a deep exploratory incremental learning framework that incrementally refines the classifier model through a trial-and-error decision making process. A joint distribution-aware reward function is introduced to guide learning, incorporating three key factors: intra-class compactness, inter-class dispersion, and cross-session consistency, enabling balanced knowledge retention and acquisition. Furthermore, we design a dynamic gradient guidance module that adaptively adjusts gradient updates within a Gaussian-derived policy space, enhancing training stability and mitigating overfitting risks in the few shot regime. Extensive experiments conducted on three publicly available datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in the FSCIL setting.},
  archive      = {J_KBS},
  author       = {Cao Han and Ziqi Gu and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.knosys.2025.114496},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive exploration for few-shot incremental learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings. <em>KBS</em>, <em>330</em>, 114495. (<a href='https://doi.org/10.1016/j.knosys.2025.114495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermomechanical responses of refractory linings in steel ladles is critical to optimizing production efficiency and ensuring safety in the iron and steel smelting industry. However, traditional numerical simulation methods suffer challenges of high computational costs and insufficient generalizability, while data-driven models are limited by a lack of physical rationality and poor interpretability. Aiming at overcoming these challenges, an artificial intelligence (AI) model, named the steel ladle Kolmogorov–Arnold network (SLKAN), is designed to predict the thermomechanical behavior of ladle linings. Based on the Kolmogorov–Arnold theorem and material constitutive equations, SLKAN precisely predicts the thermomechanical behavior of ladle linings. The model offers substantial advantages in predicting the maximum tensile stress in the steel shell and the maximum compressive stress at the working lining hot face: the coefficient of determination (R 2 ) value for compressive stress prediction reaches 0.9942, with a mean absolute error (MAE) of 9.4136 and a root mean squared error (RMSE) of 0.0192; the R 2 value for tensile stress prediction is 0.9578, with an MAE of 41.4855 and an RMSE of 0.0385. Further analysis indicates that the function expressions of SLKAN hold clear physical significance. This study provides an interpretable, efficient AI solution for multiphysics coupling modeling in complex industrial scenarios and offers theoretical guidance for the application of AI in predicting the lifespan of steel-smelting equipment.},
  archive      = {J_KBS},
  author       = {Yi Yin and Zongxian Long and Shengli Jin and Yawei Li and Fang Wang and Xin Xu},
  doi          = {10.1016/j.knosys.2025.114495},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedCleanse: Cleanse the backdoor attacks in federated learning system. <em>KBS</em>, <em>330</em>, 114494. (<a href='https://doi.org/10.1016/j.knosys.2025.114494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables multiple clients to collaboratively train an efficient deep-learning model without sharing their local data. However, due to its privacy-preserving nature, FL is vulnerable to backdoor attack, which manipulates the model behaviors on the adversary-chosen input. Existing defense methods are ineffective against sophisticated stealthy backdoors, suffering from either a low benign performance or being too specific to certain assumptions and attacks. To handle the aforementioned issues, we present FedCleanse, a novel defense mechanism to address the backdoor attack in federated learning. In this work, we study the pruning-based approach, which has been proven effective but with the need for additional data for validation and suffers from high non-IID scenarios. This paper proposes a post-aggregation approach, namely FedCleanse, to neutralize backdoor effects without needing additional clean data. Our approach identifies suspicious neurons using “neuron conductance” and subsequently suppresses them after the aggregation operation, which imposes minimal impact on benign neurons. Additionally, FedCleanse is complemented by strategic perturbations to prevent backdoor transfer. Through extensive experiments, our method demonstrates superior defense capabilities across various attack types and non-IID settings, surpassing the state-of-the-art by a large margin without compromising the main task’s performance.},
  archive      = {J_KBS},
  author       = {Siquan Huang and Yijiang Li and Chong Chen and Leyu Shi and Wentian Cai and Ying Gao},
  doi          = {10.1016/j.knosys.2025.114494},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114494},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedCleanse: Cleanse the backdoor attacks in federated learning system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments. <em>KBS</em>, <em>330</em>, 114493. (<a href='https://doi.org/10.1016/j.knosys.2025.114493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT), as a key technology to enable personalized instruction, faces the challenges of data sparsity and insufficient personalization modeling in large-scale instructional environments. To this end, this paper proposes a constructivist-inspired quantum self-attention knowledge tracing model (CQSA-KT). The deep mapping relationship between Constructivist Learning Theory (CLT) and Quantum Computing (QC) is established by characterizing the multilevel nature of learning states through quantum states, modeling knowledge associations through quantum entanglement, and simulating the assessment process through quantum measurements. The model contains four core modules: The quantum knowledge representation embedding module (QKREM) utilizes quantum complex embedding to achieve a high-dimensional representation of knowledge states; the quantum attention interaction module (QAIM) applies quantum entanglement to model the non-local nature of knowledge associations; the quantum measurement module (QMM) introduces the quantum measurement theory for learning assessment; and the hybrid cognitive feature fusion module (HCFFM) integrates classical and quantum features. Experiments on three publicly available datasets show that CQSA-KT maintains better performance under high sparsity (>98 %) conditions, significantly outperforming ten existing benchmark models. Especially in extremely sparse scenarios (only 20 % training data), the model’s AUC improves by 8.5 percentage points over the benchmark models. This theory-driven technological innovation validates the application potential of QC in education and provides a new theoretical framework for the development of intelligent education.},
  archive      = {J_KBS},
  author       = {Chengke Bao and Zhiliang Xu and Weidong Ji},
  doi          = {10.1016/j.knosys.2025.114493},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114493},
  shortjournal = {Knowl. Based Syst.},
  title        = {CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series. <em>KBS</em>, <em>330</em>, 114492. (<a href='https://doi.org/10.1016/j.knosys.2025.114492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic prediction of in-service physical fields (e.g. stress, strain, and temperature fields) constitutes a cornerstone technology for digital governance of mechanical equipment. The stochasticity and time-varying characteristics of external excitation loads (e.g. thermal, vibrational, and impact loads) introduce significant complexity in physical field prediction. Online monitoring of physical fields at the assembly interfaces of mechanical systems is critical for ensuring structural safety, extending service life, and optimizing design. This study proposes TransPhyX (Transformer-Based Physical Field Prediction with XGBoost Precoder), a hybrid data-driven framework designed to overcome these challenges. The novelty of TransPhyX lies in: (1) a recursive stochastic load generation and parametric dataset construction method tailored for dynamic prediction tasks; (2) a modular hybrid architecture that decouples transient load encoding (via XGBoost) and dynamic sequence modeling (via Transformer), improving spatiotemporal continuity and generalization; and (3) an Outlier Removal Ensemble (ORE) algorithm that fuses multi-scale predictions to eliminate anomalies and enhance robustness. Validated on flip-chip thermal management and flange-bolt stress prediction, TransPhyX achieves 99.79 % prediction fidelity with a 97.79 % reduction in computational costs compared to FEM, outperforming AutoGAN and TransUNet baselines in both accuracy and stability. These contributions establish TransPhyX as a rapid, high-fidelity solution for real-time structural health monitoring and digital twin implementation in stochastic loading environments.},
  archive      = {J_KBS},
  author       = {Qiyin Lin and Feiyu Gu and Mingjun Qiu and Chen Wang and Jian Zhuang and Jun Hong},
  doi          = {10.1016/j.knosys.2025.114492},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114492},
  shortjournal = {Knowl. Based Syst.},
  title        = {TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation. <em>KBS</em>, <em>330</em>, 114490. (<a href='https://doi.org/10.1016/j.knosys.2025.114490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation Systems (RSs) aim to provide personalized recommendations by modeling user-item interaction patterns. Current attribute-enhanced RSs leverage user archival attributes to improve predictive performance. However, the use of attribute information introduces two critical challenges: 1) the risk of privacy leakage, as sensitive user attributes can be inferred from learned representations, and 2) high computational complexity, primarily due to the quadratic complexity of attention mechanisms. To address the accuracy-privacy-efficiency trilemma, we propose an Archive Knowledge Graph-enhanced Native Sparse Attention network (AKG-NSA) for privacy-preserving lightweight recommendation. Specifically, AKG-NSA introduces a two-stage privacy protection mechanism. First, we pseudonymize user identities in the archive knowledge graph, breaking the direct linkage between users and their attributes. Second, we design a Multi-channel Native Sparse Attention (MNSA) network that utilizes compressed user representations as queries to retrieve attribute patterns from the archive knowledge graph in a privacy-preserved manner. Moreover, we also construct a parallel user-item bipartite graph and operate graph convolutions to learn the representations for users and items. By employing the native sparse attention mechanism, AKG-NSA refines the learned representations while maintaining a low computational complexity. Extensive experiments on three real-world datasets demonstrate that AKG-NSA outperforms nine state-of-the-art baselines in terms of prediction accuracy, privacy preservation, and computational efficiency. The data and source codes of this work are available at https://github.com/juandu113/AKG-NSA .},
  archive      = {J_KBS},
  author       = {Juan Du and Chenxi Ma and Yaobin Wang and Limei Sun},
  doi          = {10.1016/j.knosys.2025.114490},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114490},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetric co-training with explainable cell graph ensembling for histopathological image classification. <em>KBS</em>, <em>330</em>, 114489. (<a href='https://doi.org/10.1016/j.knosys.2025.114489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, graph convolutional networks underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification. Our code is released on https://github.com/NeuronXJTU/ACT.},
  archive      = {J_KBS},
  author       = {Ziqi Yang and Zhongyu Li and Chen Liu and Xiangde Luo and Yu Xu and Xingguang Wang and Dou Xu and Chaoqun Li and Xiaoying Qin and Meng Yang and Long Jin},
  doi          = {10.1016/j.knosys.2025.114489},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114489},
  shortjournal = {Knowl. Based Syst.},
  title        = {Asymmetric co-training with explainable cell graph ensembling for histopathological image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions. <em>KBS</em>, <em>330</em>, 114488. (<a href='https://doi.org/10.1016/j.knosys.2025.114488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online chatter detection is a critical technology in intelligent manufacturing systems, essential for ensuring high-quality and efficient milling operations. Although artificial intelligence models have been developed to automatically identify chatter, the accuracy improvement is limited by the use of single sensor signals. Therefore, a multi-source heterogeneous sensor information fusion framework is proposed for intelligent online chatter detection in this paper. To effectively mitigate noise and eliminate interference from milling parameters, a heterogeneous sensor signal processing strategy is proposed based on wavelet packet decomposition and successive variational mode decomposition. Next, a multi-source, multi-stage, and multi-scale spatial-temporal fusion attention network is proposed for extracting chatter features and achieving high-precision chatter detection. It is noteworthy that multi-source signals are fused at the feature level, and comprehensive chatter features are extracted through the multi-source information fusion module, the multi-stage spatial-temporal feature extraction and fusion module, and the multi-scale gated channel attention module. In milling experiments across different conditions, the chatter detection performance of the proposed framework is evaluated in three scenarios. The results indicate that this framework can provide more accurate and reliable detection results compared to other methods.},
  archive      = {J_KBS},
  author       = {Liangshi Sun and Xianzhen Huang and Zhiyuan Jiang and Jiatong Zhao and Xu Wang},
  doi          = {10.1016/j.knosys.2025.114488},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114488},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-conditional image synthesis with intra-class relation preservation. <em>KBS</em>, <em>330</em>, 114487. (<a href='https://doi.org/10.1016/j.knosys.2025.114487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling class-conditional data distributions remains challenging, since the intra-class variation may be very large. Different from generic class-conditional Generative Adversarial Networks (GANs), we take inspiration from the observation that there may exist multiple modes with diverse visual appearances in a single class, and propose an Intra-class Prototype-based Relation Preservation (IPRP) approach to improve class-conditional image synthesis. Toward this end, a generator is designed to learn class-specific data distribution, conditioned on intra-class prototype-based relation. To associate label embeddings with the cluster prototypes, we incorporate an auxiliary prototypical network to perform adversarial interpolation, and the synthesized data are required to encapsulate their relation to the corresponding prototypes in the form of interpolation coefficients. The prototypical network can be further leveraged to improve the class-conditional real-fake identification performance by injecting semantics-aware features into a discriminator. This design allows the generator to better capture intra-class modes We conduct extensive experiments to demonstrate that IPRP outperforms the competing class-conditional GANs in terms of data diversity and semantic accuracy.},
  archive      = {J_KBS},
  author       = {Yunfei Zhang and Xiaoyang Huo and Tianyi Chen and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2025.114487},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114487},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-conditional image synthesis with intra-class relation preservation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems. <em>KBS</em>, <em>330</em>, 114485. (<a href='https://doi.org/10.1016/j.knosys.2025.114485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of new-generation artificial intelligence technologies, machines can process and analyze large-scale data more accurately and efficiently and for more complex tasks. Enhancing the usability and value of the information derived from various information systems across multiple dimensions is essential. However, traditional data dominance relationships cannot reflect people’s different levels of attention to antithetic features, leading to higher complexity and lower classification accuracy. Therefore, it is necessary to consider the weight relationships between attributes in the data, which refers to the degree of correlation between each attribute and the decision in multi-source information systems. Based on these weights and dominance relationships, we consider an entropy-based weighted information fusion method for processing supervised data in multi-source ordered decision systems. We intend four incremental fusion mechanisms to adjust information sources and attribute changes to save running time. Furthermore, experiments are conducted on nine real datasets to demonstrate our method’s effectiveness. The results show that the inevitable accuracy comparisons by the proposed method are superior to most fusion methods. In addition, the dynamic mechanisms, compared to static mechanisms, can significantly reduce running time.},
  archive      = {J_KBS},
  author       = {Xiaoyan Zhang and Jiajia Lin},
  doi          = {10.1016/j.knosys.2025.114485},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114485},
  shortjournal = {Knowl. Based Syst.},
  title        = {A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system. <em>KBS</em>, <em>330</em>, 114484. (<a href='https://doi.org/10.1016/j.knosys.2025.114484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To evaluate radar performance in complex electromagnetic environments, a compact and efficient causal model is required to model such a complex, nonlinear high-stakes problem. Hence, in this paper, we propose a feature reduction causal network (FRCN). Firstly, to determine the number of hidden layer features in the FRCN, a feature extraction strategy is designed using the intrinsic dimension (ID) of raw data as key prior knowledge, thereby reducing modeling complexity and improving computational efficiency. Then, to further reveal the causal relationships between features and the final objective, a Bayesian network (BN) is constructed in the task layer, intuitively showing the coupling relationships through a directed graph and providing interpretability for decisions on high-stakes problems. Moreover, we extend the layer-wise relevance propagation to the BN in the FRCN, enabling bidirectional reasoning throughout the entire process, which is beneficial to understand the model and its behavior in a human-understandable way. In experiments, it is proved that ID plays a significance role in feature number selection. Next, we design a new interpretable evaluation indicator, called decision-specific average edge relevance, to quantify interpretability. Compared to eight representative models, FRCN not only achieves higher accuracy but also provides stronger interpretability in terms of relevance, informativeness, and trustworthiness. A detailed analysis of a radar system enhances the understanding of coupling relationships among various factors, thereby validating the effectiveness of FRCN in feature reduction, interpretability, and trustworthiness for high-dimensional, complex, and nonlinear data.},
  archive      = {J_KBS},
  author       = {Chenfeng Wang and Xiaoguang Gao and Zidong Wang and Bo Li and Kaifang Wan and Xinyu Li and Chuchao He},
  doi          = {10.1016/j.knosys.2025.114484},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114484},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiFusionSeg: Diffusion-driven semantic segmentation with multi-modal image fusion for enhanced perception. <em>KBS</em>, <em>330</em>, 114481. (<a href='https://doi.org/10.1016/j.knosys.2025.114481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal data fusion harnesses complementary information from diverse sensors to enhance the comprehension of scenes. While multi-modal image integration enriches tasks like semantic segmentation, differing objectives of fusion and segmentation can cause conflicts that degrade performance. Existing methods fail to achieve an optimal trade-off between visual fusion quality and segmentation accuracy. This paper proposes DiFusionSeg, a novel fusion and segmentation model that employs a joint optimization framework to alleviate conflicts between the fusion and segmentation tasks. It not only generates fusion results with exceptional visual fidelity but also ensures precise segmentation. Through the carefully designed high-fidelity texture fusion module and diffusion-based segmentation module, DiFusionSeg effectively injects semantic guidance into the fusion process and enhances segmentation performance through denoising and feature fusion. Extensive comparative experiments on public RGB-T semantic segmentation datasets demonstrate that DiFusionSeg outperforms many state-of-the-art (SOTA) models (80.83 % mIoU on MSRS, 59.6 % mIoU on MFD). Additionally, it generates fusion results with exceptional visual fidelity. The source code and results will be released at https://github.com/warren-wzw/DiFusionSeg .},
  archive      = {J_KBS},
  author       = {Zhiwei Wang and Defeng He and Li Zhao and Bo Liu and Yayu Zheng and Xiaoqin Zhang},
  doi          = {10.1016/j.knosys.2025.114481},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114481},
  shortjournal = {Knowl. Based Syst.},
  title        = {DiFusionSeg: Diffusion-driven semantic segmentation with multi-modal image fusion for enhanced perception},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-EVFL: Efficient verifiable federated learning with privacy. <em>KBS</em>, <em>330</em>, 114480. (<a href='https://doi.org/10.1016/j.knosys.2025.114480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has recently become popular and widely used in various areas. However, it still faces challenges like the leakage of the client’s local model updates and the server forging aggregation results. To address these issues, we propose an efficient verifiable federated learning scheme with privacy (P-EVFL), which seeks to ensure privacy and verifiability with a lower overhead. Specifically, we first design a lightweight masking technique to protect the honest clients’ local model updates. Next, we introduce homomorphic hash functions to develop a verifiable method to ensure the integrity of the aggregation results. Besides, to reduce the overhead of the verification process, a verification algorithm based on a Merkle tree is proposed. We also conduct comprehensive experiments and compare our scheme with other state-of-the-art schemes. The experimental results show that in a scenario with 100 clients, our scheme reduces the computational overhead by up to 8.15 % and the communication overhead by up to 67.38 %.},
  archive      = {J_KBS},
  author       = {Juan Ma and Xiangshen Ma and Yuling Chen},
  doi          = {10.1016/j.knosys.2025.114480},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114480},
  shortjournal = {Knowl. Based Syst.},
  title        = {P-EVFL: Efficient verifiable federated learning with privacy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality meets re-learning: Mitigating negative transfer in sequential recommendation. <em>KBS</em>, <em>330</em>, 114479. (<a href='https://doi.org/10.1016/j.knosys.2025.114479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective recommendation models from sparse user interactions represents a fundamental challenge in developing sequential recommendation methods. Recently, pre-training-based methods have been developed to tackle this challenge. Though promising, in this paper, we show that existing methods suffer from the notorious negative transfer issue, where the model adapted from the pre-trained model results in worse performance compared to the model learned from scratch in the task of interest (i.e., target task). To address this issue, we develop ANT (Addressing Negative Transfer) for transferable sequential recommendation. ANT mitigates negative transfer by 1) incorporating multi-modality item information, including item texts, images and prices, to effectively learn more transferable knowledge from related tasks (i.e., auxiliary tasks); and 2) better capturing task-specific knowledge in the target task using a re-learning-based adaptation strategy. Our experimental results on five target tasks demonstrate that ANT does not suffer from the negative transfer issue, and substantially outperforms baselines on the target tasks.},
  archive      = {J_KBS},
  author       = {Bo Peng and Hanwen Du and Srinivasan Parthasarathy and Xia Ning},
  doi          = {10.1016/j.knosys.2025.114479},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114479},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modality meets re-learning: Mitigating negative transfer in sequential recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to extract and aggregate contexts for link prediction in heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114478. (<a href='https://doi.org/10.1016/j.knosys.2025.114478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many diverse real-world graph datasets are heterogeneous graphs, and link prediction on these graphs is a fundamental task. The current trends of link prediction on heterogeneous graphs emphasize leveraging contextual information from either a path between a source node and a target node, or a sub-graph sampled around these two nodes. However, these approaches face limitations in identifying only beneficial contextual nodes around source and target and then effectively aggregating the representations of these nodes for improving overall prediction accuracy. To address these limitations, we claim that carefully-extracted context nodes can aid in accurate link prediction, and these context nodes should be similar to a source node or a target node in a representation space. To this end, we propose a new link prediction framework LEACH which learns to extract the beneficial context nodes and to aggregate their representations in heterogeneous graphs. Specifically, our approach involves three steps to learn: (i) generating heterogeneity-aware representations of nodes in the heterogeneous graph, (ii) selecting the context nodes based on the relatedness to the source and target nodes; and (iii) aggregating the representations of the context nodes to obtain the source and target representations. Extensive experiments demonstrate that LEACH significantly outperforms existing baselines on three publicly available heterogeneous graph datasets. We provide analytical insights into the rationale behind the superior performance of LEACH on link prediction.},
  archive      = {J_KBS},
  author       = {Jimin Woo and Minbae Park and Hyunjoon Kim},
  doi          = {10.1016/j.knosys.2025.114478},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114478},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to extract and aggregate contexts for link prediction in heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation. <em>KBS</em>, <em>330</em>, 114477. (<a href='https://doi.org/10.1016/j.knosys.2025.114477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of advanced data analytics techniques within People Analytics and Human Resource Information Systems (HRIS), emphasizing their application in both organizational and sports performance contexts. By synthesizing Tournament Theory, Human Capital Theory, and Social Network Theory, this research provides a comprehensive framework for understanding skill dissemination, performance evaluation, and wage determination. Utilizing the NBA 2 K dataset, this study quantifies both tangible and intangible player attributes, incorporating digital engagement and social media metrics to enhance traditional performance metrics. Employing community detection algorithms and the Independent Cascade Model, the research uncovers hidden competencies and their influence on team dynamics and organizational effectiveness. The results contest established HRIS approaches, suggesting a holistic talent management strategy that takes into account the multifacetedness of skills propagation through networks. This work offers significant implications for HR professionals, providing novel insights into strategic HR planning, talent acquisition, and performance management in the digital age.},
  archive      = {J_KBS},
  author       = {Tianzi Zheng and Riyaz Sikora},
  doi          = {10.1016/j.knosys.2025.114477},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification. <em>KBS</em>, <em>330</em>, 114475. (<a href='https://doi.org/10.1016/j.knosys.2025.114475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge of cross-domain few-shot learning (CD-FSL) stems from models’ inability to generalize source-domain inductive biases to target domains under significant distribution shifts. While existing methods predominantly employ strategies like auxiliary target data adaptation, feature disentanglement, or metric space alignment, they overlook two inherent biases entrenched during source-domain training: (1) channel-wise dependency on source-specific feature patterns and (2) spatial-wise preference for source-typical structures, both of which hinder cross-domain transfer. We propose the first unified C hannel- S patial D ual-dimensional B ias C alibration (CSDBC) framework to systematically address these biases through progressive dilution, recomposition, and alignment. Our approach integrates three key innovations: (1) a parameter-free S tatic B ase-class B ias D ilution (SBBD) module that dilutes source-specific channel-spatial biases through layer-wise and point-wise modulation, effectively suppressing overfitting to source-specific patterns; (2) a D ynamic N ovel-class B ias R ecomposition (DNBR) module that generates target-adaptive channel-spatial soft masks via meta-optimized lightweight depthwise separable convolutions, enabling target-domain channel reweighting and spatial preference adjustment; and (3) a N ovel-class C ross-image S emantic A lignment (NCSA) module that establishes channel correlations and spatial correspondences between support-query pairs, significantly enhancing both discriminability and semantic consistency of target-domain features. Extensive experiments across eight CD-FSL benchmarks demonstrate consistent improvements, outperforming SOTA methods by 1.35 % (5-way 1-shot) and 2.00 % (5-way 5-shot) in average accuracy under varying domain shifts.},
  archive      = {J_KBS},
  author       = {Minghui Li and Hongxun Yao},
  doi          = {10.1016/j.knosys.2025.114475},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114475},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment. <em>KBS</em>, <em>330</em>, 114470. (<a href='https://doi.org/10.1016/j.knosys.2025.114470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has advanced natural language processing by improving contextual understanding and generalization abilities. However, despite these advances, determining event causality remains a challenging task. When LLMs are applied to this task, they frequently exhibit significant inconsistencies in recognizing causal representations, resulting in the phenomenon known as causal hallucinations. Specifically, LLMs perform well in predicting events with causal relationships but struggle with events without such relationships, frequently failing to achieve balanced performance across different causal scenarios. In this study, we propose MRBalance, a novel framework that uses role-based multi-agent debates to improve event causality identification. Our method transforms the task into a single-choice question-answering task, prompting LLM-based agents to engage in structured debates and justify their answers using their unique role-based perspectives. In addition, we introduce a mechanism for optimizing team members that selects the best agents to participate in the next debate when the debate rounds are lengthy. Extensive experiments on two benchmark datasets demonstrate significant performance improvements, highlighting the effectiveness of MRBalance in reducing causal hallucinations and increasing robustness.},
  archive      = {J_KBS},
  author       = {Xiang Zou and Xuanhong Li and Po Hu and Ming Dong},
  doi          = {10.1016/j.knosys.2025.114470},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114470},
  shortjournal = {Knowl. Based Syst.},
  title        = {MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMFP: Dynamic multiscale feature perturbations for transferable adversarial attacks. <em>KBS</em>, <em>330</em>, 114469. (<a href='https://doi.org/10.1016/j.knosys.2025.114469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transferability of adversarial samples facilitates adversarial attacks for the evaluation of the robustness of deep learning models, in which mitigating overfitting is of central importance for improving the transferability of adversarial samples. Current methods use regularization approaches to improve transferability without considering the degree of fitting of the adversarial perturbation and prior multiscale information of the source model during optimization, failing to find a flat minimum and improve generalization. This results in mutual inhibition of the attack capability and transferability. Therefore, our objective is to introduce the degree of fitting of the adversarial perturbation to dynamically regularize the multiscale feature for a better tradeoff between attack capability and transferability. In this paper, we propose dynamic multiscale feature perturbations (DMFP). Specifically, we investigate the properties of legitimate and adversarial features through qualitative visualization and quantitative distance metrics and devise multiscale feature perturbations (MFP). A combination of multiscale information and feature significance can perturb the salient features of a sample. In addition, we analyze the regularization effect produced by dropout in feature-level attacks and propose dynamic features (DF) to mitigate overfitting and enhance the generalization of adversarial samples by introducing gradient information. The experimental results demonstrate that DMFP significantly enhances the transferability of existing attack methods and achieves better performance than state-of-the-art methods, i.e., improving the success rate by 3.8 % against normally trained models and 12.8 % against defense models.},
  archive      = {J_KBS},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yumiao Zheng and He Xu and Yudong Yao},
  doi          = {10.1016/j.knosys.2025.114469},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114469},
  shortjournal = {Knowl. Based Syst.},
  title        = {DMFP: Dynamic multiscale feature perturbations for transferable adversarial attacks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIAFEx: An attention-based feature extraction method for medical image classification. <em>KBS</em>, <em>330</em>, 114468. (<a href='https://doi.org/10.1016/j.knosys.2025.114468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction techniques are crucial in medical image classification; however, classical feature extractors, in addition to traditional machine learning classifiers, often exhibit significant limitations in providing sufficient discriminative information for complex image sets. While Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) have shown promise in feature extraction, they are prone to overfitting due to the inherent characteristics of medical imaging data, including small sample sizes or high intra-class variance. In this work, the Medical Image Attention-based Feature Extractor (MIAFEx) is proposed, a novel method that employs a learnable refinement mechanism to enhance the classification token within the Transformer encoder architecture. This mechanism adjusts the token based on learned weights, improving the extraction of salient features and enhancing the model’s adaptability to the challenges presented by medical imaging data. The MIAFEx output feature quality is compared against classical feature extractors using traditional and hybrid classifiers. Also, the performance of these features is compared against modern CNN and ViT models in classification tasks, demonstrating their superiority in accuracy and robustness across multiple complex medical imaging datasets. This advantage is particularly pronounced in scenarios with limited training data, where traditional and modern models often struggle to generalize effectively. The source code of this proposal can be found at github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx .},
  archive      = {J_KBS},
  author       = {Oscar Ramos-Soto and Jorge Ramos-Frutos and Ezequiel Pérez-Zarate and Diego Oliva and Sandra E. Balderas-Mata},
  doi          = {10.1016/j.knosys.2025.114468},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114468},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIAFEx: An attention-based feature extraction method for medical image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic domain information modulation algorithm for multi-domain sentiment analysis. <em>KBS</em>, <em>330</em>, 114465. (<a href='https://doi.org/10.1016/j.knosys.2025.114465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidomain sentiment classification aims to improve model performance constrained by limited labeled data in a single domain by utilizing labeled data from multiple domains. Models that simultaneously train domain classifiers and sentiment classifiers have shown benefits. In this framework, domain classification serves as an auxiliary task, supplying crucial information for sentiment analysis. It is generally assumed that the importance of sentiment classification tasks remains consistent across all domains. By contrast, domain classification tasks exhibit variability because the impact of domain information on sentiment analysis differs among fields. This variability can be managed through adjustable weights or hyperparameters. However, as the number of domains grows, existing hyperparameter optimization algorithms face several challenges, including (1) high computational requirements, (2) convergence difficulties, and (3) increased algorithmic complexity. To efficiently generate the domain-specific information required for sentiment classification, we propose a dynamic information modulation algorithm. Specifically, the training process is divided into two phases. In the first phase, a global modulation factor that controls the proportion of domain classification tasks across all domains is established. In the second phase, we introduce an innovative cross-domain balancing modulation algorithm to refine the domain information embedded in the input text. This refinement is achieved using a gradient- and loss-based method. Experimental results show that our approach consistently enhances performance across most domains, achieving improvements of 0.3–1.0 % on 10 of 16 Amazon domains and 0.5–1.5 % on 3 of 5 Yelp domains, while maintaining performance comparable to baseline models in other domains.},
  archive      = {J_KBS},
  author       = {Chunyi Yue and Ang Li},
  doi          = {10.1016/j.knosys.2025.114465},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114465},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic domain information modulation algorithm for multi-domain sentiment analysis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intention-guided imitation learning methods under limited expert demonstration data. <em>KBS</em>, <em>330</em>, 114455. (<a href='https://doi.org/10.1016/j.knosys.2025.114455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation Learning has achieved significant results in various fields, such as robot control, autonomous driving, and unmanned vessel decision-making. This technology aims to mimic human behavior in specific tasks by learning the mapping between states and actions, enabling agents to execute tasks based on demonstrations. However, these methods rely on the acquisition of high-quality demonstration data, facing challenges such as difficulties in collecting expert samples, high costs, and low efficiency in policy learning. Particularly under limited sample conditions, imitation learning can easily get trapped in local optima, leading to lower success rates and accuracy in decision-making. Researchers have used data augmentation and transfer learning to tackle limited data. However, in complex scenarios, these methods are less effective due to a lack of domain-specific knowledge, which affects the interpretability of the model. To address these challenges, we propose an Intention-guided Imitation Learning method under limited expert demonstration data (ITIL), which extracts deep intent features from a small number of samples to enhance the agent’s understanding of the scene and improve the accuracy of the mapping from states to actions during Imitation Learning. Specifically, the core method consists of three modules: (1) Semantic Enhancement Module, which extracts spatiotemporal feature maps from a small number of raw trajectories to enrich the semantic information of expert data; (2) Intention Expression Module, which constructs an intention tree network to establish connections between different levels, effectively expressing and capturing expert intent; (3) Strategy Generation Module, which integrates the outputs of the first two modules as input to form efficient decision-making, creating a closed-loop architecture of cognitive understanding-knowledge expression-decision optimization. Experimental results show that our model outperforms baseline methods in navigation, capture, and formation tasks, with an average success rate improvement of approximately +6 % compared to the baseline method (ValueDICE).},
  archive      = {J_KBS},
  author       = {Yilin Liu and Xiangfeng Luo and Shaorong Xie},
  doi          = {10.1016/j.knosys.2025.114455},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114455},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intention-guided imitation learning methods under limited expert demonstration data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction. <em>KBS</em>, <em>330</em>, 114447. (<a href='https://doi.org/10.1016/j.knosys.2025.114447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality identification and extraction are crucial in understanding causal relationships in text. Current studies heavily rely on datasets annotated with causal relationships. However, acquiring such datasets poses a challenge due to substantial costs, hindering progress in this research field. To address this, we introduce CausalEnhance, a novel approach designed to bridge this gap by combining weakly-guided pre-training with external causal knowledge. Our method starts with a rule-based system that automates causal annotation, enriching external data with explicit causal knowledge and creating pseudo labels. These pseudo-labels are then incorporated into a weakly supervised pre-training framework. We introduce three innovative pre-training tasks: the Pre-training Causal Clues Fill-Mask task (PCM) to pinpoint causality origins, the Pre-training Causality Identification task (PCI) to capture general causal patterns, and the Pre-training Causality Extraction task (PCE) for understanding explicit causal pairs and inferring implicit ones. Our experiments, conducted across eight datasets in two languages, English and Chinese, demonstrate CausalEnhance’s effectiveness in both identifying and extracting causality, highlighting its potential as a robust method for textual causality analysis in different linguistic contexts.},
  archive      = {J_KBS},
  author       = {Meiyun Wang and Kiyoshi Izumi and Hiroki Sakaji},
  doi          = {10.1016/j.knosys.2025.114447},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114447},
  shortjournal = {Knowl. Based Syst.},
  title        = {CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis. <em>KBS</em>, <em>330</em>, 114446. (<a href='https://doi.org/10.1016/j.knosys.2025.114446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain generalization (FDG) as a solution to address the cross-client data heterogeneity problem in privacy-sensitive scenarios has drawn extensive attention in the field of intelligent fault diagnosis of industrial equipment in recent years. Nevertheless, most of the existing FDG-based diagnosis methods rely on client feature distribution alignment or data augmentation strategies, risking data leakage caused by the transmission of deep features and statistical information. To overcome the above-mentioned issues, a margin-guided parameter decoupling-consensus (MGPDC) framework is proposed to decouple the dependence of conventional federated domain generalization methods on features and data distributions and realize the extraction of common knowledge across clients. This framework initially employs a federated meta-learning-driven universal feature extractor to create a transferable shared feature space amidst heterogeneous client data, effectively enhancing the generalization ability of the model for unknown working conditions. Next, a parameter decoupling-consensus synergy (PDCS) mechanism is proposed. In this mechanism, an isolation module is established based on the consistency of parameter updates for parameter decoupling, effectively suppressing model update conflict. Subsequently, an implicit alignment mapping approach is devised for the screened parameters with strong consistency to achieve the extraction of cross-domain common knowledge. Then, an adaptive global margin guidance (AGMG) strategy is proposed to mitigate the interference of the blurred class boundaries during the federated process on common knowledge extraction. Finally, extensive experiments using real wind turbine gearbox data demonstrate the effectiveness and advancement of the MGPDC framework.},
  archive      = {J_KBS},
  author       = {Linhan Gou and Qikang Li and Baoping Tang and Xiaolong Zhang and Zihao Li and Yonggang Liu},
  doi          = {10.1016/j.knosys.2025.114446},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114446},
  shortjournal = {Knowl. Based Syst.},
  title        = {Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to surrogate computational bone remodelling in the calcaneus. <em>KBS</em>, <em>330</em>, 114445. (<a href='https://doi.org/10.1016/j.knosys.2025.114445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a data-driven approach using surrogate models based on Multi-Layer Perceptrons to predict bone remodelling outcomes in the calcaneus, both with and without fractures. The objective is to develop and train a neural network that accurately captures the biomechanical factors influencing the problem and predicts the resulting bone density distribution in the calcaneus. Given the complexity of bone healing processes, a comprehensive dataset was collected to train and validate the models under two distinct scenarios: an intact calcaneus and a fractured calcaneus treated with a surgical screw. Key parameters of the surrogate model, namely, the number of hidden layers, hidden layer size, and activation function, were optimized to enhance model performance. Additionally, training parameters such as learning rate and batch size were tuned. The hyperbolic tangent activation function was found to yield a lower mean squared error compared to the rectified linear units. Larger batch sizes and learning rates were found to improve model performance. The neural network designed to predict bone density in the intact model outperformed the one used for the fractured calcaneus with a screw, largely due to the increased variability in the fractured data. When the fracture did not significantly alter the trabecular distribution, prediction accuracy improved. Finally, the structural response of the models was evaluated, and it was observed that the trabecular arrangement inferred by the neural network tended to produce less stiff responses compared to those from the finite element method, likely due to the smoother density field predicted by the network.},
  archive      = {J_KBS},
  author       = {Ana Pais and Jorge Lino Alves and Jorge Belinha},
  doi          = {10.1016/j.knosys.2025.114445},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114445},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network to surrogate computational bone remodelling in the calcaneus},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interplay between bayesian neural networks and deep learning: A survey. <em>KBS</em>, <em>330</em>, 114438. (<a href='https://doi.org/10.1016/j.knosys.2025.114438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning models have seen significant success across various domains, their black-box learning nature and lack of interpretability affect their reliability in safety-critical applications like medical diagnostics and autonomous vehicles. In an attempt to address these limitations, Bayesian neural networks (BNNs) offer a promising alternative by incorporating uncertainty estimation into model predictions, enhancing transparency and decision-making. However, BNN development has primarily focused on efficient, high-fidelity approximate inference and guaranteed convergence in asymptotic settings. These are unsuitable for modern high-dimensional, multi-modal, and non-asymptotic deep learning applications, undermining their theoretical advantages. To bridge this gap, this paper provides in-depth reviews on how approximate Bayesian inference leverages deep learning optimization to achieve high efficiency and fidelity in high-dimensional spaces and multi-modal loss landscapes. It also reconciles Bayesian consistency with generalization objectives in non-asymptotic settings and investigates the generalization capabilities of BNNs. Additionally, this survey examines the often-overlooked expressiveness of BNNs, emphasizing how weight uncertainty and the absence of in-between uncertainty affect their performance. This survey aims to inspire BNN practitioners to adopt a deep learning perspective and offer valuable insights to propel further advancements in the field.},
  archive      = {J_KBS},
  author       = {Yinsong Chen and Samson S. Yu and Zhong Li and Jason K. Eshraghian and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.114438},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114438},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interplay between bayesian neural networks and deep learning: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-aware dynamic hypergraph for semi-supervised classification. <em>KBS</em>, <em>330</em>, 114435. (<a href='https://doi.org/10.1016/j.knosys.2025.114435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural networks, as high-order graph neural networks, excel in handling intricate relationships within non-Euclidean infinite-dimensional spaces. However, conventional homophily assumption-based hypergraph methods exhibit limited effectiveness in semi-supervised classification scenarios involving heterophily problem, where neighboring nodes often belong to dissimilar categories. To address this challenge, this paper proposes a Heterophily-Aware Dynamic Hypergraph (HADHG) framework grounded in heterophily assumption through label domain analysis. The framework comprises three key components: a hypergraph-oriented label propagation method for deriving class-specific label features, a label tensor construction approach characterizing node-level heterophily intensity via 2D tensors, and a center attention mechanism that dynamically optimizes hypergraph structures. By enabling nodes to dynamically reconfigure the local graph structure based on microscopic heterophily intensity, HADHG effectively mitigates heterophily interference. Comprehensive experiments using real-flight data from Unmanned Aerial Vehicles and the public Gear dataset highlight the framework’s superiority over state-of-the-art methods. The codes and datasets are openly available at https://github.com/DL-LEO/HADHG .},
  archive      = {J_KBS},
  author       = {Shaojun Liang and Ying Zheng and Housheng Su and Lei Zhang and Yi Yang},
  doi          = {10.1016/j.knosys.2025.114435},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily-aware dynamic hypergraph for semi-supervised classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning-based stacked capsule auto-encoder network with bidirectional gated recurrent unit for MVNO slicing mechanism in 6G networks. <em>KBS</em>, <em>330</em>, 114414. (<a href='https://doi.org/10.1016/j.knosys.2025.114414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In comparison to the existing 5 G technology, 6 G technology is intended to give consumers quicker and more dependable data transport. This technology is highly anticipated and is currently experiencing popularity due to its potential to provide massive network capacity, low latency, and a significantly improved user experience. So, this paper proposes a Deep Learning network slicing architecture for 6 G networks that uses federated learning to manage Radio Access Network (RAN) network slices. Ultra-Reliable Low-Latency Communication Plus (URLLC+), Further Enhanced Mobile Broadband (FeMBB), Mobile Edge Computing Slice (MEC-Slice), and Ultra Massive Machine-Type Communication (uMTC) devices are trying to send separate packets to a single base station (BS), where the uplink of a 6 G network is considered. Furthermore, mobile network operators will lease the physical resources of the RAN, such as radio resources, to mobile virtual network operators (MVNOs), allowing MVNOs to install RAN slices in accordance with the services they provide. In this paper, federated learning serves as the foundation for the Stacked Capsule Autoencoder Network with Bidirectional Gated Recurrent Unit (FL_SCA-BiGRU) model slicing mechanism for MVNOs, which interact to enhance the efficiency of allocating communication assets to their customers. In the results section, the proposed model is compared to various models in terms of jitter, quality of service (QoS), energy consumption, latency, throughput, and cost efficiency, and the values obtained are 1.2 ms, 98.9%, 98.4%, 0.2 ms, 980 Mbps, and 98.3%, respectively. The results show the proposed model has a clear edge over all other existing models.},
  archive      = {J_KBS},
  author       = {Megha Jain and Ravi Verma and J. Amudhavel},
  doi          = {10.1016/j.knosys.2025.114414},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114414},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning-based stacked capsule auto-encoder network with bidirectional gated recurrent unit for MVNO slicing mechanism in 6G networks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability. <em>KBS</em>, <em>330</em>, 114405. (<a href='https://doi.org/10.1016/j.knosys.2025.114405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO 2 emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench’s usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.},
  archive      = {J_KBS},
  author       = {Ana Gjorgjevikj and Ana Nikolikj and Barbara Koroušić Seljak and Tome Eftimov},
  doi          = {10.1016/j.knosys.2025.114405},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114405},
  shortjournal = {Knowl. Based Syst.},
  title        = {User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel double pruning method for imbalanced data using information entropy and roulette wheel selection for breast cancer diagnosis. <em>KBS</em>, <em>330</em>, 114403. (<a href='https://doi.org/10.1016/j.knosys.2025.114403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate illness diagnosis is vital for effective treatment and patient safety. Conventional machine learning models are built on the assumption of balanced medical data to perform cancer diagnoses. However, class imbalance remains a crucial challenge that adversely affects the classifier’s performance and reliability, while the existing ensemble solutions are still prone to noisy data and tend to overlook overlaps near decision boundaries. This paper proposes RE-SMOTEBoost, a double-pruning version of the basic ensemble SMOTEBoost method, designed to overcome these drawbacks. First, the proposed method focuses on generating synthetic samples in overlapping regions to better capture the decision boundary by employing roulette wheel selection. Second, it integrates an entropy filter to reduce noisy data and borderline cases, thereby improving the quality of the generated samples. Third, we propose a double regularization penalty to control the proximity of synthetic samples to the decision boundary and prevent the creation of new overlapping samples. These enhancements enable higher-quality oversampling samples, yielding a more balanced training dataset. Experimental findings demonstrated that the proposed method outperforms state-of-the-art methods, achieving a 3.22 % improvement in accuracy and an 88.8 % reduction in variance compared to the best-performing methods. Practically, the proposed model provides a robust solution for medical applications, handling data scarcity and imbalance arising from data collection difficulties and privacy constraints.},
  archive      = {J_KBS},
  author       = {Soufiane Bacha and Huansheng Ning and Mostefa Belarbi and Doreen Sebastian Sarwatt and Sahraoui Dhelim},
  doi          = {10.1016/j.knosys.2025.114403},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114403},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel double pruning method for imbalanced data using information entropy and roulette wheel selection for breast cancer diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table. <em>KBS</em>, <em>330</em>, 114391. (<a href='https://doi.org/10.1016/j.knosys.2025.114391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Open-ViTabQA, the first Vietnamese dataset for Table Question Answering (Table QA), addressing the lack of resources for Vietnamese natural language processing. The dataset was meticulously constructed and rigorously validated to ensure high quality. A comprehensive analysis of the structural characteristics of the dataset, including table structure, question types, and answer patterns, is presented. We also introduce BIF, a novel metric combining PhoBERT embeddings within BERTScore for semantic similarity and ViNLI for logical consistency, effectively capturing Vietnamese-specific linguistic nuances and logical coherence. The rigorously validated dataset, accompanied by an analysis of its structural characteristics, provides a robust framework for evaluating Table QA systems. Experiments with pre-trained models and large language models (LLMs) show that ViT5 achieves an F1-score of 45.22 %, an Exact Match (EM) score of 45.13 %, and a BIF score of 0.562. Among large language models, Gemini 2.0 Flash Experimental achieves 60.50 % F1 and 60.20 % EM, while Gemini 1.5 Pro-leads with a BIF score of 0.649, slightly outperforming Gemini 2.0 Flash Experimental (0.644 BIF), indicating more stable reasoning capabilities. However, a significant gap persists compared to human performance (86.49 % F1, 83.43 % EM, 0.781 BIF), highlighting challenges in capturing Vietnamese linguistic subtleties and logical intricacies. These findings underscore opportunities for advancing model performance and addressing data scarcity in Vietnamese Table QA. To facilitate reproducibility and further research, the Open-ViTabQA dataset is publicly accessible for research purposes.},
  archive      = {J_KBS},
  author       = {Dung Hoang Dao and Ngan Thi-Kim Huynh and Khanh Quoc Tran and Kiet Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114391},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114391},
  shortjournal = {Knowl. Based Syst.},
  title        = {Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creative style transfer for image stylization via learning neural permutation. <em>KBS</em>, <em>330</em>, 114368. (<a href='https://doi.org/10.1016/j.knosys.2025.114368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating novel artistic styles from a single style poses a significant challenge for traditional style transfer techniques, which typically focus on emulating the given style without introducing novel, surprising and value elements—fundamental criteria for evaluating creativity. In this paper, we propose Creative Style transFer (CSFer), a new style transfer approach for producing creative artistic styles. We first introduce a neural permutation network (PerNet) to rearrange the feature maps of a single-style image, thus producing new style features. These features are then transferred to the feature maps of a content image, yielding stylized outputs. To evaluate creativity, we employ metrics encompassing style perception distance and artistic aesthetics to assess novelty, surprise, and aesthetic value, respectively. Using this evaluation, we select the most creative style from various stylized results generated via random permutation matrices and an input style. Finally, we effectively train PerNet using both the original and selected creative styles. Extensive experimental results demonstrate that CSFer can generate creative stylized results. Furthermore, CSFer exhibits robust generalization capabilities by seamlessly inserting PerNet into existing style transfer methods.},
  archive      = {J_KBS},
  author       = {Shimin Li and Zedong Zhang and Gan Sun and Li-Wei H. Lehman and Jian Yang and Jun Li},
  doi          = {10.1016/j.knosys.2025.114368},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Creative style transfer for image stylization via learning neural permutation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach. <em>KBS</em>, <em>330</em>, 114125. (<a href='https://doi.org/10.1016/j.knosys.2025.114125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have become interested in aspect-level sentiment analysis. In the traditional sentiment analysis of documents or sentences, a label was assigned to the entire sentence or document. Whereas a sentence or document can have aspects with different sentiments. Although deep learning models have succeeded in aspect-level sentiment analysis, these models require rich labeled datasets in different domains to extract text features and sentiment analysis. This paper uses deep transfer learning for sentiment analysis of aspect-level sentiment analysis (AHDT) of social network data. The backbone of the AHDT model is a version of RoBERTa’s pre-trained deep neural network specially trained to work on social data. The features extracted from the pre-trained RoBERTa network for sentiment analysis are injected into the Bi-GRU deep neural network and then the attention layer. BI-GRU can process sequences from both sides (left to right and vice versa) and extract hidden relationships. In addition, the attention layer allows the model to pay attention to the more influential aspects of the text and provide a better interpretation. Also, this article uses the Class imbalance method to balance for training the model with almost the same polarities. The test results of the AHDT model on four SemEval datasets for the aspect-sentiment analysis task show that the model has improved the F1-score value in Resturan2014, 2015, and 2016 datasets by 0.63, 27.01, and 15.93, respectively. Also, this model has increased the accuracy value in Resturan2015 and 2016 datasets to 9.21 and 0.54, respectively. In addition, the results of experimental tests in all datasets show that the obtained values of accuracy and F1-score are close to each other, which indicates the stability of the AHDT model.},
  archive      = {J_KBS},
  author       = {Kia Jahanbin and Mohammed Ali Zare Chahooki},
  doi          = {10.1016/j.knosys.2025.114125},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114125},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MaintnDist: Filter pruning via maintaining feature distribution. <em>KBS</em>, <em>330</em>, 114009. (<a href='https://doi.org/10.1016/j.knosys.2025.114009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning reduces model complexity via identifying and removing unimportant filters, thereby effectively compressing deep convolutional neural networks. Most pruning methods focus on the information content of filters, retaining those with high information and removing those with low information. However, these methods may disrupt the feature distribution of the original convolutional layers. To address this challenge, a novel pruning method called MaintnDist is proposed, which prunes filters while preserving the feature distribution in convolutional layers. MaintnDist comprehensively evaluates the criticality of filters from the perspective of feature loss, no longer exclusively depending on information content. A feature distribution loss function is created to quantify the difference between the pruned network and the original network with respect to feature distribution. Upon this foundation, an intelligent pruning strategy is proposed that considers the less loss of feature distribution. This strategy maintains the original feature distribution by constructing a suitable structure. MaintnDist eliminates redundant filters while preserving those crucial for model accuracy, including those with low information content. Furthermore, MaintnDist avoids the need to retrain the network during the pruning process, thereby enhancing efficiency. Experimental results demonstrate that MaintnDist outperforms state-of-the-art methods in both prediction accuracy and the size of pruned networks. For example, MaintnDist prunes 92.84% of parameters and 77.67% of FLOPs in VGG-16, while enhancing accuracy by 0.49% on CIFAR-10 dataset.},
  archive      = {J_KBS},
  author       = {Yali Chu and Xuming Han and Limin Wang and Chengqi Zhang},
  doi          = {10.1016/j.knosys.2025.114009},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114009},
  shortjournal = {Knowl. Based Syst.},
  title        = {MaintnDist: Filter pruning via maintaining feature distribution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning. <em>KBS</em>, <em>329</em>, 114491. (<a href='https://doi.org/10.1016/j.knosys.2025.114491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) offers significant advantages in soft tissue contrast. However, it cannot directly provide electron density information for radiotherapy, relying instead on time-consuming and error-prone MRI-CT image registration. Synthetic CT (sCT) technology, which directly generates CT images from MRI, is pivotal for achieving only MRI-based radiotherapy. However, existing synthesis methods based on generative adversarial network (GAN) and diffusion models face challenges such as prolonged inference times and insufficient utilization of multimodal information, which severely hinder the clinical application of synthetic images. In this study, we propose a novel Multimodal Latent Diffusion Conditioned GAN (MLDCGAN) Model. First, we design a non-parametric non-Gaussian complex denoising distribution based on a conditional GAN, employing a multimodal distribution to achieve large-step denoising. This is combined with a pre-trained autoencoder to compress the image into a low-dimensional latent space, significantly reducing inference time. Second, we fully leverage multimodal MRI information by constructing a local refinement conditional generator with multimodal inputs, including T1-Weighted (T1W), T2-Weighted (T2W), and Mask images. The generator is enhanced by an adaptive weighted multi-sequence fusion module and an enhanced cross-attention module, significantly improving the structural consistency and detail fidelity of the generated sCT images. Finally, by jointly optimizing the style loss and content loss, we ensure the perceptual quality and clinical accuracy of the synthetic images. Experimental results demonstrate that MLDCGAN outperforms existing state-of-the-art methods on both public and private datasets, showing significant improvements in both image quality and inference speed. Subjective evaluations from multiple experienced clinicians indicate that the generated sCT images exhibit no significant difference from real CT in terms of key anatomical structure clarity and overall quality ( P > 0.05). Further assessments of clinical target delineation and dose distribution confirm that sCT retains anatomical features well and provides dose distributions consistent with real CT, ensuring the reliability of dose calculations in radiotherapy planning. This study provides a more reliable and efficient technical foundation for achieving only MRI-based radiotherapy. It is expected to assist clinicians in developing more precise radiotherapy plans, ultimately improving treatment outcomes in future clinical practice.},
  archive      = {J_KBS},
  author       = {Can Hu and Chunchao Xia and Chuanbing Wang and Xiayu Hang and Xiuhan Li and Han Zhou and Ning Cao},
  doi          = {10.1016/j.knosys.2025.114491},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114491},
  shortjournal = {Knowl. Based Syst.},
  title        = {MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph forecasting query based on global-local historical information. <em>KBS</em>, <em>329</em>, 114476. (<a href='https://doi.org/10.1016/j.knosys.2025.114476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) queries aim to retrieve relevant facts that conform to time constraints to answer a given query by reasoning known TKG facts. The continuous development of TKG query research has extended TKG queries to the TKG forecasting domain, enabling the forecasting of answers to unknown queries by leveraging historical information from query questions. However, TKG forecasting query research is currently facing two considerable challenges. Firstly, existing TKG forecasting query methods cannot adequately capture the global historical information of query questions, which makes it difficult to effectively mine periodic features, repetitive patterns, and dynamic evolution characteristics of new events. Secondly, when modeling local historical information, existing methods fail to focus on the historical correlation of facts between adjacent timestamps, ignoring the crucial role of local information in the temporal evolution process. In this paper, a TKG forecasting query framework based on global-local historical information is proposed to solve the above challenges. Specifically, for the global historical information of the query question, the periodic and repetitive patterns of historical facts and the potential changing laws of non-historical facts are learned by modeling global historical facts and non-historical facts. Concerning the local historical information, entities and relations are aggregated in knowledge graph (KG) snapshots and their changes and evolution are simulated at adjacent timestamps to enhance the ability of the model to capture temporal dependencies. At the same time, the impact of local snapshots on query questions is quantified to capture the evolution process of local information more accurately. Finally, we design dedicated scoring functions for different types of query tasks to achieve effective query forecasting. Extensive experiments on four datasets demonstrate that the proposed model has better performances in forecasting unknown queries than other baseline models.},
  archive      = {J_KBS},
  author       = {Luyi Bai and Tongyue Zhang and Lin Zhu},
  doi          = {10.1016/j.knosys.2025.114476},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114476},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal knowledge graph forecasting query based on global-local historical information},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption. <em>KBS</em>, <em>329</em>, 114467. (<a href='https://doi.org/10.1016/j.knosys.2025.114467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moments are essential descriptors for capturing fundamental characteristics of a signal, such as its shape and texture, thereby enabling a compact and easily analyzable representation. This article introduces a new family of discrete fractional moments, the quaternion Cartesian fractional dual-Hahn moments (QCFrDHOMs). These moments are derived from the fractional dual-Hahn moments (FrDHOMs), which are constructed from the matrix of fractional dual-Hahn orthogonal polynomials (FrDHOPs), obtained through the spectral decomposition of the classical dual-Hahn orthogonal polynomials (DHOPs). To ensure the stability of the computations, particularly for high-degree polynomials, a recursive method is proposed to calculate the initial terms of the DHOPs, thereby reducing the risk of numerical instability. The FrDHOMs are then generalized into QCFrDHOMs for efficient analysis of color images using quaternion algebra. Experimental results demonstrate that the QCFrDHOMs outperform classical DHOMs in terms of robustness and reconstruction capability. Additionally, an encryption and decryption scheme using QCFrDHOMs and chaotic systems is presented. Tests show that this scheme provides significant resistance to various attacks while maintaining nearly intact quality in the decrypted images. This not only highlights the effectiveness of the encryption scheme but also the enhanced security and robustness of the approach. Compared to other existing methods, our scheme stands out for its exceptional reliability and robustness, making a significant contribution to the secure protection of color images.},
  archive      = {J_KBS},
  author       = {Karim El-khanchouli and Hanaa Mansouri and Ahmed Bencherqui and Hicham Karmouni and Nour-Eddine Joudar and Mhamed Sayyouri},
  doi          = {10.1016/j.knosys.2025.114467},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114467},
  shortjournal = {Knowl. Based Syst.},
  title        = {Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based approach for traffic prediction with fusion spatiotemporal attention. <em>KBS</em>, <em>329</em>, 114466. (<a href='https://doi.org/10.1016/j.knosys.2025.114466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic data prediction is a crucial technology for data-driven intelligent transportation systems. This has an important impact on optimizing urban traffic management, travel efficiency, traffic experience, etc. Traffic flow prediction tasks primarily focus on mining dynamic spatiotemporal dependencies. Most existing Transformer-based methods and GNN-based methods have limitations in mining local-global spatiotemporal dependencies. To address this issue, we propose a novel traffic data prediction model called LGSTformer that can perceive local-global spatiotemporal dependencies. First, we construct an embedding layer that provides multiple types of embedding representations for the model by projecting spatiotemporal data and temporal and spatial information into different embeddings. Next, we design two modules to capture local-global temporal and spatial dependencies based on the naive spatiotemporal self-attention mechanism: the local-global temporal module and the local-global spatial module. The former incorporates multi-scale temporal convolutions to capture short-term temporal dependencies, and the latter incorporates dynamic-static graph convolutions to capture local spatial dependencies. Finally, to achieve effective fusion of local-global dependency information, a dual-path adaptive gated fusion layer based on a gating mechanism is introduced to attain adaptive fusion of information at different levels. Experimental results on four public real-world traffic datasets show that LGSTformer outperforms existing methods and has potential as an advanced solution for traffic flow prediction.},
  archive      = {J_KBS},
  author       = {Wenfeng Zhou and Guojiang Shen and Zhenzhen Zhao and Zhaolin Deng and Tao Tang and Xiangjie Kong and Amr Tolba and Osama Alfarraj},
  doi          = {10.1016/j.knosys.2025.114466},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114466},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transformer-based approach for traffic prediction with fusion spatiotemporal attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment. <em>KBS</em>, <em>329</em>, 114464. (<a href='https://doi.org/10.1016/j.knosys.2025.114464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication is an emerging paradigm to enhance network efficiency and perceptual quality, particularly demonstrating strong potential in image generation tasks. However, existing deep learning (DL)-based single-modal reconstruction approaches often suffer from semantic distortion and image blurring under bandwidth-limited and highly noisy channel conditions, limiting their suitability in task-oriented perception scenarios. Although generative AI-based semantic communication can significantly reduce data transmission volume, its high sensitivity to channel noise and lack of dynamic adaptation mechanisms limit the stability of reconstruction. To address these challenges, this paper proposes a multi-modal semantic communication framework named SEER , designed for resource-constrained intelligent sensing terminals. Built upon a pretrained language model, SEER incorporates a channel-aware prompt control strategy, a dual-modal integrative semantic restoration mechanism (DISR), and a single-pass sequential cross-modal reconstruction pathway to achieve collaborative semantic representation and robust structural recovery between images and text. Experimental results demonstrate that SEER achieves approximately 2.08 % bandwidth compression, while outperforming existing methods under extreme channel conditions by 33.92 % in structural fidelity and 12.64 % in perceptual consistency, highlighting its strong engineering deployability.},
  archive      = {J_KBS},
  author       = {Shengliang Wu and Jun Jiang and Xin He and Yong Xu and Yujun Zhu and Weiwei Jiang and Heju Li},
  doi          = {10.1016/j.knosys.2025.114464},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114464},
  shortjournal = {Knowl. Based Syst.},
  title        = {SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures. <em>KBS</em>, <em>329</em>, 114457. (<a href='https://doi.org/10.1016/j.knosys.2025.114457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern engineering systems, with their increasing complexity driven by technological advancements and growing interdependencies among components, present a challenge to traditional binary-state models. These models, which classify components as either fully operational or failed, are insufficient for capturing the progressive degradation, redundancy mechanisms, and cascading effects observed in real-world systems. Multi-State System (MSS) modeling, which represents intermediate operability states, is a step forward. However, the current literature overlooks a crucial information source: the system’s internal dynamics. These dynamics, which play a crucial role in shaping the system’s behavior, can be leveraged to enhance the learning process in MSS modeling. This study introduces a novel hybrid MSS modeling methodology that incorporates a system’s internal dynamic - such as network topology, redundancy mechanisms, and operational constraints - within an MSS. The methodology is first applied to a Brazilian power system, demonstrating how internal system characteristics influence the state evolution of individual components over time. This evaluation highlights the ability of the model to capture nuanced operational behavior driven by system-level constraints. The methodology is tested on multiple European transmission systems in a second stage to assess its predictive performance in estimating key reliability metrics. The proposed approach consistently outperforms existing models, achieving significantly lower prediction errors by accounting for internal constraints and the system’s dynamics. This work offers a generalizable solution for critical infrastructure planning across domains, enhancing MSS reliability modeling in various engineering systems.},
  archive      = {J_KBS},
  author       = {Henrique O. Caetano and Luiz Desuó N and Marco Aiello and Carlos D. Maciel},
  doi          = {10.1016/j.knosys.2025.114457},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114457},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs. <em>KBS</em>, <em>329</em>, 114456. (<a href='https://doi.org/10.1016/j.knosys.2025.114456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine learning technology, the application of stock prediction in financial portfolio optimization has become increasingly important. This study proposes an intelligent portfolio optimization method that combines gated bidirectional temporal convolution-discrete cosine graph neural network (TDGNN) with the mean-conditional drawdown at risk (Mean-CDaR) model, aiming to improve the risk-return performance of the portfolio. The method consists of two main stages: first, the data is converted into a hypervariable graph through the TDGNN model, the gated bidirectional temporal convolution layer is used to capture the temporal dynamic characteristics, and the discrete cosine graph neural network is combined to effectively model the complex spatiotemporal relationship in the stock market; second, the Mean-CDaR model is used for portfolio optimization, and the maximum drawdown is used as a measurement indicator to achieve precise risk control. Experimental results show that on the CSI 300, S&P500, and Nikkei 225 data sets, TDGNN and Mean-CDaR models perform significantly better than traditional methods, with R 2 of 0.9991, 0.9991, and 0.9983, respectively. Under the assumption of no transaction costs, the cumulative returns are 0.42, 0.62, and 0.93, respectively; considering 0.05 % transaction costs, the cumulative returns are 0.1, 0.25, and 0.49, respectively. The study shows that this method not only effectively captures the spatiotemporal dependency of stock data but also effectively controls risks while improving returns, providing investors with a robust and efficient decision support system.},
  archive      = {J_KBS},
  author       = {Chia-Hung Wang and Chiwang Lin},
  doi          = {10.1016/j.knosys.2025.114456},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114456},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control. <em>KBS</em>, <em>329</em>, 114453. (<a href='https://doi.org/10.1016/j.knosys.2025.114453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis is suitable for data control systems by discovering hidden knowledge that is difficult for humans to perceive from huge and complex data. In various data analysis methods, high utility occupancy pattern analysis considers the utility occupancy of each pattern in the corresponding transaction in addition to the profit and quantity of patterns, which is effective for data control systems, including data science fields. However, recent data holds more insightful knowledge when processing real-time generated data. Previous occupancy-based approaches do not handle the relative significance of the latest data. To overcome the limitation, we introduce a new method for discovering high utility occupancy patterns from dynamic data streams where time-sensitive data consistently occurs. The proposed method assigns relative importance to each pattern by considering the temporal aspect of each transaction. Advanced constructing and restructuring processes are utilized in the proposed method for efficiently controlling data according to the time flow of each pattern in dynamic environments. In the pattern expansion process, a new upper bound adopting the decaying factor is suggested to efficiently reduce unnecessary searches for unpromising patterns. Experimental results demonstrate that the proposed method has superior runtime and scalability performance compared to state-of-the-art methods with comparable memory usage. The ablation study underscores how the proposed components contribute to the overall effectiveness of the proposed method. Additional evaluations indicate that the proposed method analyzes insightful result patterns compared to state-of-the-art methods, and a case study demonstrates its applicability to real-time dynamic data control systems.},
  archive      = {J_KBS},
  author       = {Taewoong Ryu and Doyoung Kim and Seungwan Park and Seongbin Park and Myungha Cho and Hanju Kim and Junyoung Park and Hyeonmo Kim and Unil Yun},
  doi          = {10.1016/j.knosys.2025.114453},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114453},
  shortjournal = {Knowl. Based Syst.},
  title        = {Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel TriCore scheme for multiple RGB images in telemedicine environments. <em>KBS</em>, <em>329</em>, 114451. (<a href='https://doi.org/10.1016/j.knosys.2025.114451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific community is paying high attention to propose efficient solution to the open problem related to security and privacy of still visual communications. Telemedicine is one of the real world applications, experiencing such security concerns related to virtual consultation. Among the presence of already defined encryption schemes, this paper is dedicated to define TriCore, an efficient encryption scheme for multiple RGB images, inspired by three core components: σ ∃ -permutation, Laplacian matrix and 4D hyper chaotic system. The use of Secure Hash Algorithm-256 (SHA-256) in key generation assures the randomness and make it highly sensitive. Also, this paper presents a novel σ ∃ -permutation, to enhance the randomness effect in the corresponding cipher image. The scheme mainly deals with the matrices corresponding to the three channels of the merged image, undergoing σ ∃ -permutation and XOR operations with pair of channel matrices and key matrices, a single cipher image is produced corresponding to multiple RGB images. It prevents the revelation of actual number of shared images and make the scheme more strong. Obtaining the ideal values, experimental results witness the efficiency of TriCore scheme. The entropy is measured as 7.9998. The high resistance against the differential attacks is measured through the Number of Pixel Change rate (99.6158 % ) and Unified Average Changing Intensity (33.4621 % ). The execution time for 4 images each of size 256 × 256 is just 0.173470 s. The experimental results show that this paper efficiently facilitates secure communications in telemedicine providing higher security at lowest computational costs.},
  archive      = {J_KBS},
  author       = {Muhammad Tanveer Hussain and Imrana Shafique and Shamsher Ullah},
  doi          = {10.1016/j.knosys.2025.114451},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114451},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel TriCore scheme for multiple RGB images in telemedicine environments},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration. <em>KBS</em>, <em>329</em>, 114450. (<a href='https://doi.org/10.1016/j.knosys.2025.114450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing outliers is of paramount importance in the process of feature-based point cloud registration. However, it is still extremely challenging due to the high proportion of outliers, and the estimation of the accurate transmission matrix depends on the distribution of the inliers. The effective extraction of contextual information (local view) and the acquisition of full structural information (global view) influence the identification of inliers. Inspired by Gestalt principles in handling local and global relationships, we propose a Gestalt-inspired Graph Transformer Network (G-GTNet) for robust point cloud registration. G-GTNet extracts broader and more reliable contextual information while effectively aggregating both local and global features. Specifically, adhering to Gestalt principles, we design a multi-granularity aggregation (MGA) block that refines feature maps through a cascaded expanding path to acquire contextual details and promote information exchange among correspondences. In addition, to establish a consensus mechanism between local and global information, we introduce a global consensus attention (GCA) block. Similarly, the GCA follows Gestalt principles to optimally integrate local details and information about global structure, which allows it to gather information on a larger scale. Furthermore, a dependable seed selection (DSS) block is designed to filter out reliable and evenly distributed correspondences by distinguishing outliers and inliers more efficiently. Extensive experiments demonstrate that G-GTNet achieves better performance than state-of-the-art methods. It exhibits competitive performance and robustness in both outlier removal and pose estimation tasks across various public datasets with diverse feature descriptors. Notably, our proposed G-GTNet achieves an RR of 84.36 % on the 3DMatch using FPFH descriptor, surpassing S C 2 -PCR by 1.33 %. Our code will be released at https://github.com/gwk429/G-GTNet .},
  archive      = {J_KBS},
  author       = {Weikang Gu and Mingyue Han and Li Xue and Jiaming Yu and Heng Dong and Changcai Yang and Riqing Chen and Lifang Wei},
  doi          = {10.1016/j.knosys.2025.114450},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114450},
  shortjournal = {Knowl. Based Syst.},
  title        = {G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought. <em>KBS</em>, <em>329</em>, 114448. (<a href='https://doi.org/10.1016/j.knosys.2025.114448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graphs (TKGs) have emerged as a powerful paradigm for event forecasting, owing to their ability to dynamically represent the evolving relationships between entities over time. By effectively reasoning along the temporal dimension, TKGs help address real-world data incompleteness through inference of missing facts. Recent advances in large language models (LLMs) have led to their integration with TKG reasoning tasks. However, current LLM-based approaches face three critical challenges: (1) insufficient utilization of background knowledge, (2) inadequate modeling of the evolving temporal dynamics intrinsic to TKGs, and (3) difficulty in bridging the structural mismatch between the graph structure and the sequential operation mode of LLMs. To address these challenges, we propose EV-COT, a novel EVent-aware Chain-Of-Thought reasoning framework designed to explicitly model event evolution through structured, interpretable reasoning chains. EV-COT comprises three modular, plug-and-play components – knowledge module, perception module, and thinking module – that work collaboratively to extract essential event-related cues for enhanced reasoning. Specifically, the knowledge module generates high-quality contextual knowledge to enrich entity representation, and the perception module captures intricate structural and temporal patterns inherent in TKGs. Moreover, the thinking module extracts temporal logical rules, facilitating interpretable step-by-step reasoning. By effectively integrating these diverse contextual knowledge, EV-COT delivers more accurate predictions. Extensive evaluations on three datasets demonstrate that EV-COT consistently outperforms state-of-the-art methods, highlighting its effectiveness for precise event forecasting in TKGs.},
  archive      = {J_KBS},
  author       = {Zhangtao Cheng and Shichong Li and Yichen Xin and Bin Chen and Ting Zhong and Fan Zhou},
  doi          = {10.1016/j.knosys.2025.114448},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114448},
  shortjournal = {Knowl. Based Syst.},
  title        = {Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taxonomy-guided routing in capsule network for hierarchical image classification. <em>KBS</em>, <em>329</em>, 114444. (<a href='https://doi.org/10.1016/j.knosys.2025.114444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multi-label classification in computer vision presents significant challenges in maintaining consistency across different levels of class granularity while capturing fine-grained visual details. This paper presents Taxonomy-aware Capsule Network (HT-CapsNet), a novel capsule network architecture that explicitly incorporates taxonomic relationships into its routing mechanism to address these challenges. Our key innovation lies in a taxonomy-aware routing algorithm that dynamically adjusts capsule connections based on known hierarchical relationships, enabling more effective learning of hierarchical features while enforcing taxonomic consistency. Extensive experiments on six benchmark datasets, including Fashion-MNIST, Marine-Tree, CIFAR-10, CIFAR-100, CUB-200-2011, and Stanford Cars, demonstrate that HT-CapsNet significantly outperforms existing methods across various hierarchical classification metrics. Notably, on CUB-200-2011, HT-CapsNet achieves absolute improvements of 10.32 % , 10.2 % , 10.3 % , and 8.55 % in hierarchical accuracy, F1-score, consistency, and exact match, respectively, compared to the best-performing baseline. On the Stanford Cars dataset, the model improves upon the best baseline by 21.69 % , 18.29 % , 37.34 % , and 19.95 % in the same metrics, demonstrating the robustness and effectiveness of our approach for complex hierarchical classification tasks.},
  archive      = {J_KBS},
  author       = {Khondaker Tasrif Noor and Wei Luo and Antonio Robles-Kelly and Leo Yu Zhang and Mohamed Reda Bouadjenek},
  doi          = {10.1016/j.knosys.2025.114444},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114444},
  shortjournal = {Knowl. Based Syst.},
  title        = {Taxonomy-guided routing in capsule network for hierarchical image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning with gradient norm arbitration for sample-aware few-shot learning. <em>KBS</em>, <em>329</em>, 114443. (<a href='https://doi.org/10.1016/j.knosys.2025.114443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to rapidly adapt to unseen tasks is a fundamental objective in few-shot learning. Recent advances in optimization-based meta-learning have enhanced adaptability by learning sharable prior knowledge across tasks with just a few gradient descent steps. However, we argue that this shared prior knowledge can exert an imbalanced influence on individual samples within tasks, potentially resulting in a broad loss distribution where samples closely aligned with the prior knowledge exhibit low loss values, while others display high loss values. Furthermore, our experiments show that gradients computed as the average from a broad loss distribution tend to be non-representative and low, leading to poor generalization performance since the contribution of high-loss samples is diminished by low-loss samples. To address this, we propose a novel meta-learning method that arbitrates gradient norms based on sample-aware information during task adaptation. Specifically, we first normalize the gradient vector to reduce the imbalanced influence of prior knowledge on individual samples. Subsequently, the Arbiter, a learnable network, dynamically scales the current gradient norm by analyzing the relationship between original gradient norms and weight norms, which indicates the model’s sensitivity and complexity to each sample. In this way, the proposed method, Meta-learning with Gradient Norm Arbitration (Meta-GNA), improves generalization performance by preserving more representative and higher gradients that adequately reflect high-loss samples, which are distantly aligned with prior knowledge. Experimental results show that Meta-GNA improves performance in few-shot classification, particularly in cross-domain scenarios where the imbalance in prior knowledge across samples is more pronounced.},
  archive      = {J_KBS},
  author       = {Jongmin Lim and Soobin Cha and Heesan Kong and Sungkuk Shyn and Kwangsu Kim},
  doi          = {10.1016/j.knosys.2025.114443},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114443},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta-learning with gradient norm arbitration for sample-aware few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward efficient digital twin simulation: A causal representation learning approach. <em>KBS</em>, <em>329</em>, 114442. (<a href='https://doi.org/10.1016/j.knosys.2025.114442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, digital twin (DT) technology has emerged as a focal point in the field of shaft system prognostics and health management. To reduce simulation time cost and computational overhead, data-driven intelligent data generation algorithms have been employed as surrogates for traditional finite element simulations. However, such algorithms are typically constrained to generating in-distribution data within known operational domains and fail to generalize to out-of-distribution data under unseen conditions, which significantly hindering the development of DT model under variable operating scenarios. To address this limitation, this paper proposes a novel causal factorization–recombination network (CFRN) for generating shaft vibration responses under previously unseen operating conditions. Firstly, the structural causal model (SCM) for shaft vibration response is constructed to encode the causal mechanisms linking two critical operational parameters with vibration responses. Based on the SCM, a dual-encoder architecture is developed. By optimizing causal consistency loss, causal independence loss, and reconstruction loss, the model identifies latent mediators associated with the two causal factors. Additionally, a novel bidirectional cross-attention mechanism is introduced to equitably integrate mediators corresponding to different combinations of causal factors, enabling robust feature representation under unseen operational conditions. Finally, the recombined features are utilized to synthesize vibration response data. The proposed CFRN is validated using a shaft system simulation dataset. Extensive comparative experiments demonstrate that the generated data under unseen conditions by CFRN achieves 98.06% accuracy on crucial frequency. The proposed approach offers a novel paradigm for accelerating simulation response in DT frameworks.},
  archive      = {J_KBS},
  author       = {Shuyang Luo and Jiachang Qian and Yunhan Geng and Qi Zhou and Quan Lin},
  doi          = {10.1016/j.knosys.2025.114442},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114442},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward efficient digital twin simulation: A causal representation learning approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning methods for chaotic time series prediction. <em>KBS</em>, <em>329</em>, 114441. (<a href='https://doi.org/10.1016/j.knosys.2025.114441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos is a fundamental property of nonlinear dynamical systems, characterized by sensitivity to initial conditions, aperiodicity, and long-term unpredictability. It arises in numerous real-world processes-especially in energy systems, atmospheric dynamics, financial markets, and biomedical signals-where small perturbations may lead to drastic changes. Owing to its practical importance and modeling complexity, chaotic system prediction has received increasing attention in recent years. Regarding chaotic time series forecasting, deep learning offers strong capability in capturing nonlinear dependencies and long-horizon patterns. This review provides a comprehensive summary of deep learning techniques in this area, covering five core model classes: recurrent networks, convolutional structures, attention-based models, graph neural networks, and generative architectures. It also discusses hybrid modeling schemes, input-output paradigms, evaluation strategies, and complexity analysis. In addition, challenges-such as noise, missing data, and non-stationarity-are examined, along with recent efforts to mitigate them through signal decomposition, data completion, lightweight design, and loss adaptation. Real-world applications across diverse fields are surveyed to validate model effectiveness under complex conditions. This review offers new insight into the development of reliable, efficient, and generalizable deep learning frameworks for chaotic sequence prediction-highlighting directions such as physics-informed learning, lightweight architectures, and advanced hardware architectures.},
  archive      = {J_KBS},
  author       = {Yangyang Kui and Qiang Lai},
  doi          = {10.1016/j.knosys.2025.114441},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114441},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning methods for chaotic time series prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation. <em>KBS</em>, <em>329</em>, 114432. (<a href='https://doi.org/10.1016/j.knosys.2025.114432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot unsupervised domain adaptation (FS-UDA) aims to leverage knowledge from an imbalanced, labeled source domain and apply it to an unlabeled target domain. The primary difficulties of FS-UDA stem from the disparity in data distributions across source and target domains, coupled with uneven class representation in the source data. Label propagation (LP) is commonly used in domain adaptation scenarios. However, in FS-UDA tasks, LP disproportionately favors the normal classes because the source domain suffers from imbalanced class distribution, which results in insufficient feature representation and a large domain gap for the few-shot classes. To tackle these problems, we introduce a new robust LP approach that leverages prior-guided cross-domain data augmentation for FS-UDA. Unlike conventional approaches that solely utilize source domain visual data for few-shot class augmentation, our proposed method employs contrastive language image pretraining-derived semantic priors to supervise visual feature extractor training and optimize few-shot prototypes. It enhances domain-invariant feature learning while mitigating cross-domain distribution mismatches. We introduce the visual information from the target domain to perform data augmentation via style transfer, obtaining more diverse class-specific information. Subsequently, we capture intradomain and interdomain relationships more accurately by constructing intradomain and interdomain graphs independently for all samples (original and augmented) from both domains, which facilitates more effective LP and makes LP robust to few-shot classes. Furthermore, we introduce an adaptive graph regularization loss to dynamically adjust class weights, enhance intraclass compactness within domains, and reduce intraclass distribution discrepancies between different domains. Comprehensive experiments validate that the proposed method achieves superior performance compared to existing state-of-the-art methods across various FS-UDA tasks. The proposed method achieves 77.3 % and 61.7 % average accuracies for few-shot classes on the Office-31 and Office-Home datasets, respectively.},
  archive      = {J_KBS},
  author       = {Peng Zhao and Jiakun Shi and Ping Ye and Huiting Liu and Xia Ji},
  doi          = {10.1016/j.knosys.2025.114432},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114432},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management. <em>KBS</em>, <em>329</em>, 114430. (<a href='https://doi.org/10.1016/j.knosys.2025.114430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles a complex binary multi-objective optimization problem focused on minimizing the risk of pandemic importation through strategic passenger air traffic management. The approach involves determining whether international connections to destination airports within a specified country should be activated or deactivated over a defined time frame, considering epidemiological, economic, and socio-political impacts. We introduce a preliminary decision support system designed to assist decision-makers in the parametrization of the problem and quantify their preferences, thereby facilitating the derivation of a compromise solution via a binary particle swarm optimization (BPSO) metaheuristic. The standard BPSO is prone to particles getting trapped in local optima instead of searching for new solution and does not handle infeasible solutions properly. To overcome these inherent limitations, we propose an enhanced version of the BPSO metaheuristic. This enhanced algorithm incorporates novel mechanisms to promote solution space exploration and a robust strategy for managing infeasible solutions. A rigorous comparative analysis is conducted to evaluate the performance of the enhanced BPSO against both the original BPSO and several established state-of-the-art metaheuristics utilizing three benchmark datasets of a constrained problem. Finally, the effectiveness of the proposed enhanced metaheuristic is demonstrated in the context of the pandemic importation risk reduction problem, where it outperforms the original BPSO.},
  archive      = {J_KBS},
  author       = {Gabriel A. Peña and Antonio Jiménez-Martín and Alfonso Mateos},
  doi          = {10.1016/j.knosys.2025.114430},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114430},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization. <em>KBS</em>, <em>329</em>, 114429. (<a href='https://doi.org/10.1016/j.knosys.2025.114429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding additional information into digital images is an effective method of data privacy protection. A data hiding scheme needs to have a high level of imperceptibility to provide a high level of security. At the same time, it is necessary to maintain good capacity and ability to extract information in its original form. In this study, we propose an adaptive scheme for embedding data into the hybrid spatial-frequency domain of images based on the quantization index modulation (QIM) method. Information embedding is performed by small changes in pixels in the spatial domain using a change matrix. A genetic algorithm finds the optimal change matrix for each image block. The objective function combines visual invisibility, statistical invisibility, and extraction stability metrics. Information extraction is performed in the Discrete Cosine Transform (DCT) domain. Using the hybrid spatial-frequency domain reduces the number of DCTs and inverse DCTs when calculating objective function values during optimization. Additionally, we adaptively select quantization step values. Experimental results show that the proposed scheme is efficient in terms of embedding quality indicators. Moreover, the influence of additional information embedding on image histogram in the frequency domain is minimized. In terms of imperceptibility, our scheme achieves an average PSNR of 44.0920 dB, SSIM of 0.9995, and NCC of 0.9998 with an average capacity of 0.4640 bpp. The embedded information is extracted without errors in all cases and no additional information or re-optimization is required during extraction.},
  archive      = {J_KBS},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.knosys.2025.114429},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114429},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction. <em>KBS</em>, <em>329</em>, 114427. (<a href='https://doi.org/10.1016/j.knosys.2025.114427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is critical in multi-agent systems, with applications in autonomous driving, surveillance, and robotic collaboration. It aims to anticipate future agent behaviors to support proactive decision-making. However, modeling the temporal evolution of agent interactions in complex environments remains challenging. This paper introduces a dual-perspective trajectory prediction framework that integrates a dual-coordinate graph representation with temporally-aware edge modeling. Agent-centric interactions are captured using graph attention networks, while global scene-level dependencies are modeled via a Transformer. A cross-perspective fusion module merges these complementary features into expressive node embeddings. To better capture dynamic interaction patterns, a temporal edge encoding module combines relative positional features with sequential information. This design improves the model’s temporal sensitivity and robustness. Experiments on Argoverse 1 and Argoverse 2 benchmarks show that the proposed method achieves strong single-modal prediction accuracy while maintaining competitive multi-modal performance. Ablation studies validate the contributions of each module, highlighting the framework’s effectiveness, generalization capability, and potential for real-world deployment in complex multi-agent scenarios.},
  archive      = {J_KBS},
  author       = {Xudong Zhang and Yingqun Liu and Jie Fan and Guodong Du and Yuan Zou and Xuan Liu},
  doi          = {10.1016/j.knosys.2025.114427},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114427},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGPR: Towards privacy-preserving recommendation via bayesian data generation. <em>KBS</em>, <em>329</em>, 114425. (<a href='https://doi.org/10.1016/j.knosys.2025.114425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recommender system achieves more accurate user profile mining, the risk of user privacy disclosure increases. To address this, existing privacy protection-aware works model user interests and sensitive attributes and maintain independence between them. However, these efforts ignore the extraction of potentially interesting and similar items when modeling interest and sensitive properties. In this paper, a data generation-based privacy-aware recommendation (DGPR) is proposed to improve the modeling of interest and sensitive attributes to protect privacy. Specifically, a Bayesian data generation module is designed to construct the interaction behavior of potential interest items and potential attributes-similar items. Based on the generated data, DGPR learns representations of users/items with mutual information constraint to contain less sensitive attributes. In addition, DGPR focuses on the leakage of privacy from the recommendation list by using adversarial learning to remove sensitive attributes that were leakaged from the representation of the recommendation list of each user. A new metric RLP is designed to measure privacy leakage at the recommendation list level. Experiments are conducted on two publicly available datasets to verify the effectiveness of our proposed model in improving recommendation accuracy and privacy protection.},
  archive      = {J_KBS},
  author       = {Shenghao Liu and Guoyang Wu and Xianjun Deng and Hongwei Lu and Yuanyuan He and Minmin Cheng and Laurence Yang},
  doi          = {10.1016/j.knosys.2025.114425},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114425},
  shortjournal = {Knowl. Based Syst.},
  title        = {DGPR: Towards privacy-preserving recommendation via bayesian data generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems. <em>KBS</em>, <em>329</em>, 114424. (<a href='https://doi.org/10.1016/j.knosys.2025.114424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance is a growing global challenge with significant implications for public health. Wastewater surveillance offers a promising approach to monitoring and predicting the dissemination of antibiotic-resistant bacteria and genes (ARGs) in systems like sewer systems. However, current studies often lack integration between the optimization of sampling locations and the dynamic updating of predicted source locations based on continuous measurements. This paper proposes a novel data-driven framework that bridges this gap by combining multi-objective optimization for selecting optimal sampling locations with Bayesian updating for probabilistic source detection. The framework accounts for DNA degradation, sewage dilution and measurement variability to realistically simulate ARG concentrations in hydrosystems. Through iterative updates guided by detected signals at selected sampling locations, the model refines the likelihood of each sub-catchment being the main source of multiple ARGs, enabling accurate source localization. Validation was conducted using two real-world sewer systems under varying structural and sampling constraints. Across 1,000 simulated ARG scenarios and different sampler limits, results show that using only 3 and 5 samplers, the framework can achieve over 80% detection accuracy within four iterations; using 7 and 12 samplers raises accuracy to above 90%, depending on the complexity of the networks. These findings demonstrate the scalability, robustness, and practical applicability of the framework for ARG monitoring and decision support in diverse wastewater systems.},
  archive      = {J_KBS},
  author       = {Yao Yao and Regina Nogueira and Frank Klawonn and Markus Wallner},
  doi          = {10.1016/j.knosys.2025.114424},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114424},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models. <em>KBS</em>, <em>329</em>, 114423. (<a href='https://doi.org/10.1016/j.knosys.2025.114423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-Based Image Retrieval (CBIR) is crucial in cancer diagnosis, assisting pathologists by providing similar image data from previous records for analysis, especially when there is uncertainty in diagnosing a case. This process supports decision-making by providing valuable reference points to guide the diagnostic process. Foundation models have become increasingly important in the medical field due to their ability to generalize across various tasks and datasets, offering valuable support to pathologists by enhancing the accuracy and efficiency of diagnostic processes. In this article, a foundation model pre-trained on histopathology data is leveraged as a feature extractor without the need for task-specific training, in contrast to existing models that require extensive training to learn significant data representations. The proposed method, Clustering Latent Vector Aggregation (CLAV), condenses the significant feature vectors into a unique representative vector for the Whole Slide Image (WSI). Using a unique feature vector offers the advantage of reducing the size of the memory bank, thereby making the process of querying and retrieving similar WSIs more efficient. The experimental results presented in this study demonstrate that the proposed method enhances performance in CBIR tasks. This article highlights the potential of foundation models to achieve superior retrieval metrics compared to state-of-the-art methods specifically trained for CBIR.},
  archive      = {J_KBS},
  author       = {Alejandro Golfe and Pablo Meseguer and Valery Naranjo and Adrián Colomer},
  doi          = {10.1016/j.knosys.2025.114423},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114423},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributor-centric model watermarking for image generative models. <em>KBS</em>, <em>329</em>, 114422. (<a href='https://doi.org/10.1016/j.knosys.2025.114422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an efficient watermarking method for generative models that allows the developer (distributor) to create model instances with unique watermarks that are naturally embedded in their generated images. To achieve this, we replace the convolution layers of the generator with Watermark-Informed Convolution (WIC) in the pre-trained model. WIC consists of N parallel standard convolution kernels, and a watermark encoder transforms watermarks into coefficients that modulate these parallel kernels. Once fine-tuned with WIC, the distributor only needs to generate the coefficients and use them to combine the parallel kernels in WIC to create a generator with the desired watermark. Importantly, the combined kernel is identical to a standard convolution kernel, ensuring no additional inference overhead. Our method is highly scalable and efficient, making it practical for forensic capabilities by embedding watermarks directly into model parameters, remaining robust against common attacks such as model pruning or image compression. Furthermore, we evaluate our method on scenarios with highly aggressive compression or advanced adversarial attacks, and the trade-offs between watermark capacity, robustness, and computational efficiency. Experiments on multiple generative models demonstrate that the proposed method is architecture-agnostic, achieves high fidelity, and provides superior robustness compared to the existing methods.},
  archive      = {J_KBS},
  author       = {Jianwei Fei and Yunshu Dai and Wenyuan Yang and Zhihua Xia},
  doi          = {10.1016/j.knosys.2025.114422},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114422},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distributor-centric model watermarking for image generative models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation. <em>KBS</em>, <em>329</em>, 114421. (<a href='https://doi.org/10.1016/j.knosys.2025.114421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, photorealistic image generation has been a significant task in computer vision applications. Artificial intelligence-based generative models have attracted significant attention because they can generate samples that nearly resemble the properties of the training data. However, traditional methods leveraged for image generation tasks pose certain limitations such as model collapse, overfitting, and lack of diversity. As a result, this research aims to generate photorealistic images in the presence of adversarial attacks using the Quad Attention-enabled Generative Adversarial Networks (QuadAt-GAN) framework. The proposed QuadAt-GAN model can create photorealistic images from both text and image inputs. In addition, the incorporation of four different adversarial attacks in this research aids the system in fortifying itself against potential manipulations, thereby enhancing the robustness of the generated images. Moreover, the Quad attention (QuadAt) in the discriminator section refines the image generation process and equips the framework with a much better comprehension of the global information thus reducing the computational complexity of the model. The experimental results indicate the superiority of the proposed model for the photorealistic image generation task. When compared with the existing techniques the QuadAt-GAN model achieves a superior Structural similarity index measure (SSIM) of 0.95 for the Flickr 8k dataset with a training percentage of 80.},
  archive      = {J_KBS},
  author       = {Mohd Miskeen Ali and Mujahedullah H. Syed (S M) and Zeeshan Ahmed Mohammed and Ahmed Shahebaaz},
  doi          = {10.1016/j.knosys.2025.114421},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114421},
  shortjournal = {Knowl. Based Syst.},
  title        = {QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement with luminance duality. <em>KBS</em>, <em>329</em>, 114420. (<a href='https://doi.org/10.1016/j.knosys.2025.114420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions often suffer from high noise levels and a loss of details. Existing Low-light enhancement approaches often assume illumination as a global factor under Retinex theory, which may need to be more balanced with the complexities of real-world scenes with diverse lighting conditions. We propose a novel enhancement approach rooted in the Direct Perception (DP) theory. Through empirical evidence from real-world scenes, we illustrate the phenomenon of the duality of luminance in DP model, highlighting that luminance can exhibit both global and regional variations. Motivated by the above, we propose a novel low-light image enhancement framework, namely DPNet, that considers global and local luminance differences. Central to our approach is the introduction of two key modules: the Lumimator , a luminance estimator that leverages both local and global attention mechanisms, and the NLRestorer , a normal-light restoration network that effectively fuses color and luminance information for image restoration. Extensive experiments validate the efficacy of our framework, demonstrating significant enhancements in image quality metrics over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xingguo Lv and Xingbo Dong and Jiewen Yang and Lei Zhao and Bin Pu and Zhe Jin and Yudong Zhang},
  doi          = {10.1016/j.knosys.2025.114420},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114420},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-light image enhancement with luminance duality},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT. <em>KBS</em>, <em>329</em>, 114419. (<a href='https://doi.org/10.1016/j.knosys.2025.114419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems in the Industrial Internet of Things (IIoT) face challenges from high-dimensional, redundant data, making feature selection (FS) critical. Moreover, IIoT data is distributed across devices, creating data silos as for privacy concerns. Although federated learning (FL) has been extensively applied, existing federated FS methods based on swarm intelligence have limitations in both solution quality and convergence. To overcome these issues, we propose a hybrid breeding optimization algorithm inspired federated FS (HBOFFS) for intrusion detection in IIoT. Specifically, HBOFFS operates within a horizontal FL framework, where each client first employs a hybrid breeding optimization algorithm that integrates immune evolutionary mechanisms with cauchy distribution-based sampling (IC-HBO) to select a private optimal feature subset. IC-HBO improves both the global search capability and convergence efficiency of FS. Furthermore, a multi-client cooperative ensemble strategy (MCCES) is utilized, leveraging homomorphic encryption and secure multi-party computation to ensure the transmission of the feature weight matrix and corresponding indices of the selected feature subsets between clients and the server. The performance of HBOFFS is evaluated on several benchmark datasets, including CEC2022, UCI, NSL-KDD, HAI, and WUSTL-IIOT, using classifiers such as KNN, SVM, and XGBoost. The experimental results demonstrate that HBOFFS consistently outperforms state-of-the-art federated FS methods in terms of classification accuracy, recall, F1-score, runtime, and convergence speed, while effectively preserving data privacy.},
  archive      = {J_KBS},
  author       = {Zhiwei Ỹe and Songsong Zhang and Wen Zhou and Libing Wu and Ting Cai and Mingwu Zhang and Mingwei Wang and Jixin Zhang and Mengya Lei},
  doi          = {10.1016/j.knosys.2025.114419},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114419},
  shortjournal = {Knowl. Based Syst.},
  title        = {HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection. <em>KBS</em>, <em>329</em>, 114418. (<a href='https://doi.org/10.1016/j.knosys.2025.114418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time product quality inspection (QI) of products during manufacturing enables early defect detection and reduces resource waste. However, dynamic disturbances arising from QI, such as machine maintenance and rework operations, impose significant challenges to real-time production scheduling. In this study, a dynamic re-entrant hybrid flow shop scheduling problem considering in-line product quality inspection (DHFSP-QI) is investigated, where product quality variations dynamically impact production scheduling. To address this challenge, a multi-agent system (MAS) is developed to model dynamic shop-floor interactions among machines, quality detectors, products, and scheduling units. A knowledge-driven deep reinforcement learning (DRL) framework integrated with variable neighborhood search (KDRL-VNS) is proposed. The VNS-enhanced reward feedback mechanism guides agents to acquire efficient strategies. The DRL-enhanced scheduling agents use graph attention networks (GATs) to extract graph-based state representations of the workshop in real time, thereby enabling dynamic-scheduling decisions aimed at the minimizing total weighted tardiness. Experimental evaluations across multiple scenarios demonstrate that the proposed method, by incorporating VNS-based expert knowledge, outperforms various heuristic algorithms, genetic programming algorithms and DRL algorithms. It achieves accelerated convergence and delivers an average 4.6% relative improvement in performance compared to DRL methods.},
  archive      = {J_KBS},
  author       = {Youshan Liu and Jiaxin Fan and Chunjiang Zhang and Weiming Shen},
  doi          = {10.1016/j.knosys.2025.114418},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114418},
  shortjournal = {Knowl. Based Syst.},
  title        = {A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation. <em>KBS</em>, <em>329</em>, 114417. (<a href='https://doi.org/10.1016/j.knosys.2025.114417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable success in medical image segmentation. However, most existing methods treat images as regular grids (e.g., CNNs) or sequential structures (e.g., Transformers), which are not well-suited for the flexible extraction of irregular anatomical features in medical images. In this paper, we propose an efficient graph-based method, WinGraphUNet (Windowed Graph U-Net), for medical image segmentation. Our model innovatively integrates graph learning both within and between windows to capture local and global correlations efficiently. To merge local and global correlations across multi-scale feature maps effectively, we introduce a ReMixed Context Graph Bridge Block, which remixes multi-scale feature maps. Specifically, we use self-attention mechanisms to extract local features from non-overlapping windows, which can be treated as learning on fully connected graphs, and apply dynamic graph learning to capture long-range dependencies between windows, where inter-window connections are recomputed at each layer based on feature similarity. Our model fully leverages the flexibility of graphs to capture complex anatomical structures. Extensive experimental results on three medical image datasets ( i.e. , Synapse, Polyp, and ISIC2018 datasets) show that our approach outperforms state-of-the-art methods in segmentation accuracy. Notably, by reducing model parameters by 18 % and computational cost by 68 % compared to representative graph-based methods ( e.g. , AHGNN), our design significantly enhances the applicability of graph modeling in resource-constrained clinical scenarios, where model compactness and inference efficiency are critical. The code is publicly available at https://github.com/zndxyhn/WinGraphUNet .},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Haonan Yan and Qinsong Li and Lingxiao Liu and Weixin Si and Wei Liang and Beiji Zou},
  doi          = {10.1016/j.knosys.2025.114417},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114417},
  shortjournal = {Knowl. Based Syst.},
  title        = {WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data. <em>KBS</em>, <em>329</em>, 114416. (<a href='https://doi.org/10.1016/j.knosys.2025.114416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of the tumor microenvironment (TME), yet it faces key challenges in cross-patient cell type annotation and interpretable cell interaction analysis. This study introduces scExGraph, a graph neural network framework that combines adversarial graph domain adaptation and dynamic subgraph learning. Initially, a cell-cell graph is constructed via KNN, and a dual-branch graph convolutional encoder (GCN) is used to disentangle domain-specific and shared features, with adversarial training and adjacency matrix reconstruction ensuring topological consistency. Subsequently, a random attention mechanism dynamically adjusts edge weights, and KL divergence constraints generate interpretable subgraphs to identify key cell nodes. Finally, based on experimentally validated tumor-immune interaction genes, t -tests analyze these key cell nodes to identify critical cell signaling pathways affecting immune responses. Experiments across colorectal, non-small cell lung, and breast cancer datasets (88,507 cells) show scExGraph achieves an average accuracy of 0.918 in cross-patient annotation, significantly better than the benchmark GCN, and identifies immune regulatory genes like CEACAM1 and USP15. This research offers an explainable graph learning framework for decoding TME heterogeneity, balancing computational efficiency and biological significance. The source code are available at: https://github.com/an-xing456/scExGraph .},
  archive      = {J_KBS},
  author       = {Zhihua Du and Jiale Yi and Jianqiang Li and Hai-Ru You and Zhu-Hong You and Zhi-An Huang and Yu-An Huang},
  doi          = {10.1016/j.knosys.2025.114416},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114416},
  shortjournal = {Knowl. Based Syst.},
  title        = {ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN. <em>KBS</em>, <em>329</em>, 114415. (<a href='https://doi.org/10.1016/j.knosys.2025.114415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Aim: Colon capsule endoscopy (CCE) offers a minimally invasive method for imaging gastrointestinal lesions, including colorectal polyps, which may be precursors to colorectal cancer. However, its low image quality poses challenges for tasks such as polyp characterization. This work develops a low-complexity AI model, ResNet9-KAN, by integrating the Kolmogorov-Arnold network (KAN) into 9-layer residual network (ResNet9) architecture. This model efficiently characterizes polyps as neoplastic or non-neoplastic in CCE images, facilitating real-time patient management. Methods: This work utilized a CCE dataset generated from the PillCam Colon 2 system at four hospitals in the Region of Southern Denmark. It comprises 2089 CCE images of 479 polyps (317 neoplastic, 162 non-neoplastic) from a bowel cancer screening population aged 50 to 74. The proposed ResNet9-KAN and several existing AI models were trained on 1672 CCE images (221 neoplastic, 113 non-neoplastic polyps) and evaluated on 569 test images (48 neoplastic, 25 non-neoplastic polyps). Results: The evaluation revealed that our proposed ResNet9-KAN surpassed existing AI models with per-image characterization accuracy of 97.71 %, demonstrating an excellent balance between sensitivity (97.10 %) and specificity (98.17 %). It also achieved the highest F1 score of 0.9730 and a competitive area under the curve (AUC) of 0.9895. Additionally, ResNet9-KAN exhibited per-polyp characterization accuracy of 99.23 %, with a sensitivity of 99.85 %, specificity of 98.65 %, and an F1 score of 0.9912. Conclusions: This work highlights the efficacy of ResNet9-KAN in accurately characterizing polyps in low-quality CCE images, showing substantial potential for in situ characterization where histological verification currently requires a follow-up colonoscopy.},
  archive      = {J_KBS},
  author       = {Vinay Chakravarthi Gogineni and Jan-Matthias Braun and Benedicte Schelde-Olesen and Gunnar Baatrup and Esmaeil S. Nadimi},
  doi          = {10.1016/j.knosys.2025.114415},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114415},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential contrastive learning for progressive knowledge tracing. <em>KBS</em>, <em>329</em>, 114413. (<a href='https://doi.org/10.1016/j.knosys.2025.114413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, knowledge tracing has received significant attention in personalized education. It dynamically assesses users’ knowledge states based on their historical response sequence. User response sequences are central to knowledge tracing. While most studies focus on modeling short-term and long-term dependencies, few consider the order in which interactions occur. A recent study argues that the interaction order has little impact on users’ knowledge states (Lee et al. , The Web Conference, 2022), which contradicts both our intuition and constructivist learning theory. To address this contradiction, we propose a S equential Contrastive Learning algorithm for P rogressive K nowledge T racing, termed SPKT , to test the effectiveness of order information within the response sequences for assessing users’ knowledge states. SPKT embeds order information into the response sequence representation through a carefully designed contrastive learning module, and captures users’ monotonic memory decay patterns using a carefully designed non-symmetrical augmented view construction method. The enhanced sequence representation is subsequently utilized to decode user behavior with a progressive learning process module. Extensive experiments demonstrate that, on average, SPKT outperforms 10 baselines by up to 14 % in AUC and 8 % in ACC across 6 real-world datasets. Furthermore, the results highlight that the order information in response sequences significantly improves algorithmic performance-sometimes even more than the correctness of the responses themselves. Moreover, SPKT more accurately evaluates users with better academic performance and shorter learning sequences. For the same user, longer response sequences are more helpful in assessing a user’s knowledge state.},
  archive      = {J_KBS},
  author       = {Yi-Fei Wen and Hang Liang and Carl Yang and Tao Zhou and Jia Liu and Yajun Du and Yan-Li Lee},
  doi          = {10.1016/j.knosys.2025.114413},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114413},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential contrastive learning for progressive knowledge tracing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency. <em>KBS</em>, <em>329</em>, 114412. (<a href='https://doi.org/10.1016/j.knosys.2025.114412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an innovative stochastic computing framework for modeling and simulation of within-host transmission dynamics of Chikungunya virus infection, incorporating latency and randomness. We integrate a feedforward neural network with the Legendre spectral collocation method to provide accurate results for the complex nonlinear model. The stochastic model captures intrinsic randomness associated with disease progression. A rigorous theoretical analysis is conducted, establishing the stability of the disease-free equilibrium when the control reproduction number R ˜ 0 < 1 . To explore the model’s behavior under stochastic influences, we implement the spectral collocation scheme for numerical simulations and analyze the impact of key epidemiological parameters. Extensive computational experiments are performed to support the theoretical results. The effectiveness and reliability of the present neural network-enhanced scheme are assessed through multiple evaluation criteria, including regression performance, mean squared error (MSE), error distribution, and phase portrait analysis. Additionally, the developed approach is benchmarked against the standard spectral collocation method to demonstrate its improved accuracy and predictive capabilities. The present scheme can be effectively extended to simulate complex real-world systems beyond epidemic models.},
  archive      = {J_KBS},
  author       = {Shuo Li and Misbah Ullah and Saif Ullah and Taseer Muhammad and Qaiser Iqbal},
  doi          = {10.1016/j.knosys.2025.114412},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114412},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks. <em>KBS</em>, <em>329</em>, 114411. (<a href='https://doi.org/10.1016/j.knosys.2025.114411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an essential task in natural language processing (NLP) and is applicable in various areas, such as social media monitoring and consumer feedback assessment. Existing approaches, which are primarily based on transformer architectures, perform well in capturing contextual semantics; however, they often fail to model the structured relationships and long-range dependencies inherent in complex text, especially when multiple granularities (e.g., words, aspects, sentences) interact. To address this, we propose LGM-HGNN , a unique hybrid model that utilizes heterogeneous graph neural networks enhanced with hierarchical memory tracking through dynamic GRU gating. The proposed model uses rich graph representations to capture inter-word and inter-aspect relationships. Additionally, it incorporates a dual-level memory module, with local memory for instance-level detail and global memory for corpus-level sentiment trends, which are dynamically updated and fused for better sentiment tracking. Experiments using Twitter airline reviews and financial sentiment analysis datasets demonstrate that LGM-HGNN consistently outperforms transformer-based models, highlighting its effectiveness in aspect-based sentiment analysis (ABSA). Furthermore, LGM-HGNN combines structured graph representations with dynamic memory updates to improve sentiment tracking skills in many real-world applications.},
  archive      = {J_KBS},
  author       = {Md. Mithun Hossain and Sanjara and Md. Shakil Hossain and Sudipto Chaki and Md. Saifur Rahman and A B M Shawkat Ali},
  doi          = {10.1016/j.knosys.2025.114411},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114411},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking interactive image matting as incremental gaussian process regression problems. <em>KBS</em>, <em>329</em>, 114410. (<a href='https://doi.org/10.1016/j.knosys.2025.114410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive Image Matting (IIM) aims to predict alpha mattes through user interaction. Traditional methods often depend on user experience to interact at the regions where the alpha matte are inaccurate. However, regions with inaccurate model predictions do not necessarily correspond to areas of high model uncertainty, so these methods are unable to effectively reduce model uncertainty, resulting in low interaction efficiency. To address this issue, we observe a commonality between IIM tasks and Gaussian Process (GP) regression: the former predicts alpha values of unlabeled pixels based on user-labeled information, while the latter predicts observations of unknown data based on known data and provides uncertainty estimation for predictions. Based on this observation, we model IIM as an incremental GP regression problem and propose a novel IIM paradigm, IIM-GP. First, IIM-GP is the first model to incrementally utilize model-predicted uncertainty to guide user interaction and update matting results, significantly enhancing interaction efficiency and prediction reliability. Second, an incremental update strategy is implemented within the GP framework, overcoming traditional GP models’ inefficiency in updating results for IIM tasks. Additionally, IIM-GP employs a strategy of selecting p inducing points from n labeled pixels to perform variational inference on GP, reducing computational complexity from O ( n 3 ) to O ( n p 2 ) ( p ≪ n ). Comprehensive experiments on five widely-used datasets (Composition-1k, AIM-500, Distinctions-646, HIM2K and AM-2K) demonstrate that IIM-GP achieves competitive performance.},
  archive      = {J_KBS},
  author       = {Bingjie Guo and Wenhui Huang},
  doi          = {10.1016/j.knosys.2025.114410},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114410},
  shortjournal = {Knowl. Based Syst.},
  title        = {Rethinking interactive image matting as incremental gaussian process regression problems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical imaging model-guided deep variational despeckling framework for ultrasound images. <em>KBS</em>, <em>329</em>, 114409. (<a href='https://doi.org/10.1016/j.knosys.2025.114409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despeckling is essential for enhancing the clinical interpretability of ultrasound (US) images, as speckle noise can obscure tissue details and complicate diagnoses. Traditional despeckling methods, which rely on physical models of US imaging, have proven effective but often suffer from parameter sensitivity, low computational efficiency, and a tendency to over-smooth images. In contrast, deep learning (DL) approaches excel at learning from large datasets and can significantly reduce speckle noise with high efficiency and flexibility. However, DL methods face two key challenges: the scarcity of ground-truth clean US images, which requires the use of simulated clean images that might not accurately reflect real-world conditions, and the lack of integration with prior knowledge, leading to reduced interpretability and generalizability. In this paper, we propose a novel deep Variational US Image Despeckling (VUID) framework that addresses these limitations. VUID integrates the strengths of model-based methods by incorporating prior knowledge of US imaging physics and statistical distributions of relevant parameters into a variational DL architecture. Unlike previous methods, VUID treats simulated clean US images as the mode of the distribution of ground-truth clean images, serving as a guide rather than as absolute ground truth for training, which thereby enables a more accurate representation. The framework employs two distinct deep convolutional networks to predict the parameters of variational posterior distributions for speckle noise variance and ground-truth clean images. These networks are jointly optimized using a hybrid loss function that combines an Evidence Lower Bound (ELBO) loss with an image reconstruction loss guided by the US imaging model. We conducted extensive experiments comparing VUID with state-of-the-art traditional and DL despeckling methods. Our tests included assessing overall despeckling performance on three synthetic and two real US datasets, evaluating robustness and generalizability on two unseen real US datasets, and demonstrating clinical value through diagnostic quality assessments by medical experts. The results demonstrate that VUID surpasses existing methods across multiple metrics, highlighting its potential to improve the diagnostic accuracy and clinical utility of ultrasonic imaging. The code is available at https://github.com/blackpearl2021/VUID .},
  archive      = {J_KBS},
  author       = {Wenchao Cui and Zhihong Pan and Xiaolong Li and Yongheng Tang and Shuifa Sun},
  doi          = {10.1016/j.knosys.2025.114409},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114409},
  shortjournal = {Knowl. Based Syst.},
  title        = {Physical imaging model-guided deep variational despeckling framework for ultrasound images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust contrastive knowledge distillation for long-tailed noisy class labels. <em>KBS</em>, <em>329</em>, 114408. (<a href='https://doi.org/10.1016/j.knosys.2025.114408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training robust models on datasets with both long-tailed class imbalance and label noise is critical for real-world applications. Existing methods often fail to holistically address feature-space disentanglement and the synergy between noise robustness and imbalance mitigation. We propose Robust Contrastive Knowledge Distillation (RCKD) to bridge this gap. RCKD innovates in two aspects: (1) Diverse Multi-Expert Distillation: Peer networks with self-attention-driven weight diversification yield complementary feature/logit insights, coupled with synchronized logit calibration and feature disentanglement; (2) Dual-Mode Contrastive Learning: Unsupervised contrastive learning captures intrinsic geometry for pseudo-clean samples, while reweighted supervised contrastive learning enforces discriminative features for pseudo-noise samples using class-balanced queues. Extensive experiments show RCKD achieves state-of-the-art performance, e.g., +6.66 % over the best baseline on CIFAR-100-NLT (100:1 imbalance, 50 % noise).},
  archive      = {J_KBS},
  author       = {Shao-Yuan Li and Jinpeng Zheng and Mingguang Zhang and Dong Liang and Shaofang Li and Kangkan Wang},
  doi          = {10.1016/j.knosys.2025.114408},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114408},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust contrastive knowledge distillation for long-tailed noisy class labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets. <em>KBS</em>, <em>329</em>, 114407. (<a href='https://doi.org/10.1016/j.knosys.2025.114407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalances are a common issue in machine learning. Oversampling, one of the most prevalently adopted strategies, is utilized to address this issue. However, the currently available oversampling techniques suffer from certain limitations when handling complex imbalanced datasets, such as introducing noisy samples that result in class overlap and failing to effectively tackle within-class imbalances caused by low-density and small disjuncts etc. To address these limitations, a Density Clustering Hypersphere-based Self-Adaptively Oversampling Algorithm (DCHO) is introduced in this paper. The approach first dynamically determines the clustering centers through calculating the density of minority class instances, constructs hyperspheres for clustering on each determined center and then adaptively adjusts the radius of the hypersphere according to the imbalance ratio. Finally, oversampling is performed within the hyperspheres to avoid class overlap. Additionally, it adaptively assigns oversampling weights based on local densities and the radius of the hyperspheres, thereby addressing within-class imbalances. To further enhance the boundary distribution of the minority class and explore the unknown minority class area, a new boundary-biased random oversampling technique is developed to conduct oversampling inside each hypersphere. Evaluation results show that DCHO significantly outperforms other popular oversampling algorithms in handling classification problems in imbalanced datasets.},
  archive      = {J_KBS},
  author       = {Tao Xinmin and Xu Annan and Shi Lihang and Li Junxuan and Guo Xinyue and Tao Sirui},
  doi          = {10.1016/j.knosys.2025.114407},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114407},
  shortjournal = {Knowl. Based Syst.},
  title        = {Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated vulnerability score prediction through lightweight generative AI. <em>KBS</em>, <em>329</em>, 114406. (<a href='https://doi.org/10.1016/j.knosys.2025.114406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the constantly increasing number of newly published vulnerabilities, manually assessing their scores (e.g., under the Common Vulnerability Scoring System) has become unfeasible. Recently, learning-based systems have been proposed to automatically predict vulnerability scores. Such systems use vulnerability indexing databases to train deep learning algorithms. However, their practical applicability has important limitations, including a high dependency on the quality and diversity of training data, and high computational requirements. In addition, vulnerability descriptions often do not follow the standard templates and are not rich enough with respect to the expected features. In this paper, we propose a novel architecture that takes advantage of both generative artificial intelligence and lightweight deep learning techniques to provide an efficient and effective solution for automated vulnerability scoring. Data extracted from the National Vulnerability Dataset is fed into a large language model layer, whose output (i.e., an augmented dataset) is then used in a lightweight fine-tuned BERTsmall layer. We provide the results of an extensive experimental assessment of the effect of both each layer of the architecture and end-to-end performances. The results suggest that the combination of GPT3.5-Turbo and BERTsmall provides the most effective accuracy-time trade-off. We also compare the performance of the proposed architecture with other LLMs, BERT models, and cutting-edge approaches. The results show good improvements in prediction quality also when compared to a recent technique that incorporates data from 66 different sources, including the NVD.},
  archive      = {J_KBS},
  author       = {Seyedeh Leili Mirtaheri and Andrea Pugliese and Valerio Pascucci},
  doi          = {10.1016/j.knosys.2025.114406},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114406},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated vulnerability score prediction through lightweight generative AI},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Query-efficient and dataset-independent red teaming for LLMs content safety evaluation. <em>KBS</em>, <em>329</em>, 114404. (<a href='https://doi.org/10.1016/j.knosys.2025.114404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are widely used for their remarkable ability to understand and generate natural language. Nevertheless, LLMs can also produce unintended outputs that pose significant social risks. Red teaming can identify potential security vulnerabilities in LLMs and support mitigating such risks. However, existing red teaming approaches struggle to balance query efficiency and generalizability due to their complex search processes or reliance on pre-existing datasets. To address these issues, we present RAPT, a query-efficient and dataset-independent red teaming approach. RAPT employs an adaptive generate-select framework that consists of four cyclic steps: generating test cases by an LLM-based generator, selecting test cases by an reinforcement learning (RL)-based selector, testing the target model, and refining the generator and the selector. In this framework, the generator is used to generate test cases, and the selector is used to select test cases. We introduce a contrast prompt template and diversity demonstration extraction method to guide the generator, incorporating previous test feedback as demonstrations to generate more effective and diverse test cases. For the selector, we formalize the test case selection process as a Markov decision process (MDP), allowing us to design a reinforcement learning-based agent to continuously optimize the selection policy, which is able to balance the effectiveness and diversity of test cases according to a compound reward function. Experimental results show that RAPT can effectively discover more successful and diverse test cases than existing methods within a limited number of queries without relying on any pre-existing dataset.},
  archive      = {J_KBS},
  author       = {Shuo Liu and Xiang Cheng and Sen Su},
  doi          = {10.1016/j.knosys.2025.114404},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114404},
  shortjournal = {Knowl. Based Syst.},
  title        = {Query-efficient and dataset-independent red teaming for LLMs content safety evaluation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems. <em>KBS</em>, <em>329</em>, 114402. (<a href='https://doi.org/10.1016/j.knosys.2025.114402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing opacity and lack of verifiable audit trails in AI decision-making systems pose significant challenges to establishing trust and accountability, particularly in high-impact domains. This paper introduces Blockchain-Assisted Explainable Decision Traces (BAXDT), a novel architecture designed to enhance the transparency and auditability of AI systems. BAXDT creates comprehensive, immutable records for each AI decision by integrating model outputs, SHAP-based XAI summaries, a novel Explanation Density Metric, and detailed model/data context into a unified JSON trace. The 0.80 threshold for the Explanation Density Metric was empirically supported by Kneedle-based automatic threshold detection. The BAXDT architecture leverages blockchain by recording a cryptographic hash of each decision trace on-chain, while the full trace is stored off-chain. The system's effectiveness was demonstrated through a multi-faceted evaluation: simulations across three diverse public datasets (medical, financial, educational) confirmed its domain-agnostic applicability; a scalability analysis of up to 20,000 traces demonstrated its efficient and linear performance; and a successful deployment on the Ethereum Sepolia public testnet verified its real-world viability. A case study on text data further underscored the framework's flexibility. BAXDT provides a robust framework for documenting AI decisions - what, why, based on what, and when - thereby fostering trustworthy AI and supporting regulatory compliance.},
  archive      = {J_KBS},
  author       = {İsmail Enes Parlak},
  doi          = {10.1016/j.knosys.2025.114402},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114402},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDGC: Fuzzy deep clustering with dual-granularity contrastive learning. <em>KBS</em>, <em>329</em>, 114401. (<a href='https://doi.org/10.1016/j.knosys.2025.114401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering has garnered considerable attention in data mining and computer vision due to its effectiveness in handling high-dimensional data. However, traditional deep clustering methods face notable limitations. Real-world data often exhibit complex feature distributions and ambiguous boundaries. Fixed network architectures struggle to capture both global and local dependencies among data samples and are inadequate for managing fuzzy boundaries. Additionally, contrastive learning methods commonly used in deep clustering suffer from inefficient negative sample selection, where many positive samples are mistakenly treated as negative, thereby hindering training. To address these challenges, this paper proposes a fuzzy deep clustering method with dual-granularity contrastive learning (FDGC). The method extracts features and clusters them to generate pseudo-labels, retaining only the reliable ones through a confidence screening mechanism for use as supervision signals. By integrating data augmentation strategies with a self-attention fuzzy network, FDGC effectively captures both context and local details while dynamically adapting to feature fuzziness. Furthermore, a dual-granularity contrastive loss function is introduced to enhance feature representation. This loss improves sample discriminability at both the cluster and instance levels, significantly mitigating the issue of inaccurate negative sampling in traditional contrastive learning. Experimental results across multiple benchmark datasets demonstrate that FDGC outperforms existing method, validating the effectiveness of the proposed approach.},
  archive      = {J_KBS},
  author       = {Hengrong Ju and Jing Guo and Weiping Ding and Witold Pedrycz and Xiaotian Cheng and Xibei Yang},
  doi          = {10.1016/j.knosys.2025.114401},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114401},
  shortjournal = {Knowl. Based Syst.},
  title        = {FDGC: Fuzzy deep clustering with dual-granularity contrastive learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented decoding method using semantic diverse beam search for language generation model. <em>KBS</em>, <em>329</em>, 114400. (<a href='https://doi.org/10.1016/j.knosys.2025.114400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, the task of automatically generating natural language descriptions from visual content, has achieved remarkable accuracy in recent years. However, current approaches face a critical limitation in semantic diversity. Most diversity-oriented methods evaluate similarity at the surface lexical level, incorrectly treating lexically different but semantically equivalent phrases (e.g., 'dog runs' vs 'canine sprints') as meaningfully diverse outputs. This superficial approach fails to capture true semantic variation. Consequently, generated captions appear different but convey essentially identical meanings. To address this fundamental limitation, we propose Semantic Diverse Beam Search (SDBS), an augmented decoding algorithm that operates in semantic space rather than surface lexical space. SDBS integrates four key innovations: knowledge graph-based semantic similarity scoring, adaptive thresholding for important word focus, statistics-based stratified top-k sampling, and beam size normalization. Additionally, we introduce an early-stop strategy that significantly reduces computational complexity while maintaining generation quality, making SDBS practically viable for real-world applications. Comprehensive experiments demonstrate that SDBS achieves superior performance on both traditional metrics and modern evaluation approaches (BARTScore++, LLM-based assessment), generating captions with genuine semantic diversity while maintaining high accuracy and computational efficiency.},
  archive      = {J_KBS},
  author       = {HyungSun Na and Hee-Gook Jun and Jinhyun Ahn and Dong-Hyuk Im},
  doi          = {10.1016/j.knosys.2025.114400},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114400},
  shortjournal = {Knowl. Based Syst.},
  title        = {Augmented decoding method using semantic diverse beam search for language generation model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent space refinement for unsupervised cyber threat text classification. <em>KBS</em>, <em>329</em>, 114399. (<a href='https://doi.org/10.1016/j.knosys.2025.114399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification plays a critical role in Cyber Threat Intelligence (CTI) applications, where open-source text data is mined to identify patterns such as Indicators of Compromise (IoC), Tactics, Techniques and Procedures (TTPs), Named Entities and more. However, the dynamic nature of CTI makes traditional supervised machine learning classifiers impractical due to their reliance on large number of labelled training datasets. To address this, we propose Latent Space Refinement (LSR), an unsupervised method designed for CTI text classification. LSR introduces a posterior regularisation strategy where an auxiliary distribution derived from a TF-IDF feature space serves as signals to refine latent representations derrived from Pretrained Language Models (PLMs). By iteratively refining this latent space with clustering signals, LSR enables efficient similarity-based classification using only a few user-provided seed keywords. Extensive experiments on diverse CTI tasks, including both binary and multi-class classification, demonstrate that LSR consistently outperforms state-of-the-art unsupervised and zero-shot/few-shot methods in Accuracy and Weighted F1 score, all without tuning internal PLM parameters. This makes LSR a lightweight and PLM-agnostic solution for real-world CTI applications.},
  archive      = {J_KBS},
  author       = {Yue Wang and Richi Nayak and Md Abul Bashar and Mahinthan Chandramohan},
  doi          = {10.1016/j.knosys.2025.114399},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114399},
  shortjournal = {Knowl. Based Syst.},
  title        = {Latent space refinement for unsupervised cyber threat text classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-gate self-distillation network for efficient image super-resolution. <em>KBS</em>, <em>329</em>, 114398. (<a href='https://doi.org/10.1016/j.knosys.2025.114398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The balanced extraction of both non-local and local features represents a critical requirement for effective image super-resolution (SR). While transformer-based self-attention (SA) mechanisms demonstrate superior non-local modeling capabilities, their substantial computational demands limit practical deployment. To address this efficiency-performance trade-off, the Spatial-Gate Self-Distillation Network (SGSDN) implements a dual-capacity architecture combining: an SA-like (SAL) module employing strategically dilated 1D depthwise convolutions in horizontal and vertical orientations for efficient non-local feature extraction, and a lightweight local spatial-gate (LKG) block optimized for local detail preservation. Moreover, the proposed spatial-gate self-distillation block (SGSDB) further enhances performance through an optimized distillation structure that simultaneously processes both feature types while minimizing memory overhead. Experimental results demonstrate SGSDN’s superior performance-complexity balance, with benchmark evaluations showing comparable accuracy to SwinIR-light while requiring only 25% of the computational resources (FLOPs) and 25% of parameters, attributable to its avoidance of computationally intensive matrix operations.},
  archive      = {J_KBS},
  author       = {Yinggan Tang and Mengjie Su and Quansheng Xu},
  doi          = {10.1016/j.knosys.2025.114398},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114398},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-gate self-distillation network for efficient image super-resolution},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules. <em>KBS</em>, <em>329</em>, 114397. (<a href='https://doi.org/10.1016/j.knosys.2025.114397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many trust-based social recommender systems have focused on heterogeneity in trust relations, but this heterogeneity is considered only for explicit neighbors. Most of the existing works overlook heterogeneity in the high-order network structure of user-user social networks. Most of them assume that the power of trust relationship of a neighbor on a target user is constant and applies the same value when considering different categories of recommendations. To overcome the above challenges, we propose a model architecture named Motif-induced attention-based Capsule Graph Convolutional Networks ( mCGCNs ). To the best of our knowledge, this is the first study in which the capsule network extracts multiple latent social-aware user vectors and latent preference-based user vectors of a target user, which vary from item to item based on the recommendation. To extract multiple latent social-aware user vectors, we not only consider explicit neighbors but also consider implicit neighbors, and regarding this the motif networks capture the complex higher-level pattern of interactivities among users. The investigations and empirical analyses on publicly available real-world datasets (Ciao, Epinions, and Library Thing) illustrate the effectiveness of our model compared to 13 popular baselines. It outperforms the best baseline model by margins ranging from 9.86 % to 12.78 % in HR@10, 13.07 % to 13.55 % in NDCG@10, 7.63 % to 8.97 % in MAE, 6.05 % to 7.24 % in RMSE for three datasets of product recommendations. Through ablation study, key components in mCGCNs are validated to benefit the recommendation performance improvement.},
  archive      = {J_KBS},
  author       = {Supriyo Mandal and Ralf Krestel},
  doi          = {10.1016/j.knosys.2025.114397},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114397},
  shortjournal = {Knowl. Based Syst.},
  title        = {Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask. <em>KBS</em>, <em>329</em>, 114396. (<a href='https://doi.org/10.1016/j.knosys.2025.114396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD), a key research area in remote sensing, aims to efficiently identify and localize anomalous targets. However, challenges such as the high dimensionality of hyperspectral data, the sparse and complex distribution of anomalous targets, and the strong diversity of backgrounds make it difficult to distinguish anomalies from the background, thereby affecting detection accuracy. Existing methods often rely on background reconstruction for anomaly detection, but this approach tends to weaken the expression of the anomalous targets themselves, neglecting the core task of detection–accurate identification and localization of anomalous regions. To address this issue, this paper proposes a Multi-stage Cooperative Wavelet Convolution and Attention Mask Network (MCWANet), which aims to simultaneously enhance anomaly enhancement and background reconstruction capabilities, thereby effectively amplifying the differences between anomalies and the background. MCWANet employs a wavelet-based multi-spectral feature extractor, using low-frequency information for background modeling and high-frequency information for anomaly enhancement and boundary refinement. Meanwhile, a progressive attention refinement module, based on a spatial attention mechanism, dynamically generates adaptive masks to highlight potential anomalous regions and suppress background interference. Finally, a spectral-spatial residual fusion module integrates multi-source information, balancing anomaly enhancement and background modeling. Extensive experimental results on six public datasets show that, compared to ten state-of-the-art methods, MCWANet demonstrates superior anomaly detection performance and stronger generalization ability in complex backgrounds.},
  archive      = {J_KBS},
  author       = {Yuquan Gan and Xingyu Li and Siyu Wu and Ji Zhang and Ying Liu},
  doi          = {10.1016/j.knosys.2025.114396},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114396},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection. <em>KBS</em>, <em>329</em>, 114395. (<a href='https://doi.org/10.1016/j.knosys.2025.114395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical attacks against object detection have gained significant attention due to their practical implications. However, conducting physical experiments is time-consuming and labor-intensive, and controlling physical dynamics and cross-domain transformations in the real world is challenging, leading to inconsistent evaluations and hindering the development of robust models. To address these issues, we rigorously explore realistic simulations to benchmark physical attacks under controlled conditions. This approach ensures fairness and resolves the problem of capturing strictly aligned adversarial images, which is challenging in the real world. Our benchmark includes 23 physical attacks, 48 object detectors, comprehensive physical dynamics, and evaluation metrics. We provide end-to-end pipelines for dataset generation, detection, evaluation, and analysis. The benchmark is flexible and scalable, allowing easy integration of new objects, attacks, models, and vision tasks. Based on this benchmark, we generate comprehensive datasets and perform over 8000 evaluations, including overall assessments and detailed ablation studies. These experiments provide detailed analyses from detection and attack perspectives, highlight limitations of existing algorithms, and offer revealing insights. The code and datasets are publicly available at https://github.com/JiaweiLian/PADetBench .},
  archive      = {J_KBS},
  author       = {Jiawei Lian and Jianhong Pan and Lefan Wang and Yi Wang and Shaohui Mei and Lap-Pui Chau},
  doi          = {10.1016/j.knosys.2025.114395},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114395},
  shortjournal = {Knowl. Based Syst.},
  title        = {PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning. <em>KBS</em>, <em>329</em>, 114394. (<a href='https://doi.org/10.1016/j.knosys.2025.114394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Temporal Knowledge Graph Completion (FTKGC) aims to predict missing facts when only a few instances are available for each relation. The shared relation between known few-shot instances and the query quadruple is highly time-dependent, while existing approaches model it as static. Static relation modeling faces two key challenges: First, neighbor aggregation relies on fully connected attention mechanisms, ignoring the sequential nature of neighbor quadruples. Second, relation learning treats support set knowledge as static, overlooking its dynamic temporal relations with the query. In this paper, we propose a novel F TKGC framework based on query- A daptive M amba- E nhanced temporal relation learning ( FAME ) to address above challenges. Specifically, our approach presents a three-stage relation representation learning strategy. It integrates neighbor-aware modeling for sequential neighbor aggregation, instance-aggregated modeling for relation learning across instances, and time-sensitive modeling to capture query-adaptive temporal dynamics. Experiments demonstrate the effectiveness of FAME on three benchmark datasets and validate the contribution of the proposed strategies.},
  archive      = {J_KBS},
  author       = {Xingyue Guo and Ying Zhang and Yu Zhao and Baohang Zhou and Xuhui Sui and Xinying Qian and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.114394},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114394},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting online order satisfaction with lagged data using WGAIN-GP. <em>KBS</em>, <em>329</em>, 114393. (<a href='https://doi.org/10.1016/j.knosys.2025.114393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce has grown a lot in recent years and so has the research performed in this field. In this paper we estimate order satisfaction by predicting outcomes of relevant variables at the moment an order is made, such that companies can act on this signal. In order to deal with data that is not known at the order date (i.e., lagged missing data), we propose an extension of an existing generative imputation method. The Generative Adversarial Imputation Network (GAIN) is suitable for data imputation on tabular datasets. A more stable method is the Wasserstein GAIN (WGAIN). In this paper, we propose to improve this method by adding the Gradient Penalty to WGAIN resulting in WGAIN-GP. We perform experiments on a large dataset from a Dutch online retailer. Using WGAIN-GP we obtain a better accuracy of 61 % at the order date compared to 54 % and 53 % obtained by GAIN and WGAIN, respectively.},
  archive      = {J_KBS},
  author       = {Bette Donker and Evita Hoogeveen and Lars Hurkmans and Daan Schopmeijer and Flavius Frasincar and Enzo Ido and Jasmijn Klinkhamer},
  doi          = {10.1016/j.knosys.2025.114393},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114393},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting online order satisfaction with lagged data using WGAIN-GP},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual regularized bipartite graph learning for multi-view subspace clustering. <em>KBS</em>, <em>329</em>, 114392. (<a href='https://doi.org/10.1016/j.knosys.2025.114392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) has been widely studied for its ability to effectively capture the underlying structural information of multi-view data and achieve impressive clustering performance. As the volume of real-world data continues to grow, existing multi-view subspace clustering algorithms are unable to effectively tackle large-scale datasets. Therefore, multi-view subspace clustering methods based on bipartite graphs have been proposed to effectively solve the time complexity problem. Moreover, existing bipartite graph methods inevitably cause information loss due to the use of anchor points instead of the original data, leading to degradation of clustering performance. To address the above problems, we propose a virtual regularized bipartite graph learning for multi-view subspace clustering (VRBGL-MVSC) method, which utilizes anchors and bipartite graph learning to deal with the complexity associated with large-scale datasets. Specifically, we incorporate projection learning to generate discriminative anchor graphs in potentially low-dimensional spaces. Additionally, we propose a novel virtual regularization (VR) technique to guide bipartite graph learning, which explores multi-view data information faster and more efficiently. Furthermore, we develop an algorithm with good convergence to optimize VRBGL-MVSC. Experimental data show that in tests on four large-scale datasets, the VRBGL-MVSC algorithm outperformed all comparison algorithms, with improvements in the NMI metric of 0.17 %, 1.79 %, 1.13 %, and 3.24 % compared to the next-best results. This result clearly demonstrates that the VRBGL-MVSC algorithm excels in handling large-scale multi-view subspace clustering tasks and possesses a significant performance advantage.},
  archive      = {J_KBS},
  author       = {Linlin Ma and Wenke Zang and Xincheng Liu and Yuzhen Zhao and Xiyu Liu and Zhenni Jiang and Baoqiang Yan and Yawen Chen},
  doi          = {10.1016/j.knosys.2025.114392},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114392},
  shortjournal = {Knowl. Based Syst.},
  title        = {Virtual regularized bipartite graph learning for multi-view subspace clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction. <em>KBS</em>, <em>329</em>, 114390. (<a href='https://doi.org/10.1016/j.knosys.2025.114390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational AI has been rapidly advancing with the development of large language models and has shown excellent performance. However, one of its limitations is a passive system that cannot ask or guide users back to ambiguous questions. To overcome this, we have implemented an active dialog system that can smoothly transition from previous conversations. Our system is a target-guided system, which means it can guide the conversation by asking the user to provide a desired response or target. This approach is knowledge-rich and challenging, as it requires achieving the target while maintaining contextual consistency. To generate responses, we dynamically construct knowledge paths through knowledge graphs and relation predictors. These play an essential role in generating diverse and logically connected responses. To achieve this, we follow a global planning method that systematically conducts conversations with a target, and constructs knowledge paths based on common sense. We perform multi-hop reasoning and bi-directional search simultaneously to increase diversity and logical connectivity. We have overcome the limitations of existing works that rely solely on knowledge graphs by reflecting the results of relation predictors along with each object’s WIKI data in the path. Therefore, the consideration of the knowledge graph and the performance of the relation predictor, compared to the existing system, in completing the dynamic knowledge path and generating transition responses allowed conversations to transition more naturally. We have verified the proposed model through experiments.},
  archive      = {J_KBS},
  author       = {Hayoung Lee and Soyeop Yoo and Woong-Kee Loh and Ok-Ran Jeong},
  doi          = {10.1016/j.knosys.2025.114390},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114390},
  shortjournal = {Knowl. Based Syst.},
  title        = {Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding. <em>KBS</em>, <em>329</em>, 114389. (<a href='https://doi.org/10.1016/j.knosys.2025.114389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) modeling plays a crucial role in understanding complex systems. However, existing Transformer-based approaches often struggle to capture essential temporal structures, leading to information loss and even attention dispersion. To address these challenges, we propose MVGFormer , a novel Trans former -compatible M ultivariate Time Series framework guided by V isibility G raph principles. By explicitly establishing connections between time points based on visibility criteria, we introduce a graph-based sparse Attention (VG-Attention) mechanism, which selectively focuses on crucial temporal dependencies while filtering out irrelevant noise. This sparse Attention significantly mitigates the impact of quadratic complexity, improving scalability for larger time series data. Moreover, considering existing models often overlook the global dependencies within MTS, we extract consensus information across channels and aggregate the multiplex visibility graph into a consensus graph, revealing potential cross-layer patterns. Compared to single-channel models, MSE decreases by 2.82 %, classification accuracy increases by 9.73 %, and training speed improves by 67.48 %. Experimental results across 25 real-world datasets demonstrate that MVGFormer outperforms most existing models in four main tasks, including forecasting, classification, imputation, and anomaly detection. Overall, our approach provides a fresh perspective on adapting Transformers to better understanding temporal dependencies within time series data.},
  archive      = {J_KBS},
  author       = {Ting Chen and Xinyue Ren and Jinzhou Lai and Hongming Tan and Fangming Liu and Wai Kin Victor Chan},
  doi          = {10.1016/j.knosys.2025.114389},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114389},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels. <em>KBS</em>, <em>329</em>, 114388. (<a href='https://doi.org/10.1016/j.knosys.2025.114388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin Noise Labels (TNL) in Visible-Infrared Person Re-identification (VI-ReID) introduce annotation errors, severely impacting identity consistency. Besides, these misannotations contaminate identity correspondences and increase feature uncertainty, leading to degraded retrieval performance. Existing methods predominantly rely on point-based feature representations, which extract isolated identity features but struggle to capture the distributional variations caused by noise. To address these issues, we propose Probabilistic Partial Person Embedding ( P 3 E ), which introduces a multi-probabilistic embedding strategy that models local body regions as Gaussian distributions, capturing regional uncertainty. Additionally, we propose a probabilistic embedding fusion for Re-ID, which adaptively integrates local probabilistic embeddings to form a more robust identity representation. Furthermore, a Probabilistic Embedding Triplet loss is introduced to ensure distributional consistency and enhance cross-modal identity discrimination. Extensive experiments on SYSU-MM01 and RegDB demonstrate that P 3 E significantly outperforms state-of-the-art methods. Particularly in noisy-label scenarios, it achieves superior robustness and Re-ID accuracy, effectively mitigating the impact of TNL.},
  archive      = {J_KBS},
  author       = {Wen Guo and Manyu Wei and Jing Sun and Tuo Zhou and Junling Gao},
  doi          = {10.1016/j.knosys.2025.114388},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114388},
  shortjournal = {Knowl. Based Syst.},
  title        = {Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach. <em>KBS</em>, <em>329</em>, 114387. (<a href='https://doi.org/10.1016/j.knosys.2025.114387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation Extraction (RE) is a crucial component of information extraction, with the challenge of overlapping RE presenting considerable complexity. In this overlapping scenario, text often contains multiple relation triplets involving shared entities, requiring advanced methods to disentangle the complex semantics. Some existing works or large language models cannot address the nuances of overlapping semantics in special low information density cases with longer text but sparse triplets. To address this, we introduce the Triaxial Syntactic Fusion Approach (TSFA), which leverages shortest dependency paths (SDP) to fuse semantics and capture their nuance. By identifying candidate SDPs for overlapping entity pairs and transforming these into a comprehensive fusion SDP token set, TSFA grasps contextual clues to resolve overlapping RE more effectively. Subsequently, the TSFA integrates two attention mechanisms in three dimensions to direct the attention weights toward semantically significant tokens. This method facilitates the efficient interaction of all entities in a single step, thereby enhancing the model to capture nuance semantics in sparse triplet scenarios. Our extensive experiments on the widely recognized overlapping datasets demonstrate TSFA’s superior performance, achieving an excellent improvement in the F1-score over most of the leading baselines. 1},
  archive      = {J_KBS},
  author       = {Hailin Wang and Ran Tao and Xiufen Fang and Guisong Liu and Ke Qin},
  doi          = {10.1016/j.knosys.2025.114387},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114387},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-driven input shaping method using residual impulse vector via unscented kalman filter. <em>KBS</em>, <em>329</em>, 114385. (<a href='https://doi.org/10.1016/j.knosys.2025.114385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by escalating demands for precision and speed in modern industrial applications, residual vibrations in flexible structures and underactuated systems have emerged as a critical technical challenge, particularly during high-speed emergency braking scenarios. Input shaping has proven to be an effective technique for vibration control. However, existing input shapers commonly encounter challenges with time delay and inaccurate parameters, leading to suboptimal control performance. To address these critical issues, this paper proposes an Unscented Kalman filter-based Residual negative equal-magnitude Shaping (URS) model with two-fold ideas: a) reducing the time delay and compensating the modeling error via the consideration of negative and residual impulse vector; and b) identifying system parameters using a data-driven unscented Kalman filter to enhance control effectiveness. To validate its performance, four experimental datasets from laboratory systems have been established and publicly released. Empirical studies demonstrate that the proposed URS model has achieved a significant vibration suppression effect over several state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weiyi Yang and Yuqi Li and Mingsheng Shang and Shuai Li and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114385},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114385},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel data-driven input shaping method using residual impulse vector via unscented kalman filter},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance. <em>KBS</em>, <em>329</em>, 114384. (<a href='https://doi.org/10.1016/j.knosys.2025.114384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves. ALE curves are compared using the Fréchet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios. We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson’s dataset and a bike-sharing usage dataset — both structured in tabular format — as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.},
  archive      = {J_KBS},
  author       = {Pablo Hidalgo and Daniel Rodriguez},
  doi          = {10.1016/j.knosys.2025.114384},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114384},
  shortjournal = {Knowl. Based Syst.},
  title        = {An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning. <em>KBS</em>, <em>329</em>, 114383. (<a href='https://doi.org/10.1016/j.knosys.2025.114383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer is the most common malignancy among Australian men, with over 20 000 new diagnoses each year. Accurate forecasts of its incidence and mortality inform stakeholder decision-making and help mitigate its public health impact. In this context, we introduce cutting-edge lightweight neural networks into the domain of prostate cancer data forecasting with edge intelligence for the first time. To address the issue of overfitting in coarse-grained and small-scale prostate cancer datasets, we employ structurally streamlined models: the Gated Recurrent Unit (GRU) and Temporal Convolutional Network (TCN), representing two predominant branches of neural networks. The GRU’s simplified gating mechanism maintains excellent long-term dependencies capturing capability while drastically reducing parameter count, and the TCN combines sparse connections, parameter sharing, and causal dilated convolutions for efficient temporal modeling. To further bolster generalization, we integrate multiple regularization strategies, including the snapshot ensemble method. Comparative experiments on three real-world prostate cancer datasets demonstrate that our improved lightweight, high-performance neural networks achieve over 40 % higher accuracy than linear time series forecasting suitable for small-scale datasets.},
  archive      = {J_KBS},
  author       = {Yuting Cao and Ziyu Sheng and Haibin Zhu and Tingwen Huang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114383},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114383},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes. <em>KBS</em>, <em>329</em>, 114382. (<a href='https://doi.org/10.1016/j.knosys.2025.114382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being. This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. This study evaluates a diverse set of structure learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study. This study highlights the substantial impact of algorithm selection on intervention outcomes. To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural learning algorithms.We also investigate how each of those individual graphs, as well as the average graph, compare to the structures elicited by a domain expert who categorised graph edges into high confidence, moderate, and low confidence types, leading into three individual graphs corresponding to the three levels of confidence. The resulting causal model and data are made available online, and serve as a valuable resource and a guide for informed decision-making by healthcare practitioners. Our applied work integrates and evaluates existing causal structure learning methods for decision support in patients with diabetes. It offers a comprehensive understanding of the interactions between relevant risk factors for intervention, and enables us to simulate the effect of hypothetical interventions before implementation. Therefore, this research not only contributes to the academic discussion on diabetes, but also provides practical guidance for healthcare professionals in developing efficient intervention and risk management strategies.},
  archive      = {J_KBS},
  author       = {Sheresh Zahoor and Anthony C. Constantinou and Tim M. Curtis and Mohammed Hasanuzzaman},
  doi          = {10.1016/j.knosys.2025.114382},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114382},
  shortjournal = {Knowl. Based Syst.},
  title        = {Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multimodal molecular pretraining via prompt learning. <em>KBS</em>, <em>329</em>, 114381. (<a href='https://doi.org/10.1016/j.knosys.2025.114381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the advancement of pretraining models has revolutionized artificial intelligence, driving significant progress across various domains. In drug discovery, these models have shown remarkable potential by leveraging large-scale data to learn generalizable molecular representations, accelerating the identification of promising drug candidates. However, existing models often rely on atom-based reconstruction techniques to handle molecular structures, yet they frequently overlook substructural details such as functional groups and rings—elements that are critical for drug design and discovery. Furthermore, these models exhibit limitations in task adaptability, which impedes their precision in interpreting and predicting complex chemical environments. To address these challenges, we introduce MolFinePrompt, a fine-grained multimodal molecular pretraining model designed to enhance the representational capacity of molecular structures by integrating functional group data into their topological framework. Employing a contrastive learning approach, MolFinePrompt is pre-trained on a dataset of 316K molecular structure-text pairs and features bespoke task prompt texts for optimized fine-tuning, thereby improving its task-specific comprehension. The effectiveness of MolFinePrompt is validated through exemplary experimental results on cross-modal retrieval, molecular property prediction, and drug interaction prediction tasks.},
  archive      = {J_KBS},
  author       = {Yang Li and Zhengxin Wei and Chang Liu and Guohua Wang},
  doi          = {10.1016/j.knosys.2025.114381},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114381},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained multimodal molecular pretraining via prompt learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening. <em>KBS</em>, <em>329</em>, 114374. (<a href='https://doi.org/10.1016/j.knosys.2025.114374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a chronic ocular disease that often remains undiagnosed until advanced stages, highlighting the need for early detection. Current state-of-the-art methods mainly adapt attention mechanisms into classification networks designed for natural images via transfer learning, but they fail to capture domain-specific features and show weak cross-dataset generalization. In this paper, we propose a prior knowledge-driven dual-path network (PK-Net) that integrates medical knowledge into model architecture for glaucoma screening. First, based on the diagnostic importance of the optic disc, we introduce the Global and Local Fusion Network (GloLocNet), which combines high-resolution local optic disc images with global fundus images and applies a triple-loss strategy to improve feature extraction. Second, to leverage the strong inter-eye correlation of glaucoma, we propose the Binocular Fusion Network (BFNet), where paired eye images are processed through parallel GloLocNet encoders and fused to yield joint screening results. PK-Net was validated on multiple datasets, achieving superior intra- and cross-dataset results. For PAPILA, AUC, BAcc, Sen, and Spe were 95.67 %, 91.18 %, 88.72 %, and 93.63 %; for OIA-ODIR, 92.43 %, 85.64 %, 84.62 %, and 86.67 %. Trained on ORIGA and tested on REFUGE, the values were 90.00 %, 82.29 %, 81.25 %, and 83.33 %, demonstrating strong generalization. On GAMMA, results were 95.16 %, 83.37 %, 75.49 %, and 91.29 %. These findings indicate that PK-Net effectively enhances glaucoma screening by embedding prior medical knowledge into network design.},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Zeru Hai and Beiji Zou and Yang Li and Wei Liang and Zuheng Ming and Liming Chen},
  doi          = {10.1016/j.knosys.2025.114374},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114374},
  shortjournal = {Knowl. Based Syst.},
  title        = {PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection based on positive sample information weighting. <em>KBS</em>, <em>329</em>, 114373. (<a href='https://doi.org/10.1016/j.knosys.2025.114373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has garnered significant attention due to its capacity to reduce data dimensionality while effectively eliminating noise and irrelevant features. Information-theoretic methods are predominant in this domain, as they aim to quantify the relevance and redundancy among features, as well as between features and labels. However, existing information-theoretic methods frequently disregard the inherent distributional differences between positive and negative samples when assessing relevance and redundancy among variables. In multi-label data sets, positive samples associated with the same label tend to be more concentrated in the feature space, whereas negative samples exhibit a more dispersed distribution. This disparity is particularly evident in datasets characterized by label sparsity. The dispersed distribution of feature values for negative samples often results in reduced discriminative power and increased susceptibility to noise. To mitigate this limitation, we propose a novel feature selection method termed Multi-label Feature Selection based on Positive Sample Information Weighting (PSIWFS). PSIWFS assigns higher weights to features that demonstrate strong correlations with positive samples during the feature selection process, thereby enhancing the identification and prioritization of the less frequent positive samples. Experimental evaluations conducted on 14 datasets with 7 comparison methods underscore the superior classification performance of the proposed method.},
  archive      = {J_KBS},
  author       = {Qingqi Han and Ruikai Shi and Liang Hu and Wanfu Gao},
  doi          = {10.1016/j.knosys.2025.114373},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114373},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label feature selection based on positive sample information weighting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing pre-training via target-aware source data selection. <em>KBS</em>, <em>329</em>, 114371. (<a href='https://doi.org/10.1016/j.knosys.2025.114371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, due to the explosive popularity of large-scale pre-trained models such as large language models, pre-training approaches that use a massive amount of source data and can be applied to various target tasks are becoming more popular. Pre-trained models allow us to learn highly accurate target models by fine-tuning them with target data, even when their volume is insufficient. However, the source data used to train a pre-training model is generally a large and miscellaneous data set obtained in the wild without being aware of the target task, and it highly possibly contains much data that does not contribute to relearning the target task. This study defines a novel paradigm as “target-aware source data selection,” which uses the source data itself instead of a pre-training model and selects source data for pre-training and aims to increase its quality, effectiveness, and robustness. Our proposal fundamentally differs from the current studies addressing the lack of target data and conventional transfer learning approaches, improving source data quality using the novel Domain Adaptation Information Gain criteria. Specifically, the target model is pre-trained while actively selecting only informative data from the source data using the “rough-prior knowledge” obtained from the target data training before the pre-training. Finally, fine-tuning the model with the target data results in a highly accurate model for the target (downstream) task. The effectiveness of our proposed paradigm has been demonstrated through multifaceted experiments using multiple pairs of target data and source data with different strengths of their relevance.},
  archive      = {J_KBS},
  author       = {Kanyu Miyoshi and Ryotaro Shimizu and Linxin Song and Masayuki Goto},
  doi          = {10.1016/j.knosys.2025.114371},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114371},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing pre-training via target-aware source data selection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception. <em>KBS</em>, <em>329</em>, 114370. (<a href='https://doi.org/10.1016/j.knosys.2025.114370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the diversification of remote sensing (RS) sensor types, the accessibility and availability of various RS data types are continuously improving. The collaborative use of multi-source RS data can comprehensively and effectively improve the accuracy of RS for earth observation. However, current research on multi-source RS image fusion classification primarily focuses on only two types of RS data. The heterogeneous characteristics of three or more types of RS data significantly complicate the data fusion process. In particular, how to effectively explore the correlations among the inherent characteristics of three or more heterogeneous RS data remains a critical challenge that has not been effectively addressed. This greatly affects the accuracy of RS land classification and other earth observation tasks. To address this issue, a TSH-FCNet based on feature propagation and perception for collaborative classification of hyperspectral (HS), multispectral (MS), and radar images is proposed. This network thoroughly explores the intrinsic correlations among the three heterogeneous data sources and employs an innovative feature interaction mechanism to leverage their complementary advantages. It overcomes the interference of heterogeneous characteristics between different data sources on fusion, effectively enhancing the final classification accuracy. Specifically, a distance similarity attention guides the mutual perception and fusion of triple-source RS information, promoting the flow of complementary features among the triple-source and improving the final classification accuracy. Additionally, the shared information from the triple-source RS data is injected into the features to be fused through a domain alignment mechanism, enhancing the spatial and semantic consistency of the features, thereby strengthening the classification model’s ability to recognize complex surface features. We tested the algorithm on three triple-source RS datasets. The experimental results indicate that the proposed algorithm achieves significant improvements over existing mainstream methods, exhibiting greater stability and reliability when handling highly heterogeneous and diverse data sources. The implementation code of this algorithm will be available from https://github.com/cwlnnu/TSH-FCNet .},
  archive      = {J_KBS},
  author       = {Wei Cheng and Yining Feng and Yuting Zhao and Xianghai Wang},
  doi          = {10.1016/j.knosys.2025.114370},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114370},
  shortjournal = {Knowl. Based Syst.},
  title        = {TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification. <em>KBS</em>, <em>329</em>, 114369. (<a href='https://doi.org/10.1016/j.knosys.2025.114369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high annotation cost of 3D point cloud and the natural long-tail distribution across categories, 3D Point Cloud Few-shot Learning (3DPC-FSL) has arisen and attracted wide attention. However, as a core step of representation, max-pooling results in a substantial loss of point information and, thereby, leads to unsatisfactory performance, particularly with limited training data. The current solution for addressing this issue is to project 3D data into a series of 2D views and then aggregate the resulting 2D features for sufficient mining of point information. However, such a solution unavoidably neglects the internal 3D structure of point clouds. Herein, we propose a pure 3D approach named Enhanced Prototype Network with Gated Point Recyclable Feature Mining (EPN-GPRFM) for 3DPC-FSL. EPN-GPRFM follows the prototype-based FSL paradigm and enhances this paradigm from the perspectives of feature learning and prototype representation. In terms of feature learning, EPN-GPRFM enhances the 3DPC features by cyclically and adaptively mining the beneficial information from discarded points via a gating mechanism in each stage. In terms of prototype representation, EPN-GPRFM sufficiently exploits query samples to compensate the prototypes via a query-guided prototype enhancement strategy. Experiments on three well-known 3DPC benchmarks validate the effectiveness of our method and its prominent performance advantages over baselines.},
  archive      = {J_KBS},
  author       = {Hailin Wang and Sheng Huang and Luwen Huangfu and Ma Rui and Bo Liu},
  doi          = {10.1016/j.knosys.2025.114369},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114369},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal prompting and masking strategy for video-grounded dialogue. <em>KBS</em>, <em>329</em>, 114367. (<a href='https://doi.org/10.1016/j.knosys.2025.114367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-Grounded Dialogue (VGD) is a challenging vision-language task aimed at engaging in multi-turn dialogues with humans based on video and audio content. Despite significant progress in improving AI-generated responses has been made, several challenges remain: 1) A significant amount of computing resources and time are required during training; 2) Current dominant approaches, utilizing T5 or GPT2 as base models, exhibit limited ability to understand video and audio features due to their text-based pre-training paradigms; 3) Existing studies have not addressed the robustness of models in real-world scenarios where dialog history is often missing. To address these issues, we propose VPM, a Video-Grounded Dialogue framework employing prompt-based tuning and a masking strategy. Firstly, to reduce computation resources, inspired by prompt learning, we are the first to employ prompt-based tuning in Video-Grounded Dialogue task by using only 20 % of the training set while maintaining proximal accuracy. Secondly, to enhance the model’s understanding of video and audio, we propose a slicing-based visual mapping network, integrating learnable visual prompts and video-audio slice features sequentially through a series of operations. Finally, we put forward an exponentially masking strategy for dialogue history to improve cross-modal understanding and robustness. Extensive experiments validate the effectiveness of our proposed framework, achieving state-of-the-art performance on the AVSD@DSTC7 and AVSD@DSTC8 datasets.},
  archive      = {J_KBS},
  author       = {Feifei Xu and Wang Zhou and Fumiaoyue Jia},
  doi          = {10.1016/j.knosys.2025.114367},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114367},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal prompting and masking strategy for video-grounded dialogue},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization. <em>KBS</em>, <em>329</em>, 114366. (<a href='https://doi.org/10.1016/j.knosys.2025.114366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean Matrix Factorization (BMF) is a widely used method for revealing underlying patterns, called factors, in data. In the paper, we propose a novel data preprocessing method that makes patterns more visible, thus simplifying the overall BMF process. The method first reorders the data to reveal a banded structure. Then, it applies image morphology to enhance this structure by emphasizing important information and suppressing less relevant information. We demonstrate the efficacy of our approach through various experimental evaluations, showing that it effectively modifies the data, resulting in fewer, more interpretable factors. The proposed method also allows using more straightforward and faster BMF algorithms while maintaining high-quality results.},
  archive      = {J_KBS},
  author       = {Klara Brazdilova and Martin Trnecka and Marketa Trneckova},
  doi          = {10.1016/j.knosys.2025.114366},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114366},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114364. (<a href='https://doi.org/10.1016/j.knosys.2025.114364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, electroencephalogram (EEG)-based emotion recognition tasks have attracted considerable interest. Current approaches predominantly rely on single-task learning to extract latent features and construct general models, which can result in overfitting and weak generalization of the model. To resolve this issue, we propose a Multi-Task Self-Supervised Emotion Recognition Method (MTSL-ERM). This method first eliminates the baseline signal from the raw EEG data and maps the processed signals onto a brain electrode map. The processed data is input into MTSL-TimesNet, a novel deep learning model based on TimesNet architecture. The model enables cross-task knowledge sharing and multi-task optimization through spatial jigsaw and contrastive learning tasks. Specifically, the spatial jigsaw task aims to capture spatial patterns across different brain regions, while the contrastive learning task introduces a time-frequency enhancement method and generates instance-level hard negative samples to preserve key temporal relationships in the time series, thereby enhancing the model’s discriminative capability. Through enhancing the resemblance of similar samples and reconstructing time sequences, the model better regularizes feature learning and improves its ability to learn the data’s inherent patterns. Results on the DEAP and DREAMER datasets show MTSL-ERM’s superiority over current approaches. The classification accuracy for arousal and valence in subject-dependent experiments on the DEAP dataset are 96.30 % and 95.92 % , respectively. Meanwhile, on the DREAMER dataset, the accuracies are 90.76 % and 90.66 % , respectively.},
  archive      = {J_KBS},
  author       = {Yongqi Li and Qiuhong Hong and Jibin Yin and Luyao Han and Shoulin Wei and Xiangliang Zhang},
  doi          = {10.1016/j.knosys.2025.114364},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114364},
  shortjournal = {Knowl. Based Syst.},
  title        = {MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplane depth image for view-consistent light field depth estimation. <em>KBS</em>, <em>329</em>, 114363. (<a href='https://doi.org/10.1016/j.knosys.2025.114363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field cameras capture both spatial and angular information of light rays, offering rich data that has made center-view depth estimation a topic of significant interest in recent years. However, the limited flexibility of center-view depth estimation presents substantial challenges for real-world applications, underscoring the need for full-view depth estimation. A primary challenge in this domain is ensuring view consistency. Multiplane Image is a widely used technique for view synthesis, which represents a 3D scene as a series of parallel 2D image planes. Inspired by this structure, we propose a novel approach called Multiplane Depth Image (MDI), which leverages the consistency of density features across multiple views to represent depth information more effectively. To accurately capture the spatial relationships of occluded objects, we introduce a scene-wide hierarchical density update mechanism, which renders depth from the foreground to background, facilitating a more coherent depth representation. Additionally, it corrects visible holes during propagation by focusing on the evident missing regions in the updated density. Finally, we develop an LF full-view depth estimation framework based on these techniques, which enables simultaneous depth prediction across all views. This framework incorporates a comprehensive loss function to supervise depth errors, view consistency, and edge blurring. Experimental results demonstrate that our method predicts high-quality depth maps across all views and achieves state-of-the-art performance compared to center-view methods.},
  archive      = {J_KBS},
  author       = {Tun Wang and Hao Sheng and Rongshan Chen and Ruixuan Cong and Mingyuan Zhao and Da Yang},
  doi          = {10.1016/j.knosys.2025.114363},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114363},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiplane depth image for view-consistent light field depth estimation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing text adversarial example generation using large language models. <em>KBS</em>, <em>329</em>, 114361. (<a href='https://doi.org/10.1016/j.knosys.2025.114361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Natural Language Processing (NLP) are highly based on black-box score-based models that provide only final predictions along with their score. This opacity impedes the comprehension of their internal decision-making processes, complicating the identification of potential weaknesses. A powerful strategy for analyzing model vulnerabilities is the generation of text adversarial examples. These attacks introduce subtle text perturbations that cause victim models to make incorrect predictions while preserving the original semantic meaning. This paper presents a novel method for generating text adversarial examples through Large Language Models (LLMs). The proposed method uses the outstanding text generation capabilities of LLMs to modify the original input text at multiple granularities: character-, word-, and sentence-level. First, sentence-level perturbations are introduced by generating paraphrases with an LLM instruction prompt. Next, further character- and word-level perturbations are introduced to words that most affect predictions using another set of LLM instruction prompts. In particular, vulnerable words are perturbed by replacing them with their synonyms or misspelled variants, or by inserting additional neutral words adjacent to them. Experiments were conducted to assess the proposal’s viability on two sentiment classification tasks: sentence-level reviews and full-length reviews. The proposal demonstrates an advantage over many well-known approaches based on LLMs. It preserves the original semantics to a similar extent, while increasing the deception of victim models by 29–85 % over the best-analyzed state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Natalia Madrueño and Alberto Fernández-Isabel and Rubén R. Fernández and Isaac Martín de Diego},
  doi          = {10.1016/j.knosys.2025.114361},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114361},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing text adversarial example generation using large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews. <em>KBS</em>, <em>329</em>, 114360. (<a href='https://doi.org/10.1016/j.knosys.2025.114360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of fake reviews poses a significant challenge in e-commerce, undermining consumer trust and market integrity. Recently, graph-based approaches have emerged as promising solutions. However, most existing approaches focus primarily on modeling the strong relationships among reviewers, reviews, and products. They often neglect inter-review relationships that are critical for accurate fake review detection. Additionally, their reliance on coarse-grained features limits the detection of subtle, context-aware signals in fake reviews. To address these limitations, we propose a novel method called A spect- L evel S entiment- A ware M ining of I nter- R eview relations ( ALSAMIR ) for effective fake review detection. The method comprises four key components: (1) Aspect-level sentiment-aware graph to aggregate reviews sharing similar aspect-specific sentiments based on uniformity and similarity in aspect-level sentiments. This component helps reveal abnormal spammer behavior patterns; (2) A graph-based oversampling technique to mitigate imbalanced class distribution; (3) A Graph Convolutional Network (GCN) to aggregate semantics of inter-review relation embeddings with strong relations; and (4) An attention mechanism to capture non-linear, higher-order dependencies among latent features. Extensive experiments on publicly available datasets demonstrate that ALSAMIR outperforms state-of-the-art baseline methods.},
  archive      = {J_KBS},
  author       = {Ramadhani A. Duma and Zhendong Niu and Ally S. Nyamawe and Ali Asghar Manjotho and Augustino Deve},
  doi          = {10.1016/j.knosys.2025.114360},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114360},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification. <em>KBS</em>, <em>329</em>, 114359. (<a href='https://doi.org/10.1016/j.knosys.2025.114359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal artery/vein (A/V) classification plays a crucial role in retinal disease screening and diagnosis, serving as a key biomarker for the early detection of various systemic diseases. Despite progress in automatic A/V classification, existing methods often suffer from high computational cost and the impact of irrelevant background information, limiting their practical application. To alleviate these limitations, we propose a hierarchical dynamic size transformer network (DSFormer), which integrates dynamic context-aware (DCA) blocks to improve the ability of the network to capture long-range dependencies while reducing computational complexity. The DCA block, comprising dynamic size self-attention and a dual fusion feed-forward network, is designed to emphasize crucial information in global feature representation, aggregate relevant features, and reduce the quadratic complexity of attention calculations. Additionally, a mixed shallow-deep context bridge integrates shallow and deep features across multiple scales, preserving spatial details at different scales and enhancing feature fusion. Extensive experiments on DRIVE, HRF, and IOSTAR datasets demonstrate that DSFormer outperforms state-of-the-art methods, achieving superior A/V classification performance. Code is available at https://github.com/juzi01-smallju/DSFormer .},
  archive      = {J_KBS},
  author       = {Zeyuan Ju and Chouyu Chen and Zhipeng Liu and Lijun Guo and Zhenyu Lei and Masaaki Omura and Shangce Gao},
  doi          = {10.1016/j.knosys.2025.114359},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114359},
  shortjournal = {Knowl. Based Syst.},
  title        = {DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction. <em>KBS</em>, <em>329</em>, 114358. (<a href='https://doi.org/10.1016/j.knosys.2025.114358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the Legal Judgment Prediction (LJP) task is to predict judgment outcomes based on the fact description texts within legal cases. Existing LJP methods are confined to leveraging knowledge inherent only within the dataset itself, often failing to achieve satisfactory performance when factual descriptions contain text prone to causing erroneous judgments. Consequently, extracting and utilizing external legal knowledge represents a critical challenge that the LJP task urgently needs to overcome. To address the aforementioned issues, this study proposes a legal judgment framework named MLK-LJP, which pioneers the integration of multi-granularity, multi-modal legal knowledge into the LJP task. MLK-LJP comprises two primary modules: Multimodal Legal Knowledge Extraction (MLKE) and Multi-modal Legal Knowledge Fusion (MLKF). Specifically: 1) In the MLKE module, we devise distinct methods to acquire five types of multi-modal legal knowledge: Legal article knowledge, legal event knowledge, legal relation knowledge, quantitative evidence knowledge, and image evidence knowledge. 2) In the MLKF module, we first design a Legal Knowledge Experts Fusion mechanism. This mechanism leverages a Graph Neural Network to capture collaborative signals among the five legal knowledge expert types. Subsequently, the fused multi-modal legal knowledge is allocated across different layers of a Transformer model. This legal knowledge enhanced Transfomer model, combined with LJP prompts, is used to predict the LJP outcomes. Extensive experiments conducted on the three LJP datasets demonstrate the effectiveness and validity of MLK-LJP in comparison to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qihui Zhao and Tianhan Gao and Nan Guo},
  doi          = {10.1016/j.knosys.2025.114358},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114358},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering. <em>KBS</em>, <em>329</em>, 114357. (<a href='https://doi.org/10.1016/j.knosys.2025.114357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised nonnegative matrix factorization (NMF) has attracted considerable attentions in multi-view clustering applications. However, existing semi-supervised methods only adopt either pointwise (i.e., label) or pairwise constraints as supervisory information, without considering taking full advantage of both to further enhance the effectiveness of clustering performance. To this end, a novel dual constraint based semi-supervised nonnegative matrix factorization (DSNMF) method is proposed in this paper for multi-view clustering tasks. Concretely, a new multi-view based dual constraint (MDC) algorithm is developed in DSNMF, which simultaneously utilizes both the pointwise and pairwise supervisory information to promote the performance of multi-view clustering. Specifically, when the limited label information is obtained, the MDC algorithm not only constructs the label regularization to guide the learning of the indicator matrices, but also adopts the hypergraph based pairwise constraint propagation algorithm to construct the graph regularization. Moreover, an alternating multiplicative iterative method is developed for solving the optimization problem of DSNMF, as well as analyzing its convergence, supervisory information effect and computational complexity. Finally, numerous experimental results over five multi-view datasets conclude that DSNMF has better performance than several state-of-the-art semi-supervised multi-view clustering methods.},
  archive      = {J_KBS},
  author       = {Siyuan Peng and Zimeng Huangfu and Wenyun Xie and Zhijing Yang and Feiping Nie},
  doi          = {10.1016/j.knosys.2025.114357},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114357},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with privileged information based on probabilistic tensor factorization. <em>KBS</em>, <em>329</em>, 114356. (<a href='https://doi.org/10.1016/j.knosys.2025.114356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) is a powerful technique for analyzing multi-feature datasets by integrating multiple views to enhance clustering performance. Traditional MVC methods focus mainly on the consensus principle, aiming for consistency across views, but often neglects the complementary information that can be leveraged from different views. In this paper, we propose a novel probabilistic framework for tensor-based MVC that effectively incorporates both the consensus and complementarity principles. Our approach adopts the Learning Using Privileged Information (LUPI) paradigm, where one view is used as the primary learning source while the remaining views serve as privileged information. This enables the views to complement one another, thereby improving clustering results. The proposed framework utilizes probabilistic tensor factorization to capture high-order correlations between views and incorporates a max-margin constraint to enhance robustness. The proposed approach provides an interpretable generative process for tensor factorization within a probabilistic Bayesian context. Notably, our proposed framework is highly flexible and can be naturally integrated with existing anchor graph or deep learning paradigms to construct the view-specific representations. Experimental results on benchmark multi-view datasets demonstrate that our method outperforms existing MVC counterparts.},
  archive      = {J_KBS},
  author       = {Xu Tan and Haidong Gao and Yang Yu},
  doi          = {10.1016/j.knosys.2025.114356},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114356},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view clustering with privileged information based on probabilistic tensor factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedAGHN: Personalized federated learning with attentive graph hypernetworks. <em>KBS</em>, <em>329</em>, 114355. (<a href='https://doi.org/10.1016/j.knosys.2025.114355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of learned collaboration graphs.},
  archive      = {J_KBS},
  author       = {Jiarui Song and Yunheng Shen and Chengbin Hou and Pengyu Wang and Jinbao Wang and Ke Tang and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114355},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114355},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedAGHN: Personalized federated learning with attentive graph hypernetworks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PromptAL: Sample-aware dynamic soft prompts for few-shot active learning. <em>KBS</em>, <em>329</em>, 114354. (<a href='https://doi.org/10.1016/j.knosys.2025.114354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) aims to optimize model training and reduce annotation costs by selecting the most informative samples for labeling. Typically, AL methods rely on the empirical distribution of labeled data to define the decision boundary and perform uncertainty or diversity estimation, subsequently identifying potential high-quality samples. In few-shot scenarios, the empirical distribution often diverges significantly from the target distribution, causing the decision boundary to shift away from its optimal position. However, existing methods overlook the role of unlabeled samples in enhancing the empirical distribution to better align with the target distribution, resulting in a suboptimal decision boundary and the selection of samples that inadequately represent the target distribution. To address this, we propose a hybrid AL framework, termed PromptAL (Sample-Aware Dynamic Soft Prompts for Few-Shot A ctive L earning). This framework accounts for the contribution of each unlabeled data point in aligning the current empirical distribution with the target distribution, thereby optimizing the decision boundary. Specifically, PromptAL first leverages unlabeled data to construct sample-aware dynamic soft prompts that adjust the model’s predictive distribution and decision boundary. Subsequently, based on the adjusted decision boundary, it integrates uncertainty estimation with both global and local diversity to select high-quality samples that more accurately represent the target distribution. Experimental results on six in-domain and three out-of-domain datasets show that PromptAL achieves superior performance over nine baselines. Our codebase is openly accessible.},
  archive      = {J_KBS},
  author       = {Hui Xiang and Jinqiao Shi and Ting Zhang and Xiaojie Zhao and Yong Liu and Yong Ma},
  doi          = {10.1016/j.knosys.2025.114354},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114354},
  shortjournal = {Knowl. Based Syst.},
  title        = {PromptAL: Sample-aware dynamic soft prompts for few-shot active learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection. <em>KBS</em>, <em>329</em>, 114353. (<a href='https://doi.org/10.1016/j.knosys.2025.114353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire is considered one of the major threats to life, property, ecosystems, global warming, and the economy. Recent advancements in convolution neural networks have shown potential for vision-based fire detection; however, several challenges are associated with these techniques, such as limited model performance and high computational complexity. To address these issues, we present an efficient CNN-based model in which EfficientNetV2B0 is employed as a backbone feature extractor and is integrated with a channel and modified spatial attention mechanism to extract deeper spatial details, thereby weighting important features appropriately. The spatial attention is modified by introducing two depth-separable convolution layers to control computational complexity without affecting the performance. The proposed model is assessed on four benchmark datasets in the domain of remote sensing and CCTV-based systems for effective fire detection. Experimental analysis reveals that our model outperforms existing methods in terms of higher accuracy and inference speed, with lower model size and computational burden, indicating its suitability for deployment on resource-constrained devices in real time. To explain the predictions made by the proposed model, we use explainable artificial intelligence methods called Grad-CAM, guided backpropagation, and guided Grad-CAM to provide visualizations by localizing the most salient regions in the image, as emphasized by the attention mechanism.},
  archive      = {J_KBS},
  author       = {Hikmat Yar and Fath U Min Ullah and Zulfiqar Ahmad Khan and Min Je Kim and Sung Wook Baik},
  doi          = {10.1016/j.knosys.2025.114353},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114353},
  shortjournal = {Knowl. Based Syst.},
  title        = {EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training. <em>KBS</em>, <em>329</em>, 114352. (<a href='https://doi.org/10.1016/j.knosys.2025.114352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction is vital for enabling intelligent urban services. However, due to newly deployed infrastructure, developing cities often suffer from data scarcity, which significantly limits the applicability of deep learning models that rely on large volumes of historical data. Moreover, most existing methods focus solely on pairwise spatial interactions, overlooking complex high-order spatial dependencies that are crucial for accurate prediction. To address these challenges, we propose D2MHyper, a cross-city spatio-temporal prediction framework that integrates high-order spatial information through a D ynamic M ulti-scale Hyper graph neural network enhanced by D omain adversarial training. Specifically, we design a shared-private representation learning strategy that captures both city-invariant and city-specific spatial features through inter-city shared and intra-city private hypergraphs. To effectively model complex dependencies, we develop a dynamic multi-scale hypergraph generation module based on learnable incidence matrices, which captures implicit time-varying high-order interactions at multiple granularities. To enhance generalization to data-scarce target cities, a cross-city knowledge transfer module is introduced to transfer global information from source cities. Furthermore, a domain adversarial training strategy is incorporated to enforce the disentanglement of shared and private representations. Extensive experiments on four real-world benchmark datasets consistently validate the effectiveness of D2MHyper, which outperforms state-of-the-art methods in cross-city prediction under data scarcity scenarios.},
  archive      = {J_KBS},
  author       = {Xiaocao Ouyang and Yanhua Li and Jie Zhang and Xin Yang and Yan Yang and Junbo Zhang and Wei Huang and Tianrui Li and Zhiquan Liu},
  doi          = {10.1016/j.knosys.2025.114352},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114352},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing powerful generalization for point cloud registration. <em>KBS</em>, <em>329</em>, 114351. (<a href='https://doi.org/10.1016/j.knosys.2025.114351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning-based point cloud registration have significantly enhanced performance on in-domain data. However, an ideal point cloud registration method should not only excel in same-domain scenarios but also demonstrate robust generalization to achieve the goal of ”train once, apply anywhere.” To this end, existing patch-based methods employ keypoint sampling to identify matchable local 3D patches, thereby improving generalization. Nevertheless, viewpoint variations due to changes in sensor pose, coupled with uneven density and scale issues in point clouds acquired by different sensors, hinder reliable keypoint detection, consequently complicating the identification of matching local 3D patches. To address these challenges, we propose UPG, a point cloud registration method with powerful generalization performance. First, we design an equivariant network architecture based on PPF features to detect keypoints that are rotation-equivariant. Additionally, we present a multi-level patch-wise embedding technique and a joint-level inliers generator to mitigate density and scale variations and improve both registration performance and generalization. Extensive experiments on multiple datasets demonstrate that the proposed UPG achieves state-of-the-art generalization performance.},
  archive      = {J_KBS},
  author       = {Yejun Shou and Haocheng Wang and Lingfeng Shen and Shuai Li and Yanlong Cao},
  doi          = {10.1016/j.knosys.2025.114351},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114351},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unleashing powerful generalization for point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LFE-PointMamba: Point cloud learning via local feature enhancement and state space model. <em>KBS</em>, <em>329</em>, 114350. (<a href='https://doi.org/10.1016/j.knosys.2025.114350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud learning has important application value in autonomous driving and robot navigation. To address the limitations of existing approaches-Transformer’s high quadratic complexity and Mamba’s insufficient local geometric capture, as well as its unidirectional modeling bias conflicting with the non-causal nature of point clouds-this paper proposes LFE-PointMamba. This framework co-optimizes a local feature enhancement module and an improved Mamba architecture, enabling fine-grained geometric perception and efficient global modeling. First, it employs a composite representation that integrates explicit geometric structures and implicit semantic features, alongside a three-level cascading graph convolution for multi-scale context fusion, which enhances local feature capture and provides a more robust semantic basis for global modeling. Second, it replaces causal convolution with non-causal grouping convolution, thereby resolving the conflict between Mamba’s one-way modeling and the non-causal relations inherent in point clouds. At the same time, local and global features are dynamically aggregated through dual-path feature fusion, allowing the model to better balance the capture of local details and modeling of long-range dependencies. Third, utilizing the Hilbert curve’s spatial proximity property and multi-variant dynamic rearrangement, it enables efficient global modeling and spatial topology adaptation without significantly increasing computation. Experiments show that LFE-PointMamba performs well in various downstream tasks. On ModelNet40 and the most challenging PB-T50-RS variant of ScanObjectNN, the classification accuracy achieved 93.0 % and 89.3 %, respectively. In the ShapeNetPart segmentation task, the mean IoU for all instances is 86.1 %. Additionally, the model significantly reduces the number of parameters and computational complexity, offering an efficient solution for point cloud learning.},
  archive      = {J_KBS},
  author       = {Bowen Zhou and Lixin Zhan and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114350},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114350},
  shortjournal = {Knowl. Based Syst.},
  title        = {LFE-PointMamba: Point cloud learning via local feature enhancement and state space model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo. <em>KBS</em>, <em>329</em>, 114349. (<a href='https://doi.org/10.1016/j.knosys.2025.114349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation is a significant topic to alleviate the data sparsity issue in the target domain by leveraging source domain information. However, cross-domain recommendation usually falls into the effect of data silo, since data of the source domain and target domain are generally isolated in different platforms. Intuitively, there are two limits on cross-domain recommendation for data silo. Firstly, data sharing across different domains is difficult, due to the concern of privacy breaching. Secondly, the noise of shared information during cross-platform interactions negatively impacts recommendation in target domain with limited cross-domain knowledge exchange, especially domain-specific noise (the domain information of source domain which is harmful to target domain) on cross-domain recommendation. To tackle these issues, this paper proposes a privacy-aware cross-domain recommendation framework for data silo, known as Parsilo-CDR. Parsilo-CDR introduces the pre-training module and the decoupling regularizers into cross-domain recommendation. The pre-training module is designed to convert raw data into synthetic privacy-preserving data, dynamically balancing privacy and usability based on user privacy preferences. The regularizers further enhance recommendation accuracy by separating user information into domain-common knowledge and domain-specific features, preserving common information while filtering out the domain-specific noise of the shared knowledge. Experimental results validate Parsilo-CDR’s effectiveness in improving recommendation accuracy while overcoming the privacy concern posed by data silo.},
  archive      = {J_KBS},
  author       = {Shanpeng Liu and Buqing Cao and Sheng Lin and Wenyu Zhao and Jianxun Liu and Xiong Li},
  doi          = {10.1016/j.knosys.2025.114349},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114349},
  shortjournal = {Knowl. Based Syst.},
  title        = {Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-matching framework for visual entity linking enhanced by large language models. <em>KBS</em>, <em>329</em>, 114348. (<a href='https://doi.org/10.1016/j.knosys.2025.114348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal entity linking (MEL) accurately links ambiguous textual mentions in a multimodal context to unambiguous entities within a knowledge graph (KG) or knowledge base (KB). It plays a substantial role in various application domains, such as KG construction and semantic retrieval. However, currently, this task primarily aims to enhance the textual semantic level and fails to fully leverage multimodal context to enrich the semantic depth of a KG. We address this limitation by proposing a new task called visual entity linking (VEL), which is similar to traditional MEL. The key difference is that VEL aims to jointly map ambiguous textual mentions and their corresponding visual objects to entities in the KG. To this end, we introduce DMVEL, a dual-matching framework for VEL. (1) The optimal visual object can be obtained by utilizing a multi-instance feature alignment and classification mechanism that fully leverages both coarse-grained (textual and image) and fine-grained (textual and visual object) information. (2) Pre-designed prompt templates are employed to guide large language models (LLMs) in generating entity-focused descriptions for all entities in the KG, minimizing noise from irrelevant information. (3) A dual matching strategy comprising two key components is proposed. The first component entails applying an innovative filter to align ambiguous mentions with entities at the macro level of the overall semantics. The second component is the re-ranker, which performs fine-grained matching between local features and enhanced entity feature representations at the granular level, ensuring global semantic alignment while emphasizing local semantics. Extensive experiments on three public benchmarks demonstrate that the proposed method achieves state-of-the-art performance, paving the way toward an efficient and general solution to utilize LLMs to perform VEL.},
  archive      = {J_KBS},
  author       = {Dijing Pan and Runhe Qiu and Xueqin Jiang and Shaohua Tao},
  doi          = {10.1016/j.knosys.2025.114348},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114348},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-matching framework for visual entity linking enhanced by large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>329</em>, 114347. (<a href='https://doi.org/10.1016/j.knosys.2025.114347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised cross-modal hashing (UCMH) has emerged as a promising solution for scalable multi-modal retrieval without costly annotations. However, existing methods often rely on rigid pairwise contrastive learning and fixed-size neighborhood selection, which suffer from false negatives and semantic noise, respectively—limiting their ability to model complex semantic structures in open-world scenarios. In this paper, we propose a novel framework, I nformation B ottleneck-guided K NN C ontrastive H ashing ( IBKCH ), which introduces a flexible and semantically adaptive contrastive paradigm for UCMH. Specifically, we design an information-aware neighbor sampling strategy that integrates: (1) a Hard-negative and Soft-positive (HN-SP) mechanism to adaptively distinguish informative negatives and softly aggregate latent positives; (2) an information bottleneck loss to retain task-relevant semantics while suppressing redundancy; and (3) an entropy sparsity regularizer to mitigate noisy neighbor interference. Furthermore, we develop an adaptive KNN contrastive learning scheme that unifies intra-modal and inter-modal alignment, enabling robust and discriminative hash code learning. Extensive experiments on three benchmark datasets demonstrate that IBKCH consistently outperforms state-of-the-art methods, especially under noisy or semantically diverse conditions—highlighting its effectiveness and generalizability in real-world UCMH applications.},
  archive      = {J_KBS},
  author       = {Lei Zhu and Zhengchang Yuan and Zeqian Yi and Chengyuan Zhang and Lin Wu and Ying Zhang and Farid Boussaid and Mohammed Bennamoun and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114347},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114347},
  shortjournal = {Knowl. Based Syst.},
  title        = {Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge. <em>KBS</em>, <em>329</em>, 114346. (<a href='https://doi.org/10.1016/j.knosys.2025.114346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of entities and relationships from threat intelligence reports into structured formats, such as cybersecurity knowledge graphs, is essential for automated threat analysis, detection, and mitigation. However, existing joint extraction methods struggle with feature confusion, language ambiguity, noise propagation, and overlapping relations, resulting in low accuracy and poor model performance. This paper presents TIJERE, an innovative joint entity and relation extraction framework that formulates joint extraction as a multisequence labeling representation (MSLR) problem. Specifically, separate sequences are generated for each entity pair. Unlike prior tagging schemes, MSLR integrates expert domain features to enrich positional, contextual, and semantic representations of entities, thereby enhancing feature distinction and classification accuracy. Additionally, TIJERE reduces language ambiguity and enhances domain-specific generalization by leveraging SecureBERT+, a contextual language model fine-tuned on cybersecurity text. This improves both named entity recognition (NER) and relation extraction (RE). This paper also introduces DNRTI-JE, the first publicly available jointly labeled dataset for cybersecurity entity and RE, filling a crucial gap in cyber threat intelligence automation. Empirical evaluations on the curated DNRTI-JE dataset demonstrate that TIJERE achieves state-of-the-art performance, with F1-scores exceeding 0.93 for NER and 0.98 for RE, outperforming existing methods. Together, TIJERE and the standardized benchmarking DNRTI-JE dataset enable high-performance cybersecurity intelligence extraction, with transferable applications in healthcare, finance, and bioinformatics.},
  archive      = {J_KBS},
  author       = {Inoussa Mouiche and Sherif Saad},
  doi          = {10.1016/j.knosys.2025.114346},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114346},
  shortjournal = {Knowl. Based Syst.},
  title        = {TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-cause deconfounding for recommender systems with latent confounders. <em>KBS</em>, <em>329</em>, 114345. (<a href='https://doi.org/10.1016/j.knosys.2025.114345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of modern recommender systems is often undermined by various biases, such as popularity bias, that stem from multi-causal latent confounders inherent in user-item interaction data. However, existing approaches to mitigate these confounding effects often fail to distinguish between user-side and item-side latent confounders, treating them indiscriminately and thereby limiting their effectiveness. To address this issue, a m ulti- c ause d e c on f ounding method for recommender systems with latent confounders (MCDCF) is proposed. MCDCF leverages multi-cause causal effect estimation to learn substitutes for latent confounders at the user and item sides, respectively, using user behaviour data. Specifically, MCDCF treats the multiple items that users interact with and the multiple users that interact with items as treatment variables, and then uses a variational inference model to learn substitutes for latent confounders that influence the estimation of causality between users and user feedback, as well as between items and user feedback. Additionally, this research theoretically demonstrate the soundness of the MCDCF method. Extensive experiments on four real-world datasets demonstrate that the MCDCF method effectively recovers latent confounders related to users and items, reducing bias and thereby improving recommendation accuracy. Compared with the best-performing baselines, MCDCF achieves up to a 38.61 % improvement in recommendation metrics.},
  archive      = {J_KBS},
  author       = {Zhirong Huang and Yuxuan Hu and Debo Cheng and Jiuyong Li and Lin Liu and Guixian Zhang and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114345},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114345},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-cause deconfounding for recommender systems with latent confounders},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological insights into heterogeneous information networks: A systematic review on biological data association. <em>KBS</em>, <em>329</em>, 114344. (<a href='https://doi.org/10.1016/j.knosys.2025.114344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interactions and associations among biomolecules, such as proteins, RNA, metabolites, and genes, form the foundation of the biological process. Systematic analysis of these associations is crucial for uncovering biological mechanisms and enabling more precise bioengineering applications. Given the complexity and diversity of biological entities and their interrelationships, biological networks are inherently heterogeneous, comprising multiple types of nodes and edges. This complexity has driven the growing adoption of heterogeneous information networks (HINs) for biological data association analysis. To the best of our knowledge, the influence of topological properties has been largely disregarded in previous studies, which have focused on the classification and analytical stages of HIN-based biological data association. A search was conducted across five scientific databases, and with the assistance of the guidance for systematic review and PRISMA framework, 53 articles from 2020 to 2024 were selected for analysis. The reviewed articles highlight the crucial roles of topological properties in biological HINs, such as dynamics of random walks, network completion, and path sampling. The miRNA-disease database, HMDDv4.0, is examined as a case study to identify the challenges that result from node degrees imbalances and the ambiguity of meta-paths in biological networks. Two preliminary research frameworks are proposed, one of which on modeling based on HIN and Markov model and the other on the improvement of meta-path induction ability based on this model. These findings can augment the representation capacity of HINs and to assist future research on biological data association analysis based on HINs.},
  archive      = {J_KBS},
  author       = {Di-Wen Kang and Khairunnisa Hasikin and Anis Salwa Mohd Khairuddin and Kai-Qing Zhou},
  doi          = {10.1016/j.knosys.2025.114344},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114344},
  shortjournal = {Knowl. Based Syst.},
  title        = {Topological insights into heterogeneous information networks: A systematic review on biological data association},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCINet: Multimodal context-aware network for RGBT tracking. <em>KBS</em>, <em>329</em>, 114343. (<a href='https://doi.org/10.1016/j.knosys.2025.114343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional RGBT tracking methods rely heavily on visual feature extraction and fusion, but often fail in real-world conditions where visual inputs are degraded by occlusion, illumination changes, or thermal crossover. Additionally, limited dataset scale constrains model generalization. To address these challenges, we propose MCINet, a novel multimodal tracking framework that shifts from vision-centric modeling to a multi-cue collaborative paradigm for enhanced robustness. MCINet integrates historical motion patterns, frequency-domain structure, and language-driven semantics, and employs a staged and decoupled fusion strategy to build a fault-tolerant target representation. Its long-short range attention mechanism captures both temporal dynamics and spatial variations, while a frequency-guided semantic alignment module enhances visual-textual consistency. Crucially, even when visual signals deteriorate, MCINet maintains reliable tracking by leveraging auxiliary cues. This weakly supervised multi-cue design also mitigates the dependence on large-scale labeled data, improving adaptability under modality imbalance or failure. Experimental results on RGBT210, RGBT234, and LasHeR benchmarks demonstrate that MCINet achieves competitive performance in both accuracy and robustness, highlighting its practical potential in challenging real-world environments. The code of the proposed method will be available at https://github.com/ysqidong-dotcon/MCINet .},
  archive      = {J_KBS},
  author       = {Zhao Gao and Dongming Zhou and Zhiyong Wu and Yisong Liu and Qingqing Shan},
  doi          = {10.1016/j.knosys.2025.114343},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114343},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCINet: Multimodal context-aware network for RGBT tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active source-free open-set domain adaptation. <em>KBS</em>, <em>329</em>, 114342. (<a href='https://doi.org/10.1016/j.knosys.2025.114342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free open-set domain adaptation (SFODA) aims to transfer a source model to an unlabeled target domain without explicit class restrictions. However, the SFODA setting faces a challenge in accurately identifying true labels for novel class samples. In this paper, we introduce a new research problem termed Active SFODA (ASFODA). By labeling a small budget of active samples, ASFODA aims to not only identify common class samples but also detect and identify novel class samples. Our investigations reveal that the targeted active samples should exhibit characteristics of abnormal uncertainty and diversity, which are not captured by existing active learning strategies. To remedy these shortcomings, we propose a method known as Diverse Structure Learning (DSL) comprised of Local Diversity Annotation (LDA) and Local Consistency Learning (LCL). Driven by the observation that both common and novel classes tend to form distinct clusters initially, LDA is designed to exploit this structural property. It annotates reliable samples situated in high-density regions of clusters, thereby facilitating the exploration of targeted active samples. Concurrently, LCL tackles the challenge of novel class clusters that may bear the same label but are located disparately by constructing interconnected samples between these clusters. This effectively learns the uncertain novel samples that reside between these clusters. Extensive experiments have validated the effectiveness of DSL, achieving over 15 % enhancements in the context of ASFODA.},
  archive      = {J_KBS},
  author       = {Fan Wang and Zhongyi Han and Hao Sun and Yilong Yin},
  doi          = {10.1016/j.knosys.2025.114342},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114342},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active source-free open-set domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking. <em>KBS</em>, <em>329</em>, 114341. (<a href='https://doi.org/10.1016/j.knosys.2025.114341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art (SOTA) visual tracking techniques have significantly advanced unmanned aerial vehicle (UAV) autonomy. However, their performance remains hindered by on-board camera hardware limitations and prevalent noise and blurring in complex environments, particularly under low-light conditions. Existing low-light enhancement methods frequently introduce overexposure, detail loss, and inadequate noise suppression, further degrading nighttime tracking performance. To address these challenges, we propose a Frequency Domain Prompt-based Denoising Transformer Network (FPDT). Specifically, we design a lightweight Adaptive Frequency Prompt Learning Module (AFP-LM), comprising a Frequency Learning Block (FLB) and a Prompt Block (PB). FLB leverages frequency domain analysis to achieve adaptive separation and interaction between high- and low-frequency features. PB dynamically generates frequency prompts to guide the model in suppressing high-frequency noise, thereby improving the feature extraction capabilities of the tracker. To further strengthen cross-domain feature representation, we introduce a Bidirectional Cross-Fusion Module (BCFM) that enables bidirectional interaction between frequency-domain and spatial-domain information. Additionally, a novel Multi-Dconv Head Transposed Cross-Attention (MDCA) is integrated into the decoder to facilitate multi-scale feature cross-fusion. Extensive experiments demonstrate that FPDT achieves superior performance on multiple UAV nighttime tracking benchmarks.},
  archive      = {J_KBS},
  author       = {Lihua Qi and Haijun Wang and Haoyu Qu and Zihao Su},
  doi          = {10.1016/j.knosys.2025.114341},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114341},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised pretraining model for time series classification based on data preprocessing. <em>KBS</em>, <em>329</em>, 114340. (<a href='https://doi.org/10.1016/j.knosys.2025.114340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, time series have been widely applied and made great progress in the industrial field, including pretrained models. By training models with a large amount of data similar to a certain field and fine-tuning them with a small number of samples, high-precision models, which have great value in the industrial field, can be obtained. However, the current models have two main problems. First, they mostly use supervised classification. Although the accuracy is high, it is not practical for various real-world data with a small number of labeled samples. Second, recent research has mainly focused on contrastive learning, which has higher requirements for data form and regularity. To address these two problems, we propose a self-supervised preprocessing classification model for time series. First, based on the inherent characteristics of the data, we determined the data preprocessing method by judging the properties of the time series. Second, we proposed a self-supervised contrastive learning-based sorting similarity method using coarse similarity in the pretraining stage and our sorting loss function in the fine-tuning stage to improve overall performance. Subsequently, we conducted extensive experiments on 8 different real-world datasets from various domains. The experimental results indicated that the proposed model improved over existing methods by at least 1.1 % , 2.7 % , 6.9 % , and 2 % in terms of ACC, Precision, Recall, and AUPRC, respectively.},
  archive      = {J_KBS},
  author       = {Hanlin Zhang},
  doi          = {10.1016/j.knosys.2025.114340},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114340},
  shortjournal = {Knowl. Based Syst.},
  title        = {A self-supervised pretraining model for time series classification based on data preprocessing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction. <em>KBS</em>, <em>329</em>, 114339. (<a href='https://doi.org/10.1016/j.knosys.2025.114339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction constitutes a fundamental pillar for intelligent transportation systems (ITS) optimization. However, the intricate spatiotemporal correlations within traffic networks pose significant challenges to precise prediction. Existing methods often rely on static relational assumptions, inadequately capturing global temporal correlations and struggling to model the complex trends and periodic patterns present in long-term traffic data. To surmount these limitations, we present a novel d ynamic spatiotemporal g raph c onvolutional n etwork collaborative p re- t raining l earning (DGCN-PTL). Our methodology incorporates a dual stage architecture: initially, a pre-training stage employs masked autoencoder mechanisms coupled with Transformer architectures to effectively extract temporal representations from extensive historical time series data. Subsequently, the prediction stage executes downstream forecasting through several pivotal components. We develop a dynamic graph learning module that adaptively captures evolving spatial interdependencies among network nodes across temporal intervals. Additionally, we integrate gating mechanisms with self-attention operations to augment the model’s capability in characterizing both local and global temporal correlations. A dedicated feature transformation module facilitates channel adaptation and representation refinement. Comprehensive experiments across four real-world datasets substantiate DGCN-PTL’s superior performance against 23 state-of-the-art baselines, achieving remarkable improvements of 5.49 % over the most competitive existing method.},
  archive      = {J_KBS},
  author       = {Haiyang Chi and Yuhuan Lu and Yirong Zhu and Wei Ke and Hanbin Mao},
  doi          = {10.1016/j.knosys.2025.114339},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114339},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new feature selection method using deep learning and graph representation in high-dimensional datasets. <em>KBS</em>, <em>329</em>, 114338. (<a href='https://doi.org/10.1016/j.knosys.2025.114338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in data collection and storage have led to high-dimensional datasets containing numerous, often redundant features, which can negatively affect machine learning algorithms. Feature selection has emerged as a key solution to reduce dataset dimensionality, thereby improving computational efficiency and minimizing overfitting. Traditional feature selection models have limitations in effectively handling high-dimensional data and often overlook intricate relationships between features. Therefore, they may not fully optimize model performance and may be prone to overfitting. To address these challenges, we propose a novel feature selection method based on deep learning that can better capture complex patterns and dependencies among features in high-dimensional data. This method, which uses a deep similarity measure and graph representation, involves three phases. First, the problem is modeled as a graph using the deep similarity measure. Next, primary features are clustered through a community detection model. Finally, the most influential feature within each cluster is selected using node centrality and feature appropriateness measures. Notably, the feature selection step adopts a filter-based approach rather than relying on a learning algorithm, as is common in wrapper models. This design significantly reduces computational complexity and minimizes parameter requirements compared to previous methods. By avoiding reliance on a learning algorithm, the proposed method overcomes challenges such as high computational costs while improving accuracy. Experimental results across multiple datasets demonstrate that the proposed supervised model outperforms state-of-the-art approaches, achieving average improvements of 1.5 % in accuracy and 1.77 %, 1.87 %, and 1.81 % in precision, recall, and F1-score, respectively.},
  archive      = {J_KBS},
  author       = {Matin Chiregi and Mahdi Mazinani and Mitra Mirzarezaee},
  doi          = {10.1016/j.knosys.2025.114338},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114338},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new feature selection method using deep learning and graph representation in high-dimensional datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STCKGE: Continual knowledge graph embedding based on spatial transformation. <em>KBS</em>, <em>329</em>, 114337. (<a href='https://doi.org/10.1016/j.knosys.2025.114337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Continual Knowledge Graph Embedding (CKGE) methods primarily rely on translation-based embedding approaches, leveraging previously acquired knowledge to initialize new facts. While these methods often integrate fine-tuning or continual learning strategies to enhance efficiency, they compromise prediction accuracy and lack support for complex relational structures (e.g., multi-hop relations). To address these limitations, we propose STCKGE, a novel CKGE framework based on spatial transformation. In this framework, entity positions are jointly determined by base position vectors and offset vectors, enabling the model to represent complex relations more effectively while supporting efficient embedding updates for both new and existing knowledge through simple spatial operations, without relying on traditional continual learning techniques. Furthermore, we introduce a bidirectional collaborative update strategy and a balanced embedding method to guide parameter updates, effectively minimizing training costs while improving model accuracy. We comprehensively evaluate our model on seven public datasets and a newly constructed dataset (MULTI) focusing on multi-hop relationships. Experimental results confirm STCKGE’s strong performance in multi-hop relationship learning and prediction accuracy, with an average MRR improvement of 5.4 %. Our code and dataset are available at https://github.com/Wxy13131313131/STCKGE},
  archive      = {J_KBS},
  author       = {Xinyan Wang and Jinshuo Liu and Kaijian Xie and Meng Wang and Cheng Bi and Juan Deng and Donghong Ji and Jeff Z. Pan},
  doi          = {10.1016/j.knosys.2025.114337},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114337},
  shortjournal = {Knowl. Based Syst.},
  title        = {STCKGE: Continual knowledge graph embedding based on spatial transformation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge attention via radial basis functions for temporal knowledge graphs completion. <em>KBS</em>, <em>329</em>, 114336. (<a href='https://doi.org/10.1016/j.knosys.2025.114336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, leveraging Large Language Models (LLMs) for Temporal Knowledge Graph Completion (TKGC) based on given queries and corresponding knowledge sequences has emerged as a novel architecture. The quality of knowledge sequences plays a decisive role in prediction performance. Previous studies directly generated knowledge sequences through manually defined rules, which we term Original Knowledge Sequences (OKS). However, due to the inherent complexity of Temporal Knowledge Graphs (TKGs), OKS tend to be overly cumbersome. In contrast, a comprehensive yet concise knowledge sequence (CCKS) proves crucial. To address this challenge, we propose a knowledge ranking model. First, we use the target training quadruples, along with the OKS corresponding to the head and tail entities in those quadruples, as the training samples for the model. Then, the model considers the global graph structure and temporal context of the knowledge in the OKS using a Relational Graph Convolutional Network (R-GCN) and a Transformer Encoder. Finally, the model uses Knowledge Attention via Radial Basis Functions (KA-RBF) to calculate the overall weighted similarity of all knowledge pairs in the OKS corresponding to the head and tail entities, and simplifies the OKS into CCKS by sorting the weights. We conducted experimental analysis from four different perspectives on five datasets, and the experimental results demonstrated the feasibility and effectiveness of the model. Code is available at https://github.com/foundation000/KA-RBF .},
  archive      = {J_KBS},
  author       = {Enqiang Wang and Jin Liu and Xiao Liu and Bo Huang and Xu Huang},
  doi          = {10.1016/j.knosys.2025.114336},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114336},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge attention via radial basis functions for temporal knowledge graphs completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient feature points detector for full and partial palmprint recognition. <em>KBS</em>, <em>329</em>, 114335. (<a href='https://doi.org/10.1016/j.knosys.2025.114335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, biometrics has witnessed significant advancements in various forensic and security applications for human identification and authentication, with growing interest in effective and discriminative traits such as palmprints. However, practical applications still face challenges, especially when palmprints are collected in portions, such as at crime scenes, or partially acquired for authentication in uncontrolled environments. This paper presents a novel method that incorporates the local binary patterns (LBP) operator into the conventional scale-invariant feature transform (SIFT) algorithm to detect and extract robust keypoint features. While SIFT employs a Gaussian filter to detect keypoints on the palmprint, the proposed method leverages the multi-scale LBP operator to detect stable points prior to computing the corresponding descriptors. Furthermore, an efficient method for filtering keypoints, namely the Self-Geometric Relationship (SGR) filter, is introduced to eliminate potential false matches. The proposed palmprint recognition system, LBPSIFT-SGR, demonstrates competitive performance on full palmprints compared to state-of-the-art techniques and exhibits clear superiority on partial palmprint images, where competing systems fail, across different datasets.},
  archive      = {J_KBS},
  author       = {Fouad Khelifi and Jumma Almaghtuf and Ahmed Bouridane},
  doi          = {10.1016/j.knosys.2025.114335},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114335},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient feature points detector for full and partial palmprint recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection. <em>KBS</em>, <em>329</em>, 114334. (<a href='https://doi.org/10.1016/j.knosys.2025.114334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Camouflaged Object Detection (COD) methods primarily rely on a direct mapping from image to mask. However, due to the inherent semantic and structural gap between the image and its corresponding mask, the learned feature representations often exhibit poor generalization ability. To address this issue, we propose a novel intra-domain dual reconstruction framework, termed InDReCT, which reformulates the image-to-mask prediction as a cross-domain transfer task by simultaneously reconstructing both the input image and its corresponding mask. Within this framework, semantic knowledge is transferred through two reconstruction processes from different domains: image reconstruction (appearance domain) and mask reconstruction (structure domain), and is eventually integrated back into the image-to-mask prediction task. This dual reconstruction mechanism implicitly guides the network to extract hidden appearance semantics from image-to-image reconstruction and explicit structural information from mask-to-mask reconstruction, thereby enhancing the model’s generalization capability. Extensive experiments on three benchmark COD datasets and four downstream tasks demonstrate that InDReCT consistently outperforms state-of-the-art methods in both detection accuracy and generalization ability. Notably, on the widely-used COD10K dataset, InDReCT achieves a Mean E-measure ( E m ) of 95.6 %, surpassing the latest state-of-the-art model CamoDiffusion by 1.6 %. Code and models will be publicly available at: https://github.com/KungFuProgrammerle/InDReCT .},
  archive      = {J_KBS},
  author       = {Guowen Yue and Ge Jiao and Fangyan Wang},
  doi          = {10.1016/j.knosys.2025.114334},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114334},
  shortjournal = {Knowl. Based Syst.},
  title        = {InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm. <em>KBS</em>, <em>329</em>, 114333. (<a href='https://doi.org/10.1016/j.knosys.2025.114333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced breakdown spectroscopy (LIBS) is an analytical method derived from atomic emission spectroscopy that enables the rapid acquisition of chemical composition information from samples. Due to the susceptibility of the LIBS signal to interference from the self-absorption phenomena, sample matrix, and various other factors, the accuracy of both quantitative and qualitative analyses may be compromised without appropriate data mining techniques. In this work, LIBS is integrated with multivariate analysis algorithms to analyze the major element contents of minerals quantitatively. Using a dataset of geological reference samples made available by the ChemCam and SuperCam teams, an innovative modeling approach is introduced that incorporates a bidirectional long short-term memory (Bi-LSTM) network refined through a whale optimization algorithm (WOA). The findings from the dataset indicate that WOA-Bi-LSTM achieves superior accuracy in the quantitative analysis of in-situ and Martian-like LIBS data, surpassing state-of-the-art models. Compared with those of standalone implementations of Bi-LSTM and the partial least squares (PLS) model, the WOA-Bi-LSTM model yielded average reductions in the root mean square error of prediction (RMSEP) by 15.1 %. The method also achieved an average coefficient of determination (R²) of 0.936, reflecting a close alignment between the actual sample measurements and predicted values. The WOA-Bi-LSTM algorithm achieves high accuracy and strong generalizability, its prediction results are better than those of traditional quantitative regression analysis algorithms. The model established in this paper may significantly enhance the quantitative analysis of LIBS spectral data in future Mars exploration missions.},
  archive      = {J_KBS},
  author       = {Junhui Cheng and Meibao Yao and Yan Yu},
  doi          = {10.1016/j.knosys.2025.114333},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114333},
  shortjournal = {Knowl. Based Syst.},
  title        = {An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules. <em>KBS</em>, <em>329</em>, 114332. (<a href='https://doi.org/10.1016/j.knosys.2025.114332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in social networks is crucial for understanding online interactions. Traditional methods often overlook semantic information. This paper introduces a novel framework that significantly enhances community detection accuracy and interpretability by integrating deep semantic representation with formal knowledge and logical reasoning. Our primary contributions are threefold: (1) a synergistic framework combining fine-tuned BERT embeddings, a comprehensive domain-specific ontology, and SWRL rules; (2) an ontology-guided attention mechanism that directs BERT to focus on semantically relevant concepts during fine-tuning; and (3) the application of logical inference via SWRL to refine community boundaries and identify implicit user relationships. We evaluated our framework on diverse datasets from Facebook, Twitter, and Reddit. Experiments demonstrate significant improvements in modularity, NMI, and F1-score over strong baselines, including Louvain, graph attention networks (GAT), and other embedding-based methods. An ablation study confirms the critical contributions of both the ontology-guided attention and the SWRL rules. A case study on Twitter political discussions further illustrates the framework’s ability to uncover semantically coherent communities, influential users, and fine-grained thematic structures. This research establishes a new paradigm for community detection that effectively merges structural analysis with semantic knowledge, delivering more accurate, interpretable, and scalable results.},
  archive      = {J_KBS},
  author       = {Abdelweheb Gueddes and Borhen Louhichi and Mohamed Ali Mahjoub},
  doi          = {10.1016/j.knosys.2025.114332},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114332},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities. <em>KBS</em>, <em>329</em>, 114331. (<a href='https://doi.org/10.1016/j.knosys.2025.114331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge graph, both the structural features and the textual descriptions of entities carry rich content, where structural features can be subdivided into local and global features. However, existing methods find it challenging to fully utilize entities’ structural features and textual descriptions,failing to effectively capture the multiscale interaction between entities and relations.To tackle the problems mentioned, this paper proposes a multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities (MPST). This paper solves the problem of insufficiently rich structural features of entities by learning local and global features of entities through relational graph neural network and Transformer, respectively. Then, this paper proposes a structure-text interaction module to capture the interaction between structural features and textual descriptions to fill the missing semantic information in different structural features. Finally, this paper proposes a collaborative structural decoder that fully integrates entities’ local and global features, effectively capturing the deep connections between different structural features of entities and their relations. Experimental results show that the MPST model achieves MRR scores of 0.387 and 0.509 on the FB15k-237 and WN18RR datasets for the link prediction task, respectively, both surpassing mainstream baseline models and demonstrating its remarkable performance.},
  archive      = {J_KBS},
  author       = {Song Li and Guantong Chen and Liping Zhang and Haipeng Jin and Guanglu Sun},
  doi          = {10.1016/j.knosys.2025.114331},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114331},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view temporal knowledge graph reasoning. <em>KBS</em>, <em>329</em>, 114330. (<a href='https://doi.org/10.1016/j.knosys.2025.114330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) reasoning has attracted significant attention for completing missing knowledge over time. Recent graph neural network (GNN) -based approaches that explore the temporal evolution of graph topological structures from either continuous-time or discrete-time, which offer distinct perspectives on modeling event associations in TKG. Two GNN-based approaches with different perspectives are supposed to be complementary, but effective integration has not been thoroughly explored in existing research. In addition, capturing the repetitive nature of events during GNN message passing poses a challenge in the continuous-time view, while the complex associations among co-occurring events in KG snapshots cannot be efficiently modeled in the discrete-time view. In this paper, we propose a new D ual- v iew TK G r easoning network, namely DV-TKR, which comprehensively models the temporal semantic information by integrating the strengths of both types of graph structure encoding representation for reasoning. In DV-TKR, we decompose the quadruple neighbors of each entity into triples and times in the continuous-time TKG. A time-aware event recurring modeling (TERM) module incorporating multiple attention mechanisms in the continuous-time view, is proposed to effectively distinguish the importance of the same triple at different times. For the discrete-time view, we propose a relation-aware graph evolving modeling (RGEM) module to learn the temporal evolution of entities among successive KG snapshots. The relation-aware graph attention mechanism in the RGEM module captures significant correlations among co-occurring events within the overall KG snapshot. Extensive experimental results on three public datasets demonstrate the superiority of our proposed model compared to the state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Wei Chen and Yuting Wu and Shengnan Guo and Shuhan Wu and Zhishu Jiang and Youfang Lin and Huaiyu Wan},
  doi          = {10.1016/j.knosys.2025.114330},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114330},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-view temporal knowledge graph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification. <em>KBS</em>, <em>329</em>, 114329. (<a href='https://doi.org/10.1016/j.knosys.2025.114329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of internet applications has made Quick Response (QR) codes indispensable in domains such as electronic ticketing, warehouse management, and online payments. However, enhancing QR code visual quality for advertising and branding purposes remains challenging due to the trade-off between aesthetic appeal and scanning reliability, as well as the inefficiency of existing beautification methods. To solve these issues, this research introduces a 2-Dimensional Code Instance Improved Dollmaker Masked Convolutional Network (2DMCN) that integrates segmentation-based region of interest extraction, an Improved Dollmaker Optimization (IDO) algorithm for visual quality enhancement, and a VGG-19-based style transfer module for customizable designs. Codeword adjustment and discrete cosine transform-based embedding are employed to maintain both data integrity and visual quality. Experimental results demonstrate that 2DMCN attains a PSNR of 55.38 dB, SSIM of 0.60, FSIM of 0.70, GMSD of 0.30, noise tolerance of 87.04%, error correction capability of 91.23%, a decoding rate of 0.87, and an average processing time of 6.2 seconds. These results confirm the proposed framework’s greater efficiency, strength, and aesthetic performance associated to prevailing approaches, making it highly suitable for practical, visually appealing, and reliable QR code applications.},
  archive      = {J_KBS},
  author       = {Jyoti Rathi and Surender Kumar Grewal},
  doi          = {10.1016/j.knosys.2025.114329},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114329},
  shortjournal = {Knowl. Based Syst.},
  title        = {An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation. <em>KBS</em>, <em>329</em>, 114327. (<a href='https://doi.org/10.1016/j.knosys.2025.114327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication Recommendation (MR) is a promising research topic which booms diverse applications in healthcare and clinical domains. However, existing methods mainly rely on sequential modelling and static graphs for representation learning, which ignore the dynamic correlations in diverse medical events of a patient’s sequential visits, leading to insufficient global structural exploration on nodes. Additionally, mitigating drug-drug interactions (DDIs) is another issue determining the utility of the MR systems. To address the challenges mentioned above, this paper proposes a novel MR method with the integration of dynamic networks and multi-view drug representations (DNMDR). Specifically, weighted snapshot sequences for dynamic heterogeneous networks are constructed based on discrete visits in sequential EHRs, and all the dynamic networks are jointly trained to capture both structural correlations in diverse medical events and sequential dependency in historical health conditions, aiming to achieve comprehensive patient representations with both semantic features and structural relationships. Moreover, by combining the drug co-occurrences and adverse DDIs in the internal view of drug molecule structure and the interactive view of drug pairs, safe drug representations are available to obtain high-quality medication combination recommendations. Finally, extensive experiments on real-world datasets are conducted for performance evaluation, and the experimental results demonstrate that the proposed DNMDR method outperforms the state-of-the-art baseline models with a large margin on various metrics such as PRAUC, Jaccard, DDI rates and so on. The DNMDR model’s code is available at https://github.com/Liuguanlin818/DNMDR .},
  archive      = {J_KBS},
  author       = {Guanlin Liu and Xiaomei Yu and Zihao Liu and Shucheng Liu and Xue Li and Xingxu Fan and Xiangwei Zheng},
  doi          = {10.1016/j.knosys.2025.114327},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114327},
  shortjournal = {Knowl. Based Syst.},
  title        = {DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operator transfer learning for physics field prediction on complex geometries with limited labelled data. <em>KBS</em>, <em>329</em>, 114326. (<a href='https://doi.org/10.1016/j.knosys.2025.114326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering applications and scientific discoveries involve predicting physics fields, which are usually functions that operate on complex geometries. The recently proposed neural operator, which is a new machine learning paradigm that can directly learn mappings between functions, has succeeded remarkably in solving physics field prediction problems. However, optimal performance of the neural operators relies heavily on a large amount of labelled data. Collecting sufficient labelled data is expensive and time-consuming for most engineering scenarios. However, transfer learning can leverage the knowledge of relevant domains to reduce data requirements. In this study, a novel operator transfer learning framework based on neural operators on Riemannian manifolds (OTL-NORM) is proposed, which can predict physics fields on complex geometries with limited labelled data. OTL-NORM encodes physics fields on complex geometries by the Laplace–Beltrami operator (LBO) eigenfunctions of the geometries. Additionally, a hybrid loss function is constructed using conditional embedding operator discrepancy to solve the conditional distribution adaptation problem. Experiments on multiple physics field prediction problems involving complex 2D and 3D geometries demonstrate that the proposed operator transfer learning method can accurately predict high-dimensional physics fields with only limited labelled data.},
  archive      = {J_KBS},
  author       = {Lin Hu and Lu Chen and Yingguang Li and Xu Liu and Gengxiang Chen and Qinglu Meng and Xiaozhong Hao and Changqing Liu},
  doi          = {10.1016/j.knosys.2025.114326},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114326},
  shortjournal = {Knowl. Based Syst.},
  title        = {Operator transfer learning for physics field prediction on complex geometries with limited labelled data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection. <em>KBS</em>, <em>329</em>, 114325. (<a href='https://doi.org/10.1016/j.knosys.2025.114325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Presentation Attack Detection (FacePAD) is critical for safeguarding face recognition systems against spoofing attempts, including printed photos, video replays, and 3D masks. However, many existing approaches struggle with generalization across diverse attack types and real-world conditions. In this study, we propose a dual-branch deep learning framework that leverages both RGB images and synthetically predicted depth maps to improve anti-spoofing robustness and accuracy. A monocular depth estimation network is used to generate depth cues from a single RGB image, which are then processed in parallel with the original image through two distinct branches of a convolutional neural network. The extracted features-texture-based from RGB and structure-aware from depth-are fused via concatenation to facilitate more discriminative spoof detection. Extensive experiments on four benchmark datasets demonstrate that our method achieves state-of-the-art performance, reducing HTER to 0 % on Replay-Attack and Replay-Mobile, and 1.023 % on ROSE-Youtu. Similarly, an ACER of 0.56 % is achieved on OULU-NPU, while maintaining computational efficiency. Furthermore, we introduce a knowledge distillation scheme to compress the dual-branch model into a lightweight single-branch variant suitable for real-time deployment in mobile authentication, surveillance, and biometric access control scenarios.},
  archive      = {J_KBS},
  author       = {Muhammad Shahid Jabbar and Taha Hasan Masood Siddique and Kejie Huang and Shujaat Khan},
  doi          = {10.1016/j.knosys.2025.114325},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114325},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization. <em>KBS</em>, <em>329</em>, 114324. (<a href='https://doi.org/10.1016/j.knosys.2025.114324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For entity alignment in the knowledge graph, pseudo-label iteration is an important way to address the problem of limited prior aligned entities. It is impacted by the speed, quantity, and accuracy of pseudo-label screening. However, existing methods often have some inadequacy in three factors, leading to the “buckets effect”. In this paper, the TSJO (Two Stages Joint Optimization) model is established for obtaining entity embedding representation. DR-T (Dynamic Relative Threshold) and D-Rot (Datasets Rotation) algorithms are proposed for efficiently screening and utilizing pseudo-labels. Specifically, TSJO simultaneously uses cross-entropy loss and contrastive loss to optimize the embedding layer. The joint execution of two stages allows TSJO to learn more precise entity semantics. DR-T algorithm accurately and rapidly screens a large number of pseudo-labels by comparing a ratio to a dynamically relaxed threshold. This ratio is the result of the second nearest neighbor similarity divided by nearest neighbor similarity. D-Rot algorithm generates a new dataset using prior aligned entities augmented with pseudo-labels. Then it selects either the new dataset or the inital one as the input for TSJO to learn better entity embedding representation. Extensive experiments show that, in contrast to other commonly used pseudo-label methods, the TSJO model achieves a comprehensive optimum in the speed, quantity, and accuracy of pseudo-label screening, and delivers the best entity alignment performance, demonstrating competitive performance.},
  archive      = {J_KBS},
  author       = {Haoran Xu and Wei Huang and Wenjing Xie and Le Yin and Yixin Zhao},
  doi          = {10.1016/j.knosys.2025.114324},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114324},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation. <em>KBS</em>, <em>329</em>, 114323. (<a href='https://doi.org/10.1016/j.knosys.2025.114323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Foot Ulcers (DFUs) are a severe complication of diabetes, often leading to lower limb amputation and increased patient morbidity. Accurate segmentation of DFUs is essential for effective wound assessment, treatment planning, and healing monitoring. This paper introduces a novel deep learning framework, DFUSegNet, for accurate segmentation of DFUs and other chronic wounds. The proposed architecture seamlessly integrates a learnable image preprocessor (LIP) to enhance input quality and a hierarchical encoder for capturing multiscale and multiresolution wound features. A boundary enhancer (BE) sharpens ulcer edges, while the multiresolution positional attention (MPA) module emphasizes critical spatial details. Extracted features by the encoder are refined through a local-global feature aggregation (LGFA) module before being processed by a dual-mode attention-guided hierarchical decoder, ensuring precise and robust segmentation. Extensive quantitative and qualitative evaluations on the DFUC, FUSeg, and AZH Wound datasets showcase the superior performance of DFUSegNet, achieving state-of-the-art IoU/F1-scores (in %) of 60.06/70.78 on DFUC, 79.06/85.76 on FUSeg, and 81.21/87.28 on AZH. Interpretability analysis further highlights the effectiveness of our MPA, BE modules, and dual-mode attention-guided decoder in progressively extracting intricate ulcer features. Despite encountering some anomalies in the datasets, DFUSegNet demonstrates immense potential for integration into knowledge-based systems within clinical workflows and telemedicine, enabling automated, high-precision DFU segmentation to support early diagnosis and effective wound management. While promising results validate its effectiveness, successful clinical deployment will require large, accurately annotated DFU datasets, laying the foundation for future advancements in automated DFU segmentation. Source code: https://github.com/tushartalukder/DFUSegNet},
  archive      = {J_KBS},
  author       = {Tushar Talukder Showrav and Muhammad Zubair Hasan and Md Kamrul Hasan},
  doi          = {10.1016/j.knosys.2025.114323},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114323},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance. <em>KBS</em>, <em>329</em>, 114322. (<a href='https://doi.org/10.1016/j.knosys.2025.114322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network security is increasingly critical with the growth of networks and sophisticated cyberattacks. Existing Intrusion Detection Systems (IDS) face slow training, poor scalability with high-dimensional data, and overfitting, especially in IoT and smart infrastructures. This paper presents an Enhanced Network Security approach through an Intelligent Deep Learning-Based IDS with Optimized Performance (ENS-IDS-HGWNN). Data from CICIDS-2017 and WSN-DS datasets undergo cleaning, missing value handling, and redundancy removal using Neural Correlation Integrated Adaptive Point Process Filtering (NCIAPPF). SMOTE balances datasets, while Weighted Leader Search Algorithm (WLSA) selects features. Intrusion detection and classification is done by using Hyperbolic Graph Wavelet Neural Network (HGWNN), and is optimized by Triangulation Topology Aggregation Optimizer (TTAO). ENS-IDS-HGWNN achieves 98.12 % accuracy for Brute Force (CICIDS-2017) and 96.72 % for Blackhole (WSN-DS), outperforming baselines in precision, recall, F-score, ROC-AUC, MCC, and computational efficiency across all attack categories.},
  archive      = {J_KBS},
  author       = {Siva Subramanian R and Nithya T and Sudha K and Dinesh M G},
  doi          = {10.1016/j.knosys.2025.114322},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114322},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning. <em>KBS</em>, <em>329</em>, 114321. (<a href='https://doi.org/10.1016/j.knosys.2025.114321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D semantic segmentation has shown notable progress by leveraging the complementary characteristics of RGB and depth modalities, substantially enhancing scene understanding. However, existing approaches often depend on dual-encoder architectures, leading to high computational overhead and limited inference efficiency. To overcome these limitations, we propose an Efficient Cross-Modal Reparameterization Network (ECMRN), which integrates prompt tuning with dynamic frequency-domain structural reparameterization for efficient and accurate segmentation. Specifically, we introduce a hybrid RGB-D block that combines a frozen attention branch and a trainable CNN branch, facilitating collaborative modeling of global context and local structures. A Cross-layer Prompt Adapter (CPA) is devised to bridge the modality gap via learnable attention fusion and token interaction, enabling effective semantic alignment across modalities. Moreover, we propose a unified structural reparameterization framework, instantiated in both the stem module and the Dynamic Frequency-domain Reparameterization Module (DFRM), which facilitates expressive multi-branch feature learning during training and is equivalently transformed into a compact single-branch structure at inference for efficient deployment. Additionally, a Multi-scale Feature Optimization Module (MFOM) applies grouped attention at multiple scales to further enhance feature representation. Extensive experiments demonstrate that ECMRN achieves competitive performance in RGB-D semantic segmentation with nearly half the parameters of state-of-the-art methods and also sets new benchmarks on RGB-D salient object detection. The code will be made available at https://github.com/alkaidzc/ECMRN .},
  archive      = {J_KBS},
  author       = {Di Jia and Chen Zhao and Huilun Song and Huaxiu Zhang and Wei Li},
  doi          = {10.1016/j.knosys.2025.114321},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114321},
  shortjournal = {Knowl. Based Syst.},
  title        = {ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSAE: Hierarchical structure augment embedding for various knowledge graph completion. <em>KBS</em>, <em>329</em>, 114320. (<a href='https://doi.org/10.1016/j.knosys.2025.114320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Completion (KGC) addresses the task of reasoning over existing facts to predict missing relationships, serving as a fundamental component for downstream applications including question answering systems and personalized recommendation engines. Over the years, the KGC field has evolved into specialized tasks, including static KGC, temporal KGC, hyper KGC, and few-shot KGC, each requiring specialized methodologies. Although previous methods have utilized Generative Language Models (GLMs) to theoretically support multi task compatibility, their performance remains suboptimal compared to task-specific models. This limitation stems from their inability to effectively integrate structural and textual information, leading to a fine-grained structure-text gap. To address this challenge, we propose HSAE, a novel two-stage framework that hierarchically aligns structural and textual modalities, first at the coarse-grained entity level and then at the fine-grained token level. In the first stage, Entity-Level Structure Augment, we transform structural embeddings into tree-shaped entity classifications, enriching entity representations with explicit structural information. This augmentation provides global structural guidance during beam search, ensuring that generated sequences adhere to the underlying knowledge graph topology. In the second stage, Token-Level Structure Augment, we introduce a cross-modal alignment module that dynamically fuses structural embeddings with token-level predictions. By aligning structural and textual representations at the token level, HSAE ensures that each decoding step is informed by both structural and textual coherence. Experiments on eight benchmarks demonstrate that HSAE outperforms competitive baselines across multiple KGC tasks. The data and code are released at https://anonymous.4open.science/r/HSAE-main/README.md .},
  archive      = {J_KBS},
  author       = {Yifan Xue and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
  doi          = {10.1016/j.knosys.2025.114320},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114320},
  shortjournal = {Knowl. Based Syst.},
  title        = {HSAE: Hierarchical structure augment embedding for various knowledge graph completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system. <em>KBS</em>, <em>329</em>, 114319. (<a href='https://doi.org/10.1016/j.knosys.2025.114319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation System (RS) plays a vital role in supporting decision-making processes, particularly in the context of online learning, which has gained substantial reputation in recent years. Although various advanced techniques have been proposed for RS, many still fall short of achieving optimal performance due to limitations in handling complex data formats and preprocessing challenges. Existing RS techniques often struggle with managing missing values, ensuring consistent data formatting, and capturing complex non-linear relationships within the input data. To address these issues, this work proposes an intelligent deep learning-based recommendation approach. First, input text data is collected from benchmark datasets and undergoes comprehensive pre-processing. The processed data is then passed through Multi-scale Bidirectional Encoder Representations from Transformers (BERT) and Transformer models to extract complementary and contextualized features. These features are effectively fused using a Weighted Feature Fusion (WFF) technique, where the optimal weight factor is determined by the Modified Alpha in Single Candidate Optimizer (MASCO) . The performance of the proposed model is evaluated across three benchmark datasets. The accuracy of the DCRNN framework reaches 94.4 %, 95.35 %, and 94.82 % for Datasets 1, 2, and 3, indicating consistent and high-performance results. The experimental results demonstrate that the proposed deep learning-based RS significantly outperforms existing techniques, offering improved recommendation accuracy and robustness, particularly in online learning applications.},
  archive      = {J_KBS},
  author       = {Balaji V and Anupam Das and Vishnupriya G and Safak Kayikci},
  doi          = {10.1016/j.knosys.2025.114319},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114319},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114318. (<a href='https://doi.org/10.1016/j.knosys.2025.114318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subject-independent Electroencephalogram (EEG) emotion recognition has underperformed due to significant disparities among subjects. Domain adaptation (DA) is a common solution, but traditional methods require access to target domain data, raising privacy concerns. Source-free domain adaptation offers a viable solution, however, researches on it remains unexplored. Moreover, existing methods overlooked the complementary information across source domains. To overcome this challenge, we focus on exploring the inter-domain complementarity. Our core insight is that higher-confidence predictions from source models indicate regions closer to the target domain’s distribution. Based upon, we propose Pro xy- D omain- G uiding ( ProDG ) strategy, which pioneers confidence-guidance to achieve privacy-preserving recognition. First, we propose a Proxy Guiding theory validating that predictions of source models with higher confidence exhibit closer distributional proximity to the target domain. Then, we propose two modules: Pr oxy M utual I nformation Alignment ( PrMI ) constructs a proxy domain by aggregating high-confidence predictions from source models, approximating the target-overlapping region, then each source model is aligned with proxy domain via mutual information maximization; Pr oxy P seudo- L abel Alignment ( PrPL ) refines clustering-based pseudo-labels using cross source confidence evaluation, enhancing supervised loss quality. The whole training process utilize only the source domain model and target data, with source data being inaccessible, ensuring privacy-preserving. Our method attains state-of-the-art accuracy on DEAP(65.3 %), SEED (85.9 %) and SEED-IV (70.4 %), surpassing privacy-preserving methods by a large margin and rivaling non-privacy-preserving approaches. ProDG validates the efficacy of confidence-based proxy guiding in multi-source-free domain adaptation. This work was conducted at the College of Electronics and Information Engineering, Sichuan University in May 2025.},
  archive      = {J_KBS},
  author       = {Bingtao Zhou and Mian Xiang and Qian Ning},
  doi          = {10.1016/j.knosys.2025.114318},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114318},
  shortjournal = {Knowl. Based Syst.},
  title        = {ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network. <em>KBS</em>, <em>329</em>, 114317. (<a href='https://doi.org/10.1016/j.knosys.2025.114317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based surveillance in smart Internet of Things (IoT) systems uses object detection and classification to enhance security and monitoring by processing data in the cloud, providing scalability and analysis. In this manuscript, Multi-Target Object Detection and Classification for Cloud-Based Surveillance in Smart Internet of Things using Multi-Component Attention Graph Convolutional Neural Network (MTO-IoT-MCAGCNN) is proposed. Firstly, input images are collected from PASCAL VOC Dataset. The input imagesare fed to pre-processing using Interaction-Aware Labled Multi-Bernoulli Filter (IALMBF)to remove noise from the collected input images; then the Pre-processed images are fed to feature extraction using Spatial-Temporal Knowledge-Embedded Transform (STKET)to extract Semantic features such as colour, shape and object. Then, the extracted images are fed to Multi-Component Attention Graph Convolutional Neural Network (MAGCNN) for object detection and classification. In general, MAGCNN does not express adapting optimization strategies to establish the ideal variables to guarantee the detection and classification the collected image. Hence, the Brown Bear Optimization Algorithm (BBOA) is used to optimize the weight parameter of MAGCNNused to classify the collected images. Then the proposed MTO-IoT-MCAGCNNis implemented in Python. Performance of the MTO-IoT-MCAGCNNapproach attains higher Specificity of 99.12 %, higher Accuracy of 99.55 % and higher (Mean Average Precision (maP)of 99.1 % when analysed through existing techniques like Research of multi-object detection and tracking using machine learning based on knowledge for video surveillance system(MODT-SS-CNN), a feature‐optimized Faster regional convolutional neural network for complex background objects detection (CBOD-RCNN) and deep-learning-enhanced multimarket detection for end–edge–cloud surveillance in smart IoT (MD- IoT-YONet),methods respectively.},
  archive      = {J_KBS},
  author       = {Rajasekaran A and T. Dinesh Kumar and M.A. Archana and S. Malathi and K. Saraswathi},
  doi          = {10.1016/j.knosys.2025.114317},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114317},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided distribution alignment for cross-domain few-shot learning. <em>KBS</em>, <em>329</em>, 114316. (<a href='https://doi.org/10.1016/j.knosys.2025.114316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot learning (CD-FSL) aims to recognize novel categories with minimal labeled samples in target domains that differ from source domains. However, difficulty in obtaining valid domain bias guidance leads to negative transfer challenges because the target domain samples are unknown during source domain training. Inspired by human reliance on prior knowledge when adapting to new domains, we propose a knowledge-guided distribution alignment network (KDANet). In contrast to earlier CD-FSL approaches that primarily focus on visual alignment alone, KDANet incorporates textual priors in both the training and adaptation stages, thereby enhancing domain transferability. Specifically, KDANet integrates textual priors as knowledge guidance for visual representation learning during pretraining in the source domain with sufficient samples to establish an initial learning foundation. To tackle the scarcity of target domain samples, available samples and construct pseudo-episodes are expanded through critical region detection. Leveraging the pretrained model and pseudo-episodes, a two-stage progressive finetuning method is employed to refine feature extraction and calibrate prototypes for target domain tasks, with prior knowledge guiding the learning process continuously. Moreover, adaptive distribution alignment is proposed throughout cross-domain training and finetuning to suppress distribution bias interference by utilizing multi-source domain alignment and triplet supervision. Quantitative and qualitative experiments demonstrate the superior performance of proposed method, particularly in challenging 1-shot tasks. Under the CD-FSL benchmark, proposed method achieves an average accuracy improvement of 3 % across all target domains, outperforming state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiale Chen and Feng Xu and Xin Lyu and Tao Zeng and Xin Li and Shangjing Chen},
  doi          = {10.1016/j.knosys.2025.114316},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114316},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-guided distribution alignment for cross-domain few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction. <em>KBS</em>, <em>329</em>, 114315. (<a href='https://doi.org/10.1016/j.knosys.2025.114315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease, a progressive and debilitating neurodegenerative disorder, presents considerable challenges in early diagnosis and treatment planning. Given the sensitive nature of patient health records and the diversity of medical data sources, there is a pressing need for diagnostic tools that are not only accurate and robust but also privacy-preserving. Federated learning offers a promising solution by enabling collaborative model training across multiple decentralized institutions, allowing each to contribute to a shared global model without exposing raw data. This approach safeguards patient confidentiality while ensuring compliance with data protection regulations. To further enhance the efficiency and effectiveness of federated systems, this research integrates multi-criteria decision-making methods into the federated learning framework. The use of these facilitates informed client selection, balanced model aggregation, and the prioritization of key factors such as accuracy, data distribution, volume, and computational capacity. This integration enables performance-driven decision-making under heterogeneous data conditions and enhances the scalability and personalization of collaborative learning. Various machine learning algorithms are incorporated within this federated decision-making framework to evaluate client contributions, optimize model training, and ensure the selection of top-performing clients based on multiple criteria. These algorithms play a crucial role in constructing accurate, robust and privacy-preserving models across distributed data sources, enabling effective collaboration without compromising data privacy. Together, federated learning and decision-making methods form a powerful paradigm for building intelligent, secure and high-performance diagnostic systems tailored to the complexities of Alzheimer’s disease. This research study provides an in-depth exploration of the working mechanism of federated learning combined with decision-making method. It includes the evaluation metrics calculated by these methods, a comparison of various machine learning algorithms utilized in this federated learning decision-making framework, as well as a discussion of their limitations and future directions.},
  archive      = {J_KBS},
  author       = {Maheen Sultan and Muhammad Akram and Shaista Habib and Cengiz Kahraman},
  doi          = {10.1016/j.knosys.2025.114315},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114315},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Question answering over spatio-temporal knowledge graph. <em>KBS</em>, <em>329</em>, 114314. (<a href='https://doi.org/10.1016/j.knosys.2025.114314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal knowledge graphs (STKGs) enhance traditional KGs by integrating temporal and spatial annotations, enabling precise reasoning over questions with spatio-temporal dependencies. Despite their potential, research on spatio-temporal knowledge graph question answering (STKGQA) remains limited. This is primarily due to the lack of datasets that simultaneously contain spatio-temporal information, as well as methods capable of handling implicit spatio-temporal reasoning. To bridge this gap, we introduce the spatio-temporal question answering dataset (STQAD), the first comprehensive benchmark comprising 10,000 natural language questions that require both temporal and spatial reasoning. STQAD is constructed with real-world facts containing spatio-temporal information, ensuring that the dataset reflects practical scenarios. Furthermore, our experiments reveal that existing KGQA methods underperform on STQAD, primarily due to their inability to model spatio-temporal interactions. To address this, we propose the spatio-temporal complex question answering (STCQA) method, which jointly embeds temporal and spatial features into KG representations and dynamically filters answers through constraint-aware reasoning. STCQA achieves state-of-the-art performance, significantly outperforming existing baselines. Our work not only provides a valuable resource for future research but also advances the field by offering a robust baseline for answering complex spatio-temporal questions.},
  archive      = {J_KBS},
  author       = {Xinbang Dai and Huiying Li and Nan Hu and Yongrui Chen and Rihui Jin and Huikang Hu and Guilin Qi},
  doi          = {10.1016/j.knosys.2025.114314},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114314},
  shortjournal = {Knowl. Based Syst.},
  title        = {Question answering over spatio-temporal knowledge graph},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images. <em>KBS</em>, <em>329</em>, 114313. (<a href='https://doi.org/10.1016/j.knosys.2025.114313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image fusion is designed to combine the complementary features of different image modalities, thereby improving data quality. It has numerous applications in medical imaging, industrial inspection, and autonomous driving. To explore detailed information within image scenes in detail and effectively integrate complementary information from images, we propose a universal multimodal image fusion algorithm based on the CNN-Transformer iterative feature fusion (CTIUFuse). We improve a dual-branch CNN-Transformer encoder by incorporating the Residual Gradient Dense Block (RGDB) and a lightweight attention mechanism, which collaboratively extract fine-grained and global features while reducing computational cost. Furthermore, we present an iterative feature fusion network that progressively refines cross-modal complementary features. For self-supervised training, we derive a dynamic texture loss function that adaptively adjusts weights based on the importance of information in each modality, thereby ensuring optimal fusion performance. The experimental results reveal that CTIUFuse achieves superior performance on six datasets composed of infrared-visible and medical images. It outperforms existing methods in terms of both fusion accuracy and computational efficiency, significantly enhancing downstream infrared-visible object detection tasks and demonstrating strong generalizability. The source code of the CTIUFuse algorithm is available at https://github.com/L1nCyk/CTIUFuse .},
  archive      = {J_KBS},
  author       = {Chenyoukang Lin and Tao Liu and Zixi Wang and Bo Wang},
  doi          = {10.1016/j.knosys.2025.114313},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114313},
  shortjournal = {Knowl. Based Syst.},
  title        = {CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting. <em>KBS</em>, <em>329</em>, 114312. (<a href='https://doi.org/10.1016/j.knosys.2025.114312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is pivotal in both academic research and practical applications across diverse industries. However, effectively leveraging external factors to enhance forecasting performance remains a significant challenge, necessitating further investigation. Current frameworks exhibit notable limitations in modeling the impact of external factors on both intrinsic and extrinsic correlations within time series data. To address these challenges, we propose a novel mechanism that systematically integrates contextual information from external factors with temporal dependencies, while maintaining compatibility with various encoder-decoder algorithms. This approach enables backbone models to embed dependent patterns from external factors across multiple correlated time series, effectively capturing their influence on both prior and adjacent timesteps. Our study centered on the application of time series forecasting for demand prediction, as sales forecasting poses unique challenges stemming from the complexity and variability of market conditions influenced by numerous external factors. We conducted extensive experiments on three real-world retail datasets, showcasing the substantial performance enhancement of backbone models when integrated with our proposed contextual embedding mechanism. Specifically, our approach achieves improvements of up to 26 % in Mean Squared Error (MSE) and 15 % in Mean Absolute Error (MAE) compared to both the original backbone models and other state-of-the-art (SOTA) baseline methods. The proposed mechanism is also evaluated on Weather and Energy datasets to further verify its generalization capability. We will release the source codes and experimental datasets at our GitHub 1 .},
  archive      = {J_KBS},
  author       = {Hoang Nguyen Nguyen and Wei Xiang and Lianhua Chi and Mike Da Gama and Sanjeevani Avashi and Michael Treloar and Lu Yu},
  doi          = {10.1016/j.knosys.2025.114312},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114312},
  shortjournal = {Knowl. Based Syst.},
  title        = {ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VCE: Visual concept embedding for open-set fine-grained image retrieval. <em>KBS</em>, <em>329</em>, 114311. (<a href='https://doi.org/10.1016/j.knosys.2025.114311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image retrieval (FGIR) aims to accurately distinguish highly similar subclasses from a large collection of visually similar images. In open-set scenarios, local features of unseen categories often exhibit significant overlap with those of seen categories. Therefore, the model must extract transferable local semantics from seen classes to enable compositional reasoning. However, existing approaches primarily rely on holistic feature association within seen categories, resulting in highly entangled representations that hinder generalization to novel classes in open-set conditions. To address this, we propose a FGIR framework named Visual Concept Embedding (VCE), inspired by the human cognitive process where objects are decomposed into distinct concepts to achieve a better understanding. The VCE consists of two key components: Visual Concept Decoupling (VCD) and Concept-Enhanced Representation (CER). Specifically, the VCD represents objects as a composition of multiple independent concepts by leveraging a set of learnable concept vectors and a cross-attention mechanism. This decoupling allows the model to independently analyze the discriminability of each local feature, rather than relying on entangled global representations. Furthermore, the CER models the structural relationships among concepts, enabling the model to precisely attend to critical regions that reflect fine-grained differences and ensuring alignment between feature dimensions and discriminative local semantics. Extensive experiments demonstrate that VCE effectively learns different visual concepts and validates its effectiveness across three datasets.},
  archive      = {J_KBS},
  author       = {Yuetian Wang and Shuo Ye and Wenjin Hou and Shuhuang Chen},
  doi          = {10.1016/j.knosys.2025.114311},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114311},
  shortjournal = {Knowl. Based Syst.},
  title        = {VCE: Visual concept embedding for open-set fine-grained image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dyslexia intervention through an adaptive sequential recommender system. <em>KBS</em>, <em>329</em>, 114309. (<a href='https://doi.org/10.1016/j.knosys.2025.114309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children with dyslexia face significant learning difficulties that require personalized and intensive interventions. Although computer-based support programs exist, they often fail to adapt to the unique needs of each child, representing a major challenge in the field of educational intervention. This article presents a new adaptive sequential guidance system for personalized dyslexia intervention that addresses these limitations. The proposed methodology incorporates several key innovations: (1) a dynamic word generator that creates phonetically modified words and pseudowords from seed words, (2) a three-dimensional matrix structure ( E , W ,and F ) to effectively manage word difficulty and user performance, and (3) a recommendation algorithm based on matrix factorization. To mitigate cold-start problems, the system implements a heuristic initiation process and uses an extension technique to detect difficulties in specific derived words. Additionally, the concept of “virtual children” generated from real data and based on Bayesian Knowledge Tracking is introduced, allowing thorough testing and optimization of the system prior to its actual implementation. The evaluation of the system demonstrates three main results: (1) the use of heat maps and 3D visualization of the E matrix allows identifying specific areas of difficulty for each user, facilitating more targeted interventions; (2) extensive testing confirms the robustness of the system to reduce error rates in multiple trials; and (3) a parametric study evidences the ability of the system to adapt through adjustable parameters, keeping each child in his or her optimal learning zone.},
  archive      = {J_KBS},
  author       = {J. Ignacio Mateo Trujillo and Ignacio Rodríguez-Rodríguez and Diego Castillo-Barnes and Andrés Ortiz and Auxiliadora Sánchez and Juan L. Luque},
  doi          = {10.1016/j.knosys.2025.114309},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114309},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing dyslexia intervention through an adaptive sequential recommender system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-free prototype guided representation calibration under label noise. <em>KBS</em>, <em>329</em>, 114308. (<a href='https://doi.org/10.1016/j.knosys.2025.114308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets inevitably suffer from label noise, which misleads deep networks and disrupts the underlying representation structures, resulting in poor generalization. As category representatives, prototypes are widely adopted in learning with noisy labels due to their strong semantic expressiveness. Existing works typically obtain prototypes by averaging representations within each class and update them during training. However, prototypes achieved by such label-dependent procedures may deviate from their optimal positions under noisy labels, thereby failing to guide the model towards stable and accurate predictions. In this paper, to mitigate noise-induced prototype deviation, and further learn more robust representations, we propose a novel method called Noise-Free Prototype guided Representation Calibration (NFPRC), which introduces fundamentally different, label-independent prototype construction and utilization. Specifically, NFPRC first leverages unsupervised contrastive learning to extract representations and then applies clustering to assign the nearest prototype to each instance. These noise-free prototypes are then fixed to impose directional constraints and guide robust representation learning. Additionally, NFPRC introduces a dynamic weighting strategy that assigns higher importance to instances with larger cross-entropy losses, thereby prioritizing potentially mislabeled instances and enhancing the model’s adaptability to more complex noisy label scenarios. Extensive experiments on both synthetic and real-world noisy label benchmarks validate the effectiveness of our method in improving representation learning and combating noisy labels. The code is available at: https://github.com/Huiting-hub/NFPRC .},
  archive      = {J_KBS},
  author       = {Huiting Yuan and Tingjin Luo and Xinghao Wu and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114308},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114308},
  shortjournal = {Knowl. Based Syst.},
  title        = {Noise-free prototype guided representation calibration under label noise},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-powered explanations: Unraveling recommendations through subgraph reasoning. <em>KBS</em>, <em>329</em>, 114307. (<a href='https://doi.org/10.1016/j.knosys.2025.114307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems (RecSys) are pivotal in enhancing user experiences across various web applications by analyzing the complicated relationships between users and items. An explainable RecSys is crucial for the product development and subsequent decision-making. Knowledge graphs (KGs) have been widely used to enhance the performance of RecSys. However, KGs are known to be noisy and incomplete, making it hard to provide reliable explanations for recommendation results. We introduce a novel recommender that synergies Large Language Models (LLMs) and KGs to enhance the recommendation and provide interpretable results. We first harness the power of LLMs to augment KG reconstruction, where LLMs analyze and extract information from user reviews to generate new triples. In this way, we can enrich KGs with explainable paths that express user preferences. In addition, we introduce a novel subgraph reasoning module that effectively measures the importance of nodes and discovers reasoning for recommendation. Finally, these reasoning paths are fed into the LLMs to generate interpretable explanations of the recommendation results. Our approach significantly enhances both the effectiveness and interpretability of RecSys, especially in cross-selling scenarios where traditional methods falter. The effectiveness of our approach has been rigorously tested on four open real-world datasets, with our methods demonstrating a superior performance over contemporary state-of-the-art techniques by an average improvement of 12 %. The application of our model in a cross-selling RecSys for a multinational engineering and technology company further underscores its practical utility and potential to redefine recommendation practices through improved accuracy and user trust.},
  archive      = {J_KBS},
  author       = {Guangsi Shi and Xiaofeng Deng and Linhao Luo and Lijuan Xia and Lei Bao and Bei Ye and Fei Du and Shirui Pan and Yuxiao Li},
  doi          = {10.1016/j.knosys.2025.114307},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114307},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-powered explanations: Unraveling recommendations through subgraph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QC2-VQG: Question context complement for visual question generation. <em>KBS</em>, <em>329</em>, 114306. (<a href='https://doi.org/10.1016/j.knosys.2025.114306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Generation (VQG) is a critical vision-language understanding task that involves generating human-like questions from given images and associated textual information. Most of the existing works are answer-aware and focus on modeling the complex relationship between the answer and its relevant object regions. However, we observe that these approaches disregard question context (e.g., the image description and visual entities) which is indispensable for a large number of questions, making it difficult to generate the desired questions. To address this issue, we present a novel strategy to generate questions by supplementing image-related question context. The key motivation is that the question context can bridge the task gap between visual understanding and question generation. Thus, we propose QC 2 -VQG which can automatically capture the visual information and convert it to the textual question context for the answer-aware QG. Extensive experiments on two widely used datasets demonstrate that QC 2 -VQG outperforms SOTA methods across various evaluation metrics, highlighting its effectiveness in generating high-quality, contextually grounded questions.},
  archive      = {J_KBS},
  author       = {Ying Zhang and Xubo Liu and Ziyu Lu and Wenya Guo and Xumeng Liu and Ruxue Yan},
  doi          = {10.1016/j.knosys.2025.114306},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114306},
  shortjournal = {Knowl. Based Syst.},
  title        = {QC2-VQG: Question context complement for visual question generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering. <em>KBS</em>, <em>329</em>, 114305. (<a href='https://doi.org/10.1016/j.knosys.2025.114305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids (MGs) are transforming urban energy management to sustainability by enabling flexible operation and efficient renewable integration. Facilitating electricity exchange among multiple MGs with differentiated demand structures in dual space and time dimensions is of great significance for promoting renewable energy utilization. The feasibility of such coordination for a given region is highly reliant on the characteristics of local demand. However, a systematic analysis of electricity user types and their demand profiles at high spatial and temporal resolution remains absent. Most spatial load forecasting studies only focus on the load quantities or densities at specific nodes. To address this research gap, this paper proposes a multi-source data-driven spatial-temporal electric load portrait method for multi-microgrids (MMGs). First, the functional areas are clustered into multiple MGs with different regional types. Then, typical load curve (TLC) of each functional area is extracted via information granulation. Finally, secondary clustering is performed on TLCs within each MG to reveal user types and their consumption patterns. Rough k-means (RKM) is selected as the clustering algorithm and some improvements are proposed. Case studies in a Chinese city demonstrate that the proposed approach not only outperforms existing methods in terms of clustering performance and computational efficiency, but also uncovers significant spatial and temporal heterogeneity in the user compositions and demand profiles across different MGs. These insights provide actionable references for optimizing demand response (DR) mechanisms, supporting spatial-temporal energy complementarity, and promoting renewable energy consumption.},
  archive      = {J_KBS},
  author       = {Yiling Cheng and Tengfei Zhang and Si Lv and Fumin Ma and Minghao Fan and Gregory M.P. O’hare},
  doi          = {10.1016/j.knosys.2025.114305},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114305},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction. <em>KBS</em>, <em>329</em>, 114304. (<a href='https://doi.org/10.1016/j.knosys.2025.114304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cut-in intention and trajectory prediction of the target vehicle in front of the autonomous vehicle (AV) are two major concerns relating to the safety of passengers. For both of them, it is important to consider the spatial-temporal information of the neighboring vehicles. It is a challenging task to capture this information precisely from the narrow-ranged neighbor vehicles. In such a scenario, a dynamically prioritized correlated connection is required based on the cut-in scenario of the target vehicle. Therefore, a multi-task learning framework consisting of a shared layer and a task-specific layer is proposed to capture detailed information using the prior trajectory data of vehicles as input for cut-in intention and trajectory forecasting of the target vehicle. The shared layer incorporates graph structure learning for effective graph representation, a graph neural network (GNN) with skip connections that efficiently captures spatial data, and an attentive encoder-decoder that records the sequential information. The task-specific layer utilizes fully connected neural networks with different activation functions to forecast two well-defined related tasks. The performance of the proposed model is evaluated on NGSIM and highD datasets. The experimental results show that the proposed model achieves 2.89–9.53 % more F1 score and 25.92–30.99 % lower Root Mean Square Error (RMSE) than the baseline models in predicting the cut-in intention and trajectory of the target vehicle, respectively. Furthermore, the model demonstrates the effectiveness and generalizability for real-time cut-in trajectory forecasting.},
  archive      = {J_KBS},
  author       = {Pritam Bikram and Shubhajyoti Das and Arindam Biswas},
  doi          = {10.1016/j.knosys.2025.114304},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114304},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning enhanced filter and response reliability regularization for aerial object tracking. <em>KBS</em>, <em>329</em>, 114303. (<a href='https://doi.org/10.1016/j.knosys.2025.114303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking is critical in the transport and security sectors, and recent years have seen significant progress in this field. To address the limited computational resources and stringent real-time requirements of aerial platforms, numerous UAV tracking algorithms based on Discriminative Correlation Filters (DCFs) have been developed, aiming to strike a balance between accuracy and efficiency. However, the limited discriminative power of the filters, along with complex appearance variations such as background clutter, occlusion, and camera motion, continues to pose significant challenges and degrade tracking performance. To tackle these issues, we propose an Enhanced Filter and Response Reliability Correlation Filter (EFRCF). This method introduces an Enhanced Filter Reliability (EFR) regularization module, which employs a response map quality evaluation mechanism to guide the self-adaptive learning of regularization coefficients, thereby enhancing discriminative capability. Furthermore, an Enhanced Response Reliability (ERR) regularization module is incorporated to suppress abrupt fluctuations in the response map. Extensive experiments on four popular UAV tracking benchmarks demonstrate that the proposed EFRCF outperforms several mainstream trackers. Notably, it achieves a real-time processing speed of 62.5 frames per second on a low-cost CPU. The source code will be made available at https://github.com/marico2020/EFRCF here.},
  archive      = {J_KBS},
  author       = {Zhi Chen and Lijun Liu and Zhen Yu},
  doi          = {10.1016/j.knosys.2025.114303},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114303},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning enhanced filter and response reliability regularization for aerial object tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing inductive knowledge graph completion with contextual relation topology learning. <em>KBS</em>, <em>329</em>, 114302. (<a href='https://doi.org/10.1016/j.knosys.2025.114302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) plays a crucial role in inferring missing triples within knowledge graphs (KGs), while inductive KGC extends this by enabling predictions for previously unseen entities, allowing dynamic updates in KGs. Recent methods define entity-independent features and utilize Graph Neural Networks (GNNs) to extract them from subgraphs surrounding the target triplet, which are then used to represent relational semantics and logical rules for reasoning. However, the inductive capabilities of existing work is limited as they consider limited entity-independent features. To address this issue, we introduce a novel C ontextual R elation T opology L earning-based GNN framework for inductive KGC, namely CRTL , which considers a broader range of entity-independent features. We observe that subgraph structural features, relation correlation patterns , and entity-relation interactions are crucial entity-independent features for inductive KGC. Moreover, relation correlation patterns and entity-relation interactions are complementary. Specifically, we construct enclosing subgraphs to extract subgraph structural features, relational graphs to model the correlations between relations, and context subgraphs to capture the interactions between entities and relations. In addition, we design a scoring function that dynamically adjusts the contributions of these features. Our extensive experiments on benchmark datasets reveal that CRTL surpasses current state-of-the-art methods, demonstrating improvements of 9.68 % on WN18RR v1 and 12.86 % on FB15K-237 v1 when compared to the suboptimal results.},
  archive      = {J_KBS},
  author       = {Yuxuan Lu and Guojie Ma and Shiyu Yang and Junxiao Wang},
  doi          = {10.1016/j.knosys.2025.114302},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114302},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing inductive knowledge graph completion with contextual relation topology learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network. <em>KBS</em>, <em>329</em>, 114301. (<a href='https://doi.org/10.1016/j.knosys.2025.114301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an Intrusion Detection System (IDS) for Controller Area Network with Flexible Data Rate (CAN-FD) Vehicle Networks based on hybrid Deep Learning (DL) is proposed. Initially, the CAN-FD vehicular network simulation is carried out, and then, the authentication protocol is utilized to increase the existing security of in-vehicle applications that verify the authenticity of the participating entities. Later, inter-service communication and external communication are established. Finally, IDS is performed, and the proposed IDS in CAN-FD In-Vehicle Networks is developed in the following manner. Initially, the input data undergoes normalization using z-score normalization. After that, feature selection is performed by a hybrid similarity measure based on Tanimoto and Jeffreys similarity to select the relevant features in the input data. Finally, intrusion detection is performed based on a hybrid DL model named Cascade Stacked Autoencoder Neural Network (CSANN). The proposed CSANN is developed using a Deep Stacked Autoencoder (DSA) and Deep Neuro Fuzzy Network (DNFN). Additionally, the performance of the implemented technique is evaluated using metrics such as accuracy, True Positive Rate (TPR), and True Negative Rate (TNR). The method achieved a maximum accuracy of 0.921, a TPR of 0.935, and a TNR of 0.921.},
  archive      = {J_KBS},
  author       = {V. Anjana Devi and P.V. Bhaskar Reddy and Sreenu Ponnada and K. Suresh Kumar},
  doi          = {10.1016/j.knosys.2025.114301},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114301},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML. <em>KBS</em>, <em>329</em>, 114300. (<a href='https://doi.org/10.1016/j.knosys.2025.114300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature engineering (FE) plays a crucial role in Machine Learning pipelines, yet it remains a time-consuming process requiring heavy domain expertise. While Automated Machine Learning (AutoML) has automated model selection and hyperparameter tuning, it often overlooks FE, which is particularly needed in specialised domains such as Energy Consumption Forecasting (ECF). To address this limitation, we introduce AutoEnergy, a novel, domain-aware FE algorithm tailored for ECF. AutoEnergy automatically generates interpretable features from timestamps and past consumption values through rule-based transformations, integrating them with AutoML for fully automated ECF modelling while reducing human intervention. The performance of AutoEnergy was evaluated using eighteen diverse real-world energy consumption datasets spanning residential, commercial, industrial, and grid power domains. Through extensive benchmarking against baseline AutoML without FE and established FE methods, namely TSFresh (with TSEfficient and TSMinimal configurations) and FeatureTools (FT), AutoEnergy demonstrated significant improvements in both predictive accuracy and computational efficiency. AutoEnergy achieved forecasting error reductions of 19.52 % to 84.72 % compared to benchmarking methods, with strong performance on smaller datasets and statistical validation via Friedman and Wilcoxon tests. AutoEnergy demonstrated notable computational efficiency by running 1.31 and 4.41 times faster than FT and TSEff, respectively. Although 1.58 times slower than TSMin, AutoEnergy achieved 82.38 % lower forecasting errors. Integrating AutoEnergy with the state-of-the-art Tabular Prior Data Fitted Network (TabPFN) resulted in significant forecasting error reductions across test sets. These findings highlight AutoEnergy’s potential to improve AutoML performance while reducing reliance on domain expertise for FE, paving the way for fully automated ML pipelines in ECF applications.},
  archive      = {J_KBS},
  author       = {Nasser Alkhulaifi and Alexander L. Bowler and Direnc Pekaslan and Nicholas J. Watson and Isaac Triguero},
  doi          = {10.1016/j.knosys.2025.114300},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114300},
  shortjournal = {Knowl. Based Syst.},
  title        = {AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring. <em>KBS</em>, <em>329</em>, 114299. (<a href='https://doi.org/10.1016/j.knosys.2025.114299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive business process monitoring can help detect and solve problems on time by monitoring the execution of business processes in real time, thereby improving overall business efficiency and performance. Current deep learning-based studies have found that embedding structural information of process models helps neural networks learn the deep logic behind business processes. However, they mainly focus on the control-flow perspective, while other perspectives behind the business process, such as organizational structure, social network, and resource behavior, have been largely overlooked. To address this issue, this study proposes a multi-view learning prediction approach that integrates complementary information from both multiple attribute networks and sequences. We carefully design a deep learning model framework to integrate multi-view structural and sequential information for the next-activity prediction of the running trace. On the one hand, a simple and efficient process mining algorithm is designed to model multiple attribute network graphs, and a graph convolutional network is integrated to learn their multi-view structural information, helping understand the deep features of business scenarios. For this, a node feature enhancement method is proposed to integrate global information from historical business executions to help the proposed neural network understand the structure of a complete business scenario. On the other hand, we construct the feature representation of attribute sequences and integrate the Transformer to capture the dependency relations and sequential features within attribute sequences. Experimental evaluation of twelve real-life event logs shows that the proposed approach performs well in prediction accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Binbin Chen and Shuangyao Zhao and Leilei Lin and Qiang Zhang},
  doi          = {10.1016/j.knosys.2025.114299},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114299},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms. <em>KBS</em>, <em>329</em>, 114298. (<a href='https://doi.org/10.1016/j.knosys.2025.114298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news on short-video social media platforms presents significant challenges to public awareness and social stability. While prior research has largely concentrated on text-image fake news, fake news in video format remains underexplored due to limited dataset availability and the complexities of multimodal analytical techniques. To bridge these gaps, we introduce TikCron , a large-scale, open-source dataset of short videos collected from Douyin (TikTok China). TikCron provides news videos and rich social context, specifically curated for studying pandemic-related misinformation in the health and political domains. Furthermore, we propose MAGE-fend (Multimodal Adaptive Fusion Guided by LLM Expertise), a novel framework that utilizes Large Language Models (LLMs) to extract high-level semantic information from images and provide inferential reasoning to enhance fake news detection. MAGE-fend integrates an adaptive attention-based fusion mechanism to dynamically integrate multiple modalities, effectively capturing cross-modal consistency and complementary cues. Comprehensive experiments conducted on the TikCron dataset and the publicly available FakeSV dataset demonstrate that MAGE-fend outperforms state-of-the-art methods in various evaluation metrics. This detection framework makes a substantial contribution to addressing potential future pandemic misinformation crises.},
  archive      = {J_KBS},
  author       = {Lingtong Hu and Zituo Wang and Jiayi Zhu and Yifan Hu and Xianbing Wang},
  doi          = {10.1016/j.knosys.2025.114298},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114298},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy knowledge distillation via anchor-guided distribution learning. <em>KBS</em>, <em>329</em>, 114297. (<a href='https://doi.org/10.1016/j.knosys.2025.114297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing knowledge distillation methods typically do not adequately account for the representativeness of sampled training data or the adverse effects of missing classes within mini-batches, both of which can lead to suboptimal knowledge transfer. In this paper, we introduce A nchor-based K nowledge D istillation (AKD), a method that leverages the most informative and representative samples, referred to as anchors , during the transfer process, and matches the representation distribution of the data in the feature space rather than their actual representations. Anchors are strategically chosen based on their ability to encapsulate critical features of the data distribution, ensuring that the student model focuses on the most informative aspects of the teacher’s knowledge. The proposed method enables the introduction of information from a wider variety of classes at each mini-batch iteration, ensuring a more balanced data distribution and thereby improving the knowledge transfer process. Furthermore, by leveraging the static nature of anchors, we enhance the student model’s representation learning through attention maps, improving both convergence and generalization. The proposed approach is extensively evaluated across various datasets and tasks, demonstrating that the incorporation of anchors into the knowledge distillation process improving the accuracy and trustworthiness of the resulting models.},
  archive      = {J_KBS},
  author       = {Dimitrios Spanos and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.knosys.2025.114297},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114297},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trustworthy knowledge distillation via anchor-guided distribution learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding. <em>KBS</em>, <em>329</em>, 114296. (<a href='https://doi.org/10.1016/j.knosys.2025.114296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas metal arc welding (GMAW) is widely utilized for depositing corrosion-resistant austenitic stainless steel claddings on low-carbon steel substrates, where the bead geometry directly influences the structural integrity and service life of the component. The objective of this study is to develop a predictive framework for accurately estimating clad bead geometry parameters, namely bead width, penetration depth, reinforcement height, and percentage dilution, based on key GMAW process variables. To achieve this, five supervised machine learning (ML) models—linear regression (LR), K-Nearest Neighbors (KNN), decision tree (DT), random forest (RF), and support vector regression (SVR)— were trained on experimentally obtained datasets and evaluated using performance metrics including the R² score, the mean absolute error (MAE), the mean squared error (MSE), and the root mean squared error (RMSE). Among the models, the DT demonstrated the best predictive performance, achieving an R² score of 0.959, an MAE of 0.134, an MSE of 0.150, and an RMSE of 0.388. The SVR model also performed exceptionally well, with an R² score of 0.952. This study identified the welding gun angle and wire feed rate as the most influential parameters affecting clad bead geometry. The use of these advanced ML models considerably improves the prediction accuracy of clad bead dimensions in GMAW, enabling intelligent process optimization and consistent production of high-quality weld cladding.},
  archive      = {J_KBS},
  author       = {Kannan Thankappan and Jayaram Radhakrishnan Santhi and Thanammal Indu Vijayalakshmi},
  doi          = {10.1016/j.knosys.2025.114296},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114296},
  shortjournal = {Knowl. Based Syst.},
  title        = {Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation. <em>KBS</em>, <em>329</em>, 114295. (<a href='https://doi.org/10.1016/j.knosys.2025.114295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A particularly promising property, known as watermark radioactivity, offers potential for preventing the unauthorized use of LLM outputs in downstream distillation pipelines. However, the robustness of watermarking against scrubbing attacks and its unforgeability under spoofing attacks in unauthorized knowledge distillation settings remain underexplored. Existing attack methods either assume access to model internals or fail to support both attack types simultaneously. In our work, we propose Contrastive Decoding-guided Knowledge Distillation ( CDG-KD ), a unified framework that enables dual-path attacks under unauthorized knowledge distillation. At the core of CDG-KD is a novel contrastive decoding mechanism with token-level constraint fusion, which integrates a learned watermark discriminator and probability-based constraint component to selectively manipulate watermark-relevant logits. This allows for fine-grained control of watermark strength during generation without compromising fluency or semantics. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs, followed by dual-path distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable. Our code is available at https://github.com/xinykou/CDG-KD .},
  archive      = {J_KBS},
  author       = {Xin Yi and Yue Li and Shunfan Zheng and Linlin Wang and Xiaoling Wang and Liang He},
  doi          = {10.1016/j.knosys.2025.114295},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114295},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring. <em>KBS</em>, <em>329</em>, 114294. (<a href='https://doi.org/10.1016/j.knosys.2025.114294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue driving is a leading cause of traffic accidents, underscoring the critical need for effective driver fatigue monitoring to enhance road safety. Electroencephalogram (EEG) signals are widely considered as the gold standard for detecting fatigue. However, many existing methods struggle to comprehensively capture and integrate EEG features across multiple dimensions and scales, resulting in suboptimal monitoring performance. To address this challenge, we propose a spatiotemporal graph neural network with global brain functional network partitioning (STP-Net). STP-Net facilitates the comprehensive extraction and deep fusion of both short-term and long-term temporal features, along with global and local spatial features from EEG signals, producing rich hybrid representations that effectively capture the intrinsic dynamics of EEG activity. Evaluated on the public SEED-VLA dataset, STP-Net achieves superior performance, with an accuracy of 94.09 %, recall of 94.00 %, precision of 89.55 %, and an F1 score of 0.917, outperforming existing mainstream models. Ablation studies demonstrate that the spatiotemporal interaction module, which integrates graph convolutional networks and a transformer, plays a pivotal role in enhancing network performance. Additionally, interpretability analysis of the partitioned brain regions reveals that the perceptual–motor network shows the strongest correlation with fatigue. These results highlight STP-Net’s potential for accurate driver fatigue monitoring and its broader implications for enhancing driving safety.},
  archive      = {J_KBS},
  author       = {Jinglong Zhu and Qiang Liu and Hui Liu and Zeping Chen and Zhangzhen Zhao and Junchen Liao and Qing Li},
  doi          = {10.1016/j.knosys.2025.114294},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114294},
  shortjournal = {Knowl. Based Syst.},
  title        = {STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification. <em>KBS</em>, <em>329</em>, 114293. (<a href='https://doi.org/10.1016/j.knosys.2025.114293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When pre-trained models are applied directly to chest X-ray (CXR) images without appropriate adaptation, they frequently show problems like overfitting, limited generalization, or decreased SE to clinically relevant features because of the unique characteristics of medical data, such as class imbalance and domain-specific noise. Due to the discrepancy between natural image features (used during pre-training) and radiological image characteristics, studies have shown that such models may perform well on training data but poorly on unseen clinical samples. This study comprehensively evaluates the performance of the fine-tuning method using the Iterated Race for Automatic Algorithm Configuration (IRACE) technique on pre-trained models for several medical imaging CXRs. We select five well-known CNN architectures: MobileNet-v2, EfficientNet-b0, ResNet-50, DenseNet-121, and VGG-19, utilizing the IRACE technique for HPT classification of three CXR datasets. The experimental results indicate that the IRACE technique was generally effective across CXR images, producing noticeable improvements on all models. DenseNet-121 outperformed the other architectures across all metrics, achieving accuracies of 99.83 %, 99.98 %, and 99.87 % on the three CXR datasets, respectively. Additionally, we explored the model detection mechanism by interpreting the classification of radiological images using the Gradient-weighted Class Activation Mapping (Grad-CAM) with Layer-wise Relevance Propagation (LRP) approach for CXR imaging. The results obtained have provided information on how the model classifies CXR images, which can assist radiologists in identifying and evaluating visual characteristics.},
  archive      = {J_KBS},
  author       = {Nagwan Abdel Samee and Essam H. Houssein and Eman Saber and Gang Hu and Mingjing Wang},
  doi          = {10.1016/j.knosys.2025.114293},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114293},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training. <em>KBS</em>, <em>329</em>, 114292. (<a href='https://doi.org/10.1016/j.knosys.2025.114292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization methods are fundamental to training deep neural networks, yet their effectiveness is often limited by noisy gradient estimates and unstable learning dynamics. To overcome these challenges, we introduce AdaVAM (Adaptive Variance-Aware Momentum), a novel optimizer that decouples gradient momentum from variance-based normalization. Unlike conventional approaches (e.g., Adam, Adan), AdaVAM employs a delayed variance term computed from historical gradients to dynamically normalize stochastic gradients. This design simultaneously reduces momentum bias and preserves robustness against gradient noise. Theoretically, we prove that AdaVAM attains an optimal O ( 1 / K ) convergence rate for non-convex objectives without requiring bounded gradient assumptions. Comprehensive experiments on image classification and language modeling benchmarks demonstrate that AdaVAM surpasses existing methods in both convergence speed and final task accuracy. By bridging theoretical guarantees with empirical efficacy, our work advances the development of reliable optimizers for deep learning. The PyTorch implementation is available at: https://github.com/xudp100/AdaVAM.git .},
  archive      = {J_KBS},
  author       = {Jinlan Liu and Wenhan Jiang and Xin Deng and Dongpo Xu},
  doi          = {10.1016/j.knosys.2025.114292},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114292},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-typed multi-relational heterogeneous graph neural network model for complex networks. <em>KBS</em>, <em>329</em>, 114291. (<a href='https://doi.org/10.1016/j.knosys.2025.114291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are a prevalent relationship in real-world society, and the use of graphs and graph neural networks (GNNs) to model these networks and capture their characteristic relationships has shown tremendous development potential. Due to the inherent complexity of node and edge relationships within networks, heterogeneous graph neural networks (HGNNs) have become the preferred modeling approach. However, existing HGNNs primarily focus on heterogeneous graphs with only single relationships between nodes, which limits their ability to handle complex network graphs with multiple relational interactions. To effectively capture the complex node objects and multi-relational interactions in networks, this paper proposes a neural network model for multi-class multi-relational heterogeneous graphs (MMHGNN), consisting of three modules: structural feature encoding, weighted multi-relation path aggregation, and feature fusion. In the structural feature encoding module, MMHGNN employs the Four Color Theorem to color the graph and generates type encodings of edge relationships along paths, merging color features with path encodings to serve as structural features for different paths, thereby enhancing the distinguishability of nodes under complex relationships and structures. In the weighted multi-relation path aggregation module, MMHGNN aggregates neighbors along paths based on the number of edge relationships between nodes as weights and implements a balancing strategy to prevent excessive weights on long paths. In the feature fusion module, MMHGNN combines the structural features from the structural feature encoding with the embeddings from the relation aggregation module, leveraging a graph-level attention mechanism to fuse node features across different paths and generate the final node embeddings. Experiments conducted on real-world complex network datasets demonstrate the significant advantages of MMHGNN across multiple tasks.},
  archive      = {J_KBS},
  author       = {Yufei Zhao and Junyue Dong and Wenhao Wang and Hua Duan},
  doi          = {10.1016/j.knosys.2025.114291},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114291},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-typed multi-relational heterogeneous graph neural network model for complex networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSGNN: Simple siamese graph neural networks for out-of-distribution generalization. <em>KBS</em>, <em>329</em>, 114290. (<a href='https://doi.org/10.1016/j.knosys.2025.114290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have proven effective for analyzing relational data in a variety of domains. Nevertheless, their performance tends to deteriorate significantly under distribution shifts between training and test datasets, presenting a central challenge for real-world machine learning applications. This work proposes the Simple Siamese Graph Neural Network (SSGNN), a Self-supervised Learning (SSL) method aimed at improving Out-of-Distribution (OOD) generalization in node classification tasks. In contrast to many existing SSL approaches that depend on data augmentation and the creation of positive and negative sample pairs, SSGNN adopts a simplified framework based on a Siamese GNN architecture with integrated dropout, thus avoiding the need for explicit pair generation. The method addresses common shortcomings in graph representation learning—particularly the tendency to capture spurious correlations—by introducing a three-stage training procedure utilizing dual Graph Convolutional Network (GCN) encoders with shared parameters. Furthermore, SSGNN incorporates a composite loss function whose components optimize node representation similarity, label prediction consistency, and overall prediction accuracy. Through this approach, SSGNN learns stable graph representations that demonstrate improved generalization across varying data distributions. Experimental results show that SSGNN outperforms existing methods and enhances generalization by reducing the GAP metric, which quantifies the relative performance difference between IID and OOD settings.},
  archive      = {J_KBS},
  author       = {Seyedeh Hamideh Erfani and Mohammad Javad Fadaeieslam and Reza Mortazavi and Mohammad Rahmanimanesh},
  doi          = {10.1016/j.knosys.2025.114290},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114290},
  shortjournal = {Knowl. Based Syst.},
  title        = {SSGNN: Simple siamese graph neural networks for out-of-distribution generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model. <em>KBS</em>, <em>329</em>, 114289. (<a href='https://doi.org/10.1016/j.knosys.2025.114289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semi-supervised semantic segmentation, existing studies have shown promising results in academic settings with controlled splits of benchmark datasets. However, the potential benefits of leveraging significantly larger sets of unlabeled images remain unexplored. In real-world scenarios, abundant unlabeled images are often available from online sources (web-scraped images) or large-scale datasets. However, these images may have different distributions from those of the target dataset, a situation known as out-of-distribution (OOD). Using these images as unlabeled data in semi-supervised learning can lead to inaccurate pseudo-labels, potentially misguiding network training. In this paper, we propose a new semi-supervised semantic segmentation framework with an open-vocabulary segmentation model (SemiOVS) to effectively utilize unlabeled OOD images. Extensive experiments on Pascal VOC and Context datasets demonstrate two key findings: (1) using additional unlabeled images improves the performance of semi-supervised learners in scenarios with few labels, and (2) using the open-vocabulary segmentation (OVS) model to pseudo-label OOD images leads to substantial performance gains. In particular, SemiOVS outperforms existing PrevMatch and SemiVL methods by +3.5 and +3.0 mIoU, respectively, on Pascal VOC with a 92-label setting, achieving state-of-the-art performance. These findings demonstrate that our approach effectively utilizes abundant unlabeled OOD images for semantic segmentation tasks. We hope this work can inspire future research and real-world applications. The code is available at https://github.com/wooseok-shin/SemiOVS .},
  archive      = {J_KBS},
  author       = {Wooseok Shin and Jisu Kang and Hyeonki Jeong and Jin Sob Kim and Sung Won Han},
  doi          = {10.1016/j.knosys.2025.114289},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114289},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation. <em>KBS</em>, <em>329</em>, 114288. (<a href='https://doi.org/10.1016/j.knosys.2025.114288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has gained significant traction as an effective approach for learning representations across diverse domains. However, current methods confined to Euclidean space face a fundamental limitation: they struggle to preserve the complex topological structures inherent in hierarchical graph data. Existing graphical representation learning methods face three interrelated challenges. Specifically, embedding hierarchical graph structures into Euclidean space inevitably results in topological distortion. Conventional contrastive methods rely heavily on negative samples. In particular, the limited transformation capabilities restrict the model's ability to capture complex hierarchical relationships. To address these challenges, we propose the Hy perbolic Cro ss-space D iffusion ( HyCroD ), which seamlessly integrates hyperbolic geometric diffusion within a multi-scale contrastive learning architecture. It enhances information preservation through a dual-space augmentation strategy, where transformations are performed independently in both Euclidean and Hyperbolic spaces. By incorporating cross-grid and cross-view contrastive objectives alongside carefully designed spatial transformation modules, HyCroD effectively captures and preserves the rich hierarchical information present in graph data. Experiments across five benchmark datasets demonstrate improvements over state-of-the-art methods on node classification tasks. Our findings show that combining dual-space representation learning with self-supervised objectives effectively preserves hierarchical information in graph data, offering a promising direction for learning representations of complex multi-level structures.},
  archive      = {J_KBS},
  author       = {Zhirui Chen and Qiancheng Yu and Xiao Chen and Xuchu Jiang},
  doi          = {10.1016/j.knosys.2025.114288},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114288},
  shortjournal = {Knowl. Based Syst.},
  title        = {Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning. <em>KBS</em>, <em>329</em>, 114287. (<a href='https://doi.org/10.1016/j.knosys.2025.114287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multimodal sentiment analysis (MSA) for personalized users under uncertain modalities missing has become a new challenging problem. To address this issue, we propose a two-step idea. First, we propose an effective MSA model under uncertain modalities missing and train it with some public datasets, thus to enable the model to possess better preliminary MSA ability. Then, we make the pretrained model to continuously learn user’s personalized characteristics with online learning methods, thereby enable the model grow into a robust model for personalized MSA. Based on this idea, we propose a Personalized MSA model under uncertain modalities missing via Pretraining and Online Learning (termed as PMSAPO). For Personalized MSA under uncertain modalities missing, PMSAPO firstly generates the fused modality and allocate weights for each modality with a Fully Connected Neural Network Evaluation Module. Then, PMSAPO completes the final sentiment classification based on the fusion modality with a Joint feature optimization module. For the pretrained PMSAPO, we make it autonomously learn the personalized users via our proposed online learning techniques, including an online meta-learning method, a learning rate adaptive adjustment strategy, and a dynamic weight assignment strategy for sample data. Finally, based on three public benchmark datasets (IEMOCAP, MELD and CMU-MOSI), we conduct extensive experiments and prove that PMSAPO completely outperforms the Twelve state-of-the-art baseline models. (Code is available at https://github.com/SHX-AI/PMSAPO .)},
  archive      = {J_KBS},
  author       = {Hongxiang Sun and Zhizhong Liu and Dianhui Chu and Quan Z. Sheng and Zhaowei Liu and Jian Yu},
  doi          = {10.1016/j.knosys.2025.114287},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114287},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGA: An adaptive group alignment framework for structured medical cross-modal representation learning. <em>KBS</em>, <em>329</em>, 114286. (<a href='https://doi.org/10.1016/j.knosys.2025.114286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning medical visual representations directly from paired medical images and reports has emerged as a promising direction in representation learning. However, existing vision-language pretraining (VLP) methods in the medical domain often oversimplify clinical reports into single entities or fragmented tokens, overlooking their inherent structured nature. Moreover, contrastive learning paradigms typically rely on large quantities of hard negative samples, which poses challenges when dealing with small scale medical datasets. To address these issues, we propose Adaptive Grouped Alignment (AGA), a novel framework for learning structured information from paired medical images and reports. Specifically, we design a bidirectional grouping mechanism based on a sparse similarity matrix. Given an image-report pair, we first compute a fine-grained similarity matrix between each text token and each image patch. For each token, we select the top-matching patches to form a visual group, and conversely, for each patch, we select the most semantically related tokens to form a language group. To enable adaptive grouping, we introduce two threshold gating modules, Language-grouped Threshold Gate and Vision-grouped Threshold Gate, which dynamically learn similarity thresholds for group construction. The group representation corresponding to each token or patch is computed as a weighted average over the elements in its group, where the weights are given by their similarity scores. To align each token representation with its corresponding group representations, we propose an Instance-aware Group Alignment (IGA) loss, which operates solely within individual image-text pairs, eliminating the need for external negative samples and thereby alleviating the reliance on large scale hard negatives. Finally, we employ a Bidirectional Cross-modal Grouped Alignment (BCGA) module to facilitate fine-grained alignment between visual and linguistic group representations. Extensive experiments on both public and private datasets across various downstream tasks, including image-text retrieval and classification (in both fine-tuning and zero-shot settings), demonstrate the effectiveness of our proposed framework.},
  archive      = {J_KBS},
  author       = {Wei Li and Xun Gong and Jiao Li and Xiaobin Sun},
  doi          = {10.1016/j.knosys.2025.114286},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114286},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGA: An adaptive group alignment framework for structured medical cross-modal representation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention. <em>KBS</em>, <em>329</em>, 114285. (<a href='https://doi.org/10.1016/j.knosys.2025.114285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of network attacks poses serious challenges to device security and data privacy. As an important mean, malicious traffic detection method converts the raw traffic into intermediate representations (such as CSV format or gray-scale images) for feature analysis and protects network devices by identifying malicious traffic. These representations have following limitations: CSV format is difficult to capture the spatiotemporal correlations of traffic sequences, the single channel characteristics of gray-scale images result in the loss of multidimensional features. In addition, existing methods are prone to pattern collapse in imbalanced category scenarios. To solve these problems, this paper proposes a malicious traffic augmentation model called CT-SSSA based on the c lassifier T ransGAN and s patial-channel s ynergistic s elf- a ttention (SCSSA). Its innovations are reflected in: 1) We propose a key feature extraction method based on mutual information, it converts original traffic into RGB images and preserves multidimensional semantic features through three channel superposition; 2) We introduce the SCSSA mechanism into TransGAN to jointly capture the global context dependencies and local fine-grained features, thereby reducing the complexity of generator; 3) We design the auxiliary classifier and dynamic adaptive loss function to constrain the class consistency of generated samples, and alleviate the pattern collapse problem caused by class imbalance. Experiments on three publicly available datasets show that CT-SSSA achieves a 40.5 % and 88.35 % reduction in FID value and FPR compared to advanced baselines, and the accuracy, TPR and F1-score are improved by 1.01 %, 2.4 % and 13.85 %, respectively.},
  archive      = {J_KBS},
  author       = {Saihua Cai and Xingyu Zhao and Jinfu Chen and Yige Zhao and Junyi Chen and Lizhou Chen},
  doi          = {10.1016/j.knosys.2025.114285},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114285},
  shortjournal = {Knowl. Based Syst.},
  title        = {CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention. <em>KBS</em>, <em>329</em>, 114283. (<a href='https://doi.org/10.1016/j.knosys.2025.114283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trend prediction is challenging due to the nonlinear dynamics of financial markets. Existing approaches often neglect extreme price fluctuations (outliers) and complex inter-stock relationships, limiting predictive performance. In this paper, we propose a novel framework integrating an abnormal volatility point detection mechanism with a multi-relational hypergraph hierarchical attention network. Specifically, we first employ a convolutional LSTM enhanced with an overnight gap price criterion to detect and down-weight abnormal price fluctuations, effectively reducing errors in stock temporal feature extraction. Second, we use temporal attention to emphasize influential historical time steps. Third, to model complex inter-stock dependencies, we construct a multi-relational hypergraph capturing both industry and supply-chain relations. Finally, we develop a hierarchical attention mechanism to adaptively weight stocks within relation groups (intra-hyperedge attention) and assess the relative importance of different relation types (inter-hypergraph attention). Extensive experiments on seven years of NYSE and NasdaqGS data show that our approach significantly outperforms state-of-the-art baselines in prediction accuracy and risk-return performance, demonstrating the effectiveness of capturing abnormal volatility and higher-order stock interactions.},
  archive      = {J_KBS},
  author       = {Suochao Yi and Jing Chi and Yandi Shi and Caiming Zhang},
  doi          = {10.1016/j.knosys.2025.114283},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114283},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach. <em>KBS</em>, <em>329</em>, 114282. (<a href='https://doi.org/10.1016/j.knosys.2025.114282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the volume of scientific publications grows, predicting the future citation counts of research papers is crucial for identifying influential studies and promising research directions. Existing graph neural network methods often rely solely on neighbor aggregation, which neglects the global heterogeneous nature of academic networks, thereby limiting their ability to fully capture the intricate relationships between different types of nodes and edges. This paper proposes a novel model, named C entrality-guided and D ual C lustering driven H eterogeneous G raph N etwork (CDCHGN) that addresses these limitations. CDCHGN captures both global and local structural dynamics of a dynamic academic graph using node centrality information, dual clustering techniques, and edge-type encoding to enrich semantic representation and effectively model heterogeneous relationships among various node types. Additionally, it incorporates time-injected attention to capture the temporal evolution of node features. Extensive experiments on real-world datasets demonstrate that our model achieves superior performance. Notably, on the APS dataset, CDCHGN achieves a 5.88 % improvement in Mean Absolute Log Error (MALE) and a 6.87 % improvement in Root Mean Squared Log Error (RMSLE) compared to the second-best models.},
  archive      = {J_KBS},
  author       = {Tianming Zhang and Junkai Fang and Xuanyu Chen and Zhengyi Yang and Bin Cao},
  doi          = {10.1016/j.knosys.2025.114282},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114282},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks. <em>KBS</em>, <em>329</em>, 114281. (<a href='https://doi.org/10.1016/j.knosys.2025.114281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we tackled the task assignment problem in the capacity-enhanced version of Multi-Agent Pickup and Delivery (MAPD), a lifelong variant of the classical Multi-Agent Path Finding (MAPF) problem. Capacity-enhanced agents can carry multiple items, allowing them to operate several tasks simultaneously by visiting a sequence of pickup and delivery locations (i.e. waypoints) to fulfill their assignments. When determining the next task of the agent from the available options, a method encountered in the literature is to select the task with the nearest pickup location to the agent’s current location. In this research, we suggest that improving task assignments of capacitated agents can significantly enhance the solution quality of multi-agent route plans in lifelong pickup and delivery scenarios. We propose novel task assignment strategies that incorporate waypoints as a factor in the task selection process. We devised three groups of task assignment methods based on Closeness Centrality, Hausdorff Distance, and Cost Estimation within the context of the complete Token Passing with Multiple Capacity (TPMC) algorithm. We evaluated the methods in small and large-scale automated warehouse simulations, assessing their effectiveness in terms of makespan against the contemporary task selection method and one another. As a result of our experiments, the Closeness Centrality class of heuristics failed to enhance solution quality in large majority of cases. The Average Hausdorff Distance heuristic achieved good outcomes in scenarios with higher capacity agents. The Cost-Based Estimation method demonstrated significant improvements across all scenarios.},
  archive      = {J_KBS},
  author       = {Evren Çilden and Faruk Polat},
  doi          = {10.1016/j.knosys.2025.114281},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114281},
  shortjournal = {Knowl. Based Syst.},
  title        = {Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing. <em>KBS</em>, <em>329</em>, 114279. (<a href='https://doi.org/10.1016/j.knosys.2025.114279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning-based methods have achieved notable progress in image dehazing through supervised training on synthetically paired datasets. However, the substantial domain gap between synthetic and real-world hazy images often impairs generalization performance, thereby limiting their effectiveness in practical applications where target domains differ significantly from the training data. Even worse, acquiring sufficient pixel-aligned hazy-clear image pairs in real-world scenarios is costly and challenging. To this end, we introduce a novel Bidirectional Disentangled Translation Network (BDT-Net) for unsupervised dehazing, which regards haze removal as a feature disentanglement task, i.e., separating content-relevant information from the clean factor and haze-related information from the fuzzy factor. Specifically, we design a dual-branch disentanglement framework comprising a Content Recovery Branch (CRB) for extracting structural content information and a Parameter Estimation Branch (PEB) dedicated to capturing haze-related characteristics. Among them, we leverage forward dehazing and reverse rehazing physics-based models to establish haze cycle consistency, thus our BDT-Net can be optimized only needing the hazy image itself. To better distinguish the haze information from the clean content in the latent space, we design an effective Feature-wise Contrastive Representation (FCR), which can not only consider the inherent self-similarity within each information flow but also exploit the mutual exclusivity between different components. Furthermore, a two-way Pixel-wise Contrastive Representation (PCR) is incorporated to enhance the capability of restoring clear image clarity and content. Extensive experimental results on benchmark datasets demonstrate the superiority of our BDT-Net over other compared state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weichao Yi and Liquan Dong and Ming Liu and Lingqin Kong and Yue Yang and Xuhong Chu and Yuejin Zhao},
  doi          = {10.1016/j.knosys.2025.114279},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114279},
  shortjournal = {Knowl. Based Syst.},
  title        = {You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAFNet: Circular attention fusion for medical image segmentation. <em>KBS</em>, <em>329</em>, 114277. (<a href='https://doi.org/10.1016/j.knosys.2025.114277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images is crucial for clinical diagnosis and treatment planning. Recently, Transformers have demonstrated promising performance in medical image segmentation tasks, yet the quadratic complexity of the attention mechanism presents difficulties. Various methods attempt to reduce this complexity by constraining the range of attention to local regions, thereby improving efficiency. However, these methods often result in receptive fields that are not large enough, leading to insufficient context modeling. To address this issue, we propose an attention mechanism called Circular Attention (CA), which confines the attention region within a circular window through polar coordinate transformation, and apply it to the Circular Attention Fusion (CAF) module for feature fusion. CAF integrates feature information from both CNNs and Transformers to improve the accuracy of medical image segmentation. The CAF module consists of a circular attention block, a multi-scale convolution module, and a residual block with deep convolution. Furthermore, adjusting the radius and edge width of the circular attention in various CAFs allows CAFNet to perform multi-scale feature fusion by covering different regions during the fusion process. The proposed method achieves state-of-the-art segmentation performance on multiple datasets. The code is available at: https://github.com/EchoSixHIYA/CAFNet},
  archive      = {J_KBS},
  author       = {Xudong Wu and Baohua Yuan and Ning Li and Lin Shi and Mingjie Jiang and Juxiao Zhang and Rui Tang and Qile Qin and Jin Ma and Shoukun Xu},
  doi          = {10.1016/j.knosys.2025.114277},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114277},
  shortjournal = {Knowl. Based Syst.},
  title        = {CAFNet: Circular attention fusion for medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment. <em>KBS</em>, <em>329</em>, 114276. (<a href='https://doi.org/10.1016/j.knosys.2025.114276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decline in balance function is a major contributor to falls among older adults. Assessing balance function can facilitate early detection of potential issues, and reduce the risk of falls and related injuries. However, a significant challenge is the lack of sufficient data on older adults, which leads to poor model evaluation performance and limits its application in daily life. To address this issue, we propose KDDA, a knowledge-driven semi-supervised domain adaptation method that leverages relevant gait information to improve balance assessment across age domains.The KDDA-Balance model incorporates multidimensional features through a gait knowledge computation module to enrich the feature space. A domain adversarial module with dual classifiers is used to reduce feature discrepancies between the target and source domains. Additionally, an alternative loss function integrates the dual classifier module with a multi-source domain adaptation module, further improving evaluation performance in the target domain. Extensive experiments on the Falling Risk Assessment (FRA) dataset and the Impaired Gait Ground Reaction Force (GaitRec) dataset demonstrate the superiority of our proposed model. On the FRA dataset, KDDA-Balance achieved an evaluation accuracy of 90.07 %, representing an average improvement of 7.83 %. On the GaitRec dataset, the model reached an evaluation accuracy of 83.02 %, with an average accuracy gain of 5.46 %. These results validate the effectiveness of KDDA-Balance in cross-domain evaluation, providing a novel approach for assessing fall risk among older adults.},
  archive      = {J_KBS},
  author       = {Zhaoyang Ge and Shujie Huang and Huiqing Cheng and Jingzhe Ma and Zhuang Tong and Liying Zhang and Mingliang Xu},
  doi          = {10.1016/j.knosys.2025.114276},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114276},
  shortjournal = {Knowl. Based Syst.},
  title        = {KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection. <em>KBS</em>, <em>329</em>, 114275. (<a href='https://doi.org/10.1016/j.knosys.2025.114275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With commercial air traffic’s increasing complexity, intelligent flight anomaly detection becomes crucial in ensuring flight safety. Existing solutions usually aggregate multiple sensor records of one flight to a flat and indivisible atomic sample to be classified. It is hard for them to incorporate outer information from similar flights and identify inner mechanisms between sensors. However, the degree of deviation from similar normal flights can evaluate the flight risks, and the modeling of sensors can reveal where the risk comes from. To this end, we propose MMGCL, a flight anomaly detection model based on m ulti-scale and m ulti-channel g raph c ontrastive l earning. MMGCL first constructs two types of graphs regarding flight similarity and sensor correlations to model the relations between flights and sensors, respectively. Then, multi-channel contrastive learning is proposed to differentiate normal and abnormal flights from different sensor aspects, where each type of sensor is related to one channel and has one normal center. The learnable representations of sensors are further applied to train a classifier judging the risk score. Finally, the risk score and the distances of sensors from their normal centers are combined to determine whether the flight is abnormal. Extensive experiments validate that our model outperforms the compared ones and has good interpretability of identified anomalies. Our code is publicly available at: anonymous.4open.science/r/MMGCL-6768 .},
  archive      = {J_KBS},
  author       = {Nengjun Zhu and Yuqiang Ren and Yu Liu and Hang Yu and Xinzhi Wang and Xiangfeng Luo},
  doi          = {10.1016/j.knosys.2025.114275},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114275},
  shortjournal = {Knowl. Based Syst.},
  title        = {MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust unsupervised method for outlier set detection. <em>KBS</em>, <em>329</em>, 114274. (<a href='https://doi.org/10.1016/j.knosys.2025.114274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a robust method that identifies sets of points that collectively deviate from typical patterns in a dataset, which it calls “outlier sets”, while excluding individual points from detection. This new methodology, Outlier Set Two-step Identification (OSTI) employs a two-step approach to detect and label these outlier sets. First, it uses Gaussian Mixture Models for probabilistic clustering, identifying candidate outlier sets based on cluster weights below a hyperparameter threshold. Second, OSTI measures the Inter-cluster Mahalanobis distance between each candidate outlier set’s centroid and the overall dataset mean. OSTI then tests the null hypothesis that this distance does not significantly differ from its theoretical chi-square distribution, enabling the formal detection of outlier sets. We test OSTI systematically on 8000 synthetic 2D datasets across various inlier configurations and thousands of possible outlier set characteristics. Results show OSTI robustly and consistently detects outlier sets with an average F1 score of 0.92 and an average purity (the degree to which outlier sets identified correspond to those generated synthetically, i.e., our ground truth) of 98.58 %. We also compare OSTI with state-of-the-art outlier detection methods, to illuminate how OSTI fills a gap as a tool for the exclusive detection of outlier sets.},
  archive      = {J_KBS},
  author       = {Amal Sarfraz and Abigail Birnbaum and Flannery Dolan and Jonathan Lamontagne and Lyudmila Mihaylova and Charles Rougé},
  doi          = {10.1016/j.knosys.2025.114274},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114274},
  shortjournal = {Knowl. Based Syst.},
  title        = {A robust unsupervised method for outlier set detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel loan eligibility prediction model with effective use of data transformation methods. <em>KBS</em>, <em>329</em>, 114272. (<a href='https://doi.org/10.1016/j.knosys.2025.114272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A loan eligibility prediction model (LEP) determines the eligibility of an applicant for a loan based on the applicant’s data. A novel loan eligibility prediction model has been presented in this research work. To improve the prediction performance, we experimented with several data transformation (DT) methods on the data before feeding it to machine learning models. At the end, we chose the adaptive Weight-of-Evidence (aWOE) DT method, which preserves data privacy. Before applying DT, we preprocessed the data (e.g., cleaning, missing value replacement, categorical encoding) to ensure data quality. To mitigate feature redundancy, Pearson correlation was applied. In order to select the most relevant features from the datasets, the Chi-square feature selection technique was employed. Additionally, the Grid Search method was used to identify the optimal hyperparameters for the classifiers. The experiments have been carried out on seven publicly available datasets. Subsequently, the proposed models were evaluated based on standard evaluation metrics. We also conducted a non-parametric statistical test to examine the statistical significance of our results. Our experimental analysis and statistical tests reveal that the proposed aWOE based approach outperforms its counterparts. The privacy assessment demonstrates that the aWOE based model preserves data privacy. To explain our model, we conducted a SHAP analysis, which demonstrated that aWOE prioritizes features which are more aligned with loan eligibility in practice. Our proposed methodology enhanced the prediction performance by as much as 6.3 % and 3.8 % in terms of accuracy and F-measure, respectively. Moreover, the proposed methodology achieved 100 % prediction performance on two datasets across all evaluation metrics. Through comprehensive experimental analysis, the merits of data transformation methods in conjunction with feature selection and optimal hyperparameters have been illustrated for loan eligibility prediction in the context of the lending industry.},
  archive      = {J_KBS},
  author       = {Joydeb Kumar Sana and M. Sohel Rahman and M. Saifur Rahman},
  doi          = {10.1016/j.knosys.2025.114272},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114272},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel loan eligibility prediction model with effective use of data transformation methods},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for effective phishing URL detection using an LSTM-based siamese network. <em>KBS</em>, <em>329</em>, 114271. (<a href='https://doi.org/10.1016/j.knosys.2025.114271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting phishing attacks in the era of generative AI presents a significant challenge due to the increasing sophistication of AI-generated phishing schemes. Neural network-driven approaches, including deep learning-based detection techniques, face notable limitations such as vulnerability to adversarial perturbations, reliance on large labeled datasets, poor generalization to novel attack patterns, and an over-dependence on shallow lexical features that fail to capture deeper semantic patterns. To address these limitations, we propose a pioneering approach leveraging a Siamese network that integrates twin LSTM subnetworks with shared weights, transforming URL sequences into robust feature representations. The Siamese Network effectively distinguishes between phishing and legitimate URLs by comparing the latent representations of URL pairs. Central to this approach is a specially curated pairwise dataset of phishing and legitimate URLs meticulously designed to facilitate fine-grained similarity analysis. This paired dataset enables the model to capture subtle distinctions between the two URL classes. Rigorous evaluation, including a dedicated test set of traditional and AI-generated URLs, demonstrates the model’s robust generalization capability. This innovative twin LSTM-based framework sets a new benchmark in phishing detection, providing a scalable, adaptive solution to combat increasingly sophisticated attacks.},
  archive      = {J_KBS},
  author       = {Sruthi K and Manohar Naik S},
  doi          = {10.1016/j.knosys.2025.114271},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114271},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel framework for effective phishing URL detection using an LSTM-based siamese network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer. <em>KBS</em>, <em>329</em>, 114270. (<a href='https://doi.org/10.1016/j.knosys.2025.114270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-style transfer aims to rewrite source texts into a target style while preserving their core content. However, challenges such as the lack of parallel training data and the difficulty in balancing style transfer with content preservation remain significant. To address these issues, we propose a novel unsupervised text-style transfer framework, the Style Mamba Transformer, based on the adversarial generative network (GAN) architecture. This framework includes a hybrid encoder that combines Transformer and Mamba blocks, leverages skip connections to enhance feature reuse, and focuses on the style intensity of individual tokens. This design enables high-precision style transfer while preserving the text content. Our model outperforms other similar style-transfer models, such as MSSRNet, in terms of both style transfer accuracy and content preservation. On two benchmark datasets, the Yelp Review Dataset and IMDb Movie Review Dataset, our model achieved a transfer accuracy of 97.5 % and a BLEU score of 59.3, as well as a transfer accuracy of 95.1 % and a BLEU score of 64.2, respectively.},
  archive      = {J_KBS},
  author       = {Deyu Meng and Ziheng Wang and Wenhao Yan and Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1016/j.knosys.2025.114270},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114270},
  shortjournal = {Knowl. Based Syst.},
  title        = {Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based anomaly representation enhancement on graphs. <em>KBS</em>, <em>329</em>, 114268. (<a href='https://doi.org/10.1016/j.knosys.2025.114268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is significantly challenged by information loss during graph embedding, label scarcity, and intricate structural patterns. While graph neural networks (GNNs) have advanced the field, their efficacy is often limited by sensitivity to data quality and oversmoothing. This paper introduces DARE-G, a novel diffusion-based anomaly detection framework that leverages conditional and unconditional diffusion models to mitigate these limitations. Our approach features a dual-phase diffusion process: conditional anomaly augmentation to synthesize realistic anomalous patterns, and unconditional graph denoising to alleviate information loss and enhance the distinction between normal and anomalous node representations. Extensive experiments on both synthetic and real-world datasets demonstrate DARE-G’s significant superiority over state-of-the-art methods, achieving an 8.76 percentage point increase in AUC-ROC compared to the best-performing baselines. Ablation studies further validate the framework’s robustness across various GNN backbones, highlighting the critical role of denoising steps in capturing multi-hop structural anomalies. The proposed method establishes new benchmarks for graph anomaly detection, particularly in scenarios with extreme label sparsity and adversarial camouflage.},
  archive      = {J_KBS},
  author       = {Jian Zhang and Yitong Li and Zhen Wang},
  doi          = {10.1016/j.knosys.2025.114268},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114268},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion-based anomaly representation enhancement on graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTMA: Optimal transfer modality alignment for visible-thermal person re-identification. <em>KBS</em>, <em>329</em>, 114267. (<a href='https://doi.org/10.1016/j.knosys.2025.114267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible thermal person re-identification (VT-ReID) is a crucial task in real-world surveillance systems, primarily challenged by significant cross-modality discrepancies and intra-class variations. While numerous methodologies have been developed to address this issue by optimizing instance similarity across modalities, they often overlook the impact of intra-class variations on cross-modality alignment. To handle this issue, we propose Optimal Transfer Modality Alignment (OTMA), a method designed to mitigate the impact of intra-class variations during cross-modality alignment. Specifically, OTMA utilizes the Earth Mover’s Distance (EMD) to establish an initial transfer strategy between the two modalities. To avoid the unintended alignment of cross-modality negative pairs, OTMA further refines the EMD-based transfer weights by suppressing excessively high weights assigned to negative pairs and enhancing insufficient weights of positive pairs. In this manner, OTMA mitigates the adverse effects of intra-class variations during modality alignment and reduces the risk of aligning cross-modality negative pairs, thereby achieving a better balance between alignment and discriminative optimization. Additionally, two complementary techniques are introduced to further enhance the effectiveness of OTMA. First, Cross-Modality Discrimination Learning (CM-DL) is proposed to alleviate the degradation of feature discrimination caused by OTMA by regulating the variance ratio between intra-class and inter-class distributions. Second, a Multi-Granularity Structure (MGS) is designed to facilitate modality alignment at both coarse and fine levels, enabling OTMA to capture more comprehensive cross-modality correspondences. Extensive experiments conducted on two datasets demonstrate the effectiveness and advantages of the proposed OTMA method, along with its supplementary techniques, in significantly improving cross-modality matching performance.},
  archive      = {J_KBS},
  author       = {Yongguo Ling and Zihao Hu and Gangzhu Lin and Shaozi Li and Min Jiang},
  doi          = {10.1016/j.knosys.2025.114267},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114267},
  shortjournal = {Knowl. Based Syst.},
  title        = {OTMA: Optimal transfer modality alignment for visible-thermal person re-identification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN. <em>KBS</em>, <em>329</em>, 114266. (<a href='https://doi.org/10.1016/j.knosys.2025.114266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain pedestrian trajectory prediction is crucial in fields such as autonomous driving, robotics and video surveillance. Due to the inherent diversity and uncertainty of pedestrian trajectories, they exhibit various behavioral patterns. However, most existing cross-domain methods neglect these behavioral differences by employing a unified network with shared parameters, modeling all trajectories in the same manner. This often results in biased knowledge transfer and reduced prediction accuracy. To address this, a model based on behavioral pattern-aware multi-instance graph convolutional networks, called PMITra, is proposed for cross-domain pedestrian trajectory prediction. PMITra consists of three core modules. The trajectory embedding module uses a pretrained micro-model to extract spatiotemporal features from trajectories. The pattern-aware interaction module extracts and aggregates behavioral patterns through deep clustering, and employs a multi-instance graph convolutional network to enable fine-grained knowledge transfer among trajectories exhibiting the same behavioral patterns. The pattern alignment module constructs an attention-based pattern loss to align the pedestrian feature representations weighted by pattern probabilities. PMITra achieves state-of-the-art performance on the ETH/UCY pedestrian trajectory datasets, with comprehensive ablation studies validating the effectiveness of each module.},
  archive      = {J_KBS},
  author       = {Haifeng Yang and Yi Chen and Jianghui Cai and Yuqing Yang and Lichan Zhou and Jianing Tian and Yan Li and Yaling Xun and Xujun Zhao},
  doi          = {10.1016/j.knosys.2025.114266},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114266},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling. <em>KBS</em>, <em>329</em>, 114265. (<a href='https://doi.org/10.1016/j.knosys.2025.114265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving relies on high-precision 3D perception. Multi-camera 3D object detection is limited by long-tail distribution issues, making it difficult to comprehensively recognize all object categories. In contrast, 3D occupancy prediction unifies the perception of foreground and background by partitioning the 3D space into semantically labeled voxel grids, thereby providing more effective support for driving safety. This paper proposes an innovative panoramic semantic occupancy perception model, DFOcc, designed to enhance the 3D scene understanding capability of autonomous driving systems. DFOcc takes multi-camera images as input and first constructs a 3D voxel feature space through multi-scale feature extraction and the Lift-Splat-Shoot (LSS) method. It then employs an occupancy decoder to predict the occupancy state of each voxel in the scene. To further improve perception accuracy and computational efficiency, ELANet is adopted as the backbone network to enhance 2D visual feature extraction and accelerate model training. Additionally, an improved class-guided sampling strategy combined with the Focal Loss function is proposed to alleviate class imbalance issues, thereby enhancing detection performance for sparse objects and low-frequency categories. Furthermore, an automatic annotation method based on scene flow estimation is introduced, which generates high-quality dense occupancy labels and velocity ground truth labels, eliminating the reliance on 3D bounding box annotations and significantly reducing data construction costs. Experimental results on the nuScenes dataset demonstrate that DFOcc achieves significant improvements in both accuracy and generalization for 3D occupancy perception. Compared to the recently proposed TPVFormer and OccFormer models, DFOcc improves the mean Intersection over Union (mIoU) by 2.1 and 0.9, respectively, and attains performance comparable to state-of-the-art LiDAR-based methods.},
  archive      = {J_KBS},
  author       = {Ruijie Shan and Yanchun Zhang and Jian Zeng},
  doi          = {10.1016/j.knosys.2025.114265},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114265},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection. <em>KBS</em>, <em>329</em>, 114264. (<a href='https://doi.org/10.1016/j.knosys.2025.114264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of cognitive disorders such as Alzheimer’s disease is critical for enabling timely clinical intervention and improving patient outcomes. In this work, we introduce CogniAlign, a multimodal architecture for Alzheimer’s detection that integrates audio and textual modalities, two non-intrusive sources of information that offer complementary insights into cognitive health. Unlike prior approaches that fuse modalities at a coarse level, CogniAlign leverages a word-level temporal alignment strategy that synchronizes audio embeddings with corresponding textual tokens based on transcription timestamps. This alignment supports the development of token-level fusion techniques, enabling more precise cross-modal interactions. To fully exploit this alignment, we propose a Gated Cross-Attention Fusion mechanism, where audio features attend over textual representations, guided by the superior unimodal performance of the text modality. In addition, we incorporate prosodic cues, specifically interword pauses, by inserting pause tokens into the text and generating audio embeddings for silent intervals, further enriching both streams. We evaluate CogniAlign on the ADReSSo dataset, where it achieves an accuracy of 87.35 % over a Leave-One-Subject-Out setup and of 90.36 % over a 5 fold Cross-Validation, outperforming existing state-of-the-art methods. A detailed ablation study confirms the advantages of our alignment strategy, attention-based fusion, and prosodic modeling. Finally, we perform a corpus analysis to assess the impact of the proposed prosodic features and apply Integrated Gradients to identify the most influential input segments used by the model in predicting cognitive health outcomes.},
  archive      = {J_KBS},
  author       = {David Ortiz-Perez and Manuel Benavent-Lledo and Javier Rodriguez-Juan and Jose Garcia-Rodriguez and David Tomás},
  doi          = {10.1016/j.knosys.2025.114264},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114264},
  shortjournal = {Knowl. Based Syst.},
  title        = {CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction. <em>KBS</em>, <em>329</em>, 114263. (<a href='https://doi.org/10.1016/j.knosys.2025.114263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of the rapid evolution and escalating complexity of financial markets, precise stock price prediction has become a critical area of research for scholars and practitioners alike. Stock markets are subject to a vast array of influencing factors, both internal and external, which complicates prediction efforts. This study proposes BiMT-TCN, a novel model combining Bidirectional Long Short-Term Memory (BiLSTM), a modified Transformer, and Temporal Convolutional Network (TCN), aimed at enhancing the accuracy and stability in stock price prediction. BiLSTM facilitates the capture of bidirectional dependencies, which aids in decoding the intricate patterns within time-series data. The modified Transformer integrates global information, enhancing the model’s capacity to manage long-range dependencies effectively. TCN, known for its parallel processing and proficiency in capturing deep historical patterns, further bolsters model stability and generalizability. Empirical evaluations on major indices such as SSE, HSI, and NASDAQ demonstrate that BiMT-TCN consistently outperforms state-of-the-art models, achieving R 2 scores of 0.9779, 0.9776, and 0.9969 respectively, along with significantly lower RMSE, MAE, and MAPE values. The implications of this work extend to practical investment decision-making, where improved forecast precision can enhance risk management, optimize trading strategies, and inform financial planning in volatile markets.},
  archive      = {J_KBS},
  author       = {Guangyang Tian and Tingwen Huang and Chengyu Peng and Yin Yang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114263},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114263},
  shortjournal = {Knowl. Based Syst.},
  title        = {BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system. <em>KBS</em>, <em>329</em>, 114261. (<a href='https://doi.org/10.1016/j.knosys.2025.114261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of people affected by cardiac diseases is increasing extremely. Heart attacks are most common and painful disease. According to the World Health Organization, this disease kills around 17.5 million people each year. In this paper, Cardiac Disease Detection using Temporal Attention Recurrent Graph Convolutional Neural Network based Smart Wearable System (CDD-SWS-TRGCNN) is proposed. The proposed method uses to monitor and signal a patient's current heart status based on necessary heart diagnosis signal. Initially, input data are collected from cardiovascular disease dataset and cardio health risk assessment dataset. The collected dataset are pre-processed with the nonlinear adaptive backscatter filter (NABF) is employed for normalizing the data. After preprocessing, the Lifted Euler Characteristic Transform (LECT) is used to extract statistical features like Mean, Standard Deviation, Kurtosis, Skewness, entropy. These features are then used by TARGCNN for classifying cardiac disease as cardiac and healthy in the cardiovascular disease dataset and presence and absence in the cardio health risk assessment dataset. To enhance accuracy, the Wolf-Bird Optimizer (WBO) is utilized to optimize TARGCNN parameters, ensuring precise cardiac disease classification. The proposed CDD-SWS-TRGCNN method is implemented in Python. The proposed method achieves 23.11%, 24.96%, 25.23% higher accuracy; 31.10%, 33.02% and 29.98% higher precision when compared with existing techniques like SWS-CAM-RFA, PHD-WD-CNN, and WMD-HDD-IoT respectively.},
  archive      = {J_KBS},
  author       = {Mr Jibin E P ( Research Scholar ) and Dr Menaka D ( Associate Professor )},
  doi          = {10.1016/j.knosys.2025.114261},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114261},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model. <em>KBS</em>, <em>329</em>, 114260. (<a href='https://doi.org/10.1016/j.knosys.2025.114260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images from multi-center, multi-modality, and multi-source datasets (3M Datasets) is critical for clinical applications such as diagnosis and image-guided intervention. However, existing models often struggle with image heterogeneity, blurry boundaries, and low contrast, which severely affect segmentation accuracy. Diffusion Probabilistic Models (DPMs) have shown promise in modeling complex data distributions and capturing fine-grained structures. Yet, their generalization capability and detail recovery remain limited when applied to 3M Datasets. To address these challenges, we propose D M 3 diff, a novel medical image segmentation framework that integrates Discrete Wavelet Transform (DWT) with DPMs. Specifically, we introduce a Self-adaptive Wavelet Transform Feature Aggregation Module (SWT-FAM) to serve as a high-pass filter that preserves high-frequency details while suppressing noise and redundancy. Furthermore, we design a Multi-Stage Detail Control Block (MS-DCB) that utilizes Kullback-Leibler divergence to align the distributions of generated and target images, enabling multi-scale control of structure and detail during the denoising process. We evaluate our method on three benchmark anatomical datasets. D M 3 diff achieves consistent improvements over state-of-the-art methods, with Dice scores reaching up to 92.4 % on ISIC, and notable gains in IOU, sensitivity, and Hausdorff distance across all datasets.},
  archive      = {J_KBS},
  author       = {Dong Sui and Xiao Tian and Yacong Li and Maozu Guo and Xiangyu Li and Kuanquan Wang and Gongning Luo},
  doi          = {10.1016/j.knosys.2025.114260},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114260},
  shortjournal = {Knowl. Based Syst.},
  title        = {DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lag selection in feature-based clustering of time series. <em>KBS</em>, <em>329</em>, 114258. (<a href='https://doi.org/10.1016/j.knosys.2025.114258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based time series clustering methods typically involve extracting vectors of statistical quantities that capture the serial dependence structure of each time series in the dataset. These feature vectors are then used as input to a standard clustering algorithm. In the feature extraction step, the user usually selects a set of lags of interest in advance, a choice that can significantly affect clustering accuracy. This article addresses this limitation by introducing a natural approach in which the set of lags is automatically selected as part of the clustering optimization process. The effectiveness of the proposed methodology is demonstrated through simulations and real data applications.},
  archive      = {J_KBS},
  author       = {Ángel López-Oriona and Ying Sun},
  doi          = {10.1016/j.knosys.2025.114258},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114258},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lag selection in feature-based clustering of time series},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting. <em>KBS</em>, <em>329</em>, 114257. (<a href='https://doi.org/10.1016/j.knosys.2025.114257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sunspots, the dark patches observed on the surface of the Sun, exhibit cyclical behavior with significant implications for various terrestrial phenomena. Forecasting sunspots accurately is crucial for understanding solar activity and its impact on Earth’s climate and technology-dependent systems. In this study, we propose a novel approach for sunspots forecasting utilizing ambiguous set theory. Using ambiguous set theory, a time series forecasting model is proposed, called ambiguous time series forecasting model (ATSFM) . We begin by collecting historical sunspots spanning from 1700 to 2023. Next, apply ATSFM, which incorporates the ambiguity inherent in sunspots. The ATSFM begins with the partitioning the sunspots with equal-length intervals. For this purpose, this study employs Riemann integration that assists for partitioning the universe of discourse of the sunspots into various equal-length intervals. Then, ambiguous entropy (AE) is calculated for each of the distributed sunspots in equal-length intervals. Ambiguous entropy relationships (AERs) and ambiguous entropy relationship groups (AERGs) are formulated to describe the relationships between previous and current sunspots. Finally, unambiguousness process is applied to obtain forecasted values from the AERGs. To evaluate the ATSFM’s performance, we compare its forecasting accuracy with existing methods, including traditional statistical and machine learning methods. Various statistical measures are used to assess the ATSFM’s forecasting capability. Our experimental results demonstrate that the ATSFM outperforms existing methods, yielding more accurate forecasting results of sunspots. To enhance reproducibility, the source code will be made available upon request by contacting the corresponding author via email.},
  archive      = {J_KBS},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.knosys.2025.114257},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114257},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering. <em>KBS</em>, <em>329</em>, 114253. (<a href='https://doi.org/10.1016/j.knosys.2025.114253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Vehicles (AVs) promise safer and more efficient transportation but remain vulnerable to security threats when trained using Federated Learning (FL). While FL preserves privacy by enabling decentralized training, it is particularly exposed to model poisoning (Byzantine attacks) and adversarial threats (evasion attacks). Traditional defenses, such as robust aggregation and adversarial training (AT), often degrade accuracy under Non-Independent and Identically Distributed data (non-IID). To overcome these challenges, we propose a lightweight defense framework that combines AT, supervised contrastive learning (SCL), and spatial robust aggregation. It includes (1) Pre-Defense Training , using Wasserstein-based Projected Gradient Descent (PGD) adversarial samples; (2) Robust AT with SCL , extending Model-Contrastive (MOON) with a second contrastive objective to improve model resilience and alignment for both local and FL versions; and (3) Spatial Robust Aggregation , using pairwise Wasserstein distance and 2-median clustering to filter outliers. FL pretraining was applied to accelerate convergence and enhance performance. Extensive experiments conducted with three benchmark datasets confirmed that our defense consistently outperforms other state-of-the-art methods. Our approach effectively defends against stealthy model poisoning and adversarial attacks, with only minor accuracy drops observed under extreme attack scenarios. For instance, in CIFAR-10, the clean accuracy drops from 93 % to 82 % in the IID setting and from 88 % to 75 % in the non-IID setting. This demonstrates that the proposed design represents a new benchmark for secure and reliable FL in adversarial environments. We also aim to demonstrate the practical benefits of our approach in reducing traffic accidents and congestion when deployed in AV systems.},
  archive      = {J_KBS},
  author       = {Suzan Almutairi and Ahmed Barnawi},
  doi          = {10.1016/j.knosys.2025.114253},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114253},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis. <em>KBS</em>, <em>329</em>, 114251. (<a href='https://doi.org/10.1016/j.knosys.2025.114251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing fault diagnosis under varying working conditions faces challenges, including lack of labeled data, distribution discrepancies, and resource constraints. To address these issues, we propose a progressive knowledge distillation framework that transfers knowledge from a complex teacher model, utilizing a Graph Convolutional Network (GCN) with Autoregressive moving average (ARMA) filters, to a compact and efficient student model. To mitigate distribution discrepancies and labeling uncertainty, we introduce Enhanced Local Maximum Mean Square Discrepancy (ELMMSD), which leverages mean and variance statistics in the Reproducing Kernel Hilbert Space (RKHS) and incorporates a priori probability distributions between labels. This approach increases the distance between clustering centers, bridges subdomain gaps, and enhances subdomain alignment reliability. Experimental results on benchmark datasets (CWRU and JNU) demonstrate that the proposed method achieves superior diagnostic accuracy while significantly reducing computational costs. Comprehensive ablation studies validate the effectiveness of each component, highlighting the robustness and adaptability of the approach across diverse working conditions.},
  archive      = {J_KBS},
  author       = {Mohammadreza Kavianpour and Parisa Kavianpour and Amin Ramezani and Mohammad Th Beheshti},
  doi          = {10.1016/j.knosys.2025.114251},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114251},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CUOM: A causal unbiased optimization method for federated domain generalization. <em>KBS</em>, <em>329</em>, 114249. (<a href='https://doi.org/10.1016/j.knosys.2025.114249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Domain Generalization (FedDG) aims to develop robust models for multi-domain discrete data, enabling generalization to unseen domains while ensuring data privacy. It facilitates collaborative training among multiple institutions, producing efficient models that generalize across diverse contexts. Existing methods emphasize extracting global domain-invariant features but frequently neglect client-specific data biases, resulting in models that learn non-causal, biased feature prototypes with limited generalization. To address this challenge, we propose a Causal Unbiased Optimization Method (CUOM) for FedDG, aimed at achieving unbiased feature learning both within and across domains. Specifically, we introduce a Structural Causal Model (SCM) based on a novel causal inference framework to analyze both data and prototype biases. Leveraging this SCM, we design the Generalization Compensation Module (GCM) and the Unbiased Prototype Learning Module (UPLM). The Generalization Compensation Module facilitates intra- and cross-domain data augmentation separately, distinguishing itself from traditional single perspective approaches. It aims to simulate domain diversity, thereby mitigating data bias more effectively. The Unbiased Prototype Learning Module integrates representation alignment loss and prototype contrastive loss to guide the model in learning instance-level unbiased features robust to prototype bias in both original and augmented data. Extensive experiments show that our method outperforms existing state-of-the-art methods in generalization across multiple benchmarks. Our code is available at https://github.com/dhaksndg/CUOM .},
  archive      = {J_KBS},
  author       = {Mi Wen and Kang Han and DongYang Li and QiYe Cai and HaiLun Shen},
  doi          = {10.1016/j.knosys.2025.114249},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114249},
  shortjournal = {Knowl. Based Syst.},
  title        = {CUOM: A causal unbiased optimization method for federated domain generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive active learning framework for sparsely labeled multi-label drifting data streams. <em>KBS</em>, <em>329</em>, 114248. (<a href='https://doi.org/10.1016/j.knosys.2025.114248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label data streams consist of sequential instances, each associated with multiple labels, continuously arriving for classification. This setting presents several challenges, including dynamic data distributions, limited labeled data, high labeling costs, and the computational burden of continuous model updates in the presence of concept drift. Although various solutions have been proposed for multi-label data stream classification, they often exhibit a notable limitation in addressing online learning from sparsely labeled data streams and adapting to concept drift with competitive performance. To approach this gap, this paper introduces Multi-Label Active Learning for Drifting Data Streams (MLALDDS), a novel framework tailored for multi-label drifting streams, tackling key issues through single-pass active learning, incremental updates, and effective adaptation to concept drift. MLALDDS employs a self-adjusting k-nearest neighbor classifier within a binary relevance architecture to decompose the multi-label classification problem into simpler tasks. A budget-aware selective sampling strategy is used to query only the most informative instances, minimizing labeling costs while maintaining classification performance. Model updates are conducted incrementally, and a reflective mechanism leverages ADWIN to deliver precise warnings of potential data distribution changes, ensuring individual label-specific classifiers adapt efficiently to concept drift within their respective subspaces. The proposed framework was evaluated on 30 diverse multi-label datasets against 20 state-of-the-art classifiers using 12 performance metrics. Results from nonparametric statistical analysis demonstrate that MLALDDS consistently outperforms competing methods, confirming the effectiveness of its key components in improving classification performance.},
  archive      = {J_KBS},
  author       = {Reza Rahimian and Hoda Mashayekhi and Maryam Khodabakhsh},
  doi          = {10.1016/j.knosys.2025.114248},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114248},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive active learning framework for sparsely labeled multi-label drifting data streams},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding. <em>KBS</em>, <em>329</em>, 114242. (<a href='https://doi.org/10.1016/j.knosys.2025.114242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graph embedding aims to map each node into compact, low-dimensional vectors that preserve the intrinsic properties of the graph. The effectiveness of these embeddings is crucial for capturing structural information and node relationships, which directly impacts the performance of downstream applications such as recommender systems and bioinformatics. However, due to the inherent sparsity and large scale of many real-world bipartite graphs, existing methods often suffer from missing contextual information and excessive feature smoothing. In this paper, we take the first step toward systematically addressing the challenges of embedding large and sparse bipartite graphs. To this end, we propose Adaptive Anchor-based Graph Attention Networks (A 2 GAT), a novel framework that integrates entropy regularization to ensure a balanced distribution of attention weights, preserve feature distinctiveness, and mitigate over-smoothing. In addition, we design an adaptive anchor node generation mechanism and introduce a fully connected attention (FCA) module that dynamically adjusts interaction weights, effectively addressing sparse connectivity and enhancing representation learning in low-density regions. Extensive experiments on eight benchmark datasets demonstrate the effectiveness and generalizability of our model across both recommendation and link prediction tasks.},
  archive      = {J_KBS},
  author       = {Linlin Ding and Yiming Han and Mo Li and Ningning Cui and Xin Wang and Renata Borovica-Gajic},
  doi          = {10.1016/j.knosys.2025.114242},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114242},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA dropout as a sparsity regularizer for overfitting reduction. <em>KBS</em>, <em>329</em>, 114241. (<a href='https://doi.org/10.1016/j.knosys.2025.114241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks. However, fine-tuning LoRA-series models also faces the risk of overfitting on small training datasets, and there’s still a lack of theoretical guidance and practical mechanisms to control overfitting on LoRA-based PEFT methods. This paper introduces a novel dropout-based sparsity regularizer for LoRA, dubbed LoRA Dropout, which mitigates overfitting by applying refined dropout to LoRA’s low-rank matrices. We establish a theoretical framework that models dropout in LoRA as a sparse fine-tuning process and derive a generalization error bound under this sparsity regularization. Theoretical results show that appropriate sparsity can tighten the gap between empirical and generalization risks and thereby control overfitting. We further enhance the sparsity patterns in conventional dropout methods and propose an innovative LoRA Dropout method for more precise sparsity regularization to achieve better overfitting reduction. Furthermore, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound and lead to better performance. Extensive experiments on various tasks validate the effectiveness of our LoRA Dropout framework in improving the model’s performance.},
  archive      = {J_KBS},
  author       = {Yang Lin and Xinyu Ma and Xu Chu and Yujie Jin and Zhibang Yang and Yasha Wang},
  doi          = {10.1016/j.knosys.2025.114241},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114241},
  shortjournal = {Knowl. Based Syst.},
  title        = {LoRA dropout as a sparsity regularizer for overfitting reduction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential hash representation for deep hashing-based image retrieval. <em>KBS</em>, <em>329</em>, 114229. (<a href='https://doi.org/10.1016/j.knosys.2025.114229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision, convolutional neural networks have significantly improved the effectiveness of deep hashing-based image retrieval. However, existing deep hashing techniques often regard hash codes as spatial features. It leads to insensitivity of existing hash representations to spatial shifts in real number space which can be explained by mismatch between the real number space and the Hamming space. In response to these limitations, this paper introduces SeqHash, a novel approach grounded in sequential hash representation. Diverging from existing deep hashing methods, SeqHash treats hash codes as hash sequences. Benefiting from the sequential properties of chaos theory and the robust fitting capabilities of Kolmogorov-Arnold Networks (KANs), SeqHash constructs a hash-coding layer called sequence-KAN layer to produce hash codes as sequential outputs in the processes of hash encoding and category hash centers generation. Furthermore, SeqHash devises a loss function that facilitates convergence of the sequential outputs to reach the stable states of the predefined sequence in temporal domain. The error propagation of sequential hash representation and the randomness of chaos mapping facilitate each hash code bit to be contingent upon its previous bits, and endow hashing with higher sensitivity to spatial shifts in real number space. This property aligns the shifts in Hamming space and real number space during training and capture the differences among samples effectively. The quantitative and qualitative experiments demonstrate that SeqHash offers remarkable performance in image retrieval tasks and yields more discernible hash codes compared to other cutting-edge deep hashing algorithms.},
  archive      = {J_KBS},
  author       = {Yinqi Chen and Yangting Zheng and Zhiyi Lu and Peiwen Li and Wenbin He and Shuo Kang and Xiang Gao},
  doi          = {10.1016/j.knosys.2025.114229},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114229},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential hash representation for deep hashing-based image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADR-net: Attention-oriented detail recovery network for document image shadow removal. <em>KBS</em>, <em>329</em>, 114228. (<a href='https://doi.org/10.1016/j.knosys.2025.114228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods based on deep learning have extensively explored the problem of document image shadow removal. However, most of them seldom consider the key regions of complex shadows and ignore detail preservation. Moreover, they usually have large model parameters that limit the potential values in real-world applications. To address these issues, we propose a simple but effective Attention-oriented Detail Recovery Network (ADR-Net) to remove complex shadows while preserving details in low complexity. In particular, on one hand, we explore the properties of shadows in color space and use luminance information to guide and generate shadow attention maps, which can accurately capture complex shadow distributions. For this purpose, we further design a Shadow Attention Generation Sub-Network (SAGN) that uses Multi-scale Large Kernel Attention (MLKA) mechanism to obtain long-range dependencies of shadows at various granularity levels. On the other hand, we propose a Dynamic Fusion (DF) strategy to avoid the ambiguity issues from wrong attention map during the learning process. In addition, we propose a Detail Refinement Sub-Network (DRN) that adopts Lightweight Spatial-Channel Convolution (LSCC) to facilitate recover details while decreasing redundant computing. Extensive experiments on public benchmarks and Optical Character Recognition (OCR) performance validate the effectiveness of our proposed ADR-Net and its superiority over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fan Yang and Nanfeng Jiang and Da-Han Wang and Xu-Yao Zhang and Yun Wu and Shunzhi Zhu},
  doi          = {10.1016/j.knosys.2025.114228},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114228},
  shortjournal = {Knowl. Based Syst.},
  title        = {ADR-net: Attention-oriented detail recovery network for document image shadow removal},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic interaction and router selection network for multi-modality biometric recognition. <em>KBS</em>, <em>329</em>, 114223. (<a href='https://doi.org/10.1016/j.knosys.2025.114223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality biometric recognition has attracted significant attention owing to its benefits of convenient acquisition, high security, and accurate recognition. However, most existing modality-fusion methods are static and rely on expert experience or knowledge to design interaction models, which limits their flexibility. Additionally, these interaction models fail to adaptively respond to the evolving and complex intra- and inter-modal relationships, thereby limiting the ability of the model to capture diverse and intricate patterns. To address these issues, we propose a dynamic interaction and router selection network, enabling the adaptive learning of previously unexplored interaction patterns. We designed three progressive interaction units, which are responsible for preserving unique modality information, aligning and enhancing modality features, and dynamically reinforcing inter-modality channel and intra-modality spatial interactions. Dynamic soft router is incorporated into each interaction unit, enabling the generation of an adaptive interaction path that is determined by sample complexity. In addition, within the interaction units, we propose a novel inter-channel and intra-spatial modality interaction fusion unit, which incorporates a dynamic inter-modality linear channel interaction unit and an intra-modality bidirectional multiscale attention unit. By leveraging dynamically reconstructed inter-modality channel features, the unit progressively guides intra-modality spatial features, thereby enhancing the complementarity of inter-modality features and improving the discriminability of intra-modality features. In contrast to nonextensible methods, which suffer from limitations in constrained by limited flexibility, our approach enables simultaneous integration of data across multiple modalities. Extensive experiments conducted on four databases demonstrate that the proposed model significantly outperforms current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xiao Yang and Hai Yuan and Jie Hu and Zaiyu Pan and Zhengwen Shen and Jun Wang},
  doi          = {10.1016/j.knosys.2025.114223},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114223},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic interaction and router selection network for multi-modality biometric recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontology-based data federation and query optimization. <em>KBS</em>, <em>329</em>, 114216. (<a href='https://doi.org/10.1016/j.knosys.2025.114216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology-based data access (OBDA), also known as virtual knowledge graphs (VKG), is a well-established approach to information management that facilitates the access to a (single) relational data source through the mediation of a high-level ontology, and the use of a declarative mapping linking the data layer to the ontology. In order to integrate multiple, possibly distributed and heterogeneous, data sources, in this work we formally introduce an extension of OBDA, called ontology-based data federation (OBDF), by combining OBDA with a data federation layer, which can expose multiple data sources as a single relational database. We discuss opportunities and challenges of OBDF, and provide techniques to deliver efficient query answering in OBDF by exploiting inter-source relations (called data hints) in the federated sources. Such techniques are validated through an extensive experimental evaluation based on the Berlin SPARQL Benchmark.},
  archive      = {J_KBS},
  author       = {Zhenzhen Gu and Davide Lanti and Francesco Corcoglioniti and Marco Di Panfilo and Alessandro Mosca and Diego Calvanese and Guohui Xiao},
  doi          = {10.1016/j.knosys.2025.114216},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114216},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ontology-based data federation and query optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding. <em>KBS</em>, <em>329</em>, 114212. (<a href='https://doi.org/10.1016/j.knosys.2025.114212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how humans process visual information is one of the key steps in revealing the underlying mechanisms of the brain. Recent research has significantly progressed in brain signal decoding and visual content reconstruction. However, due to complex noise and insufficient alignment accuracy, methods for extracting effective information from electroencephalogram (EEG) are still limited. Existing decoding strategies often fail to adequately represent the fine-grained information of visual embeddings and struggle to deal with data scarcity. To address these issues, we propose the PinVC ( P inpointing V isual C ontent) framework, which aims to integrate fine-grained multimodal information in EEG signals and represent similar activation patterns cross-subject to enhance the accuracy of EEG representation and visual decoding. This method introduces a feature adaptation mechanism that mitigates individual differences and noise effects by masking attention, thus ensuring cross-subject generalizability. In addition, we align the EEG with the implicit target semantic embedding of the LLM and construct a spatial information attention (SIA) module to extract spatial features, thus further improving the quality of the multilevel reconstructed images. PinVC provides accurate multimodal guidance for the pre-trained generative model. We conducted rigorous experimental evaluations on different datasets as well as downstream tasks including visual reconstruction and caption generation, demonstrating PinVC’s excellent performance and generalization. Our project is available at https://github.com/HolderXJTU/PinVC .},
  archive      = {J_KBS},
  author       = {Haodong Jing and Yongqiang Ma and Panqi Yang and Haibo Hua and Nanning Zheng},
  doi          = {10.1016/j.knosys.2025.114212},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114212},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm. <em>KBS</em>, <em>329</em>, 114093. (<a href='https://doi.org/10.1016/j.knosys.2025.114093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Citrus is vital for vitamin C production, but existing disease classification methods struggle with low accuracy due to poor feature representation, limited complex pattern handling and weak fusion under varied textures and lighting. To overcome these complications, Citrus Plant Classification using Gated Fusion Adaptive Graph Neural Network with Harbor Seal Whiskers Optimization Algorithm (CPC-GFAGNN HSWOA) is proposed. Here, the images are taken from Citrus leaf dataset. Afterwards the images are fed into the pre-processing stage. In preprocessing, Unsharp Structure Guided Filtering (USGF) is applied to eliminate noise from the input images. The pre-processed images are given to the Semantic Invariant Multi-view Clustering (SIMVC) for segmenting region of interest from the citrus leaf images. Next, the segmented images are supplied to the feature extraction process. By using Feature Affine Residual Network (FA-ResNet), the features are extracted, like shapes, colors and textures. The extracted features are fed into the Gated Fusion Adaptive Graph Neural Network (GFAGNN) to classify the citrus leaf images as Black Spot, Canker, Greening, Healthy and Melanose. Finally, Harbor Seal Whiskers Optimization Algorithm (HSWOA) is employed to improve the weight parameter of GFAGNN. This combination effectively mitigates issues such as over fitting, class imbalance and suboptimal feature learning, resulting in robust and accurate classification of citrus leaf diseases. The proposed CPC-GFAGNN HSWOA method is implemented and performance is evaluated using metrics. The experimental results shows that the proposed CPC-GFAGNN HSWOA method achieves 18.75 %, 26.89 %, 32.57 % better accuracy, 18.43 %, 25.64 %, 31.40 % better sensitivity when compared with existing AD-CPL-DNN, SA-DNN CDD and CL-DC CNN models respectively.},
  archive      = {J_KBS},
  author       = {Aswini E and C. Vijayakumaran},
  doi          = {10.1016/j.knosys.2025.114093},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114093},
  shortjournal = {Knowl. Based Syst.},
  title        = {Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding word positions with polar coordinates. <em>KBS</em>, <em>329</em>, 113903. (<a href='https://doi.org/10.1016/j.knosys.2025.113903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word positions provide grammatical information and help identify linguistic structures. Recent works have shown that the positions of words in a sentence play an important role in natural language processing (NLP). In this paper, we propose a novel method using polar coordinates to embed word positions. The main idea is to decouple a position embedding into a semantic component and a sequential order component, which are implemented by the polar radius and the polar angle respectively. We further propose a Polar-Fix module and plug it in the conventional Transformer encoder. This module (1) enables the stacked Transformer networks to maintain the polarized representation and (2) avoids the danger of over tuning the context-free parameters that are independent on the contexts. Experimental results on three classic NLP tasks, i.e., language modeling, text classification and semantic similarity, show that our method achieves significant improvements over the state-of-the-art Transformer based models. The visualization of polar embeddings indicates that our model is highly interpretable.},
  archive      = {J_KBS},
  author       = {Xiaotang Wen and Chen Yan and Huimin Huang and Hong Shen},
  doi          = {10.1016/j.knosys.2025.113903},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113903},
  shortjournal = {Knowl. Based Syst.},
  title        = {Embedding word positions with polar coordinates},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redundancy reduction penalty term of loss function in deep neural network. <em>KBS</em>, <em>329</em>, 113776. (<a href='https://doi.org/10.1016/j.knosys.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel regularization algorithm that is introduced as a penalty term to the loss function. Differing from conventional L1 and L2 regularization methods, our approach does not aim to diminish the weights of individual neurons or enforce sparsity by driving certain neurons to zero. Instead, it functions by increasing the differences between neurons and enhancing the diversity of neurons within each layer. Our method incorporates ensemble learning techniques by treating the layer weight matrix as a collective learning model, where each neuron serving as a weak learner within the layer. The proposed algorithm improves the performance of DCNN by simultaneously considering the distance between multiple filters in the same layer. This algorithm reduces the redundancy of the parameter layer filters in DCNN and enhances its robustness. The penalty term proposed by our algorithm dynamically adjusts its value in a cyclical manner, compelling the neural network to navigate away from its current gradient state. In the parameter space, different weights correspond to different locations. The proposed algorithm quantifies the distance between neurons and iteratively increases the distance between neurons during thereby encouraging greater diversity within the network. Experimental evaluations demonstrate the effectiveness of our algorithm in enhancing neural network performance without requiring adjustments to other hyper-parameters.},
  archive      = {J_KBS},
  author       = {Xueheng Hu and Shuhuan Wen and H.K. Lam},
  doi          = {10.1016/j.knosys.2025.113776},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113776},
  shortjournal = {Knowl. Based Syst.},
  title        = {Redundancy reduction penalty term of loss function in deep neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSER-net: Multi-stage edge refinement network for deepfake detection. <em>KBS</em>, <em>328</em>, 114280. (<a href='https://doi.org/10.1016/j.knosys.2025.114280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, the malicious creation and dissemination of deepfake content has reached a level that threatens personal privacy and even social stability. To address this issue, many researchers have focused on deepfake detection tasks. However, many approaches rely solely on single spatial domain information, with training models directly extracting global artefacts from images for detection. Such approaches frequently lack accuracy and are vulnerable to interference. Meanwhile, forgery traces typically appear at the edges of tampered regions, and these subtle edge inconsistencies serve as effective cues for detecting deepfakes. To address these issues, we propose the multi-stage edge refinement network (MSER-Net), which uses VMamba as its backbone network and incorporates channel residual image (CRI) to detect unnatural colour anomalies introduced during the deepfake process. First, the designed multiscale edge enhancement module (MSEEM) processes low-level features from both branches, obtaining multi-scale edge information using the Sobel operator and highlighting subtle forgery traces. In addition, we use the detail-aware interaction module (DAIM) to extract complementary information from spatial and residual features, which improves edge artefacts. Finally, we propose the multidimensional attention fusion module (MAFM), which improves dual-branch features from multiple perspectives using the attention mechanism, resulting in more effective fusion. Experimental results on multiple public datasets show that our method outperforms state-of-the-art detection approaches and exhibits the best robustness against most post-processing attacks. The code is available at: https://github.com/ypzhang123/MSER-Net .},
  archive      = {J_KBS},
  author       = {Yupeng Zhang and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.knosys.2025.114280},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114280},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSER-net: Multi-stage edge refinement network for deepfake detection},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-level semantic collaboration and inference network for medical image report generation. <em>KBS</em>, <em>328</em>, 114278. (<a href='https://doi.org/10.1016/j.knosys.2025.114278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of computer-aided systems in generating medical image reports has notably reduced the workload of radiologists. However, despite substantial advancements, several challenges continue to persist. Firstly, the accurate identification of pathological conditions faces constraints and CNNs often struggle to capture fine-grained lesion features arising from the inherent properties of medical images and data imbalance. Furthermore, bridging the semantic gap between medical images and their corresponding textual reports prove challenging. Existing approaches frequently encounter limitations when precisely mapping lesions to specific anomaly descriptions. To address these challenges, we introduce the Dual-Level Semantic Collaboration and Inference (DSCI) network. It comprises three modules: the Semantic Association Encoding (SAE) module, which utilizes high-level concept labels to establish meaningful semantic correlations and calibrate image representation for more accurate recognition of abnormal features. The Visual-Semantic Interaction (VSI) module further employs concept labels as supervisory signals and intermediate vectors, efficiently merging semantic and visual information to bridge gaps for enhanced comprehension. Lastly, the Contextual Cross-modal Attention (CCA) module is utilized in decoding, integrating global context to enhance the accuracy and relevance of generated reports. Extensive experiments on the IU X-Ray, MIMIC-CXR, and COV-CTR datasets have demonstrated the superior performance of the DSCI model over established benchmarks. Code is available at https://github.com/MRG22/DSCI .},
  archive      = {J_KBS},
  author       = {Junsan Zhang and Yuxue Liu and Mingwen Shao and Chenglizhao Chen and Zixuan Wang and Junliang Li and Yao Wan and Philip S. Yu},
  doi          = {10.1016/j.knosys.2025.114278},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114278},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-level semantic collaboration and inference network for medical image report generation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Schrödinger optimizer: A quantum duality-driven metaheuristic for stochastic optimization and engineering challenges. <em>KBS</em>, <em>328</em>, 114273. (<a href='https://doi.org/10.1016/j.knosys.2025.114273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Schrödinger Optimizer (SRA), a new metaheuristic algorithm motivated by principles of quantum mechanics, specifically Schrödinger's equation and wave-particle duality. SRA possesses a twin update mechanism that balances probabilistic exploration and deterministic exploitation, facilitating effective navigation in high-dimensional, intricate search spaces. The algorithm was extensively tested on benchmark suites such as CEC 2019 (low-dimensional), CEC 2017 (50D and 100D), CEC 2022 (20D), and eight real-world engineering design optimization problems. Comparison tests with state-of-the-art physics-inspired and advanced metaheuristic algorithms revealed SRA's superior performance. In the 100D CEC 2017 benchmark, SRA ranked the best average rank (1.87) among the physics-based algorithms and performed better than its rivals on 20 of the 29 functions. It also performed best (2.92) among emerging metaheuristic variants. Statistical tests (Friedman and Wilcoxon signed rank) confirmed the significance of these results. In engineering applications, SRA consistently obtained better solutions with fewer computations. These findings accentuate SRA's potential in solving complex optimization problems efficiently. This study opens up new possibilities for powerful and versatile optimization methods through the integration of quantum-inspired concepts into the metaheuristic paradigm. The source code is available at https://github.com/MohammedQaraad/SRA/blob/main/SRA_framework.ipynb},
  archive      = {J_KBS},
  author       = {Nazar K. Hussein and Mohammed Qaraad and Abdelwahab M. El Najjar and M.A. Farag and Mostafa A. Elhosseini and Seyedali Mirjalili and David Guinovart},
  doi          = {10.1016/j.knosys.2025.114273},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114273},
  shortjournal = {Knowl. Based Syst.},
  title        = {Schrödinger optimizer: A quantum duality-driven metaheuristic for stochastic optimization and engineering challenges},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to customer segmentation for product development on social media data: Integrating aspect-based sentiment analysis and text mining. <em>KBS</em>, <em>328</em>, 114269. (<a href='https://doi.org/10.1016/j.knosys.2025.114269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel framework for customer segmentation in the laptop market, leveraging Aspect-Based Sentiment Analysis (ABSA) and graph-based community detection to analyze over 1.4 million tweets from X (formerly Twitter). By combining feature-specific sentiment analysis with dynamic user categorization, the research bridges critical gaps in understanding how diverse consumer needs and preferences influence product development strategies. The findings reveal distinct regional variations: consumers in developing markets prioritize affordability and core features like design and battery life, demonstrating higher satisfaction levels, whereas those in developed markets demand advanced specifications, such as high-performance CPUs, GPUs, and thermal management, yet express lower satisfaction due to heightened expectations. Universal pain points, including battery life and charging inefficiencies, highlight cross-market opportunities for innovation. The analysis identifies diverse personas, such as Everyday Office Workers and Student Programmers in developing countries, and Power Users and Connectivity Enthusiasts in developed regions, offering actionable insights for tailoring product features and marketing strategies to meet specific user needs. This research introduces a cutting-edge method for integrating sentiment analysis with user segmentation, enabling manufacturers to align product designs with evolving consumer demands effectively. The study concludes by emphasizing the potential of this framework to drive innovation in new product development while laying a foundation for future research on emerging trends and advanced analytical techniques.},
  archive      = {J_KBS},
  author       = {Mehrdad Maghsoudi and Navid Mohammadi and Mohammadreza Bakhtiari},
  doi          = {10.1016/j.knosys.2025.114269},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114269},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel approach to customer segmentation for product development on social media data: Integrating aspect-based sentiment analysis and text mining},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-knowledge reinforcement transfer framework: Solving supersonic combustion flow in extreme environments. <em>KBS</em>, <em>328</em>, 114262. (<a href='https://doi.org/10.1016/j.knosys.2025.114262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel Multi-Knowledge Reinforcement Transfer (MKRT) framework to predict supersonic combustion flows in extreme environments, addressing the computational challenges of large-scale engineering applications. By integrating multiple knowledge representations and transfer learning techniques, the framework significantly enhances prediction accuracy and computational efficiency. The MKRT framework introduces a cross-layer feature dynamic fusion mechanism and a multi-scale fusion method to effectively capture the intricate interactions between physical fields and handle the multi-scale characteristics of combustion flows. Additionally, a "segmentation-reconstruction" strategy is employed to reduce model parameters while maintaining prediction accuracy. The experimental results under the condition of wide domain Mach number show that after multi-knowledge enhanced transfer, the average MAE and MSE errors are reduced by 23.39% and 43.89%, and the number of parameters of the model is reduced by 96.16%, which significantly reduces the computational complexity while maintaining high prediction accuracy. These advancements make the framework particularly suitable for high-speed combustion applications in aerospace engineering, offering a promising solution for efficient and accurate predictions of complex combustion phenomena in extreme environments.},
  archive      = {J_KBS},
  author       = {Xue Deng and Ye Tian and Yinglin Wang and Shicai Huang and Jingrun Wu and Hua Zhang},
  doi          = {10.1016/j.knosys.2025.114262},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114262},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-knowledge reinforcement transfer framework: Solving supersonic combustion flow in extreme environments},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-aware quantitative adversarial network: A novel partial-set transfer mechanism for cross-domain fault diagnosis of rotating machinery. <em>KBS</em>, <em>328</em>, 114259. (<a href='https://doi.org/10.1016/j.knosys.2025.114259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-domain fault diagnosis leveraging domain adaptation has garnered significant attention, where the research assumes that the source and target domains share identical label spaces. Nonetheless, mechanical monitoring data typically encompasses a subset of fault classes from the source domain, which is a partial domain adaptation (PDA) problem. Existing PDA methods primarily emphasize the feature transferability, lacking class-specific information. Moreover, the influence of uncertainty in the adaptation conformity of target domain samples is often neglected. To achieve reliable fault diagnosis under the interference of outlier classes, a novel partial-set transfer mechanism for intelligent diagnosis named class-aware quantitative adversarial network (CQAN) is proposed. Concretely, to amplify the class-specific feature representation for high-confidence in decision-making, the class-attention boosting module is designed, through which constraints are imposed on the attention distribution. Furthermore, a feature alignment calibration scheme is constructed to quantify the adaptation conformity of target domain samples. By embedding this scheme into the domain-adversarial framework, the learning of diagnostic knowledge can achieve dynamic adjustment and precise alignment. The effectiveness and adaptability of CQAN in partial-set fault diagnosis are verified through extensive experiments on two rotating machinery datasets.},
  archive      = {J_KBS},
  author       = {Yanlin Zhou and Chuancang Ding and Mingkuan Shi and Hongbo Que and Yifan Huangfu and Changqing Shen and Weiguo Huang and Zhongkui Zhu},
  doi          = {10.1016/j.knosys.2025.114259},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114259},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-aware quantitative adversarial network: A novel partial-set transfer mechanism for cross-domain fault diagnosis of rotating machinery},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving hierarchical semantic parsing with LLMs: Demonstration selection and chain-of-thought prompting via semantic fragment decoding. <em>KBS</em>, <em>328</em>, 114256. (<a href='https://doi.org/10.1016/j.knosys.2025.114256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, pre-trained Large Language Models (LLMs) have shown remarkable effectiveness in various Natural Language Processing (NLP) tasks. In hierarchical semantic parsing, previous methods typically process the entire semantic representation, which hinders language models from generalizing sub-semantic fragments (semantic units). In our approach, the original semantic representation of a sentence is divided into a list of semantic fragments. These fragments are used for demonstration selection, enabling the model to generalize sub-semantic fragments and incrementally decode these semantic units. Our contributions are threefold: (1) proposing a novel method for demonstration selection that maximally covers the semantic fragments present in a query sentence, (2) introducing a chain-of-thought (CoT) semantic representation based on logical decomposition, and (3) incorporating instruction fine-tuning for LLMs in this task. Experimental results demonstrate that our proposed method significantly improves the baseline system in both in-context learning and instruction fine-tuning settings for LLMs. In the in-context learning setting, our demonstration selection method outperforms the baseline approach, with improvements ranging from 6 % to 10 % in Exact Match scores on three well-known benchmark datasets: TOP, ATIS, and SNIPS. Additionally, performance is further enhanced when the CoT prompting technique is incorporated, achieving competitive state-of-the-art results across all datasets, including TOP, ATIS, SNIPS, and a large-scale dataset, TOPv2, using the instruction fine-tuning technique. Furthermore, our approach is highly applicable to various structural parsing tasks in NLP. The source code is available at https://github.com/phuongnm94/hsp_sem_fragment_dec .},
  archive      = {J_KBS},
  author       = {Phuong Minh Nguyen and Truong Dinh Do and Minh Le Nguyen},
  doi          = {10.1016/j.knosys.2025.114256},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114256},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving hierarchical semantic parsing with LLMs: Demonstration selection and chain-of-thought prompting via semantic fragment decoding},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-reinforcement-learning-based distributed path planning for collaborative multi-AGV systems. <em>KBS</em>, <em>328</em>, 114255. (<a href='https://doi.org/10.1016/j.knosys.2025.114255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Guided Vehicle (AGV) systems, recognized for their high efficiency and automation, are extensively applied in intelligent factory logistics, warehouse management, and manufacturing. In multi-AGV systems operating in environments with dynamic obstacles and inter-AGV interactions, efficient path planning methods are required to achieve real-time and reliable material distribution. However, existing approaches face significant challenges in decision-making efficiency and scalability, primarily due to limited prior information, reliance on local observations, and complex interactions among AGVs. To address these challenges, this paper proposes a Graph Node-edge Multi-Agent Path Planning (GNMAPP) algorithm, a multi-agent reinforcement learning path planning method based on Graph Neural Networks (GNN), leveraging a centralized training and distributed execution framework to improve system efficiency. The GNMAPP algorithm formulates the problem as a locally observable Markov decision process, representing AGVs and environmental entities as nodes and edges in a dynamic heterogeneous graph to reflect their real-time interaction relationships. Multi-head attention interaction mechanism is employed to obtain the importance weights for node and edge features, enabling adaptive aggregation of relevant information and enhancing the environmental perception capabilities of the AGV system. Furthermore, the training process is optimized by incorporating a Rapidly-exploring Random Tree (RRT)-guided strategy improvement mechanism. Simulation results demonstrate that the proposed GNMAPP algorithm significantly outperforms existing algorithms in terms of convergence speed and decision-making efficiency.},
  archive      = {J_KBS},
  author       = {Huaguang Shi and Zichao Yu and Jian Huang and Tianyong Ao and Wei Li and Yi Zhou},
  doi          = {10.1016/j.knosys.2025.114255},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114255},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph-reinforcement-learning-based distributed path planning for collaborative multi-AGV systems},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-branch federated graph learning model with global graph structure information. <em>KBS</em>, <em>328</em>, 114254. (<a href='https://doi.org/10.1016/j.knosys.2025.114254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated graph learning combines the power of graph learning and the data privacy-preserving properties of federated learning to provide a new solution for processing complex graph data scattered across different data sources. However, data heterogeneity may not only lead to model performance degradation but also affect the stability and convergence of model training. In addition, the local model has to consider the data security problem in the process of delivery and aggregation. Therefore, this paper proposes a Dual-branch Federated Graph Learning model with Global Graph Structure information (DFGL2GS) to cope with the statistical heterogeneity of graph data distribution and the secure interaction of graph structure information. Specifically, the local model contains two branches, Local and Global, which are used to capture personalized local features and generalized global features, respectively. The server further assists global federated graph learning modeling by capturing global graph structure information from a client generated graph that incorporates node and graph structure information. Finally, we demonstrate the effectiveness of the proposed method by conducting extensive experiments on four datasets of different domain.},
  archive      = {J_KBS},
  author       = {Wei Huang and Chao Zhu and Yanyong Huang and Jia Liu and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.114254},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114254},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-branch federated graph learning model with global graph structure information},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-architecture masked contrastive learning framework for few-shot underwater acoustic target classification. <em>KBS</em>, <em>328</em>, 114252. (<a href='https://doi.org/10.1016/j.knosys.2025.114252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic target classification (UATC) is a technology employed to detect, classify, and identify specific underwater targets through the analysis of underwater acoustic signals. Recently, deep learning has been widely adopted in UATC, yielding significant achievements. However, in practical applications, annotating underwater acoustic signals and data remains time-consuming and labour-intensive. Moreover, deep learning models often undergo significant performance degradation when trained on limited datasets. To address these challenges, this study proposes a novel two-stage cross-architecture masked contrastive learning (CAMCL) framework. Specifically, CAMCL is first employed for pre-training, following which labeled data are fine-tuned. The associated method integrates two strategies: masked contrastive learning, which combines the advantages of masked learning and contrastive learning; and cross-architecture self-supervised learning, where knowledge learned from a Transformer architecture is transferred to a lightweight convolutional neural network architecture. For validating the effectiveness of the proposed framework, experiments are conducted on two datasets: AudioSet-2M and DeepShip. Ultimately, the proposed framework is revealed to demonstrate performance superior to that of existing self-supervised and supervised learning methods in UATC tasks.},
  archive      = {J_KBS},
  author       = {Wenhan Li and Zhenzhong Chen and Jiangong Wang and Taijun Liu and Hua Chen and Gaoming Xu},
  doi          = {10.1016/j.knosys.2025.114252},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114252},
  shortjournal = {Knowl. Based Syst.},
  title        = {A cross-architecture masked contrastive learning framework for few-shot underwater acoustic target classification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel frequency-stratified transformer framework with cross-frequency attention for reliable cardiac arrhythmia classification. <em>KBS</em>, <em>328</em>, 114250. (<a href='https://doi.org/10.1016/j.knosys.2025.114250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases remain the leading cause of mortality worldwide, with arrhythmias requiring timely and accurate diagnosis. The presented work is motivated by the urgent clinical need for automated ECG analysis systems that can match the diagnostic accuracy of cardiologists while being computationally efficient for real-time applications. The key problem addressed is the inability of existing systems to effectively capture the dual nature of cardiac signals, simultaneously analysing local morphological features and global rhythmic patterns. Current Deep Learning (DL) approaches suffer from three limitations: inadequate handling of frequency-specific characteristics inherent in different cardiac components, insufficient integration of multi-scale temporal information, and lack of clinical reasoning mechanisms. To address the limitations, the work proposes a novel Frequency-Guided Hierarchical Shifted Window (FG-HSWIN) transformer with Cross-Frequency Attention (CFA) head for automatic arrhythmia classification. The method introduces a Quantized Adaptive Wavelet Threshold (QAWT) denoising technique, followed by continuous wavelet transform (CWT) to convert pre-processed ECG data into scalogram images. Three primary mechanisms constitute core innovation: Frequency-Aware Positional Encoding (FAPE) for improved frequency context, Lightweight Multi-scale Feature Fusion (LMFF) for hierarchical feature integration, and Frequency-Stratified Window Attention (FSWA) for frequency bands based window size adaptation. To simulate clinical thinking, Cross-Frequency Attention classifier assesses beat morphology and rhythm patterns independently. In comparison to state-of-the-art techniques, experimental evaluation on 109,462 total samples from the MIT-BIH dataset demonstrates advanced results and shows higher performance with 98.72 % accuracy, which translates into a 2.03 % improvement in minority class categorization. The proposed method overcomes constraints of typical vision transformers for cardiac signal processing by introducing domain-specific modifications.},
  archive      = {J_KBS},
  author       = {Sumita Lamba and Satender Kumar and Manoj Diwakar},
  doi          = {10.1016/j.knosys.2025.114250},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114250},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel frequency-stratified transformer framework with cross-frequency attention for reliable cardiac arrhythmia classification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPCAC: Effective multi-scale graph contrastive learning via dual-perspective clustering and adaptive contrast. <em>KBS</em>, <em>328</em>, 114247. (<a href='https://doi.org/10.1016/j.knosys.2025.114247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning has emerged as a powerful paradigm for learning expressive node representations in an unsupervised setting. However, numerous existing methods construct contrastive views from a single-perspective, relying solely on either node attributes or topological structure. This limits the semantic diversity of the learned representations. Moreover, negative samples are often treated with equal importance, without accounting for their semantic proximity to anchor nodes. This uniform treatment weakens the ability to distinguish between true negatives and false negatives, impairing contrastive effectiveness. To address these limitations, we propose a contrastive learning framework named D ual- P erspective C lustering and A daptive C ontrast ( DPCAC ). DPCAC constructs two complementary graph views by integrating feature-based clustering with connectivity-sensitive clustering, enabling the model to capture global and local semantic information. Furthermore, DPCAC employs a multi-level adaptive contrastive mechanism that assigns importance weights to negative samples based on their semantic similarity at the node-level and structural strength at the group-level. This design mitigates the influence of false negatives and enhances representation discrimination. Extensive experiments on graph datasets demonstrate that DPCAC consistently outperforms competitive baselines in both node classification and node clustering tasks.},
  archive      = {J_KBS},
  author       = {Fangjing Li and Zhihai Wang and Diping Wang and Haiyang Liu and Xinxin Ding},
  doi          = {10.1016/j.knosys.2025.114247},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114247},
  shortjournal = {Knowl. Based Syst.},
  title        = {DPCAC: Effective multi-scale graph contrastive learning via dual-perspective clustering and adaptive contrast},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient personalized federated learning with evolutionary strategies and cluster-aware knowledge transfer. <em>KBS</em>, <em>328</em>, 114246. (<a href='https://doi.org/10.1016/j.knosys.2025.114246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed model training across multiple clients while preserving data privacy. However, in real-world scenarios, challenges such as high communication cost and non-iid data distributions often lead to degraded model performance and increased system overhead. While existing research has made some progress in addressing these challenges, achieving a balance between model accuracy and communication efficiency remains difficult. To address this issue, we propose FedECT, an efficient FL framework that leverages evolutionary perturbation strategies and cluster-aware knowledge transfer. Instead of transmitting high-dimensional gradients, FedECT employs fitness-based communication, significantly reducing bandwidth consumption while enhancing privacy protection. Specifically, clients generate perturbation model populations by evolutionary strategy and compute fitness values to transmit model information, which are then utilized for similarity-based clustering. Within each cluster, we introduce an optimization enhancement parameter that facilitates personalized knowledge transfer among similar clients, improving model generalization across heterogeneous data distributions. Extensive experiments on four datasets demonstrate that FedECT achieves up to 7 % higher accuracy and reduces communication costs by at least 14 % compared to most of the advanced FL approaches. Additionally, ablation studies confirm the effectiveness of fitness transmission based on evolutionary strategy and knowledge transfer within clusters in enhancing model performance and communication costs.},
  archive      = {J_KBS},
  author       = {Yue Wang and Han Hu and Wenli Du},
  doi          = {10.1016/j.knosys.2025.114246},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114246},
  shortjournal = {Knowl. Based Syst.},
  title        = {Communication-efficient personalized federated learning with evolutionary strategies and cluster-aware knowledge transfer},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HFA-UNet: Hybrid and full attention UNet for thyroid nodule segmentation. <em>KBS</em>, <em>328</em>, 114245. (<a href='https://doi.org/10.1016/j.knosys.2025.114245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound imaging is the most commonly used method for screening thyroid nodules due to its low cost and non-invasive nature. Thyroid nodule lesions have variable shapes, rich aspect ratios, unclear boundaries, calcified nodule-induced acoustic shadows, and noise interference, causing challenges in accurate segmentation. Recent methods ignore various scale features and details in different resolutions of images, leading to redundant or missing feature information and then affecting the segmentation performance. In this paper, we introduce a hybrid and full attention UNet model for ultrasound thyroid nodule segmentation. Self, spatial and channel attention are combined in a U-Net-like structure to extract global and local features simultaneously. A novel full attention multi-scale fusion stage is designed to enhance boundary features while suppressing noise features. At the same time, the model dynamically adjusts the number of skip connections corresponding to images of different resolutions to better utilize multi-scale features and detailed information. We evaluate our model on DDTI, TN3K and Stanford Cine-Clip datasets, including internal validation and cross-dataset testing. The results show that our proposed model for internal validation in the DDTI dataset increases the Dice score and mean intersection over union by 2.36 % and 1.04 % compared to the state-of-the-art model. In the TN3K dataset, they increase by 1.66 % and 3.05 %.},
  archive      = {J_KBS},
  author       = {Yue Li and Yuanhao Zou and Xiangjian He and Qing Xu and Ming Liu and Shengji Jin and Qian Zhang and Maggie M. He and Jian Zhang},
  doi          = {10.1016/j.knosys.2025.114245},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114245},
  shortjournal = {Knowl. Based Syst.},
  title        = {HFA-UNet: Hybrid and full attention UNet for thyroid nodule segmentation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMF: A semantic-guided dynamic attention framework for visual-haptic-textual multimodal fusion. <em>KBS</em>, <em>328</em>, 114244. (<a href='https://doi.org/10.1016/j.knosys.2025.114244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust robotic object recognition and manipulation depend on the effective integration of heterogeneous sensory modalities, particularly vision and haptics. While vision provides global contextual cues such as shape and texture, haptics captures localized physical feedback through direct interaction. However, semantic discrepancies and spatial misalignments between these modalities complicate global-local feature alignment, thus posing challenges for effective fusion. Additionally, collecting haptic data is costly and challenging, resulting in sparse and imbalanced samples that hinder model generalization. To address these challenges, a semantic-guided dynamic attention framework (DAMF) is proposed for visual-haptic-textual multimodal fusion. DAMF incorporates a dual cross-modal attention mechanism, where global visual semantics guide haptic exploration, and haptic feedback adaptively refines visual attention. To mitigate issues arising from sparse haptic data, we introduce Text-Aided Haptic Learning on Small Sample Datasets (TAHS), which leverages high-level structured semantic priors to enhance tactile representation learning under small sample conditions. Furthermore, a locally modulated self-attention mechanism is employed to decouple modality-specific features and suppress semantic interference, thereby preserving discriminability during fusion. We also present HTV, a large-scale dataset comprising synchronized visual-haptic samples and textual annotations. Experiments conducted on the HTV, Touch and Go, and MSDO-master datasets demonstrate the effectiveness of our method, particularly in data-scarce scenarios. This work provides novel insights and scalable solutions for developing adaptive and data-efficient robotic perception systems.},
  archive      = {J_KBS},
  author       = {Bin Wang and Baojiang Li and Tianwei Gao and Liang Li and Haiyan Wang and Chunbo Zhao and Zizhen Yi},
  doi          = {10.1016/j.knosys.2025.114244},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114244},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMF: A semantic-guided dynamic attention framework for visual-haptic-textual multimodal fusion},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic prediction and mitigation in 6G software-defined networks using bobcat bi-GRU and reinforcement learning based on proximal policy optimization. <em>KBS</em>, <em>328</em>, 114243. (<a href='https://doi.org/10.1016/j.knosys.2025.114243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networking (SDN) allows more flexible network administration in 6 G networks by separating control from data planes, which facilitates intelligent traffic prediction and routing. However, existing intelligent traffic prediction and routing models struggle with vanishing gradients, limited context, and unstable traffic. To avoid these issues Bobcat Bi-GRU algorithm-based traffic prediction and RL integrated routing framework is developed to deliver smarter and more efficient network routing. Initially, data collected from the data plane is given to a centralized control plane for routing adjustments and policy implementation, enhancing network performance and reliability. The control plane collects network measurement information, which is then analysed by the Knowledge Plane, employing RL based PPO algorithm to identify optimal routing paths and traffic predictions using the Bobcat Bi-GRU algorithm. The Proactive Forwarding module leverages these optimal paths and traffic predictions to implement a rule-based process aimed at minimizing network delay and packet loss. Installing these rules on switches allows normal data flow under non-congested conditions and quickly finds alternative paths if congestion occurs. Remarkable outcomes were obtained by the proposed model, including a higher accuracy of 97.1% and a 97.1% F1 score. Additionally, it recorded a packet delivery ratio of 87% and a throughput of 73.16 Gbps. These findings clearly show that the traffic prediction and RL-based routing in the SDN model are highly essential for effective data transmission. The model maintains low computational overhead due to the use of the Bobcat Bi-GRU, which was optimized for fast, efficient traffic pattern recognition with minimal processing resources.},
  archive      = {J_KBS},
  author       = {R. Aiyshwariya Devi and Bharti Mehra and M. Kavitha and Anandan P},
  doi          = {10.1016/j.knosys.2025.114243},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114243},
  shortjournal = {Knowl. Based Syst.},
  title        = {Traffic prediction and mitigation in 6G software-defined networks using bobcat bi-GRU and reinforcement learning based on proximal policy optimization},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tapas: Enabling faithful data-to-text generation through task-adaptive pre-training with data alignment strategy. <em>KBS</em>, <em>328</em>, 114240. (<a href='https://doi.org/10.1016/j.knosys.2025.114240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-to-text generation is the task of converting structured data into human-readable and coherent text, with applications in fields such as automated reporting and real-time information dissemination. Despite recent progress with pre-trained language models, which have significantly improved human-readability and coherence, a major challenge remains: hallucination, where generated text fails to faithfully align with the input data. These hallucinations primarily stem from two factors: limitations in the model’s ability to understand the structural information of the data, and inconsistencies between structured data and reference texts in the training data. To address these challenges, we propose Tapas, a task-adaptive pre-training model that mitigates hallucination from both the model and data perspectives. First, we employ task-adaptive pre-training with three effective learning objectives. This aims to enhance the ability of pre-trained language models to learn data structure and align structured data with reference texts. Then, during the fine-tuning phase, we incorporate a heuristic data alignment strategy to further mitigate hallucination. Experimental results indicate that Tapas achieves the state-of-the-art BLEU-4 scores on the E2E and WebNLG datasets in fully supervised scenarios. In few-shot scenarios, notable improvements of 2.1 % and 1.8 % are observed for E2E and WebNLG, respectively. These results confirm Tapas’ effectiveness in addressing the core causes of hallucination and improving fidelity in data-to-text generation compared to baseline models.},
  archive      = {J_KBS},
  author       = {Xin Sun and Haoran Zhang and Shuo Zhao},
  doi          = {10.1016/j.knosys.2025.114240},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114240},
  shortjournal = {Knowl. Based Syst.},
  title        = {Tapas: Enabling faithful data-to-text generation through task-adaptive pre-training with data alignment strategy},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting confirmed cases of various epidemics using global temporal-feature-based graph convolutional network. <em>KBS</em>, <em>328</em>, 114239. (<a href='https://doi.org/10.1016/j.knosys.2025.114239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the spread of infectious diseases is challenging as the propagation of an epidemic is influenced by various factors. We propose the GLObal temporal feature-based Graph Convolutional Network(GLOGCN), which focuses on the global temporal patterns present in the spread of infectious diseases. Considering the existence of anomalous data in the epidemic dataset, using global temporal patterns leads the model to grasp the overall trends of the epidemic. We conducted experiments on the United States COVID-19, Hungary chickenpox, and German tuberculosis epidemic datasets to validate the performance of GLOGCN. Both graph and non-graph models were selected as baseline models for a performance comparison. Each model was trained to predict future confirmed cases of the epidemic based on the past timesteps. The experimental results show that GLOGCN achieved better performance than other baseline models in the sense of lower accumulated error. Further, we verified the model robustness on diverse patterns in the test data. The ablation study confirmed that using global temporal features had a significant impact on the model performance. In summary, GLOGCN exhibited robust performance across every dataset used in this study by processing the global temporal patterns. Thus, GLOGCN can provide supplemental data to improve epidemic policymaking.},
  archive      = {J_KBS},
  author       = {Jisu Kang and Jin Sob Kim and Hyun Joon Park and Soyeon Lee and Ye Ji Han and Yajun Mei and Sung Won Han},
  doi          = {10.1016/j.knosys.2025.114239},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114239},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting confirmed cases of various epidemics using global temporal-feature-based graph convolutional network},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical surrogate-assisted evolutionary algorithm for high-dimensional expensive multimodal optimization problems. <em>KBS</em>, <em>328</em>, 114238. (<a href='https://doi.org/10.1016/j.knosys.2025.114238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, many optimization problems exhibit multimodal, high-dimensional, and computationally expensive characteristics, referred to as high-dimensional expensive multimodal optimization problems (HEMMOPs). For such complex problems, it is often expected to identify multiple optima with limited expensive computing resources to enhance optimization robustness and/or increase the flexibility of solution options. This poses a significant challenge, as even finding a single optimum in high-dimensional space is difficult. However, existing studies primarily focus on tackling low- or medium-dimensional expensive multimodal optimization problems, with limited extension to high-dimensional scenarios. In light of this, this study proposes a hierarchical surrogate-assisted multimodal evolutionary algorithm (HSAMMEA), which comprises three components: space-subspace joint search-based crowding differential evolution (S2JCDE), network decomposition-based niching technique (NDN), and neighbor similarity-based pruning local search (NPLS). S2JCDE achieves comprehensive modality exploration by jointly searching in both the original and random subspaces with global surrogate-assisted crowding differential evolution. NDN utilizes information from both the decision and objective spaces to describe the population as a network and achieves modality delineation by network decomposition. NPLS takes a local surrogate model as the objective function to exploit the optimum of each identified modality, while eliminating redundant searches based on subregion similarity. Extensive experimental results on nine benchmark functions and two real-world applications demonstrate that HSAMMEA gains a competitive edge over state-of-the-art algorithms.},
  archive      = {J_KBS},
  author       = {Wenhao Du and Zhigang Ren and Fan Li and Hanqing Liu},
  doi          = {10.1016/j.knosys.2025.114238},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114238},
  shortjournal = {Knowl. Based Syst.},
  title        = {A hierarchical surrogate-assisted evolutionary algorithm for high-dimensional expensive multimodal optimization problems},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Signal-relationship-aware explainable intrusion detection in controller area networks using graph transformers. <em>KBS</em>, <em>328</em>, 114237. (<a href='https://doi.org/10.1016/j.knosys.2025.114237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The controller area network (CAN) bus, a critical component of vehicular communication, is vulnerable to various data intrusions owing to its arbitration mechanism and lack of message authentication. The signals carried within CAN messages contain specific data defined by the application layer and can be manipulated by attackers to execute intrusions. However, most current intrusion detection methods focus on frame-level detection, failing to explore complex relationships among CAN signals. Since signal assignments can offset each other, the absence of signal-level detection leads to a high false positive rate and makes it challenging to trace the source of intrusive signals. To address these challenges, this paper proposes a novel signal-relationship-aware intrusion detection method based on Graph Transformers. The main idea of this approach is to transform CAN messages into a dynamic multivariate signal series, leveraging graph neural networks (GNN) to model relationships among signals, where signal node features are employed to learn the graph structure. To capture the global dependencies of signal features, a temporal Transformer-based supervised learning model is introduced to learn node embeddings extracted by the GNN. Additionally, this method can identify components related to the intrusion source, demonstrating strong interpretability. This method has been validated using two real in-vehicle CAN datasets including the Car-Hacking Dataset and our self-collected CAN-Injection Dataset from a real vehicle. Experimental results indicate that our approach achieved 100 % precision, recall, and F1-score for intrusion detection across all attack types, surpassing six state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fei Gao and Jinshuo Liu and Chengzhe Li and Zhenhai Gao and Rui Zhao},
  doi          = {10.1016/j.knosys.2025.114237},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114237},
  shortjournal = {Knowl. Based Syst.},
  title        = {Signal-relationship-aware explainable intrusion detection in controller area networks using graph transformers},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised graph convolutional community detection empowered by large language models. <em>KBS</em>, <em>328</em>, 114236. (<a href='https://doi.org/10.1016/j.knosys.2025.114236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection, which aims to automatically identify community structures within graphs, is one of the focal points in the field of network analysis. Recently, Large Language Models (LLMs) have demonstrated exceptional performance in various tasks. However, the integration of community detection and LLMs has yet to be investigated. Furthermore, existing community detection methods are limited in their ability to detect overlapping and non-overlapping communities simultaneously, failing to achieve unified semi-supervised overlapping and non-overlapping community detection. Therefore, this study proposes a novel method, called semi-supervised graph convolutional community detection empowered by large language models (LLMCom). First, LLMCom improves understanding of graph structures by mining multi-hop nodes and node ranking values from the graph. Second, to align the feature spaces of community detection tasks and language processing tasks, a new alignment-aware network is designed. Subsequently, a new dual-decoder is proposed to reconstruct the attributed graph and attributed hypergraph, enabling a fine-grained recognition of the differences between overlapping and non-overlapping communities. Finally, LLMCom integrates a semi-supervised prior module to learn prior information of graphs. Experiments on 10 benchmark datasets show that LLMCom outperforms current mainstream methods in community detection.},
  archive      = {J_KBS},
  author       = {Shan Yang and Xiaoling Huang and Shan Ji and Cheng Zhang and Shuai Zhang},
  doi          = {10.1016/j.knosys.2025.114236},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114236},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised graph convolutional community detection empowered by large language models},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABG-NAS: Adaptive bayesian genetic neural architecture search for graph representation learning. <em>KBS</em>, <em>328</em>, 114235. (<a href='https://doi.org/10.1016/j.knosys.2025.114235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective and efficient graph representation learning is essential for enabling critical downstream tasks, such as node classification, link prediction, and subgraph search. However, existing graph neural network (GNN) architectures often struggle to adapt to diverse and complex graph structures, limiting their ability to produce structure-aware and task-discriminative representations. To address this challenge, we propose ABG-NAS, a novel framework for automated graph neural network architecture search tailored for efficient graph representation learning. ABG-NAS encompasses three key components: a Comprehensive Architecture Search Space (CASS), an Adaptive Genetic Optimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASS systematically explores diverse propagation ( P ) and transformation ( T ) operations, enabling the discovery of GNN architectures capable of capturing intricate graph characteristics. AGOS dynamically balances exploration and exploitation, ensuring search efficiency and preserving solution diversity. BGTM further optimizes hyperparameters periodically, enhancing the robustness and scalability of the resulting architectures to both large-scale graphs and high-complexity models. Empirical evaluations on benchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate that ABG-NAS consistently outperforms both manually designed GNNs and state-of-the-art neural architecture search (NAS) methods. These results highlight the potential of ABG-NAS to advance graph representation learning by providing adaptive solutions that scale effectively across varying graph sizes and architectural complexities. Our code is publicly available at https://github.com/sserranw/ABG-NAS .},
  archive      = {J_KBS},
  author       = {Sixuan Wang and Jiao Yin and Jinli Cao and Mingjian Tang and Hua Wang and Yanchun Zhang},
  doi          = {10.1016/j.knosys.2025.114235},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114235},
  shortjournal = {Knowl. Based Syst.},
  title        = {ABG-NAS: Adaptive bayesian genetic neural architecture search for graph representation learning},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order hypergraph convolutional network framework for intracranial brain hemorrhage detection in wearable healthcare systems. <em>KBS</em>, <em>328</em>, 114234. (<a href='https://doi.org/10.1016/j.knosys.2025.114234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute Cerebral Hemorrhage (ICH) is a life-threatening condition that needs immediate medical intervention. The complexity of the subtle findings makes the diagnosis of acute ICH on CT scans a challenge for radiologists. To address this, a Multi-order hyper graph convolutional network for Automated Detection with Classification of Brain Intracranial Haemorrhage images in Wearable Networks (MHGCNN-ADC-ICH) is proposed in this paper. Here, the input images are collected from benchmark ICH dataset. The collected images are pre-processed using Distributed Set-Membership Fusion Filtering (DSMFF) to remove the noise from the image. Then Local Sample-weighted Multiple Kernel Clustering (LSMKC) is used to detect diseased portions. The morphological features are extracted using Ternary Pattern and Discrete Wavelet Transforms (TPDWT) technique. Afterwards, the Multi-order Hypergraph Convolutional Networks (MHGCNN) are used for classify ICH types. Finally, Binary chimp optimization algorithm (BChOA) is used to optimize the MHGCNN classifier. The proposed MHGCNN-ADC-ICH method attains 19 %, 15.2 % and 12.67 % high accuracy and 28.8 %, 25.4 %, 23.5 % less computation time when compared with existing methods.},
  archive      = {J_KBS},
  author       = {Atul B Kathole and Kapil Netaji Vhatkar and Jayashree Katti and Amit Sadanand Savyanavar and Vinod V Kimbahune},
  doi          = {10.1016/j.knosys.2025.114234},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114234},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-order hypergraph convolutional network framework for intracranial brain hemorrhage detection in wearable healthcare systems},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MNiST: A deep learning framework for multi-scale spatial feature modeling and cellular landscape decoding in spatial. <em>KBS</em>, <em>328</em>, 114233. (<a href='https://doi.org/10.1016/j.knosys.2025.114233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial transcriptomics (ST) has revolutionized our understanding of gene expression by preserving spatial context, enabling insights into tissue architecture and cellular heterogeneity. However, existing computational methods often rely on graph convolutional or attention-based mechanisms, which are limited in modeling long-range spatial dependencies and incorporating frequency-domain information. These limitations can hinder accurate reconstruction of spatial expression patterns, especially in complex tissues. To address this, we propose MNiST (Mamba-based Network integrating Spatial Transcriptomics), a unified deep learning framework that integrates state space modeling, frequency-domain analysis, and contrastive learning for spatial feature extraction and cellular landscape decoding. MNiST features a dual-branch encoder, Gmamba, composed of a Conv-branch for local feature extraction and a SpatialMamba branch for modeling long-range dependencies. The SpatialMamba branch leverages continuous-time state space modeling and a query-gated mechanism to propagate features across distant tissue regions efficiently. Additionally, MNiST employs Chebyshev polynomial expansion to extract multi-order frequency features, enhancing its robustness to noise and its ability to capture diverse spatial structures. We evaluated MNiST on datasets from axolotl brain development and human melanoma, demonstrating its superior performance in spatial clustering and cell-type deconvolution. MNiST successfully reveals biologically meaningful spatial patterns such as developmental trajectories, immune cell aggregation, and tumor heterogeneity. These findings highlight its potential as a generalizable computational tool for analyzing spatial omics data across complex biological contexts.},
  archive      = {J_KBS},
  author       = {Zhenghui Wang and Ruoyan Dai and Kaitai Han and Mengqiu Wang and Lixin Lei and Zhiwei Zhang and Zhenxing Li and Xingyu Liu and Jirui Zhang and Han Yan and Qianjin Guo},
  doi          = {10.1016/j.knosys.2025.114233},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114233},
  shortjournal = {Knowl. Based Syst.},
  title        = {MNiST: A deep learning framework for multi-scale spatial feature modeling and cellular landscape decoding in spatial},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy transformation for abnormal breast mass detection. <em>KBS</em>, <em>328</em>, 114232. (<a href='https://doi.org/10.1016/j.knosys.2025.114232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast mass detection remains a significant challenge in developing effective computer-aided diagnosis (CADx) systems to assist clinicians in differentiating between benign and malignant masses. This paper introduces a ovel fuzzy rule-based CADx approach for mammographic mass classification, utilising Transformation-based Fuzzy Rule Interpolation with Mahalanobis matrices (MT-FRI). This method enables reliable and interpretable classification by transforming attributes into a new feature space and interpolating for unmatched cases, making it well-suited to limited-data scenarios. The proposed approach integrates a structured pipeline encompassing feature extraction, feature selection, fuzzy rule generation, and interpolation inference, all designed to enhance transparency in diagnostic decisions. The system implementing the approach is evaluated on four widely-used mammographic datasets-INbreast, CBIS-DDSM, BCDR-D01, and BCDR-F01. For the first time, comparative experiments demonstrate that state-of-the-art fuzzy rule interpolative methods, particularly MT-FRI, achieve superior classification performance over representative classical machine learning models and deep neural networks. Unlike deep learning models, which require extensive labelled data and function as “black boxes”, MT-FRI produces transparent, human-readable rules, supporting clinical interpretability. This work underscores the potential of MT-FRI as an adaptable and interpretable CADx solution for mammographic diagnosis, especially valuable in sparse-data environments.},
  archive      = {J_KBS},
  author       = {Mou Zhou and Guobin Li and Changjing Shang and Shangzhu Jin and Jinle Lin and Liang Shen and Nitin Naik and Jun Peng and Qiang Shen},
  doi          = {10.1016/j.knosys.2025.114232},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114232},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive fuzzy transformation for abnormal breast mass detection},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superpoint-enhanced transformer for fine-grained segmentation of slender primary scaffolding elements in point clouds. <em>KBS</em>, <em>328</em>, 114231. (<a href='https://doi.org/10.1016/j.knosys.2025.114231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slender structural components in construction, such as scaffolding elements, are critical but pose significant safety risks due to failures. Traditional inspection methods are inefficient and inaccurate, especially in complex environments. Achieving reliable automated safety inspections requires precise segmentation of individual components, which is challenging due to dense arrangements and uniform geometry. This study addresses this key technical issue by proposing a unified computer vision framework that combines fine-grained superpoint generation with Transformer-based decoding. In addition, shape-aware constraints and refinement strategies are incorporated to improve segmentation accuracy for slender, spatially entangled components. A dedicated benchmark dataset of scaffolding elements was developed for validation. Experimental results demonstrate promising performance, achieving an accuracy of 93.67 %, AP@0.5 of 83.51 %, and PQ of 62.3 %, with AP@0.5 gains of 11.69 % for diagonal braces and 8.86 % for horizontal tubes over the baseline. These improvements are particularly evident in the most challenging level-5 subset, emphasizing the robustness of our model in complex construction scenes. The proposed method provides a comprehensive solution for semantic, instance, and panoptic segmentation of scaffolding elements in 3D point clouds, offering a solid foundation for downstream tasks such as structural analysis and automated compliance checking.},
  archive      = {J_KBS},
  author       = {Zeyu Gao and Yutong Tang and Zhenhua Zhu and Xiaochun Luo},
  doi          = {10.1016/j.knosys.2025.114231},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114231},
  shortjournal = {Knowl. Based Syst.},
  title        = {Superpoint-enhanced transformer for fine-grained segmentation of slender primary scaffolding elements in point clouds},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the noise robustness of sparse-form patches for image denoising. <em>KBS</em>, <em>328</em>, 114230. (<a href='https://doi.org/10.1016/j.knosys.2025.114230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important prior for distinguishing textures and noise, the sparsity of patches from clear images has attracted much attention in denoising tasks. However, few studies have discussed whether sparse-form patches are robust to noise, which is a key factor for denoising methods to effectively leverage sparse priors. In this paper, we revisit the importance of noise robustness in sparse-form patches used in denoising methods and propose a novel denoising framework, named FeaPD, which can effectively reduce the adverse interference of noise on sparse-form patches. Specifically, the expected patch log likelihood (EPLL) and UNet are taken as our baseline to verify the effectiveness of this framework, resulting in two new denoising methods: FeaEPLL and FeaUNet. First, sparse-form patches are constructed by applying PN on a mean domain with reduced noise intensity, which offers greater robustness to image noise than applying PN directly on the noisy image. Then, matrix-based complete convolution is incorporated for lossless decomposition, and a cross-domain joint probability model is used to enhance texture representation precision by sparse-form patches in the feature domain. Finally, this denoising framework was explicitly validated on the FeaEPLL and further applied to design the advanced FeaUNet. Experiments on synthetic noise using the public datasets Set12, BSD68, Kodak24, McMaster, and Urban100 demonstrate that our methods achieve superior performance with low computational overhead, while also showing competitive results on real-world noise in the SIDD dataset. The code and all pretrained models are available at https://github.com/Xin-Ge/Feature-Patch-Denoiser .},
  archive      = {J_KBS},
  author       = {Xin Ge and Liping Qi and Yu Zhu and Wei Sun and Axi Niu and Qingsen Yan and Jinqiu Sun and Yanning Zhang},
  doi          = {10.1016/j.knosys.2025.114230},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114230},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing the noise robustness of sparse-form patches for image denoising},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VCIF: Visually-compelling infrared and visible image fusion under darkness. <em>KBS</em>, <em>328</em>, 114227. (<a href='https://doi.org/10.1016/j.knosys.2025.114227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVF) enables comprehensive representation of low-light scenes. Current IVF methods are prone to yield visually poor results in extremely dark conditions because they tend to focus solely on the fusion process without considering the degradation of source images. To solve this problem, a novel infrared and visible image fusion method is proposed, which incorporates low-light image enhancement (LLIE) within a unified framework to achieve visually compelling fusion results even under severe environments, namely VCIF. The network first acquires proficient capabilities in illumination correction and chromatic transformation over LLIE tasks. Then, the LLIE module of VCIF is refined for varying brightness conditions through image enhancement and denoising. Finally, the fusion step is realized through elaborate fusion rules and a simple encoder-decoder structure based on Transformer blocks. Moreover, a maximum selection loss that integrates intensity and gradient constrained on different color spaces is designed to boost the fusion performance. Experimental results exhibit that the proposed method outperforms the state-of-the-art methods by generating human-aligned visual results. The source code will be available at https://github.com/JJGNB/VCIF .},
  archive      = {J_KBS},
  author       = {Chenggong Li and Junchao Zhang and Degui Yang and Dangjun Zhao},
  doi          = {10.1016/j.knosys.2025.114227},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114227},
  shortjournal = {Knowl. Based Syst.},
  title        = {VCIF: Visually-compelling infrared and visible image fusion under darkness},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global fusion network for remote sensing object detection. <em>KBS</em>, <em>328</em>, 114226. (<a href='https://doi.org/10.1016/j.knosys.2025.114226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In object detection tasks, remote sensing typically contain far fewer available features compared to natural images. To enhance detection performance, it is crucial for the feature fusion network (neck) to maximize feature fusion while minimizing feature loss during transmission. Many existing studies have adopted complex feature transmission paths to enhance fusion performance. However, complex propagation paths exacerbate feature loss during propagation. To improve fusion capability and reduce feature loss, we propose the Global Fusion Network (GFNet), which incorporates specialized global fusion modules and feature injection modules. The global fusion module generates global features by aggregating and enhancing features through multi-layer reparameterization and feed-forward neural networks prior to feature transmission. The feature injection module injects global features into the transmission layers and enhances feature fusion by integrating adjacent layer features through average pooling and linear interpolation. Additionally, a strip convolution mechanism is introduced to improve sensitivity to strip-shaped objects and enrich relevant object features. The feature loss problem is effectively alleviated by continuously injecting the fused features into the transmission path. Together, these two components significantly enhance the detection performance of GFNet on publicly available remote sensing datasets, including DOTA-v1.0 and HRSC2016, as well as the original low-resolution dataset GTACity.},
  archive      = {J_KBS},
  author       = {Aoran Wang and Xuan Wang and Yongchao Song and Zhe Dai and Haigen Min},
  doi          = {10.1016/j.knosys.2025.114226},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114226},
  shortjournal = {Knowl. Based Syst.},
  title        = {Global fusion network for remote sensing object detection},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imperceptible pixel-precise adaptive multi-level sparse adversarial attacks on video recognition models. <em>KBS</em>, <em>328</em>, 114225. (<a href='https://doi.org/10.1016/j.knosys.2025.114225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video recognition models, pivotal in areas like security, traffic management, and medical diagnostics, face significant challenges due to their vulnerability to adversarial attacks. Existing sparse adversarial attack methods often exhibit low fooling rates and require substantial perturbations, resulting in poor attack stealth.To address the aforementioned issues, we propose an adaptive sparse attack method. Our approach first incorporates Class Activation Map (CAM) technology to quantify the importance of each pixel by analyzing the model’s response to input frames during the backpropagation process. Additionally, we introduce a dynamic adjustment mechanism to set customized spatiotemporal thresholds for each example during the attack. Based on pixel importance, we adaptively identify key regions at the video level using spatial thresholds, ensuring sparsity within frames. Building on these spatial selection results, we further select key frames adaptively through temporal thresholds. This interconnected hierarchical selection process ensures that the resulting 0–1 binary sparse mask exhibits strong spatiotemporal correlations. Furthermore, considering the varying importance of different pixels, we propose an adaptive importance mask. Finally, We utilize Projected Gradient Descent (PGD) attacks extended to the video domain, incorporating adversarial perturbations into key frames and regions to create adversarial examples. Extensive experiments showcase that our method dramatically decreases the number of perturbed pixels needed across five popular video recognition models on three benchmark datasets. Additionally, it achieves a lower mean absolute perturbation. Notably, compared to current state-of-the-art methods, ours achieves a 100 % success rate in attacks, with an average reduction of 75.12 % in mean absolute perturbation and 69.14 % fewer perturbed pixels.},
  archive      = {J_KBS},
  author       = {Xiaolong Shi and Chuxiao Su and Hui Xia and Zi Kang and Rui Zhang and Zuming Zhang},
  doi          = {10.1016/j.knosys.2025.114225},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114225},
  shortjournal = {Knowl. Based Syst.},
  title        = {Imperceptible pixel-precise adaptive multi-level sparse adversarial attacks on video recognition models},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequences and nodes: Probability-guided contrastive learning for hierarchical text classification. <em>KBS</em>, <em>328</em>, 114224. (<a href='https://doi.org/10.1016/j.knosys.2025.114224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical text classification (HTC) is an important task in the field of natural language processing (NLP), which aims to classify text into multiple levels according to a predefined hierarchical structure. While most existing methods integrate text features with label hierarchies to enhance classification accuracy, they often fail to differentiate between fine-grained labels effectively. To overcome this limitation, contrastive learning has emerged as a promising approach to enhance label distinction. However, the complex hierarchical structure of HTC frequently results in low-quality negative samples in current contrastive learning methods, which limits their ability to resolve fine-grained label confusion. To address this challenge, we propose a probability-guided contrastive learning (PGCL) framework that improves label differentiation by constructing high-quality samples from both sequence and node perspectives. Specifically, the sequence-wise method generates diverse negative samples by exploring variations in hierarchical label-path sequences, while the node-wise method refines negative sample quality by dynamically selecting challenging boundary nodes based on their prediction probabilities. By synergistically combining these two complementary methods, PGCL dynamically selects the most difficult and informative sample combinations during various training stages for maximizing contrastive learning effectiveness. This framework not only enables the model to learn more nuanced text representations but also aligns more accurately with the hierarchical label structure. Experiments on three widely used public datasets demonstrate that PGCL achieves state-of-the-art (SOTA) performance on two of them.},
  archive      = {J_KBS},
  author       = {Lijuan Zhang and Juncheng Zhou and Rongli Fan and Neal Xiong and Lei Zhang and Jian Wan},
  doi          = {10.1016/j.knosys.2025.114224},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114224},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequences and nodes: Probability-guided contrastive learning for hierarchical text classification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mamba based adaptive conformal inference for probabilistic short-term load forecasting. <em>KBS</em>, <em>328</em>, 114222. (<a href='https://doi.org/10.1016/j.knosys.2025.114222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate load forecasting is essential for power system stability and operational planning. While deterministic forecasts provide point estimates, they fail to capture uncertainty, which can lead to grid imbalances or reserve misallocations. This study evaluates six non-parametric probabilistic forecasting approaches which are Adaptive Conformal Inference (ACI), Deep Quantile Regression (QR), Bayesian LSTM (BLSTM), CatBoost Quantile Regression, Mamba ACI and Mamba QR applied to short-term load forecasting. The stacked LSTM and Mamba models are first optimized via grid search and then used to generate point forecasts over which prediction intervals are constructed. Using 3.4 years of hourly load data from Tamil Nadu, India, the models are evaluated on an unseen dataset of 8.21 months based on coverage, mean interval width (MIW), Continuous Ranked Probability Score (CRPS), and Winkler score. Mamba ACI achieved the highest coverage (92.47 %) with MIW of 8.5 % of peak load, while LSTM ACI followed with 90.24 % coverage and 5.9 % MIW. CatBoost yielded the sharpest intervals (3.8 % of peak) but with lower coverage (83.81 %). DQR showed moderate performance, and BLSTM achieved 89.60 % coverage with an MIW of 8.0 % of peak load, striking a balance between reliability and sharpness. Mamba QR, though covering 90.29 %, produced excessively wide intervals (26.9 % of peak). The results highlight that ACI delivers the best balance between sharpness and reliability across architectures. Given the importance of coverage in avoiding forecasting-related operational risks, Mamba ACI emerges as the most practical and robust choice for uncertainty quantification in very short-term load forecasting.},
  archive      = {J_KBS},
  author       = {Vishnu Suresh and Anshuman Swain and B. Sri Revathi and Josep M. Guerrero},
  doi          = {10.1016/j.knosys.2025.114222},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114222},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mamba based adaptive conformal inference for probabilistic short-term load forecasting},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary population management for the design of metaheuristic search algorithms: Three improved algorithms, real-time charge scheduling problems, optimal solutions and stability analysis. <em>KBS</em>, <em>328</em>, 114221. (<a href='https://doi.org/10.1016/j.knosys.2025.114221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first introduces evolutionary population management (EPM), which is based on three novel hypotheses on the design of (i) epoch, (ii) update and (iii) mating processes to improve the performance of nature-inspired search algorithms. Secondly, three different algorithms designed based on EPM are introduced. Thirdly, the benchmark suite for real-time charge scheduling problems (CSBP-2) is introduced. Fourth, optimal solutions and stability analysis results for CSBP-2 are presented. According to the results of the statistical analysis of 252 different cases on global optimisation problems and constrained engineering problems, the average Friedman scores of the three EPM-based algorithms and their base versions are (1.205/1.795), (1.276/1.724) and (1.257/1.743), respectively. According to the Wilcoxon pairwise test, the three EPM-based algorithms found better solutions than their base versions in 166 of these 252 comparisons and converged similarly to the optimum in 86 problems. In the study conducted on the CSBP-2 suite for 36 different cases, the average Friedman scores of the three EPM-based algorithms and their base versions are (1.17/1.83), (1.05/1.95) and (1.10/1.90), respectively. According to the Wilcoxon pairwise test results, in 32 of these 36 comparisons, the three EPM-based algorithms managed to find better solutions compared to their base versions, and in 4 cases they converged similarly to the optimum results.},
  archive      = {J_KBS},
  author       = {Furkan Üstünsoy and Hamdi Tolga Kahraman and H. Hüseyin Sayan and Yusuf Sönmez},
  doi          = {10.1016/j.knosys.2025.114221},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114221},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evolutionary population management for the design of metaheuristic search algorithms: Three improved algorithms, real-time charge scheduling problems, optimal solutions and stability analysis},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransNet: A transfer-augmented domain adaptation model for cross-domain water quality index prediction in data-scarce scenarios. <em>KBS</em>, <em>328</em>, 114220. (<a href='https://doi.org/10.1016/j.knosys.2025.114220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freshwater scarcity and rising pollution pose critical challenges to global water resource management. The Water Quality Index (WQI) provides a standardized framework for evaluation, facilitating cross-domain collaborative management. However, traditional WQI prediction models often depend on linear assumptions, struggle with data heterogeneity, and lack cross-domain generalization, failing to capture the dynamic, high-dimensional, and nonlinear interactions inherent in water quality systems. To address these shortcomings, this study introduces TransNet, a novel hybrid model for Transfer-Augmented Domain Adaptation. By incorporating transfer learning, TransNet enhances prediction accuracy in data-scarce scenarios, delivering improved efficiency and robustness. The model combines a multi-reservoir Echo State Network with a fully connected layer, optimized through a mathematically rigorous adaptive parameter tuning approach to bolster cross-domain adaptability. Additionally, a domain alignment strategy mitigates data distribution discrepancies across regions, further improving generalization. Extensive experiments on water quality datasets from the Yangtze River Basin and Hai He Basin demonstrate that TransNet significantly enhances long-term prediction accuracy and cross-domain generalization for four key indicators (pH, DO, NH 3 -N, TN) under data-scarce conditions. Comparative evaluations against state-of-the-art methods, conducted using standardized benchmarking practices, confirm the model’s superior performance, establishing it as a reliable framework for collaborative watershed management and precise pollution control.},
  archive      = {J_KBS},
  author       = {Zehui Mu and Dengao Li and Jumin Zhao and Hairong Jiang and Qi Shao},
  doi          = {10.1016/j.knosys.2025.114220},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114220},
  shortjournal = {Knowl. Based Syst.},
  title        = {TransNet: A transfer-augmented domain adaptation model for cross-domain water quality index prediction in data-scarce scenarios},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGMcRec: Large language models-augmented light graph model for multi-criteria recommendation. <em>KBS</em>, <em>328</em>, 114219. (<a href='https://doi.org/10.1016/j.knosys.2025.114219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of digital personalization, multi-criteria recommender systems (MCRSs) play a vital role in capturing the multi-dimensional nature of user preferences by considering multiple evaluation criteria rather than relying on a single overall rating. However, existing approaches to MCRSs face challenges in managing graph sparsity, criterion independence, and leveraging semantic information for recommendation tasks. To address these limitations, we propose a novel framework named Large L anguage Models-augmented Light G raph Model for M ulti- c riteria Rec ommendation ( LGMcRec ). LGMcRec integrates the strengths of graph neural networks (GNNs) and large language models (LLMs) to improve the representation and recommendation capabilities of MCRSs. In our model, we construct a tripartite graph structure that captures user-item interactions, item-criterion associations, and criterion interdependencies, effectively addressing issues of sparsity and unmodeled correlations in multi-criteria data. We extend the LightGCN architecture to learn embeddings over this graph, which are further enriched through semantic alignment with embeddings generated by LLMs from textual user and item profiles. To bridge the gap between graph-based and LLM-based embeddings, we employ a contrastive learning approach that maximizes the mutual information between the two embedding spaces, ensuring cohesive and comprehensive user and item representations. Experimental results on three MCRS datasets demonstrate that LGMcRec achieves significant performance improvements over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Zhenhua Meng and Fanshen Meng and Rongheng Lin and Budan Wu},
  doi          = {10.1016/j.knosys.2025.114219},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114219},
  shortjournal = {Knowl. Based Syst.},
  title        = {LGMcRec: Large language models-augmented light graph model for multi-criteria recommendation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedECP: Enhancing global collaboration and local personalization for personalized federated learning. <em>KBS</em>, <em>328</em>, 114218. (<a href='https://doi.org/10.1016/j.knosys.2025.114218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) has received a lot of attention, owing to its significant advantages in addressing the statistical heterogeneity problem in federated learning (FL). Existing PFL methods typically partition model parameters by layers into two parts: shared parameters, which participate in global collaboration for learning shared knowledge among clients, and personalized parameters, which are retained locally to facilitate local personalization. However, during local training, parameters inevitably absorb both personalized and shared knowledge, preventing the shared and personalized parameters from effectively fulfilling their intended roles, weakening the effectiveness of global collaboration and local personalization. To address this issue, we propose a new PFL method called FedECP. FedECP stores global and personalized knowledge in separate models, preventing the interference and achieving a clearer separation of knowledge. Furthermore, we optimize the model learning strategy at both the feature representation and model parameter levels so that shared parameters learn shared knowledge, and the personalized parameters learn client-specific personalized knowledge. We conduct extensive experiments on four benchmark datasets, comparing FedECP with twelve state-of-the-art methods. The results demonstrate that FedECP performs well in various heterogeneous scenarios.},
  archive      = {J_KBS},
  author       = {Yingxun Fu and Shulan Yin and Li Ma and Jie Liu},
  doi          = {10.1016/j.knosys.2025.114218},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114218},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedECP: Enhancing global collaboration and local personalization for personalized federated learning},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GMVE: Graph-mamba variational encoder for interpretable remaining useful life prediction with uncertainty quantification. <em>KBS</em>, <em>328</em>, 114217. (<a href='https://doi.org/10.1016/j.knosys.2025.114217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the remaining useful life (RUL) of industrial systems is essential for effective prognostics and health management. However, current deep learning approaches often fail to adequately model complex spatiotemporal dependencies in multi-sensor data and lack the interpretability crucial for maintenance decision-making. This study presents a graph-Mamba variational encoder (GMVE) that addresses these limitations through three key innovations: a graph-edge attention mechanism that captures dynamic inter-sensor relationships, the integration of these relationships into Mamba’s selective state space model for efficient temporal modeling, and a variational framework that enables both uncertainty quantification and interpretable representation of system degradation. The GMVE maps degradation patterns into a probabilistic latent space where mean and variance parameters enable accurate RUL predictions with uncertainty estimates. Experiments conducted on benchmark datasets reveal that the GMVE outperforms state-of-the-art methods while offering valuable insights into equipment health evolution. The proposed approach effectively unifies spatiotemporal dependency modeling with uncertainty-aware interpretable predictions, thereby advancing prognostics for complex industrial systems.},
  archive      = {J_KBS},
  author       = {Bing Yu and Zhiming Yang and Yang Yu and Gang Xiang},
  doi          = {10.1016/j.knosys.2025.114217},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114217},
  shortjournal = {Knowl. Based Syst.},
  title        = {GMVE: Graph-mamba variational encoder for interpretable remaining useful life prediction with uncertainty quantification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reviewing clinical knowledge in medical large language models: Training and beyond. <em>KBS</em>, <em>328</em>, 114215. (<a href='https://doi.org/10.1016/j.knosys.2025.114215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large-scale development of large language models (LLMs) in medical contexts, such as diagnostic assistance and treatment recommendations, necessitates that these models possess accurate medical knowledge and deliver traceable decision-making processes. Clinical knowledge, encompassing the insights gained from research on the causes, prognosis, diagnosis, and treatment of diseases, has been extensively examined within real-world medical practices. Recently, there has been a notable increase in research efforts aimed at integrating this type of knowledge into LLMs, encompassing not only traditional text and multimodal data integration but also technologies such as knowledge graphs (KGs) and retrieval-augmented generation (RAG). In this paper, we review the various initiatives to embed clinical knowledge into training-based, KG-supported, and RAG-assisted LLMs. We begin by gathering reliable knowledge sources from the medical domain, including databases and datasets. Next, we evaluate implementations for integrating clinical knowledge through specialized datasets and collaborations with external knowledge sources such as KGs and relevant documentation. Furthermore, we discuss the applications of the developed medical LLMs in the industrial sector to assess the disparity between models developed in academic settings and those in industry. We conclude the survey by presenting evaluation systems applicable to relevant tasks and identifying potential challenges facing this field. In this review, we do not aim for completeness, since any ostensibly “complete” review would soon be outdated. Our goal is to illustrate diversity by selecting representative and accessible items from current research and industry practices, reflecting real-world situations rather than claiming completeness. Thus, we emphasize showcasing diverse approaches.},
  archive      = {J_KBS},
  author       = {Qiyuan Li and Haijiang Liu and Caicai Guo and Chao Gao and Deyu Chen and Meng Wang and Feng Gao and Frank van Harmelen and Jinguang Gu},
  doi          = {10.1016/j.knosys.2025.114215},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114215},
  shortjournal = {Knowl. Based Syst.},
  title        = {Reviewing clinical knowledge in medical large language models: Training and beyond},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extended LSTM network with multi-scale channels attention for remaining useful life prediction and predictive uncertainty quantification. <em>KBS</em>, <em>328</em>, 114214. (<a href='https://doi.org/10.1016/j.knosys.2025.114214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A notable increase in scholarly attention has been witnessed in recent times, specifically regarding the application of deep learning methodologies for the precise prediction of remaining useful life (RUL). The squeeze-and-excitation (SE) network and attention mechanism (AM) are widely employed to extract feature representation across the multi-scale channels. However, the implementation of these techniques results in redundant feature extraction operations and a significant increase in computational burden. Here, we propose an extended long short-term memory (LSTM) model with multi-scale channel attention (MSCA-ELSTM) as a solution to the above challenges. First, the multi-scale channel attention (MSCA) module is engineered to allocate weights across multi-scale channels through a lightweight feature extraction operation. Then, the extended LSTM (ELSTM) is devised to address the limitations existing in the LSTM model by revising the storage mechanism. Compared to the traditional LSTM, the ELSTM demonstrates superior adaptability in processing the long-term and highly fluctuating time-series data. It contributes to enhancing the extraction of feature representations. Ultimately, a Bayesian neural network functions as the regression layer to generate RUL predictions with predictive uncertainty. The prediction efficacy is substantiated through experimental validation on the aero-engine dataset.},
  archive      = {J_KBS},
  author       = {Fanfan Gan and Ping Zhou and Baizhan Xia},
  doi          = {10.1016/j.knosys.2025.114214},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114214},
  shortjournal = {Knowl. Based Syst.},
  title        = {An extended LSTM network with multi-scale channels attention for remaining useful life prediction and predictive uncertainty quantification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WD2L: A novel approach for overcoming data imbalance in whole-body pose estimation. <em>KBS</em>, <em>328</em>, 114213. (<a href='https://doi.org/10.1016/j.knosys.2025.114213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of whole-body pose estimation is to detect and localize human-body keypoints in input images. However, training-data imbalances across keypoints significantly degrade the model’s performance in certain keypoint categories. Despite its importance, research on the impact of data imbalance in whole-body pose estimation has been limited. We propose a whole-body data debias learning (WD2L) technique to mitigate keypoint data imbalances in whole-body pose estimation. The original label distributions inadequately capture data imbalances, partly because of correlations between keypoints. We introduce a labeling distribution smoothing module to create a smoothed distribution that better reflects the skewed data. This smoothed distribution is then used to reweight keypoint learning. Additionally, we apply feature-distribution smoothing to prevent the features of minority keypoints from becoming overly similar to that of majority keypoints. Extensive experiments on two whole-body pose-estimation datasets show that our model achieves competitive performance and outperforms most of the state-of-the-art methods in several key metrics.},
  archive      = {J_KBS},
  author       = {Rui Ma and Bin Zhang and Xuegang Dai and Jian Liu},
  doi          = {10.1016/j.knosys.2025.114213},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114213},
  shortjournal = {Knowl. Based Syst.},
  title        = {WD2L: A novel approach for overcoming data imbalance in whole-body pose estimation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CDSF: A curvature-driven semi-supervised framework with dynamic receptive fields for fine-grained vehicle component segmentation. <em>KBS</em>, <em>328</em>, 114211. (<a href='https://doi.org/10.1016/j.knosys.2025.114211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate semantic segmentation of vehicle exterior components is crucial for automotive design, manufacturing, and quality inspection. However, existing fully supervised methods rely on extensive pixel-level annotations, resulting in high labeling costs that are impractical for large-scale industrial applications. While semi-supervised methods alleviate some of the annotation burden, they still face challenges regarding pseudo-label quality and model robustness, especially when handling high-curvature regions and complex boundaries. To address these issues, we propose a novel curvature-aware semi-supervised framework (CSDF) that integrates curvature-driven dynamic adaptation with edge-guided feature aggregation. By dynamically adjusting receptive fields and pseudo-label confidence thresholds, our approach effectively preserves fine details in high-curvature areas while capturing broader context in low-curvature regions, significantly enhancing segmentation accuracy.Extensive experiments demonstrate that, under comparable parameter sizes and training speeds, our method consistently outperforms state-of-the-art approaches, particularly in industrial scenarios with complex boundaries, highlighting its superior segmentation performance and practical applicability in real-world settings.},
  archive      = {J_KBS},
  author       = {Zhili Gong and Chunyuan Zheng and Shanshan Huang and Huayi Yang and Guoxin Su and Li Liu},
  doi          = {10.1016/j.knosys.2025.114211},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114211},
  shortjournal = {Knowl. Based Syst.},
  title        = {CDSF: A curvature-driven semi-supervised framework with dynamic receptive fields for fine-grained vehicle component segmentation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Searching for the best student architecture in a knowledge distillation framework. <em>KBS</em>, <em>328</em>, 114210. (<a href='https://doi.org/10.1016/j.knosys.2025.114210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation aims to find a smaller model (i.e., student) that can perform at the level of a larger model (i.e., teacher). While the student model is highly beneficial in resource-constrained environments, finding the optimal student remains challenging due to the extensive search required through potential architectures and hyperparameters. To address this, we introduce a novel framework that integrates a caching mechanism and proximity analysis into Reinforcement Learning (RL) for Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in knowledge distillation. This approach improves computational efficiency by avoiding redundant evaluations and estimating the performance of similar configurations. Our results, benchmarked against foundational and modern evolutionary search methods, demonstrate that the proposed framework can reduce full training evaluations by over 75 % relative to a standard RL search, offering a robust advantage in computationally or operationally constrained environments.},
  archive      = {J_KBS},
  author       = {Steve Bakos and Heidar Davoudi},
  doi          = {10.1016/j.knosys.2025.114210},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114210},
  shortjournal = {Knowl. Based Syst.},
  title        = {Searching for the best student architecture in a knowledge distillation framework},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature analysis for proper intensity scaling and feature distinction in class activation maps. <em>KBS</em>, <em>328</em>, 114209. (<a href='https://doi.org/10.1016/j.knosys.2025.114209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the decisions of deep learning (DL) models is crucial for their acceptance in risk-sensitive applications. Class activation maps (CAMs) are commonly used in image analysis to visualize model reasoning by generating attention maps where signal intensities represent contributions to outputs. However, existing CAM algorithms focus on optimal weight design and salient feature layer selection, neglecting two key limitations in population-level interpretation: (1) lack of an appropriate intensity scale for proper interpretation and quantitative analysis, and (2) inability to identify which features within selected layers predominantly drive model reasoning. These gaps can lead to miscorrelations between CAMs and model outputs, causing erroneous interpretations, while restricting CAMs to case-specific visual inspections. We propose a framework to statistically analyze DL-extracted features at a population level, determinizing feature contributions for global intensity scaling and within-layer feature distinction. The global intensity scale standardizes CAMs, achieving high correlation coefficients (R) with model outputs. Within-layer feature distinction identifies overfitting, confounding factors, outliers, redundancies, and principal features. Applied to eight datasets, including five medical imaging datasets, this framework improved Rs between CAMs and outputs by 10.7–64.2 %, achieving near 100 % consistency. Furthermore, distinguishing principal features (5–25 % in the selected layer) produced CAMs of equal quality while maintaining model output accuracy. This method, relying on minimal assumptions, enhances CAM-model consistency and broadens CAM applications by enabling standardized interpretation and deeper feature-level insights.},
  archive      = {J_KBS},
  author       = {Yanli Li and Denis P. Shamonin and Tahereh Hassanzadeh and Monique Reijnierse and Annette H.M. van der Helm-van Mil and Berend C. Stoel},
  doi          = {10.1016/j.knosys.2025.114209},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114209},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature analysis for proper intensity scaling and feature distinction in class activation maps},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained visual tracking via distribution-aware mask modeling and temporal propagation. <em>KBS</em>, <em>328</em>, 114208. (<a href='https://doi.org/10.1016/j.knosys.2025.114208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking holds significant importance in enabling diverse practical applications, yet critical challenges persist in two key aspects: target characterization and motion dynamics. Foreground-background discrimination becomes problematic under real-world complexities like occlusion and scale variation, necessitating highly discriminative feature extraction. Moreover, appearance changes during target motion render static template strategies insufficient, demanding dynamic template updates to ensure continuity and prevent tracker drift. In this paper, we present FGTrack, a novel single object tracker that addresses these challenges through two perspectives. First, the Distribution-Aware Mask Modeling (DMM) enhances feature discriminability by leveraging Transformer attention distribution in conjunction with GridShift clustering to generate nuanced foreground mask. Building upon token candidate elimination from one-stream training process, this approach employs a simple yet efficient adaptive clustering to achieve precise foreground localization without the need for manual threshold adjustment. It effectively suppresses background interference by utilizing the token correlation between the template and search regions. Second, the Temporal Feature Propagation (TFP) ensures motion consistency by integrating autoregressive queries with spatio-temporal features. The TFP module maintains a dynamically updated query queue and aggregates historical features through a temporal attention mechanism. The spatio-temporal fusion maintains adaptive template updates and correlates the current frame’s spatially encoded features with historical queries, capturing target evolution patterns through multi-head cross-attention. Experiments across five short-term and two long-term benchmarks demonstrate FGTrack’s superiority over state-of-the-art trackers, particularly in occlusion and deformation scenarios, validating its balanced approach to spatial discrimination and temporal coherence. The code will be released at https://github.com/BroCome25/FGTrack .},
  archive      = {J_KBS},
  author       = {Xin Zhou and Junjie Zhang and Hongwen Yu and Fangyu Wu and Xiaoshui Huang and Jian Zhang},
  doi          = {10.1016/j.knosys.2025.114208},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114208},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained visual tracking via distribution-aware mask modeling and temporal propagation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BCVR: Bootstrap clustering with variance regularization and covariance contrast for self-supervised learning. <em>KBS</em>, <em>328</em>, 114207. (<a href='https://doi.org/10.1016/j.knosys.2025.114207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has made significant progress by using auxiliary tasks to extract supervised information from large-scale unlabeled data. However, SSL methods rely on pseudo-labels generated from the data itself rather than true labels, making them susceptible to the presence of false positives and false negatives. Therefore, we propose a new method, “BCVR: B ootstrap C lustering with V ariance R egularization and Covariance Contrast for Self-Supervised Learning”, which utilizes two identical deep neural networks, but maintains separate weights. One network serves as the online network, which is used to predict the representations of the target network, while the other acts as the target network, which is updated using a moving average of the online network’s parameters. Firstly, to address the challenge of lacking reallabels, BCVR incorporates Sinkhorn-Knopp clustering within the online network. The clustering algorithm iteratively updates a regularized assignment matrix, grouping similar data points while separating dissimilar ones, thereby improving pseudo-label quality. Secondly, to mitigate vanishing gradients, we propose an RBMLP architecture by placing Batch Normalization after the Rectified Linear Unit in both the online and target networks. RBMLP helps stabilize training and enhances feature representation in the Predictor and Projector of BCVR. Finally, to mitigate false positives and negatives, BCVR introduces a new loss function that combines variance invariance, covariance regularization, redundancy elimination, and correlation clustering. Experiments show that,with a standard ResNet-50 and a small batch size, BCVR achieves 52.2 % top-1 classification accuracy on ImageNet using K-Nearest-Neighbor evaluation, surpassing supervised learning by 5.7 % . Code is available at https://github.com/Tracygc/BCVR .},
  archive      = {J_KBS},
  author       = {Cong Guo and Kan Ren and Qian Chen},
  doi          = {10.1016/j.knosys.2025.114207},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114207},
  shortjournal = {Knowl. Based Syst.},
  title        = {BCVR: Bootstrap clustering with variance regularization and covariance contrast for self-supervised learning},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing ovarian cancer outcomes with CTGAN-enhanced hybrid machine learning approach. <em>KBS</em>, <em>328</em>, 114206. (<a href='https://doi.org/10.1016/j.knosys.2025.114206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer is a gynecologic malignancy with a high mortality rate owing to its asymptomatic nature and often late diagnosis. Early detection is vital to improving patient outcomes, and machine learning techniques have shown promise in assisting with diagnosis and prognosis. However, a lack of data can make it difficult to achieve significant results. The objective of this study is to assess the ability of machine learning to detect ovarian cancer despite having only a limited amount of clinical data. To address the limited data issue, we employ the Conditional Tabular Generative Adversarial Network (CTGAN), a technique that generates highly correlated data by using the original data to increase the data size. Subsequently, we developed an ensemble model named Decision Logistic Forest (DLF) that combines three models (logistic regression, the decision tree, and random forest) and uses majority voting and probability based on voting criteria. The proposed DLF achieved significant accuracy of 99 % by using CTGAN data augmentation, demonstrating its potential in assisting with ovarian cancer diagnosis and prognosis. The statistical T-test demonstrates the significance of the proposed approach compared to other approaches.},
  archive      = {J_KBS},
  author       = {Rahman Shafique and Ahmad Sami Al-Shamayleh and Sarath Kumar Posa and Abid Ishaq and Furqan Rustam and Gyu Sang Choi},
  doi          = {10.1016/j.knosys.2025.114206},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114206},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing ovarian cancer outcomes with CTGAN-enhanced hybrid machine learning approach},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVCNet: Multi-view contrastive network for motor imagery classification. <em>KBS</em>, <em>328</em>, 114205. (<a href='https://doi.org/10.1016/j.knosys.2025.114205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG)-based brain-computer interfaces (BCIs) enable neural interaction by decoding brain activity for external communication. Motor imagery (MI) decoding has received significant attention due to its intuitive mechanism. However, most existing models rely on single-stream architectures and overlook the multi-view nature of EEG signals, leading to limited performance and generalization. We propose a multi-view contrastive network (MVCNet), a dual-branch architecture that parallelly integrates CNN and Transformer blocks to capture both local spatial-temporal features and global temporal dependencies. To enhance the informativeness of training data, MVCNet incorporates a unified augmentation pipeline across time, frequency, and spatial domains. Two contrastive modules are further introduced: a cross-view contrastive module that enforces consistency of original and augmented views, and a cross-model contrastive module that aligns features extracted from both branches. Final representations are fused and jointly optimized by contrastive and classification losses. Experiments on five public MI datasets across three scenarios demonstrate that MVCNet consistently outperforms nine state-of-the-art MI decoding networks, highlighting its effectiveness and generalization ability. MVCNet provides a robust solution for MI decoding by integrating multi-view information and dual-branch modeling, contributing to the development of more reliable BCI systems.},
  archive      = {J_KBS},
  author       = {Ziwei Wang and Siyang Li and Xiaoqing Chen and Dongrui Wu},
  doi          = {10.1016/j.knosys.2025.114205},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114205},
  shortjournal = {Knowl. Based Syst.},
  title        = {MVCNet: Multi-view contrastive network for motor imagery classification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LbpRIPooling: A novel rotation-invariant pooling method for CNNs. <em>KBS</em>, <em>328</em>, 114204. (<a href='https://doi.org/10.1016/j.knosys.2025.114204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pooling layers in convolutional neural networks (CNNs) are crucial for reducing computational complexity and facilitating deeper model training by downsampling image/feature maps. While max and average pooling are commonly used for their efficiency, they fail to retain pixel position information, leading to potential informationloss. LbpPooling addresses this by considering pixel neighborhoods and preserving local correlations but generates different values when the input image is rotated, affecting performance. This paper introduces LbpRIPooling, a novel method that provides rotation-invariant values by dynamically assigning weights based on the magnitude of values in the pooling area. LbpRIPooling is evaluated against LbpPooling, max pooling, average pooling, and several advanced pooling techniques across diverse datasets, consistently demonstrating superior performance, particularly on challenging datasets like CIFAR10 and CIFAR100, and Pins Face Recognition. Additionally,these methods are integrated into transfer learning models such as DenseNet121, VGG16, ResNet50, InceptionV3, and the recent transformer-based MaxViT architecture. DenseNet121, with LbpRIPooling, surpasses LbpPooling by 0.78 % on CIFAR10 and outperforms the original model by 2.33 %. On CIFAR100, LbpRIPooling shows a 9.16 % improvement over LbpPooling and a 15.78 % improvement over the original model. To demonstrate real-world applicability, LbpRIPooling was tested on the Pins Face dataset, confirming its robustness to rotation in practical scenarios. The method achieved the highest accuracy and F1-score among compared pooling strategies, validating its effectiveness in real-world face recognition tasks.This method’s ability to consistently preserve meaningful information highlights its potential for significant advancements in CNN-basedtasks.},
  archive      = {J_KBS},
  author       = {Yahya Dogan},
  doi          = {10.1016/j.knosys.2025.114204},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114204},
  shortjournal = {Knowl. Based Syst.},
  title        = {LbpRIPooling: A novel rotation-invariant pooling method for CNNs},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective multi-objective metaheuristic for the support vector machine with feature selection. <em>KBS</em>, <em>328</em>, 114203. (<a href='https://doi.org/10.1016/j.knosys.2025.114203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is crucial in supervised learning, mainly when dealing with high-dimensional datasets, since the models’ efficiency decreases due to the curse of dimensionality. Reducing the number of features enhances computational efficiency and improves models’ interpretability and generalization. Support vector machine (SVM) has been widely used with FS due to its ability to assign importance to individual features through feature-specific regressors, which can be eliminated when deemed irrelevant. This paper proposes a multi-objective metaheuristic approach based on non-dominated sorting genetic algorithm II, integrating FS into the soft-margin SVM model to optimize both predictive performance and computational efficiency. Unlike prior methods with static FS, our approach dynamically selects features to approximate the Pareto-optimal frontier, balancing structural and empirical risk. The proposed algorithm incorporates a novel solution representation, specialized crossover and mutation operators, and a weighted optimization strategy to effectively handle dataset imbalances. Additionally, we apply effective parameter tuning based on three considered performance metrics, resulting in three distinct versions of our approach, each exhibiting different search behaviors. Extensive experiments on well-known binary classification datasets demonstrate that all three versions outperform the state-of-the-art algorithm in both predictive performance and computational efficiency within the given time limits. Among them, the version that employs a conservative FS strategy, maintaining larger feature subsets while applying high mutation rates, achieved the best overall results. In addition, our approach also exhibits competitive performance on real-world large-scale datasets.},
  archive      = {J_KBS},
  author       = {Mathias Badilla-Salamanca and Rosa Medina Durán and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114203},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114203},
  shortjournal = {Knowl. Based Syst.},
  title        = {An effective multi-objective metaheuristic for the support vector machine with feature selection},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Most likely heteroscedastic gaussian process via kernel smoothing. <em>KBS</em>, <em>328</em>, 114202. (<a href='https://doi.org/10.1016/j.knosys.2025.114202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is an intrinsic aspect of many scientific experiments and stochastic simulations. In these settings, observation noise can vary across the input space, leading to heteroscedasticity. Heteroscedastic Gaussian process (HGP) regression has been widely used as a surrogate model in various applications due to its capability to handle noise-varying problems. However, the computational cost of HGP models remains high. In this paper, we propose a novel approach to reduce this computational burden. Our method follows a post-modelling learning strategy akin to the most likely heteroscedastic Gaussian process (MLHGP) algorithm. Unlike the MLHGP and its variations, which require multiple GP models, our proposed methodology only requires one GP model to fit the main function and uses the trained kernel parameters to estimate the noise level via kernel smoothing regression. Our proposed method is able to reduce the computational complexity from O ( 2 N 3 ) to O ( N 3 + N 2 ) and cut the requirements of training two models to only one. This approach translates to roughly 2 × speed-up during training in our test cases. We also found that the proposed method is able to achieve better and more stable performance metrics. Additionally, in our Bayesian optimisation test case, the result shows that the proposed method outperforms MLHGP in case of a low number of initial observations and remains competitive in the medium and high initial observation settings, all while being faster in every case.},
  archive      = {J_KBS},
  author       = {Ghifari Adam Faza and Nasrulloh R.B.S. Loka and Keivan Shariatmadar and Hans Hallez and David Moens},
  doi          = {10.1016/j.knosys.2025.114202},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114202},
  shortjournal = {Knowl. Based Syst.},
  title        = {Most likely heteroscedastic gaussian process via kernel smoothing},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OAFN: An efficient open-world audio few-shot learning network for event classification. <em>KBS</em>, <em>328</em>, 114201. (<a href='https://doi.org/10.1016/j.knosys.2025.114201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of audio events is essential for a wide range of real-world applications, including anomaly detection, species conservation, and new species discovery. However, these tasks are often hindered by several challenges, such as complex data acquisition, limited sample availability, and the need for precise recognition. While few-shot learning has shown efficacy in addressing data scarcity, existing approaches largely overlook the challenges posed by mixed label noise and environmental interference in real-world audio datasets. To address these issues, we propose the O pen-world A udio F ew-Shot Learning N etwork (OAFN), a novel framework designed to mitigate both label noise and environmental noise in few-shot audio event classification. Our method quantifies the similarity between samples and labels, leveraging a dual-channel calibration strategy to enhance label noise learning. We used MobileNetV3 as the feature extraction backbone and employed transfer learning to improve audio feature representation, particularly in low-data scenarios, thereby enhancing noise robustness. In addition, we incorporated mixed data perturbation techniques to further strengthen the model’s resilience against diverse environmental noise. Extensive experiments on the ESC-50, Watkins Marine Mammal Sounds (WMMS), and BirdCLEF 2020 datasets showed that our approach achieved state-of-the-art(SOTA) recognition accuracy in scenarios involving label noise, environmental noise, and their combination.},
  archive      = {J_KBS},
  author       = {Fei Chen and Hui Xue and Pengfei Fang},
  doi          = {10.1016/j.knosys.2025.114201},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114201},
  shortjournal = {Knowl. Based Syst.},
  title        = {OAFN: An efficient open-world audio few-shot learning network for event classification},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel consistency low-rank graph learning for multi-view clustering. <em>KBS</em>, <em>328</em>, 114200. (<a href='https://doi.org/10.1016/j.knosys.2025.114200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering has attracted significant attention due to the ability to capture potential associations among data. Existing multi-view graph learning methods learn graphs that contain noise and primarily explore consistency information through graph fusion. Few methods simultaneously consider learning higher-quality graphs and exploiting the latent consistency information in multi-view data. In this paper, we propose a novel Consistency Low-rank Graph Learning for Multi-view Clustering, called CLGLMC. Specially, we learn the initial graphs through adaptive neighbor method, and employ Robust Principal Component Analysis (RPCA) to decompose the initial graphs into low-rank graphs and sparse noise. Meanwhile, we impose a rank equality constraint on the low-rank graphs, where the rank is equal to the number of clusters, to indicate the novel consistency. We use matrix factorization with an orthogonality constraint to solve the rank constraint problem. Above all procedures are into a unified objective function that encourages mutual promote each other during the optimization process. The clustering results are obtained by applying K -means clustering to the optimized shared consensus matrix by matrix factorization. We employ an Augmented Lagrangian Multiplier (ALM) approach to optimize the objective function. Extensive experiments on benchmark multi-view datasets demonstrate that our method outperforms several advanced approaches for clustering performance.},
  archive      = {J_KBS},
  author       = {Lin Liu and Shuisheng Zhou and Dezheng Kong and Ying Zhang and Banghe Han and Yinli Dong},
  doi          = {10.1016/j.knosys.2025.114200},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114200},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel consistency low-rank graph learning for multi-view clustering},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced near-field depth estimation: Integrating global and local path networks. <em>KBS</em>, <em>328</em>, 114198. (<a href='https://doi.org/10.1016/j.knosys.2025.114198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional depth estimation models often focus on global scene features, limiting their accuracy with near-field objects critical for applications like autonomous driving and robotic grasping. To overcome this limitation, this paper aims to develop model architecture specifically tailored for near-field depth estimation. The proposed Near-field Global-Local Path Network (NF-GLPN) integrates a U-Net-based attention mechanism with the Global-Local Path Network (GLPN) architecture and employs a multi-loss training strategy, dynamically balancing global and near-field feature learning during training. Experiments on the NYU Depth V2 and KITTI datasets demonstrate that NF-GLPN outperforms existing advanced models across various depth estimation metrics, particularly excelling in scenes dominated by near-field objects, thereby offering enhanced depth perception accuracy and stability for space-constrained or safety-critical applications.},
  archive      = {J_KBS},
  author       = {Yu-Hsiang Chen and Yu-Jen Chen and Chung-Chian Hsu},
  doi          = {10.1016/j.knosys.2025.114198},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114198},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced near-field depth estimation: Integrating global and local path networks},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Labeling issues through semantic patterns in open-source agile practices. <em>KBS</em>, <em>328</em>, 114197. (<a href='https://doi.org/10.1016/j.knosys.2025.114197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, our objective is to find a balanced trade-off between interpretability and accurate, reliable Issue classification-specifically Bug severity-by creating an ensemble Machine Learning (ML) and Natural Language Processing (NLP) methodological approach that enhances software maintenance in Agile development environments. Using the TAWOS dataset, we explored the capabilities of state-of-the-art models such as eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Categorical Boosting (CatBoost), integrated with advanced NLP techniques such as Term Frequency-Inverse Document Frequency (TF-IDF) and Singular Value Decomposition (SVD) for feature extraction. Our results demonstrate that CatBoost achieved superior performance, with accuracies of 99. 61 % for ‘high’ labeled severity bugs, 97.73 % for ‘Critical’ , and 97.65 % for ‘Blocker’ . SHapley Additive exPlanations (SHAP) analysis further identified key semantic descriptors, such as “crash” and “timeout,” as critical predictors in these models. Moreover, this research addresses a critical gap in software engineering by improving the precision and efficiency of bug triaging processes, thereby supporting more effective resource allocation and reducing costs in Agile software projects. Finally, the comprehensive preprocessing pipeline we developed, including lemmatization, outlier removal, and non-oversampling techniques, was essential in optimizing model performance, offering a robust framework for enhancing software quality assurance.},
  archive      = {J_KBS},
  author       = {Nevena Rankovic and Dragica Rankovic},
  doi          = {10.1016/j.knosys.2025.114197},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114197},
  shortjournal = {Knowl. Based Syst.},
  title        = {Labeling issues through semantic patterns in open-source agile practices},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular stochastic configuration networks for uncertain data modeling. <em>KBS</em>, <em>328</em>, 114196. (<a href='https://doi.org/10.1016/j.knosys.2025.114196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular neural networks (GrNNs) leverage granular computing (GrC) to process information granules and offer a promising alternative to resolving uncertain data modeling tasks. However, challenges such as difficult optimisation, sensitivity to initialization, and slow convergence are still remained. To address these limitations, this study proposes granular stochastic configuration networks (GrSCNs), a novel method that seamlessly integrates GrC with incremental learning and stochastic configuration strategies. The dynamic granulation approach allows GrSCNs to adapt to uncertain data efficiently and effectively minimize reliance on expert knowledge. Advanced optimization techniques, including hybrid fitness functions and customized model-construction approaches, achieve an good balance between coverage and specificity in interval information learning with help from the particle swarm optimization (PSO). Experimental results on simulated datasets and industrial applications validate the superior effectiveness of the proposed GrSCNs in dealing with uncertain data regression and clearly indicate the potential of GrSCNs for resolving complex data modeling tasks.},
  archive      = {J_KBS},
  author       = {Yuanhang Qiu and Dianhui Wang},
  doi          = {10.1016/j.knosys.2025.114196},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114196},
  shortjournal = {Knowl. Based Syst.},
  title        = {Granular stochastic configuration networks for uncertain data modeling},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-enhanced multi-level knowledge distillation for molecular property prediction. <em>KBS</em>, <em>328</em>, 114195. (<a href='https://doi.org/10.1016/j.knosys.2025.114195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting molecular properties is paramount in drug development, yet traditional methods are inefficient and costly. Existing models also face limitations such as overreliance on molecular geometry, insufficient knowledge utilization, and poor generalization capability resulting from the single-learner strategy. This paper proposes MolLLMKD , a novel method for molecular property prediction by integrating L arge L anguage M odel (LLM) enhancement and M ulti-level K nowledge D istillation. Unlike using LLM to directly generate relevant descriptions, MolLLMKD first designs a user input template. LLM will generate robust, rich, and normative descriptions of molecules according to the requirements of the template and regard these descriptions as prompts, which avoids the hallucination problem of LLM. These prompts help extract high-precision molecular features that enhance downstream tasks. Secondly, MolLLMKD designs a multi-level distillation that allows two graph neural network models to exchange knowledge at various levels of molecular structure (atom level, bond level, substructure level, molecule level) for mutual benefit. Finally, it adopts an innovative hierarchical message-passing neural network (HMPNN) as the encoder for comprehensive molecular analysis. MolLLMKD not only leverages the prompts from LLM but also aggregates all-around information of molecular graphs, including atoms, bonds, substructures and the entire molecule, thereby making full use of the rich information contained in molecular graphs. MolLLMKD achieves state-of-the-art results on 12 benchmark datasets, demonstrating its great potential and superiority in molecular property prediction.},
  archive      = {J_KBS},
  author       = {Luhe Zhuang and Yanshen Sun and Jun Zhao and Yue Lu and Hong Wang},
  doi          = {10.1016/j.knosys.2025.114195},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114195},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-enhanced multi-level knowledge distillation for molecular property prediction},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling for dual-resource constrained flexible job-shop via semantic-aware graph modelling and deep reinforcement learning. <em>KBS</em>, <em>328</em>, 114192. (<a href='https://doi.org/10.1016/j.knosys.2025.114192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual-resource constrained flexible job-shop scheduling problem (DRCFJSP) poses significant challenges in dynamic manufacturing environments. Effective scheduling requires the integration of heterogeneous data from machines, workers, and operations and the ability to adapt to real-time changes. To address these challenges, this study proposes a hybrid scheduling method that combines knowledge graph (KG) techniques with deep reinforcement learning (DRL) to enable adaptive decision-making. A scheduling optimisation model is first formulated to minimise makespan and total production cost. To support real-time environmental perception, a manufacturing process dynamic knowledge graph (MPDKG) is constructed using a multi-level ontology framework. The MPDKG represents static attributes and dynamic states of scheduling entities, allowing continuous data updates during production. Semantic features are extracted using a semantic-aware heterogeneous graph attention network (SHGAT), which incorporates relation-aware and node-aware semantic aggregation to fuse multi-source data and capture global contextual information on operations, machines, and workers. The extracted features characterise the current state of the shop floor and serve as input to a multi-actor proximal policy optimisation (MA-PPO) algorithm. MA-PPO assigns specialised agents to different scheduling entities and learns coordinated decision policies through interaction with the environment. Experimental results from an aerospace structural component workshop show that the proposed method significantly outperforms baseline approaches in responsiveness and scheduling efficiency. These findings demonstrate the method’s effectiveness and applicability in complex, dynamic production scenarios.},
  archive      = {J_KBS},
  author       = {Yiwen Hu and Jie Chen and Zequn Zhang and Dunbing Tang and Qixiang Cai},
  doi          = {10.1016/j.knosys.2025.114192},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114192},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic scheduling for dual-resource constrained flexible job-shop via semantic-aware graph modelling and deep reinforcement learning},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IntelliCare: Improving healthcare analysis with patient-level knowledge from large language models. <em>KBS</em>, <em>328</em>, 114191. (<a href='https://doi.org/10.1016/j.knosys.2025.114191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While pioneering deep learning approaches have made significant progress in analyzing electronic health record (EHR) data, they often struggle to fully capture the semantics of diverse medical codes-especially when trained on limited datasets. Integrating external knowledge from Large Language Models (LLMs) offers a promising path toward enhancing healthcare prediction models. However, LLM responses for EHR data can exhibit high variability due to issues such as ambiguity and inconsistency, which hinder their practical application. To address these challenges, we propose IntelliCare, a novel framework that effectively leverages LLMs to generate high-quality, patient-level external knowledge and enhance existing EHR models. IntelliCare first identifies relevant patient cohorts and incorporates task-specific statistical information to improve LLM understanding and generation for clinical prediction tasks, thereby mitigating ambiguity. Furthermore, it refines LLM-derived knowledge through a hybrid strategy that calibrates multiple LLM responses using both EHR model embeddings and perplexity measures. Experimental evaluations across three clinical prediction tasks on two large-scale EHR datasets demonstrate that IntelliCare significantly improves performance over existing methods, underscoring its potential for advancing personalized healthcare predictions and decision support systems for physicians. Our code is available at https://github.com/yzhHoward/IntelliCare .},
  archive      = {J_KBS},
  author       = {Zhihao Yu and Yujie Jin and Yongxin Xu and Xiaoyun Zhang and Yasha Wang},
  doi          = {10.1016/j.knosys.2025.114191},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114191},
  shortjournal = {Knowl. Based Syst.},
  title        = {IntelliCare: Improving healthcare analysis with patient-level knowledge from large language models},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cyclical loss-based optimization algorithm for pretraining LLMs on noisy data. <em>KBS</em>, <em>328</em>, 114189. (<a href='https://doi.org/10.1016/j.knosys.2025.114189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) depend on vast web-scale datasets, which frequently include noisy or low-quality samples that degrade performance and fairness-despite conventional data cleaning. This paper introduces an in-training filtering approach that selectively ignores noisy data points based on real-time loss statistics during training. The approach combines deterministic and probabilistic selection mechanisms using robust loss-based metrics and cyclically adjusted thresholds to balance stability and diversity. Evaluations on Turkish-language datasets demonstrate that this strategy reduces validation loss and improves downstream task accuracy without any preprocessing. By integrating filtering directly into the training loop, the method maintains data diversity, requires minimal overhead, and improves learning efficiency-offering a scalable alternative for robust LLM pretraining in noisy or low-resource environments.},
  archive      = {J_KBS},
  author       = {H. Toprak Kesgin and M. Fatih Amasyali},
  doi          = {10.1016/j.knosys.2025.114189},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114189},
  shortjournal = {Knowl. Based Syst.},
  title        = {A cyclical loss-based optimization algorithm for pretraining LLMs on noisy data},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source information fusion and region-focused strategy for optimized neural architecture search. <em>KBS</em>, <em>328</em>, 114186. (<a href='https://doi.org/10.1016/j.knosys.2025.114186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) has garnered significant attention due to its ability to automatically discover high-performing neural network architectures for specific tasks. However, the high computational cost and inefficient search process involved have hindered its broader application. The zero-cost proxy can alleviate this problem to some extent, but suffers from low evaluation relevance and poor generalizability. To address these challenges, we propose an efficient NAS method based on multi-source information fusion and region-focused strategy, aimed at reducing both evaluation and search costs while increasing the generalization and accuracy of the evaluation process. Specifically, our approach dynamically adjusts by automatically integrating information from multiple zero-cost proxies, combined with explicit architectural information, thereby effectively reducing the time consumed by individual evaluations. Compared to existing methods, our approach does not require manual selection of zero-cost proxies, avoiding the cold-start problem, and improves both the accuracy and generalization of the evaluations. Furthermore, to reduce the number of individual evaluations during the search process, we efficiently utilize previously evaluated individuals for targeted exploration, thereby enhancing the quality of the search. Experimental results demonstrate that the proposed algorithm outperforms existing NAS methods on multiple benchmark datasets, significantly reducing computational resource consumption.},
  archive      = {J_KBS},
  author       = {Yang An and Changsheng Zhang and Jintao Shao},
  doi          = {10.1016/j.knosys.2025.114186},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114186},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source information fusion and region-focused strategy for optimized neural architecture search},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyline quantity-utility sequential pattern mining: An efficient and effective approach. <em>KBS</em>, <em>328</em>, 114185. (<a href='https://doi.org/10.1016/j.knosys.2025.114185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High utility sequential pattern mining identifies valuable patterns to support decision-making, with applications in business analytics and web clickstream prediction. Existing algorithms rely on minimum utility thresholds or Top- k strategies, making them sensitive to hyperparameters and reducing robustness. They also incur high computational costs and memory usage due to complex utility upper-bound calculations and inefficient pruning strategies. Additionally, they focus solely on utility, neglecting the quantity factor, which leads to suboptimal decision-making. To address these issues, we explore skyline quantity-utility (SQU) sequential pattern mining and propose an algorithm named SQUMiner, which considers both quantity and utility factors for robust decision-making. Specifically, we introduce two compact data structures: QU-array and QUPro projected database, which manage the quantity and utility values of individual q -sequences and the entire database. These structures allow SQUMiner to efficiently compute utility upper bounds for two-objective mining without excessive memory usage. During the search process, we design heuristic global and local pruning strategies based on utility upper bounds, supported by two additional data structures, maximum utility quantity array and sequence Pareto front array (SPFA), which preserve non-dominance attributes for 1-sequence and extended sequence pruning, respectively. Our pruning strategies dynamically update SPFA, thereby pruning dominated sequences regarding prefix extension quantity and utility. Consequently, SQUMiner can mine SQU sequential patterns without relying on threshold and k -value settings for improved decision-making. Experimental results on 20 real and 8 synthetic datasets show that SQUMiner achieves up to two orders of magnitude speed-up compared with six state-of-the-art baselines, with superior robustness and stability.},
  archive      = {J_KBS},
  author       = {Tiantian Xu and Xingyu Wang and Tao Lu and Youxi Wu},
  doi          = {10.1016/j.knosys.2025.114185},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114185},
  shortjournal = {Knowl. Based Syst.},
  title        = {Skyline quantity-utility sequential pattern mining: An efficient and effective approach},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HELIOT: LLM-based CDSS for adverse drug reaction management. <em>KBS</em>, <em>328</em>, 114184. (<a href='https://doi.org/10.1016/j.knosys.2025.114184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication errors significantly threaten patient safety, leading to adverse drug events and substantial economic burdens on healthcare systems. Clinical Decision Support Systems (CDSSs) aimed at mitigating these errors often face limitations when processing unstructured clinical data, including reliance on static databases and rule-based algorithms, frequently generating excessive alerts that lead to alert fatigue among healthcare providers. This paper introduces HELIOT, an innovative CDSS for adverse drug reaction management that processes free-text clinical information using Large Language Models (LLMs) integrated with a comprehensive pharmaceutical data repository. HELIOT leverages advanced natural language processing capabilities to interpret medical narratives, extract relevant drug reaction information from unstructured clinical notes, and learn from past patient-specific medication tolerances to reduce false alerts, enabling more nuanced and contextual adverse drug event warnings across primary care, specialist consultations, and hospital settings. Evaluation using three state-of-the-art LLMs on synthetic and real-world datasets demonstrates classification accuracy ranging from 98.77 % to 99.80 % with zero false negatives for life-threatening reactions. This high accuracy enabled HELIOT to achieve a 50–53 % reduction in interruptive alerts compared to traditional CDSSs while maintaining perfect safety profiles. To support clinical deployment, the system incorporates a confidence-based risk stratification framework that enables automated decisions for high-certainty cases while ensuring appropriate clinical oversight for uncertain classifications. Clinical usability evaluation with healthcare professionals validated these achievements, revealing strong acceptance and unanimous preference for HELIOT’s contextual approach over traditional systems. These findings show promise; however, broader clinical trials remain essential to confirm effectiveness across diverse healthcare environments.},
  archive      = {J_KBS},
  author       = {Gabriele De Vito and Filomena Ferrucci and Athanasios Angelakis},
  doi          = {10.1016/j.knosys.2025.114184},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114184},
  shortjournal = {Knowl. Based Syst.},
  title        = {HELIOT: LLM-based CDSS for adverse drug reaction management},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CyberLLaMA: A fine-tuned large language model for cybersecurity named entity recognition. <em>KBS</em>, <em>328</em>, 114183. (<a href='https://doi.org/10.1016/j.knosys.2025.114183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity-specific Named-Entity Recognition (NER) is critical in addressing the escalating complexity and evolving cyber threats. While deep learning methods form the foundation of modern NER tasks, they still fall short in addressing cybersecurity-specific NER tasks due to the limited availability of up-to-date cybersecurity datasets and the unique characteristics of cybersecurity terminology (jargon, abbreviations, and rapidly evolving vocabulary). To bridge this gap we (i) compile a 42 404-article corpus and manually annotate 4788 unique security terms, and (ii) present CyberLLaMA -a framework that fine-tunes LLaMA-3.2-3B and stacks a bidirectional LSTM plus conditional-random-field layers to preserve label consistency. On the held-out test set, CyberLLaMA attains an F 1 of 98.88 %, surpassing RoBERTa, SCBERT, and GPT-NER. The results indicate that CyberLLaMA , as an effective solution for Cybersecurity NER tasks, offers practical value to cybersecurity professionals and the general public by enhancing the extraction of cybersecurity information in texts.},
  archive      = {J_KBS},
  author       = {Hao Zhang and Tingmin Wu and Tianqing Zhu and Sheng Wen and Yang Xiang},
  doi          = {10.1016/j.knosys.2025.114183},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114183},
  shortjournal = {Knowl. Based Syst.},
  title        = {CyberLLaMA: A fine-tuned large language model for cybersecurity named entity recognition},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A willingness-aware session-based social recommendation method with heterogeneous global graph embedding. <em>KBS</em>, <em>328</em>, 114181. (<a href='https://doi.org/10.1016/j.knosys.2025.114181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on Session-based Social Recommendation (SSR) employed the social information to enhance the session interest and achieve the next item recommendation. However, existing studies exhibit two main limitations: first, the learning of session interests overlooks the collaborative signals inherent in user-item interactions; second, the enhancement of session interests fails to consider the willingness of the target user on adopting his or her friends’ interests. Toward this end, we develop a willingness-aware SSR method with heterogeneous global graph embedding, short for WSSR. Specifically, we construct the heterogeneous global graph based on item transitions as well as user-item interactions, and then introduce the heterogeneous graph neural network to learn more sufficient embeddings of uses and items. Moreover, we construct the dynamic social graph for the target user and develop a novelty willingness-aware graph attention network to consider the willingness of the target user in enhancing the session interest. Extensive experiments are conducted on three real-world datasets in different domains, and empirical results verify that WSSR outperforms eight mainstream baselines on multiple measurements.},
  archive      = {J_KBS},
  author       = {Xiongtao Zhang and Jianmin Xu},
  doi          = {10.1016/j.knosys.2025.114181},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114181},
  shortjournal = {Knowl. Based Syst.},
  title        = {A willingness-aware session-based social recommendation method with heterogeneous global graph embedding},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep gated network model for explainable diabetes mellitus prediction at early stages based on trustworthy data. <em>KBS</em>, <em>328</em>, 114178. (<a href='https://doi.org/10.1016/j.knosys.2025.114178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes mellitus is a prevalent chronic disease that impacts the metabolic system of an increasing number of individuals every year. Due to this persistent and rapid increase, hospitals worldwide face a significant global health burden. An advanced and accurate predictive system is essential to alleviate this increasing burden and enable early diagnosis and effective treatment. Existing predictive methods predominantly rely on traditional Artificial Intelligence (AI) models; however, these models often struggle to address challenges such as high feature complexity, data imbalance, non-linear pattern learning, and lack of interpretability. To address the significant class imbalance in the trustworthy and patient privacy-concious diabetes health indicator dataset, this study employs the proximity-weighted random affine shadow sampling technique, which reduces prediction bias by focusing on borderline instances. The point-biserial correlation coefficient is used to choose the most significant and important features from the dataset. To capture the complex relationships within the diabetes dataset, Deep Gated Network (DGNet), a novel Deep Learning (DL) model, is proposed. DGNet’s architecture includes fully connected dense layers and a unique gating mechanism. The experimental findings demonstrate that the proposed DGNet performs significantly better than state-of-the-art logistic regression, support vector machines, decision trees, k-nearest neighbors, residual networks, long-short-term memory, multi-layer perceptrons, deep neural networks, highway networks, and deep belief networks. Compared to conventional models, DGNet achieves notable performance improvements, with gains of 11.4 % in accuracy, 8.2 % in F1-score, 7.73 % in recall, 9.13 % in precision, 11.8 % in receiver operating characteristics area under the curve, 12.22 % in precision-recall area under the curve, and 40.54 % reduction in log loss. The 10-fold cross validation technique is used to assess the DGNet’s generalizability and reliability. Furthermore, advanced explainable AI techniques, Shapley additive explanations, and local interpretable model-agnostic explanations are employed to interpret the importance of features in early diabetes prediction. This study establishes the DGNet as an effective and interpretable approach for early-stage diabetes prediction, with the rising need for responsible AI solutions in healthcare, where transparency, trust, and data privacy have become necessary for patient-focused innovation.},
  archive      = {J_KBS},
  author       = {Hira Khan and Nadeem Javaid and Tariq Bashir and Zeeshan Ali and Farrukh Aslam Khan and Dragan Pamucar},
  doi          = {10.1016/j.knosys.2025.114178},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114178},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel deep gated network model for explainable diabetes mellitus prediction at early stages based on trustworthy data},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-channel knowledge distillation for flood mapping in synthetic aperture radar images. <em>KBS</em>, <em>328</em>, 114177. (<a href='https://doi.org/10.1016/j.knosys.2025.114177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flood incidents frequently occur under rainy and overcast conditions, which restricts the effectiveness of optical satellite imaging. In contrast, Synthetic aperture radar (SAR) offers greater adaptability to adverse weather and varying illumination. Significant progress has been made in flood detection using SAR imagery. However, increasing computational demands and model complexity hinder real-world applications. Moreover, due to the irregular boundaries of flood regions, accurately outlining the overall flood contour from SAR images remains a challenging task. To conquer these issues, a Feature selection–edge generation refinement network (FS-EGR) is proposed. This network leverages knowledge distillation techniques, employing a Feature selection-spatial channel module (FS-SC) to help the student model extract valuable spatial and channel information. In addition, an Edge generation refinement module (EGR) is used to guide the student model to focus more on boundary cues during flood feature learning. This method outperforms 15 state-of-the-art methods across three SAR flood datasets while using fewer parameters. It meets the requirements for hardware deployment and achieves a strong balance between accuracy and efficiency. The code is available at https://github.com/TChi-Xu/A1 .},
  archive      = {J_KBS},
  author       = {Tianchi Xu and Chaomin Huang and Changyu Chen},
  doi          = {10.1016/j.knosys.2025.114177},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114177},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-channel knowledge distillation for flood mapping in synthetic aperture radar images},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphBSSN: A simple yet effective generative method for node classification in class-imbalanced graphs. <em>KBS</em>, <em>328</em>, 114175. (<a href='https://doi.org/10.1016/j.knosys.2025.114175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown significant promise in node classification tasks. However, in practical scenarios, the distribution of samples across various categories is often imbalanced. When GNNs are trained on such imbalanced graphs, they often fail to adequately represent the minority classes, resulting in a severe decline in performance. To address this issue, one potential solution is to generate supplementary samples for the minority classes to balance the graph. However, the existing generative methods are complex and tend to squeeze the subspace of minority classes. Additionally, the topology of synthesized samples deviates from the true neighbor distribution. In response, we propose a simple yet effective generative framework, GraphBSSN, by synthesizing B oundary S amples and sampling S imilar N odes. Specifically, we devise a boundary-aware feature synthesis strategy to expand the decision boundary of minority classes. Moreover, we design a similar node-based topology modeling method to position the synthesized samples within a reasonable distribution of neighbors. Our experimental results on eight class-imbalanced datasets demonstrate the effectiveness of the proposed method. The datasets and codes are available on GitHub at https://github.com/ZZY-GraphMiningLab/GraphBSSN .},
  archive      = {J_KBS},
  author       = {Qi Meng and Gen Liu and Guangkai Wu and Hui Zhou and Zhongying Zhao},
  doi          = {10.1016/j.knosys.2025.114175},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114175},
  shortjournal = {Knowl. Based Syst.},
  title        = {GraphBSSN: A simple yet effective generative method for node classification in class-imbalanced graphs},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning with joint probabilistic modeling for point cloud semantic segmentation. <em>KBS</em>, <em>328</em>, 114171. (<a href='https://doi.org/10.1016/j.knosys.2025.114171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in sensing technologies, the demand for point cloud semantic segmentation has grown significantly across various applications, while current deep learning-based methods rely heavily on costly, well-annotated datasets. Recently, label-efficient learning strategies have been explored to reduce annotation demands, with active learning emerging as a preferred approach by selectively annotating only the most informative samples. However, existing point cloud active learning methods often depend solely on neural network softmax scores for sample selection, which can introduce bias and be affected by overconfidence in network predictions. To overcome this limitation, we propose an active learning framework with Joint Probabilistic modeling (JoPro), aiming to select unlabeled points that can provide more post-annotation information. At the core of JoPro is a novel probabilistic model that efficiently captures the distribution of embedded features to generate richer probabilistic representations for unlabeled data. Utilizing this probabilistic modeling, we propose a feature mixing stability metric to identify uncertain points near decision boundaries, ensuring more informative sample selection. Furthermore, a cluster-aware hybrid contrastive regularization method is incorporated to maximize the utilization of unlabeled data to enhance training of the segmentation model. Our proposed active learning framework achieves competitive results on popular benchmarks, delivering near fully supervised performance with only 1 % of the annotation budget.},
  archive      = {J_KBS},
  author       = {Baochen Yao and Dongjie Zhang and Jie Zhao and Ye Zheng and Chengbin Peng},
  doi          = {10.1016/j.knosys.2025.114171},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114171},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active learning with joint probabilistic modeling for point cloud semantic segmentation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity graph reasoning for semantic entity recognition in maritime fault knowledge extraction. <em>KBS</em>, <em>328</em>, 114170. (<a href='https://doi.org/10.1016/j.knosys.2025.114170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing automation in maritime maintenance systems, extracting structured fault knowledge from unstructured engine room records is increasingly important. This research addresses the challenge of semantic entity recognition in highly specialised textual data such as operational logs and technical reports. Specifically, these challenges include the diversity of entity types, strong domain specificity, and limited distinguishability of boundary features. To mitigate these issues, a semantic recognition model for maritime fault texts that integrates multi-granularity graph reasoning is proposed. The model constructs graphs at the character, word, and phrase levels. These graphs capture semantic features across different levels of granularity. Graph Transformer Networks (GTNs) are employed to transfer information within each level and between different levels. In addition, a boundary smoothing mechanism enhances boundary detection, while a contrastive learning strategy improves semantic discrimination. Experimental results indicate that the proposed model achieves superior performance in marine semantic recognition and classification. It efficiently extracts critical information, including failure causes and malfunction symptoms. Its final F1-score reaches 80.65 % on a self-constructed dataset, surpassing traditional recognition methods. This study not only provides a novel solution for knowledge extraction from unstructured marine records but also establishes a foundation for intelligent fault diagnosis and decision support in maritime systems.},
  archive      = {J_KBS},
  author       = {Henglong Shen and Hui Cao and Longde Wang and Zeren Ai and Saishuai Dai},
  doi          = {10.1016/j.knosys.2025.114170},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114170},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granularity graph reasoning for semantic entity recognition in maritime fault knowledge extraction},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning event detector from long-term signal variation for seismic activity warning out of schumann resonance. <em>KBS</em>, <em>328</em>, 114166. (<a href='https://doi.org/10.1016/j.knosys.2025.114166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has shown capability in many areas of impact on everyday life. The paper proposes a DL architecture tailored for event detection from examining the time evolution of a signal. With temporal characteristics extracted by a Convolutional Neural Network (CNN) encoder and fed as input to a recurrent neural network, the model targets the detection of a possibly occurring investigated event in the given time interval. The utility of DL methodologies to solve physical problems is demonstrated for an application of the complex experimentally-studied existing interaction between Schumann Resonance (SR) and seismic activity. SR signals are electromagnetic waves propagating along the Earth-ionosphere cavity. Intense lightning activity is continuously present at the same locations around the world, being sensitive to physical perturbation. Seismic activity modifies this steady lightning pattern. The new DL model is applied to answer the research question of whether the variation of the SR signal is truly a verifiable forerunner of seismic activity. Several parameter configurations are explored, either model-related or linked to criteria for selecting seismic events. Results show preliminary evidence about the relation between distance-intensity space and SR perturbation, and provide valuable corroboration about the sensitivity of the sensor to a specific azimuth between the observatory and the Earthquake (EQ) epicenter, hence argumentatively supporting the SR temporal characteristics as an early seismic warning. This is the first generalization of seismic disturbance as a derivative of the SR, based only on its signal time series variation, as a hypothesized precursor of the EQ event.},
  archive      = {J_KBS},
  author       = {Carlos Cano-Domingo and Ruxandra Stoean and Manuel Soler-Ortiz and Nuria Novas and Manuel Fernández-Ros and Gonzalo Joya and Jose A. Gázquez Parra},
  doi          = {10.1016/j.knosys.2025.114166},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114166},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning event detector from long-term signal variation for seismic activity warning out of schumann resonance},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph topology adaptive judgment against node label noise. <em>KBS</em>, <em>328</em>, 114162. (<a href='https://doi.org/10.1016/j.knosys.2025.114162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have exhibited remarkable capabilities in processing graph data. Nevertheless, their performance is highly dependent on the labeled data, making them vulnerable to label noise. Existing methods often improve the robustness of node classification by adding trusted edges to the graph. However, most of them overlook the impact of potential noisy edges on the model’s robustness, leading to a notable decline in performance as the average degree of the dataset increases. In this paper, we provide a theoretical explanation for the performance degradation observed in existing methods on datasets with high average degrees. Building on this insight, we propose the Graph Topology Adaptive(GTA) model, which incorporates EdgeBoost Module to add trusted edges based on node latent space similarity and EdgePrune Module to eliminate untrusted edges through optimized screening mechanism. Two modules work collaboratively to adaptively adjust the graph topology and generate final predictions. Both theoretical analysis and extensive experimental results validate the effectiveness of the GTA model.},
  archive      = {J_KBS},
  author       = {Mengyao Zhou and Xiao Han and Wei Wei and Guiying Yan},
  doi          = {10.1016/j.knosys.2025.114162},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114162},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph topology adaptive judgment against node label noise},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep self-weighted multi-view fuzzy clustering. <em>KBS</em>, <em>328</em>, 114158. (<a href='https://doi.org/10.1016/j.knosys.2025.114158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has attracted considerable attention in various fields, such as computer vision and information retrieval. Most existing methods adopt a stepwise strategy to achieve a consistent representation and produce final clusters. However, this strategy neglects label consistency for the same sample across different views, which results in sub-optimal representations. Furthermore, conventional methods frequently overlook the potential fuzzy membership relationships inherent in multi-view data and predominantly rely on shallow models, which fail to capture the complex properties of data, resulting in unsatisfactory outcomes. To address these challenges, we propose a novel deep self-weighted multi-view fuzzy clustering method that thoroughly explores the intricate view-specific characteristics of data to better represent consensus membership (i.e. consistent representation) between samples and centroids across multiple views. In particular, the method uses deep auto-encoders to non-linearly project samples from each view into corresponding latent spaces in a layer-wise manner. The consensus membership is then shared by samples from the middle and reconstruction layers, thereby reducing discrepancies in soft cluster assignment between the same sample in the latent and original spaces. Without introducing additional parameters, the self-weighted strategy adjusts the contribution of each view to fuzzy clustering. In addition, we adopt entropy regularization to tune the uniformity of the membership and design an alternating optimization algorithm to update all variables. Experimental results demonstrate the superior performance of the proposed method on five datasets (including images, web pages and videos) evaluated using four metrics.},
  archive      = {J_KBS},
  author       = {Mei Shi and Xiaowei Zhao and Xiaoyan Yin and Yun Xiao and Jun Guo},
  doi          = {10.1016/j.knosys.2025.114158},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114158},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep self-weighted multi-view fuzzy clustering},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personally identifiable information detection in smart edge computing: A robust model evaluation. <em>KBS</em>, <em>328</em>, 114153. (<a href='https://doi.org/10.1016/j.knosys.2025.114153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of smart edge computing, visual content has become a primary means of online communication, offering engaging and easily shareable interactions. However, images often contain sensitive and personal information, particularly Personally Identifiable Information (PII), posing significant privacy risks. This paper presents a comprehensive framework for PII object detection on edge devices using Deep Learning algorithms, consisting of i) dataset preparation, ii) model training and implementation, and iii) error analysis and robust evaluation. We curate a specialized dataset named PIIod ( PII o bject d etection dataset), and train a model achieving benchmark performance for on-device PII detection. Moreover, we introduce two novel model evaluation metrics, i.e., cAP ( c ustomized A verage P recision) and PEAC ( P erformance E valuation by Location A ccuracy and C lassification Confidence). By incorporating cAP and PEAC into the evaluation framework, a more flexible and robust assessment of model effectiveness in PII detection can be achieved.},
  archive      = {J_KBS},
  author       = {Xichen Zhang and Amir David and Haruna Isah and Hasan Cavusoglu},
  doi          = {10.1016/j.knosys.2025.114153},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114153},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personally identifiable information detection in smart edge computing: A robust model evaluation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-consistency graph-spectral embedding joint learning for multi-view single-cell clustering. <em>KBS</em>, <em>328</em>, 114149. (<a href='https://doi.org/10.1016/j.knosys.2025.114149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) enables detailed analysis of transcriptional activity at the single-cell level, which is crucial for detecting distinct cell types and subtypes. However, the high dimensionality and noise present in scRNA-seq data pose challenges for effective clustering. To track these, we propose a dual-consistency graph-spectral embedding joint learning multi-view clustering method named DcGSE, which leverages consistent and complementary information across multiple views. DcGSE constructs multi-view similarity graph spaces of cells from scRNA-seq data and models both the consistency and inconsistency among the views. Specifically, the dual-consistency spectral embedding is obtained through spectral embedding low-rank decomposition of the consensus similarity graph and multi-view similarity graph spaces. Furthermore, a weighted tensor low-rank constraint is designed for view-specific embeddings to effectively mine high-order relationships with diverse views. Besides, multi-view similarity graphs learning and spectral embedding learning are integrated within a unified optimization framework, enhancing inter-cell correlation information while ensuring the preservation of critical clustering structures. Extensive experiments on 8 real scRNA-seq datasets demonstrate that DcGSE outperforms 12 state-of-the-art baseline methods in clustering performance, providing strong evidence of its superiority in clustering cells by revealing the shared cellular spectral embedding structure of multiple views.},
  archive      = {J_KBS},
  author       = {Ao Li and Tongtong Ji and Chunrui Wang and Fengwei Gu and Tianyu Gao and Lili Zhou},
  doi          = {10.1016/j.knosys.2025.114149},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114149},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-consistency graph-spectral embedding joint learning for multi-view single-cell clustering},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimal feature selection based hybrid intelligent model for software defect prediction. <em>KBS</em>, <em>328</em>, 114146. (<a href='https://doi.org/10.1016/j.knosys.2025.114146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defect Prediction (SDP) plays a vital role in the Software Development Life Cycle (SDLC), which remains an essential and critical task. It is mainly utilized to ensure the quality of software systems based on various preferences and security. Several studies were conducted to develop an efficient SDP system by identifying imperfect or defective artefacts. However, most of the SDP systems do not provide efficient prediction and consume more time to predict software defects. Thus, the proposed methodology is developed to provide an efficient SDP system. Initially, the data were gathered from the dataset to resolve the class imbalance issues using the combination of Synthetic Minority Over-sampling Technique (SMOTE) and Random Under-Sampling (RUS). Then, the Enhanced Flamingo Search Algorithm (EFSA) is utilized for feature selection. Finally, a hybrid model is used to predict software defects, which combines the Dual attention One-Dimensional Residual Autoencoder (1-D-ResAE) and Extreme Gradient Boosting (XGBoost) models. It provides an intelligent prediction model for software defects, and the COOT optimization algorithm is used to tune the hyperparameters of the proposed prediction technique. Then, five datasets from the promise repository (PC1, KC1, KC2, JM1, and CM1) are used in this research. The performance of the proposed technique is analyzed using various related techniques to determine its effectiveness. The proposed method achieves an accuracy of 98.65% for PC1, 99.46% for KC1, 99.51% for KC2, 98.92% for JM1, and 99.56% for CM1.},
  archive      = {J_KBS},
  author       = {V Kiran Kumar and P Vidya Sagar},
  doi          = {10.1016/j.knosys.2025.114146},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114146},
  shortjournal = {Knowl. Based Syst.},
  title        = {An optimal feature selection based hybrid intelligent model for software defect prediction},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random forest calibration. <em>KBS</em>, <em>328</em>, 114143. (<a href='https://doi.org/10.1016/j.knosys.2025.114143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Random Forest (RF) classifier is often claimed to be relatively well calibrated when compared with other machine learning methods. Moreover, the existing literature suggests that traditional calibration methods, such as isotonic regression, do not substantially enhance the calibration of RF probability estimates unless supplied with extensive calibration data sets, which can represent a significant obstacle in cases of limited data availability. Nevertheless, there seems to be no comprehensive study validating such claims and systematically comparing state-of-the-art calibration methods specifically for RF. To close this gap, we investigate a broad spectrum of calibration methods tailored to or at least applicable to RF, ranging from simple scaling techniques to more advanced algorithms. Our results based on synthetic as well as real-world data unravel the intricacies of RF probability estimates, scrutinize the impact of hyper-parameters, and compare calibration methods in a systematic way. We demonstrate that a well-optimized RF matches or outperforms state-of-the-art calibration methods. In particular, statistical tests on metrics such as accuracy, ECE, Brier score, and log-loss consistently place the optimized RF among the top-performing group.},
  archive      = {J_KBS},
  author       = {Mohammad Hossein Shaker and Eyke Hüllermeier},
  doi          = {10.1016/j.knosys.2025.114143},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114143},
  shortjournal = {Knowl. Based Syst.},
  title        = {Random forest calibration},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage sand-dust image enhancement method based on concentration scaling and domain adaptation. <em>KBS</em>, <em>328</em>, 114142. (<a href='https://doi.org/10.1016/j.knosys.2025.114142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The captured images under sand-dust weather conditions often suffer from tonality deviation and poor visibility, hindering their effective use in high-level vision tasks. Current image enhancement methods treat all degraded images equally, disregarding the variations in visual style caused by different levels of sand-dust pollution. To address this issue, we propose a novel two-stage sand-dust image enhancement method. Our approach consists of two stages: 1) the Sand-dust Image Concentration Scaling stage, which unifies the visual styles of sand-dust images by pixel-based distribution compensation; 2) the Domain Adaptation-based Details Enhancement stage, which enhances the details of the degraded images by sharing knowledge learned across different domains. The first stage transforms the sand-dust images affected by varied levels of sand-dust concentration into an intermediate domain to eliminate the differences between them. The second stage enhances the details of the intermediate domain images that still exhibit degradation, such as noise and blur. We performed extensive experiments for various sand-dust images and compared the performance with the SOTA sand-dust image enhancement methods. The experimental results demonstrate compelling evidence that our proposed method achieved the best performance in sand-dust removal. Code and results are available at: https://github.com/Youtheasth/python_desand .},
  archive      = {J_KBS},
  author       = {Yuting Yu and Zhidong Yang and Ruiheng Zhang and Bosheng Ding and Lixin Xu and He Zhao},
  doi          = {10.1016/j.knosys.2025.114142},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114142},
  shortjournal = {Knowl. Based Syst.},
  title        = {Two-stage sand-dust image enhancement method based on concentration scaling and domain adaptation},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAL-SNN: Balanced active learning for spiking neural networks. <em>KBS</em>, <em>328</em>, 114097. (<a href='https://doi.org/10.1016/j.knosys.2025.114097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are gaining significant attention in the field of artificial intelligence due to their offering low-power consumption and powerful spatiotemporal information processing capabilities. However, a large amount of labeled data is required to train high-performance deep SNNs. Furthermore, generalization performance remains limited when encountering new visual scenes, limiting the practical application of SNNs. Active learning (AL) aims to alleviate dependence on large amounts of labeled data by intelligently selecting the most valuable samples for training. However, existing AL methods face challenges such as data overlap, blurred classification boundaries, and susceptibility to local minima. To address these issues, we propose a Balanced Active Learning for Spiking Neural Network (BAL-SNN). Specifically, to resolve data overlap, we introduced a local density clustering upward distance to measure the information content of different data. To address data confusion, a balanced AL strategy based on SNNs was introduced to optimize the data selection process. Finally, we present an SNN algorithm with nuclear norm regularization to address the issue of error accumulation over multiple time steps in AL model for SNNs, which causes the model to easily fall into local minima. Experimental results show that the proposed method achieves exciting performance on both static and dynamic datasets. Our proposed approach can be applied to many fields, such as image classification and object detection, especially in the case of significant data processing but high labeling costs, which can significantly improve the learning efficiency and model performance.},
  archive      = {J_KBS},
  author       = {Meiling Zhong and Chunyan She and Bingrui Xu and Qing Yang and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.knosys.2025.114097},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114097},
  shortjournal = {Knowl. Based Syst.},
  title        = {BAL-SNN: Balanced active learning for spiking neural networks},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender inclusive language generation framework: A reasoning approach with RAG and CoT. <em>KBS</em>, <em>328</em>, 114092. (<a href='https://doi.org/10.1016/j.knosys.2025.114092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language is a dynamic and evolving concept that shapes thought and perception. The increasing reliance on Natural Language Processing models necessitates careful consideration of their alignment with inclusive language practices. However, Large Language Models often perpetuate biases due to training on androcentric and stereotypical data, undermining fairness and inclusivity. To address this, we propose a novel Two-Pass Retrieval Augmented Generation RAG with Chain of Thought framework that first retrieves contextual, unbiased references from a created corpus of inclusive texts and then applies structured, step-by-step reasoning via CoT prompting to enhance inclusivity in LLM output. By systematically retrieving relevant, unbiased references and enforcing structured reasoning, the framework promotes the generation of more inclusive and less biased content. Both LLM and human based evaluation using structured prompts with metrics like gender assumption, gender neutrality and quality and relevance Score are utilized. The text completion and generation tasks demonstrate that the proposed framework reduces gender bias.},
  archive      = {J_KBS},
  author       = {Shunmuga Priya Muthusamy Chinnan and Meghann Drury-Grogan and Bharathi Raja Chakravarthi},
  doi          = {10.1016/j.knosys.2025.114092},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114092},
  shortjournal = {Knowl. Based Syst.},
  title        = {Gender inclusive language generation framework: A reasoning approach with RAG and CoT},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiModFuseNet: Advancing multimodal text classification for low-resource languages through textual-visual feature fusion. <em>KBS</em>, <em>328</em>, 114085. (<a href='https://doi.org/10.1016/j.knosys.2025.114085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of social media activity and the widespread availability of electronic devices have led to an overwhelming influx of multimodal contents on the World Wide Web (WWW), much of which are unstructured, nonfactual, or toxic. Classification of such multimodal web contents (particularly, image-text) is challenging due to image-only instances with ambiguous meanings, short text-only instances lacking sufficient context and semantic clarity, shortage of annotated data and above all lack of tools for low resource languages. Manual classification of these contents is both time-consuming and costly. This paper presents MultiModFuseNet, a low-resource multimodal image-text classification system that leverages the fusion of textual and visual embeddings to overcome image ambiguity and enhance textual interpretation. MultiModFuseNet employs a systematic approach to develop a low-resource multimodal image-text corpus and identifies the best-performing image and text classification models through empirical analysis of Vision-Language Models (VLMs), Large Language Models (LLMs), Multilingual Language Models (MLMs), and Vision Transformers. Based on this analysis, MultiModFuseNet integrates pre-trained Vision Transformers for visual encoding and Multilingual Language Models for textual encoding, combining them through a trained fusion layer. This fusion layer is optimized via extensive ablation studies on the best-performing models, including tuning the learning rate, loss function, fusion technique, and embedding dimensions. MultiModFuseNet outperforms all baseline models, achieving an accuracy improvement of 4.32 % over text-only models, 12.89 % over image-only models, and 12.93 % over VLMs. The corpus and proposed solution are publicly available at: https://github.com/mrhossain/MultiModFuseNeT .},
  archive      = {J_KBS},
  author       = {Md Rajib Hossain and Sadia Afroze and Asif Ekbal and Mohammed Moshiul Hoque and Nazmul Siddique},
  doi          = {10.1016/j.knosys.2025.114085},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114085},
  shortjournal = {Knowl. Based Syst.},
  title        = {MultiModFuseNet: Advancing multimodal text classification for low-resource languages through textual-visual feature fusion},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The iBoxplot: A visual tool based on lows and highs to support decision-making and acquire knowledge. <em>KBS</em>, <em>328</em>, 114000. (<a href='https://doi.org/10.1016/j.knosys.2025.114000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing lows and highs is at the core of financial markets and is absolutely essential for health management systems, real estate management systems, climatic change analysis, traffic flow management systems, cybersecurity management systems, computational statistics and so on. Using candlestick charts by pattern recognition is key to establishing better decision rules in financial markets. Interval-valued (IV) data is a set of numbers with lower and upper bounds. Visualizing IV data is crucial in most fields of knowledge and will be decisive in artificial intelligence, big data, computer vision, data science, machine learning, quantum computing, and storage requirements. This paper develops an extension of the popular boxplot for IV datasets (IVD) in the so-called iBoxplot, investigating order statistics of lows and highs and showing them through two polygonal lines, and evaluating their distance. The result is a polygon whose shape, the area covered, and the distance value visualize features of the IVD, highlighting exceptional IV values or outliers through two rules of thumb. Forecasting interval time series, process monitoring, or comparison are explored and demonstrated in blood pressure measurements, temperatures, precious metal prices, exchange rates, or energy prices with over twenty quite different iBoxplots patterns. Some ideas to use the iBoxplot in some machine learning algorithms are put forward. As a case study, the value of the iBoxplot as a helping tool to cluster objects or entities in the IVD is addressed showing how iBoxplots can give advice in clustering tasks and be useful when describing each cluster. Further research issues are summarized.},
  archive      = {J_KBS},
  author       = {Carlos G. Maté},
  doi          = {10.1016/j.knosys.2025.114000},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114000},
  shortjournal = {Knowl. Based Syst.},
  title        = {The iBoxplot: A visual tool based on lows and highs to support decision-making and acquire knowledge},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A plug-and-play method for linguistic alignment in language models. <em>KBS</em>, <em>328</em>, 113597. (<a href='https://doi.org/10.1016/j.knosys.2025.113597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-specific linguistic alignment is essential for large language models (LLMs) in personalized applications. Traditional controlled text generation methods typically require additional training modules or defined target objectives. However, in the era of LLMs, these training methods are costly, and the target domains are constantly evolving. Training LLMs on target corpora is not always effective, making it challenging to achieve reliable alignment results. To effectively align a language model (LM) with a target corpus without any additional training target or well-trained modules, we propose FlexAlign, a plug-and-play method for target domain text adaptation during the inference stage. Using the n-gram token frequency of the target domain corpus and the instantaneous entropy during the generation process, we restructure the probability distribution of the language model across both domain style adjustment and temperature adjustment. This restructuring narrows the gap between the language model’s original distribution and that of the target domain, enabling the text generated by the language model to exhibit the explicit semantic attribute or implicit linguistic characteristics of the target domain. We conducted experiments using three different language models and two datasets, and our results show that FlexAlign effectively aligns the generated text with the target domain while maintaining high linguistic quality, whether the LMs are fine-tuned for specific domains or guided by prompts.},
  archive      = {J_KBS},
  author       = {Kaiyi Pang and Minhao Bai and Jinshuai Yang and Yue Gao and Minghu Jiang and Yongfeng Huang},
  doi          = {10.1016/j.knosys.2025.113597},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {113597},
  shortjournal = {Knowl. Based Syst.},
  title        = {A plug-and-play method for linguistic alignment in language models},
  volume       = {328},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCAN: Cross-domain self-supervised attention network based on multiscale EEG feature learning for epileptic seizure detection. <em>KBS</em>, <em>327</em>, 114199. (<a href='https://doi.org/10.1016/j.knosys.2025.114199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a common neurological disorder that severely affects patient safety and quality of life. Electroencephalography (EEG) is crucial for detecting epileptic seizures. However, the manual annotation of seizures during long-term EEG monitoring is labor-intensive, error-prone, and highly dependent on clinical expertise. Furthermore, real-world EEG-based seizure detection is also challenging due to distribution shifts across subjects and datasets, along with the significant class imbalance between seizure and normal segments. To address these challenges, we propose a cross-domain hybrid self-supervised attention network (MCAN) for the automatic detection of seizures. The network offers the following key contributions: Firstly, a cross-domain hybrid self-supervised learning strategy is designed to capture the temporal dynamics of EEG signals while simultaneously preserving the spatial distributions across electrodes and the spectral characteristics of neural oscillations. Secondly, a multiscale feature learning module is developed to model the hierarchical spatiotemporal dynamics of EEG signals through diverse receptive fields, thereby reducing the model’s dependency on subject-specific features. Thirdly, we propose a self-attention mechanism guided by a sparse electrode adjacency matrix to effectively capture seizure-related neuronal synchrony. Extensive experiments were conducted using real-world clinical epilepsy monitoring datasets and three publicly available datasets to evaluate the performance of our MCAN. The results demonstrate that MCAN consistently outperforms baseline methods in seizure detection across multiple datasets. Notably, it achieves an area under the receiver operating characteristic curve of 0.914 and an F1-score of 0.709, highlighting its potential for seizure monitoring applications.},
  archive      = {J_KBS},
  author       = {Tingxuan Hong and Desheng Li and Yuan Chang and Xiangqing Wang and Ziliang Cai and Rongfei Wang and Xiaochen Zhang and Xiaoya Liu and Chunxiao Yang and Shengyuan Yu and Shuang Liu and Dong Ming},
  doi          = {10.1016/j.knosys.2025.114199},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114199},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCAN: Cross-domain self-supervised attention network based on multiscale EEG feature learning for epileptic seizure detection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLIP-SDMG:CLIP knowledge distillation based on semantic decoupling and mask generation. <em>KBS</em>, <em>327</em>, 114194. (<a href='https://doi.org/10.1016/j.knosys.2025.114194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive language-image pretraining (CLIP) achieves cross-modal semantic alignment via image text contrastive learning and delivers remarkable performance in zero-shot image text retrieval and image classification tasks. However, its massive parameter size restricts practical deployment. Moreover, current CLIP distillation methods rely on response distillation, which causes a knowledge capacity barrier and loss of fine-grained features in the student model, eventually affecting task accuracy. To address these issues, we propose a semantic feature distillation framework, CLIP-SDMG. We design a progressive global semantic loss that enables the student model to gradually understand the process by which the teacher model generates complete image and text responses along with the teacher’s underlying reasoning mechanism; through an exponential decay scheduling, a smooth transition is achieved for global semantic learning. Considering that global semantics are updated through interactions with local semantics, we further propose a collaborative local semantic distillation strategy. For shallow local semantics, a dynamic attention balance mechanism is adopted, wherein the student initially relies on the teacher’s attention to focus on key local semantic features and gradually transitions to independent exploration. For deep local semantics, we construct a dual-path mask generation strategy for the vision and text modalities: the vision branch integrates squeeze-and- excitation attention with adaptive residual reconstruction to enhance visual semantic representation, while the text branch incorporates masked language modeling to improve contextual reasoning.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Zhicheng Si and Mingwen Shao and Hong Liang},
  doi          = {10.1016/j.knosys.2025.114194},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114194},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLIP-SDMG:CLIP knowledge distillation based on semantic decoupling and mask generation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic patch-aware enrichment transformer for occluded person re-identification. <em>KBS</em>, <em>327</em>, 114193. (<a href='https://doi.org/10.1016/j.knosys.2025.114193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-ID) continues to pose a significant challenge, particularly in scenarios involving occlusions. Prior approaches aimed at tackling occlusions have predominantly focused on aligning physical body features through the utilization of external semantic cues. However, these methods tend to be intricate and susceptible to noise. To address the aforementioned challenges, we present an innovative end-to-end solution known as the Dynamic Patch-aware Enrichment Transformer (DPEFormer). This model effectively distinguishes human body information from occlusions automatically and dynamically, eliminating the need for external detectors or precise image alignment. Specifically, we introduce a dynamic patch token selection module (DPSM). DPSM utilizes a label-guided proxy token as an intermediary to identify informative occlusion-free tokens. These tokens are then selected for deriving subsequent local part features. To facilitate the seamless integration of global classification features with the finely detailed local features selected by DPSM, we introduce a novel feature blending module (FBM). FBM enhances feature representation through the complementary nature of information and the exploitation of part diversity. Furthermore, to ensure that DPSM and the entire DPEFormer can effectively learn with only identity labels, we also propose a Realistic Occlusion Augmentation (ROA) strategy. This strategy leverages the recent advances in the Segment Anything Model (SAM) [1]. As a result, it generates occlusion images that closely resemble real-world occlusions, greatly enhancing the subsequent contrastive learning process. Experiments on occluded and holistic re-ID benchmarks signify a substantial advancement of DPEFormer over existing state-of-the-art approaches. The code is publicly available at https://github.com/zhangxin06/DPEFormer .},
  archive      = {J_KBS},
  author       = {Xin Zhang and Keren Fu and Qijun Zhao},
  doi          = {10.1016/j.knosys.2025.114193},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114193},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic patch-aware enrichment transformer for occluded person re-identification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLVM-drone: A synergistic framework integrating large language models and vision models for visual tasks in unmanned aerial vehicles. <em>KBS</em>, <em>327</em>, 114190. (<a href='https://doi.org/10.1016/j.knosys.2025.114190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Large Language Models (LLMs) and Visual Language Models (VLMs) with drone technology holds significant potential for enhancing Unmanned Aerial Vehicle (UAV) capabilities. However, a critical challenge arises from the inherent uncertainty and hallucination tendencies of LLMs when processing ambiguous natural language instructions and generating executable code. These limitations make LLMs unreliable for direct deployment in UAVs, particularly in vision-based tasks where precision and safety are paramount. To address these challenges, we propose LLVM-Drone, a novel framework that combines Domain-Guided Structured Prompt Execution Framework (DGSPEF) with lightweight task-specific vision models to ensure accurate code generation and reliable visual feedback. DGSPEF leverages structured prompts and domain knowledge to mitigate LLM hallucinations, translating user intent into precise executable commands, while lightweight vision models provide real-time perceptual validation. This approach enables zero-shot visual task execution without additional training, maintaining a separation between language understanding and visual processing. Extensive evaluations involving eight state-of-the-art LLMs demonstrate the effectiveness of LLVM-Drone across a wide range of UAV vision missions, including aerial object detection, precise localization, object tracking, and vision-language navigation. The framework has been successfully deployed on real UAV hardware for basic tasks, indicating its strong potential for future applications in real-world scenarios such as autonomous mapping, disaster response, precision agriculture, and infrastructure inspection.},
  archive      = {J_KBS},
  author       = {Yibiao Hu and You Zhou and Zhengqiang Zhu and Xi Yang and Han Zhang and Kun Bian and Hong Han},
  doi          = {10.1016/j.knosys.2025.114190},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114190},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLVM-drone: A synergistic framework integrating large language models and vision models for visual tasks in unmanned aerial vehicles},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating radius margin constraints and class variance for improved CNN-based image recognition. <em>KBS</em>, <em>327</em>, 114188. (<a href='https://doi.org/10.1016/j.knosys.2025.114188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition aims to classify images by learning predictive models, with Convolutional Neural Network (CNN) emerging as the dominant approach. While SVM-driven CNNs, which employ Support Vector Machine (SVM) as the energy function, outperform traditional Softmax-driven CNNs in generalization, they overlook the influence of the Minimum Enclosing Ball (MEB) radius on the generalization bounds and fail to utilize the overall sample distribution, limiting their performance. To address these issues, we propose two models: (1) RMB-driven CNN, which incorporates the Radius Margin Bound (RMB) to optimize feature learning by maximizing inter-class margins while minimizing the MEB radius; (2) MCVSVM-driven CNN, which integrates Minimum Class Variance Support Vector Machine (MCVSVM) and Fisher’s discriminant theory to refine hyperplanes using sample distribution, enhancing feature discriminability. Experiments on the FER2013, CIFAR-10, CIFAR-100, MNIST, and SVHN datasets using AlexNet, VGGNet, and ResNet demonstrate that the proposed models achieve superior feature extraction and recognition accuracy compared to existing methods, validating their effectiveness and robustness.},
  archive      = {J_KBS},
  author       = {Qi Jiang and Yao Xiao and Gang Zhou and Guofang Liu and Zhen Li and Jia Luo and Kailin He and Shishi Liao},
  doi          = {10.1016/j.knosys.2025.114188},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114188},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating radius margin constraints and class variance for improved CNN-based image recognition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interaction-aware vehicle trajectory prediction using spatial-temporal dynamic graph neural network. <em>KBS</em>, <em>327</em>, 114187. (<a href='https://doi.org/10.1016/j.knosys.2025.114187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of autonomous driving, vehicle trajectory prediction (VTP) plays a crucial role in enhancing safety and efficiency. Equipped with perception and communication devices, autonomous vehicles (AVs) can obtain trajectory information of surrounding vehicles, enabling more accurate trajectory predictions. Although recent interactive methods have achieved significant progress by modelling the interactions among neighboring vehicles, the VTP task still remains a challenging research issue due to the dynamic and heterogeneous nature of vehicle interaction. To address this issue, we propose a novel interaction-aware VTP model (IA-STDGNN) to simultaneously predict the trajectories of both target and surrounding vehicles. Specifically, we begin by designing a feature extraction module to extract vehicle motion state information through trajectory residual and discrete derivative operations. Next, we introduce instance normalization and linear integration modules to normalize the input data and deduce trend trajectories. Afterward, a vehicle interaction-based dynamic graph convolutional network is developed, incorporating single-lane and multi-lane vehicle interaction mechanisms to account for spatial interactions between vehicles. Building on this, a spatial-temporal feature dependency fusion module is designed to enhance the model's spatiotemporal representation capabilities further and effectively integrate spatial and temporal features. Finally, the trajectory prediction module produces multi-modal predictions, concatenating the output of the linear model to generate the final predicted trajectory. Extensive experiments conducted on the public datasets demonstrate that our method outperforms other state-of-the-art VTP approaches.},
  archive      = {J_KBS},
  author       = {Ruiyu Wang and Wenxie Lin and Gang Ren and Qi Cao and Zhe Zhang and Yue Deng},
  doi          = {10.1016/j.knosys.2025.114187},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114187},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interaction-aware vehicle trajectory prediction using spatial-temporal dynamic graph neural network},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliced wasserstein weighted multimodal mambavision for emotion recognition. <em>KBS</em>, <em>327</em>, 114182. (<a href='https://doi.org/10.1016/j.knosys.2025.114182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current field of physiological signal-based affective computing, the capture of both local and global information from single-modal signals, as well as the effective fusion of multimodal signals, still face significant challenges. Recently, Mamba-based models have attracted widespread attention due to their linear complexity and exceptional long-sequence modeling capabilities, yet existing Mamba-based models are primarily designed for single-modal tasks. This study introduces the Sliced Wasserstein Weighted Multimodal (SWWM) MambaVision, a novel multimodal fusion model designed to achieve more effective multimodal integration by leveraging the correlations and complementarities of physiological signals. This model inherits the high computational efficiency of the Mamba’s State Space Model (SSM) and integrates the cross-window connection mechanism to capture the global information of single-modal physiological signals. Furthermore, this study innovatively constructs a dual-stream structure framework to achieve the fusion of multimodal signals. Simultaneously, a weighting mechanism based on the Sliced-Wasserstein (SW) distance is proposed, which fully utilizes the manifold structural features of physiological signals to calculate the distance metric of modal feature matrices, achieving a more flexible and effective multimodal fusion. The method was validated on the Deap and Dreamer datasets, achieving average accuracies of 98.99 % and 97.58 %, respectively. The throughput was improved by 84 %, 22 %, and 8 % compared to Conv-Based, Transformer-Based, and Conv-Transformer-Based multimodal models, respectively. The results thoroughly demonstrate its performance advantages in multimodal physiological signal processing and open up new directions for further research in this field.},
  archive      = {J_KBS},
  author       = {Hao Wang and Li Xu and Weiyue Ding and Yiming Xu},
  doi          = {10.1016/j.knosys.2025.114182},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114182},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sliced wasserstein weighted multimodal mambavision for emotion recognition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaF-transformer: Leveraging coupling text-graph embedding for semantic calibration in textual entailment. <em>KBS</em>, <em>327</em>, 114180. (<a href='https://doi.org/10.1016/j.knosys.2025.114180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Textual Entailment (TE) aims to recognize the semantic relationships between premises and hypotheses, a fundamental task in Natural Language Inference (NLI). Given the growing complexity of inference information, Transformer-based methods have explored concatenating various structural and semantic information for further improvement. The semantics of input information vary in different sources, leading to decreased performance due to negative generalization from semantic inconsistencies in straightforward concatenation. To address this issue, we proposed a novel Transformer-based method named Latent Fusion Transformer (LaFT). LaFT leverages latent topic information to couple the text and graph information, calibrating the semantic knowledge in TE. The latent topic information extracted from texts is employed to sample the graph information to construct text-graph embedding for rational concatenation of premises and hypotheses. The attention mechanism is often employed as a black-box module, lacking the explicit design for capturing the consistent semantics between inputs. To calibrate the semantics of inputs for TE, LaFT utilizes an attention scaling matrix derived from latent topic similarity to guide the attention allocation in the training. Considering the coupling of text-graph embedding and the calibration of semantics, LaFT improves the rational concatenation of premises and hypotheses in TE, offering a promising advancement in NLI. Extensive experiments are conducted on five public datasets with accuracy and macro F1-score evaluation metrics. On average, LaFT outperforms the state-of-the-art baselines in extensive experiments.},
  archive      = {J_KBS},
  author       = {Shaokang Wang and Li Pan},
  doi          = {10.1016/j.knosys.2025.114180},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114180},
  shortjournal = {Knowl. Based Syst.},
  title        = {LaF-transformer: Leveraging coupling text-graph embedding for semantic calibration in textual entailment},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-DDA: Meta-learning with diffusion and dual augmentation for few-shot text classification. <em>KBS</em>, <em>327</em>, 114179. (<a href='https://doi.org/10.1016/j.knosys.2025.114179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning can construct neural architectures endowed with rapid task adaptation capabilities under limited labeled data regimes while preserving the generalization efficacy across distribution shifts. Meta-learning frameworks that adopt bi-level optimization paradigms have emerged as predominant solutions for few-shot learning problems owing to their architectural parsimony and parameter efficiency. However, inherent hierarchical optimization dynamics (outer-loop meta-optimization over task-specific loss landscapes and inner-loop, gradient-based task adaptation) cause computational pathology via second-order gradient backpropagation across inner-loop trajectories. This induces sensitivity degradation in parameter initialization and gradient propagation instability, particularly under cross-task distributional disparities. To address these limitations, we propose Meta-DDA, a novel meta-learning framework that substitutes conventional gradient descent in the inner-loop with diffusion-based denoising trajectories. Meta-DDA effectively circumvents the numerical instability of traditional meta-learning, second-order gradient backpropagation by reconstructing inner-loop gradient optimization as a denoising trajectory of the task conditions. This significantly reduces the sensitivity to initialization by utilizing noise scheduling with progressive parameter updating of Gaussian prior to achieve more stable and robust optimization in scenarios with few samples. Furthermore, we develop dual data augmentation strategies that are compatible with the bi-level architecture: (1) task-level augmentor at the meta-level stage mitigates excessive parameter updates caused by task difficulty variance; (2) sample-level augmentor at the base learner stage augments task-specific feature learning. Extensive experiments on four text classification datasets and four intent recognition datasets demonstrate the superior performance of Meta-DDA with markedly improved cross-domain generalization.},
  archive      = {J_KBS},
  author       = {Yongjun Wang and Yizhao Zhu and Hao Wang and Ru Wang and Huajuan Duan and Lei Guo and Peiyu Liu},
  doi          = {10.1016/j.knosys.2025.114179},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114179},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta-DDA: Meta-learning with diffusion and dual augmentation for few-shot text classification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample efficient reinforcement learning via low-rank regularization. <em>KBS</em>, <em>327</em>, 114176. (<a href='https://doi.org/10.1016/j.knosys.2025.114176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the usefulness of low-rankness in state-action value function estimation is demonstrated using a simplified setup that is amenable to theoretical analysis. First, the concept of low-rank functions is defined motivated by standard functional analysis results. Subsequently, a specific procedure is proposed based on nuclear-norm penalized series estimation, in which the estimation of the low-rank function naturally leads to estimation of a low-rank matrix. Risk bounds are established for the estimator, which shows faster convergence rates compared to the standard estimator without using low-rankness. Several simulated toy examples are used as proof of concept to demonstrate the performances in simulations.},
  archive      = {J_KBS},
  author       = {Jiamin Liu and Heng Lian},
  doi          = {10.1016/j.knosys.2025.114176},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114176},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sample efficient reinforcement learning via low-rank regularization},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale welding defect detection method based on image adaptive enhancement. <em>KBS</em>, <em>327</em>, 114174. (<a href='https://doi.org/10.1016/j.knosys.2025.114174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic detection of welding internal defects using radiographic images is an important technique for improving the efficiency and consistency of weld fault diagnosis. However, accurate defect detection is challenging due to the low contrast of radiographic images and the large difference in the sizes of different welding defects. In existing methods, the ray image enhancement and defect detection processes are isolated, and the enhancements that are beneficial to defect detection need to be obtained by manual parameter adjustment, which cannot adapt to large-scale detection tasks. Moreover, the adjustment strategy of the methods to the input image is not conducive to detecting multiscale welding defects. Therefore, this paper proposes a multiscale welding defect detection method based on image adaptive enhancement to address these problems. The method comprises two modules: image adaptive adjustment (IAA) and defect detection based on global and local semantic fusion (DD-GLF). In the IAA module, the parameter prediction network is trained to adaptively predict the parameters of the differentiable image processing function to improve the detection accuracy, and in the DD-GLF module, a defect detection model that accepts global and local window images of welds as inputs is designed to detect multiscale welding defects. Experiments on actual inspection data show that the proposed method achieves enhancement results that are consistent with those of human experts and performs well for dense and large defects.},
  archive      = {J_KBS},
  author       = {Huyue Cheng and Hongquan Jiang and Deqiang Jing and Lei Huang and Jianmin Gao and Yong Zhang and Bo Meng},
  doi          = {10.1016/j.knosys.2025.114174},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114174},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiscale welding defect detection method based on image adaptive enhancement},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach of transfer learning and feature concatenation for classification of camouflage images. <em>KBS</em>, <em>327</em>, 114173. (<a href='https://doi.org/10.1016/j.knosys.2025.114173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since camouflaged objects in camouflage images have weak boundaries and very close texture, color and pattern characteristics with the background, their detection and classification are very challenging problems. Traditional methods, which are widely used in the literature, are insufficient to solve this problem. Therefore, pre-trained transfer learning (TL) architectures were used to calculate classification performances. In this study we propose a novel dual-branch transfer learning architecture that integrates DenseNet201 and MobileNet models via a concatenation-based feature fusion strategy. This design allows the model to leverage multi-level semantic features from both networks, enhancing its ability to distinguish camouflaged objects in complex scenes. In deep learning-based architectures, it is very important to have enough data for classification success. However, this good performance is usually based on a sufficient amount of data. Insufficient data can lead to low classification performance or problems such as overfitting. Therefore, the number of raw training images was increased by applying data augmentation to the training images in the COD10K camouflage dataset used in this study. Additionally, augmented training data provided by ERVA 1.0, a challenging camouflage dataset, was used with ERVA 1.0 test data. As a result of the experimental studies, the DenseNet201 model showed the best classification performance with an accuracy of 97.67 % for the classification task on the COD10K dataset and the DenseNet201 model showed the best classification performance with an accuracy of 98.49 % on the ERVA 1.0 dataset. The study also combines pre-trained TL architectures with different combinations to create a new concatenation-based pre-trained approach with more extensive feature extraction and generalization capabilities. In this context, the architectures that perform the best classification performance are combined in different combinations. With these combinations, the best results were obtained with 98.41 % accuracy for the COD10K and 98.83 % accuracy for the ERVA 1.0 with the concatenation-based DenseNet201 + MobileNet model.},
  archive      = {J_KBS},
  author       = {Erkan Bayram and Vasif V. Nabiyev and Adilzhan Kereyev},
  doi          = {10.1016/j.knosys.2025.114173},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114173},
  shortjournal = {Knowl. Based Syst.},
  title        = {An approach of transfer learning and feature concatenation for classification of camouflage images},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain multi-step thinking: Zero-shot fine-grained traffic sign recognition in the wild. <em>KBS</em>, <em>327</em>, 114172. (<a href='https://doi.org/10.1016/j.knosys.2025.114172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose C ross- d omain M ulti-step T hinking ( CdMT ) to improve zero-shot fine-grained traffic sign recognition (TSR) performance in the wild. Zero-shot fine-grained TSR in the wild is challenging due to the cross-domain problem between clean template traffic signs and real-world counterparts, and existing approaches particularly struggle with cross-country TSR scenarios, where traffic signs typically differ between countries. The proposed CdMT framework tackles these challenges by leveraging the multi-step reasoning capabilities of large multimodal models (LMMs). We introduce context, characteristic, and differential descriptions to design multiple thinking processes for LMMs. Context descriptions, which are enhanced by center coordinate prompt optimization, enable the precise localization of target traffic signs in complex road images and filter irrelevant responses via novel prior traffic sign hypotheses. Characteristic descriptions, which are derived from in-context learning with template traffic signs, bridge cross-domain gaps and enhance fine-grained TSR. Differential descriptions refine the multimodal reasoning ability of LMMs by distinguishing subtle differences among similar signs. CdMT is independent of training data and requires only simple and uniform instructions, enabling it to achieve cross-country TSR. We conducted extensive experiments on three benchmark datasets and two real-world datasets from different countries. The proposed CdMT framework achieved superior performance compared with other state-of-the-art methods on all five datasets, with recognition accuracies of 0.93, 0.89, 0.97, 0.89, and 0.85 on the GTSRB, BTSD, TT-100K, Sapporo, and Yokohama datasets, respectively.},
  archive      = {J_KBS},
  author       = {Yaozong Gan and Guang Li and Ren Togo and Keisuke Maeda and Takahiro Ogawa and Miki Haseyama},
  doi          = {10.1016/j.knosys.2025.114172},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114172},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain multi-step thinking: Zero-shot fine-grained traffic sign recognition in the wild},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Actminer: Applying causality tracking and increment aligning for graph-based threat hunting. <em>KBS</em>, <em>327</em>, 114169. (<a href='https://doi.org/10.1016/j.knosys.2025.114169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To defend against advanced persistent threats on the endpoint, threat hunting employs security knowledge, such as cyber threat intelligence (CTI), to continuously analyze system audit logs through retrospective scanning, querying, or pattern matching, aiming to uncover attack patterns/graphs that traditional detection methods (e.g., recognition for point of interest) fail to capture. However, existing threat hunting systems based on provenance graphs face challenges of high false negatives (FNs), high false positives (FPs), and low efficiency when confronted with diverse attack tactics and voluminous audit logs. To address these issues, we propose a system called Actminer , which constructs query graphs from descriptive relationships in CTI reports for precise threat hunting (i.e., graph alignment) on provenance graphs. First, we present a heuristic search strategy based on equivalent semantic transfer to reduce FNs. Second, we establish a filtering mechanism based on causal relationships of attack behaviors to mitigate FPs. Finally, we design a tree structure to incrementally update the alignment results, significantly improving hunting efficiency. Evaluation on the DARPA Engagement dataset demonstrates that compared with the SOTA POIROT, Actminer reduces FPs by 39.1 %, eliminates all FNs, and effectively counters adversarial attacks.},
  archive      = {J_KBS},
  author       = {Mingjun Ma and Tiantian Zhu and Shuang Li and Tieming Chen and Mingqi Lv and Zhengqiu Weng and Guolang Chen},
  doi          = {10.1016/j.knosys.2025.114169},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114169},
  shortjournal = {Knowl. Based Syst.},
  title        = {Actminer: Applying causality tracking and increment aligning for graph-based threat hunting},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-aware adversarial ensemble learning for multivariate time series anomaly detection. <em>KBS</em>, <em>327</em>, 114168. (<a href='https://doi.org/10.1016/j.knosys.2025.114168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In safety-critical systems like aircraft, manufacturing, and energy, anomalies often signal early issues, and failing to detect them promptly can lead to severe losses of life and property. In these scenarios, anomaly detection faces challenges including the scarcity of anomalous data and the complexity and diversity of fault modes. To address these challenges, we proposes a novel boundary-aware anomaly detection method in which training data are augmented with boundary samples near the normal data. In contrast with other data augmentation techniques, the boundary samples are beneficial to anomaly detection in that it provide a natural and convenient computational mechanism to incorporate prior knowledge about the abnormality while maintaining their diversity. For this purpose, we use an ensemble-based model to infer the uncertainty about the degree of abnormality of the candidate samples, and only accept those with low uncertainty, while those samples themselves are produced by an end-to-end trained deep generative model. Extensive experiments demonstrate that our method outperforms 13 existing methods across 5 categories, and achieves statistically significant improvements. The experiments results also validate the critical role of uncertainty in boundary sample generation and offer a new perspective for multivariate time-series anomaly detection in safety-critical systems.},
  archive      = {J_KBS},
  author       = {Pengcheng He and Xiaoyang Tan and Yuehua Cheng},
  doi          = {10.1016/j.knosys.2025.114168},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114168},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boundary-aware adversarial ensemble learning for multivariate time series anomaly detection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Poly-TF: A polymeric transformer framework for multiple visual tasks at once. <em>KBS</em>, <em>327</em>, 114167. (<a href='https://doi.org/10.1016/j.knosys.2025.114167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, vision transformer (ViT) has demonstrated remarkable efficacy across multiple visual tasks. However, prevalent paradigms of ViT variants involve the optimization of a singular model for a particular task, resulting in a linear escalation in total model size as the number of tasks increases. To address this issue, we develop Poly-TF, a polymeric transformer framework tailored to concurrently optimize multiple visual tasks spanning diverse dataset domains. The core of Poly-TF is leveraging shared parameters to reduce total storage requisites, along with the utilization of task-specific parameters to capture distinctive feature representations for each task. Technically, we develop a prompt-based modulation mechanism that seeks to compensate discrepancies across diverse task domains, thereby empowering the network to gain a deep understanding for each prevailing task and facilitating task-specific feature extraction. Besides, we introduce an adaptive granular parameter-sharing scheme applied to each linear layer within the transformer block, which automatically discerns the shared parameters for efficient storage and task-specific parameters for further specific task perception. Benefitting from the proposed techniques, Poly-TF explicitly establishes feature representations unique to each task via the task-specific components while implicitly modeling generic information along with cross-task correlations through the shared ones. Rigorous experiments prove that Poly-TF exhibits competitive performance in various visual tasks with substantially reduced storage demands. Moreover, we also demonstrate that the presence of task-specific components in Poly-TF intrinsically facilitates incremental learning while circumventing catastrophic forgetting. The code is available at https://github.com/Mrfanxuan/poly-tf .},
  archive      = {J_KBS},
  author       = {Xuan Fan and Cheng Zhang and Tao Sun and Jinghan Gao and Tao Xie and Kun Dai and Lijun Zhao and Ruifeng Li},
  doi          = {10.1016/j.knosys.2025.114167},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114167},
  shortjournal = {Knowl. Based Syst.},
  title        = {Poly-TF: A polymeric transformer framework for multiple visual tasks at once},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting cognitive impairment in diabetics based on retinal photos by a deep learning method. <em>KBS</em>, <em>327</em>, 114165. (<a href='https://doi.org/10.1016/j.knosys.2025.114165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive impairment in diabetic patients has drawn increasing attention, yet conventional assessments like neuroimaging and cognitive scales are costly, invasive, or subjective, limiting their use in large-scale screening. This study proposes a deep learning-based method for identifying moderate to severe cognitive impairment in type 2 diabetes patients using only fundus images. A total of 1000 fundus images from 250 patients were collected. We developed a four-branch model, FB_Net, incorporating a self-designed Average Attention Block (AA_Block) and Multi-Scale Convolutional Block Attention Module (MS_CBAM). The latter introduced a Multi-Scale Convolution Block (MSC_Block) to enhance the multi-scale feature extraction capability of the original Convolutional Block Attention Module (CBAM). We compare four backbone networks—MobileNetV1, AlexNet, EfficientNet-b0, and ResNet34, among which MobileNetV1 achieved the best performance for classification, with an accuracy of 0.732 and an AUC of 0.790. Grad-CAM visualization revealed that regions rich in fundus vasculature are key to classification as biomarkers. These results highlight the importance of vascular features in cognitive assessment and demonstrate that the proposed artificial intelligence approach is a promising, non-invasive, and cost-effective tool for early screening and potential clinical application in diabetic populations.},
  archive      = {J_KBS},
  author       = {Xinlong Xing and Mengyao Ye and Zhantian Zhang and Ou Liu and Chaoyi Wei and Xiaosen Li and Zhimin He and Graham Smith and Zhen Wang and Xiaoming Jiang and Wenjun Wu},
  doi          = {10.1016/j.knosys.2025.114165},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114165},
  shortjournal = {Knowl. Based Syst.},
  title        = {Detecting cognitive impairment in diabetics based on retinal photos by a deep learning method},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed incremental arc-consistency reasoning method for temporal network in multi-probe collaborative mission planning. <em>KBS</em>, <em>327</em>, 114164. (<a href='https://doi.org/10.1016/j.knosys.2025.114164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-probe collaborative exploration represents a future trend in asteroid exploration. Significant improvements in onboard mission planning efficiency rely on rapidly inspecting the consistency of temporal constraints during probe mission planning. This research study proposes an innovative algorithm to address the dynamic temporal constraint problem in multi-probe collaborative mission planning. A Distributed Incremental Arc-Consistency (DIAC) algorithm, which limits the scope of constraint propagation through localized reasoning, is therefore proposed. A dynamic strategy for processing different constraints is designed to reduce the number of constraint checks. In its process of dynamically updating the temporal network, the algorithm avoids unnecessary global computations, thereby improving the efficiency of temporal consistency reasoning in planning. Simulations conducted on benchmark datasets demonstrate the effectiveness of the proposed algorithm. The DIAC algorithm effectively circumvents the privacy concerns of agents inherent in path-consistency algorithms. Compared with arc-consistency-based algorithms such as DisACSTP and GDAC, the proposed DIAC algorithm demonstrates superior performance. It reduces constraint reasoning time by 77.2 % and planning time by 23.69 % compared to DisACSTP. Against GDAC, DIAC consistently exhibits lower running time and fewer constraint checks, with its advantages remaining stable even as the number of agents increases or external constraints are introduced. In addition, DIAC significantly reduces redundant computation and inter-agent communication. These results highlight DIAC’s potential to advance multi-probe mission planning in complex environments, particularly in scenarios requiring privacy preservation and real-time responsiveness.},
  archive      = {J_KBS},
  author       = {Bang Wang and Rui Xu and Zhaoyu Li and Shengying Zhu and Xiuwei Li},
  doi          = {10.1016/j.knosys.2025.114164},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114164},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distributed incremental arc-consistency reasoning method for temporal network in multi-probe collaborative mission planning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-graph convolution networks for robust multi-view clustering. <em>KBS</em>, <em>327</em>, 114163. (<a href='https://doi.org/10.1016/j.knosys.2025.114163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep contrastive representation learning methods for unlabeled multi-view data have shown impressive performance by shrinking the cross-view discrepancy. However, most of these methods primarily focus on the procedure of common semantics extraction from multiple views, which is just one of the factors affecting the performance of unsupervised multi-view representation learning. Two additional factors are often overlooked: i) how to improve the discriminative ability of final representations. Existing unsupervised-based approaches normally perform worse on clustering as the number of categories increases. ii) how to balance the contribution of multiple views (specifically in data with more than two views). We observe that the quality of the learned representation is also influenced by certain views, i.e., the model precision may be decreased when some views are involved in the training. To address these factors, we propose a novel contrastive learning-based method, called Cluster-Graph Convolution networks for Robust Multi-view Clustering (CGC-RMC), for unlabeled multi-view data. Specifically, we design a specialized spatial-based cluster-graph convolution and a new adaptive sample-weighted strategy in a contrastive-based basic framework for the above two factors. Additionally, the proposed method adopts a communication fusion module to relieve the influence of view-private information in final view representations. Extensive experiments demonstrate that the proposed method outperforms eleven competitive unsupervised representation learning methods on six multi-view datasets based on the performance of the learned representation on the clustering task.},
  archive      = {J_KBS},
  author       = {Wei Zheng and Xiao-Yuan Jing and Wei Liu and Fei Wu and Changhui Hu and Bo Du},
  doi          = {10.1016/j.knosys.2025.114163},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114163},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cluster-graph convolution networks for robust multi-view clustering},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVSTD: Multi-view spatio-temporal graphs with external disturbance consideration for ride-hailing demand prediction. <em>KBS</em>, <em>327</em>, 114161. (<a href='https://doi.org/10.1016/j.knosys.2025.114161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of ride-hailing demand is crucial for intelligent transportation systems, optimizing fleet management, reducing idle vehicle times, and alleviating urban traffic congestion. This task is particularly challenging due to intricate spatio-temporal dependencies, dynamic demand fluctuations, and the influence of external factors such as weather and public holidays. Existing methods often fail to adequately capture these non-linear dynamics or integrate the full spectrum of external disturbances. To address these challenges, we propose the Multi-View Spatio-Temporal Graphs with External Disturbance Consideration (MVSTD) framework. MVSTD innovatively combines multi-view spatio-temporal graph modeling with explicit incorporation of external disturbances, enabling more accurate and robust demand forecasting. The framework captures critical interactions between historical demand patterns and external variables, such as weather and holidays, to identify key drivers of demand variability. Extensive experiments on two large-scale, real-world datasets demonstrate that MVSTD consistently outperforms state-of-the-art methods across multiple evaluation metrics. Notably, MVSTD demonstrates superior performance in high-variability scenarios, including public holidays and adverse weather conditions, showcasing its practical relevance for real-world ride-hailing demand prediction.},
  archive      = {J_KBS},
  author       = {Xuanxuan Fan and Zihang Yin and Kaiyuan Qi and Dong Wu and Zhijian Qu and Chongguang Ren},
  doi          = {10.1016/j.knosys.2025.114161},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114161},
  shortjournal = {Knowl. Based Syst.},
  title        = {MVSTD: Multi-view spatio-temporal graphs with external disturbance consideration for ride-hailing demand prediction},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilled mid-fusion transformer networks for multi-modal human activity recognition. <em>KBS</em>, <em>327</em>, 114160. (<a href='https://doi.org/10.1016/j.knosys.2025.114160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition is an important task in many human-computer collaborative scenarios, with various practical applications. Although uni-modal approaches have been extensively studied, they suffer from data quality issues and require modality-specific feature engineering, making them neither robust nor effective enough for real-world deployment. By utilizing various sensors, Multi-modal Human Activity Recognition can leverage complementary information to build models that generalize well. While deep learning methods have shown promising results, their potential in extracting salient multi-modal spatial-temporal features and better fusing complementary information has not been fully explored. Additionally, reducing the complexity of the multi-modal approach for edge deployment is another unresolved issue. To address these issues, a Knowledge Distillation-based Multi-modal Mid-Fusion approach, DMFT, is proposed to facilitate informative feature extraction and fusion for efficiently solving the Multi-modal Human Activity Recognition task. DMFT first encodes the multi-modal input data into a unified representation. The DMFT teacher model then applies an attentive multi-modal spatial-temporal transformer module that extracts the salient spatial-temporal features. A temporal mid-fusion module is also proposed to further fuse the temporal features. Subsequently, the Knowledge Distillation method is applied to transfer the learned representation from the teacher model to a simpler DMFT student model, which consists of a lite version of the multi-modal spatial-temporal transformer module, to produce the results. Evaluation of DMFT was conducted on two public multi-modal human activity recognition datasets alongside various state-of-the-art approaches. The experimental results demonstrate that the model achieves competitive performance in terms of effectiveness, scalability, and robustness.},
  archive      = {J_KBS},
  author       = {Jingcheng Li and Lina Yao and Binghao Li and Claude Sammut},
  doi          = {10.1016/j.knosys.2025.114160},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114160},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distilled mid-fusion transformer networks for multi-modal human activity recognition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPGOH: Label-prototype guided online hashing for efficient cross-modal retrieval. <em>KBS</em>, <em>327</em>, 114159. (<a href='https://doi.org/10.1016/j.knosys.2025.114159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing has recently received widespread attention due to its fast query speed, and existing batch-based methods are generally inefficient in an online scenario, i.e., multi-modal data points appear in a streaming manner. Although some online cross-modal hashing methods have been explored, they often neglect the semantic interdependency among the label categories and potentially suffer from the limited semantic preservations between newly coming data and existing data. To alleviate this concern, this paper proposes an efficient label-prototype guided online hashing (LPGOH) for cross-modal retrieval, which can incrementally learn the discriminative hash codes of streaming data while adaptively optimizing the hash function in a streaming manner. To be specific, the proposed framework first innovates a group of label-prototype codes to exploit the semantic interdependency between the label categories, and then combine the semantic similarity regularization to jointly learn the semantic-preserving hash codes. Meanwhile, ε -dragging operation is seamlessly utilized to provide provable large semantic margins, which can further promote the discrimination power of the learnt hash code and speed up the learning process. Besides, an online discrete optimization algorithm is efficiently designed to parse the semantic interdependency between the label categories, learn the compact hash codes for the current arriving data, and optimize the hash functions adaptively. Accordingly, the hash codes of streaming data are discriminatively learned to benefit various online cross-modal retrieval tasks. Extensive experiments evaluated on benchmark datasets verify the advantages of the proposed LPGOH framework, by achieving the competitive and mostly improved retrieval performance over the state-of-the-arts.},
  archive      = {J_KBS},
  author       = {Shu-Juan Peng and Xueting Jiang and Xin Liu and Ji-Xiang Du and Jianjia Cao},
  doi          = {10.1016/j.knosys.2025.114159},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114159},
  shortjournal = {Knowl. Based Syst.},
  title        = {LPGOH: Label-prototype guided online hashing for efficient cross-modal retrieval},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning global dependencies via parallelized graph transformer with hybrid attention. <em>KBS</em>, <em>327</em>, 114157. (<a href='https://doi.org/10.1016/j.knosys.2025.114157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a Parallelized Graph Transformer (ParaFormer) model with hybrid attention to enhance the computational efficiency and representational capability of Graph Transformer Models (GTMs). Compared to existing GTMs, ParaFormer achieves parallelized computation by segmenting the input graph as subgraph blocks. This approach effectively improves computational speed and reduces memory consumption. Additionally, to establish global semantic modeling within the segmented graph, we devise a hybrid attention mechanism between different feature levels, which combines multi-scale attention across node-to-node, block-to-block, and node-to-block interactions. This mechanism effectively captures global dependencies in the segmented parallel computation process and strengthens the model’s ability to encode both global and local information. To further optimize the efficiency of global information aggregation, we employ a bidirectional attention-scoring mechanism. This mechanism enhances the model’s selectivity for relevant information while suppressing irrelevant information, improving the global information filtering process. Experimental results on multiple real-world graph datasets demonstrate that ParaFormer achieves comparable or superior performance while significantly reducing resource consumption. Specifically, memory usage is reduced by approximately 60 %, and training time by around 70 %, compared to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yutai Duan and Jie Liu and Xingyang He and Yi Lv},
  doi          = {10.1016/j.knosys.2025.114157},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114157},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning global dependencies via parallelized graph transformer with hybrid attention},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single & cross: A graph-enhanced framework for cross-domain recommendation with transfer learning. <em>KBS</em>, <em>327</em>, 114156. (<a href='https://doi.org/10.1016/j.knosys.2025.114156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation (CDR) helps improve the recommendation performance of the target domain by transferring knowledge from relevant auxiliary domains, which will tend to alleviate data sparsity and cold start problems. Many cross-domain recommendation methods only focus on a single target domain, which makes them less effective at precisely predicting user preferences. Recently, dual-target cross-domain recommendation has been proposed to promote performance improvement in both domains simultaneously by utilizing the information from both domains. However, most existing studies suffer from the problem of insufficient extraction of domain-specific information and the neglect of cross-domain non-overlapping item associations, which result in the inability to transfer multiple potential features across various domains effectively. To this end, we propose a graph-enhanced framework for the cross-domain recommendation, single&cross, to promote Top- N recommendation. The framework comprises three key parts: multi-graph construction, preference feature modeling, and multiple potential features fusion. It can capture both intra-domain and inter-domain information based on constructing exclusive graphs and a shared graph simultaneously, and a cross-domain mechanism at the element level is adopted to adaptively transfer the deep multiple potential preference features of specific and shared domains. Experiments conducted on two pairs of real-world cross-domain datasets composed of Amazon comment datasets have demonstrated that our method outperforms state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Yiru Chang and Zhiyuan Zhang and Yang Zhang},
  doi          = {10.1016/j.knosys.2025.114156},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114156},
  shortjournal = {Knowl. Based Syst.},
  title        = {Single & cross: A graph-enhanced framework for cross-domain recommendation with transfer learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal visiting-monitoring feature interaction learning for modelling structured electronic health records. <em>KBS</em>, <em>327</em>, 114155. (<a href='https://doi.org/10.1016/j.knosys.2025.114155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records (EHRs) contain patients’ longitudinal visit records, and modelling EHRs can be applied to various clinical prediction tasks. Previous works primarily focus on visit sequences and perform feature interaction on visit-level data to capture patient states. Nonetheless, incorporating finer-grained monitoring sequences simultaneously in structured EHRs, where each visit involves multiple monitoring sessions, can improve prediction performance. However, these studies have not accounted for the relationships between visit-level and monitoring-level data. To address this gap, we propose a method for modelling structured EHRs that focuses on capturing the dynamic interactions between visit-level and monitoring-level data, enabling the identification of finer-grained health trends. Specifically, we first capture the dynamic influence between medical data, and then perform a visiting-monitoring feature interaction on the relationships between visit data and monitoring data. Finally, we train models hierarchically across different granularities, from monitoring-level to visit-level, to obtain patient representations for clinical prediction tasks. We conducted extensive experiments on disease prediction and drug recommendation tasks, with MIMIC-III and MIMIC-IV datasets, demonstrating that our method outperforms state-of-the-art models significantly.},
  archive      = {J_KBS},
  author       = {Xiang Li and Xiao-Hua Zhou},
  doi          = {10.1016/j.knosys.2025.114155},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114155},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal visiting-monitoring feature interaction learning for modelling structured electronic health records},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using natural language definitions and language models for relationship classification. <em>KBS</em>, <em>327</em>, 114154. (<a href='https://doi.org/10.1016/j.knosys.2025.114154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying relationships between concepts is a very important task for several NLP tasks, as well as for building explicit knowledge models (ontologies and knowledge graphs). In many of these tasks, experts usually manually establish these relationships by carefully analyzing each concept’s meaning and considering the domain knowledge elicited from domain practitioners or from domain literature. While some studies automate parts of the process of building knowledge models, most focus on identifying general concepts or rely on static word embeddings, which fail to address challenges like polysemy and contextual ambiguity. This research addresses the problem of classifying semantic relationships between concepts, focusing on hypernym and holonym relations. We propose an approach based on the pre-trained language model BERT to classify these relationships between concepts. We assume that we can represent the concept’s semantics using their definitions in natural language. To evaluate this approach, we developed a methodology to construct a labeled dataset of definitions of concepts using WordNet as a reference. Thus, our proposed approach classifies the relations based solely on natural language expressions representing the concept’s definition. Our experiments showed notable classification results, achieving an F1 score of 96 % in the classification of holonyms, hypernyms, and concepts that are not related by any of these relations, indicating that our approach can accurately predict semantic relations between concepts using only their natural language definitions as input.},
  archive      = {J_KBS},
  author       = {Marina Martins Amorim and Alcides Gonçalves Lopes Junior and Fabrício Henrique Rodrigues and Joel Luís Carbonera},
  doi          = {10.1016/j.knosys.2025.114154},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114154},
  shortjournal = {Knowl. Based Syst.},
  title        = {Using natural language definitions and language models for relationship classification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A segmented motion synthesis method for robotic task-oriented locomotion imitation system. <em>KBS</em>, <em>327</em>, 114152. (<a href='https://doi.org/10.1016/j.knosys.2025.114152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research highlights the potential of learning agile robotic locomotion by imitating segmented motion data from humans. However, using single-mode motion data for imitation learning is inefficient for task-specific actions, and motion capture and retargeting processes can be time-consuming. To address these challenges, we propose a motion synthesis framework that combines segmented motions to produce task-specific behaviors characterized by natural movement. Our approach involves three main components: the State Variational Autoencoder (SVAE), the Control Network of Synthesized Motion (SMC-Net), and Critical Joint Constraints (CJC). The SVAE learns motion dynamics from segmented movements and encodes them into a latent space, enabling efficient combination of diverse motions during reinforcement learning. The SMC-Net selects optimal postures from segmented data using Deep Reinforcement Learning (DRL), and its integration with the SVAE’s latent space enhances motion realism. Critical joint constraints are incorporated into the reward to further improve motion quality. Testing on two reach-target-and-reaction tasks with three types of motions demonstrated a 2.6-fold increase in mean rewards and a 1.1-fold reduction in task completion time compared to state-of-the-art baselines using single-mode motions.},
  archive      = {J_KBS},
  author       = {Haobin Shi and Ziming He and Jianning Zhan and Kao-Shing Hwang},
  doi          = {10.1016/j.knosys.2025.114152},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114152},
  shortjournal = {Knowl. Based Syst.},
  title        = {A segmented motion synthesis method for robotic task-oriented locomotion imitation system},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is AI-assisted paraphrase the new tool for fake review creation? challenges and remedies. <em>KBS</em>, <em>327</em>, 114151. (<a href='https://doi.org/10.1016/j.knosys.2025.114151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake review detection is a substantive problem that affects businesses and consumers who form purchase opinions about products or services. With the recent advances of generative artificial intelligence (GAN) and more specifically large language models (LLMs) there is a new kind of fake review creation mechanism that is now available to malicious users. Paraphrasing existing reviews is a new form of AI assisted plagiarism that can be used to artificially manipulate the online reputation of a product, service, or business. In this paper, we describe these new challenges, we provide a pattern detection-based methodology that can be used to strengthen current information systems management algorithms. and we perform a comparison against commercial and open-source AI text detection tools. We demonstrate the use of the proposed methodology with a review dataset from real reviews from TripAdvisor mixed with paraphrased reviews with ChatGPT 4.0. The classification performance of the proposed method achieves high scores in confusion matrix metrics, where accuracy, precision, sensitivity, specificity, and F1-score are above 90 %.},
  archive      = {J_KBS},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.knosys.2025.114151},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114151},
  shortjournal = {Knowl. Based Syst.},
  title        = {Is AI-assisted paraphrase the new tool for fake review creation? challenges and remedies},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A machine learning approach for detecting cybersecurity vulnerabilities in the internet of medical things. <em>KBS</em>, <em>327</em>, 114150. (<a href='https://doi.org/10.1016/j.knosys.2025.114150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber incidents in healthcare are rising, targeting medical devices with outdated security. While networking medical devices improves performance, it also expands the attack surface, requiring urgent security measures. Our study introduces a novel approach to vulnerability assessment in networked medical devices using machine learning on the CICIoMT2024 dataset from the Canadian Institute for Cybersecurity. This dataset includes traffic data from 40 IoMT devices under 18 attack types (DDoS, DoS, Recon, MQTT, and spoofing) and normal lifecycle behaviour (power, idle, active, interaction). Its diverse protocols mirror real-world healthcare environments. We conducted a three-stage vulnerability assessment. First, we built a lifecycle classifier to predict device states under attack, with Random Forest achieving the highest accuracy (0.8915), precision (0.8905), recall (0.8915), and F1-score (0.8907). Second, we developed a device classifier to identify attack types per device, where Random Forest again performed best (accuracy: 0.9789, precision: 0.9791, recall: 0.9789, F1-score: 0.9789). Lastly, we analysed device vulnerabilities across lifecycle stages using visual plots. Our findings highlight the importance of lifecycle-aware security strategies to protect IoMT devices from evolving Cyber threats.},
  archive      = {J_KBS},
  author       = {Ukamaka Oragwu and Benjamin Aziz and Shahadate Rezvy},
  doi          = {10.1016/j.knosys.2025.114150},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114150},
  shortjournal = {Knowl. Based Syst.},
  title        = {A machine learning approach for detecting cybersecurity vulnerabilities in the internet of medical things},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MASA: Multi-view adaptive subspace alignment for enhanced few-shot learning. <em>KBS</em>, <em>327</em>, 114148. (<a href='https://doi.org/10.1016/j.knosys.2025.114148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning, which aims to make predictions with very few training samples, often employs the concept of meta-learning, where numerous training tasks are constructed to facilitate effective generalization. Although many existing few-shot learning methods have demonstrated good performance in image classification, it remains challenging to handle images with complex backgrounds and hidden targets. One potential solution to this limitation is the integration of complementary information from multiple views, rather than relying on a single perspective, which can enhance the effectiveness of few-shot learning. In this work, we propose MASA, a m ulti-view few-shot learning approach via a daptive s ubspace a lignment, which leverages the complementary information in few-shot scenarios by adaptively aligning view-specific subspaces in each class to improve classification performance. The MASA first learns the view-class-specific subspaces for the support samples, then adaptively align these subspaces across different views by maximizing the class-specific subspace distances and minimizing the view-specific subspace distances, and finally assign the query to the category corresponding to the subspace with the smallest distance. Experiments on four multi-view image datasets show that our MASA approach yields the best classification results over other state-of-the-art methods. Furthermore, it also outperforms current Vision Foundation Models (VFMs) on multi-view images with high-noise backgrounds and hidden targets, which highlights the advantage of our MASA method for capturing multi-view features in few-shot scenarios.},
  archive      = {J_KBS},
  author       = {Xi Wang and Jing Liu and Limin Li},
  doi          = {10.1016/j.knosys.2025.114148},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114148},
  shortjournal = {Knowl. Based Syst.},
  title        = {MASA: Multi-view adaptive subspace alignment for enhanced few-shot learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient federated knowledge graph embedding with entity-wise top-K sparsification. <em>KBS</em>, <em>327</em>, 114147. (<a href='https://doi.org/10.1016/j.knosys.2025.114147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Knowledge Graphs Embedding learning (FKGE) encounters challenges in communication efficiency stemming from the considerable size of parameters and extensive communication rounds. However, existing FKGE methods only focus on reducing communication rounds by conducting multiple rounds of local training in each communication round, and ignore reducing the size of parameters transmitted within each communication round. To tackle the problem, we first find that universal reduction in embedding precision across all entities during compression can significantly impede convergence speed, underscoring the importance of maintaining embedding precision. We then propose bidirectional communication-efficient FedS based on Entity-Wise Top-K Sparsification strategy. During upload, clients dynamically identify and upload only the Top-K entity embeddings with the greater changes to the server. During download, the server first performs personalized embedding aggregation for each client. It then identifies and transmits the Top-K aggregated embeddings to each client. Besides, an Intermittent Synchronization Mechanism is used by FedS to mitigate negative effect of embedding inconsistency among shared entities of clients caused by heterogeneity of Federated Knowledge Graph. Extensive experiments across four datasets showcase that FedS significantly enhances communication efficiency with negligible (even no) performance degradation. The code is available at: https://anonymous.4open.science/r/FedS-68E4 .},
  archive      = {J_KBS},
  author       = {Xiaoxiong Zhang and Zhiwei Zeng and Xin Zhou and Dusit Niyato and Zhiqi Shen},
  doi          = {10.1016/j.knosys.2025.114147},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114147},
  shortjournal = {Knowl. Based Syst.},
  title        = {Communication-efficient federated knowledge graph embedding with entity-wise top-K sparsification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active differentiable structure learning for clinical causal discovery. <em>KBS</em>, <em>327</em>, 114145. (<a href='https://doi.org/10.1016/j.knosys.2025.114145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical causal analysis is critical in deciphering the complex relationships between health-related factors to enhance diagnosis, treatment, and prevention strategies. However, traditional machine learning approaches often emphasize correlations, not causation, which might not accurately reflect the underlying clinical phenomena. Traditional causal analysis methods like Bayesian Networks, while robust, sometimes fail to capture subtle yet critical relationships due to their reliance on probabilistic reasoning and discrete algorithms. Although gradient-based continuous optimization algorithms have advanced causal discovery, challenges still arise from factors like noise, hidden variables, and the intricate nature of clinical data. Addressing these challenges, this paper introduces a novel active differentiable structure learning method that enhances causal model accuracy by integrating external knowledge during the learning process. This integration is managed through a soft constraint mechanism that balances data-driven learning and knowledge-based adjustments, allowing the model to dynamically adapt to new information and refine the causal relationships iteratively. We evaluate our approach using four synthetic datasets, two publicly available breast cancer datasets, and a custom-collected clinical dataset, showing that it significantly improves the accuracy and clinical relevance of the derived causal structures. This method not only enhances the interpretability of the causal models but also ensures that they remain robust and representative of the underlying clinical realities.},
  archive      = {J_KBS},
  author       = {Zhenchao Tao and Yanze Gao and Yijia Sun and Qiang Tu and Fei Gao and Lyuzhou Chen and Wei Wang and Huanhuan Chen},
  doi          = {10.1016/j.knosys.2025.114145},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114145},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active differentiable structure learning for clinical causal discovery},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic data selection with normalized gradient-based influence approximation for targeted fine-tuning of LLMs. <em>KBS</em>, <em>327</em>, 114144. (<a href='https://doi.org/10.1016/j.knosys.2025.114144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting suitable data yields increasing importance for Supervised Fine-Tuning (SFT) of large language models, efficiently enhancing their performance on specific tasks. To this end, gradient-based selection methods via influence approximation offer promising solutions by estimating how individual training data samples affect the target task loss. However, previous studies implicitly reveal that classic one-step gradient-based selection methods suffer from both selection length bias and decreasing long-time selection effectiveness. In this paper, we perform theoretical and empirical analysis to systematically investigate these two issues: (1) the selection length bias is caused by the negative correlation between the influence approximation and the lengths of the sample completion, which is introduced by the cumulative effect of token gradient norms; (2) the decreasing long-time selection effectiveness lies in the decreasing correlation between the one-step influence approximation and the targeted task loss optimization during the long training process. To address these issues, we further propose a dynamic normalized gradient-based data selection framework, where the selected data coreset is continuously updated based on recomputed influence scores with normalized gradients. Extensive experimental results verify our analysis, indicating that dynamic selection is better than static selection in loss optimization, targeting the model’s general, mathematical, or coding abilities. Meanwhile, our proposed framework also outperforms the state-of-the-art method in performance enhancement.},
  archive      = {J_KBS},
  author       = {Zige Wang and Qi Zhu and Fei Mi and Yasheng Wang and Haotian Wang and Lifeng Shang},
  doi          = {10.1016/j.knosys.2025.114144},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114144},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic data selection with normalized gradient-based influence approximation for targeted fine-tuning of LLMs},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal meta-learning for trajectory representation learning. <em>KBS</em>, <em>327</em>, 114141. (<a href='https://doi.org/10.1016/j.knosys.2025.114141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory representation learning translates sequences into low-dimensional vectors that are convenient for computer processing and analysis. Trajectory representation learning is widely used by various intelligent applications and is notable for its ability to enhance application performance. However, previous methods assume that trajectories are independently and identically distributed in time and space. In practice, trajectories exhibit significant heterogeneity in time and space sources due to the uncertainty of individual activities and the diversity of activity patterns. This leads to bias in the generated representation vectors that fail to effectively support various geographic applications. To address this issue, this study proposes a spatio-temporal meta-learning method for trajectory representation learning, namely STMetaT, which aims to generate accurate trajectory representation vectors. STMetaT designs a spatio-temporal constraint sampling module that divides trajectory sets into subsets based on the frequency and density of trajectories, which constructs training task samples with diverse spatio-temporal semantics. And, STMetaT uses a multi-view local encoder to generate representation vectors for each subset by fusing the diversity of trajectory semantics. Finally, STMetaT learns a generalization process from local to global promotability to optimize the trajectory representation vectors. Extensive experiments on two urban trajectory datasets show that STMetaT outperforms baseline methods in three classical evaluation tasks, thereby improving the performance of trajectory representation. The proposed method provides an approach for learning trajectory representation by combining meta-learning, and also provides a methodological reference for various intelligent applications.},
  archive      = {J_KBS},
  author       = {Zhouzheng Xu and Yuxing Wu and Hang Zhou and Chaofan Fan and Bingyi Li and Kaiyue Liu and Yaqin Ye and Shunping Zhou and Shengwen Li},
  doi          = {10.1016/j.knosys.2025.114141},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114141},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatio-temporal meta-learning for trajectory representation learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRP: LLM-based logical reasoning via prolog. <em>KBS</em>, <em>327</em>, 114140. (<a href='https://doi.org/10.1016/j.knosys.2025.114140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the logical reasoning capabilities of large language models (LLMs) is crucial for advancing LLMs’s applications in complex problem-solving contexts. Neurosymbolic programming-based approaches have demonstrated significant advantages in logical reasoning. Prolog is a high-level declarative programming language based on formal logic, well-suited for handling complex deductive reasoning tasks. However, its strict syntactic structure imposes inherent limitations on expressiveness, making it difficult to represent certain common logical constructs found in natural language. Since first-order logic (FOL) is the most fundamental formal language for logical semantic representation, we take it as a reference for analysis and find that even some of its most basic structures cannot be directly expressed in Prolog. To address this, we propose a systematic translation mechanism from FOL to Prolog, thereby extending Prolog’s expressiveness to support richer logical representations. Building on this foundation, we propose LoRP (LLM-based Logical Reasoning via Prolog), a novel framework that utilizes LLMs to convert natural language queries into Prolog code, and delegates reasoning to the external SWI-Prolog interpreter. This hybrid architecture combines the formal rigor of symbolic logic with the flexibility of LLMs, enabling precise, interpretable, and verifiable reasoning. Empirical evaluations demonstrate that LoRP significantly improves LLMs’ reasoning performance, particularly as inference depth increases. It also exhibits strong generalization and stability across various model architectures. These findings highlight the potential of symbolic-neural integration as a promising direction for advancing the logical reasoning capabilities of LLMs.},
  archive      = {J_KBS},
  author       = {Zhengkun Di and Chaoli Zhang and Hongtao Lv and Lizhen Cui and Lei Liu},
  doi          = {10.1016/j.knosys.2025.114140},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114140},
  shortjournal = {Knowl. Based Syst.},
  title        = {LoRP: LLM-based logical reasoning via prolog},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KMANet: A spatio-temporal enhancement network for micro-action recognition. <em>KBS</em>, <em>327</em>, 114139. (<a href='https://doi.org/10.1016/j.knosys.2025.114139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition technology has gained widespread application due to its ability to capture and process fine-grained motion details. Recent research has increasingly focused on analyzing individual emotions and intentions, bringing greater attention to micro-action recognition (MAR), which involves subtle and low-intensity movements. However, MAR faces several challenges, such as subtle variations in motion amplitude and highly similar visual features. These factors limit the effectiveness of traditional action recognition methods in achieving high detection accuracy. To address these limitations, we drew inspiration from the MAR benchmark MANet and focused on temporal feature modeling and effectively discriminative regions of micro-actions. Accordingly, we propose a two-stage MAR framework with a collaborative mechanism, termed KMANet, which adopts a two-stage spatiotemporal feature enhancement strategy. Specifically, in the temporal dimension, we design a Key Frame Attention Mechanism (KFAM) to automatically focus on key-frame sequences of micro-actions and capture inter-frame dynamic relationships, thereby reducing the interference of non-essential frames. This approach effectively addresses the issue of insignificant motion amplitude changes. The integration of the Micro-Action Focus Module (MAFM) on top of KFAM serves to further enhance local spatial features and reinforce detailed representation in core motion regions. The integration of these two modules achieves a substantial improvement in recognition accuracy at a minor computational expense. Extensive experimentation on the MAR dataset MA-52 and BBSI demonstrates that, in comparison to state-of-the-art methods, KMANet fulfills the requirements of fine-grained scenario detection and attains superior recognition accuracy and performance in micro-action recognition tasks.},
  archive      = {J_KBS},
  author       = {Jian Zhou and Jingchao Yao and Nan Su and Jingchen Lu and Qingyang Yu and Yichi Zhang and Wenqiang Hu},
  doi          = {10.1016/j.knosys.2025.114139},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114139},
  shortjournal = {Knowl. Based Syst.},
  title        = {KMANet: A spatio-temporal enhancement network for micro-action recognition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to utilize image second-order derivative information for crisp edge detection. <em>KBS</em>, <em>327</em>, 114138. (<a href='https://doi.org/10.1016/j.knosys.2025.114138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a fundamental task in computer vision. It has made great progress under the development of deep convolutional neural networks (DCNNs), some of which have achieved a beyond human-level performance. However, recent top-performing edge detection methods tend to generate thick and noisy edge lines. In this work, we solve this problem from two aspects: (1) the lack of prior knowledge regarding image edges, and (2) the issue of imbalanced pixel distribution. We propose a second-order derivative-based multi-scale contextual enhancement module (SDMCM) to help the model locate true edge pixels accurately by introducing the edge prior knowledge. We also construct a hybrid focal loss function (HFL) to alleviate the imbalanced distribution issue. In addition, we employ the conditionally parameterized convolution (CondConv) to develop a novel boundary refinement module (BRM), which can further refine the final output edge maps. In the end, we propose a U-shape network named LUS-Net which is based on the SDMCM and BRM for crisp edge detection. We perform extensive experiments on three standard benchmarks, and the experiment results illustrate that our method can predict crisp and clean edge maps and achieves state-of-the-art performance on the BSDS500 dataset (ODS=0.829), NYUD-V2 dataset (ODS=0.768), and BIPED dataset (ODS=0.903).},
  archive      = {J_KBS},
  author       = {Changsong Liu and Yimeng Fan and Mingyang Li and Wei Zhang and Yanyan Liu and Yuming Li and Wenlin Li and Liang Zhang},
  doi          = {10.1016/j.knosys.2025.114138},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114138},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to utilize image second-order derivative information for crisp edge detection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An early warning method for arrhythmias in long-term ECGs based on self-supervised learning and LSTM. <em>KBS</em>, <em>327</em>, 114137. (<a href='https://doi.org/10.1016/j.knosys.2025.114137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-term electrocardiogram (ECG) monitoring, the early warning of paroxysmal and acute arrhythmias is crucial for timely medical intervention, potentially preventing severe outcomes. Current studies face two primary challenges: accurately extracting ECG state features and effectively modeling state evolution before dangerous events, leading to suboptimal warning performance. This paper introduces a novel ECG warning method that employs self-supervised learning and long short-term memory (LSTM) networks to address these challenges. Initially, ECG state features are extracted using a self-supervised pre-training model. Then an LSTM-based warning model is employed to assess ECG state sequences, enhancing the understanding of transitional ECG states. We validate the warning method on two long-term ECG early warning tasks: paroxysmal atrial fibrillation (PAF) and ventricular fibrillation (VF). Our approach attains a 93.7 % accuracy with an 18.9 min average lead time for PAF using 30 min recordings, and a 98.6 % accuracy with a 2.9 min lead time for VF using 5 min recordings. This indicates our model's capacity to elucidate ECG state transitions preceding arrhythmias, showcasing its potential in personalized medicine and wearable healthcare solutions.},
  archive      = {J_KBS},
  author       = {Zhiyuan Li and Yuanyuan Tian and Yanrui Jin and Xiaoyang Wei and Mengxiao Wang and Jinlei Liu and Liqun Zhao and Chengliang Liu},
  doi          = {10.1016/j.knosys.2025.114137},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114137},
  shortjournal = {Knowl. Based Syst.},
  title        = {An early warning method for arrhythmias in long-term ECGs based on self-supervised learning and LSTM},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-driven multi-scale contextual alignment for robust E-nose drift compensation. <em>KBS</em>, <em>327</em>, 114136. (<a href='https://doi.org/10.1016/j.knosys.2025.114136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor drift poses a significant challenge to the performance and reliability of electronic noses (e-noses) in practical applications. To address this, we propose a Transformer-driven Multi-Scale Contextual Alignment (TMSCA) framework. TMSCA comprises three mutually reinforcing modules: (i) Cross-Domain Prior Attention, encoding source knowledge as a learnable prior to guide alignment even when target classes are missing; (ii) k-nearest-neighbor-constrained Local Maximum Mean Discrepancy, providing fine-grained distribution matching; and (iii) Approximate Low-Rank Canonical Correlation Analysis, preserving cross-domain correlations with sub-quadratic complexity. By synergistically leveraging these components, TMSCA systematically tackles the limitations of prior methods, such as incomplete target data adaptation, local distribution discrepancies, and prohibitive computational costs associated with deep models. Experimental results on two public e-nose datasets, under both long-term and short-term drift scenarios, demonstrate that TMSCA achieves strong and consistent performance in sensor drift compensation, suggesting potential improvements in e-nose accuracy and reliability.},
  archive      = {J_KBS},
  author       = {Jie Sun and Mengyang Dong and Fang Lu and Zheng Wang and Jie Zhu and Yintong Wang and Lingling Zheng and Fen Zhao},
  doi          = {10.1016/j.knosys.2025.114136},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114136},
  shortjournal = {Knowl. Based Syst.},
  title        = {Transformer-driven multi-scale contextual alignment for robust E-nose drift compensation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCAC: Causal discovery from low-dimensional small-scale time series. <em>KBS</em>, <em>327</em>, 114135. (<a href='https://doi.org/10.1016/j.knosys.2025.114135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery is pivotal in unraveling causal structures, deciphering underlying mechanisms, and explaining complex phenomena within time series. Current studies predominantly focus on estimating causal structures for high-dimensional and large-scale time series. For low-dimensional, small-scale time series, existing causal discovery methods still face challenges of underfitting and high computational complexity. To solve these challenges, we present an enhanced Pearson correlation coefficient framework, termed PCAC, tailored for causal structure discovery in low-dimensional, small-scale time series. The PCAC comprises three core components. First, a time-delay estimation module is incorporated to identify latent temporal lags in causal relationships across different dimensions, enabling the detection of delayed causal effects that could otherwise remain obscured. Second, a rolling window module is designed to capture dynamic changes and evolving trends within time series data, efficiently adapting to the non-stationary characteristics inherent in such datasets by continuously updating statistical estimates over sliding temporal segments. Finally, these two modules are seamlessly integrated into the PCAC framework to leverage their respective strengths synergistically. Experimental evaluations demonstrate that the proposed PCAC outperforms several state-of-the-art baselines, highlighting its efficacy in overcoming the challenges specific to low-dimensional small-scale time series analysis.},
  archive      = {J_KBS},
  author       = {Wei Sun and Yingjun Zhang and Jiang Liu and Baigen Cai},
  doi          = {10.1016/j.knosys.2025.114135},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114135},
  shortjournal = {Knowl. Based Syst.},
  title        = {PCAC: Causal discovery from low-dimensional small-scale time series},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GANFR: GAN fingerprint removal network for image anti-forensics. <em>KBS</em>, <em>327</em>, 114134. (<a href='https://doi.org/10.1016/j.knosys.2025.114134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GAN fingerprints are unique patterns generated by Generative Adversarial Networks (GANs) during image generation and have become the focus of advanced forensic methods. Effectively removing GAN fingerprints are critically important for enhancing anti-forensic capabilities. However, existing anti-forensic methods usually retain the upsampling-downsampling structure, typically employing end-to-end image reconstruction networks or adversarial attack models. This often fails to alter the subtle statistical characteristics embedded in images and therefore, cannot effectively remove GAN fingerprints. Additionally, their exclusive focus on modifications in the spatial domain poses significant challenges in maintaining image quality. In this paper, we propose a novel anti-forensic method called GAN Fingerprints Removal (GANFR), specifically designed to remove GAN fingerprints without compromising image quality. The generator in the proposed GANFR is based on the GCRS module, which consists of two key components: the feature decomposition network and the threshold learning network. The feature decomposition network extracts global contextual features, while the threshold learning network adaptively determines a threshold for each channel to reduce unrelated residuals, effectively removing GAN fingerprints while preserving image content. The discriminator in GANFR is a dual-domain network that integrates both spatial and frequency domains, guiding the generation of anti-forensic images. This dual-domain discriminator structure enhances the generation of high-quality anti-forensic images through adversarial training.},
  archive      = {J_KBS},
  author       = {Yihong Lu and Jianyi Liu and Ru Zhang},
  doi          = {10.1016/j.knosys.2025.114134},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114134},
  shortjournal = {Knowl. Based Syst.},
  title        = {GANFR: GAN fingerprint removal network for image anti-forensics},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled progressive negative sampling for graph collaborative filtering recommendation. <em>KBS</em>, <em>327</em>, 114133. (<a href='https://doi.org/10.1016/j.knosys.2025.114133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are widely applied in collaborative filtering (CF) recommendations, learning user and item representations from large-scale interaction data using negative sampling. However, existing negative sampling methods for graph-based CF face two limitations: (1) underutilization of feedback signals due to GNNs’ message-passing mechanisms, and (2) the false negative problem caused by fixed sampling distributions. Graph neural networks (GNNs) are widely utilized in collaborative filtering (CF) recommendations to learn user and item representations from large-scale interaction data using negative sampling. However, existing negative-sampling methods for graph-based CF face two limitations: (1) underutilization of feedback signals owing to the message-passing mechanisms of GNNs, and (2) the false-negative problem due to fixed sampling distributions. Therefore, we propose a novel framework, disentangled progressive negative sampling (DPNS), for graph-based CF. DPNS introduces flexible sampling distributions and disentangles positive and negative feedback by focusing on wider ranks during negative sampling to avoid feedback conflict in low-rank spaces. It comprises three phases: (1) disentangling low- and wider-rank eigenvalue spaces via semantic contrastive learning and applying a wide-rank-aware sampling strategy to guide negative feedback into the wider-rank space, (2) generating synthetic hard negatives to optimize positive feedback in the low-rank space, and (3) integrating an adaptive gradient-reversal technique with Bayesian personalized ranking loss to reduce false negatives. Experiments on three real-world datasets demonstrated significant performance gains. For example, on the Amazon Patio dataset with LightGCN, DPNS improved recall (+24.4 %), NDCG (+18.9 %), and hit ratio (+20 %), evidencing its effectiveness in enhancing graph-based CF models. The code is available at https://github.com/wayneHallway/DPNS .},
  archive      = {J_KBS},
  author       = {Hewei Li and Xin Zhang and He Weng and Yingjie Shen and Kangkai Cai and Dongjing Wang and Zhen Qin and Shuiguang Deng},
  doi          = {10.1016/j.knosys.2025.114133},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114133},
  shortjournal = {Knowl. Based Syst.},
  title        = {Disentangled progressive negative sampling for graph collaborative filtering recommendation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual variational graph contrastive learning for social recommendation. <em>KBS</em>, <em>327</em>, 114132. (<a href='https://doi.org/10.1016/j.knosys.2025.114132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging paradigm that merges collaborative filtering with social networking, social recommender systems endeavor to integrate additional social relationships to mitigate data sparsity issues. However, the available social data for training often remain sparse and contain noise. To tackle this, recent studies have leveraged contrastive learning methods to derive extra self-supervised signals. Despite the potential, existing approaches are limited by the cumbersome selection of augmentations and the ambiguous definition of positive pairs. To overcome these limitations, we propose an innovative framework, dual variational graph contrastive learning (DVGCL), tailored for social recommendation. Specifically, we utilize a dual variational graph autoencoder as view generator, which captures variational distributions of user preferences to exploit more underlying collaborative information during graph reconstruction. Additionally, we implement a socially aware light graph convolution network as our backbone to obtain contextual embeddings. Finally, we develop a contrastive loss function based on diverse positive instances to refine the learning of robust representations. By integrating social friends and interacted neighbors, DVGCL provides auxiliary training signals for collaborative filtering-based recommendation tasks. Extensive evaluations across three real-world datasets demonstrate that DVGCL surpasses numerous cutting-edge recommendation methods.},
  archive      = {J_KBS},
  author       = {Yifan Wang and Fei Xiong and Zhiyuan Zhang and Shirui Pan and Liang Wang and Hongshu Chen},
  doi          = {10.1016/j.knosys.2025.114132},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114132},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual variational graph contrastive learning for social recommendation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-GCC: Global classifier consensus for conventional/task-free federated class-incremental learning. <em>KBS</em>, <em>327</em>, 114131. (<a href='https://doi.org/10.1016/j.knosys.2025.114131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Class-Incremental Learning (FCIL) merges continual learning with federated learning to incrementally accommodate new classes. However, a significant limitation of existing methods is their reliance on predefined task information which requires all participants to collaboratively agree on beforehand. This assumption is overly idealized, as the process of clients learning new knowledge does not proceed according to the pre-specified task information, and the task information regarding the timing and content of the clients’ learning is also unpredictable. To address this limitation, we introduce a more realistic FCIL scenario called Task-Free Federated Class-Incremental Learning (TF-FCIL), without the need for prior knowledge of tasks. To tackle the TF-FCIL problem, we propose the () (Fed-GCC) approach, which constructs a unified classifier, ensuring that all clients engage in local model learning consistently with this classifier consensus. This enables seamless adaptation to new classes on any client. Additionally, we introduce a quantity balancing loss to address data quantity imbalances and a quality balancing loss to tackle quality imbalances. These mechanisms effectively mitigate issues related to class imbalance and catastrophic forgetting, enhancing overall model stability and performance. The proposed method is applicable to both conventional and Task-Free settings. Extensive experiments demonstrate that Fed-GCC significantly outperforms existing alternatives in both settings, achieving performance gains of up to 10.7 % in scenarios characterized by limited memory and severe Non-IID data.},
  archive      = {J_KBS},
  author       = {Dianqi Liu and Liang Bai and Yanming Guo and Jun Tang and Yirun Ruan and Da Li and Tianyuan Yu},
  doi          = {10.1016/j.knosys.2025.114131},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114131},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fed-GCC: Global classifier consensus for conventional/task-free federated class-incremental learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mamba-advanced unsupervised cross-modality medical image segmentation via domain adaptation and task decomposition. <em>KBS</em>, <em>327</em>, 114130. (<a href='https://doi.org/10.1016/j.knosys.2025.114130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation (MIS) is pivotal for smart healthcare systems. Since medical diagnosis often requires multi-type and multi-period image data, unsupervised cross-modality unpaired image segmentation has emerged as a challenging task. However, mixed modalities and structural discrepancies in unpaired images pose significant challenges. In this paper, we try to break down the difficult task into two relatively simple tasks. Specifically, we generate a bridging image by using a translation network with structural preservation capability from the labeled source domain image. And thus, this bridging image inherits the structural characteristics and label information of the source domain image. Then, this bridging image is separately combined with the source domain image and the target domain image to form two sets of images, which are used to train segmentation networks with shared parameters. Thanks to task decomposition, these two segmentation networks will undergo supervised cross-modality training and semi-supervised mono-modality training respectively, which is more conducive to improving segmentation accuracy. Meanwhile, a Domain-Specific Layer Normalization (DSLN) module is equipped to the segmentation network to ensure the training balance between two sets of training data. Finally, a Mamba-advanced framework with Multi-scale Detail Supplement (MSDS) module has been designed for extracting segmentation features. We extensively evaluate our proposed framework on bidirectional cross-domain tasks, including cardiac substructure segmentation and abdominal multi-organ segmentation between MRI and CT images. Experimental results demonstrate that our proposed framework sets a new benchmark in segmentation performance on unlabeled target images, outperforming state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Haoran Feng and Danyang Peng and Jun Wu and Yong Zhang and Feidan Kou and Yuanyuan Li and Gangming Zhao and Xiaohu Li and Lei Qu},
  doi          = {10.1016/j.knosys.2025.114130},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114130},
  shortjournal = {Knowl. Based Syst.},
  title        = {A mamba-advanced unsupervised cross-modality medical image segmentation via domain adaptation and task decomposition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CELAN: An efficient layer aggregation network based on the attention mechanism and large-kernel architecture for small-object detection tasks. <em>KBS</em>, <em>327</em>, 114129. (<a href='https://doi.org/10.1016/j.knosys.2025.114129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in specialized fields—such as industrial inspection, autonomous driving, and remote sensing—presents significantly greater challenges than in general scenarios, particularly when detecting small targets in complex and cluttered environments. These scenarios often involve challenges such as low resolution, occlusion, scale variation, and class imbalance, all of which can significantly degrade the performance of conventional detection models. To effectively improve the detection performance of small objects in complex environments, we propose the information-coordinated fusion attention mechanism (ICFAM), which extracts features from multiple spatial directions and effectively preserves the essential positional information of targets. Building on this, we incorporate an inverted bottleneck structure and depthwise separable convolutions to develop the large-kernel correlation module (LKCM). This module incorporates ICFAM, which capitalizes on the synergy between expansive receptive fields and attention mechanisms. Furthermore, we design an efficient multi-branch network architecture known as the coordinative efficient layer aggregation network (CELAN). This architecture replaces traditional stacked convolutions with depthwise separable convolutions, thereby reducing computational load. It also introduces an independent pathway that integrates with LKCM, ensuring noninterfering computation and enabling deeper computational blocks to extract richer, multi-level semantic information. Using CELAN as the core module and the YOLOv9 framework, we develop a novel object detector YOLO-CELAN. Extensive testing on two public datasets substantiates the effectiveness of the proposed modules. This work demonstrates that the YOLO-CELAN series (N/S/M/L) significantly improves mAP50 by 1.2 %, 2.9 %, 1.9 %, and 2.3 %, respectively, compared to the YOLOv9 models (S, M, C, and E).},
  archive      = {J_KBS},
  author       = {Zhoutian Xu and Yadong Xu and Mingming Wang and Liuxuan Wei and Junhua Chen and Manyi Wang},
  doi          = {10.1016/j.knosys.2025.114129},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114129},
  shortjournal = {Knowl. Based Syst.},
  title        = {CELAN: An efficient layer aggregation network based on the attention mechanism and large-kernel architecture for small-object detection tasks},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open world out-of-distribution generalization via dream open and sustain close. <em>KBS</em>, <em>327</em>, 114128. (<a href='https://doi.org/10.1016/j.knosys.2025.114128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models often suffer from the inability to obtain large-scale or high-quality target domain data. A subset of domain generalization (DG), based on augmentation techniques, aims to utilize source domain data to expand the feature range. In the era where diffusion models are prevalent, generative-based DG methods have not yet flourished. The reasons include the domain gap that is hard to bridge between real-world and synthetic images and the samples of unknown categories in the open world. For this, we propose a novel “Dream Open and Sustain Close” (DoSc) framework for Open Generative-based Domain Generalization (OGDG) based on diffusion models. We address three emerging challenges: 1) How to inject class and domain awareness into a generative model using only known-class samples from the source domain, and enable the model to reasonably generate potential unseen classes, i.e. , Dream Open. 2) How to utilize generated samples to adapt the model to unknown environments to safely deploy it, i.e. , Sustain Close. Specifically, we use the Early Branch structure to extract domain and class variables from samples, enabling diffusion models to have multi-perspective semantic awareness as auxiliary conditions. At the hidden space level, we decouple domain and class factors using frequency in the middle layers. We generate unknown class samples conforming to the correct distribution through semantic and spatial interactions. Finally, we compress the source’s known class embedding space to refine the decision boundaries between known and unknown.},
  archive      = {J_KBS},
  author       = {Kunze Huang and Luyao Tang and Yuxuan Yuan and Jieyuan Yang and Xiaotong Tu and Yue Huang and Xinghao Ding},
  doi          = {10.1016/j.knosys.2025.114128},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114128},
  shortjournal = {Knowl. Based Syst.},
  title        = {Open world out-of-distribution generalization via dream open and sustain close},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HA-U3Net: A modality-agnostic framework for 3D medical image segmentation using nested V-net structure and hybrid attention. <em>KBS</em>, <em>327</em>, 114127. (<a href='https://doi.org/10.1016/j.knosys.2025.114127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D medical image segmentation is essential for disease diagnosis and treatment planning across a wide range of imaging modalities (e.g., MRI, CT, ultrasound, and PET). However, modality-specific challenges, such as noise, artifacts, low contrast, and anatomical variability, along with the presence of small lesions and fuzzy boundaries, hinder the generalization capability of existing segmentation models. In this work, we present HA-U 3 Net, a novel 3D U-Net-based model designed to address these limitations through a stepwise approach. First, we introduce a deeply nested U 3 -shaped structure built upon 3D V-Net modules, enabling multi-scale hierarchical representation learning. Second, we integrate a hybrid attention mechanism combining spatial and channel-wise attention to enhance salient features extraction and the delineation of small or poorly defined structures. Third, we demonstrate the cross-modality generalization capabilities of HA-U 3 Net through extensive evaluations on several datasets, where our model consistently outperforms baseline methods. Finally, we propose a lightweight variant, U 3 Mamba, reducing computational complexity while maintaining high performance.},
  archive      = {J_KBS},
  author       = {Mohamed Lamine Allaoui and Mohand Saïd Allili and Ahror Belaid},
  doi          = {10.1016/j.knosys.2025.114127},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114127},
  shortjournal = {Knowl. Based Syst.},
  title        = {HA-U3Net: A modality-agnostic framework for 3D medical image segmentation using nested V-net structure and hybrid attention},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFCMS-net: Adaptive feature coupling and multi-level supervision network for effective image forgery localization. <em>KBS</em>, <em>327</em>, 114126. (<a href='https://doi.org/10.1016/j.knosys.2025.114126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of forged images on the internet, the development of effective methods for localizing image forgery has become a research topic of increasing interest. Although deep learning-based models have generally demonstrated good performance, most focus only on Convolutional Neural Network (CNN)-based local information and ignore feature purification. This leads to feature redundancy and a lack of global context, resulting in inaccurate localization of tampered regions. In addition, they often overlook the importance of modeling the correlations between tampered and real regions in an image; thus, the extracted features lack discrimination. To address these challenges, we propose a novel method for improving the localization accuracy of multi-scale tampered regions by fusing multi-scale local and global critical correlations and enhancing feature discrimination. First, we use a multi-level Transformer to establish long-range dependencies between different regions in the images. This global information extraction capability contributes to a more comprehensive localization of tampered regions in an image. Second, we designed an Adaptive Selection and Interaction Aggregation (ASIA) module, which adaptively aggregates multi-level features and captures multi-scale hierarchical dependencies. This can enhance the representation of critical information and improve the accuracy of multi-scale tampered region localization. Third, the proposed Cross-domain Coupling Guide Refinement (CCGR) module can achieve complementary fusion and correlation enhancement of the local features and global representations based on the importance of different information. This fusion mechanism allows the model to consider both local details and global structure when locating tampered regions, which helps to improve localization accuracy and stability. Furthermore, we propose a multi-level intermediate supervision mechanism to compare the similarities and differences between tampered and real regions in forged images at multi-level features. It can learn more discriminative representations, thereby effectively enhancing the robustness of the model. Comprehensive experiments demonstrate that the proposed method has superior performance compared to most advanced techniques. It exhibits remarkable performance in localizing multi-scale tampered regions, even for post-processing and Online Social Network (OSN) attack images. The code of our proposed method can be available at https://github.com/SwallowIsXYZ/0617_AFCMS-Net},
  archive      = {J_KBS},
  author       = {Yanzhi Xu and Jinchang Ren and Aiqing Fang and Muhammad Irfan and Jiangbin Zheng},
  doi          = {10.1016/j.knosys.2025.114126},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114126},
  shortjournal = {Knowl. Based Syst.},
  title        = {AFCMS-net: Adaptive feature coupling and multi-level supervision network for effective image forgery localization},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanism-empowered multivariate time series forecasting model: Application to tuberculosis prediction. <em>KBS</em>, <em>327</em>, 114124. (<a href='https://doi.org/10.1016/j.knosys.2025.114124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuberculosis, a highly contagious chronic disease, remains a major global public health concern. Despite medical progress, current methods struggle with new challenges, including systematic and effective downscaling, accurate prediction of disease incidence, and implementation of source reduction measures, all of which have added to the difficulty of tuberculosis control. Given the limitations of the recently proposed eight models in predictive accuracy, this study employs a Learnable Decomposition and Dual Focus Module Model and then introduces a novel mechanism-supported multivariate spatiotemporal series framework, to address the challenges in tuberculosis prediction through an investigation of coal power generation in China. This framework substantially simplifies the complexity of tuberculosis prediction, enables more accurate dimensionality reduction, and improves traceability. It also enhances the interpretability power and accuracy of the model, applied in this study, in tuberculosis prediction. On the test set, the proposed framework achieved an R² of 0.906, an MSE of 0.079, and an MAE of 0.160, whereas the lowest baseline scores were an R² of -4397.777, an MSE of 0.177, and an MAE of 0.227 for DLinear. This study provides a novel perspective for enhancing epidemic forecasting, exploring source reduction measures for industrial activities, and demonstrating the feasibility of AI-assisted public health strategies and green production.},
  archive      = {J_KBS},
  author       = {Danyu Li},
  doi          = {10.1016/j.knosys.2025.114124},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114124},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mechanism-empowered multivariate time series forecasting model: Application to tuberculosis prediction},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using bayesian model averaging. <em>KBS</em>, <em>327</em>, 114123. (<a href='https://doi.org/10.1016/j.knosys.2025.114123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-time augmentation (TTA) is a well-known technique employed during the testing phase of computer vision tasks. It involves aggregating multiple augmented versions of input data. Combining predictions using a simple average formulation is a common and straightforward approach after performing TTA. This paper introduces a novel framework for optimizing TTA, called BayTTA (Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First, we generate a prediction list associated with different variations of the input data created through TTA. Then, we use BMA to combine predictions weighted by the respective posterior probabilities. Such an approach allows one to take into account model uncertainty, and thus to enhance the predictive performance of the related machine learning or deep learning model. We evaluate the performance of BayTTA on various public data, including three medical image datasets comprising skin cancer, breast cancer, and chest X-ray images and two well-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental results indicate that BayTTA can be effectively integrated into state-of-the-art deep learning models used in medical image analysis as well as into some popular pre-trained CNN models such as VGG-16, MobileNetV2, DenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in their accuracy and robustness performance. The source code of the proposed BayTTA method is freely available at: https://github.com/Z-Sherkat/BayTTA .},
  archive      = {J_KBS},
  author       = {Zeinab Sherkatghanad and Moloud Abdar and Mohammadreza Bakhtyari and Paweł Pławiak and Vladimir Makarenkov},
  doi          = {10.1016/j.knosys.2025.114123},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114123},
  shortjournal = {Knowl. Based Syst.},
  title        = {BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using bayesian model averaging},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M2-net: Multi-view learning multi-scale fusion network for image tampering detection. <em>KBS</em>, <em>327</em>, 114122. (<a href='https://doi.org/10.1016/j.knosys.2025.114122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As image tampering techniques become increasingly sophisticated and covert, accurately localizing tampered regions becomes a key challenge in digital image forensics. Existing deep learning-based methods often show limited robustness and high false detection rates when dealing with complex operations such as JPEG compression, online social network compression, and Gaussian blur. To address these limitations, a novel deep learning network model, M2-Net, is proposed. The model incorporates a multi-view feature learning mechanism, which combines tampering boundary information and image noise features to achieve pixel-level clue capture across multiple scales and channels. Additionally, a multi-scale feature fusion mechanism is designed to integrate global context from low-scale features with local details from high-scale features, thereby enhancing the model’s ability to comprehend image-level clues. To target low-quality image scenarios, an enhanced version, M2-Net++, is further developed. Both versions demonstrate exceptional performance in experiments conducted across multiple large-scale datasets and cross-dataset scenarios. A comprehensive evaluation is conducted to compare 16 mainstream detection models across 10 datasets. Results show that our model ranks among the top in the composite F1 metric on 7 out of 8 test sets. Even under the complex post-processing challenges of Online Social Networks, it remains robust and demonstrates superior generalization with only 107 GFLOPs of computational cost.},
  archive      = {J_KBS},
  author       = {Yanling Chen and Chenglong Mi and Jingyi Wei and Yuanjiao Zhu and Jie Zhou},
  doi          = {10.1016/j.knosys.2025.114122},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114122},
  shortjournal = {Knowl. Based Syst.},
  title        = {M2-net: Multi-view learning multi-scale fusion network for image tampering detection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous multiviews-based efficient graph contrastive learning model for short text classification. <em>KBS</em>, <em>327</em>, 114121. (<a href='https://doi.org/10.1016/j.knosys.2025.114121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short Text Classification (STC) is widely applied in various industrial scenarios. However, the limited semantic content of short texts and the scarcity of labeled data hinder accurate and efficient classification in practice. Recent studies have demonstrated the effectiveness of graph contrastive learning for text classification. Nevertheless, integrating external corpora to enrich semantics often introduces noise, and graph feature compression can further degrade the original semantic information–both of which negatively affect classification accuracy and robustness. To address these issues, we propose a novel Heterogeneous multiviews-based Efficient Graph Contrastive Learning model (HEGCL) for STC. First, we construct heterogeneous graphs from multiple information sources at the word, entity, and tag levels, preserving original semantics while mitigating external noise. Then, we generate enhanced feature views using a two-layer Graph Convolutional Network (GCN) and a main-term (MD) matrix derived from the original text, capturing diverse semantic aspects and alleviating information loss during feature compression. Finally, we perform multiview contrastive learning using three modules of GECL, NDCL, and CCL to improve representation learning. Extensive experiments on six real-world datasets demonstrate that HEGCL outperforms state-of-the-art (SOTA) methods in both classification accuracy and model robustness on STC tasks. Our code can be found in https://github.com/zkq454/HEGCL .},
  archive      = {J_KBS},
  author       = {Kangqi Zhang and Xiaoyang Liu and Jiawei Zhang and Lin Gan and Giacomo Fiumara and Pasquale De Meo},
  doi          = {10.1016/j.knosys.2025.114121},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114121},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous multiviews-based efficient graph contrastive learning model for short text classification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming imbalanced safety data using extended accident triangle. <em>KBS</em>, <em>327</em>, 114120. (<a href='https://doi.org/10.1016/j.knosys.2025.114120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing interest in using safety analytics and machine learning to support the prevention of workplace incidents, especially in high-risk industries like construction and trucking. Although existing safety analytics studies have made remarkable progress, they suffer from imbalanced datasets, a common problem in safety analytics, resulting in prediction inaccuracies. This can lead to practical problems, e.g., incorrect resource allocation and improper interventions. To overcome the imbalanced data problem, we extend the theory of accident triangle to claim that the importance of data samples should be based on characteristics such as injury severity, accident frequency, and accident type. Thus, three oversampling methods are proposed based on assigning different weights to samples in the minority class. We find robust improvements among different machine/deep learning algorithms. For the lack of open-source safety datasets, we are sharing three imbalanced datasets, e.g., a 9-year nationwide construction accident record dataset, an accident and safety management dataset, and a US truck driver safety climate survey dataset, and their corresponding source codes.},
  archive      = {J_KBS},
  author       = {Kailai Sun and Tianxiang Lan and Yang Miang Goh and Yueng-Hsiang Huang},
  doi          = {10.1016/j.knosys.2025.114120},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114120},
  shortjournal = {Knowl. Based Syst.},
  title        = {Overcoming imbalanced safety data using extended accident triangle},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q2HO-MFTV: A binary hippopotamus optimization algorithm for feature selection with a brief review of binary optimization. <em>KBS</em>, <em>327</em>, 114119. (<a href='https://doi.org/10.1016/j.knosys.2025.114119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial step for enhancing classification accuracy and reducing computational complexity, especially in high-dimensional datasets. Although metaheuristic algorithms have been successful in continuous optimization, their binary counterparts often suffer from premature convergence and limited exploration. To overcome these challenges, we introduce the Quantum Q-Learning Hippopotamus Optimizer with Fuzzy Time-Varying Transfer Functions (Q2HO-MFTV), a novel binary variant of the Hippopotamus Optimization Algorithm, which is binarized through the integration of Fuzzy Time-Varying transfer functions (FTVs). This method leverages FTVs for smooth state transitions, incorporates a quantum-inspired chaotic initialization to boost population diversity, and employs a Q-learning mechanism to dynamically balance exploration and exploitation. We evaluated Q2HO-MFTV on 41 benchmark datasets from diverse domains, including text, image, and biomedical, with up to 22,283 features. The algorithm consistently outperformed 14 state-of-the-art methods such as Binary Marine Predator Algorithm (BMPA-TVSinV), Binary Grey Wolf Optimizer (BGWO), and Binary Salp Swarm Algorithm (BSSA). Q2HO-MFTV achieved 98.56 % accuracy on the BreastCancer dataset with 43 % feature selection, 99.26 % on COVID-19 II with just 10.63 %, and 100 % on Colon with only 0.10 %. It also recorded the lowest fitness values (e.g., 0.0151 on KrvskpEW), ranked first in the Friedman test (mean rank = 1.2976), and showed an average speed-up of 22 %, saving over 500 s on large problems. These results demonstrate that Q2HO-MFTV is a robust, scalable, and efficient solution for feature selection in classification tasks.},
  archive      = {J_KBS},
  author       = {Nastaran Mehrabi Hashjin and Mohammad Hussein Amiri and Amin Beheshti and Maryam Khanian Najafabadi},
  doi          = {10.1016/j.knosys.2025.114119},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114119},
  shortjournal = {Knowl. Based Syst.},
  title        = {Q2HO-MFTV: A binary hippopotamus optimization algorithm for feature selection with a brief review of binary optimization},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Playing to spot the difference: Enhancing HDR imaging with dual-task synergy and multi-perspective consensus learning. <em>KBS</em>, <em>327</em>, 114118. (<a href='https://doi.org/10.1016/j.knosys.2025.114118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of High Dynamic Range (HDR) imaging, a prevalent approach is to reconstruct HDR image from multiple Low Dynamic Range (LDR) exposures. However, this method encounters significant challenges, particularly in dynamic scenes where ghosting artifacts often emerge, and their effective identification and mitigation remain elusive. Drawing inspiration from the multiplayer game of ‘Spot the Difference’, this paper presents a Dual-Task Synergy and Multi-Perspective Consensus Learning (DTS-MPCL) framework, tailored to effectively mitigate the impact of ghosting on HDR reconstruction. This innovative framework leverages the synergy between dual tasks and insights from MPCL to address the ghosting issue. DTS synergizes single-image HDR reconstruction with multi-exposure HDR reconstruction processes, achieving the reconstruction of three HDR images. Alongside the ground truth (GT), we establish a group of observers simulating participants in a ‘Spot the Difference’ game, which aids in identifying discrepancies between the reconstructed image and the GT from various perspectives. MPCL utilizes these observers’ insights to attentively examine the differences, directing the model towards producing HDR images that closely mirror the GT. This strategy significantly enhances the model’s ability to generate HDR image virtually indistinguishable from the GT. Comparative experiments conducted across several widely recognized benchmarks demonstrate that our method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations. The source code of the proposed method is available at https://github.com/luo-jc/DTS-MPCL .},
  archive      = {J_KBS},
  author       = {Yafei Zhang and Juncheng Luo and Huafeng Li and Qing Cai},
  doi          = {10.1016/j.knosys.2025.114118},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114118},
  shortjournal = {Knowl. Based Syst.},
  title        = {Playing to spot the difference: Enhancing HDR imaging with dual-task synergy and multi-perspective consensus learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoSTI: Consistency models for (a faster) spatio-temporal imputation. <em>KBS</em>, <em>327</em>, 114117. (<a href='https://doi.org/10.1016/j.knosys.2025.114117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series Imputation (MTSI) is crucial for many applications, such as healthcare monitoring and traffic management, where incomplete data can compromise decision-making. Existing state-of-the-art methods, like Denoising Diffusion Probabilistic Models (DDPMs), achieve high imputation accuracy; however, they suffer from significant computational costs and are notably time-consuming due to their iterative nature. In this work, we propose CoSTI, an innovative adaptation of Consistency Models (CMs) for the MTSI domain. CoSTI employs Consistency Training to achieve comparable imputation quality to DDPMs while drastically reducing inference times, making it more suitable for real-time applications. We evaluate CoSTI across multiple datasets and missing data scenarios, demonstrating up to a 98 % reduction in imputation time with performance on par with diffusion-based models. This work bridges the gap between efficiency and accuracy in generative imputation tasks, providing a scalable solution for handling missing data in critical spatio-temporal systems. The code for this project can be found here: https://github.com/javiersgjavi/CoSTI .},
  archive      = {J_KBS},
  author       = {Javier Solís-García and Belén Vega-Márquez and Juan A. Nepomuceno and Isabel A. Nepomuceno-Chamorro},
  doi          = {10.1016/j.knosys.2025.114117},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114117},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoSTI: Consistency models for (a faster) spatio-temporal imputation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seeded poisson factorization: Leveraging domain knowledge to fit topic models. <em>KBS</em>, <em>327</em>, 114116. (<a href='https://doi.org/10.1016/j.knosys.2025.114116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models are widely used for discovering latent thematic structures in large text corpora, yet traditional unsupervised methods often struggle to align with pre-defined conceptual domains. This paper introduces seeded Poisson factorization (SPF), a novel approach that extends the Poisson factorization (PF) framework by incorporating domain knowledge through seed words. SPF enables a structured topic discovery by modifying the prior distribution of topic-specific term intensities, assigning higher initial rates to pre-defined seed words. The model is estimated using variational inference with stochastic gradient optimization, ensuring scalability to large datasets. We present in detail the results of applying SPF to an Amazon customer feedback dataset, leveraging pre-defined product categories as guiding structures. SPF achieves superior performance compared to alternative guided probabilistic topic models in terms of computational efficiency and classification performance. Robustness checks highlight SPF’s ability to adaptively balance domain knowledge and data-driven topic discovery, even in case of imperfect seed word selection. Further applications of SPF to four additional benchmark datasets, where the corpus varies in size and the number of topics differs, demonstrate its general superior classification performance compared to the unseeded PF model.},
  archive      = {J_KBS},
  author       = {Bernd Prostmaier and Jan Vávra and Bettina Grün and Paul Hofmarcher},
  doi          = {10.1016/j.knosys.2025.114116},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114116},
  shortjournal = {Knowl. Based Syst.},
  title        = {Seeded poisson factorization: Leveraging domain knowledge to fit topic models},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal isomorphic cross-brain region interaction network for cross-subject EEG emotion recognition. <em>KBS</em>, <em>327</em>, 114115. (<a href='https://doi.org/10.1016/j.knosys.2025.114115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) has high temporal resolution and low cost and has become one of the important tools for emotion recognition in human-computer interaction. The intricate architecture and functioning of the brain, along with substantial individual variances among participants, and existing methods are difficult to simultaneously model the temporal and spatial consistency of brain area interactions and EEG signals between subjects, which limits the generalization performance of the model in cross-subject contexts. To meet this challenge, we propose a cross-subject EEG emotion recognition model based on a spatiotemporal isomorphic cross-brain region interaction network (STCBI-Nets). In this model, we first designed the cross-brain region interaction module (CBI), which dynamically models the interaction relationship between different brain regions through a multi-head cross-attention mechanism, captures heterogeneous information flow between local brain regions, enhances the long-range dependency modeling ability of EEG time series, and effectively integrates the collaborative activation mode of the whole brain. Secondly, we design a spatiotemporal isomorphic adaptive fusion (STIAF) block, which adopts a dual branch structure to mine hierarchical and complementary information of spatiotemporal features and introduces a negative sample weighted contrastive learning mechanism and dynamic fusion strategy to improve the robustness and discriminative power of cross-view shared representations, thereby enhancing the model's adaptability to different subject features. Finally, we propose a joint optimized adaptive domain alignment strategy (JOADAS), which combines global adversarial learning with an adaptive class center alignment mechanism to reduce domain bias between different subjects from both macro and micro levels, enhance intra-class aggregation and inter-class separability, and improve the model's discriminative performance and cross-subject generalization ability. Extensive experiments on multiple datasets demonstrated the superior performance of the proposed algorithm, and STCBI-Nets outperform state-of-the-art (SOTA) methods and exhibit stronger generalization ability and stability in cross-subject EEG emotion recognition tasks.},
  archive      = {J_KBS},
  author       = {Yanling An and Shaohai Hu and Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yudong Zhang},
  doi          = {10.1016/j.knosys.2025.114115},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114115},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatiotemporal isomorphic cross-brain region interaction network for cross-subject EEG emotion recognition},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic warping as a sensor reconstruction method for remaining useful life estimation. <em>KBS</em>, <em>327</em>, 114114. (<a href='https://doi.org/10.1016/j.knosys.2025.114114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes Dynamic Warping (DW) as a sensor reconstruction method for Remaining Useful Life (RUL) estimation. The method utilizes the DW model for sensor reconstruction, where Median Absolute Deviation measures the reconstruction error, which is expected to increase when abnormal system behavior is measured. We apply an exponential model to the reconstruction error to estimate a system’s RUL. The DW model is based on the Dynamic Time Warping algorithm applied to a non-temporal context. The concept is to preprocess sensor data into a non-temporal motion profile representing a cycle. We validate our proposed DW model with two baseline models: Singular Value Decomposition (SVD) and LSTM Autoencoder (LSTM-AE). The SVD model is applied to the non-temporal motion profile, while the LSTM-AE model is applied to the original sensor data. A case study was conducted at a semiconductor Original Equipment Manufacturer, whose dataset contained information on a bearing failure in a water-cooled direct drive rotary motor. The failure occurred due to increased friction caused by bearing wear. The valuable motion control signal found was torque applied to the shaft for the R and S phases. It was demonstrated that the proposed method is most efficient, and an alarm can be raised 11 hours before failure, after which the RUL can be estimated, which is promising for warning service engineers for this industrial application. This research shows that the DW model could predict maintenance furthest in advance while only needing a fraction of the training data.},
  archive      = {J_KBS},
  author       = {Raymon Van Dinter and Ke Cao and Philippe Leduc and Bedir Tekinerdogan and Cagatay Catal and Yiping Sun},
  doi          = {10.1016/j.knosys.2025.114114},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114114},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic warping as a sensor reconstruction method for remaining useful life estimation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on domain adaptation for intelligent fault diagnosis. <em>KBS</em>, <em>327</em>, 114109. (<a href='https://doi.org/10.1016/j.knosys.2025.114109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based intelligent fault diagnosis methods have typically been developed under the assumption that an abundant and diverse set of training samples and labels is available. Thus, it is crucial to develop models capable of generalizing effectively to distributions characterized by limited samples and insufficient labels. The transfer of knowledge from semantically related but distributionally different source domains has been recognized as an effective approach; however, discrepancies between distributions may result in negative transfer issues. Domain adaptation (DA), as a prominent research area within transfer learning, has been extensively studied to enhance generalization performance on target tasks. In this survey, the various concepts, formulations, algorithms, and applications of DA in industrial fault diagnosis are thoroughly reviewed. Broader DA solutions are covered, including (a) metric learning, adversarial adaptation, reconstruction, and generation within a homogeneous setting, and (b) source-free domain adaptation, domain generalization, partial domain adaptation, open-set domain adaptation, and universal domain adaptation within a heterogeneous setting, all of which extend beyond the traditional divisions of semi-supervised and unsupervised learning. This survey allows researchers to quickly and comprehensively grasp the research foundation, current status, theoretical limitations, and under-explored directions in the field, thereby facilitating the achievement of universally applicable methods in diverse industrial scenarios.},
  archive      = {J_KBS},
  author       = {Chuang Wang and Zidong Wang and Qingqiang Liu and Hongli Dong and Weibo Liu and Xiaohui Liu},
  doi          = {10.1016/j.knosys.2025.114109},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114109},
  shortjournal = {Knowl. Based Syst.},
  title        = {A comprehensive survey on domain adaptation for intelligent fault diagnosis},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving open set recognition with dissimilarity-based metric learning. <em>KBS</em>, <em>327</em>, 114108. (<a href='https://doi.org/10.1016/j.knosys.2025.114108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open set recognition addresses the problem of classifying instances where the model must not only recognize and classify examples from known classes, but also handle unknown classes not present in the training set. Unlike traditional classifiers, which assume only samples from known classes appear during testing, OSR must detect and manage instances beyond the scope of the training classes. In this paper, we propose a novel approach that combines dissimilarity-based representation with task-specific metric learning in an end-to-end framework. Dissimilarity representation is an alternative to the traditional feature space representation that represents samples based on their differences. By adaptively learning a dissimilarity function specific to the task, our method improves the ability to distinguish between known and unknown classes. We evaluate the proposed method using two popular representation learning techniques, triplet loss and contrastive loss, across multiple experiments: standard OSR benchmarks (CIFAR-10 and SVHN), class-scaling scenarios (DTD and FMD), and the Semantic Shift Benchmark; our proposal consistently outperforms baseline models in both closed-set accuracy and open-set detection.},
  archive      = {J_KBS},
  author       = {Lucas O. Teixeira and Diego Bertolini and Luiz S. Oliveira and George D.C. Cavalcanti and Yandre M.G. Costa},
  doi          = {10.1016/j.knosys.2025.114108},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114108},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving open set recognition with dissimilarity-based metric learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient RGB-D scene understanding via multi-task adaptive learning and cross-dimensional feature guidance. <em>KBS</em>, <em>327</em>, 114107. (<a href='https://doi.org/10.1016/j.knosys.2025.114107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene understanding plays a critical role in enabling intelligence and autonomy in robotic systems. Traditional approaches often face challenges, including occlusions, ambiguous boundaries, and the inability to adapt attention based on task-specific requirements and sample variations. To address these limitations, this paper presents an efficient RGB-D scene understanding model that performs a range of tasks, including semantic segmentation, instance segmentation, orientation estimation, panoptic segmentation, and scene classification. The proposed model incorporates an enhanced fusion encoder, which effectively leverages redundant information from both RGB and depth inputs. For semantic segmentation, we introduce normalized focus channel layers and a context feature interaction layer, designed to mitigate issues such as shallow feature misguidance and insufficient local-global feature representation. The instance segmentation task benefits from a non-bottleneck 1D structure, which achieves superior contour representation with fewer parameters. Additionally, we propose a multi-task adaptive loss function that dynamically adjusts the learning strategy for different tasks based on scene variations. Extensive experiments on the NYUv2, SUN RGB-D, and Cityscapes datasets demonstrate that our approach outperforms existing methods in both segmentation accuracy and processing speed.},
  archive      = {J_KBS},
  author       = {Guodong Sun and Junjie Liu and Gaoyang Zhang and Bo Wu and Yang Zhang},
  doi          = {10.1016/j.knosys.2025.114107},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114107},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient RGB-D scene understanding via multi-task adaptive learning and cross-dimensional feature guidance},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid genetic algorithm for the vehicle relocation problem with ride-sharing options in one-way car-sharing systems. <em>KBS</em>, <em>327</em>, 114106. (<a href='https://doi.org/10.1016/j.knosys.2025.114106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalance of idle cars at different stations remains a critical challenge in one-way car-sharing systems. This paper proposes a novel mixed user-operator-based relocation strategy for this problem. In this one-way car-sharing system, ride-sharing service is allowed, and customers can share trips with others by a rental vehicle. Ride-sharing, as a supplement to operator-based relocation, can relieve the pressure of vehicle relocation, lowering the relocation fee and reducing the required fleet size. In this study, the operators must determine a mixed vehicle relocation scheme, including operator-based vehicle relocation routes and user-based ride-sharing matches. This problem can be defined as a bi-objective mixed-integer linear programming model to minimize total user fees and maximize system benefits. The linear weighting method can combine those two objectives into one objective. To solve this problem, we propose a meta-heuristic algorithm based on the state-of-the-art hybrid genetic search with adaptive diversity control (HGSADC). The computational results show that the proposed algorithm can produce high-quality solutions within acceptable computing time. We also show that the proposed mixed vehicle relocation strategy can benefit operators and users.},
  archive      = {J_KBS},
  author       = {Weimin Tan and Min Kong and Muhammet Deveci and Weizhong Wang and Witold Pedrycz},
  doi          = {10.1016/j.knosys.2025.114106},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114106},
  shortjournal = {Knowl. Based Syst.},
  title        = {A hybrid genetic algorithm for the vehicle relocation problem with ride-sharing options in one-way car-sharing systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On deep CFR integrated with opponent model in imperfect information games. <em>KBS</em>, <em>327</em>, 114105. (<a href='https://doi.org/10.1016/j.knosys.2025.114105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imperfect information games are widely present in computer networking. For such games, CFR families, employing Nash equilibrium theory, is a safe and effective approach, but huge conservative on profits also follow. Identification of opponents’ behavioral models and exploiting sub-optimal opponents are efficient methods to improve agents’ profits. Furthermore, the accuracy, timeliness, and generalization of the opponent model seriously affect the game results. Therefore, in this paper, a novel online implicit opponent modeling, based on a neural network, is introduced into Deep Counterfactual Regret Minimization, and the Opponent Modeling Deep Counterfactual Regret Minimization(ODCFR) with two structures is proposed. Moreover, different network training methods are provided for unknown and known opponents, which effectively balance high profits with security. The method is evaluated on the Leduc game, which shows that ODCFR has superior performance over Deep CFR.},
  archive      = {J_KBS},
  author       = {Jiao Wang and Yun Li and Shanshan Niu and Ziyang Wu},
  doi          = {10.1016/j.knosys.2025.114105},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114105},
  shortjournal = {Knowl. Based Syst.},
  title        = {On deep CFR integrated with opponent model in imperfect information games},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-channel optimized multi-view learning via information bottleneck. <em>KBS</em>, <em>327</em>, 114104. (<a href='https://doi.org/10.1016/j.knosys.2025.114104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning has garnered significant attention due to its ability to learn more comprehensive representations. However, a critical challenge lies in the presence of redundant information within multi-view data. This redundancy not only dramatically increases computational complexity but also introduces substantial noise, severely disrupting the learning process and undermining the effectiveness of the model. To address this issue, we propose a learnable framework termed dual-channel optimized multi-view learning via Information bottleneck. This framework aims to capture more comprehensive consistency and complementary information while minimizing the influence of redundant information. Specifically, we design a dual-channel architecture to thoroughly explore both feature and topology information from multi-view data. For the feature space, we utilize deep neural networks to approximate matrix factorization, better capturing latent commonalities across multiple views. In the topology space, we adopt a prediction-driven approach, emphasizing the importance of views with higher prediction confidence in the fused view while reducing the contribution of views with lower confidence. Furthermore, we employ information bottleneck on both features and topology to minimize redundant information and connections while preserving the most relevant information for downstream tasks. The experiments confirm the robustness of the model and its effectiveness in classification tasks.},
  archive      = {J_KBS},
  author       = {Jiacheng Li and Yuhong Chen and Jie Lian and Jielong Lu and Weiran Liao and Shiping Wang},
  doi          = {10.1016/j.knosys.2025.114104},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114104},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-channel optimized multi-view learning via information bottleneck},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medcongtm: Interpretable multi-label clinical code prediction with dual-view graph contrastive topic modeling. <em>KBS</em>, <em>327</em>, 114103. (<a href='https://doi.org/10.1016/j.knosys.2025.114103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Accurate and interpretable clinical code assignment from free-text medical records is a fundamental challenge in healthcare informatics. Traditional machine learning and language model-based methods often lack transparency and struggle with multi-label prediction across complex taxonomies such as ICD, CPT, and LOINC. Existing topic modeling techniques, while interpretable, are rarely optimized for the clinical coding task and fail to leverage the rich semantic structure inherent in medical texts and ontologies. Methods We propose MedConGTM , a novel dual-view graph contrastive topic modeling framework tailored for interpretable and multi-label clinical code prediction. MedConGTM constructs two semantic views of each document: a document-token semantic graph and a document-code co-assignment graph. These views are jointly optimized through a novel dual-view contrastive learning objective that maximizes the mutual information between topic distributions inferred from text and task-specific code views. We introduce a code-aware word co-occurrence graph enhanced with medical ontologies and propose a hierarchy-sensitive contrastive loss that incorporates structural relationships between clinical codes. To ensure transparency, we design a topic-to-code attention decoder that links predicted codes to interpretable latent topics and salient textual evidence. Results Experiments on MIMIC-III and i2b2 datasets demonstrate that MedConGTM outperforms state-of-the-art baselines in both code prediction accuracy and topic coherence. It also provides interpretable code rationales aligned with clinical semantics. Conclusions MedConGTM offers a powerful, interpretable, and clinically grounded solution for automated ICD/CPT/LOINC code assignment, bridging the gap between topic modeling, contrastive learning, and real-world healthcare applications.},
  archive      = {J_KBS},
  author       = {Tuğba Çelikten and Aytuğ Onan},
  doi          = {10.1016/j.knosys.2025.114103},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114103},
  shortjournal = {Knowl. Based Syst.},
  title        = {Medcongtm: Interpretable multi-label clinical code prediction with dual-view graph contrastive topic modeling},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A natural language processing-based approach for early detection of heart failure onset using electronic health records. <em>KBS</em>, <em>327</em>, 114102. (<a href='https://doi.org/10.1016/j.knosys.2025.114102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective This study set out to develop and validate a risk prediction tool for the early detection of heart failure (HF) onset using real-world EHR data. Background While existing HF risk assessment models have shown promise in clinical settings, they are often tailored to specific medical conditions, limiting their generalizability. Moreover, most methods rely on hand-crafted features, making it difficult to capture the high-dimensional, sparse, and temporal nature of EHR data, thus reducing their predictive accuracy. Methods A total of 2561 HF and 5493 matched control patients were identified from the OneFlorida+ Clinical Research Consortium. We employed a suite of natural language processing (NLP) models, including Bag of Words, Skip-gram, and ClinicalBERT, to generate EHR embeddings, which were used as inputs for five prediction models. Subgroup analyses were conducted across gender, race, and ethnicity. Model calibration was assessed under three calibration scenarios: no recalibration, recalibration in the large, and logistic recalibration. Results The XGBoost model demonstrated the best overall performance, achieving an AUROC of 0.7672, an F1 score of 0.5547, an AUPRC of 0.6382, and a Matthews correlation coefficient of 0.3993. The most impactful predictors included diagnoses, procedures, medications, lab tests, and patient age. Model performance varied across gender, race, and ethnicity subgroups. Logistic recalibration significantly improved model calibration in the overall cohort and demographic subgroups. Conclusion Our NLP-based approach demonstrated strong predictive performance and practical relevance, highlighting its potential for integration into real-world clinical applications to facilitate the early detection and proactive management of individuals at risk for HF.},
  archive      = {J_KBS},
  author       = {Yuxi Liu and Zhen Tan and Zhenhao Zhang and Song Wang and Jingchuan Guo and Huan Liu and Tianlong Chen and Jiang Bian},
  doi          = {10.1016/j.knosys.2025.114102},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114102},
  shortjournal = {Knowl. Based Syst.},
  title        = {A natural language processing-based approach for early detection of heart failure onset using electronic health records},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMRL: A distributed multi-agent reinforcement learning algorithm for imbalanced classification. <em>KBS</em>, <em>327</em>, 114101. (<a href='https://doi.org/10.1016/j.knosys.2025.114101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional imbalanced classification methods rely on sampling or allocating different weights to different classes to improve the recognition rate for minority classes. However, these methods ignore the importance of adaptability, particularly as the degree of imbalance increases, resulting in significant limitations when dynamically selecting the optimal classification strategy. To tackle this issue, we propose a distributed multi-agent reinforcement learning (DMRL) method for imbalanced classification problems, which models the classification problem as a multi-agent Markov decision-making process within the distributed computing scheme. Subsequently, there are three important schemes implemented in DMRL: 1) A multi-agent classification scheme based on improved double deep Q-network (MCSQ) that dynamically optimizes the imbalanced classification strategy through the reward function and importance weights; 2) A prioritized experience replay-based scheme for sampling agents experience (PERS) that uses prioritized experience replay to learn from important samples; 3) A distributed computing scheme based on the multi-agent centralized training and decentralized execution (CTDE) paradigm (DCSM) that combines distributed computing with multi-agent CTDE to improve learning efficiency. Finally, we perform our experiment on public datasets such as IMDB, Cifar-10, Fashion-Mnist, and Mnist using the various imbalanced ratios. Experimental results demonstrate that DMRL outperforms eight representative methods, with a maximum improvement of 8.9 % in G-mean and 10.7 % in F-measure when compared to the suboptimal method. Simultaneously, we study the impact of the value of the reward function, the number of agents and servers, and the effectiveness of prioritized experience replay on the performance of DMRL.},
  archive      = {J_KBS},
  author       = {Yixin Ji and Chao Jing},
  doi          = {10.1016/j.knosys.2025.114101},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114101},
  shortjournal = {Knowl. Based Syst.},
  title        = {DMRL: A distributed multi-agent reinforcement learning algorithm for imbalanced classification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpaMGAN: Multi-view graph augmentation network for spatial domain identification in spatial transcriptomics. <em>KBS</em>, <em>327</em>, 114100. (<a href='https://doi.org/10.1016/j.knosys.2025.114100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in spatial transcriptomics have made it possible to profile gene expression while maintaining the spatial organization of cells, opening new avenues for exploring tissue microenvironments. However, integrating spatial and gene expression data to accurately identify spatial domains remains challenging. In this study, we present SpaMGAN as a multi-view graph augmentation network for spatial domain identification in spatial transcriptomics. The model constructs a spatial neighborhood graph by combining spot spatial proximity with cosine-weighted gene expression similarity. A pre-clustering pruning strategy generates a cell-type-aware K-nearest neighbor graph to better capture spatial similarity at domain boundaries. These graphs are merged into a weighted adjacency matrix. To enhance robustness and generalization, SpaMGAN incorporates adjacency matrix weighting, node shuffling, and feature masking. Using a consistency-based contrastive strategy, multiple augmented graph views are processed through graph convolution layers, and feature representations are fused via an attention mechanism. Evaluated on four datasets from three spatial transcriptomics platforms, SpaMGAN outperforms eight advanced methods. Specifically, the algorithm achieved the highest adjusted rand index scores of 0.594 and 0.585 on the datasets of the human dorsolateral prefrontal cortex and mouse visual cortex, respectively. In breast cancer tissue, SpaMGAN effectively reveals spatial heterogeneity, offering insights into the tumor microenvironment. On large-scale datasets such as mouse embryos, it identifies major anatomical regions and uncovers biologically meaningful domains enriched in developmental processes. Overall, SpaMGAN demonstrates strong scalability and biological interpretability, making it a powerful tool for analyzing tissue structure and disease mechanisms in spatial transcriptomics.},
  archive      = {J_KBS},
  author       = {Hao Liu and Yue Gao and Cui-Na Jiao and Chun-Hou Zheng and Ying-Lian Gao and Jin-Xing Liu and Yan-Li Wang},
  doi          = {10.1016/j.knosys.2025.114100},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114100},
  shortjournal = {Knowl. Based Syst.},
  title        = {SpaMGAN: Multi-view graph augmentation network for spatial domain identification in spatial transcriptomics},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyper lightweight neural networks towards spike-driven deep residual learning. <em>KBS</em>, <em>327</em>, 114099. (<a href='https://doi.org/10.1016/j.knosys.2025.114099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are bio-inspired models that apply binary spikes for encoding spatiotemporal cues. Recently, deep residual SNNs trained directly have achieved remarkable performance in classification and detection tasks, while there are still three challenges remain unresolved: 1) Mainstream residual SNN architectures have yet to achieve a balance between model expressivity and computational complexity; 2) The unreasonable stacking of spiking residual blocks impedes information flow across network layers; 3) The traditional Leaky Integrate-and-Fire (LIF) mechanism fails to capture spiking during the reverse variation of membrane potential. To address these issues, we built a novel directly trained lightweight framework called Hyper Lightweight Residual Neural Network (HL-ResNet), which incorporates Depth-Wise Convolution (DWC) and Lightweight Membrane Shortcut (LMS) to reduce both model parameters and computational cost. Furthermore, we propose Group-Wise Summation (GWS) to facilitate information flow through the integration of inter-channel depth features and high-frequency details. Additionally, we introduce the dynamical isometry theory to analyse the rationality of the designed modules, while demonstrating that HL-ResNet can perform well in a depth-insensitive way. Moreover, we propose a trainable Bidirectional Leaky Integrate-and-Fire (BLIF) strategy to adaptively learn membrane potential changes and extend the spike information during the firing activity, complemented by the gradient evolvement at backpropagation to derive its effectiveness in mitigating vanishing gradients. Finally, extensive experiments demonstrate that the proposed model outperforms state-of-the-art methods on the DVS-CIFAR10, DVS-Gesture, CIFAR10, and CIFAR100 datasets.},
  archive      = {J_KBS},
  author       = {Shilong Jing and Hengyi Lv and Yuchen Zhao and Hechong Wang and Guangsha Guo and Xianda Xu and Yisa Zhang and Yang Feng},
  doi          = {10.1016/j.knosys.2025.114099},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114099},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hyper lightweight neural networks towards spike-driven deep residual learning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pyramidal structure-correlated refinement for robust face alignment. <em>KBS</em>, <em>327</em>, 114098. (<a href='https://doi.org/10.1016/j.knosys.2025.114098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent face alignment methods attempt to capture representations of facial landmarks and learn the correlation between them. However, they often ignore the consistency between local landmarks and the overall face shape, which may lead to the low-efficiency correlation learning between long-distance landmarks. Besides, due to the uncertain localization, these methods may capture invalid local cues of landmark representations. To resolve these issues, we propose a pyramidal structure-correlated refinement method that integrates a novel fusion interactor into a pyramidal refinement framework. Specifically we introduce a fusion interactor to aggregate local regression cues of landmark representations into a global representation and encode the facial structure information. The facial structure information is then allocated to local representations to compensate for missing contexts of landmarks, such as occluded parts. Unlike vanilla attention mechanisms, our fusion interactor performs indirect interaction to avoid inconsistent landmark contexts, and incurs tiny computational complexity burdens. Additionally, to obtain valid local cues of landmarks, we further introduce a pyramidal refinement framework with multi-scale feature maps, which can sample landmark representations from the feature maps of specific scales according to the uncertainty of sampling positions. It can also gradually regularize the global representation with correct multi-scale spatial contexts to constrain the overall face shape. Experiments on some popular benchmarks demonstrate the effectiveness and robustness of our proposed method, especially its notably low failure rates in challenging scenarios.},
  archive      = {J_KBS},
  author       = {Qiyuan Dai and Qiang Ling},
  doi          = {10.1016/j.knosys.2025.114098},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114098},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pyramidal structure-correlated refinement for robust face alignment},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging temporal validity of rules via LLMs for enhanced temporal knowledge graph reasoning. <em>KBS</em>, <em>327</em>, 114094. (<a href='https://doi.org/10.1016/j.knosys.2025.114094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graphs (TKGs) are critical for understanding dynamic real-world scenarios. However, incorporating temporal validity into temporal knowledge graph reasoning (TKGR) is a critical yet often overlooked challenge. This is largely because most existing methods rely on static representations or predefined temporal windows, which fail to capture the dynamic and context-dependent nature of rule applicability over time. It can result in inaccurate predictions and a limited understanding of the evolving relationships within TKGs. Large Language Models (LLMs) are well-suited for addressing this challenge due to their inherent ability to capture sequential dependencies and reason over contextual relationships in temporal data. As a solution, we propose TV-LLM, a novel framework that primarily utilizes LLMs to guide the generation of temporal rules, while integrating rule-based learning and graph-based modeling to enhance temporal reasoning. The framework features LLM-guided rule generation with explicit modeling of temporal validity to dynamically determine the active time ranges of rules. Additionally, TV-LLM combines retrieved temporal facts with graph-based candidate scores to construct structured prompts, effectively leveraging both explicit knowledge and LLM reasoning capabilities. Extensive experiments on multiple benchmark datasets demonstrate that TV-LLM achieves competitive performance, with Mean Reciprocal Rank (MRR) gains of 1.2 % to 2.3 % and Hit@1 improvements of 1.9 % to 4.5 % over strong baselines on the ICEWS benchmarks. These results underline the importance of modeling temporal validity and motivate further exploration of structured knowledge integration in temporal reasoning tasks. Future work may explore real-time applications and improve the scalability of TV-LLM for large-scale temporal graphs.},
  archive      = {J_KBS},
  author       = {Qihong Pan and Limin Yao and Guojiang Shen and Xiao Han and Yichuan Chen and Xiangjie Kong},
  doi          = {10.1016/j.knosys.2025.114094},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114094},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging temporal validity of rules via LLMs for enhanced temporal knowledge graph reasoning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ActiveFreq: Integrating active learning and frequency domain analysis for interactive segmentation. <em>KBS</em>, <em>327</em>, 114091. (<a href='https://doi.org/10.1016/j.knosys.2025.114091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation is commonly used in medical image analysis to obtain precise, pixel-level labeling, typically involving iterative user input to correct mislabeled regions. However, existing approaches often fail to fully utilize user knowledge from interactive inputs and achieve comprehensive feature extraction. Specifically, these methods tend to treat all mislabeled regions equally, selecting them randomly for refinement without evaluating each region’s potential impact on segmentation quality. Additionally, most models rely solely on spatial domain features, overlooking frequency domain information that could enhance feature extraction and improve performance. To address these limitations, we propose ActiveFreq, a novel interactive segmentation framework that integrates active learning and frequency domain analysis to minimize human intervention while achieving high-quality labeling. ActiveFreq introduces AcSelect, an autonomous module that prioritizes the most informative mislabeled regions, ensuring maximum performance gain from each click. Moreover, we develop FreqFormer, a segmentation backbone incorporating a Fourier transform module to map features from the spatial to the frequency domain, enabling richer feature extraction. Evaluations on the ISIC-2017 and OAI-ZIB datasets demonstrate that ActiveFreq achieves high performance with reduced user interaction, achieving 3.74 NoC@90 on ISIC-2017 and 9.27 NoC@90 on OAI-ZIB, with 23.5 % and 12.8 % improvements over previous best results, respectively. Under minimal input conditions, such as two clicks, ActiveFreq reaches mIoU scores of 85.29 % and 75.76 % on ISIC-2017 and OAI-ZIB, highlighting its efficiency and accuracy in interactive medical segmentation.},
  archive      = {J_KBS},
  author       = {Lijun Guo and Qian Zhou and Zidi Shi and Hua Zou and Gang Ke},
  doi          = {10.1016/j.knosys.2025.114091},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114091},
  shortjournal = {Knowl. Based Syst.},
  title        = {ActiveFreq: Integrating active learning and frequency domain analysis for interactive segmentation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demand-driven kNN classification. <em>KBS</em>, <em>327</em>, 114090. (<a href='https://doi.org/10.1016/j.knosys.2025.114090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the optimal k has become a widely adopted approach in kNN classification applications. However, in real-world scenarios where training data is large, users often expect k to be sufficiently large to ensure confidence in the kNN classification results. In other words, the mathematically optimal k may not always be the most suitable for practical needs. To address this, we propose a demand-driven approach to learning the most suitable k for kNN classification. Specifically, we introduce a bias term and an anchor graph to formulate a novel objective function, enabling the optimal selection of k for each test sample. Additionally, we define new entropy-based metrics, namely k -entropy and k + -entropy, to determine the most suitable k value while aligning with user-defined expectations. We evaluate the proposed method through extensive experiments on ten publicly available datasets. The results indicate that our algorithm not only delivers superior classification performance but also adaptively determines the most suitable k value in accordance with user requirements. Notably, our method improves classification accuracy by an average of 4.18 % compared to the best state-of-the-art baseline. The source code of the proposed method is available at: https://github.com/Lijy207/DDKNN .},
  archive      = {J_KBS},
  author       = {Jiagang Song and Hang Xu and Jiaye Li and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114090},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114090},
  shortjournal = {Knowl. Based Syst.},
  title        = {Demand-driven kNN classification},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label emotion classification based on transfer information and external knowledge. <em>KBS</em>, <em>327</em>, 114089. (<a href='https://doi.org/10.1016/j.knosys.2025.114089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion classification aims to identify and understand the emotions expressed in a text. It is essential for many practical applications, such as opinion monitoring, product evaluation analysis, and customer service. However, previous works ignored the order of appearance of emotion labels and the kind of emotion transfer information embedded in them. At the same time, it did not use two forms of external knowledge, including emotion label and compound emotion knowledge. To address these problems, we propose a multi-label emotion classification model based on transfer information and external knowledge (ME-TIEK) that consists of three components: emotion transfer learning module, emotion reinforcement learning module, and linear emotion classifier. Specifically, we use the graph convolutional network (GCN) to explore emotions’ dependency and transfer relationships. We also use the external knowledge of labels to enhance the label node representations. In addition, we design a multi-level attention mechanism to learn the expression of different emotions in the text. Then, we use the cross-attention mechanism to learn the correlation between primary and compound emotions. Finally, we enhance the semantics of textual emotion in terms of primary and compound emotions. The experiments show that the macro-average scores of ME-TIEK averagely outperform by 20.7 % on the English dataset and improve by 0.2–31.2 % on the Chinese dataset compared with existing baseline models.},
  archive      = {J_KBS},
  author       = {Chen Huang and Xianyong Li and Xin Zheng and Yajun Du and Dong Huang and Xiaoliang Chen and Jian Zhu},
  doi          = {10.1016/j.knosys.2025.114089},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114089},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label emotion classification based on transfer information and external knowledge},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PerioDformer: Periodic disposition enhanced transformer for times series forecasting. <em>KBS</em>, <em>327</em>, 114088. (<a href='https://doi.org/10.1016/j.knosys.2025.114088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the permutation-invariant nature of the self-attention mechanism and the absence of inherent semantic meaning in individual time points, temporal information is inevitably lost, impairing the Transformer’s ability to capture temporal dependencies. However, when sequence elements are semantically rich, the impact of losing temporal order tends to be less severe. Motivated by this observation, we propose the Periodic Disposition Enhanced Transformer (PerioDformer) for time series forecasting, which transforms input sequences into semantically enriched tokens. In the proposed Periodic Disposition strategy, the input sequence is segmented into periodic blocks according to a predefined period length. These blocks are then reorganized into two complementary structures to form phase-wise and period-wise tokens, which are fed into two separate encoders. Each phase-wise token aggregates time points from the same phase across multiple periods, capturing cross-period temporal patterns at that specific phase position. In contrast, each period-wise token encapsulates an entire periodic block, preserving the complete intra-period dynamics. This periodic disposition greatly reduces the number of tokens fed into the Transformer, allowing for a significantly longer look-back window with only a marginal increase in memory consumption and computational complexity. Empirical results demonstrate that PerioDformer achieves state-of-the-art performance on six challenging real-world datasets. The source code is available at: https://github.com/wenjietang218/PerioDformer .},
  archive      = {J_KBS},
  author       = {Wenjie Tang and Yilei Xiao and Yizhi Zhou and Heng Qi},
  doi          = {10.1016/j.knosys.2025.114088},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114088},
  shortjournal = {Knowl. Based Syst.},
  title        = {PerioDformer: Periodic disposition enhanced transformer for times series forecasting},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phonetic-aware word reconstruction in ancient tamil inscriptions using adaptive graph networks. <em>KBS</em>, <em>327</em>, 114087. (<a href='https://doi.org/10.1016/j.knosys.2025.114087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An enormous amount of information and traditional knowledge are found in Tamil Stone Inscriptions, which are ancient handwritten documents engraved on stone. Numerous issues including limited diversity in datasets, inadequate use of advanced feature extraction techniques, high computational costs, insufficient exploration of various optimization methods, and prolonged training times were determined from existing approaches. Therefore, an innovative framework is a novel Artificial Depthwise separable Graph Convolutional based Bidirectional Encoder Representations Transformer technique is proposed in the field of ancient Tamil language recognition from inscriptions. The different types of inscription were selected from diverse data sources and it leverages several preprocessing techniques to improve image visibility and lessen the effects of noise and distortions. Subsequently, additional line and character segmentation tasks are carried out to produce meaningful regions. After that, the Light Graph Neural Network is applied to derive feature vectors with the use of aggregators by extracting global information and highlighting significant textual elements. Additionally, an adaptive Graph Convolutional Network automatically learns representative data and optimizes the feature representation. To enhance efficiency, depthwise separable convolution is utilized for reducing computational load and minimizing the number of parameters. Finally, the Fast Bidirectional Encoder Representations Transformers technique is applied for character identification by embedding words in the sentences. After the character identification, the words are identified using the Probabilistic Artificial Fast Bidirectional Encoder Representations Transformers model according to the Tamil grammatical rules and Phonetic lookup tables. The proposed technique attains a greater recognition accuracy of 99.14 % and an execution time of 25 s, which outperforms previous techniques. Consequently, it is claimed that the proposed technique is the most effective for supporting ancient Tamil character recognition in inscriptions.},
  archive      = {J_KBS},
  author       = {Vidhyavani. A and T. Manoranjitham},
  doi          = {10.1016/j.knosys.2025.114087},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114087},
  shortjournal = {Knowl. Based Syst.},
  title        = {Phonetic-aware word reconstruction in ancient tamil inscriptions using adaptive graph networks},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image deraining via dual-level contextual information associated learning for autonomous driving. <em>KBS</em>, <em>327</em>, 114086. (<a href='https://doi.org/10.1016/j.knosys.2025.114086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have made progress in utilizing low-level contextual information to reduce the impact of rain on autonomous driving. However, objects within the same semantic category tend to share similar characteristics, aiding background recovery. To this end, we propose the Dual-Level Contextual Associated Learning Network (DCALNet), which integrates both low-level and semantic-level contextual information to exploit object similarities better. DCALNet employs a Coarse Background Recovery Module (CBRM) with a hybrid feature representation to predict a coarse derained image enriched with semantic context, effectively capturing spatial distributions of semantically similar objects, whether adjacent or non-adjacent. Furthermore, the Dual-Level Contextual Associated Learning Module (DCALM) further enhances background recovery by mining similarities in texture, structure, and color. To ensure semantic consistency, we apply both local and global semantic constraints, improving the accuracy of semantic information in the derained image. Experimental results show that DCALNet outperforms state-of-the-art methods by achieving an improvement of 1.33dB/0.0034 in PSNR/SSIM, and 0.56/0.42 % in mIoU/PA on average, demonstrating its effectiveness in both deraining and segmentation tasks.},
  archive      = {J_KBS},
  author       = {Xiaofen Wang and Bin Yang and Tao Wen and Zhen Han and Zheng Wang},
  doi          = {10.1016/j.knosys.2025.114086},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114086},
  shortjournal = {Knowl. Based Syst.},
  title        = {Image deraining via dual-level contextual information associated learning for autonomous driving},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LF-HGRILF: A law-fact heterogeneous graph representation and iterative learning framework for legal judgment prediction. <em>KBS</em>, <em>327</em>, 114083. (<a href='https://doi.org/10.1016/j.knosys.2025.114083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal Judgment Prediction (LJP) is a key aspect of legal intelligence, leveraging machine learning and natural language processing to analyze legal facts and predict relevant law articles, charges, and penalties. Most existing methods, however, focus solely on semantic relationships between individual cases and law articles, neglecting the topological structure connecting them. This oversight results in misjudgments, particularly in cases with overlapping legal grounds due to law article similarities. To address these limitations, we propose the Law-Fact Heterogeneous Graph (LF-HetG) and its corresponding iterative learning framework (LF-HGRILF). Unlike prior approaches, LF-HetG integrates four types of nodes-case facts, factual sentences, keywords, and law articles-capturing both the connections between case facts and law articles and enabling the establishment of semantically similar relationships through common keywords. LF-HGRILF addresses the shortcomings of existing models by incorporating legal domain knowledge, case associations, and word-level semantic information. The framework learns deep case embeddings through neighbor aggregation in an iterative process and introduces a law article distinction module (LADM) to enhance the distinctiveness of similar law articles’ embeddings. Finally, we use different classifiers to yield prediction outcomes for the three LJP tasks.Experimental results demonstrate that LF-HGRILF significantly outperforms existing methods across all predictive tasks, highlighting its effectiveness in improving legal judgment prediction.},
  archive      = {J_KBS},
  author       = {Yinying Kong and You-Gan Wang and Haodong Deng and Zhanhao Xiao and Yuke Zhang},
  doi          = {10.1016/j.knosys.2025.114083},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114083},
  shortjournal = {Knowl. Based Syst.},
  title        = {LF-HGRILF: A law-fact heterogeneous graph representation and iterative learning framework for legal judgment prediction},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-query frequency prompting for physiological signal domain adaptation. <em>KBS</em>, <em>327</em>, 114082. (<a href='https://doi.org/10.1016/j.knosys.2025.114082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses three key challenges in blood pressure prediction from physiological signals: limited labeled data, domain shifts between source and target populations, and under-representation of hypertensive and hypotensive groups. We propose Multi-Query Frequency Prompting (MQFP), a prompt-learning framework that inserts a small, learnable embedding, formulated in the frequency domain, into a frozen pre-trained model. By capturing key signal characteristics such as variability, periodicity, and locality, the frequency-space prompt enables robustness to both distributional and temporal shifts while mitigating overfitting in few-shot settings. Evaluated on three PPG and two ECG datasets, MQFP achieves up to a 21.3 % reduction in mean absolute error relative to its backbone, while reducing trainable parameters by up to 98.4 %. These results demonstrate MQFP as a lightweight and effective approach to BP estimation in real-world settings.},
  archive      = {J_KBS},
  author       = {Jinho Kang and Hoyoon Byun and Taero Kim and Jiyoung Jung and Kyungwoo Song},
  doi          = {10.1016/j.knosys.2025.114082},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114082},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-query frequency prompting for physiological signal domain adaptation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-driven privacy-preservation of healthcare insurance data using improved ECC based encryption and deep learning based key tuning. <em>KBS</em>, <em>327</em>, 114078. (<a href='https://doi.org/10.1016/j.knosys.2025.114078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, safeguarding the confidentiality and integrity of health insurance data is crucial, especially when considering blockchain technology. Although blockchain technology provides cryptographic protection, maintaining the privacy of private medical data is still quite difficult. In response, the Blockchain-driven Policy Preservation of Healthcare Insurance data via Multi-Head Attention SqueezeNet Model (BPPHIM) is a unique framework that is proposed in this research. The three main phases of the BPPHIM system are proxy, data storage, and data encryption. Data from the Data Owner (DO) is first encrypted using an Improved ECC technique aided by optimization and DL approach. Data partitioning using a K-means clustering technique is the first step in the encryption process. The partitioned data has optimal keys produced by a Self-Improving Coati Optimization Algorithm (SI-COA) and adjusted using the Multi-Head Attention SqueezeNet (M-HAS) model. The customized keys are then safely saved in the Blockchain after being encrypted using the Improved ECC method. The Proxy, a key management and distribution entity, receives the tuned keys at the same time. It uses a Modified Chaotic Map (MCM) to encrypt the keys and keeps itself updated. Encrypted data is obtained from the Block Chain Center (BCC) upon the Data User's authorized request. The original sensitive healthcare data is then obtained by the DU using the encrypted tuned keys to decrypt the data. Thus, the proposed framework offers enhanced data security through advanced encryption techniques and efficient key management, guaranteeing the protection of health insurance data privacy. By integrating blockchain, it ensures decentralized and tamper-proof storage. The use of deep learning models optimizes key generation, improving encryption efficiency. Additionally, the system enables secure and controlled access to sensitive healthcare data, enhancing privacy and accessibility.},
  archive      = {J_KBS},
  author       = {Jeeva Buvana and R Gayathri},
  doi          = {10.1016/j.knosys.2025.114078},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114078},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-driven privacy-preservation of healthcare insurance data using improved ECC based encryption and deep learning based key tuning},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dronetology: A domain ontology for UAS applications. <em>KBS</em>, <em>327</em>, 114074. (<a href='https://doi.org/10.1016/j.knosys.2025.114074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing importance of Unmanned Aerial Systems (UAS) has led to the development of various applications, resulting in significant fragmentation in technologies, components, and data formats. The UAS domain must meet stringent requirements regarding safety, regulatory compliance, and interoperability with other systems. It also faces challenges such as efficiency, airspace sharing, scalability, awareness of other aircraft, and effective data analysis. Semantic technologies provide solutions for these challenges, offering interoperability and intelligent decision-making. Ontologies stand out for their ability to model knowledge and facilitate understanding within the UAS domain. This paper introduces Dronetology, https://dronetology.net/dronetology , a domain ontology designed to provide a common framework for UAS concepts. It aims to improve interoperability, data quality, and knowledge integration. Dronetology has been implemented in a decision support prototype using an expert system architecture to address complex UAS use cases, including flight efficiency, collision avoidance, and compliance with regulations. We also outline how Dronetology can be specialized to create application ontologies for specific UAS needs.},
  archive      = {J_KBS},
  author       = {David Martín-Lammerding and José Javier Astrain and Alberto Córdoba},
  doi          = {10.1016/j.knosys.2025.114074},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114074},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dronetology: A domain ontology for UAS applications},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perceptual stretch and multi-feature fusion for enhancing nighttime images. <em>KBS</em>, <em>327</em>, 114073. (<a href='https://doi.org/10.1016/j.knosys.2025.114073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images acquired under suboptimal illumination conditions encounter low brightness and contrast, blurry details, and color distortion. To tackle these issues, we propose an image enhancement framework based on perceptual stretch and multi-feature fusion, named PSMF. Specifically, a multiscale convolution-guided filter is developed to fully explore hierarchical frequency information at different scales and levels. And an adaptive perceptual histogram equalization relying on frequency clipping technique and visual perception is presented for contrast stretching. Meanwhile, the pyramid transformation is employed for detail boosting. Subsequently, we employ a multiweight map constrained fusion strategy to aggregate these different feature maps, and further remove color deviation according to the characteristic of the image by using a linear color correction model. Extensive experiments on public benchmarks illustrate that our PSMF is superior to state-of-the-art comparison methods in generating artifact-free images with high global contrast, vivid color, and clearer details. The experiments further suggest that our method significantly improves the performance in advanced computer vision tasks, such as feature point matching and face detection.},
  archive      = {J_KBS},
  author       = {Haoxiang Lu and Tianle Fang and Zhenbing Liu and Weidong Zhang and Rushi Lan},
  doi          = {10.1016/j.knosys.2025.114073},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114073},
  shortjournal = {Knowl. Based Syst.},
  title        = {Perceptual stretch and multi-feature fusion for enhancing nighttime images},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GIP-stereo: Geometry-aware information propagation network for stereo matching. <em>KBS</em>, <em>327</em>, 114062. (<a href='https://doi.org/10.1016/j.knosys.2025.114062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo matching is a critical task in computer vision. Despite significant advances over the last decade, existing methods often fail to fully exploit geometric cues throughout the entire stereo matching pipeline, which leads to suboptimal performance in ill-posed regions. To address this issue, we propose GIP-Stereo, a novel framework that establishes a structured flow of geometric information throughout the process, thereby improving robustness and accuracy in ill-posed regions. We introduce Multi-Scale Feature Aggregation (MSFA) at the feature extraction stage to establish a robust feature foundation by capturing and fusing multi-scale representations. To further enhance the propagation of geometric cues, we design a Propagation-Enhanced Correlation Volume (PECV), which incorporates the Latent Geometric Propagation (LGP) module to refine feature representations in challenging areas. Moreover, as geometric information may be lost during disparity map generation, we propose the Geometric-Aware Interaction Refinement Network (GIRN), which adaptively integrates previously propagated geometric-aware information with supplementary information for enhanced disparity refinement. Experimental results show that GIP-Stereo is effective in handling ill-posed regions. At the time of submission, our method ranks 1st on the ETH3D benchmark with a 0.70 % 1-pixel outlier rate (Bad 1.0) and 1st on the KITTI-2012 Reflective with a 2.99 % 3-pixel outlier rate in non-occluded regions (3-noc). Furthermore, GIP-Stereo achieves state-of-the-art (SOTA) performance on KITTI-2015 with a 1.51 % 3-pixel outlier rate in all regions (D1-all), surpassing IGEV-Stereo by 5.13 % and on the Middlebury with a 7.35 % 2-pixel outlier rate (Bad 2.0).},
  archive      = {J_KBS},
  author       = {Yang Zhao and Ziyang Chen and Junling He and Wenting Li and Yao Xiao and Chunwei Tian and Yongjun Zhang},
  doi          = {10.1016/j.knosys.2025.114062},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114062},
  shortjournal = {Knowl. Based Syst.},
  title        = {GIP-stereo: Geometry-aware information propagation network for stereo matching},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced deep learning network induced by full visual mechanism for image compressive sensing. <em>KBS</em>, <em>327</em>, 114060. (<a href='https://doi.org/10.1016/j.knosys.2025.114060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing (CS) is the only major theory proposed in the field of signal processing in recent years to break through the bottleneck of Shannon's sampling theorem. At present, several major challenges remain for deep learning (DL) of CS. The modeling theory of DL is not interpretable for human beings until now. DL requires a large number of parameters and computations. The unsatisfactory quality of signal reconstruction remains one of the biggest challenges. By analyzing the principles of the human brain and visual system, we propose an interpretable theory and better balance for the compressive sensing network (ITB2-CSNet) which is induced by the full visual mechanism from the source. We in addition introduce the principle of the central brain's understanding on images, which is also called the internal generative mechanism (IGM). We construct a visual weighted feature map learning module (VWFMLM) for optimizing the learning of IGM parameters. Furthermore, a deep image reconstruction sub-network is constructed including a vision partial feature distillation block (VPFDB) as its core block. We design a measurement residual information compensation module (MRICM) and a wavelet sub-band interactive learning module (WSBILM) to further enhance the performance of the deep reconstruction sub-network. Experimental results show that the ITB2-CSNet achieves a better balance between image reconstruction quality and model complexity. Our method improves the interpretability of DL models used for this task. In addition, the sophistication of our modeling method is also reflected in the robustness to image noise and its overall high performance results.},
  archive      = {J_KBS},
  author       = {Mingkun Feng and Xiaole Han and Kai Zheng},
  doi          = {10.1016/j.knosys.2025.114060},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114060},
  shortjournal = {Knowl. Based Syst.},
  title        = {An enhanced deep learning network induced by full visual mechanism for image compressive sensing},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDDPFuse: Multi-driven dynamic perception network for infrared and visible image fusion via data guidance and semantic injection. <em>KBS</em>, <em>327</em>, 114027. (<a href='https://doi.org/10.1016/j.knosys.2025.114027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to generate a fused image that simultaneously contains salient target information and rich texture details. Therefore, this task frequently serves as a preprocessing module to enhance the performance of downstream tasks. When dealing with dynamic and complex environments, existing fusion methods typically treat both modalities equally, ignoring the interaction between modal features and environmental characteristics, which limits the generalization ability of the model. In this study, we propose a Multi-Driven Dynamic Perception Fusion model (MDDPFuse), which achieves adaptive dynamic perception fusion in sophisticated and dynamic environments through data guidance and semantic injection mechanisms. Initially, the High-Low Frequency Feature Extraction module we designed fully extracts multi-scale high-frequency details and low-frequency background information. Meanwhile, the Adaptive Dynamic Perception Fusion module we proposed effectively addresses the challenge of dynamic dominance of modality in fused images through its dynamic fusion rule guided by visible grayscale distribution. Finally, we design a Semantic Feature Injection module to direct the fusion procedure, elevating the semantic representation capability of the fused images. MDDPFuse outperforms existing SOTA methods in both subjective visual effects and objective evaluation metrics. Further research confirms that our method significantly improves the performance of segmentation tasks. The code is publicly available and can be accessed at https://github.com/Minglei-Wang/MDDPFuse .},
  archive      = {J_KBS},
  author       = {Minglei Wang and Yue Pan and Zilong Zhao and Zhongtao Li and Shuanglong Yao},
  doi          = {10.1016/j.knosys.2025.114027},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114027},
  shortjournal = {Knowl. Based Syst.},
  title        = {MDDPFuse: Multi-driven dynamic perception network for infrared and visible image fusion via data guidance and semantic injection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical differential attention for multimodal relation extraction. <em>KBS</em>, <em>327</em>, 114023. (<a href='https://doi.org/10.1016/j.knosys.2025.114023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multimodal relation extraction task aims to extract and comprehend the semantic relationships between different modalities. The task is crucial for accurately capturing the correlations between modalities and has wide applications in fields such as image captioning, cross-modal retrieval, and multimodal question answering. Despite significant progress made by existing methods, challenges such as attention noise interference remain. For this reason, this paper proposes the Hierarchical Differential Attention for Multimodal Relation Extraction (HDAMRE). HDAMRE consists of two main modules: the Unimodal Feature Enhancement (UFE) module and the Multimodal Feature Integration (MFI) module. The UFE module extracts multi-scale features from visual and language modalities using Wavelet Transform, and suppresses intra-modal attentional noise by combining Self-Differential Attention. In the MFI module, the integration of the Cross-Differential Attention and Co-regularization constraint is implemented to optimize inter-modal information fusion, reducing interference from irrelevant information and enhancing the model’s cross-modal understanding capabilities. Evaluations conducted on commonly used multimodal relation extraction datasets demonstrate that HDAMRE achieves superior performance across multiple metrics, including Accuracy, Precision, Recall, and F1-score. Furthermore, ablation studies validate the contribution of key components such as Wavelet Transform, Self-Differential Attention, Cross-Differential Attention, and Co-regularization in enhancing the model’s performance.},
  archive      = {J_KBS},
  author       = {Yun Liu and Xiaoheng Jiang and Yang Lu and Kunli Zhang and Yafei Li and Mingliang Xu},
  doi          = {10.1016/j.knosys.2025.114023},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114023},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical differential attention for multimodal relation extraction},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-augmentation and attribute-aware graph contrastive learning with weak information. <em>KBS</em>, <em>327</em>, 114015. (<a href='https://doi.org/10.1016/j.knosys.2025.114015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown impressive performance in many graph learning tasks. Traditional GNNs assume that input data is complete, however, GNNs are typically constrained by weak information (such as incomplete structure, incomplete features, and insufficient labels). Moreover, GNNs rely on the homophily assumption of the network, which ignores the node similarity in the attribute space. In this paper, we propose a S tructure-augmentation and A ttribute-aware G raph C ontrastive L earning with Weak Information method (SA-GCL), which integrates multiple weak signals and processes them through unified modeling and joint contrastive mechanisms. Specifically, we generate the feature completion graph, which utilizes the feature information of the long-range neighbors to complement the original nodes, to effectively alleviate the weak feature problem. To address the weak structure problem, we enhance the original graph and further construct the global structure graph that is not limited to first-order neighbors, fully capturing the global topological relationships in the graph. In addition, to mitigate the non-homophilic problem, we retain the attribute information of the original graph and generate the attribute-aware graph based on the attribute-association relationships among nodes. Then, we input the above graph data into the GNN encoder and achieve collaborative contrastive learning of multiple weak signals through joint contrastive learning under four different views. Finally, the SA-GCL model maximizes the common information between similar instances, which effectively mitigates the weak label problem. Experimental results on real datasets with different levels of homophily show that our method outperforms state-of-the-art graph representation learning approaches on both node classification and link prediction tasks.},
  archive      = {J_KBS},
  author       = {Wen Li and Kai Yang and Kairong Li},
  doi          = {10.1016/j.knosys.2025.114015},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {114015},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structure-augmentation and attribute-aware graph contrastive learning with weak information},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing vision-language models through pre-training-free knowledge fusion with TransferCVLM. <em>KBS</em>, <em>327</em>, 113986. (<a href='https://doi.org/10.1016/j.knosys.2025.113986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent large vision-language multimodal models pre-trained with huge amount of image-text pairs show remarkable performances in downstream tasks. However, the multimodal pre-training has limitations in terms of resources and training time when it comes to obtaining new models that surpass existing models. To address these issues, we propose TransferCVLM, a method for efficiently constructing an advanced vision-language model without extensive multimodal pre-training. TransferCVLM integrates existing pre-trained unimodal models and a cross-modal fusion module into a combinative vision-language model (CVLM). For each task application, the CVLM is fine-tuned and further enhanced through knowledge distillation, where multimodal knowledge from a teacher vision-language model is transferred to the CVLM. We demonstrate that (1) the fine-tuned CVLM performs comparable to other vision-language models of similar size, that (2) the multimodal knowledge transfer consistently enhances the CVLM, and the knowledge-transferred CVLM outperforms the teacher multimodal model in most downstream tasks, and that (3) TransferCVLM can also be used for model compression when using small-size unimodal models, achieving better retainability than existing pre-training-based knowledge distillation methods. We estimate that the training of TransferCVLM takes only 6% of pre-training of other vision-language models. Our code is available at https://github.com/DMCB-GIST/TransferCVLM .},
  archive      = {J_KBS},
  author       = {Dongha Choi and Jung-jae Kim and Hyunju Lee},
  doi          = {10.1016/j.knosys.2025.113986},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {113986},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing vision-language models through pre-training-free knowledge fusion with TransferCVLM},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning bird’s eye view scene graph and knowledge-inspired policy for embodied visual navigation. <em>KBS</em>, <em>327</em>, 113959. (<a href='https://doi.org/10.1016/j.knosys.2025.113959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embodied agents in visual navigation tasks can infer the object location based on commonsense knowledge about unknown environments. Most existing methods primarily focus on constructing 2D scene graphs using panoramic observations or encoding semantic information in 2D representations using large language models. However, these methods hinder to perceive 3D scene geometry, prone to ignore the surrounding details by ambiguous selection of observations and lack grounding interaction with the environment, which generalizes poorly to novel objects or unseen environments. We propose BevNav framework to solve these issues from three aspects: (i) We introduce a novel Bird’s Eye View (BEV) scene graph (BevSG) that utilizes multi-view 2D information transformed into 3D under the supervision of 3D detection to encode scene layouts and geometric clues. It can distinguish multi-view semantically similar objects and make plans in this graph. (ii) We propose BEV-BLIP based contrastive learning that aligns the BEV and language grounding inputs. It transfers constrained commonsense knowledge in pre-trained models without other training in the environments. (iii) We design BEV-based view search navigation strategy, which encourages representations that encode the semantics, relationships, and positional information of objects. This policy leverages the topological relations of locally collected BEV representations to infer invisible objects. Utilizing BevSG, the agent can predict a BEV graph decision score, for more accurate action prediction, thus improving exploration efficiency. Extensive experiments demonstrate that BevNav shows promising results on Gibson, HM3D, and ProcTHOR, which exhibits higher success rates than existing graph-based and LLM-based methods, indicating the feasibility of BevSG and commonsense knowledge from language models, leading efficient semantic exploration.},
  archive      = {J_KBS},
  author       = {Jian Luo and Jian Zhang and Jie Yang and Siwei Huang and Bo Cai},
  doi          = {10.1016/j.knosys.2025.113959},
  journal      = {Knowledge-Based Systems},
  month        = {10},
  pages        = {113959},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning bird’s eye view scene graph and knowledge-inspired policy for embodied visual navigation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class boundary prediction method by self-representation based pattern selection and geometric-constrained diffusion generation. <em>KBS</em>, <em>326</em>, 114096. (<a href='https://doi.org/10.1016/j.knosys.2025.114096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data-driven decision systems, boundary patterns are instrumental for delineating distinct categories. However, the scarcity of representative samples that encapsulate the class data distribution often results in a dearth of critical boundary information, impeding the comprehension of data structures and the extraction of pivotal details. To surmount the challenge of predicting boundary patterns amidst insufficient data, this paper proposes a class boundary prediction method by self-representation based pattern selection and geometric-constrained diffusion generation (BP-PSG). It leverages the negative components of samples based on self-representation to distinguish between different edge patterns. A novel conditioning mechanism is proposed for diffusion model that constrains data generation along geometrically meaningful directions. The aggregated data is then subjected to a cycle of evaluation and generation to obtain more potential representative samples that reflect the class data distribution. The ultimate edge patterns derived from this comprehensive dataset are deemed as class boundary. The effectiveness of our method has been validated on both high-dimensional and low-dimensional data, including synthetic data, benchmark datasets, and the RSRAC dataset. Notably, BP-PSG enhances anomaly detection accuracy by 5.44 % to 27.38 % on the benchmark datasets. On the RSRAC dataset, it improves individual emitter identification accuracy by an average of 3.95 % and unknown-class detection accuracy by an average of 11.35 %.},
  archive      = {J_KBS},
  author       = {Wei Quan and Zhaoyu Chen and Rui Peng},
  doi          = {10.1016/j.knosys.2025.114096},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114096},
  shortjournal = {Knowl. Based Syst.},
  title        = {A class boundary prediction method by self-representation based pattern selection and geometric-constrained diffusion generation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph convolutional network with multiple aggregators for learning to branch. <em>KBS</em>, <em>326</em>, 114095. (<a href='https://doi.org/10.1016/j.knosys.2025.114095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Multi-Aggregator Graph Convolutional Network (MAGCN) that enhances variable selection in Mixed-Integer Linear Programming (MILP) solvers by addressing the trade-off between selection accuracy and computational efficiency inherent in traditional branching methods. Unlike prior models that rely on a single aggregation function, the proposed approach uses Principal Neighborhood Aggregation (PNA) to integrate multiple aggregators - mean, sum, max, and standard deviation - along with degree-scalers that adjust neighbor influence dynamically. By breaking Weisfeiler–Leman-equivalent symmetries without incurring the O ( n 2 ) or O ( n 3 ) blow-up of pairwise GNNs, MAGCN preserves linear complexity of O ( n ) while capturing richer structural patterns. A fusion Multi-Layer Perceptron (MLP) stack with skip-connections further improves gradient flow, each layer operating in O ( n d ² ) for feature dimension d , and stabilizes learning on large and complex MILP instances. The model, trained through imitation learning based on strong branching decisions and integrated within a Branch-and-Bound framework, effectively minimizes the number of explored nodes and LP relaxations while maintaining linear scalability. Benchmark tests on various MILP instances, including variants of the Multi-Traveling Salesman Problem and Job Shop Scheduling Problem, reveal competitive or superior performance compared to conventional and attention-enhanced GCN architectures in solving complex MILP problems.},
  archive      = {J_KBS},
  author       = {Nguyen Vinh Toan and Nguyen Van-Hop},
  doi          = {10.1016/j.knosys.2025.114095},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114095},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph convolutional network with multiple aggregators for learning to branch},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiFeature fusion graph attention network for aspect-based sentiment analysis. <em>KBS</em>, <em>326</em>, 114084. (<a href='https://doi.org/10.1016/j.knosys.2025.114084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task, which aims to predict the sentiment polarity of a given aspect in a sentence. Most of the approaches rely on syntactic and semantic parsing to derive textual insights, often overlooking how aspectual and contextual factors impact model performance. Alternatively, they focus on an in-depth study of the information in the dependency tree, thereby ignoring the importance of the constituent trees. In this work, we introduce a multifeature fusion graph attention network (MFF-GAT) model. The model constructs syntactic, semantic and contextual channels, fusing dependent syntactic information and constituent syntactic information through a gating mechanism. The semantic graph is constructed based on self-attention, and the contextual graph is constructed based on point interaction information. In addition, this study uses the multi-head attention mechanism to interact with aspects and three features and capture aspect-related information. Our MFF-GAT model performs better on the ABSA task than other baseline models, according to experiments conducted on five public datasets.},
  archive      = {J_KBS},
  author       = {Jiaofeng Wang and Hongfang Gong and Xinyu Guo},
  doi          = {10.1016/j.knosys.2025.114084},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114084},
  shortjournal = {Knowl. Based Syst.},
  title        = {MultiFeature fusion graph attention network for aspect-based sentiment analysis},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On controllability of discrete-time multi-agent networks based on impulsive and switching systems. <em>KBS</em>, <em>326</em>, 114081. (<a href='https://doi.org/10.1016/j.knosys.2025.114081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controllability studies of multi-agent systems (MAS) are mainly based on node dynamics without impulsive state jumps. However, in real dynamic environments, impulsive jumps will occur during the evolution of node dynamics due to abrupt communication interruptions or topology reconfigurations, which leads to the limited applicability of existing controllability theories. To address this gap, in this paper a discrete-time impulsive MAS (DTIMAS) is proposed, which incorporates impulsive jumps and switching effects in a discrete-time communication framework. First, through the comination of regular and instantaneous communication interactions, a DTIMAS model is introduced, where the network topology or leadership may change over time. Then, combining algebraic analysis and geometric tools, the controllability conditions over single and multiple switching periods are established for DTIMAS with topology switching, revealing a mechanism whereby a DTIMAS may be fully controllable over multiple switching periods even if it is uncontrollable over a single switching period. Furthermore, a controllability criterion for DTIMAS with changing leadership is further developed through mathematical induction and switching system theory. It is found that dynamic leadership can enhance the controllability of DTIMAS. To validate the theoretical results, two numerical examples are provided. Compared with existing works, the controllability criteria derived in this paper aim to deal with a wider range of MAS, thus providing a more comprehensive framework for MAS controllability analysis.},
  archive      = {J_KBS},
  author       = {Qiyang Xiao and Yuhao Fang and Jiayuan Yan and Yong Jin and Lin Zhou},
  doi          = {10.1016/j.knosys.2025.114081},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114081},
  shortjournal = {Knowl. Based Syst.},
  title        = {On controllability of discrete-time multi-agent networks based on impulsive and switching systems},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STREAM-net: Spatio-temporal feature fusion network for robust rPPG signal measurement in remote health monitoring. <em>KBS</em>, <em>326</em>, 114080. (<a href='https://doi.org/10.1016/j.knosys.2025.114080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) has become a popular, non-invasive, contactless technique for detecting physiological signals with promising applications. The latest advancements employ deep learning to address the challenges, including motion artifacts, redundancy, and external noise in video-based rPPG signal extraction. To this end, we propose a bilateral spatio-temporal network for estimating blood volume pulse (BVP) signals by analyzing human physiological processes through video frames. The spatio-temporal branches leverage lateral attention and multi-scale feature integration to enhance the extraction of rPPG signals. The spatio-temporal lateral attention module integrates spatial-temporal features at higher and lower resolutions to preserve essential dependency between spatial and temporal data at different scales. Whereas, the multi-scale feature enhancement module encodes high-level features to refine spatial features further with distinct local and global representations. We conducted extensive experiments to validate the effectiveness and superior performance of the proposed method on two benchmark datasets. In cross-dataset validation, STREAM-Net achieved MAE accuracy of 1.151 and RMSE of 2.715 on the UBFC dataset, whereas MAE accuracy of 1.318 and MAPE of 1.384 on the PURE dataset. Cross-dataset testing on both benchmarks demonstrates the efficacy of our proposed approach. Given the importance of repeatability and reliability in clinical measurements, we also quantified predictive uncertainty of our model using Monte Carlo dropout. This analysis exhibited the robust performance and high repeatability of the proposed model, with uncertainty variance ranging from 0.0049 to 0.0113 across different dropout rates. The source code is publicly available at https://github.com/usmanraza121/STREAM-Net .},
  archive      = {J_KBS},
  author       = {Muhammad Usman and Milena Sobotka and Jacek Ruminski},
  doi          = {10.1016/j.knosys.2025.114080},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114080},
  shortjournal = {Knowl. Based Syst.},
  title        = {STREAM-net: Spatio-temporal feature fusion network for robust rPPG signal measurement in remote health monitoring},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving adversarial transferability via adaptive ensemble attack with post-optimization. <em>KBS</em>, <em>326</em>, 114079. (<a href='https://doi.org/10.1016/j.knosys.2025.114079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transferability of adversarial examples poses serious security threats to deep neural networks (DNNs), as it enables black-box attacks without access to target model details. Studying this phenomenon is crucial for understanding model vulnerabilities and enhancing the robustness and security of DNNs. Model ensemble adversarial attacks have proven to be an effective approach for improving adversarial transferability by leveraging adversarial information of multiple surrogate models. Although existing ensemble attack methods adopt various strategies to integrate surrogate models, they tend to underutilize the strengths of each model or exhibit insufficient model diversity, thus limiting further improvement in attack transferability. To address this issue, we propose an Adaptive Ensemble Attack with Post-Optimization (AEAPO). This method adopts a strategy analogous to mini-batch processing, performing iterative attacks using randomly selected surrogate subsets to reduce memory consumption and preserve model diversity. In the model ensemble attack process, we introduce an adaptive weight adjustment to fully exploit adversarial information from surrogate models and identify commonly vulnerable directions. To mitigate local overfitting to high-weight models and gradient oscillations during weight adaptation, we propose Lookahead gradient optimization with fast and slow gradients for smoother and more generalizable optimization. Additionally, a test model set is introduced in each attack iteration to evaluate and refine adversarial examples, preventing overfitting to the fixed set of surrogate models. Extensive experiments demonstrate that AEAPO outperforms existing methods in black-box scenarios on both normally trained and defense models, and can be effectively combined with various transfer-based attacks, validating its effectiveness and generality.},
  archive      = {J_KBS},
  author       = {Yun Zhang and Yan Wo},
  doi          = {10.1016/j.knosys.2025.114079},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114079},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving adversarial transferability via adaptive ensemble attack with post-optimization},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multi-label feature selection via adaptive dual-graph regularization. <em>KBS</em>, <em>326</em>, 114077. (<a href='https://doi.org/10.1016/j.knosys.2025.114077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Multi-Label Learning (PML) tackles the challenge of developing accurate models based on candidate label sets that include both ground-truth labels and noisy ones. However, high-dimensional data often limits the performance of existing methods. Furthermore, traditional Multi-Label Feature Selection (MFS) methods face challenges in accurately identifying the optimum feature subset from partial multi-label data. To solve these issues, we propose a novel method, Partial Multi-label Feature Selection via Adaptive Dual-graph Regularization (PMFS-ADG). First, we leverage low-rank constraints and sparse representation to model the global relationships among labels, recovering the ground-truth label distribution from the original label space and distinguishing noisy labels. Then, adaptive dual-graph regularization is introduced to learn the non-linear geometric information of both the ground-truth label space and the feature space, enhancing label disambiguation while improving the discriminative ability of the selected features. The L 2 , 1 -norm is utilized to impose sparse constraints on the weight matrix, effectively removing irrelevant features. Furthermore, to ensure convergence, we design an efficient alternating optimization algorithm. Experimental results on both synthetic and genuine partial multi-label datasets demonstrate that the proposed method outperforms existing methods.},
  archive      = {J_KBS},
  author       = {Hao Xie and Ivy Liu and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.knosys.2025.114077},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114077},
  shortjournal = {Knowl. Based Syst.},
  title        = {Partial multi-label feature selection via adaptive dual-graph regularization},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing evolutionary multitasking for high-dimensional feature selection through task relevance evaluation and knowledge transfer. <em>KBS</em>, <em>326</em>, 114076. (<a href='https://doi.org/10.1016/j.knosys.2025.114076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a crucial step in machine learning that involves selecting the most relevant features from a dataset to enhance the performance of predictive models. Evolutionary multitasking (EMT), a powerful approach in this domain, achieves considerable success in high-dimensional FS for classification. However, current EMT-based FS methods focus solely on feature relevance but not task relevance, which affects the effectiveness and stability of subsequent knowledge transfer. Therefore, we propose a subtask relevance evaluation-based EMT method for high-dimensional classification FS. Specifically, this method introduces a novel multi-task generation strategy to obtain high-quality FS subtasks based on feature weights. Aiming at consideration of task similarity, we define a metric to evaluate the relevance of different subtasks. Using this metric, we convert the optimal subtask selection into the heaviest k -subgraph problem and obtain the optimal subtasks by branch-and-bound methods. Following this, based on guiding vectors, we propose an innovative knowledge transfer strategy during multi-task optimization to effectively facilitate beneficial knowledge transfer between related tasks, thereby improving the search capability and convergence speed of the algorithm. Extensive simulations on 21 high-dimensional datasets show that our proposed method outperforms various state-of-the-art FS methods. Furthermore, through experimental exploration, we have successfully determined the optimal values for the defined metric, providing a significant basis for subsequent research.},
  archive      = {J_KBS},
  author       = {Wenzheng Yu and Hui Kang and Jiahao Xu and Jiahui Li and Hongjuan Li and Geng Sun},
  doi          = {10.1016/j.knosys.2025.114076},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114076},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing evolutionary multitasking for high-dimensional feature selection through task relevance evaluation and knowledge transfer},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph network for online multiple object tracking. <em>KBS</em>, <em>326</em>, 114072. (<a href='https://doi.org/10.1016/j.knosys.2025.114072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Multiple Object Tracking (MOT), target interactions and occlusions in dense scenes increase the risk of identity changes for similar targets. To overcome these challenges, the use of higher-order semantic relations can accurately capture complex target interactions and help distinguish similar targets in complex environments. However, due to the heterogeneous nature of semantic cues, traditional methods struggle to efficiently integrate such cues into a unified framework, which limits the effective acquisition of higher-order semantic relations and affects the stability and accuracy of tracking. To overcome these issues, this paper transforms the MOT problem into a task for solving node relations in heterogeneous bipartite graphs and proposes a Heterogeneous Graph Network (HGN) model for capturing higher-order semantic relations. Compared to other approaches, the advantage of this model lies in the integration of heterogeneous clues into the model by constructing different semantic edges within the heterogeneous bipartite graph. To further improve the tracking efficiency, a Latent Trajectory Generation (LTG) module is introduced to predict and identify latent target trajectories to speed up the HGN solving process. Experimental results show that this model improves Multiple Object Tracking Accuracy (MOTA) results in the MOTchallenge and DanceTrack by 1–4 %, with minimal impact on processing speed. For ease of reading, this paper summarizes some key Nomenclature in Table 1 .},
  archive      = {J_KBS},
  author       = {Junwen Zhang and Xiaolong Zhang and Ziqi Zhu and Chunhua Deng},
  doi          = {10.1016/j.knosys.2025.114072},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114072},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous graph network for online multiple object tracking},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional implicit degradation estimation for real-world image super-resolution under spatially variant degradation. <em>KBS</em>, <em>326</em>, 114071. (<a href='https://doi.org/10.1016/j.knosys.2025.114071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most methods used for addressing spatially variant degradation (SVD) explicitly estimate degradation factors (e.g., blur kernels) to guide image super-resolution (SR). However, owing to the varied nature of real-world SVD, accurately estimating the degradation factors is difficult. A method that extracts an implicit degradation representation reflecting the spatial variation characteristic of real-world SVD is required to address this difficulty. In this study, we propose a three-dimensional implicit-degradation-estimation-based SR network (TDSR) to address real-world SVD. The TDSR consists of a three-dimensional implicit degradation estimator (3D-IDE) and an SR network. Specifically, the 3D-IDE extracts 3D implicit degradation representation (3D-IDR) from low-resolution (LR) images, which contain spatial and channel-wise degradation information. Furthermore, we design channel-split process, spatial attention, and information fusion modules to enable the SR network to fully leverage the information obtained from the 3D-IDR. Extensive experiments on synthetic and real-world LR images show that the proposed TDSR not only yields favorable results but also exhibits state-of-the-art performance under spatially invariant degradation conditions.},
  archive      = {J_KBS},
  author       = {Rui Xie and Tingting Leng and Xiaolong Xiong and Chuan Liu and Jun Zhou},
  doi          = {10.1016/j.knosys.2025.114071},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114071},
  shortjournal = {Knowl. Based Syst.},
  title        = {Three-dimensional implicit degradation estimation for real-world image super-resolution under spatially variant degradation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Textual emotion detection with complementary BERT transformers in a condorcet’s jury theorem assembly. <em>KBS</em>, <em>326</em>, 114070. (<a href='https://doi.org/10.1016/j.knosys.2025.114070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a novel approach to textual emotion detection (TED) in Spanish and English, leveraging an ensemble of partially trained BERT transformers within a Condorcet’s Jury Theorem (CJT) framework. Recognizing the challenges of limited training data and the complexities of emotion classification, this research investigates whether a combination of BERT models in the CJT ensemble can enhance performance even when individual models have incomplete training. The study evaluates different BERT modalities (BERT, RoBERTa, DistilBERT) and datasets, including SemEval-2018, XED, and Dair-ai/emotion. The main contribution is the development of a CJT ensemble, specifically the Jury Dynamic (JD), a key contribution of this research. This algorithm is designed for deployment in unsupervised production environments, eliminating the need for labeled data or continuous human supervision, leveraging Reinforcement Learning (RL). The Jury Dynamic (JD) adapts to incoming data, making it suitable for real-time applications. Experiments involve retraining BERT models with varying levels of emotional data reduction to simulate incomplete training. Results demonstrate that the CJT ensemble, particularly the JD, can effectively mitigate the negative impacts of limited training data, achieving comparable performance to fully trained models and outperforming individual models. The study highlights the importance of high-quality datasets for TED, particularly in Spanish, and proposes future research directions, including the evaluation of various classifiers and ensemble configurations.},
  archive      = {J_KBS},
  author       = {Gerardo Bárcena Ruiz and Richard De Jesús Gil Herrera},
  doi          = {10.1016/j.knosys.2025.114070},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114070},
  shortjournal = {Knowl. Based Syst.},
  title        = {Textual emotion detection with complementary BERT transformers in a condorcet’s jury theorem assembly},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-branch bidirectional coupled interaction fusion network for multi-retinal diseases diagnosis. <em>KBS</em>, <em>326</em>, 114069. (<a href='https://doi.org/10.1016/j.knosys.2025.114069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color fundus photography (CFP) serves as an effective screening tool for retinal disease (RD). The advancement of artificial intelligence (AI) technologies has significantly improved the ability to identify RD based on CFP. However, most existing AI-assisted models are tailored specifically to a single RD and are developed using private and single-source datasets. This results in limited generalizability, posing challenges in achieving reliable recognition and classification of multiple retinal diseases (MRDs) in real-world clinical practice. To tackle these issues, we collect 16 public CFP datasets, covering 16 retinal conditions. The inherent diversity introduced by multi-source MRD datasets presents substantial challenges for feature extraction in MRD diagnostics, thereby constraining its clinical applicability. We propose the Bi-Branch bidirectional coupled interaction fusion network (BBCIF-Net) for MRD diagnosis. The concurrent dual-branch architecture in BBCIF-Net effectively integrates the local features from convolutional neural networks with the global representation provided by transformers. Consequently, it enhances the multi-fold feature extraction capabilities for MRD. The coupling interaction between the dual branches occurs across multiple feature spaces, facilitated by the bidirectional feature coupling unit. Additionally, we adopt redundant feature elimination strategies in both branch networks. This approach not only enables the model to better focus on combining key characteristics of the diseases but also compresses the model’s parameters to a certain extent. The comprehensive experimental results demonstrate the effectiveness of the proposed method in MRD identification and two disease grading tasks. Our code is available at: https://github.com/SB-Chen/MRDs-BBCIF-Net .},
  archive      = {J_KBS},
  author       = {Shaobin Chen and Tao Tan and Xinyu Zhao and Wei Ke and Xiayu Xu and Yanwu Xu and Guoming Zhang and Chan-Tong Lam and Yue Sun},
  doi          = {10.1016/j.knosys.2025.114069},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114069},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bi-branch bidirectional coupled interaction fusion network for multi-retinal diseases diagnosis},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid model for low-resource language text classification and comparative analysis. <em>KBS</em>, <em>326</em>, 114068. (<a href='https://doi.org/10.1016/j.knosys.2025.114068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: The growing digital content in many languages helps users share diverse information. However, classifying user reviews is time-consuming and biased. Transformers like BERT excel in NLP, but low-resource languages still face challenges due to limited data, computational resources, and linguistic tools. Objective: The objective of this paper is twofold: (1) to evaluate and compare existing text classification methods using a newly annotated dataset for Malay, a low-resource language; and (2) to propose a new hybrid model for classifying low-resource languages that combines rule-based linguistic features with transfer learning approaches. Methods: For this analysis, five tools—LangDetect, spaCy, FastText, XLM-RoBERTa and LLaMA were applied. The study compares these tools against a low-resource dataset (Malay) to identify gaps and limitations in performance. The research focuses on several main areas: (i) Challenges in Low-Resource Languages, (ii) Comparative Analysis, (iii) Proposed Model, and (iv) Empirical Evaluation. The dataset includes 74,931 user reviews from Google Play Store apps (MyBayar, PDRM, MyJPJ, and MySejahtera). A subset of 2621 reviews was selected and annotated by two independent coders, and Fleiss’ Kappa was used to ensure reliable agreement for a ground-truth dataset. Results: The proposed hybrid model demonstrated statistically significant improvements in classification performance, achieving an accuracy of 84 %. Paired t-tests further confirm these improvements, showing significant differences in F1-score compared to baseline methods (p < 0.05). Conclusion: Findings emphasize the need for tailored NLP approaches for underrepresented languages, showing the importance of custom models to handle language diversity and further development in low-resource language.},
  archive      = {J_KBS},
  author       = {Amran Salleh and Mohd Hafeez Osman and Sa’adah Hassan and Mar Yah Said and Khaironi Yatim Sharif and Koh Tieng Wei},
  doi          = {10.1016/j.knosys.2025.114068},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114068},
  shortjournal = {Knowl. Based Syst.},
  title        = {A hybrid model for low-resource language text classification and comparative analysis},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TA-EnVODT: A cloud-edge integrated temporal-aware ensemble for real-time video object detection and tracking using knowledge projection. <em>KBS</em>, <em>326</em>, 114067. (<a href='https://doi.org/10.1016/j.knosys.2025.114067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object detection and tracking (VODT) is essential in computer vision applications such as surveillance, video analytics, and autonomous systems. However, maintaining detection accuracy across consecutive frames poses challenges in high-performance video analytics (HPVA) due to motion blur, occlusions, and temporal variations. This paper introduces a Cloud-Edge integrated temporal-aware ensemble video object detection and tracking (TA-EnVODT) model to address these challenges and enable robust real-time VODT in complex scenes. Our approach integrates one- and two-stage detection models, incorporating suitable RNNs in pairs such as YOLOv5-LSTM, SSD-GRU, and Faster R-CNN-LSTM, ensuring consistent detection and tracking across video frames. We employ a weighted boxes fusion algorithm to merge bounding box predictions, generating an optimal bounding box (OBB) for each object. This design enables multi-scale object detection while preserving long-range dependencies in video sequences. A lightweight meta-learner using Tiny YOLOv5-LSTM is designed for the Edge device to perform real-time VODT. We introduce a knowledge projection strategy for distilling the knowledge from the TA-EnVODT to the meta-learner, enhancing performance by utilizing efficient loss functions. Evaluated on benchmark video datasets, the TA-EnVODT achieves better precision, recall, and FPS while reducing end-to-end delay by weighting OBB predictions based on confidence scores, making it well-suited for VODT in Cloud-Edge environments.},
  archive      = {J_KBS},
  author       = {Sudha S K and Aji S},
  doi          = {10.1016/j.knosys.2025.114067},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114067},
  shortjournal = {Knowl. Based Syst.},
  title        = {TA-EnVODT: A cloud-edge integrated temporal-aware ensemble for real-time video object detection and tracking using knowledge projection},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-DiffAug: Enhancing few-shot object detection via LLM-guided diffusion augmentation. <em>KBS</em>, <em>326</em>, 114066. (<a href='https://doi.org/10.1016/j.knosys.2025.114066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot object detection remains challenging due to limited training data for novel classes. While diffusion models have shown promise for data augmentation, their full potential for generating diverse and informative samples has yet to be realized. In this paper, we present LLM-DiffAug, a novel framework that leverages Large Language Models (LLMs) to enhance the diversity of generated samples for few-shot object detection. By harnessing the rich semantic knowledge encoded in LLMs, our approach generates diverse and contextually meaningful prompts that guide diffusion models to produce more varied and informative samples. Besides, we further introduce two key components to make generated data more suitable for object detection tasks: an Inpaint Alignment (IA) module to ensure generated images match their corresponding prompts, and box constraints (BC) that ensure generated objects properly fit within designated bounding boxes. We evaluate our method in few-shot settings on PASCAL VOC and COCO benchmarks, where experimental results demonstrate significant improvements over baselines and state-of-the-art approaches. Our code will be publicly available at https://github.com/jayyuci/LLM-DiffAug .},
  archive      = {J_KBS},
  author       = {Yunqing Jiang and Sunyuan Qiang and Wuchen Li and Yanyan Liang},
  doi          = {10.1016/j.knosys.2025.114066},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114066},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-DiffAug: Enhancing few-shot object detection via LLM-guided diffusion augmentation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large language model-driven reward design framework via dynamic feedback for reinforcement learning. <em>KBS</em>, <em>326</em>, 114065. (<a href='https://doi.org/10.1016/j.knosys.2025.114065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have shown significant potential in designing reward functions for Reinforcement Learning (RL) tasks. However, obtaining high-quality reward codes often involves human intervention, numerous LLM queries, or per-iteration RL training. To address these issues, we propose CARD, an LLM-driven Reward Design framework that generates and improves reward function code iteratively. Specifically, CARD includes a Coder that generates and verifies the code, while an Evaluator provides dynamic feedback to improve the code. We introduce Trajectory Preference Evaluation (TPE), which evaluates the current reward function based on trajectory preferences. The Evaluator constructs the feedback based on whether the code passes TPE dynamically, thus avoiding repetitive RL training. Empirical results on Meta-World and ManiSkill2 demonstrate that our method outperforms or matches the baselines across all tasks. On 10 out of 12 tasks, CARD shows better or comparable performance to policies trained with expert-designed rewards and even surpasses the oracle on 3 tasks.},
  archive      = {J_KBS},
  author       = {Shengjie Sun and Runze Liu and Jiafei Lyu and Jing-Wen Yang and Liangpeng Zhang and Xiu Li},
  doi          = {10.1016/j.knosys.2025.114065},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114065},
  shortjournal = {Knowl. Based Syst.},
  title        = {A large language model-driven reward design framework via dynamic feedback for reinforcement learning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-LADE: Large language model-based log anomaly detection with explanation. <em>KBS</em>, <em>326</em>, 114064. (<a href='https://doi.org/10.1016/j.knosys.2025.114064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of software systems and the exponential growth of log data have made anomaly detection and fault localization from massive logs a critical research area. However, existing log anomaly detection methods struggle to capture context-dependent semantic relationships present in unstructured logs and lack explainable decision-making mechanisms, substantially restricting their applicability in complex systems. The present study proposes LLM-LADE, a novel large language model (LLM)-based framework for log anomaly detection and explanation. LLM-LADE introduces a three-stage coordinated architecture encompassing ‘data augmentation - parameter-efficient fine-tuning (PEFT) - online optimization’, representing the first implementation of LLMs for simultaneous anomaly discrimination and explanation generation in log sequences. The framework overcomes the interpretability limitations of conventional approaches through a joint learning objective of label-cause pairs. An incrementally matched knowledge base mechanism is designed to enable zero-parameter-update online optimization via real-time capture of misjudged samples, ensuring continuous adaptability to dynamic logging environments. Experimental results on three benchmark datasets demonstrate that LLM-LADE outperforms current state-of-the-art algorithms in detection performance, with explanations generated exhibiting professional-grade usability in terms of both informativeness and readability.},
  archive      = {J_KBS},
  author       = {Zhiwei Zhang and Saifei Li and Lijie Zhang and Jianbin Ye and Chunduo Hu and Lianshan Yan},
  doi          = {10.1016/j.knosys.2025.114064},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114064},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-LADE: Large language model-based log anomaly detection with explanation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DACMF-DTI: Dual attention embedded cross-modality fusion for drug-target interaction prediction. <em>KBS</em>, <em>326</em>, 114063. (<a href='https://doi.org/10.1016/j.knosys.2025.114063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the efficiency of drug discovery and reuse, an increasing number of researchers are employing computational methods to predict drug-target interactions (DTI). However, existing models solely focus on the impact of one molecule on the other, disregarding the mutual interactions between the local substructures of the drug and the target. In this paper, we propose a novel deep neural network named DACMF-DTI to address these issues. In our network, we first employed the 1D-CNN structure to extract distinct molecular features from both the drug and target. In addition, we designed a dual attention module to simulate the actual biological DTI process, enabling the network to capture post-interaction features between molecular substructures, revealing the specific substructures that contribute to the interaction. Subsequently, the features corresponding to the interactions among multiple substructures within the drug and target as well as the individual molecular features of the drug and target are jointly input into the multi-head self-attention fusion module, which enhances flexibility in acquiring and integrating molecular features across various scales, thereby capturing more comprehensive fusion features. We conduct extensive experiments on three well-known benchmark datasets to verify the effectiveness of the proposed network. The experimental results significantly demonstrate its superiority over other state-of-the-art ones. The code is accessible at https://github.com/hey-xw/DACMF-DTI .},
  archive      = {J_KBS},
  author       = {Ziyu Wei and Xiao Zheng and Chuankun Li and Minhui Wang and Chang Tang},
  doi          = {10.1016/j.knosys.2025.114063},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114063},
  shortjournal = {Knowl. Based Syst.},
  title        = {DACMF-DTI: Dual attention embedded cross-modality fusion for drug-target interaction prediction},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive in-context expert network with hierarchical data augmentation for sequential recommendation. <em>KBS</em>, <em>326</em>, 114061. (<a href='https://doi.org/10.1016/j.knosys.2025.114061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based sequential recommendation systems have achieved remarkable success by modeling higher-order item dependencies. However, they often struggle to learn robust sequence representations in the presence of data sparsity, interaction noise, and cold-start issues. To address these issues, we propose a general framework named adaptive In- C ontext e xpert network with hierarchical D ata augmentation for sequential Rec ommendation (CeDRec). Specifically, inspired by the hierarchical structure of text, we introduce a deep data augmentation method, DAug, which operates on higher-level semantic units to reconstruct users’ general preferences by capturing the interconnectivity of subsequences in latent space. Moreover, we design an adaptive in-context expert network that incorporates additional context experts to dynamically allocate attention weights, effectively alleviating the impact of noisy interactions. To further enhance the representation of unpopular items and improve overall recommendation quality, we introduce a mimic learning module that encourages popular items to approximate the distribution of unpopular ones, thereby providing richer self-supervision signals for underrepresented items. Extensive experiments show that CeDRec significantly outperforms state-of-the-art baselines in recommendation accuracy. Our model is capable of learning accurate and robust item representations even when faced with the problem of sparse interaction.},
  archive      = {J_KBS},
  author       = {Xiujuan Sun and Fuzhen Sun and Yihao Wang and Shouda Song and Weiyan Tang and Shaoqing Wang},
  doi          = {10.1016/j.knosys.2025.114061},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114061},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive in-context expert network with hierarchical data augmentation for sequential recommendation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Category relationship enhancement transformer for industrial defect segmentation. <em>KBS</em>, <em>326</em>, 114059. (<a href='https://doi.org/10.1016/j.knosys.2025.114059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of industrial manufacturing, using deep learning for intelligent defect detection has become crucial for quality control. However, in real industrial environments, defects belonging to the same category can vary in appearance, while those across different categories might appear similar, leading to misclassification. Additionally, the inconspicuousness of the defects and the complexity of their backgrounds further complicate detection. To address these challenges, we propose the Category Relationship Enhancement Transformer (CRET) that incorporates an Intra-Inter Class Relationship Enhancement Module (ICREM) with a Class Token Contrastive (CTC) loss into hierarchical vision transformer architectures, expanding the inter-class and narrowing the intra-class feature distances, thereby improving the ability of the model for recognizing defect categories. Additionally, to enhance the model’s detection capability for weak defects in complex backgrounds, we integrate a CNN feature stream and inject it into the Transformer using our designed Feature Semantic-balanced Bridge Module (FSBM), which maximizes the use of the CNN feature to focus on local details. Experiments on the NEU, Rubber, and FPCB datasets demonstrate that the proposed CRET outperforms the mainstream networks. Code is available at https://github.com/luojxscut .},
  archive      = {J_KBS},
  author       = {Zican Hu and Jiaxiang Luo and Zixiang Hong},
  doi          = {10.1016/j.knosys.2025.114059},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114059},
  shortjournal = {Knowl. Based Syst.},
  title        = {Category relationship enhancement transformer for industrial defect segmentation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative approach for obstacle avoidance and path planning of mobile robot using adaptive deep reinforcement learning for indoor environment. <em>KBS</em>, <em>326</em>, 114058. (<a href='https://doi.org/10.1016/j.knosys.2025.114058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the use of mobile robots used in a wide range of applications like emergency assistance, space exploration, intelligent logistics, and agricultural and industrial production. In general, robots accomplish the task by moving autonomously. Path planning in the unknown environment is considered a major issue in the robotic field. For local path planning, one of the commonly used effective methods is the Dynamic Window Approach (DWA), which also has limitations in the evaluation performance and the selection of algorithm because of the lack of weight function that makes the global reference to highly dependent and failed in the unknown environment. In this context, the use of Reinforcement Learning (RL) for obstacle avoidance algorithms and path planning has become increasingly popular in recent years. So, in this work, we developed an innovative RL-based model for obstacle avoidance and path planning of mobile robots for indoor environments to tackle the existing challenges. At first, the needed data are collected from the standard data sources. Further, the collected data is given to the obstacle avoidance and path planning phase. This phase is done by Adaptive Deep Reinforcement Learning (ADRL) to execute the effective process. Here, the parameters are tuned by using the Revised Pine Cone Optimization (RPCO) to improve the process. Finally, the developed model provides the classified outcome. Then, the effectiveness of the suggested model is contracted with numerous baseline systems to showcase the effectiveness of other models.},
  archive      = {J_KBS},
  author       = {R. Karthikeyan and B. Sheela Rani},
  doi          = {10.1016/j.knosys.2025.114058},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114058},
  shortjournal = {Knowl. Based Syst.},
  title        = {An innovative approach for obstacle avoidance and path planning of mobile robot using adaptive deep reinforcement learning for indoor environment},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JISS: Joint image super-resolution and segmentation of magnetic resonance images via disentangled representation learning. <em>KBS</em>, <em>326</em>, 114057. (<a href='https://doi.org/10.1016/j.knosys.2025.114057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image super-resolution (SISR) algorithms that utilize deep learning techniques have demonstrated significant promise in reconstructing high-resolution (HR) magnetic resonance (MR) images from low-resolution (LR) inputs. Nonetheless, many of these approaches depend on supervised training with paired LR and HR MR images, which can be challenging to acquire in clinical practice. In this paper, we address the image super-resolution problem with resolution translation from the LR domain to the HR domain by restoring high-frequencies, and thus propose a joint image super-resolution and segmentation (JISS) method, integrating an unsupervised disentangled resolution translation (DRT) module and a semi-supervised entropy-guided semantic segmentation (ESS) module into one end-to-end trainable network. In particular, the DRT module is trained using unpaired LR and HR images while the ESS module is trained on labeled HR images and unlabeled super-resolved HR images which are generated by the DRT module. Through the joint optimization, the two parts can benefit from each other. Additional advantages of the proposed method include: 1) it removes the necessity for paired LR and HR images during training stage; 2) we only need to train a single model to handle image super-resolution of different scales; and 3) the trained model can generate both a super-resolved HR image and the corresponding semantic segmentation from an LR input. Comprehensive experiments are conducted on two public datasets, i.e., the OAI-ZIB dataset which includes 507 knee MR volumes and the HCP-1200 dataset which comprises 1113 brain MR volumes. The results of the experiments exhibit that the proposed JISS method is better than the state-of-the-art (SOTA) methods.},
  archive      = {J_KBS},
  author       = {Jiale Wang and Guoyan Zheng},
  doi          = {10.1016/j.knosys.2025.114057},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114057},
  shortjournal = {Knowl. Based Syst.},
  title        = {JISS: Joint image super-resolution and segmentation of magnetic resonance images via disentangled representation learning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A2CEM: A contrastive embedding framework for adversarial robustness in large language models. <em>KBS</em>, <em>326</em>, 114056. (<a href='https://doi.org/10.1016/j.knosys.2025.114056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous Natural Language Processing (NLP) tasks, yet they remain vulnerable to adversarial prompts that can trigger misleading or factually incorrect outputs. While most existing defenses focus on detecting manipulations at the prompt level, they fail to model how such perturbations propagate into the generated responses. To address this gap, we propose A2CEM (Adversarially-Aware Contrastive Embedding Model), a hierarchical contrastive learning framework that learns to disentangle adversarially influenced responses from natural ones in the embedding space. A2CEM captures adversarial patterns across three linguistic levels-token, sentence, and context-and leverages a novel positive-aware hard-negative mining strategy with a margin-based separation objective. We construct a large-scale benchmark of 39,648 prompt-response pairs spanning ten domains and multiple adversarial strategies. Empirical results show that A2CEM outperforms strong baselines such as SimCSE, ANCE, and BGE, achieving up to 8.5 % F1 gain in adversarial classification and 4.58 % BLEURT improvement in factual consistency evaluation.},
  archive      = {J_KBS},
  author       = {Ahmet Emre Ergün and Aytuğ Onan},
  doi          = {10.1016/j.knosys.2025.114056},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114056},
  shortjournal = {Knowl. Based Syst.},
  title        = {A2CEM: A contrastive embedding framework for adversarial robustness in large language models},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinated path planning for autonomous ground vehicles in off-road environments with 3D rigid terrain and obstacles. <em>KBS</em>, <em>326</em>, 114055. (<a href='https://doi.org/10.1016/j.knosys.2025.114055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating safe, smooth, and efficient path is a fundamental and difficult task for autonomous ground vehicles (AGVs) in off-road environments with 3D rigid terrain and obstacles. In this paper, a coordinated path planning approach is proposed to deal with the influence of off-road terrains and obstacles systematically for the path planning of AGVs. The proposed approach consists of integrated traversable area assessment (ITAA) layer and path planning and path optimization (PPPO) layer. In the ITAA layer, a hierarchical map model is established to solve the problem of difficult off-road terrain evaluation in path planning. Based on the hierarchical map, we evaluated the slope, maximum height difference, and roughness of the off-road terrain. In addition, we also model the vehicle’s motion capabilities on off-road roads, including off-road vehicle pose estimation, longitudinal stability analysis, and static stability analysis. For the PPPO layer, a reference path generation method considering terrain is proposed to generate a passable reference path that meets the vehicle’s kinematic constraints and static stability requirements. Based on the generated reference path, a path optimization method based on a differential flat model is proposed to generate the optimal path, where a safe driving corridor method is established to ensure the safety of the vehicle. Finally, the proposed coordinated path planning approach is validated in both simulations and real-vehicle, and experimental results demonstrate that the proposed system can plan a feasible path fast with the constraints from vehicle kinematics, obstacle avoidance and off-road terrains.},
  archive      = {J_KBS},
  author       = {Zheng Zang and Xiaojie Gong and Xi Zhang and Jianwei Gong},
  doi          = {10.1016/j.knosys.2025.114055},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114055},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coordinated path planning for autonomous ground vehicles in off-road environments with 3D rigid terrain and obstacles},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent chatbot dialogue breakdown solutions and challenges: A systematic literature review. <em>KBS</em>, <em>326</em>, 114054. (<a href='https://doi.org/10.1016/j.knosys.2025.114054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatbots are being widely used by businesses worldwide to offer customer service and facilitate interactions with their clients. They are becoming increasingly advanced due to their foundation in artificial intelligence and natural language processing, enabling them to address complicated requests and responses. However, chatbots face numerous issues and challenges that could potentially result in low-quality outcomes. One of these issues is chatbot dialogue breakdown, an issue which needs to be solved to enhance user satisfaction and elevate the chatbot quality of service. Although there are several reviews related to chatbots, this is the first review to focus on chatbot dialogue breakdown. In this study, we comprehensively discuss intelligent solutions for chatbot dialogue breakdown. We apply a systematic literature review approach to identify and analyze the methodologies and the datasets used with their evaluation metrics to answer our two key questions. Then, we comprehensively examine studies that offer intelligent solutions to dialogue breakdowns and compare them with our defined requirements to build a chatbot dialogue breakdown early warning system. Finally, based on the findings, we identify seven areas of open challenges that could guide future research.},
  archive      = {J_KBS},
  author       = {Khuloud Alshawkani and Farookh Khadeer Hussain},
  doi          = {10.1016/j.knosys.2025.114054},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114054},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intelligent chatbot dialogue breakdown solutions and challenges: A systematic literature review},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XKanFuse: A novel cross-modal fusion method based on kolmogorov-arnold network for multi-modal medical image fusion. <em>KBS</em>, <em>326</em>, 114053. (<a href='https://doi.org/10.1016/j.knosys.2025.114053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal medical image fusion enables the integration of complementary information from different medical imaging modalities, providing comprehensive insights for clinic applications and diagnosis. Nevertheless, existing methods exhibit considerable potential for improvement in terms of fusion accuracy for insufficient feature representation and cross-modal interaction. To tackle these challenges, a novel cross-modal fusion algorithm based on Kolmogorov–Arnold Network (Kan) for multi-modal medical image fusion is proposed to improve fusion performance, namely, XKanFuse. Specifically, the XKanFuse introduces an innovative Adaptive Kan Convolution (ACKan), which enables precise local-global nonlinear characterization via the adaptive perception mechanism coupled with learnable nonlinear functions, thereby significantly enhancing feature representation. Additionally, the newly designed Cross-Kansformer (XKansformer) in XKanFuse enables effective cross-modal exchange and capture of multi-scale attention flows. By incorporating learnable nonlinear transformations, it reinforces multi-level complementarity and integration, thereby facilitating precise cross-modal interaction and fusion. Extensive quantitative and qualitative experiments on various medical datasets demonstrate the proposed XKanFuse outperforms state-of-the-art methods regarding accuracy on salient regions and edge sharpness, offering superior fusion and significant clinic application potential.},
  archive      = {J_KBS},
  author       = {Xinjian Wei and Yafei Xiong and Haotian Lu and Xiaoxuan Xu and Jing Xu},
  doi          = {10.1016/j.knosys.2025.114053},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114053},
  shortjournal = {Knowl. Based Syst.},
  title        = {XKanFuse: A novel cross-modal fusion method based on kolmogorov-arnold network for multi-modal medical image fusion},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-ACR: A new architecture for real-time object detection with advanced feature fusion and bounding box regression. <em>KBS</em>, <em>326</em>, 114052. (<a href='https://doi.org/10.1016/j.knosys.2025.114052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the YOLO series has achieved remarkable progress in the field of real-time object detection, striking a favorable balance between speed and accuracy. However, challenges still persist in feature representation and bounding box regression, especially in scenarios involving dense objects, overlapping instances, and small object detection. To enhance detection performance, this paper proposes an improved architecture based on YOLOv11, named YOLO-ACR, which introduces enhancements in feature fusion, structural design, and regression optimization. Specifically, YOLO-ACR incorporates the CASAFF module, which adaptively fuses channel and spatial features to effectively strengthen the model’s multi-scale representation capability. The proposed C3k2-RV structure draws on the efficient design of RepVGG, achieving a balance between lightweight architecture and feature extraction capability. For bounding box localization, we introduce the IS-MPDIoU loss function, which combines the spatial distance between bounding boxes and the overlap ratio of internal regions, and incorporates a dynamic scaling and coordinate distribution modeling mechanism to significantly improve regression precision and model robustness. Experiments on the PASCAL VOC dataset demonstrate that YOLO-ACR consistently outperforms YOLOv11 across different model scales: achieving a 1.7 % improvement in mAP 50 for the large-scale model (approximately 59M parameters), a 2.7 % improvement for the medium-scale model (approximately 38M parameters), and a 0.5 % improvement for the small-scale model (approximately 9.5M parameters). Furthermore, the proposed method also achieves noticeable performance improvements on the COCO2017 dataset.},
  archive      = {J_KBS},
  author       = {Ferrante Neri and Mengchen Yang and Yu Xue},
  doi          = {10.1016/j.knosys.2025.114052},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114052},
  shortjournal = {Knowl. Based Syst.},
  title        = {YOLO-ACR: A new architecture for real-time object detection with advanced feature fusion and bounding box regression},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A front-back view fusion strategy and a novel dataset for super tiny object detection in remote sensing imagery. <em>KBS</em>, <em>326</em>, 114051. (<a href='https://doi.org/10.1016/j.knosys.2025.114051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super tiny objects (STOs) are frequently submerged in complex backgrounds of remote sensing and natural images, which brings major challenges for existing learning-based object detection methods. Currently, You Only Look Once (YOLO) is one of the most widely used mainstream methods in the field of object detection. However, its performance on STOs detection is still not satisfactory. The biggest challenge lies in the network’s difficulty in effectively extracting the scarce geometric and spectral information of STOs. Towards this end, a front-back view fusion (FBV-Fusion) strategy compatible with the famous YOLO framework is proposed. Firstly, to prevent background information from overwhelming STOs features, a target mask is generated through the YOLO backbone, dividing the feature layer into target and background regions. Then, to enhance the utilization of feature extraction in the target area and background information, the skip convolution replaces all normal convolution in YOLO neck, focusing on the features of the target region. The feature layer size is increased to mitigate the information loss of STOs at the source. Moreover, to address the scarcity of datasets and the imbalance of samples for remote sensing STOs detection, a novel dataset called super tiny object detection for remote sensing (RS-STOD) dataset was constructed. To evaluate its generalization capability and the effectiveness of FBV-Fusion, the experiments were conducted on RS-STOD, AI-TOD and TinyPerson. Meanwhile, the FBV-Fusion strategy was validated across YOLOv5, v7, v9, v10 and v11. The results demonstrate that FBV-Fusion outperforms other state-of-the-art (SOTA) methods. The related code and RS-STOD are public available at https://github.com/lixinghua5540/FBVF-YOLO .},
  archive      = {J_KBS},
  author       = {Xuechen Bai and Xinghua Li and Jianhao Miao and Huanfeng Shen},
  doi          = {10.1016/j.knosys.2025.114051},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114051},
  shortjournal = {Knowl. Based Syst.},
  title        = {A front-back view fusion strategy and a novel dataset for super tiny object detection in remote sensing imagery},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-GAODE: Large-language-model augmented neural ordinary differential equation network for video nystagmography classification. <em>KBS</em>, <em>326</em>, 114050. (<a href='https://doi.org/10.1016/j.knosys.2025.114050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benign paroxysmal positional vertigo (BPPV), a common type of vertigo with complex etiologies, is traditionally diagnosed using video nystagmography (VNG). Current automated methods lack diagnostic precision owing to subjective interpretation of eye movement characteristics. To address these challenges, we introduce a l arge l anguage m odel-augmented G ram-based a ttentive neural o rdinary d ifferential e quation ( LLM-GAODE ), an innovative and data-driven framework integrating eye-tracking technology with a Gram-based attention mechanism and a neural ordinary differential equation network to improve BPPV classification. Furthermore, when the neural network exhibits low confidence in its predictions, an LLM can supplement the process with advanced reasoning in natural language. LLM-GAODE was evaluated using an extensive VNG dataset provided by a collaborative university hospital. Results suggest that LLM-GAODE significantly outperforms existing benchmarks in trajectory classification for BPPV diagnosis. The framework enhances BPPV diagnostic accuracy and achieves state-of-the-art performance in open-source trajectory classification benchmarks. The code is available at https://github.com/XiheQiu/LLM-GAODE .},
  archive      = {J_KBS},
  author       = {Xihe Qiu and Shaojie Shi and Bin Li and Xiaoyu Tan and Yongbin Gao and Shuo Li},
  doi          = {10.1016/j.knosys.2025.114050},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114050},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-GAODE: Large-language-model augmented neural ordinary differential equation network for video nystagmography classification},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An fMRI visual neural encoding method with multimodal large language model. <em>KBS</em>, <em>326</em>, 114049. (<a href='https://doi.org/10.1016/j.knosys.2025.114049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal large language models (MLLMs) are revolutionizing the field of artificial intelligence by integrating diverse data types, such as text and image, into a unified representational framework. These foundation models leverage the power of deep learning and attention mechanisms to capture the intricate relationships between modalities, enhancing feature extraction and understanding. However, MLLM’s potential in the field of brain visual information processing has not been fully explored. Research has found that text semantic information is an important additional information in the brain's visual information processing. Based on the current state of development, this paper proposes a functional magnetic resonance imaging (fMRI) visual encoding method with the MLLM. The proposed method designs a visual encoding model based on MLLM and a three-stage training/fine-tuning paradigm. The method constructs the MLLM module by combining Vicuna with stimulus images and user instructions, then implements fMRI-based visual encoding through multi-subject fusion and voxel mapping modules. Our method utilizes the advantages of MLLM in cross-modal information processing, effectively integrating textual semantic information with visual information, capturing key features in visual information more accurately, and achieving more efficient visual encoding. Our method achieves a 2.87 % improvement in neural response prediction accuracy compared to non-LLM approaches. The experimental results indicate that the multimodal method achieves impressive performance in the MIT-hosted Algonauts 2023 Challenge, a benchmark for modeling human brain responses to visual stimuli. This method validates the effectiveness of MLLM, bringing new solutions for visual neural encoding.},
  archive      = {J_KBS},
  author       = {Shuxiao Ma and Linyuan Wang and Libin Hou and Senbao Hou and Bin Yan},
  doi          = {10.1016/j.knosys.2025.114049},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114049},
  shortjournal = {Knowl. Based Syst.},
  title        = {An fMRI visual neural encoding method with multimodal large language model},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE-GSSL: Soft-mask enhanced graph self-supervised learning with multi-aspect knowledge encoding and adaptive sample selection. <em>KBS</em>, <em>326</em>, 114048. (<a href='https://doi.org/10.1016/j.knosys.2025.114048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph self-supervised learning (GSSL) has garnered significant attention owing to its powerful expressive capabilities. It learns from unlabeled graph data through pretext tasks, such as AttributeMask, S 2 GRL, and GZL. However, most existing methods face challenges when performing these pretext tasks: (1) The model tends to select nodes whose features are easy to predict, resulting in the learned information being too simple and lacking actual semantic value. (2) The noise in node features can mislead the model to learn wrong information, which can easily lead to over-fitting and reduce generalization ability. To address these limitations, we propose a novel GSSL framework termed Selection-Enhanced GSSL (SE-GSSL) , which integrates sample selection into the learning paradigm. Furthermore, we introduce an end-to-end Soft-Mask-based SE-GSSL framework as a concrete implementation. First, we design multiple individual encoders to extract differentiated knowledge of node features and graph topology, and achieve complementary enhancement in fusion. Second, a multi-head global projection matrix with diversity regularization is presented to calculate the scores for all nodes to enhance the evaluation of node importance. Third, a new masking strategy called Soft-Mask is proposed to mask nodes, which can adaptively adjust the difficulties of different self-supervised reconstruction tasks. Finally, extensive experiments on various public graph benchmarks demonstrate that the proposed framework can achieve better or at least competitive performance compared to many other baselines or recent state-of-the-art methods in semi-supervised node classification and node clustering tasks.},
  archive      = {J_KBS},
  author       = {Yang-Geng Fu and Xinlong Chen and Shuling Xu and Jin Li and Qirong Zhang and Wen Meng and Genggeng Liu},
  doi          = {10.1016/j.knosys.2025.114048},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114048},
  shortjournal = {Knowl. Based Syst.},
  title        = {SE-GSSL: Soft-mask enhanced graph self-supervised learning with multi-aspect knowledge encoding and adaptive sample selection},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFDB: Multimodal feature fusion and dynamic behavior modeling for interactive recommendation systems. <em>KBS</em>, <em>326</em>, 114047. (<a href='https://doi.org/10.1016/j.knosys.2025.114047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems have shown its potential in online shopping and video push. However, previous methods struggle to effectively capture the dynamic changes in user behavior sequences while integrating multi-source heterogeneous data, resulting in difficulties in achieving precise, context-sensitive, and sustainably adaptive personalized recommendations that meet user needs. To address these challenges, this study introduces the MFDB (Multimodal Feature Fusion and Dynamic Behavior Modeling) framework, a novel approach based on interactive recommendation strategies. The MFDB framework employs Graph Neural Networks (GNN) and Transformer architectures to model multimodal item data and users’ long-term and short-term preferences, respectively. By conceptualizing multimodal contextual information as states and framing the recommendation process as a sequential decision-making procedure, the framework utilizes reinforcement learning techniques to guide model updates, dynamically incorporating user feedback and behavioral trajectories to ensure that decision-making aligns with user preferences. Extensive experimental results demonstrate that MFDB significantly outperforms various advanced baseline methods across multiple metrics on two real-world datasets, validating its ability to adaptively model user behavior characteristics and efficiently integrate multimodal data sources. This provides robust support for the development of recommendation systems with enhanced robustness and contextual sensitivity.},
  archive      = {J_KBS},
  author       = {Rongxuan Wei and Jiaming Lan and Kangkang Li and Yu Luo and Yongbin Hu},
  doi          = {10.1016/j.knosys.2025.114047},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114047},
  shortjournal = {Knowl. Based Syst.},
  title        = {MFDB: Multimodal feature fusion and dynamic behavior modeling for interactive recommendation systems},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GLMP: Geometric prior learning with multimodal pre-training representation compensation for 3D human shape estimation. <em>KBS</em>, <em>326</em>, 114046. (<a href='https://doi.org/10.1016/j.knosys.2025.114046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating a full 3D human shape from a Single RGB Image is an important and challenging inverse task in virtual reality. Recent approaches apply deep learning to achieve significant success by learning geometric features from given images and corresponding 3D annotations of human datasets. However, humans in images are often occluded or self-occluded due to complex outdoor environments. Additionally, the difficulty in obtaining accurate 3D data means that most 3D annotations are inaccurate pseudo-labels generated by simulation software. These issues limit the effective learning of human geometric features, resulting in reduced performance of existing deep learning-based 3D human shape estimation methods. In this paper, to fully leverage the prior knowledge from such low-quality data (i.e.,), we propose a novel geometric prior learning approach with multimodal representation compensation for 3D human shape estimation. First, we design a multimodal pre-training task that reconstructs the human image and mesh from masked input data in a self-supervised manner, facilitating geometric prior learning for our network. Then, we use the pre-trained image and mesh network to guide and fine-tune the end-to-end human shape estimation framework. Evaluations across multiple public datasets show that our method clearly improves upon the baseline of previous work with more accurate human shapes, particularly in outdoor scenes with occlusion and inaccurate labeling.},
  archive      = {J_KBS},
  author       = {Feng Chen and Jilin Huang and Biao Jiang and Pingping Chen and Mengxi Jiang},
  doi          = {10.1016/j.knosys.2025.114046},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114046},
  shortjournal = {Knowl. Based Syst.},
  title        = {GLMP: Geometric prior learning with multimodal pre-training representation compensation for 3D human shape estimation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph anomaly detection via multi-level information alignment and decoupling. <em>KBS</em>, <em>326</em>, 114045. (<a href='https://doi.org/10.1016/j.knosys.2025.114045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Anomaly Detection (GAD) is crucial for identifying abnormal behaviors in various networks, such as those encountered in financial transaction systems and online social platforms. Existing methods are often confined to Local Inconsistency Mining (LIM), struggling to capture the complex characteristics of real-world anomalies from a global perspective. This paper reveals a novel global property of graph anomalies: although individual anomalous nodes may exhibit lower average global similarity, their collective presence can manifest a counter-intuitive “Pattern Concentration” in the distribution of global similarity scores. Specifically, they tend to significantly suppress the variance of the overall distribution of global similarity scores, diverging from the traditional notion of anomalies as simply dispersed outliers. This discovery fundamentally challenges the traditional notion of identifying anomalies solely from a local perspective and demonstrates that judging abnormality requires a comprehensive assessment across multiple information levels. Inspired by this insight, we propose MiLIAD (Multi-Level Information Alignment and Decoupling Framework), a novel unsupervised GAD framework designed specifically to address this challenge. MiLIAD integrates representations from three natural information levels: individual node, neighborhood, and global context. Its core Alignment and Decoupling mechanism learns consistency and complementarity among these levels without explicit negative sampling or data augmentation, identifying nodes deviating from normal patterns. Extensive experiments on 10 challenging real-world benchmark datasets against 12 SOTA baselines validate MiLIAD’s effectiveness. Results show MiLIAD achieves significant AUC and AUPRC improvements, demonstrating strong competitiveness, especially for complex real-world anomalies, and validating its efficacy in leveraging complex global anomaly signals.},
  archive      = {J_KBS},
  author       = {Wensen Wu and Yijun Gu},
  doi          = {10.1016/j.knosys.2025.114045},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114045},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph anomaly detection via multi-level information alignment and decoupling},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MonoAFKD: Align and frequency cross knowledge distillation for monocular 3D object detection. <em>KBS</em>, <em>326</em>, 114043. (<a href='https://doi.org/10.1016/j.knosys.2025.114043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection is a promising yet inherently ill-posed task due to the absence of reliable depth cues. To mitigate this limitation, cross-modal knowledge distillation (CMKD) from depth-pretrained teacher models to RGB-based student models has emerged as an effective solution. However, discrepancies induced by modality differences, particularly those related to spatial alignment and frequency characteristics, can lead to noisy or negative transfer, ultimately degrading the performance of the student model. Specifically, depth-based teachers primarily encode smooth, low-frequency geometric structures, whereas RGB-based students are more sensitive to high-frequency textures and appearance details, making direct knowledge transfer challenging. To address these issues, we propose MonoAFKD, a structured CMKD framework designed to alleviate modality heterogeneity. It incorporates two novel components: (1) an Attention-based Feature Alignment (AFA) module that adaptively aligns spatially misaligned features between the teacher and student, (2) a Wavelet-based multi-Frequency Distillation (WFD) module that decomposes features into frequency bands, enabling selective transfer of low-frequency depth cues while suppressing high-frequency noise. Extensive experiments on the KITTI 3D detection benchmark and Waymo dataset demonstrate that MonoAFKD achieves state-of-the-art performance without additional inference overhead, validating its practicality and efficiency. The code is available at https://github.com/pxrw/MonoAFKD.git .},
  archive      = {J_KBS},
  author       = {Xiaorui Peng and Yu Meng and Chao Zheng and Meijun Wang},
  doi          = {10.1016/j.knosys.2025.114043},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114043},
  shortjournal = {Knowl. Based Syst.},
  title        = {MonoAFKD: Align and frequency cross knowledge distillation for monocular 3D object detection},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causality-inspired representation learning for weakly supervised skeleton-based action recognition. <em>KBS</em>, <em>326</em>, 114042. (<a href='https://doi.org/10.1016/j.knosys.2025.114042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has become an important research topic in computer vision. Most existing methods tackle this task by mapping skeletal features to fine-grained labels. However, weakly labeled samples—containing both relevant and irrelevant human instances—inevitably emerge during data collection and annotation, adversely impacting model training and inference. To address this challenge, we utilize a structural causal model to formalize the Weakly Supervised Skeleton-based Action Recognition (WS-SAR) problem, treating relevant and irrelevant instances as causal and non-causal factors, respectively. Our primary goal is to learn representations of relevant human instances, i.e., causal factors, from weakly labeled data in WS-SAR. Based on this formulation, we propose a Causality-inspired Representation Learning (CiRL) framework, comprising the Causality DEtection TRansformer (C-DETR) and Supervised Contrastive Learning (Sup-CL). C-DETR leverages learned embeddings as class queries and employs class-matching along with causality-enhanced contrastive learning to extract causal factors from both sample-level and instance-level features. Subsequently, the Sup-CL training strategy applies supervised contrastive learning to effectively capture shared causal representations among weakly labeled samples within the same class. Experimental results show that our framework achieves state-of-the-art performance across multiple datasets, including WL-NTU, IT-NTU120, and SBU. The source code is available at https://github.com/KennCoder7/CiRL .},
  archive      = {J_KBS},
  author       = {Kun Wang and Jiuxin Cao and Jiawei Ge and Chang Liu and Bo Liu},
  doi          = {10.1016/j.knosys.2025.114042},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114042},
  shortjournal = {Knowl. Based Syst.},
  title        = {Causality-inspired representation learning for weakly supervised skeleton-based action recognition},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A closed-loop architecture with knowledge-of-results feedback for neural-symbolic planning. <em>KBS</em>, <em>326</em>, 114041. (<a href='https://doi.org/10.1016/j.knosys.2025.114041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning has long been a central focus of artificial intelligence (AI) research, and it is widely regarded as a core capability of intelligent agents. Early planners were primarily symbolic systems, that relied on structured expertise and could not learn from experience. The development of neural networks has prompted their integration into symbolic planning to enhance learning capabilities. However, previous studies have primarily focused on using neural networks to one-way augment symbolic planning. To activate the full potential of neural and symbolic systems, a bidirectional integration between the two paradigms represents an ideal approach to learning from experience and improving interpretability. Inspired by human motor learning, this study introduces a knowledge-of-results based closed-loop (KRCL) architecture to establish bidirectional integration, maximizing the complementary strengths of both neural and symbolic systems. The proposed KRCL architecture includes a neural planner and a symbolic instructor within a closed-loop, where the planner learns actions and the instructor infers the planning goal. The integration of the planner and instructor formulates the knowledge-of-results (KR) feedback, which promotes continuous improvement through error detection and correction. To improve planning efficiency and enhance the planner flexibility, we design a self-controlled module that controls the frequency of delivering KR feedback and reduces the dependency on feedback. Empirical evaluations demonstrate the superior performance of KRCL across advanced planners and various tasks, illustrating its advantages in adaptability, stability, efficiency, and interpretability. Experimental results confirm KRCL’s potential as a promising approach for bridging the gap between neural and symbolic systems and achieving superior planning capabilities.},
  archive      = {J_KBS},
  author       = {Jiajing Zhang and Jiamei Jiang and Linjing Li and Chenyang Zhang and Jiahui Shi and Daniel Zeng},
  doi          = {10.1016/j.knosys.2025.114041},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114041},
  shortjournal = {Knowl. Based Syst.},
  title        = {A closed-loop architecture with knowledge-of-results feedback for neural-symbolic planning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily learning and global–local dependencies enhanced multi-view representation learning for graph anomaly detection. <em>KBS</em>, <em>326</em>, 114039. (<a href='https://doi.org/10.1016/j.knosys.2025.114039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, application of graph neural networks (GNNs) methods in the realm of graph-based anomaly detection has achieved remarkable results. However, existing methods fail to comprehensively consider the heterophily and global–local dependencies issues in graph anomaly detection task, thereby limiting their effectiveness in graph anomaly detection. Therefore, an innovative method based on multi-view representation learning, i.e. heterophily, local dependency and global dependency learning for graph anomaly detection is developed to better overcome these challenges, namely MGADN (Multi-view Representation-Based Graph Anomaly Detection Network). First, the heterophily issue means the existence of connections between anomalous nodes and normal nodes, which is difficult to handle using general GNNs. To better alleviate this, we propose a heterophily learning-based representation module. This module calculates and learns the difference in features between connected nodes of different types, which enlarges the disparity in latent embeddings space of normal and anomalous nodes, thereby enhancing the effectiveness of anomaly detection. Second, considering that anomalous nodes may exhibit both local and global dependencies, to enhance the anomaly detection we propose a global–local awareness representation module, which effectively captures the global and local dependencies information. Furthermore, in the global–local awareness representation module, an enhanced attention mechanism is proposed to effectively model global dependencies for anomalous nodes on the graphs. Finally, the representations learned from the different modules are fused to obtained the final representation which can use for subsequent graph anomaly detection. Experiments conducted on five benchmarks verify that MGADN surpasses state-of-the-art methods in term of AUC-ROC, AUC-PR and Rec@K metrics.},
  archive      = {J_KBS},
  author       = {Xiang Wang and Hao Dou and Zhenyu Meng},
  doi          = {10.1016/j.knosys.2025.114039},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114039},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily learning and global–local dependencies enhanced multi-view representation learning for graph anomaly detection},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal event extraction based on adaptive feature selection and semantic-aware graph. <em>KBS</em>, <em>326</em>, 114038. (<a href='https://doi.org/10.1016/j.knosys.2025.114038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing models for cross-modal event extraction primarily aim to improve the model accuracy by expanding background information and reducing the impact of simple noises in texts and images with attention mechanism. However, the background information usually contains some kinds of complex noises and specific word or phrase with multiple meanings, which lead to entity and semantic role misidentification, ultimately negatively affecting the accuracy of cross-modal event extraction. In this paper, we propose an Adaptive Feature Selection and Semantic-Aware Graph (AFSSAG) approach to address these challenges. To mitigate the complex noises in background information during event argument extraction, we introduce the Adaptive Feature Selection (AFS) module. Additionally, to tackle the issue of polysemy, we present the Semantic-Aware Graph (SAG) module by integrating Abstract Meaning Representation (AMR) graphs with entity similarity matrices. To validate the effectiveness of our proposed AFSSAG approach, we conduct experiments on the CMMEvent and M2E2 datasets. The experimental results demonstrate that AFSSAG significantly outperforms baseline models, achieving F1 score improvements of 3.5% on CMMEvent and 1.2% on M2E2, and highlight the strong accuracy and generalization capabilities of our approach in cross-modal event extraction task.},
  archive      = {J_KBS},
  author       = {Maofu Liu and Zhenyi Hu and Bingying Zhou and Huijun Hu and Chen Qiu and Xiaokang Zhang},
  doi          = {10.1016/j.knosys.2025.114038},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114038},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-modal event extraction based on adaptive feature selection and semantic-aware graph},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised contrastive learning for heterophilic graph with latent recurring pattern embedding. <em>KBS</em>, <em>326</em>, 114037. (<a href='https://doi.org/10.1016/j.knosys.2025.114037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurring patterns, which denote semantic relations frequently occurring among nodes within a heterophilic graph, encapsulate rich semantic information crucial for modeling semantic relations. Previous approaches have relied on manual design or annotation of recurring patterns, such as meta-paths and motif substructures, to discriminate and focus on homophilic nodes, limiting their utility in unsupervised graph representation learning. To overcome this limitation, we propose a self-supervised Contrastive Learning framework with Latent Recurring Pattern Embedding (CL-LRPE) to learn semantic relations in heterophilic graphs and facilitate node discrimination. Initially, we propose a novel latent recurring pattern embedding module to capture the common semantic relations therein across the subgraphs in an unsupervised manner and integrate them into node representation. Subsequently, the latent recurring pattern embedding module is integrated into a contrastive learning framework featuring an elaborate graph decoder. This integration makes the learned representations not only distinguish nodes but also capture maximum information to reconstruct the features and structure of the neighborhood comprehensively. Extensive experiments have demonstrated that our CL-LRPE framework significantly outperforms state-of-the-art unsupervised methods in node classification tasks on heterophilic graphs. Furthermore, it achieves classification accuracy comparable to some supervised methods. Our code is available at https://github.com/yang-xidian/CL-LRPE.git .},
  archive      = {J_KBS},
  author       = {Juan Song and Lijie Yang and Mingtao Feng},
  doi          = {10.1016/j.knosys.2025.114037},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114037},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised contrastive learning for heterophilic graph with latent recurring pattern embedding},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised risk factor model using dual recurrent state space models. <em>KBS</em>, <em>326</em>, 114036. (<a href='https://doi.org/10.1016/j.knosys.2025.114036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asset pricing models are crucial in finance for asset valuation, portfolio management, and investment strategy formulation. The integration of deep learning into these models leverages their ability to distill meaningful patterns from extensive datasets, recognize complex nonlinear interdependencies, and improve predictive precision. However, the inherently noisy nature of financial data poses significant challenges in model training and generalizability to new data. Addressing these challenges, our paper introduces an innovative risk factor model framework, grounded in a Recurrent State Space Model (RSSM). We have designed a dual RSSM structure that separately models the overall market and individual assets. This approach facilitates a deep comprehension of market trends and captures the temporal dynamics specific to each asset. Furthermore, we present a novel self-supervised technique to enhance our model’s performance. Our model provided a better understanding of volatility in the U.S. stock market and achieved a 41% improvement in predicting asset returns compared to the best-performing model among previous studies. We also demonstrated the ability to generate a 79% increase in risk-adjusted returns through investment simulations. Our code is available at https://github.com/Osj1614/dualrssm .},
  archive      = {J_KBS},
  author       = {Ji-hun Lee and Seungjun Oh and Jongchan Park and Da-Hea Kim and Yusung Kim},
  doi          = {10.1016/j.knosys.2025.114036},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114036},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised risk factor model using dual recurrent state space models},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotional inverse reasoning trees and dominant modality focus for emotion recognition in conversations. <em>KBS</em>, <em>326</em>, 114035. (<a href='https://doi.org/10.1016/j.knosys.2025.114035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in conversation (ERC) is crucial to advancing human–computer interaction. However, current methods often ignore the importance of keywords in emotional expression, neglecting both the emotional information these keywords convey and their dynamic variations. In addition, previous studies have not deeply considered the characteristics and commonalities of heterogeneous modalities before fusion, leading to noise accumulation and weakened intermodal interactions. During multimodal fusion, these methods have not effectively accounted for strength differences between modalities, particularly underestimating the notable influence of the text modality on ERC. Moreover, traditional research has made only limited attempts to enhance modality representation capabilities. To address these issues, we propose the Emotional Inverse Reasoning Trees and Dominant Modal Focus model (EIRT-DMF) for ERC. The model leverages commonsense knowledge to extract keywords from utterances and introduces an innovative emotional inverse reasoning tree structure to enhance textual semantic representation and strengthen the transmission of emotional cues. Meanwhile, we design a modality optimization module to handle intra-modality associations and cross-modality interactions. In the fusion phase, the text modality is employed as the dominant modality to gain a collaborative understanding of intermodal semantics. In addition, we introduce a hybrid knowledge-distillation mechanism that employs multilevel learning to generate higher-quality multimodal representations. Experiments on the IEMOCAP and MELD datasets indicate that EIRT-DMF achieved state-of-the-art (SOTA) performance compared to all baselines.},
  archive      = {J_KBS},
  author       = {Shidan Wei and Xianying Huang and Chengyang Zhang},
  doi          = {10.1016/j.knosys.2025.114035},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114035},
  shortjournal = {Knowl. Based Syst.},
  title        = {Emotional inverse reasoning trees and dominant modality focus for emotion recognition in conversations},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric bayesian transfer learning for robust cardiopulmonary diseases classification in X-ray images. <em>KBS</em>, <em>326</em>, 114034. (<a href='https://doi.org/10.1016/j.knosys.2025.114034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized the detection of cardiopulmonary diseases by using readily available X-ray images. Transfer learning offers an exciting avenue for accelerating progress in this field, particularly when large training datasets are scarce. However, difficulties arise when transferring knowledge from one domain to another unrelated task, potentially harming model performance. Therefore, we propose a novel nonparametric Bayesian statistical model to investigate the effectiveness of transfer learning on radiographic images. The proposed model comprises of two main components: deep transfer learning and classification. The deep transfer learning component extracts domain-invariant discriminating features using an Indian buffet process-driven variational autoencoder. This Bayesian nonparametric model enables flexible modeling of networks with potentially unbounded sizes while simultaneously capturing complex structural patterns and regularities within the data. The classification component further fine-tunes these features using a supervised algorithm rather than the current approaches that use a single feature space represented by the last fully connected layer of the convolutional neural networks across all conditions. Our model achieved a mean area under the curve (AUC) score of 88.01% for 14 cardiopulmonary diseases in the NIH chest radiograph dataset, outperforming the existing state-of-the-art methods. Validation of the collected external data demonstrates the generalizability of the model.},
  archive      = {J_KBS},
  author       = {Kibrom Haftu and Yaregal Assabie},
  doi          = {10.1016/j.knosys.2025.114034},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114034},
  shortjournal = {Knowl. Based Syst.},
  title        = {Nonparametric bayesian transfer learning for robust cardiopulmonary diseases classification in X-ray images},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). INQUIRER: Harnessing internal knowledge graphs for video question generation. <em>KBS</em>, <em>326</em>, 114033. (<a href='https://doi.org/10.1016/j.knosys.2025.114033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video question generation (VideoQG) aims to generate questions about video content to facilitate and assess video understanding. Existing works which primarily condition question generation on answer-related information such as the answer itself or its attributes. However, these methods are primarily designed as data augmentation techniques and thus struggle to produce semantically diverse questions. We propose INQUIRER, a novel VideoQG framework that leverages internal knowledge graphs derived from video information to generate meaningful and diverse questions. INQUIRER consists of three key steps: KCon, which constructs an internal knowledge graph to represent a video similarly to human knowledge structures, QGen which generates questions based on the video and the knowledge graph, and QCur which refines the generated questions to ensure quality and contextual relevance. Each generated question is accompanied by a correct answer and plausible distractors to support downstream QA evaluation. To comprehensively evaluate the generated QAs and utility of INQUIRER from multiple perspectives, we utilize widely used video question answering (VideoQA) benchmarks, including DramaQA, TVQA, How2QA, and STAR. Experiment results demonstrate that INQUIRER not only generates high-quality question–answer pairs but also significantly enhances VideoQA performance, validating its effectiveness as a robust framework for video question generation.},
  archive      = {J_KBS},
  author       = {Woo Suk Choi and Youwon Jang and Minsu Lee and Byoung-Tak Zhang},
  doi          = {10.1016/j.knosys.2025.114033},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114033},
  shortjournal = {Knowl. Based Syst.},
  title        = {INQUIRER: Harnessing internal knowledge graphs for video question generation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of heuristic adapted serial-based deep learning for efficient adversarial malware detection framework in windows. <em>KBS</em>, <em>326</em>, 114032. (<a href='https://doi.org/10.1016/j.knosys.2025.114032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware detection is the process of validating the presence of malicious intent. In these days, malware recognition and detection are getting harder due to some malware characteristics of multiple classes being present at the same time. More researchers have developed for accurately detecting malware activities in network and window systems.However, the detection of malware still remains problematic. It does not have the ability to capture relevant features and does not remove redundant and noisy data thus; it minimizes the accuracy value of detection performance. With the aim of resolving these issues, this paper presentsa newly developed strategy of a hybrid deep learning-based adversarial malware detection model in Windows to preserve the functionalities and improve the evading detection performance. Initially, the Windows malware data is obtained from a benchmark website and the data is subjected to the data cleaning operation. Secondly, the “optimal features are chosen from the input data by utilizing the” Boundary Value-assisted Remora- Smart Flower Optimization (BVR-SFO). Then, an efficient Average-based Ensemble Deep Learning (AEDL) is developed by the combination of Autoencoder, “1-Dimentional Convolutional Neural Network (1DCNN), and Bi-directional Long Short Term Memory (BiLSTM)” in the malware detection process. The parameters present in Autoencoder, 1DCNN, and Bi-LSTM is optimized by utilizing the same BVR-SFO algorithm for detecting malware in Windows. Finally, the developed method attains 96.73 % of accuracy, 96.85 % of sensitivity, 96.53 % of specificity, and 97.98 % of precision to demonstrate its better and more reliable outcomes.},
  archive      = {J_KBS},
  author       = {Payal Awwal and Dr Smita Naval},
  doi          = {10.1016/j.knosys.2025.114032},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114032},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of heuristic adapted serial-based deep learning for efficient adversarial malware detection framework in windows},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGphormer: Heterophilic graph transformer. <em>KBS</em>, <em>326</em>, 114031. (<a href='https://doi.org/10.1016/j.knosys.2025.114031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been widely used in various node-level tasks on graphs due to their powerful representation learning ability. Traditional GNNs rely on the homophily assumption that nodes with the same label in a graph tend to be connected to each other. But there are a large number of heterophily graphs in the real world, where most proximal nodes have different labels. So heterophily GNNs has been proposed, which tried to improve the performance of GNNs on heterophily graph by obtaining information from multi-hop neighbor nodes. A promising way for heterophily graphs is Graph Transformers (GTs). Without relying on the homophily assumption, GTs aggregate information of nodes depending on their similarity, thus is suitable for both homophily and heterophily graphs. Since the quadratic time complexity of GTs, most of existing GTs focus on how to reduce the complexity and make it applicable for nodes classification, their performance is still unsatisfied in heterophily graphs. To solve the above problem, Heterophilic Graph Transformer (HGphormer) is proposed in this paper. In order to reduce the interference between attribute embedding and structure embedding, a parallel architecture of Transformer is proposed. HGphormer also decouples the aggregated information into homophily and heterophily information and uses them adaptively to further improve the accuracy. A sample technique is proposed to sample neighbors from multiple hops and reduce the time complexity. Experiments show that the proposed HGphormer outperforms the state of the art methods on both homophily graph and heterophily graph datasets.},
  archive      = {J_KBS},
  author       = {Jianshe Wu and Yaolin Liu and Yuqian Wang and Lingjie Zhang and Jingyi Ding},
  doi          = {10.1016/j.knosys.2025.114031},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114031},
  shortjournal = {Knowl. Based Syst.},
  title        = {HGphormer: Heterophilic graph transformer},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Broadfusion: A novel two-stage multifocus image fusion approach with human visual system embedded broad learning system. <em>KBS</em>, <em>326</em>, 114030. (<a href='https://doi.org/10.1016/j.knosys.2025.114030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multifocus image fusion, widely acknowledged as one of the most significant techniques for obtaining an all-in-focus image representation, has garnered substantial research attention. However, current neural network-based fusion methods typically incur substantial training time costs. To address this limitation and augment the efficacy of such approaches while attaining superior performance, a novel multifocus image fusion methodology termed Broadfusion, is proposed in this paper. Broadfusion employs a two-stage framework that synergistically integrates a human visual system-based broad neural network with multi-image guided filtering techniques. To be more consistent with human visual perception, multiple visual features are initially extracted from the source images and then embedded into broad learning system (BLS) by human visual system for selecting the clearer pixel . Furthermore, a novel post-processing method based on multi-image guided filtering is employed to refine the initial decision map, thereby enhancing the overall image clarity and saliency. The final fused image is generated by applying a weighted-averaging fusion rule utilizing the refined decision map. Comprehensive experimental results demonstrate that the proposed Broadfusion can achieve superior or comparable fusion performance in comparison to eleven other state-of-the-art multifocus image fusion techniques, while mitigating the training time costs associated with conventional neural network-based approaches.},
  archive      = {J_KBS},
  author       = {Junwei Duan},
  doi          = {10.1016/j.knosys.2025.114030},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114030},
  shortjournal = {Knowl. Based Syst.},
  title        = {Broadfusion: A novel two-stage multifocus image fusion approach with human visual system embedded broad learning system},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust image watermarking towards iPhone intelligent matting and social platform sharing. <em>KBS</em>, <em>326</em>, 114029. (<a href='https://doi.org/10.1016/j.knosys.2025.114029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking serves as a pivotal technique for identifying the origin and asserting copyright ownership of an image. However, the development of intelligent systems, particularly the advent of the latest iPhone intelligent matting, poses a formidable challenge in the realm of image watermarking. Specifically, the iPhone intelligent matting process generates irregular and localized images that undergo a series of lossy operations during the splicing process and social platform sharing, rendering it challenging for existing methods to effectively synchronize and extract watermarks. In this study, we tackle this challenge and propose an irregular local feature-based adaptive (ILFA) embedding strategy, which makes significant contributions to improving the robustness and invisibility of watermarks in irregular iPhone matting and social platform sharing. Within the stable symmetric framework, this strategy precisely localizes the image into distinct regions for adaptive embedding, harnessing comprehensive image feature analysis to optimize both the robustness and visual quality of local watermark units. We also developed a segmentation and local correlation analysis (SLCA) method to detect irregular watermarked matting regions. Extensive experiments confirm our outstanding performance in countering iPhone intelligent matting, social platform sharing, and common image editing manipulations in real-world smartphone applications. Moreover, the proposed method also demonstrates good performance in image processing, geometric attacks, and composite attacks.},
  archive      = {J_KBS},
  author       = {Ling Yang and Hongxia Wang and Fei Zhang and Yuyuan Xiang and Jinhe Li},
  doi          = {10.1016/j.knosys.2025.114029},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114029},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust image watermarking towards iPhone intelligent matting and social platform sharing},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clinical decision support system for comprehensive analysis and long-term surveillance of post-endovascular repair in abdominal aortic aneurysms. <em>KBS</em>, <em>326</em>, 114026. (<a href='https://doi.org/10.1016/j.knosys.2025.114026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An abdominal aortic aneurysm is a critical vascular condition involving the continuous dilatation of thrombus, even after surgical intervention such as endovascular aneurysm repair. Clinical decision support systems (CDSSs) can enhance the comprehensive analysis and long-term surveillance of post-operative complications and outcomes. However, research on their development and implementation remains largely untapped. In this work, we design, develop, and evaluate a novel CDSS for post-operative care in collaboration with two senior domain experts. Our image processing module enables automated, precise, and rapid detection and segmentation of regions of interest (ROIs) containing thrombus in post-operative computed tomography angiography (CTA) image studies. It utilizes both mask region-based convolutional neural network (Mask R-CNN) and U-Net++ models and optimizes their sub-networks and loss functions. In addition, the longitudinal knowledge exploration module goes beyond analyzing individual time points (i.e., individual CTA studies) to identify changes in thrombus ROIs over a sequence of studies. It also highlights crucial diagnostic indicators, such as endoleaks and ruptures, and provides synchronized visualization and tracking. Our experiments demonstrate that the image processing module achieves high accuracy when compared to five CNN models across 48 patient studies. The longitudinal knowledge exploration module is validated through informal expert reviews of two representative clinical cases, with positive feedback regarding its clinical feasibility and usability. The CDSS is shown to be computationally efficient, thereby allowing accessibility on standard laptops for routine use. To promote widespread adoption, we are releasing it as a plug-in extension for the well-established 3D Slicer platform.},
  archive      = {J_KBS},
  author       = {Haill An and Sungmin Lee and Hyoseok Hwang and Eunyoung Kim and Jeongho Kim and Younhyun Jung},
  doi          = {10.1016/j.knosys.2025.114026},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114026},
  shortjournal = {Knowl. Based Syst.},
  title        = {Clinical decision support system for comprehensive analysis and long-term surveillance of post-endovascular repair in abdominal aortic aneurysms},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVA-BLS: Polynomial vector autoregression broad learning system for multivariate time series prediction. <em>KBS</em>, <em>326</em>, 114025. (<a href='https://doi.org/10.1016/j.knosys.2025.114025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a broad learning system (BLS), the original input signal first transits through the feature nodes for feature learning and then is transmitted to the enhancement nodes through nonlinear learning. One advantage of the BLS is that its structure can be easily improved and extended. As an extension of the traditional BLS, the recurrent BLS (RBLS) employs replacing the enhancement nodes of the BLS with a dynamic structure, making the RBLS more suitable for dealing with time series data. However, the recurrent structure in the enhancement nodes of RBLS suffers from over-parameterization, excessive randomness, and poor interpretability. To address these shortcomings of RBLS, we propose a polynomial vector autoregression BLS model (PVA-BLS) based on RBLS theory and optimize its hyperparameters by the Bayesian optimization algorithm (BOA). The advantages of BOA-PVA-BLS can be summarized as follows: (1) BOA-PVA-BLS solves the problems of uncertainty in weight matrices and difficulty in large-scale parameter selection in the enhancement nodes of RBLS. (2) The PVA module can avoid massive recurrent hyperparameters and effectively reduce the number of enhancement nodes of RBLS. (3) The proposed BOA-PVA-BLS shows good performance, strong stability, and robustness in several synthetic and real-world datasets for one-step-ahead prediction. The simulation results confirm that the BOA-PVA-BLS not only outperforms some gate-structured recurrent networks and traditional RBLS but also requires fewer hyperparameters to be initialized and can significantly reduce the computational requirements of RBLS while greatly reducing the complexity of RBLS.},
  archive      = {J_KBS},
  author       = {Chudong Tong and Liangkun Guo and Bowen Sun and Zhepeng Wang and Heshan Wang},
  doi          = {10.1016/j.knosys.2025.114025},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114025},
  shortjournal = {Knowl. Based Syst.},
  title        = {PVA-BLS: Polynomial vector autoregression broad learning system for multivariate time series prediction},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VS-MRC: A visual semantics-guided machine reading comprehension framework for multimodal named entity recognition with multiple images. <em>KBS</em>, <em>326</em>, 114024. (<a href='https://doi.org/10.1016/j.knosys.2025.114024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal named entity recognition with multiple images presents the challenge of extracting relevant visual information across images to enable effective interaction with text. Existing methods primarily follow an extraction-then-fusion paradigm, focusing on visual feature learning and cross-modal interaction. However, most approaches treat all images equally or model relevance solely at the image level, leading to redundant or irrelevant visual content, which hampers cross-modal interaction and textual understanding. To facilitate the learning of meaningful visual representations and the formation of a coherent multimodal context for improved understanding, we propose an aggregation–mapping–comprehension paradigm. This paradigm aggregates text-relevant visual features and maps them into the textual space as heuristic prompts. Based on this paradigm, we develop a visual semantics-guided machine reading comprehension framework, named VS-MRC. We first introduce a text-guided visual aggregator that simultaneously extracts visual semantics from all images, iteratively refined based on the textual content. Subsequently, VS-MRC employs a dedicated embedding space and a reconstruction mechanism to accurately map visual semantics into the textual space, ensuring coherent cross-modal alignment. The aligned visual representations are then concatenated with the textual representations to form a synergistic input sequence for an encoder–decoder model, which ultimately outputs entity-type pairs. Additionally, we incorporate an Image–Text Matching module to predict the paired relationships between images and text, supervising the training of both the aggregator and reconstructor to enhance the quality of the visual representations. Extensive experiments on two public datasets demonstrate that the proposed VS-MRC framework achieves state-of-the-art performance compared to previous methods. Our source code is available at: https://github.com/Jiapei-Hu/VS-MRC .},
  archive      = {J_KBS},
  author       = {Jiapei Hu and Yifan Lyu and Yun Xue},
  doi          = {10.1016/j.knosys.2025.114024},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114024},
  shortjournal = {Knowl. Based Syst.},
  title        = {VS-MRC: A visual semantics-guided machine reading comprehension framework for multimodal named entity recognition with multiple images},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DD-NeuS: Dense depth self-supervised neural surface reconstruction from few images. <em>KBS</em>, <em>326</em>, 114022. (<a href='https://doi.org/10.1016/j.knosys.2025.114022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) reconstruction from a limited number of images is highly valuable for fast and efficient information extraction in applications such as digital Earth modeling and urban planning. Most existing studies on 3D reconstruction rely on dense input views, as models generated from a few images typically suffer from voids, noise, and severe geometric distortions in fine details. To address these challenges, we propose DD-NeuS, a neural implicit-based joint learning framework capable of rendering high-quality novel view images and generating high-quality 3D models from only a few input images. DD-NeuS consists of two primary modules: the dense depth supervision (DDS) module and the rendering and reconstruction (RR) module. First, the DDS module performs depth completion in a self-supervised manner to generate a dense depth map. The supervised weights for each pixel in the depth map are then used to effectively guide the RR module. Next, using the Kullback–Leibler divergence, we match the distribution of the depth values and corresponding weights to the distribution of sample points produced by the RR module. This approach helps address issues such as noise and gaps in models generated from limited input images. Finally, the RR module collects points along camera rays and their corresponding dense depth map pixel-level features, guiding the accurate generation of the implicit object surface and improving the fine-grained representation of the scene. Experimental results on the DTU and BlendedMVS datasets demonstrate that DD-NeuS is highly effective in reconstructing detailed surfaces, even from a small number of images.},
  archive      = {J_KBS},
  author       = {Yaru Qiu and Guoxia Wu and Ziyu Wei and Xueying Li and Yongqing Li and Yuanyuan Sun},
  doi          = {10.1016/j.knosys.2025.114022},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114022},
  shortjournal = {Knowl. Based Syst.},
  title        = {DD-NeuS: Dense depth self-supervised neural surface reconstruction from few images},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prototype-based personalized federated learning for medical image classification. <em>KBS</em>, <em>326</em>, 114021. (<a href='https://doi.org/10.1016/j.knosys.2025.114021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a collaborative learning approach in which raw data are not shared. However, data heterogeneity across clients remains a crucial challenge in federated learning, which affects model performance, especially in medical scenarios. This paper proposes a novel method named Prototype-based Personalized Federated Learning (PPFed) to address this problem. PPFed employs the gradient-based meta-learning algorithm as a personalization strategy to find an initial global prototype that can effectively adapt to the local distribution. To improve the representativeness of prototypes, PPFed further introduces two complementary modules: the prototype learning module and the prototype refinement module. Specifically, the prototype learning module is jointly trained with the feature extractor to ensure that prototypes are tightly clustered in the embedding space. Meanwhile, the prototype refinement module reduces semantic differences and enhances intra-class compactness. Extensive experiments on two real-world medical image tasks reveal that PPFed outperforms ten popular benchmark methods.},
  archive      = {J_KBS},
  author       = {Chunling Chen and Haiwei Pan and Kejia Zhang and Zhe Li and Fengming Yu},
  doi          = {10.1016/j.knosys.2025.114021},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114021},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prototype-based personalized federated learning for medical image classification},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal feature alignment and fusion with contrastive learning in multimodal recommendation. <em>KBS</em>, <em>326</em>, 114020. (<a href='https://doi.org/10.1016/j.knosys.2025.114020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing availability of multimedia information, multimodal recommendation systems have gained significant attention. These systems integrate and process data from various modalities for generating personalized recommendations. Despite notable advances in recommendation performance, current models face several limitations: (1) Information loss or noise introduction during feature alignment. Existing methods often overemphasize feature similarity while neglecting the potential complex differences between modalities, which may result in the loss of modality-specific information and the inclusion of irrelevant features. (2) Overreliance on interaction data leads to insufficient and inaccurate modality fusion. The user–item interaction data is typically sparse, causing systems to overlook important features when learning user preferences or item characteristics, leading to suboptimal fusion. To address these challenges, we propose a novel multimodal recommendation model, named CLAM, which leverages C ontrastive L earning (CL) to achieve effective cross-modal feature A lignment and M odality fusion. Specifically, to minimize information loss and the introduction of noise during the feature alignment process, we employ item ID embeddings as an anchor, comparing them with the corresponding modality features after semantic encoding across various modalities. This indirect alignment mechanism allows modality features to preserve their unique information, thus preventing distortion in feature representation caused by an overemphasis on similarity in direct alignment. Furthermore, to prevent unreasonable modality fusion due to excessive reliance on interaction data, we adopt a multi-task learning mechanism, ensuring that interaction data is not the sole training signal. Extensive experiments conducted on three real-world datasets demonstrate that CLAM outperforms several state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Xu Yuan and Ange Qi and Huinan Wu and Jiaqiang Wang and Yi Guo and Shijin Li and Liang Zhao},
  doi          = {10.1016/j.knosys.2025.114020},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114020},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-modal feature alignment and fusion with contrastive learning in multimodal recommendation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFDG: Adaptive federated learning for dynamic graph-based traffic forecasting. <em>KBS</em>, <em>326</em>, 114019. (<a href='https://doi.org/10.1016/j.knosys.2025.114019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and scalable traffic forecasting is vital for optimizing urban mobility, reducing congestion, and enhancing transportation safety. However, modeling traffic dynamics remains challenging due to spatio-temporal complexity, data heterogeneity, and privacy concerns. Traditional models often struggle with the non-Euclidean structure of traffic networks, while graph neural networks (GNNs) offer promising spatio-temporal modeling capabilities but face difficulties adapting to dynamic data distributions and ensuring data privacy. To address these limitations, we propose Dynamic Federated Graphs for Decentralized Learning (DFDG) , a novel framework that integrates federated learning with dynamic GNNs for decentralized, privacy-preserving traffic forecasting. DFDG introduces a Kolmogorov–Arnold Network with ordinary differential equations (KANODE), based on Chebyshev polynomials, to model continuous-time temporal dynamics. It also employs Self-Organizing Maps (SOMs) for unsupervised clustering of participants based on local behavior, enabling adaptive personalization. To preserve privacy, DFDG leverages a graph Fourier transform (GFT)-based mechanism to transmit compressed and perturbed spectral coefficients instead of raw gradients. A dynamic weighting strategy further improves robustness by prioritizing contributions from high-quality participants during aggregation. Extensive experiments on three real-world benchmark datasets — METR-LA, PEMS-BAY, and NE-BJ — demonstrate that DFDG achieves state-of-the-art performance, with Mean Absolute Errors (MAE) of 2.47, 1.20, and 3.56, respectively, on 15-minute forecasting horizons. Moreover, DFDG supports real-time deployment with an average inference latency of 2.83 s per 100 graphs across up to 21 asynchronous federated participants. These results establish DFDG as a scalable, accurate, and privacy-preserving solution for real-world traffic forecasting, offering strong generalizability and efficient deployment across intelligent transportation networks.},
  archive      = {J_KBS},
  author       = {Muhammad Usman and Yugyung Lee},
  doi          = {10.1016/j.knosys.2025.114019},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114019},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFDG: Adaptive federated learning for dynamic graph-based traffic forecasting},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale fine-grained image retrieval via proxy mask pooling and multilateral semantic relations. <em>KBS</em>, <em>326</em>, 114018. (<a href='https://doi.org/10.1016/j.knosys.2025.114018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image retrieval poses significant challenges due to subtle inter-class differences and large intra-class variations. Attention mechanisms have been widely adopted to enhance feature discrimination, yet their serial application remains underexplored due to computational constraints and the risk of over-focusing on redundant information. Meanwhile, recent advances in attribute-aware deep hashing have underscored the interpretability of hash codes, offering a promising avenue for improving retrieval performance. To address these challenges, we propose a novel deep learning framework with two key innovations. First, the Proxy Mask Pooling Module mitigates the trade-off between computational efficiency and model performance in serial attention mechanisms while enhancing spatial and positional information. By guiding the model to focus on diverse and semantically rich regions, this module improves the discriminative power of fine-grained features at both local and global levels. Second, inspired by the interpretability of hash codes as attribute descriptors, we introduce the Multilateral Semantic Tuple Relation Strategy , which leverages a hypergraph-based structure and a novel loss function to model intricate multi-way relationships among images. This design effectively strengthens semantic representation and retrieval accuracy. Extensive experiments on multiple benchmark fine-grained image retrieval datasets demonstrate the superiority of our method, achieving notable improvements in retrieval precision, computational efficiency, and generalization ability over state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Xianxian Zeng and Jie Zhou and Dunhao Liu and Jun Yuan and Ming Yin and Weichao Xu and Shun Liu},
  doi          = {10.1016/j.knosys.2025.114018},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114018},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large-scale fine-grained image retrieval via proxy mask pooling and multilateral semantic relations},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight embedding method for knowledge graph quality evaluation. <em>KBS</em>, <em>326</em>, 114013. (<a href='https://doi.org/10.1016/j.knosys.2025.114013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) quality evaluation seeks to assess the quality of triples in a KG. Existing approaches for KG quality evaluation often rely on high-dimensional embeddings to improve the model's evaluative performance. This reliance, however, not only increases the model's scale but also introduces feature redundancy, constraining its applicability to real-world problems. To tackle this challenge, this study proposes a Lightweight Embedding Method for KG Quality Evaluation (LEKGQE). This method performs kernel principal component analysis on each dimension of the triples, mapping multivariate data into univariate data, thereby effectively extracting the main features of the data. Furthermore, we quantify the contribution of each dimension on the target variable. Cross-entropy is used to identify the most discriminative features for KG quality evaluation, significantly reducing the model's embedding dimension and improving the KG quality evaluation performance under low-dimensional embeddings. Extensive experiments demonstrate the effectiveness of the LEKGQE model. With an embedding dimension of 32, the LEKGQE achieves a 14 % increase in F1 score on the FB15K dataset and a 12 % increase in F1 score on the WN18 dataset, markedly improving the model’s performance in low-dimensional embedding scenarios.},
  archive      = {J_KBS},
  author       = {Bin Chen and Hongyi Li and Di Zhao and Chengwei Pan},
  doi          = {10.1016/j.knosys.2025.114013},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114013},
  shortjournal = {Knowl. Based Syst.},
  title        = {A lightweight embedding method for knowledge graph quality evaluation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Botfip-LLM: An enhanced multimodal scientific computing framework leveraging knowledge distillation from large language models. <em>KBS</em>, <em>326</em>, 114012. (<a href='https://doi.org/10.1016/j.knosys.2025.114012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the introduction of AI technologies has brought transformative changes to scientific computing. However, AI models typically focus on single-task and single-modal data processing, limiting their application. To address this, multimodal scientific computing frameworks have become a trend. The Botfip framework aligns function images with symbolic operation trees through multimodal training, extracting deep scientific information. However, Botfip struggles with processing Formula Strings, leading to inadequate understanding in multimodal learning. To enhance Botfip’s learning of Formula Strings and expand its applicability to related tasks, we propose the Botfip-LLM framework based on knowledge distillation, incorporating pre-trained large language models for aligning operation tree data. Experimental analysis shows that the choice of LLM is crucial, with ChatGLM-2 outperforming others in training and testing. Botfip-LLM not only improves performance, generalization, and extrapolation over the original Botfip model but also significantly enhances applicability to Formula String-related tasks, enabling more diverse task handling.},
  archive      = {J_KBS},
  author       = {Tianhao Chen and Pengbo Xu and Haibiao Zheng},
  doi          = {10.1016/j.knosys.2025.114012},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114012},
  shortjournal = {Knowl. Based Syst.},
  title        = {Botfip-LLM: An enhanced multimodal scientific computing framework leveraging knowledge distillation from large language models},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained stateful knowledge exploration: Effective and efficient graph retrieval with large language models. <em>KBS</em>, <em>326</em>, 114011. (<a href='https://doi.org/10.1016/j.knosys.2025.114011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have shown impressive capabilities, yet updating their knowledge remains a significant challenge, often leading to outdated or inaccurate responses. A proposed solution is the integration of external knowledge bases, such as knowledge graphs, with LLMs. Most existing methods use a paradigm that treats the whole question as the objective, with relevant knowledge being incrementally retrieved from the knowledge graph. However, this paradigm often leads to a granularity mismatch between the target question and the retrieved entities and relations. As a result, the information in the question cannot precisely correspond to the retrieved knowledge. This may cause redundant exploration or omission of vital knowledge, thereby leading to enhanced computational consumption and reduced retrieval accuracy. To address the limitations of coarse-grained knowledge exploration, we propose FiSKE, a novel paradigm for Fi ne-grained S tateful K nowledge E xploration. FiSKE first decomposes questions into fine-grained clues, then employs an adaptive mapping strategy during knowledge exploration process to resolve ambiguity in clue-to-graph mappings. This strategy dynamically infers contextual correspondences while maintaining a stateful record of the mappings. A clue-driven termination mechanism ensures rigorous augmentation—leveraging fully mapped paths for LLMs while reverting to chain-of-thought reasoning when necessary. Our approach balances precision and efficiency. Experiments on multiple datasets revealed that our paradigm surpasses current advanced methods in knowledge retrieval while significantly reducing the average number of LLM invocations. The code for this paper can be found at https://github.com/nnnoidea/stateful-KGQA .},
  archive      = {J_KBS},
  author       = {Dehao Tao and Congqi Wang and Feng Huang and Junhao Chen and Yongfeng Huang and Minghu Jiang},
  doi          = {10.1016/j.knosys.2025.114011},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114011},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained stateful knowledge exploration: Effective and efficient graph retrieval with large language models},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PGC-CSS: A parallel graph clustering framework with collaborative self-supervision. <em>KBS</em>, <em>326</em>, 114010. (<a href='https://doi.org/10.1016/j.knosys.2025.114010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is a fundamental yet challenging task in data analysis, aiming to partition nodes into coherent groups based on graph topology and node features. Recently, deep clustering methods based on graph convolutional networks (GCN) have achieved remarkable success. However, most existing approaches rely on a single learning pipeline built upon the original graph structure, which is often corrupted by noisy or unreliable edges. As a result, the clustering performance becomes unstable. To address the above issue, we propose a novel parallel graph clustering framework, termed PGC-CSS. Specifically, we introduce a graph refinement method that alleviates noise in the original graph by uncovering latent structural patterns from node embeddings. The refined graph is then integrated with the original graph in a parallel architecture, enabling robust and discriminative representation learning through the complementary modeling of multiple graph structures. Furthermore, we design a collaborative self-supervision module that combines distribution-based and pseudo-label-based self-supervision strategies to guide the model toward learning optimal clustering representations. Extensive experiments on six benchmark datasets demonstrate the effectiveness and superiority of PGC-CSS for deep attributed graph clustering.},
  archive      = {J_KBS},
  author       = {Meng Li and Jun Wu and Bo Yang and Yuanyuan Li and Lei Qu},
  doi          = {10.1016/j.knosys.2025.114010},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114010},
  shortjournal = {Knowl. Based Syst.},
  title        = {PGC-CSS: A parallel graph clustering framework with collaborative self-supervision},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous federated learning framework for human activity recognition. <em>KBS</em>, <em>326</em>, 114008. (<a href='https://doi.org/10.1016/j.knosys.2025.114008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated human activity recognition (FedHAR) leverages federated learning (FL) to collaboratively train HAR models across clients(users) while preserving privacy by keeping data local to each device. However, FedHAR faces two key challenges: model heterogeneity, arising from the diverse computational capabilities of client devices, and data heterogeneity, resulting from behavioral differences across individual clients. In this paper, we propose HFedHAR, a heterogeneous federated learning framework for HAR, to address dual heterogeneity (i.e. model heterogeneity and data heterogeneity). Under model heterogeneity, clients use different model structures, making gradient-based knowledge sharing ineffective in existing FedHAR approaches. To address this, we first design a new ‘bridge’ (i.e., synthetic data generated from clients with high computational power), to link clients. Each client represents their knowledge as prediction logits on the bridge, enabling structure-agnostic knowledge sharing. To further enhance the bridge’s effectiveness, we introduce an information entropy loss. To tackle data heterogeneity, we employ a similarity-based knowledge distillation strategy based on a relation graph constructed among clients, enabling each client to effectively absorb knowledge from others. We evaluate the proposed HFedHAR framework on four HAR datasets, and experimental results demonstrate its effectiveness in addressing the dual-heterogeneity challenges in FedHAR.},
  archive      = {J_KBS},
  author       = {Xinhui Yu and Arvin Tashakori and Martin J. McKeown and Z. Jane Wang},
  doi          = {10.1016/j.knosys.2025.114008},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114008},
  shortjournal = {Knowl. Based Syst.},
  title        = {A heterogeneous federated learning framework for human activity recognition},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Registration-fusion binocular diffusion model: Exploring continuous fusion of unregistered hyperspectral and multispectral images. <em>KBS</em>, <em>326</em>, 114007. (<a href='https://doi.org/10.1016/j.knosys.2025.114007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of hyperspectral image (HSI) and multispectral image (MSI) constitutes an effective approach to obtain high spatial resolution HSI (HR-HSI). However, in practice, multi-source images obtained under different imaging conditions are difficult to be perfectly registered. The vast majority of existing fusion methods crudely assume that HSI and MSI are registered, which is challenging to generalize to practical applications. To this end, we propose a unified registration-fusion binocular diffusion model (RF-BDiff) to achieve continuous fusion of unregistered HSI and MSI. RF-BDiff alternately optimizes image registration and fusion tasks to gradually recover HR-HSI by repeated refinement over multi time steps. The refinement operation at each time step is performed by the specially designed implicit neural registration module (INRM) and invertible spatial–spectral fusion module (IS 2 FM). INRM parameterizes the mapping between spatial coordinates of MSI and spectral values of reconstructed image and HSI as continuous implicit functions to provide the registered spatial coordinates for subsequent refinement. IS 2 FM designs an invertible bijective transformation for modeling fusion problem of registered images to reduce the information loss in fusion process and enriches the spatial–spectral information of reconstructed image. INRM and IS 2 FM are executed alternately to continuous fuse unregistered HSI and MSI. Such a design is conducive to the generalization of RF-BDiff in real applications, and we especially provide a real dataset to verify its effectiveness in real scenarios. Systematic experiments on simulated and real datasets demonstrate the state-of-the-art performance of RF-BDiff.},
  archive      = {J_KBS},
  author       = {Xiaoyang Wu and Jiahui Qu and Wenqian Dong and Hongxiang Li and Song Xiao and Yunsong Li},
  doi          = {10.1016/j.knosys.2025.114007},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114007},
  shortjournal = {Knowl. Based Syst.},
  title        = {Registration-fusion binocular diffusion model: Exploring continuous fusion of unregistered hyperspectral and multispectral images},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual prompt-driven universal model for medical image segmentation in radiotherapy. <em>KBS</em>, <em>326</em>, 114006. (<a href='https://doi.org/10.1016/j.knosys.2025.114006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of organs at risk (OARs) and tumors plays an indispensable role during radiotherapy treatment planning. Due to the high time and labor costs of training specific models for each task, the universal model capable of simultaneously segmenting multiple OARs and tumors has drawn considerable research attention. However, most existing universal models concentrate on targets with well-defined boundaries like OARs and gross tumor volume (GTV), while clinical target volume (CTV) is vitally important but more challenging to segment due to its unclear boundaries. To solve this dilemma, we propose the Visual Prompt-Driven Universal Model (VPDUM), which introduces the visual prompts (clicks and bounding boxes) as priors to simulate the experience of radiation oncologists. Specifically, VPDUM consists of an encoder–decoder architecture, a Spatial Relation Construction module (SRC), several Spatial Relation Interaction modules (SRI), and a Transformer-Prompt Interaction Module (TPIM). First, SRC is responsible for establishing spatial relations between the input image and the provided prompts. Second, SRI leverages these spatial relations to guide the model to be aware of the spatial location, shape, and size of the target, enabling precise segmentation of CTV. Third, TPIM performs deep interactions between image features and prompts to further improve segmentation accuracy. To evaluate the performance of the proposed method, we conduct experiments on multiple medical datasets, including six clinical CTV datasets, an open-source dataset called UaNet with eight organ annotations, the KiTS19 dataset, and the MSD-Colon dataset. Experimental results demonstrate the superiority and efficiency of our method.},
  archive      = {J_KBS},
  author       = {Shengqian Zhu and Chengrong Yu and Zhang Yi and Junjie Hu},
  doi          = {10.1016/j.knosys.2025.114006},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114006},
  shortjournal = {Knowl. Based Syst.},
  title        = {Visual prompt-driven universal model for medical image segmentation in radiotherapy},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDVD: Self-supervised dual-view modeling of user and cascade dynamics for information diffusion prediction. <em>KBS</em>, <em>326</em>, 114005. (<a href='https://doi.org/10.1016/j.knosys.2025.114005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion prediction aims to estimate the likelihood of a user participating in a spreading message by leveraging social relationships and historical diffusion patterns. However, existing approaches often overlook a crucial factor: users’ participation behaviors are influenced by diverse and evolving motivations. Moreover, treating historical data as a whole may introduce noise from outdated information — especially as new users join — highlighting the dynamic nature of diffusion cascades. In addition, many current methods lack explicit supervision signals to effectively model these dynamics. To address these limitations, we propose SDVD, a novel framework for S elf-supervised D ual- V iew modeling of user and cascade D ynamics for information diffusion prediction. SDVD begins by constructing two auxiliary graphs from historical data: an adjacency dependency graph to capture temporal dependencies and a hypergraph to model group interactions. These structures explicitly model cascade dynamics and enhance user–cascade interaction understanding. We leverage graph neural networks and hypergraph neural networks to extract structural features from the graphs and introduce a user-aware fusion mechanism that integrates multisource information while reducing redundancy and noise. Furthermore, we design a self-supervised dual-view dynamic modeling module to learn temporal variations in diffusion patterns from both user and cascade perspectives. A cross-attention mechanism then combines static and dynamic representations, capturing contextual information within the cascade sequence. Experiments on four real-world datasets — with consistent preprocessing and data splitting — show that SDVD achieves statistically significant improvements ( p < 0 . 05 ), with up to a 6.63% increase in MAP@10.},
  archive      = {J_KBS},
  author       = {Haoyu Xiong and Jiaxing Shang and Fei Hao and Dajiang Liu and Geyong Min},
  doi          = {10.1016/j.knosys.2025.114005},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114005},
  shortjournal = {Knowl. Based Syst.},
  title        = {SDVD: Self-supervised dual-view modeling of user and cascade dynamics for information diffusion prediction},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving (α,f)-byzantine resilience in federated learning via layerwise aggregation and cosine distance. <em>KBS</em>, <em>326</em>, 114004. (<a href='https://doi.org/10.1016/j.knosys.2025.114004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of artificial intelligence systems has amplified societal concerns regarding their usage, necessitating regulatory frameworks that encompass data privacy. Federated learning (FL) is proposed as a potential solution to the challenges of data privacy in distributed machine learning by enabling collaborative model training without data sharing. However, FL systems remain vulnerable to Byzantine attacks, where malicious nodes contribute corrupted model updates. Although Byzantine resilient rules have emerged as a widely adopted robust aggregation algorithm to mitigate these attacks, their effectiveness drops significantly in high-dimensional parameter spaces, sometimes leading to poor-performing models. This paper introduces Layerwise Cosine Aggregation, a novel aggregation scheme designed to enhance the robustness of these rules in such high-dimensional settings while preserving computational efficiency. A theoretical analysis is presented, demonstrating the superior robustness of the proposed Layerwise Cosine Aggregation compared to the original robust aggregation rules. Empirical evaluation in diverse image classification datasets, under varying data distributions and Byzantine attack scenarios, consistently demonstrates the improved performance of Layerwise Cosine Aggregation, achieving up to a 16% increase in model accuracy.},
  archive      = {J_KBS},
  author       = {M. García-Márquez and N. Rodríguez-Barroso and M.V. Luzón and F. Herrera},
  doi          = {10.1016/j.knosys.2025.114004},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114004},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving (α,f)-byzantine resilience in federated learning via layerwise aggregation and cosine distance},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge enhancement and disentanglement learning for video captioning. <em>KBS</em>, <em>326</em>, 114003. (<a href='https://doi.org/10.1016/j.knosys.2025.114003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning, bridging computer vision and natural language, is crucial for various knowledge-based systems in the age of video streaming. Recent video captioning approaches have shown promise by integrating additional text-related knowledge to enhance understanding of video content and generate more informative captions. However, methods relying heavily on knowledge graphs face several limitations, including (i) a restricted capacity to reason complex relations among object words due to static logic rules, (ii) a lack of context awareness for spatio-temporal relation analysis in videos, and (iii) the complexity of manually constructing a knowledge graph. These limitations lead to insufficient semantic information and obstruct effective alignment between visual and textual modalities. To tackle these issues, we propose a novel knowledge enhancement and disentanglement learning method for video captioning. Our approach introduces a comprehensive and adaptable knowledge source to enhance text-related knowledge, thus directly improving caption generation. Specifically, we leverage a large language model to infer enriched semantic relations between object words and speech transcripts within video frames. By integrating visual, auditory, and textual information into universal tokens with task-specific prompts, our approach enhances semantic understanding and captures more diverse relations. Furthermore, we propose a novel modality-shared disentanglement learning strategy to better align modalities, enabling a more precise link of visual cues to their corresponding textual descriptions. Specifically, we disentangle two modalities into shared and specific features, leveraging shared features to ensure alignment while mitigating uncorrelated information. Extensive experiments demonstrate that our proposed method outperforms existing methods in both quantitative and qualitative results.},
  archive      = {J_KBS},
  author       = {Mingyue Wang and Yujun Ma and Biao Cai and Dongfen Li and Xiangjian He and Ruili Wang},
  doi          = {10.1016/j.knosys.2025.114003},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114003},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge enhancement and disentanglement learning for video captioning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain. <em>KBS</em>, <em>326</em>, 114001. (<a href='https://doi.org/10.1016/j.knosys.2025.114001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising influence of social media platforms in various domains, including tourism, has highlighted the growing need for efficient and automated Natural Language Processing (NLP) strategies to take advantage of this valuable resource. However, the transformation of multilingual, unstructured, and informal texts into structured knowledge still poses significant challenges, most notably the never-ending requirement for manually annotated data to train deep learning classifiers. In this work, we study different NLP techniques to establish the best ones to obtain competitive performances while keeping the need for training annotated data to a minimum. To do so, we built the first publicly available multilingual dataset (French, English, and Spanish) for the tourism domain, composed of tourism-related tweets. The dataset includes multilayered, manually revised annotations for Named Entity Recognition (NER) for Locations and Fine-grained Thematic Concepts Extraction mapped to the Thesaurus of Tourism and Leisure Activities of the World Tourism Organization, as well as for Sentiment Analysis at the tweet level. Extensive experimentation comparing various few-shot and fine-tuning techniques with modern language models demonstrate that modern few-shot techniques allow us to obtain competitive results for all three tasks with very little annotation data: 5 tweets per label (15 in total) for Sentiment Analysis, 30 tweets for Named Entity Recognition of Locations and 1K tweets annotated with fine-grained thematic concepts, a highly fine-grained sequence labeling task based on an inventory of 315 classes. We believe that our results, grounded in a novel dataset, pave the way for applying NLP to new domain-specific applications, reducing the need for manual annotations and circumventing the complexities of rule-based, ad-hoc solutions.},
  archive      = {J_KBS},
  author       = {Maxime Masson and Rodrigo Agerri and Christian Sallaberry and Marie-Noelle Bessagnet and Annig Le Parc Lacayrelle and Philippe Roose},
  doi          = {10.1016/j.knosys.2025.114001},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114001},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic tabular data generation using a VAE-GAN architecture. <em>KBS</em>, <em>326</em>, 113997. (<a href='https://doi.org/10.1016/j.knosys.2025.113997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data generation (SDG) can be used to augment an existing dataset or create a new dataset with statistical characteristics similar to the original. SDG for tabular data is challenging because of the need to model both continuous and categorical features and their correlations. multiple approaches for tabular SDG use generative adversarial networks (GAN) or variational autoencoders (VAEs). Generally, GAN-based architectures create high-quality samples but have greater difficulty modeling the distribution of the target dataset. VAE-based approaches accurately model the data distribution but sometimes produce lower-quality samples. In this study, we propose T-VAE-GAN, a novel solution for tabular SDG. Our approach hierarchically combines GANs and VAEs to enable the generation of high-quality samples while ensuring that the overall feature distribution is highly similar to that of the original dataset. Extensive evaluation on a large number of datasets shows that our approach either outperforms or achieves comparable results to leading approaches while also being more computationally efficient.},
  archive      = {J_KBS},
  author       = {Dmitry Anshelevich and Gilad Katz},
  doi          = {10.1016/j.knosys.2025.113997},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113997},
  shortjournal = {Knowl. Based Syst.},
  title        = {Synthetic tabular data generation using a VAE-GAN architecture},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal multi-task deep learning framework for classification of sentiment, emotion, humor, sarcasm and toxicity from speech. <em>KBS</em>, <em>326</em>, 113995. (<a href='https://doi.org/10.1016/j.knosys.2025.113995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents M2-S2ETH, a Multimodal Multi-task deep learning framework designed for recognizing Sentiment, Sarcasm, Emotion, Toxicity, and Humor from speech and text. M2-S2ETH overcomes the limitations of existing approaches, which mainly rely on datasets consisting of relatively short audio clips of 10–30 s. In contrast, we introduce MuSETHS, a new dataset consisting of videos sourced from social media platforms, featuring variable audio durations. This shift towards longer audios presents unique challenges in analyzing contextually rich content. The proposed architecture is specifically tailored to handle these longer audio segments, allowing for more complex interactions between different modes of communication. We leverage the attention mechanism to selectively focus on the most relevant parts of the audio, ensuring that the model can effectively capture the nuances in long audio data. In this work, three primary challenges are addressed: context dependency, multimodal fusion, and multi-task interaction. By addressing these issues, our model achieves significant improvements over state-of-the-art multimodal architectures in the tasks of emotion, sarcasm, humor, toxicity, and sentiment classification. This work not only broadens the scope of existing methodologies by considering long-form audio, but also demonstrates the efficacy of attention mechanisms like extracting meaningful insights from complex, real-world audio data.},
  archive      = {J_KBS},
  author       = {Harish Pratap Singh and Puneet Prashar and Gaddam Sai Bharath Chandra Reddy and Santosh Kumar Mishra},
  doi          = {10.1016/j.knosys.2025.113995},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113995},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal multi-task deep learning framework for classification of sentiment, emotion, humor, sarcasm and toxicity from speech},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language-guided change detection for high-resolution remote sensing imagery with limited labelled data. <em>KBS</em>, <em>326</em>, 113994. (<a href='https://doi.org/10.1016/j.knosys.2025.113994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been extensively applied in the field of remote sensing for tasks such as change detection (CD). However, since CD is a pixel-level task, the high cost of data annotation and often limited availability of labelled data significantly restrict the performance of existing deep learning-based CD methods. To mitigate this problem, a novel Language-Guided Change Detection (LGCD) framework is introduced. Within this LGCD network, text information is leveraged to precisely locate changed areas, addressing the shortcomings associated with insufficient labelled image data. Also, augmentation semi-supervised learning techniques are employed to generate high-quality pseudo-labels, further reducing the reliance on labelled samples. Additionally, the utilisation of Fusion UNet (FUNet) and Transformer capitalises on their sensitivity to local and global features respectively, offering a comprehensive examination of change features in high-resolution bi-temporal remote sensing imagery. For evaluation purposes, three publicly available CD datasets are exploited. Experimental results demonstrate that the proposed LGCD framework achieves exceptional detection performance in both fully supervised and semi-supervised settings, despite the constraints of limited labelled data.},
  archive      = {J_KBS},
  author       = {Xuan Hou and Yunpeng Bai and Yefan Xie and Ying Li and Changjing Shang and Qiang Shen},
  doi          = {10.1016/j.knosys.2025.113994},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113994},
  shortjournal = {Knowl. Based Syst.},
  title        = {Language-guided change detection for high-resolution remote sensing imagery with limited labelled data},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive confident masking attention network for Audio–Visual segmentation. <em>KBS</em>, <em>326</em>, 113992. (<a href='https://doi.org/10.1016/j.knosys.2025.113992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio and visual signals typically occur simultaneously, and humans possess an innate ability to correlate and synchronize information from these two modalities. Recently, a challenging problem known as Audio–Visual Segmentation (AVS) has emerged, intending to produce segmentation maps for sounding objects within a scene. However, the methods proposed so far have not sufficiently integrated audio and visual information, and the computational costs have been extremely high. Additionally, the outputs of different stages have not been fully utilized. To facilitate this research, we introduce a novel Progressive Confident Masking Attention Network (PMCANet). It leverages attention mechanisms to uncover the intrinsic correlations between audio signals and visual frames. Furthermore, we design an efficient and effective cross-attention module to enhance semantic perception by selecting query tokens. This selection is determined through confidence-driven units based on the network’s multi-stage predictive outputs. Experiments demonstrate that our network outperforms other AVS methods while requiring less computational resources. The code is available at: https://github.com/PrettyPlate/PCMANet .},
  archive      = {J_KBS},
  author       = {Yuxuan Wang and Jinchao Zhu and Feng Dong and Shuyue Zhu},
  doi          = {10.1016/j.knosys.2025.113992},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113992},
  shortjournal = {Knowl. Based Syst.},
  title        = {Progressive confident masking attention network for Audio–Visual segmentation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biclustering-KNN joint learning in anomaly detection for handling class-imbalance-problem. <em>KBS</em>, <em>326</em>, 113991. (<a href='https://doi.org/10.1016/j.knosys.2025.113991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of imbalanced data sets is a major challenge in machine learning. To overcome the limitations of existing methods, this paper proposes an ensembled bicluster-based classification method (EBC) approach to address the problem of imbalanced data. This method combines biclustering algorithms, anomaly detection algorithms, and ensemble learning to perform classification tasks on imbalanced datasets. Existing methods model majority samples in specific feature spaces, leading to learning relatively limited distributions. EBC integrates bicluster with anomaly detection to construct basic classifiers, allowing the model to learn more diverse distributions. Additionally, many existing methods only model majority samples, which may result in misclassifications. EBC adopts a two-stage classification framework, where the first stage models majority samples and the second stage models minority samples. This approach not only improves the classification accuracy of minority samples but also ensures the accuracy of majority samples, ultimately enhancing the model’s generalization performance. To ensure diversity among basic classifiers, each basic classifier in EBC corresponds to a unique biclustering result comprising different samples and features. Comparative experiments between the proposed algorithm and several typical algorithms demonstrate the effectiveness of the proposed algorithm. It performed best in 20 groups of comparative experiments with different imbalance ratios. The average GMeans on all data sets is 85.96%, which is 22.27% better than baseline, significantly ahead of other comparison algorithms.},
  archive      = {J_KBS},
  author       = {Zhenkun Lu and Haohan Wei and Fengyu Ye and Qinghua Huang},
  doi          = {10.1016/j.knosys.2025.113991},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113991},
  shortjournal = {Knowl. Based Syst.},
  title        = {Biclustering-KNN joint learning in anomaly detection for handling class-imbalance-problem},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised equilibrium K-means for imbalanced data clustering. <em>KBS</em>, <em>326</em>, 113990. (<a href='https://doi.org/10.1016/j.knosys.2025.113990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equilibrium K-means (EKM) represents a novel advancement in fuzzy clustering methodologies, outperforming Bezdek’s fuzzy C-means (FCM) algorithm when applied to datasets with imbalanced distributions. Nonetheless, EKM is inherently limited by its inability to integrate supervision information, rendering it less effective in scenarios wherein partial data labels are accessible. In this paper, we propose a semi-supervised variant of EKM (SSEKM) that can effectively leverage supervision knowledge. The effects of supervision knowledge on the model and convergence behavior are elucidated via theoretical analysis. Empirical evaluations conducted on four synthetic and 16 real-world datasets from medical, biological, and industrial sectors indicate that SSEKM exhibits competitive performance against semi-supervised FCM (SSFCM) and other state-of-the-art semi-supervised fuzzy clustering algorithms on balanced datasets and surpasses them on imbalanced datasets. Additionally, SSEKM maintains a computational complexity comparable to SSFCM and offers a higher convergence speed than most comparative algorithms.},
  archive      = {J_KBS},
  author       = {Yudong He},
  doi          = {10.1016/j.knosys.2025.113990},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113990},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised equilibrium K-means for imbalanced data clustering},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cluster-wise regression method for distribution-valued data. <em>KBS</em>, <em>326</em>, 113989. (<a href='https://doi.org/10.1016/j.knosys.2025.113989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a cluster-wise regression method for distributional data. The objects to be clustered are elements of p + 1 distributional variables, { Y , X 1 , … , X p } , where Y is the response variable and the X j ’s are the p predictors. In light of recent advancements in distributional data analysis (DDA), we propose transforming distributional data into logarithmic-derived quantile (LDQ) functions. This transformation enables the mapping of density functions within a Hilbert space, effectively addressing several challenges inherent to DDA. A functional data regression model is then applied to the LDQ functions, extending the classical ordinary least squares method to such data for predicting the response variable within each cluster model. This new strategy removes the non-negativity constraint on the regression model parameters, which was introduced in previous methods to ensure that the predicted variable could still be expressed as a distributional variable through an inverse transformation of the LDQ functions. The proposed cluster-wise regression method for distributional data alternates between assigning elements to clusters — based on minimizing the sum of squared errors for each regression model — and estimating the cluster regression models until convergence to a stable solution. Applications on both synthetic and real data confirm the effectiveness of the new cluster-wise regression method for distributional data, even when compared to a single global model.},
  archive      = {J_KBS},
  author       = {Antonio Balzanella and Rosanna Verde and Francisco de Assis Tenorio de Carvalho},
  doi          = {10.1016/j.knosys.2025.113989},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113989},
  shortjournal = {Knowl. Based Syst.},
  title        = {A cluster-wise regression method for distribution-valued data},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ClusterRiceNet: A novel rice seed variety classification network based on hyperspectral imaging and spectral band clustering. <em>KBS</em>, <em>326</em>, 113988. (<a href='https://doi.org/10.1016/j.knosys.2025.113988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice seed variety classification is crucial for agricultural production and seed quality control. Hyperspectral imaging technology enables the detection of subtle spectral variations between varieties but suffers from high dimensionality and information redundancy. Traditional dimensionality reduction methods, such as band selection and feature extraction, often result in the loss of critical details or compromise physical significance of spectral bands. To address these issues, we propose ClusterRiceNet, a novel rice seed classification network based on hyperspectral imaging and spectral band clustering. Within ClusterRiceNet, an Input Space Redefinition algorithm (ISRK) is designed to reduce spectral redundancy while preserving the physical significance of all bands and enabling flexible data augmentation. Furthermore, two feature extraction modules at different granularities, i.e. SFEIDT (Isometric Domain Transformation-based Spectral Feature Extraction) and GDFE (Swin-Transformer-based Global Dependency Feature Extraction), are introduced to capture discriminative spectral details and nonlocal dependencies, respectively. Finally, a fusion module integrates these features into a unified representation for efficient, non-destructive classification. Experiments on two constructed rice seed hyperspectral datasets show that ClusterRiceNet outperforms eight state-of-the-art image classification models and four advanced rice classification networks in terms of accuracy, F1-score, and κ coefficient. The proposed framework provides a new perspective for efficient and physically meaningful hyperspectral image analysis across diverse domains.},
  archive      = {J_KBS},
  author       = {Shuang Yu and Zikang Wang and Zeyu Wang and Mingyi Liu and Yongze Zhan and Shaozong Song and Zhongjie Wang},
  doi          = {10.1016/j.knosys.2025.113988},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113988},
  shortjournal = {Knowl. Based Syst.},
  title        = {ClusterRiceNet: A novel rice seed variety classification network based on hyperspectral imaging and spectral band clustering},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ATESA-BÆRT: A heterogeneous ensemble learning model for aspect-based sentiment analysis. <em>KBS</em>, <em>326</em>, 113987. (<a href='https://doi.org/10.1016/j.knosys.2025.113987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing volume of online reviews has made the development of sentiment analysis models possible for determining customers’ opinions regarding different products and services. Until now, sentiment analysis has proven to be an effective tool for determining the overall polarity of reviews. To improve the granularity at the aspect level for a better understanding of the service or product, the task of aspect-based sentiment analysis aims to first identify aspects and then determine the user’s opinion about them. The complexity of this task lies in the fact that the same review can present multiple aspects, each with its own polarity. Current solutions have poor performance on such data. We address this problem by proposing ATESA-BÆRT, a heterogeneous ensemble learning model for Aspect-Based Sentiment Analysis. Firstly, we divide our problem into two sub-tasks, i.e., Aspect Term Extraction and Aspect Term Sentiment Analysis. Secondly, we use the argmax multi-class classification on six transformers-based learners for each sub-task. The proposed ensemble integrates representations from pre-trained and fine-tuned BERT and BART models in order to capture diverse linguistic features. By combining these with Linear , BiLSTM , and CNN-BiLSTM models, we aim to achieve enhanced performance on the aspect-based sentiment analysis task. Initial experiments on two publicly available real-world English online review datasets prove that ATESA-BÆRT outperforms current state-of-the-art solutions while tackling the sentiment analysis many aspects problem.},
  archive      = {J_KBS},
  author       = {Elena-Simona Apostol and Alin-Georgian Pisică and Ciprian-Octavian Truică},
  doi          = {10.1016/j.knosys.2025.113987},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113987},
  shortjournal = {Knowl. Based Syst.},
  title        = {ATESA-BÆRT: A heterogeneous ensemble learning model for aspect-based sentiment analysis},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projection-iterative-methods-based optimizer: A novel metaheuristic algorithm for continuous optimization problems and feature selection. <em>KBS</em>, <em>326</em>, 113978. (<a href='https://doi.org/10.1016/j.knosys.2025.113978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Projection-Iterative-Methods-based Optimizer (PIMO) is a novel metaheuristic algorithm inspired by projection iterative methods. PIMO introduces four new operators to guide the population towards optimal convergence while enhancing both exploration and convergence speed. This approach, presented for the first time, integrates techniques such as Kaczmarz and stochastic gradient descent to improve performance and prevent convergence to local optima. The effectiveness of PIMO is validated through three sets of experiments: the CEC2017 benchmark functions, four real-world constrained problems, and twelve UCI datasets, where it outperforms five excellent feature selection algorithms. The numerical results indicate that PIMO consistently surpasses other algorithms across various problems, including eleven highly referenced new algorithms, seven state-of-the-art algorithms, seven novel mathematics-inspired algorithms, and five leading binary algorithms. The findings confirm that PIMO is robust, user-friendly, and effective for both continuous and discrete problem-solving. The source code for the PIMO is publicly available at https://www.mathworks.com/matlabcentral/fileexchange/181013-pimo .},
  archive      = {J_KBS},
  author       = {Dongmei Yu and Yanzhe Ji and Yiqiang Xia},
  doi          = {10.1016/j.knosys.2025.113978},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113978},
  shortjournal = {Knowl. Based Syst.},
  title        = {Projection-iterative-methods-based optimizer: A novel metaheuristic algorithm for continuous optimization problems and feature selection},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for evaluation and requirement extraction for fine-tuning of large language models in multimodal medical diagnosis. <em>KBS</em>, <em>326</em>, 113975. (<a href='https://doi.org/10.1016/j.knosys.2025.113975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: Large language models constitute a breakthrough state-of-the-art Artificial Intelligence technology which is rapidly evolving and promises to aid in medical diagnosis. In this study, we propose a novel evaluation framework for extraction of fine-tuning requirements based on the Objective Structured Clinical Examinations (OSCE) that can increase LLM potential and applicability. Methods: We developed an OSCE based evaluation meta-framework leveraging IoT-based data retrieval with a two-step approach designed to analyze and guide improvement of LLMs in multimodal medical diagnosis: (1) structured interaction evaluation and (2) domain-specific analysis of extracted data. Using Image-Metadata Analysis (IMA), Named Entity Recognition (NER), and Knowledge Graphs (KG), this framework identifies image domains, extracts relevant entities, and assesses connections in KGs. These methods collectively reveal areas for improvement, guiding fine-tuning to enhance diagnostic accuracy and contextual understanding in medical applications. Results: Using this paradigm, (1) we evaluate the correctness and accuracy of generated medical diagnosis with publicly available multimodal-multiple-choice-questions in the vast domain of General Pathology and (2) proceed to the domain-specific analysis. We identify and visualize the model performance across specific organs, diseases, and pathological themes, detecting areas of lower accuracy, such as in cardiovascular conditions like atherosclerosis. This targeted approach enables precision-focused fine-tuning, applying additional data to specific weaknesses rather than a broad, generalized tuning across all pathology. Contributions: Our framework’s primary contribution is its OSCE-inspired ability to dynamically identify and target under-performing areas within a broad domain, enhancing fine-tuning efficiency and diagnostic accuracy in a resource-effective and iterative manner removing the dependency on bulk adjustments, making it particularly suitable for sensitive applications where precision and resource efficiency are essential, such as in medical diagnostics.},
  archive      = {J_KBS},
  author       = {Dimitrios P. Panagoulias and Anastasios Palamidas and Maria Virvou and George A. Tsihrintzis},
  doi          = {10.1016/j.knosys.2025.113975},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113975},
  shortjournal = {Knowl. Based Syst.},
  title        = {A framework for evaluation and requirement extraction for fine-tuning of large language models in multimodal medical diagnosis},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tri-level interaction fusion network for graph similarity learning. <em>KBS</em>, <em>326</em>, 113969. (<a href='https://doi.org/10.1016/j.knosys.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph similarity learning is vital in various domains, such as chemical molecular structure comparison and transportation network optimization. Although existing graph similarity learning methods are effective, the following challenges still exist: (i) how to enrich node representation, (ii) how to capture and fuse multi-level graph interaction information, and (iii) how to effectively learn rich graph interaction features. To address these challenges, we propose a novel three-level interaction fusion network (TIFN) by fusing node-node, node-graph, and graph-graph interaction information at different stages to capture the complex interdependencies between graphs. At the enhanced node embedding learning stage, we first propose a skip-connected multi-layer graph isomorphism network to extract high-quality node features and present a novel style-based multi-head attention mechanism to capture long-range dependencies between nodes. At the dual graph interaction learning stage, we model graph dependencies from multi-granularity and multi-perspective views. Specifically, we effectively incorporate a coarse-fine grained aggregation module and a node-graph interaction comparison module to learn rich graph interaction features. At the similarity score stage, global-level graph-graph interactions transform the aggregated features into a final score. Extensive experimental results demonstrate the performance of TIFN by comparing it with 15 baselines on three benchmark datasets. Notably, on the LINUX dataset, TIFN achieves approximately 45.79% improvement in MSE compared to the state-of-the-art method.},
  archive      = {J_KBS},
  author       = {Yan Kang and Hao Peng and Yue Peng and Jing Guo and Ying Lin},
  doi          = {10.1016/j.knosys.2025.113969},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113969},
  shortjournal = {Knowl. Based Syst.},
  title        = {Tri-level interaction fusion network for graph similarity learning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing deep neural network training through learnable adaptive normalization. <em>KBS</em>, <em>326</em>, 113968. (<a href='https://doi.org/10.1016/j.knosys.2025.113968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalization is a fundamental preprocessing technique in data science, commonly used to standardize data distributions prior to model training. Its primary role is to maintain consistent statistical properties across features, which facilitates efficient learning and enhances training stability. In deep learning, normalization methods are particularly beneficial, as they regulate input distributions within neural networks, promoting more stable training and faster convergence. This study introduces and evaluates a novel approach: learnable adaptive normalization layers integrated into neural networks. Experiments were conducted across nine datasets encompassing feature, image, and time-series data, utilizing various deep learning architectures, including feed-forward, convolutional, and transformer-based neural networks. The results demonstrate that adaptive normalization consistently outperforms traditional methods, such as mean subtraction, standard deviation scaling, and layer normalization. Moreover, in many scenarios, adaptive normalization achieved performance that was either superior to or comparable with batch normalization, with image classification being the notable exception. These findings indicate that adaptive normalization not only accelerates training convergence but also enhances final model performance in most cases, underscoring its effectiveness. Given that the choice of network architecture is inherently a hyperparameter tuning challenge, we recommend considering adaptive normalization in the preprocessing step for future networks. Furthermore, replacing batch or layer normalization with adaptive normalization may lead to improved training efficiency and final performance, depending on the specific problem.},
  archive      = {J_KBS},
  author       = {Jan Benedikt Ruhland and Iraj Masoudian and Dominik Heider},
  doi          = {10.1016/j.knosys.2025.113968},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113968},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing deep neural network training through learnable adaptive normalization},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharpness-aware minimization method with momentum acceleration for deep neural networks. <em>KBS</em>, <em>326</em>, 113967. (<a href='https://doi.org/10.1016/j.knosys.2025.113967'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharpness-Aware Minimization (SAM) utilizes gradient ascent perturbations to find a flat region during the training, thereby improving the generalization of the deep neural networks (DNNs). However, simple gradient ascent perturbations cannot guarantee that SAM finds flatter regions. To address this issue, this paper introduces momentum acceleration and Nesterov accelerated gradient (NAG) techniques to the SAM algorithm, named MNSAM. Specifically, momentum acceleration is used in the inner loop to allow MNSAM to skip sharp areas and find flatter areas, while NAG is used in the outer loop to accelerate MNSAM. Theoretically, we investigate the convergence of MNSAM in a nonconvex setting under mild assumptions, showing that the minimum expected squared gradient of MNSAM can converge to zero. Additionally, we obtain the sublinear convergence rates of MNSAM with diminishing step sizes and fixed step sizes. Finally, we empirically validate the performance of MNSAM on benchmark datasets: CIFAR-10, CIFAR-100 and ImageNet-1K. Experimental results show that MNSAM has a faster convergence rate and better generalization performance than the state-of-the-art optimizers. The PyTorch code of MNSAM is available at https://github.com/kksmd520/MNSAM .},
  archive      = {J_KBS},
  author       = {Helei Kang and Yiming Jiang and Jinlan Liu and Dongpo Xu},
  doi          = {10.1016/j.knosys.2025.113967},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113967},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sharpness-aware minimization method with momentum acceleration for deep neural networks},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLIP-MEI: Exploit more effective information for few-shot action recognition. <em>KBS</em>, <em>326</em>, 113965. (<a href='https://doi.org/10.1016/j.knosys.2025.113965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition (FSAR) aims to address the challenge of limited labeled data, yet most existing methods struggle to effectively tackle the insufficient visual information arising from scarce labeled samples. So, this paper proposes the CLIP-MEI (Contrastive Language-Image Pre-training, More Effective Information) framework, which enhances model representation through multi-modal feature fusion and latent information mining. Specifically, we build a CLIP-based prototype matching framework and design three core modules: (1) Query-specific Semantic information Augmentation (QSA), which generates adaptive semantic embeddings by integrating support set label semantics with query visual features to mitigate semantic disparities between support and query sets; (2) Task-based Feature Enhancement (TFE), which optimizes feature representations by exploiting latent relationships between support and query sets within the same task; and (3) Motion Information Compensation (MIC), which extracts highly invariant motion features by aligning shallow and deep motion representations. Extensive experimental results demonstrate that CLIP-MEI establishes new performance records across diverse benchmark datasets, notably achieving leading results on HMDB51. For example, it attains a 1-shot accuracy of 76.4% on HMDB51, outperforming baseline by 10.1%. The implementation can be accessed via GitHub .},
  archive      = {J_KBS},
  author       = {XuanHan Deng and WenZhu Yang and XinBo Zhao and Tong Zhou and Xin Deng},
  doi          = {10.1016/j.knosys.2025.113965},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113965},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLIP-MEI: Exploit more effective information for few-shot action recognition},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy-guided meta-initialization regularization for few-shot text classification. <em>KBS</em>, <em>326</em>, 113961. (<a href='https://doi.org/10.1016/j.knosys.2025.113961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning has emerged as the dominant approach for tackling the problem of limited datasets in text classification and achieved state-of-the-art performance. In particular, gradient-based meta-learning finds good meta-initialization (parameters) through learning on a variety of tasks, which is known to be effective for the few-shot problem. However, we find that meta-initialization of the existing method has an over-confidence for the specific class before task adaptation, which potentially leads to deterioration in generalization performance. To address this issue, we propose a simple and effective Entropy-Guided Meta-Initialization regularization (EGMI) method. The proposed EGMI focuses on maximizing entropy so that the model has meta-initialization to prevent over-confidence for specific classes. In our experiments, we show that EGMI outperforms the current state-of-the-art methods on few-shot benchmark datasets by a large margin. In particular, we achieve a performance improvement from 84.13% to 91.36% on the 15-way 5-shot of the clinc150 dataset. We also do not need any additional parameters and the training cost does not increase. Our code is publicly available https://anonymous.4open.science/r/EGMI-9D60/README.md .},
  archive      = {J_KBS},
  author       = {Jongyun Shin and Jinwoo Kim and Jangho Kim},
  doi          = {10.1016/j.knosys.2025.113961},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113961},
  shortjournal = {Knowl. Based Syst.},
  title        = {Entropy-guided meta-initialization regularization for few-shot text classification},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multiview clustering through consistency fusion of shared bipartite graphs. <em>KBS</em>, <em>326</em>, 113960. (<a href='https://doi.org/10.1016/j.knosys.2025.113960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph learning has gained increasing popularity in multiview clustering tasks, as it enables the construction of a unified and robust graph that integrates information from multiple views. Despite significant advancements in this area, several key limitations persist. Firstly, many existing algorithms suffer from high computational complexity, making them impractical for handling large-scale datasets. Secondly, most methods employ single-stage fusion strategies to combine multiview information, thereby overlooking the potential benefits of progressive multistage fusion. Lastly, existing graph learning methods predominantly focus on enforcing consistency across views, while neglecting potential inconsistencies between views. To address these challenges;a novel approach called Scalable Multiview Clustering through Consistency Fusion of Shared Bipartite Graphs (MVC-CFBG) is proposed. The method introduces the concept of arbitrary view groups to flexibly capture diverse relationships among views. Early stage fusions are performed simultaneously within these arbitrary view groups to generate view-shared bipartite graphs that compactly represent the shared structure. Furthermore, for the late-stage fusion, the proposed framework explicitly models both multiview consistency and inconsistency within a unified objective function. Multiview consistency is iteratively learned from the bipartite graphs and progressively integrated into a final unified graph that is both robust and scalable. Extensive experiments on 15 benchmark multiview datasets demonstrate that MVC-CFBG consistently outperforms state-of-the-art methods, particularly excelling in scalability and clustering accuracy on large datasets.},
  archive      = {J_KBS},
  author       = {Shalini and Avaneesh Singh and Krishna Kumar Sharma and Ayan Seal},
  doi          = {10.1016/j.knosys.2025.113960},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113960},
  shortjournal = {Knowl. Based Syst.},
  title        = {Scalable multiview clustering through consistency fusion of shared bipartite graphs},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CVC: Further aligning LLMs via cross-view correction for time series forecasting. <em>KBS</em>, <em>326</em>, 113957. (<a href='https://doi.org/10.1016/j.knosys.2025.113957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With robust reasoning and pattern recognition capabilities, Large Language Models (LLMs) show great promise in time series forecasting. However, the inherent modality gap between textual and time series data poses significant challenges for LLM-based applications. To tackle this challenge, we propose the Cross-View Correction (CVC) framework, a novel approach designed to enhance modality alignment in LLM-based time series forecasting. CVC employs a dual-branch LLM architecture that integrates two complementary alignment strategies to address the modality gap between time series and text: a weighted attention mechanism that adaptively fuses time-frequency and semantic features for improved cross-modal interaction, and a graph-based prompt learning method that dynamically selects prompts for detailed semantic alignment. Furthermore, a contrastive correction mechanism is employed within CVC to mitigate redundancy interference and further align modalities by comparing the intermediate representations and final outputs of the two LLM branches. Extensive experiments on public benchmarks demonstrate that CVC consistently outperforms state-of-the-art methods across both common and challenging scenarios. The code will be available in https://github.com/dsglff/CVC .},
  archive      = {J_KBS},
  author       = {Feifei Li and Haote Xu and Haodi Xu and Yinhao Liu and Xinghao Ding},
  doi          = {10.1016/j.knosys.2025.113957},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113957},
  shortjournal = {Knowl. Based Syst.},
  title        = {CVC: Further aligning LLMs via cross-view correction for time series forecasting},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perspective shifts: Cultivating teacher diversity in online knowledge distillation. <em>KBS</em>, <em>326</em>, 113955. (<a href='https://doi.org/10.1016/j.knosys.2025.113955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Knowledge Distillation (KD) is an emerging paradigm capable of generating posterior knowledge without a pre-trained teacher. Online KD concurrently trains auxiliary teachers and a student, wherein the ensemble of teachers collaboratively guides the student’s learning trajectory. While diversity is crucial in ensemble learning, achieving it is a challenging task, particularly in multi-head structures where teachers share parts of their parameters. We propose a novel online KD framework designed to explicitly cultivate diverse teachers by exposing them to heterogeneous label distributions. This might seem infeasible because all teachers and the student in online KD use the same mini-batch for efficiency and knowledge transfer. Our key idea is the adoption of importance sampling, which enables teachers to experience diverse perspectives by controlling exposure to the data based on labels. To merge the knowledge of these teachers exposed to different label distributions, we employ post-compensating Softmax that adjusts the posteriors to compensate for the distorted prior. Extensive experimental analysis demonstrates the effectiveness of our approach in improving the student’s performance and enhancing its feature representations for downstream computer vision tasks.},
  archive      = {J_KBS},
  author       = {Mincheol Park and Woojeong Kim and Junsik Bang and Yuna Park and Won Woo Ro and Suhyun Kim},
  doi          = {10.1016/j.knosys.2025.113955},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113955},
  shortjournal = {Knowl. Based Syst.},
  title        = {Perspective shifts: Cultivating teacher diversity in online knowledge distillation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMK-KEN: A high-performance approach for assessing knowledge value in citation network. <em>KBS</em>, <em>326</em>, 113949. (<a href='https://doi.org/10.1016/j.knosys.2025.113949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of academic literature, effectively evaluating the knowledge value of literature has become crucial. However, existing citation evaluation methods face challenges of low efficiency and insufficient robustness when dealing with large-scale citation networks. Traditional methods mainly rely on citation frequency, which can lead to overlooking many highly contributory papers. Moreover, graph neural network (GNN)-based methods, despite their excellence in structural information acquisition, typically require modeling the entire citation network, resulting in high computational costs and lengthy training times. To address these challenges, we introduce EMK-KEN, a novel evaluation approach that combines the Mamba and KAN architectures. This approach enables efficient capture of citation network structural information and precise assessment of knowledge value. EMK-KEN uses Mamba to process bibliographic metadata and text embeddings, enhancing model efficiency, and leverages KAN to capture the topological patterns of citation networks, achieving effective improvements in robustness and generalization. Experimental results demonstrate that EMK-KEN outperforms existing methods in computational efficiency, robustness, and generalization. It also shows practical application potential in scientometric analysis and academic recommendation systems, helping researchers identify high-impact articles more accurately.},
  archive      = {J_KBS},
  author       = {Chengzhi Liu and Zehui Qu},
  doi          = {10.1016/j.knosys.2025.113949},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113949},
  shortjournal = {Knowl. Based Syst.},
  title        = {EMK-KEN: A high-performance approach for assessing knowledge value in citation network},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-confidence pseudo-label graph guided multi-view clustering structure discovery. <em>KBS</em>, <em>326</em>, 113942. (<a href='https://doi.org/10.1016/j.knosys.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multi-view clustering methods based on contrastive learning have gained significant attention because of deep neural networks’ powerful representational capabilities. However, most existing methods focus primarily on learning consistent representations of the same sample across different views, or they rely on traditional clustering to improve the clustering structure. These limitations hinder the thorough exploration of the clustering structure in multi-view data, frequently resulting in suboptimal clustering performance or requiring additional post-processing. To address these challenges, this study introduces the high-confidence pseudo-label graph-guided multi-view clustering structure discovery for exploring clustering structures in multi-view data at both inter- and intra-class levels, resulting in more accurate clustering without post-processing. First, at the class level, category alignment is used to reduce inconsistencies in category information across views, resulting in initially aligned category assignments. Meanwhile, negative pairs in the loss function reduce ambiguous samples while increasing inter-class distances. Second, at the sample level, using pre-aligned pseudo-labels derived earlier, we detect high-confidence similar samples across and within views, increasing the similarity of their embedding features. Thus, intra-class distances are reduced. By jointly optimizing inter- and intra-class clustering structures, the proposed framework achieves precise clustering directly from pseudo-labels. Extensive experiments on benchmark multi-view datasets show that it outperforms state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Zengbiao Yang and Yihua Tan},
  doi          = {10.1016/j.knosys.2025.113942},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113942},
  shortjournal = {Knowl. Based Syst.},
  title        = {High-confidence pseudo-label graph guided multi-view clustering structure discovery},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive deep reinforcement learning with multi-agent systems for adaptive time series forecasting. <em>KBS</em>, <em>326</em>, 113941. (<a href='https://doi.org/10.1016/j.knosys.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has been increasingly applied in monitoring applications because of its ability to learn from previous experiences and make adaptive decisions. However, existing machine learning-based health monitoring applications are mostly supervised learning algorithms, trained on labels, and they cannot make adaptive decisions in an uncertain, complex environment. This study proposes a novel and generic system, predictive deep reinforcement learning (PDRL), with multiple RL agents in a time series forecasting environment. The proposed generic framework accommodates virtual Deep Q Network (DQN) agents to monitor predicted future states of a complex environment with a well-defined reward policy so that the agent learns existing knowledge while maximizing their rewards. In the evaluation process of the proposed framework, three DRL agents were deployed to monitor a subject’s future heart rate, respiration, and temperature predicted using a BiLSTM model. With each iteration, the three agents were able to learn the associated patterns, and their cumulative rewards gradually increased. It outperformed the baseline models for all three monitoring agents. The proposed PDRL framework achieves state-of-the-art performance in time series forecasting by effectively integrating reinforcement learning agents with deep learning-based prediction. The proposed DRL agents and deep learning model in the PDRL framework are customized to enable transfer learning in other forecasting applications like traffic and weather, and monitor their states. The PDRL framework is able to learn the future states of the traffic and weather forecasting, and the cumulative rewards are gradually increasing over each episode.},
  archive      = {J_KBS},
  author       = {Thanveer Shaik and Xiaohui Tao and Lin Li and Haoran Xie and U.R. Acharya and Raj Gururajan and Xujuan Zhou},
  doi          = {10.1016/j.knosys.2025.113941},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113941},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predictive deep reinforcement learning with multi-agent systems for adaptive time series forecasting},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private-library-oriented code generation with large language models. <em>KBS</em>, <em>326</em>, 113934. (<a href='https://doi.org/10.1016/j.knosys.2025.113934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs), such as Codex and GPT-4, have recently showcased their remarkable code generation abilities, facilitating a significant boost in coding efficiency. This study explored the utilization of LLMs for code generation in private libraries, as they are widely employed in everyday programming. Despite their remarkable capabilities, generating such private APIs poses a formidable challenge for LLMs, as they inherently lack exposure to these private libraries during pre-training. To address this challenge, we propose a novel framework that emulates the process of programmers writing private code. This framework comprises two modules: APIFinder first retrieves potentially useful APIs from API documentation, and APICoder then leverages these retrieved APIs to generate private code. Specifically, APIFinder employs vector retrieval techniques and allows user involvement in the retrieval process, while APICoder can directly utilize off-the-shelf code generation models. To further cultivate explicit proficiency in invoking APIs from prompts, we continuously pre-train a reinforced version of APICoder, named CodeGenAPI . Our goal is to train the above two modules on vast public libraries, enabling their generalization to private libraries. Meanwhile, we created four private library benchmarks, TorchDataEval, TorchDataComplexEval, MonkeyEval, and BeatNumEval, and meticulously handcrafted test cases for each benchmark to support comprehensive evaluations. Numerous experiments on the four benchmarks consistently affirm the effectiveness of the proposed approach. Furthermore, a deeper analysis was conducted to gain additional insights.},
  archive      = {J_KBS},
  author       = {Daoguang Zan and Bei Chen and Yongshun Gong and Junzhi Cao and Fengji Zhang and Bingchao Wu and Bei Guan and Yilong Yin and Yongji Wang},
  doi          = {10.1016/j.knosys.2025.113934},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113934},
  shortjournal = {Knowl. Based Syst.},
  title        = {Private-library-oriented code generation with large language models},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly supervised semantic segmentation via multi-type semantic affinity learning. <em>KBS</em>, <em>326</em>, 113933. (<a href='https://doi.org/10.1016/j.knosys.2025.113933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation methods typically utilize class activation maps (CAMs) to generate pixel-level pseudo annotations, thereby reducing the burden of manual labeling. However, existing methods fail to address the problem of sparse localization in CAMs, resulting in inaccurate pseudo annotations. This sparsity arises primarily from insufficient local details, a disregard for semantic context, and a lack of pixel-level supervision. To address these challenges, we introduce a novel multi-type semantic affinity learning method that enhances the classification network, yielding more complete object regions compared to traditional generation techniques. Specifically, we present a dynamic convolutional reconstruction module, that integrates pixel-to-superpixel semantic affinity within the classification network, improving the network’s ability to capture local details and producing low-resolution CAMs enriched with fine-grained information. We also implement a pixel-to-superpixel semantic affinity-based upsampling scheme to create full-resolution CAMs, which serve as the final localization cues while maintaining spatial coherence in object regions. Additionally, we propose an affinity propagation module designed to incorporate pixel-to-pixel semantic affinity into the lowresolution CAMs, enhancing the accuracy of object localization by effectively leveraging semantic context. Furthermore, we propose an intra-patch prototype contrast loss that utilizes pixel-to-prototype semantic affinity to reconstruct the input image, facilitating pixel-level supervision of CAMs by minimizing the distance between the reconstructed image and the original input, thereby activating more precise object regions. Extensive experiments on the PASCAL VOC 2012 and MS COCO 2014 datasets demonstrate that our proposed method achieves state-of-the-art performance. Codes are available at: https://github.com/CHENDL-SHEN/MSA .},
  archive      = {J_KBS},
  author       = {Zheng Xue and Dinghao Guo and Dali Chen and Yumin Zhang and Xin Lin and Shixin Liu},
  doi          = {10.1016/j.knosys.2025.113933},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113933},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly supervised semantic segmentation via multi-type semantic affinity learning},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive many-task differential evolution with reinforcement learning and meta-knowledge transfer. <em>KBS</em>, <em>326</em>, 113931. (<a href='https://doi.org/10.1016/j.knosys.2025.113931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive many-task optimization (CMaTO) is a special many-task optimization paradigm whose purpose is to find the best optimal solution for all tasks. However, the existing CMaTO algorithms perform poorly in the design of knowledge transfer from auxiliary tasks to the main task, resulting in a prolonged period of stagnant optimal fitness for the main task. To address these shortcomings, a competitive many-task optimization algorithm is proposed, based on reinforcement learning and meta-knowledge transfer, leveraging differential evolution as a foundational evolutionary strategy. This algorithm employs a reinforcement learning algorithm to select auxiliary tasks that can accelerate the convergence of the optimal value or jump out of the stagnation state according to the evolutionary state. Meanwhile, a stagnation detection operator is designed to switch the main task when the optimal value stagnation threshold upper limitation is reached. Furthermore, the meta-knowledge migration algorithm is embedded to judge the evolutionary state of the population based on the distance between the optimal solution and the centroid of the population. The migration radius is adaptively adjusted, and the knowledge is utilized to facilitate the evolution of high-quality solutions for the source task, which can assist the population in accelerating convergence or escaping a local optimum. To evaluate the performance of the proposed algorithm, three CMaTO benchmark test suites and a real-world Unmanned Aerial Vehicle (UAV) task allocation problem are chosen to compare it with other state-of-the-art strategies. The results show that the proposed algorithm achieved better performance.},
  archive      = {J_KBS},
  author       = {Yuxuan Song and Yue Xu and Dechang Pi and Shengxiang Yang},
  doi          = {10.1016/j.knosys.2025.113931},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113931},
  shortjournal = {Knowl. Based Syst.},
  title        = {Competitive many-task differential evolution with reinforcement learning and meta-knowledge transfer},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADBNet: Asymmetric dual-branch network for indoor real-time RGB-D semantic segmentation. <em>KBS</em>, <em>326</em>, 113885. (<a href='https://doi.org/10.1016/j.knosys.2025.113885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time RGB-D semantic segmentation is critical for a wide range of visual scene understanding tasks. Although recent methods have achieved notable progress, they still face significant challenges in fully exploiting depth information and achieving robust RGB-D fusion, particularly under the constraints of real-time performance. Balancing segmentation accuracy and computational efficiency remains a key bottleneck for practical deployment. To address these challenges, we propose ADBNet, an efficient asymmetric dual-branch network for real-time indoor semantic segmentation. ADBNet employs an asymmetric encoder with enhanced depth processing and incorporates a novel Conv-Former Pyramid Vision Transformer (CF-PVT) featuring decomposed convolutional attention to improve depth feature extraction. Furthermore, an Adaptive Feature Recalibration and Fusion (AFRF) module is introduced to enable effective cross-modal alignment and multi-scale feature fusion. Experiments on the NYU-Depth V2 dataset demonstrate that ADBNet achieves an excellent trade-off between accuracy and efficiency, running at 66 FPS with 79.40% pixel accuracy and 56.0% mean IoU.},
  archive      = {J_KBS},
  author       = {Cunlu Xu and Gang Ma and Feng Gao and Bin Wang and Jun Liu},
  doi          = {10.1016/j.knosys.2025.113885},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113885},
  shortjournal = {Knowl. Based Syst.},
  title        = {ADBNet: Asymmetric dual-branch network for indoor real-time RGB-D semantic segmentation},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvSpoofGuard: Optimal transport driven robust face presentation attack detection system. <em>KBS</em>, <em>326</em>, 113759. (<a href='https://doi.org/10.1016/j.knosys.2025.113759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for face recognition systems across various domains underscores the critical need for secure and reliable face anti-spoofing systems. Common spoofing attacks include the use of printed photographs, videos, 3D masks, paper masks, partial tattoos/glasses, and makeup. Designing face anti-spoofing or face presentation attack detection (face PAD) systems involves utilizing multiple datasets, where all images that are not real must be considered fake. However, generating a large and diverse presentation attack dataset is costly. To improve model security, we present a novel robust face anti-spoofing system called AdvSpoofGuard, which aims at mitigating presentation attacks generated by deep generative models. Our proposed method leverages adversarial meta-training to enhance overall robustness. We conducted extensive experiments to evaluate the performance of our method on various face anti-spoofing datasets. The results demonstrate that our optimal transport (OT)-driven CycleGAN-based adversarial meta-learning approach improves classification across different domains and types of attacks, outperforming state-of-the-art methods in performance gain and defense against adversarial attacks.},
  archive      = {J_KBS},
  author       = {Taha Hasan Masood Siddique and Shujaat Khan and Zeyu Wang and Kejie Huang},
  doi          = {10.1016/j.knosys.2025.113759},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113759},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdvSpoofGuard: Optimal transport driven robust face presentation attack detection system},
  volume       = {326},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-guided memory enhancement and causality-inspired generalization framework for continual fault diagnosis. <em>KBS</em>, <em>325</em>, 114044. (<a href='https://doi.org/10.1016/j.knosys.2025.114044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing fault diagnosis methods, which are primarily designed for static scenarios, often suffer from degraded retention of previously learned knowledge in dynamic and continual industrial diagnostic processes. Continual fault diagnosis requires models with learning ability for new operating condition data, memory ability for old operating condition data, and generalization ability for unseen operating condition data. Therefore, the paper proposes a physics-guided memory enhancement and causality-inspired generalization framework (PMECG) for continual fault diagnosis. First, a physical knowledge-guided adaptive knowledge accumulation strategy, which combines physical confidence and historical forgetting rate for dynamic sample replay, is proposed to increase the model's memory for old operating condition knowledge. Secondly, a novel dynamic elastic weight consolidation approach is proposed to balance the model's memory and learning performance in the model parameter solution space. Among them, the dynamic Fisher information matrix under the balance of historical forgetting rate is the key. Finally, a causal feature extractor guided by causality loss is constructed to extract fault-relevant causal features, which enhances the model's learning ability, memory capacity, and generalization performance. The effectiveness and superiority of the proposed method are validated through multiple sets of continual learning experiments.},
  archive      = {J_KBS},
  author       = {Ning Jia and Weiguo Huang and Panpan Guo and Chuancang Ding and Yifan Huangfu and Changqing Shen and Zhongkui Zhu},
  doi          = {10.1016/j.knosys.2025.114044},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114044},
  shortjournal = {Knowl. Based Syst.},
  title        = {A physics-guided memory enhancement and causality-inspired generalization framework for continual fault diagnosis},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved brain-motivated network for forecasting day-ahead stock prices of electricity companies. <em>KBS</em>, <em>325</em>, 114040. (<a href='https://doi.org/10.1016/j.knosys.2025.114040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the complexity of the trading market, stock prices of electricity companies present nonlinear, non-stationary, and random fluctuations, resulting in its high-precision forecasting being a challenging task. Deep learning, particularly in bionically-inspired networks, has shown great potential in time series forecasting. To this end, this paper proposes an improved brain-motivated network with GELU function and residual connection for forecasting the day-ahead stock prices of electricity companies. Specifically, from a macro view, the improved brain-motivate network effectively simulates gate, parallel handling, and collaboration functions in the brain, inheriting some of the superior analytical capabilities of the biological brain. From a micro view, the GELU function is first adopted to extract nonlinear features, which not only avoids the gradient vanishing of Tanh function but also deals with the learning issue of ReLU function when the input is negative. Moreover, the residual connection is utilized to convey information between the shallow and deep layers, making full use of information for mining deeply hidden features. In summary, the cooperation of the above components improves the forecasting accuracy. Experimental results and analysis of two case study from Finnish electricity companies show that the improved brain-motivated network outperforms 18 baselines with improved average mean absolute percentage errors of 13.28 % and 8.56 %, thus helping stakeholders make informed decisions and gain profitable returns.},
  archive      = {J_KBS},
  author       = {Han Wu and Xiao-Zhi Gao and Kang Li and Jia-Ni Heng},
  doi          = {10.1016/j.knosys.2025.114040},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114040},
  shortjournal = {Knowl. Based Syst.},
  title        = {An improved brain-motivated network for forecasting day-ahead stock prices of electricity companies},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer-based decision-making method with criterion weight and reliability transfer. <em>KBS</em>, <em>325</em>, 114028. (<a href='https://doi.org/10.1016/j.knosys.2025.114028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the coming of information age, more and more historical data are accumulated in the social life. These data bring benefits to the mankind while they increase the complexity of human decision-making. Data-driven multi-criteria decision-making (D2MCDM) is adept at extracting relevant parameters from extensive historical data to aid decision-makers in crafting satisfactory solutions. However, the scarcity of historical data in certain domains can lead to inaccurate or inconsistent parameter information. To mitigate this challenge, a feasible way is to integrate the parameter-based transfer learning into D2MCDM. The basic idea is to leverage the sufficient historical data from a related domain called the source domain (SD) to help learn parameter information in the D2MCDM model, which can be applied to the target domain (TD) with limited historical data. This paper proposes a transfer-based decision-making (TBDM) method with criterion weight and reliability transfer. In the method, a data selection for the SD is constructed based on the Tri-training algorithm to enhance data similarity between the SD and TD. The selected data in the SD are then used to identify the criterion weights and reliabilities involved in the constructed D2MCDM models, which are further integrated into the D2MCDM model in the TD to construct the TBDM method. A case study of auxiliary diagnosis of breast lesions is analyzed to demonstrate the effectiveness of the TBDM method. Furthermore, its advantages are validated by comparative experiments on the UCI data sets.},
  archive      = {J_KBS},
  author       = {Xuefei Jia and Wenjun Chang and Baoyu Liao},
  doi          = {10.1016/j.knosys.2025.114028},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114028},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transfer-based decision-making method with criterion weight and reliability transfer},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multi-label learning via K-means graph transformer. <em>KBS</em>, <em>325</em>, 114017. (<a href='https://doi.org/10.1016/j.knosys.2025.114017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Multi-Label Learning (PML) is a weakly supervised learning problem in which each instance is assigned a set of candidate labels, including relevant and irrelevant ones. The traditional label disambiguation strategies often rely on prior knowledge or auxiliary information and do not fully consider the complementary information between different label features. To tackle this challenge, we propose a K-means Graph Transformer for PML (PML-KGT), which introduces cluster centers and graph structure design to approximate label features. The goal of this process is to learn the features of different label classes through the complementary information from candidate labels of similar instances in the graph structure, while effective label features can accurately measure the relationship between instance and candidate labels, thus mitigating the influence of noisy labels. Additionally, we introduce a novel partial multi-label correction loss that determines candidate label weights based on evaluating the correlation between cluster centers and instances, thereby alleviating the effect of noise labels. As training progresses, the ground-truth labels are gradually recognized, and the improved cluster centers and labels contribute to enhancing the performance of the classifier. Comprehensive experiments on the real-world and synthetic PML datasets validate the advantage of the PML-KGT.},
  archive      = {J_KBS},
  author       = {Zhiyong Li and Linqing Huang and Tianhao Gu and Qingkai Bu and Fuyu Qi and Jinfu Fan},
  doi          = {10.1016/j.knosys.2025.114017},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114017},
  shortjournal = {Knowl. Based Syst.},
  title        = {Partial multi-label learning via K-means graph transformer},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart metering data enhancement in sustainable buildings via knowledge graph-guided graph neural networks. <em>KBS</em>, <em>325</em>, 114016. (<a href='https://doi.org/10.1016/j.knosys.2025.114016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven analytics in sustainable buildings heavily rely on data of smart meters. In practice, the smart metering data is usually low-quality deficient data, which is incomplete and ineffectual for the development of data-driven analytics. To enhance the data of a target meter, referring to data of other dependence meters within the building is crucial. Thus, the meter dependence needs to be clarified for metering data enhancement. In this paper, we empirically demonstrate that building knowledge graphs (BKGs) contain the knowledge about meter dependence. We introduce BKGs into metering data enhancement problem. We summarize the challenges of utilizing the BKGs in this problem. To tackle these challenges, we present BuildKnow, a uniform solution for metering data enhancement with BKGs. BuildKnow outputs BKG-guided graph neural network models for the target meters. With such models, the metering data can be accurately enhanced. We evaluate the BuildKnow on three real-world sustainable buildings with their BKGs and metering data. The results show that BuildKnow models outperform the SOTA time-series data enhancement models and enhance metering data with a CV-RMSE of 16.53%.},
  archive      = {J_KBS},
  author       = {Fang He and Jiaqi Fan and Yang Deng and Xiaoyang Zhang and Ka Tai Lau and Dan Wang},
  doi          = {10.1016/j.knosys.2025.114016},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114016},
  shortjournal = {Knowl. Based Syst.},
  title        = {Smart metering data enhancement in sustainable buildings via knowledge graph-guided graph neural networks},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards unified bijective image–text generation for text-to-image person re-identification. <em>KBS</em>, <em>325</em>, 114014. (<a href='https://doi.org/10.1016/j.knosys.2025.114014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a unified multi-modal generative model to address two key challenges in text-to-image person re-identification (T2I ReID): lack of sufficient training data and large cross-modal difference. To this end, this paper adapts diffusion probabilistic models for bijective generation of text–image pairs, achieving both text-to-image generation and image-to-text generation by a unified framework. For the purpose of bijective generation and computational efficiency, this paper leverages the latent diffusion model as generative models, collaborating with text/image encoders and decoders. Specifically, a CLIP-based text encoder and an image one first transform the raw data into a shared feature space, then a mutual-conditional diffusion model (MCDiff) is implemented to estimate the probability density of the latent features, and finally an image decoder and a text decoder generate required data from the latent features. In MCDiff, the latent features of paired image–text serve as mutual conditions to input to UNet. The text latent features guide the refinement of image features, while the image latent features condition the generation of text features, forming a bidirectional conditioning mechanism that effectively captures the semantic alignment between modalities. By this fashion, dual path of text-to-image generation and image-to-text generation can be integrated into a unified framework, enabling both training sample augmentation and cross-modal generation. Experimental results on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that the proposed approach significantly outperforms multiple baseline T2I ReID models. In particular, our method achieves Rank-1 accuracy gains of 2.1% and 2.0% on CUHK-PEDES compared to IRRA and CADA, respectively.},
  archive      = {J_KBS},
  author       = {Qianqian Wang and Xiaoguang Ma and Xiaoyu Jiang and Jianmin Ji and Honghu Pan},
  doi          = {10.1016/j.knosys.2025.114014},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114014},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards unified bijective image–text generation for text-to-image person re-identification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward learnable and interpretable data shapley valuation for deep learning. <em>KBS</em>, <em>325</em>, 114002. (<a href='https://doi.org/10.1016/j.knosys.2025.114002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the value of individual samples is essential for a wide range of data-driven tasks, particularly in deep learning. The Shapley value, rooted in game theory, serves as the primary metric for data valuation, and numerous methods have been proposed for its computation. While the Shapley value boasts a robust theoretical foundation, its estimation traditionally relies on game experiment-based procedures rather than learnable approaches, leaving the construction of an explicit valuation model unaddressed. Furthermore, existing data Shapley valuation methods lack interpretability, as they fail to explain the factors contributing to a specific sample’s value — whether high or low — or the mechanisms by which these factors exert influence. This study seeks to develop a learnable and interpretable data Shapley valuation model tailored to deep learning tasks. To this end, we propose a novel learning framework that maps sample characteristics directly to their Shapley values. Central to this framework is the design of an innovative neural regression tree, which surpasses existing neural regression trees in both interpretability and computational efficiency. Leveraging this structure, we introduce a new data Shapley valuation method that employs the neural regression tree as its core component. The resulting learnable valuation model offers significant advantages, such as a fixed number of parameters and the ability to reuse knowledge across tasks, while the interpretability of the model enables explanations for why certain samples are assigned specific values. Comprehensive experiments on benchmark datasets validate the effectiveness of our approach, demonstrating its initial success in producing learnable and interpretable Shapley values.},
  archive      = {J_KBS},
  author       = {Mengyang Li and Weiyao Zhu and Ou Wu},
  doi          = {10.1016/j.knosys.2025.114002},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {114002},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward learnable and interpretable data shapley valuation for deep learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained knowledge progressive network with multivariate enhancements for text-based person retrieval. <em>KBS</em>, <em>325</em>, 113999. (<a href='https://doi.org/10.1016/j.knosys.2025.113999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: Text-Based Person Retrieval (TBPR) aims to match target images using natural language descriptions, yet it faces significant challenges such as complex visual structures, diverse semantic expressions, and limited annotated data. These issues lead to intra-modal knowledge uncertainty and weak inter-modal correlations. Existing approaches predominantly focus on explicit alignment between heterogeneous modalities, often overlooking the latent associations within homogeneous knowledge. This study addresses these limitations to enhance both the performance and efficiency of TBPR. Method: This paper proposes a Multivariate Enhancement Fine-Grained Knowledge Progressive Network (ME-FKPN) to address the challenge of text-based person retrieval across modalities. ME-FKPN enhances the synergy between homogeneous and heterogeneous knowledge in a hierarchical manner, progressively establishing more accurate semantic alignments between images and texts. The framework comprises three key innovations: Standardized Knowledge Anchor (SKA) constructs a knowledge graph to standardize semantics; Mixed of LoRA Experts (MoLE) integrates defogged color and grayscale images to extract multi-level visual features; Multivariate Knowledge Progressive Optimization Strategy (MKPOS) achieves steady performance improvements through hierarchical augmentation and staged training. Novelty: The proposed ME-FKPN model introduces a novel solution to the TBPR task by integrating hierarchical knowledge enhancement and progressive optimization strategies. By deeply mining latent associations among homogeneous knowledge and fostering collaborative representation of heterogeneous knowledge, the approach effectively overcomes the limitations of existing techniques in handling complex cross-modal relationships and data sparsity. Findings: ME-FKPN outperforms all state-of-the-art TBPR models across three public datasets. Notably, on the challenging UFine6926 ultra-fine-grained dataset, our method achieves improvements of 16.49%, 9.79%, 6.23%, and 14.69% on R@1, R@5, R@10, and mAP metrics, respectively, compared to mainstream approaches.},
  archive      = {J_KBS},
  author       = {Kai Ren and Chuanping Hu and Hao Xi and Yongqiang Li and Jinhao Fan and Lihua Liu},
  doi          = {10.1016/j.knosys.2025.113999},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113999},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained knowledge progressive network with multivariate enhancements for text-based person retrieval},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute-aware implicit modality alignment for text attribute person search. <em>KBS</em>, <em>325</em>, 113998. (<a href='https://doi.org/10.1016/j.knosys.2025.113998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text attribute person search aims to find specific pedestrians through textual attributes, which is meaningful in the scene of searching for designated pedestrians through witness descriptions. The key challenge is the significant modality gap between textual attributes and images. Previous methods focused on achieving explicit feature representation and alignment through unimodal pre-trained models. However, the lack of correspondence between modalities may lead to the distortion of intra-modal information. Moreover, these methods typically aim for cross-modal alignment while paying less attention to the differences between various attribute categories. To mitigate the above problems, we propose an Attribute-Aware Implicit Modality Alignment (AIMA) framework that implicitly learns the correspondence between local representations of textual attributes and images and perceives the differences among various attribute categories. Firstly, we introduce the CLIP model as the backbone and design prompt templates to transform attribute combinations into structured sentences, which facilitates the model to better understand and match image details. Next, we design a Masked Attribute Prediction (MAP) module to achieve implicit modality alignment. This module predicts the masked attributes by enabling interactions between image and masked textual attribute features without requiring explicit additional supervision. Finally, to perceive differences between various attributes, we propose an Attribute-IoU Guided Intra-Modal Contrastive (A-IoU IMC) loss. It aligns the distribution of different textual attributes in the embedding space with their IoU distribution, achieving a better semantic arrangement. Extensive experiments on the Market-1501 Attribute, PETA, and PA100K datasets show that the performance of our proposed method significantly surpasses the current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fangfang Liu and Xin Wang and Zheng Li and Caili Guo and Yang Yang and Lin Hu},
  doi          = {10.1016/j.knosys.2025.113998},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113998},
  shortjournal = {Knowl. Based Syst.},
  title        = {Attribute-aware implicit modality alignment for text attribute person search},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-sighted knowledge discovery in temporal transaction database via time pruning. <em>KBS</em>, <em>325</em>, 113996. (<a href='https://doi.org/10.1016/j.knosys.2025.113996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern mining is a crucial area in data mining focused on discovering interesting patterns, primarily aiming to assess frequency and utility. However, existing approaches often overlook the full potential of temporal indicators. Two key aspects remain underexplored: (1) the greater value of recent past data compared to older data (temporal weight) and (2) the significance of temporal trends over simply observing data magnitudes (temporal trend). Some patterns may exhibit high utility initially; however, decline over time, resulting in low utility in later stages. Traditional methods classify these as high utility patterns (HUPs); however, when considering temporal weight and trend, they differ from true HUPs and are termed short-sighted patterns. Identifying these patterns helps avoid misleading conclusions and assists decision-makers in understanding the reasons behind declining utility, allowing for more effective strategies to address implicit losses. This study introduces the concept of short-sighted itemset mining (SSIM) and prior short-sighted itemset mining (PSSIM) by leveraging temporal indicators. We present two algorithms, SSIM and PSSIM, designed to address these problems. These algorithms employ new lists to minimize redundant database scans and implement innovative pruning strategies to filter out irrelevant candidates. Experimental results demonstrate the effectiveness and efficiency of both algorithms.},
  archive      = {J_KBS},
  author       = {Xiaojie Zhang and Guoting Chen and Linqi Song and Wensheng Gan},
  doi          = {10.1016/j.knosys.2025.113996},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113996},
  shortjournal = {Knowl. Based Syst.},
  title        = {Short-sighted knowledge discovery in temporal transaction database via time pruning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly supervised camouflaged object detection as progressive perception learning. <em>KBS</em>, <em>325</em>, 113993. (<a href='https://doi.org/10.1016/j.knosys.2025.113993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scribble-Supervised Camouflaged Object Detection (SCOD) aims to detect camouflaged objects that seamlessly blend into their surroundings using sparse and coarse scribble annotations as weak supervision. However, existing SCOD methods face two main natural deficiencies. First, the weak richness of pixel training samples (WRPS) hinders robust camouflaged object perception learning, as scribble annotations provide insufficient pixel-level supervision. Second, the poor structural integrity of camouflaged objects (PSIO) makes direct structural learning infeasible, resulting in imprecise segmentation. To address these challenges, we propose the Progressive Perception Learning (PPL) Framework, which employs the PPL optimization function to progressively enhance pixel-level perception, semantic alignment, and global understanding combined with three key components: the Clue-Guided Region Restoration Module (CGRRM), Semantic Interaction Refinement Fusion Module (SIRFM), and Global Perception Module (GPM). Specifically, CGRRM improves object localization by guiding the restoration of key regions based on sparse scribble annotations. SIRFM refines the interaction between low-level spatial features and high-level semantic information. GPM captures long-range dependencies across the image, providing a global understanding while preserving local details. Additionally, we design a Feature Alignment Fusion Module (FAFM) to further refine structural alignment. Extensive experiments demonstrate that our method outperforms existing state-of-the-art SCOD approaches and is competitive with several fully-supervised methods. Our code and data are available at: https://github.com/NGI-vision/PPL .},
  archive      = {J_KBS},
  author       = {Tianxin Han and Xingwei Wang and Qing Dong and Min Huang and Jie Jia and Fu Zhang},
  doi          = {10.1016/j.knosys.2025.113993},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113993},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly supervised camouflaged object detection as progressive perception learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Purely sentiment-driven stock index trend forecast: A probability model based on social media sentiment space. <em>KBS</em>, <em>325</em>, 113985. (<a href='https://doi.org/10.1016/j.knosys.2025.113985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the feasibility of abandoning market fundamental analysis in a highly sentiment-driven stock market and instead using purely sentiment-based features for market trend prediction. To achieve this, we developed a spatial geometry model based on social media sentiment, conceptually inspired by assumptions similar to those in the Bollinger Bands strategy—such as local market stability, symmetry, and known probability distributions—while not directly employing this technical indicator. Using Particle Swarm Optimization (PSO) to identify extreme sentiment states and employing determination and filtering parameters to eliminate random noise, the model effectively captures sentiment-driven market states. With appropriate sliding window lengths and optimized parameter combinations, the model achieves a sentiment space coverage rate exceeding 90 %, predictive sample coverage of 40 %, and a prediction accuracy of 83 %. This study demonstrates the feasibility of using sentiment-only indicators for market prediction and evaluation in sentiment-driven markets, offering a novel approach to applying sentiment data in financial analysis.},
  archive      = {J_KBS},
  author       = {Qing Liu and Changhong Huang and Yanfeng Liu and Hosung Son},
  doi          = {10.1016/j.knosys.2025.113985},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113985},
  shortjournal = {Knowl. Based Syst.},
  title        = {Purely sentiment-driven stock index trend forecast: A probability model based on social media sentiment space},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble-based feature selection and optimization-driven deep learning for attack detection in cloud computing. <em>KBS</em>, <em>325</em>, 113984. (<a href='https://doi.org/10.1016/j.knosys.2025.113984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attack detection identifies and analyses malicious activities within a network to prevent potential damage, whereas legitimate activities are highlighted as attacks, and this leads to delays in responses and resources are wasted. Thus, the new Chronological Hiking Optimization Algorithm with Dense Network (C-HOA_ DenseNet) is introduced for efficient detection. First, the cloud is replicated in a distributed situation. Subsequently, the recorded log file is collected, and input data is passed for normalization by feature scaling. Next, the feature selection is performed by collaborative procedures, such as Correlation-based Feature Selection (CFS), mutual information, and Support Vector Machine with Recursive Feature Elimination (SVM-RFE). The data augmentation is performed by oversampling. Ultimately, the newly introduced C-HOA_DenseNet detects the attack efficiently, in which the DenseNet is tuned by the new C-HOA, which is a fusion of chronological & Hiking Optimization Algorithms (HOA). The analytical results obtained by C-HOA_DenseNet are 92.877 % of accuracy, 94.766 % of True Positive Rate (TPR), 90.877 % of True Negative Rate (TNR), precision of 91.876 %, and F1-score of 93.298 % for k-fold value 8. Thus, the results prove that C-HOA_DenseNet yielded better detection outcomes.},
  archive      = {J_KBS},
  author       = {Susila Nagarajan and Daniel Francis Selvaraj Jayapalan and Ponmary Pushpa Latha Devaraj and Ramesh Kumar R},
  doi          = {10.1016/j.knosys.2025.113984},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113984},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ensemble-based feature selection and optimization-driven deep learning for attack detection in cloud computing},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPM-EViT: Tri-probability map-enhanced vision transformer framework for UAV object detection. <em>KBS</em>, <em>325</em>, 113983. (<a href='https://doi.org/10.1016/j.knosys.2025.113983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in Unmanned Aerial Vehicle (UAV) imagery has become increasingly important for numerous applications. However, the unique characteristics of UAV imagery, like high variability in object sizes, occlusions, and complex backgrounds, limit the efficiency of traditional methods in achieving better detection accuracy. The inability of those methods to perform accurate pixel-level classification reduces their efficiency in distinguishing between foreground, boundary, and background regions, causing misdetections of small or partially hidden objects. Motivated by these challenges, this study proposes a novel Tri-Probability Map-Enhanced Vision Transformer (TPM-EViT) framework to handle the complex nature of UAV imagery. The TPM-EViT leverages tri-probability maps within a ViT backbone to perform pixel-wise classification into foreground, boundary, and background regions, thereby enhancing object localization and boundary recognition under challenging conditions. The framework incorporates a multi-stage detection mechanism to iteratively refine bounding boxes, class predictions, and confidence scores to improve detection accuracy. In addition, a feature balancing module based on a balanced pyramid structure is introduced to combine low-level fine-grained details with high-level semantic features, thereby enabling robust detection across varying object sizes. The comprehensive experiments on the VisDrone2019 and UAVDT datasets demonstrate the superior performance of the proposed model in UAV object detection. The TPM-EViT achieves AP 50 of 60.1 %, AP s of 43.2 %, AP m of 56.3 %, Recall of 70.3 %, and mAP 0.5 of 69.3 % on the VisDrone2019 dataset, and AP 50 of 59.1 %, AP s of 40.2 %, AP m of 54.3 %, Recall of 68.4 %, and mAP 0.5 of 66.2 % on the UAVDT dataset, thereby highlighting its potential for real-world applications.},
  archive      = {J_KBS},
  author       = {Weiye Wang and Qing Li},
  doi          = {10.1016/j.knosys.2025.113983},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113983},
  shortjournal = {Knowl. Based Syst.},
  title        = {TPM-EViT: Tri-probability map-enhanced vision transformer framework for UAV object detection},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reference-based infrared image colorization via feature enhancement and context refinement. <em>KBS</em>, <em>325</em>, 113982. (<a href='https://doi.org/10.1016/j.knosys.2025.113982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference-based infrared image colorization is a pioneering task that establishes a precise semantic relationship between infrared images and reference color images, facilitating the accurate transfer of color information from the reference image to the infrared image. However, existing methods often neglect the correlation between the input and reference images, which can result in the loss of essential details. To address these issues, we propose a reference-based infrared image colorization method that employs feature enhancement and context refinement (FCNet). Specifically, we design a dual-path feature mining module to extract features at different scales and fuse features from various levels. In the image reconstruction phase, we introduce a multi-information saliency transformer to capture global, frequency, and local features, allowing the network to better learn and model the target’s features for precise colorization. Finally, by aggregating the correspondence between feature maps of varying depths and the target through a cross-scale information aggregation module and a context information refinement module, we enhance the feature information to aid the network in recovering edge and texture details. Extensive experiments demonstrate that the proposed FCNet achieves state-of-the-art performance, with PSNR and SSIM reaching 28.670 and 0.542 on the KAIST dataset, and 30.424 and 0.726 on the FLIR dataset, respectively. Our code and models are available on GitHub .},
  archive      = {J_KBS},
  author       = {Weida Zhan and Yu Chen and Yichun Jiang and Depeng Zhu and Xiaoyu Xu and Jinxin Guo and Ziqiang Hao and Deng Han and Jin Li},
  doi          = {10.1016/j.knosys.2025.113982},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113982},
  shortjournal = {Knowl. Based Syst.},
  title        = {Reference-based infrared image colorization via feature enhancement and context refinement},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDGINet: Multi-frequency dynamic guidance and interaction network for image denoising. <em>KBS</em>, <em>325</em>, 113981. (<a href='https://doi.org/10.1016/j.knosys.2025.113981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) have demonstrated strong performance in image denoising. However, many existing approaches rely heavily on increasing network depth to improve results, which can limit the ability to effectively capture structural information. In this paper, we propose a Multi-frequency Dynamic Guidance and Interaction network (MDGINet) for image denoising. MDGINet consists of a frequency decomposition block (FDB), two frequency interaction blocks (FIBs), a frequency progressive coordinate-attention fusion block (PCFB) and a reconstruction block (RB). Specifically, the FDB employs large kernel dilated convolutions to decompose the input features into multiple frequency components and incorporates a frequency dynamic guidance attention module (FGAM) to selectively enhance or suppress these components. FIBs are designed to further refine the low- and mid-frequency features, while the PCFB progressively integrates multi-frequency information using multi-scale coordinate attention. Experimental results on both synthetic and real-world noise datasets demonstrate that MDGINet outperforms several popular denoising methods in terms of both quantitative metrics and visual quality.},
  archive      = {J_KBS},
  author       = {Heng Li and Feng Shao and Hangwei Chen and Xiongli Chai and Qiuping Jiang},
  doi          = {10.1016/j.knosys.2025.113981},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113981},
  shortjournal = {Knowl. Based Syst.},
  title        = {MDGINet: Multi-frequency dynamic guidance and interaction network for image denoising},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel stack-model configuration for merox-treated gasoline yield prediction synergized with EMMS-CFD hydrodynamic analysis. <em>KBS</em>, <em>325</em>, 113980. (<a href='https://doi.org/10.1016/j.knosys.2025.113980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The catalytic extraction of mercaptans is important for ensuring that gasoline meets environmental regulations and property specifications. The digitization of the oil and gas industry has prompted the widespread adoption of statistical, computational intelligence, meta-heuristics, and machine learning modelling methods. Despite some approaches offering valuable insights into predictive maintenance and process optimization, their susceptibility to overfitting and uncertainties in performance pose challenges to their reliability and applicability in real-world decision-making. The present study addresses this gap by proposing a stack configuration of Ant Colony Optimization (ACO) in optimizing hyperparameters for the Random Forest (RF) regressor model, while dropout optimizes hyperparameters for the Deep Neural Network (DNN) model, with their inputs further analyzed by the XGB model for improved prediction accuracy. In reducing feature dimensionality, the Elastic Net regularization (ENR) technique is incorporated for feature selection. In comparison with other models, the proposed ACO+RF+DNN+XGB framework test prediction results had the least error values, with an MSE value of 0.0558 m 3 /hr, an RMSE value of 0.2361 m 3 /hr, an MAE value of 0.1862 m 3 /hr, and an R 2 value of 95.20 %. The improvement of the proposed model in percentages showed that the MAE, MSE, and RMSE decreased by 210.85 %, 295.75 %, and 98.91 %, respectively, while the R 2 had an increase of 3.56 %. Energy-Minimization Multi-scale-based computational fluid dynamics (EMMS-CFD) computation further described the hydrodynamic behaviour of a simulated reactor, critical for ensuring reactions occur under optimal conditions. The study synergizes novel computational methodologies and practical industrial implementation, with high relevance to the petroleum refining industry.},
  archive      = {J_KBS},
  author       = {Oluwayomi Joel Oyejide and Faiz Ahmad and Shahrul bin Kamaruddin and Modestus Okechukwu Okwu and Francis Amadhe and Adeleke Tunde Basit and Rilwan Anjorin and Mohammed Abdulmalek},
  doi          = {10.1016/j.knosys.2025.113980},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113980},
  shortjournal = {Knowl. Based Syst.},
  title        = {Novel stack-model configuration for merox-treated gasoline yield prediction synergized with EMMS-CFD hydrodynamic analysis},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-augmented biomechanical optimization of energy-absorbing structure towards improved hip injury protection. <em>KBS</em>, <em>325</em>, 113979. (<a href='https://doi.org/10.1016/j.knosys.2025.113979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall accidents among older adults represent a major public health challenge worldwide. Energy-absorbing flooring has gained increasing attention due to its high usability and robustness against fall-related hip impacts. This study proposes a novel method that integrates finite element (FE) analysis, deep learning (DL) models, and multi-objective optimization (MOO) algorithms to enhance the biomechanical protective performance of a bio-inspired energy-absorbing structure. To achieve this, 100 structural configurations were generated based on a design of experiments (DOE) framework, automatically modeled in Hypermesh, and integrated into a hip regional model in LS-DYNA. The deep neural network (DNN) models were developed to predict femoral neck force ( F n e c k ) and energy absorption efficiency ( S E A v ), and were subsequently utilized in the MOO framework to construct the Pareto front, optimizing the dual objectives of minimizing F n e c k and maximizing S E A v using 50,000 optimization samples. Five optimal solutions on the Pareto front were validated and demonstrated substantial performance improvements. Compared to the baseline structure, the optimized designs demonstrated up to a 23% reduction in peak femoral neck force and a 65% increase in energy absorption efficiency. This study presents a framework that ensures high accuracy, robustness, and continuity in representing biomechanical responses towards improved hip protection. The findings have practical implications for enhancing safety in high fall-risk environments and provide valuable guidance for manufacturers in designing protective devices with enhanced performance and clinical effectiveness.},
  archive      = {J_KBS},
  author       = {Qi Huang and Zhou Zhou and Svein Kleiven},
  doi          = {10.1016/j.knosys.2025.113979},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113979},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning-augmented biomechanical optimization of energy-absorbing structure towards improved hip injury protection},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel bijective substitution box design based on nomadic people optimizer and discrete chaotic map. <em>KBS</em>, <em>325</em>, 113977. (<a href='https://doi.org/10.1016/j.knosys.2025.113977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel optimization algorithm, Simulated Annealing Nomadic People Optimization (SANPO), which synergizes the Nomadic People Optimization (NPO) method with the Simulated Annealing (SA) algorithm for efficient design and optimization of substitution boxes (S-boxes). A key feature of SANPO lies in its hybrid approach: leveraging NPO for adaptive search capabilities while integrating SA to enhance the algorithm's ability to escape local optima, improving overall exploration. To further boost nonlinearity and diversify the solution set, SANPO incorporates a discrete chaotic map, replacing traditional pseudo-random number generators during population initialization. This combination strengthens the cryptographic properties of S-boxes. The proposed SANPO method was rigorously evaluated across multiple cryptographic performance metrics, including bijectivity, nonlinearity, strict avalanche criteria (SAC), bit independence criteria (BIC), differential uniformity, and linear probability. Comparative analysis with existing S-box generation methods demonstrated that SANPO-generated S-boxes exhibit superior cryptographic strength and robustness against various cryptanalysis attacks. This work addresses emerging challenges in cryptography by offering a robust solution capable of enhancing security in modern encryption systems.},
  archive      = {J_KBS},
  author       = {Hussam S. Alhadawi and Musheer Ahmad and Sinan Q. Salih},
  doi          = {10.1016/j.knosys.2025.113977},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113977},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel bijective substitution box design based on nomadic people optimizer and discrete chaotic map},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced computational modeling of malaria using artificial neural networks and stochastic solvers. <em>KBS</em>, <em>325</em>, 113976. (<a href='https://doi.org/10.1016/j.knosys.2025.113976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the transmission dynamics and progression of malaria through a computational modeling framework based on artificial neural networks, with a particular focus on severe disease manifestations and predictive epidemiology. Traditional mathematical models of malaria often face challenges in accurately capturing infection patterns due to the computational burden of solving nonlinear differential equations. To address these limitations, we enhance the classical susceptible, exposed, infectious, recovered model by incorporating key biological and epidemiological factors that reflect the progression of malaria, including cases of cerebral malaria and reinfection due to waning immunity. The neural network model is trained using the Levenberg–Marquardt backpropagation optimization method, utilizing simulated data generated via the Runge–Kutta numerical solver. The dataset is partitioned into 85% for training, 10% for validation, and 5% for testing. This approach enables high-precision modeling of disease dynamics, treatment outcomes, and population-level recovery trends. The model achieves a mean squared error of 1 . 8673 × 1 0 − 10 , with regression values approaching unity, highlighting its predictive accuracy and robustness. The population is stratified into high and low-risk groups based on behavioral and immunological differences, enabling a more nuanced understanding of malaria spread. Unlike conventional numerical methods such as Euler or Runge–Kutta schemes, the neural network-based technique offers enhanced computational efficiency and accuracy. Sensitivity and uncertainty analyses are also conducted to identify critical parameters influencing the basic reproduction number, using both direct differentiation and statistical sampling methods such as Latin Hypercube Sampling and random sampling. This comprehensive modeling framework demonstrates the value of neural networks in malaria research, offering practical insights for designing targeted interventions and improving disease control strategies.},
  archive      = {J_KBS},
  author       = {Kamel Guedri and Rahat Zarin and Basim M. Makhdoum and Soliman Aljarboa and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.knosys.2025.113976},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113976},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced computational modeling of malaria using artificial neural networks and stochastic solvers},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFLM-GCN: Multi-relation fusion and latent-relation mining graph convolutional network for entity alignment. <em>KBS</em>, <em>325</em>, 113974. (<a href='https://doi.org/10.1016/j.knosys.2025.113974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) is the task of identifying equivalent entities in two knowledge graphs (KGs) using a limited set of seed entities. Existing research mainly uses graph neural networks (GNNs) to aggregate entity neighborhood features for representation to achieve better entity alignment. However, most of them ignore the fusion of multiple relations between entities and the mining of latent relations, which limits the effectiveness of entity representation to some extent. Therefore, this paper proposes a novel multi-relation fusion and latent-relation mining graph convolutional network (MFLM-GCN) for entity alignment. Specifically, first, we use seed entity pairs to establish the connection between two knowledge graphs and enhance semantic consistency with the help of local isomorphism. Second, we screen potential important related entities through graph random walks and fuse multiple local and global relationships to obtain a preliminary representation of the entity. Third, we use a multi-head attention mechanism to generate multiple association graphs, prune them and construct a densely connected layer to fully explore the deep potential relationships between entities and obtain a multi-branch representation of the entity. Finally, we use linear fusion to obtain the final embedding of the entity and achieve entity alignment. In experiments on multiple real-world datasets, the MFLM-GCN method effectively improves the entity alignment performance by enhancing the entity node representation. The source code for our method is openly accessible on GitHub at the following link: https://github.com/meng-tao/MFLR-GCN .},
  archive      = {J_KBS},
  author       = {Wei Ai and Yulu Liu and Chen Wei and Tao Meng and Hongen Shao and Zhixiong He and Keqin Li},
  doi          = {10.1016/j.knosys.2025.113974},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113974},
  shortjournal = {Knowl. Based Syst.},
  title        = {MFLM-GCN: Multi-relation fusion and latent-relation mining graph convolutional network for entity alignment},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HyperFKAN: A parallelized fourier series-based KAN for hyperspectral image classification. <em>KBS</em>, <em>325</em>, 113973. (<a href='https://doi.org/10.1016/j.knosys.2025.113973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been proven to be effective for feature extraction from hyperspectral image (HSI) data. In HSI classification, multi-layer perceptrons (MLPs) typically follow a spectral-spatial feature extraction phase and serve as a cornerstone of deep learning. However, Kolmogorov-Arnold network (KAN) marks a fundamental shift in deep learning, serving as an alternative to the MLP by transferring learnable activation functions from neurons to connecting edges and enhancing the expressiveness of the model. Inspired by this advancement, we propose a novel lightweight model called HyperFKAN, which is a parallelized Fourier series-based KAN, especially for HSI classification. In HyperFKAN, an innovative periodic spatial shift (PSS) module is introduced to capture spatial context information and enhance local feature interaction. Additionally, the parallelized Fourier series-based KAN (PFKAN) module provides a scheme for splitting a complex function into multiple relatively simple nonlinear functions by replacing the B-splines in native KAN with Fourier series as learnable activation functions, which adopts parallelization strategies in terms of algorithms and model architectures. PFKAN module significantly ramps up the quality and speed of learning spectral-spatial nonlinear features, thereby improving the accuracy and computational efficiency of the HyperFKAN model. Experiments conducted on four HSI datasets confirm that the HyperFKAN surpasses existing methods in terms of accuracy while reducing computational demands.},
  archive      = {J_KBS},
  author       = {Xin Zhang and Zitong Zhang and Chunlei Zhang and Kai Zhang and Qiaoyu Ma},
  doi          = {10.1016/j.knosys.2025.113973},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113973},
  shortjournal = {Knowl. Based Syst.},
  title        = {HyperFKAN: A parallelized fourier series-based KAN for hyperspectral image classification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation network based on multi-level feature alignment constraints for cross scene hyperspectral image classification. <em>KBS</em>, <em>325</em>, 113972. (<a href='https://doi.org/10.1016/j.knosys.2025.113972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cross-scene hyperspectral image classification (HSIC) has received widespread attention. Domain adaptation (DA) is one of the most important techniques for cross-scene HSIC. However, existing methods often focus solely on the overall spectral–spatial feature distribution matching of hyperspectral images, overlooking the alignment of individual categories. The domain-invariant features between the source domain (SD) and the target domain (TD) are not fully utilized, making it difficult to achieve efficient cross-scene HSIC. To this end, a domain adaptive network based on multi-level feature alignment constraints (DAN_MFAC) is proposed. Firstly, a spectral–spatial feature category alignment (SSFCA) module is designed, which can effectively align each category and is more conducive to cross-scene HSIC. In addition, in order to better utilize the domain-invariant features between two domains, a multi-level feature alignment constraint (MFAC) strategy is designed based on SSFCA. Subsequently, considering the excellent ability of convolutional neural networks (CNN) in extracting local features and the significant advantages of Transformers in global feature modeling, this paper proposes a new integrated CNN-Transformer architecture (ICT) for more efficient learning of domain-invariant features. In this architecture, a spatial-spectral correlation (SSC) module is introduced into the CNN branch, which strengthens the ability to capture discriminative local features across domain scenes through multi-scale group convolutions combined with an SE-based feature recalibration mechanism. And a multi-level residual structure is employed in the Transformer branch to mitigate information decay in long-distance feature modeling, ensuring the integrity of global features. Moreover, to further improve the efficiency of feature interaction and fusion, this paper also constructs a hybrid module to optimize the feature integration process. Finally, experiments were conducted on three cross-scene datasets, and the results demonstrate that the proposed method exhibited better generalization and classification performance under conditions with limited samples compared to some recent approaches.},
  archive      = {J_KBS},
  author       = {Haiyang Wu and Cuiping Shi and Shuheng Yue and Fei Zhu and Zhan Jin},
  doi          = {10.1016/j.knosys.2025.113972},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113972},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain adaptation network based on multi-level feature alignment constraints for cross scene hyperspectral image classification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLANet: An efficient recurrent neural network for long-term time series forecasting. <em>KBS</em>, <em>325</em>, 113971. (<a href='https://doi.org/10.1016/j.knosys.2025.113971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformer-based deep learning models have attracted widespread attention in time series forecasting due to their remarkable ability to capture interactions within long sequences. However, their self-attention mechanism struggles to effectively represent temporal continuity and causal relationships. To address this issue, we propose an innovative model based on recurrent neural networks, called mLANet. This model is designed to better capture long-sequence dependencies while fully reflecting temporal continuity and causality. In mLANet, we developed the AECCM module, which transforms one-dimensional time series data into a two-dimensional format. By integrating convolutional neural networks with attention mechanisms, this module simultaneously extracts both local and global features. The output of the mLSTM is fused with the AECCM features through element-wise multiplication, enabling the model to dynamically emphasize critical information. This approach enhances the model’s feature representation and improves its ability to capture long-term dependencies. Furthermore, we introduce a novel time series data transformation strategy that processes multiple time windows in parallel. This approach significantly reduces computational complexity while strengthening the model’s ability to detect local patterns. Experimental results demonstrate that mLANet achieves state-of-the-art predictive performance across seven publicly available multivariate time series datasets. Its exceptional accuracy and robustness highlight its superiority in time series forecasting tasks. Code is available at: https://github.com/jiangjihua8/mLANet .},
  archive      = {J_KBS},
  author       = {Jihua Jiang and Bin Jiang and Yong Wang and Duoqian Miao},
  doi          = {10.1016/j.knosys.2025.113971},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113971},
  shortjournal = {Knowl. Based Syst.},
  title        = {MLANet: An efficient recurrent neural network for long-term time series forecasting},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stream and dual-branch generative adversarial network for image forgery localization. <em>KBS</em>, <em>325</em>, 113970. (<a href='https://doi.org/10.1016/j.knosys.2025.113970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of image editing technology, the behavior of using content hiding or image object forgery to achieve harm is becoming more and more common. Image forgery localization (IFL) is an important defense line to prevent image abuse and maintain social security. However, traditional methods and learning-based algorithms, which are highly dependent on manual feature design, severely limit the model's adaptability in diverse application scenarios. To address this limitation, we propose a Dual-stream and Dual-branch Generative Adversarial Network (DSDB-GAN). Specifically, a dual-stream generator adopts an RGB stream based on Convolution Neural Network (CNN) structure and a noise stream based on Transformer structure, respectively. The Feature Interaction Fusion Module (FIFM) employs an progressive strategy to integrate features from different modalities, thereby enhancing the features' ability to characterize forgery cues. Secondly, the Adaptive Receptive Field module (ARFM) is designed to compute the attention scores for each layer of the dilated convolution features and assign weights to each corresponding scale, enabling efficient localization prediction mask. Concurrently, the Edge Aware Module (EAM) acquires edge information through both horizontal and vertical directions to achieve accurate edge prediction mask. In the dual-branch discriminator, we introduce the localization discriminator and edge discriminator to predict the true/false of the localization mask or edge mask using a gating approach. A comprehensive experimental validation has been conducted in this study, and the results show that DSDB-GAN outperforms current state-of-the-art methods on several mainstream image forgery datasets.},
  archive      = {J_KBS},
  author       = {Ruyi Bai},
  doi          = {10.1016/j.knosys.2025.113970},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113970},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-stream and dual-branch generative adversarial network for image forgery localization},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised locally linear embedding model for discriminant feature learning. <em>KBS</em>, <em>325</em>, 113966. (<a href='https://doi.org/10.1016/j.knosys.2025.113966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminant feature learning is an important and popular research topic in machine learning, because it allows the exploration of explore high-dimensional data for discriminant feature information. Locally linear embedding (LLE) is widely used topological structure projection, but it ignores the discriminative information between clusters, which is critical in subsequent machine learning tasks such as data clustering and classification. To strengthen the LLE’s discriminative power, this study proposes a weakly-supervised discriminant feature learning (WSLLE) model. First, the WSLLE objective function is carefully designed to theoretically enhance the discriminative properties of data features, while preserving the data’s manifold structure. Second, the objective function is rigorously derived using the gradient descent method, which guarantees the existence of a solution and its convergence. Then, based on the inference of the objective function, an algorithm is proposed that utilises clustering methods to calculate the dissimilarity between samples. Finally, comparative experiments were conducted using clustering and classification methods to measure the discriminant properties of the WSLLE model. The experimental results demonstrate that the WSLLE model outperforms other feature learning approaches in terms of discriminative performance.},
  archive      = {J_KBS},
  author       = {Luqing Wang and Chengsu Wang and Hongjun Wang and Chongshou Li and Jie Hu and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113966},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113966},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly-supervised locally linear embedding model for discriminant feature learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granular legal information fusion with adversarial compensation: A hierarchical and logic-aware framework for robust case retrieval. <em>KBS</em>, <em>325</em>, 113964. (<a href='https://doi.org/10.1016/j.knosys.2025.113964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal case retrieval plays a pivotal role in intelligent legal systems, requiring robust semantic understanding, legal logic modeling, and alignment with statutory reasoning. However, current approaches struggle to capture the hierarchical structure and causal dependencies inherent in legal documents. This issue is especially pronounced under sparse supervision or high information noise. To address these challenges, we propose HLAF-LCR, a Hierarchical and Logic-Aware Framework for Legal Case Retrieval, which systematically models the fact–reasoning–ruling structure of legal texts. We design a hierarchical dynamic masking mechanism that applies distinct masking strategies to different modules: detail-preserving masking in the fact module, high-ratio conceptual masking in the reasoning module, and causality-constrained masking in the ruling module. Furthermore, a cross-hierarchical semantic and logic-guided fusion mechanism enables contextual and logical information to propagate across modules, while a dual-channel adversarial compensation module leverages Wasserstein-based training to mitigate semantic distortion under aggressive masking. The framework is optimized using multi-task training. It jointly learns multi-granular representations, logic-guided reconstruction, retrieval relevance, and adversarial robustness. Extensive experiments on both Chinese and English legal case retrieval datasets — including LeCaRD, CAIL2022-LCR, COLIEE2020 and COLIEE2021 — demonstrate that HLAF-LCR significantly outperforms competitive baselines in both supervised and unsupervised settings. The interpretable model architecture and its robust performance under high masking ratios validate the framework’s effectiveness in capturing fine-grained legal semantics, inference chains, and ruling logic.},
  archive      = {J_KBS},
  author       = {Chunyun Meng and Cheng Tang and Yuki Todo and Weiping Ding},
  doi          = {10.1016/j.knosys.2025.113964},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113964},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granular legal information fusion with adversarial compensation: A hierarchical and logic-aware framework for robust case retrieval},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal incremental learning with three-dimensional fuzzy fusion for thermal processes modeling under sparse sensing. <em>KBS</em>, <em>325</em>, 113963. (<a href='https://doi.org/10.1016/j.knosys.2025.113963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As data-driven modeling becomes increasingly prevalent in smart manufacturing, thermal processes often encounter challenges owing to sparse and limited sensor coverage, resulting in incomplete data acquisition. Achieving accurate modeling under such constraints remains a critical challenge. In this study, a spatiotemporal incremental learning approach with three-dimensional fuzzy fusion is proposed. First, a spatiotemporal incremental learning method is developed to rapidly track time-varying local dynamics. An error-triggered technique is also introduced to determine the optimal timing for model updates. Based on the local spatiotemporal model, a three-dimensional fuzzy fusion method is proposed to construct global performance by exploiting the relationships between spatial coordinates and process data, thereby enabling the reconstruction of the global spatial thermal field from limited sensor data. Finally, experiments are performed on an industrial thermal process to validate the proposed method. Compared with existing methods-linear regression, B-spline interpolation, and inverse distance weighting, the proposed method achieves the root mean square error improvements of 84.27%, 76.76%, and 77.42%, respectively.},
  archive      = {J_KBS},
  author       = {Yaxin Wang and Tianyue Wang and Maciej Ławryńczuk},
  doi          = {10.1016/j.knosys.2025.113963},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113963},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatiotemporal incremental learning with three-dimensional fuzzy fusion for thermal processes modeling under sparse sensing},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural-temporal mining for motif-level anomaly detection in dynamic graphs. <em>KBS</em>, <em>325</em>, 113962. (<a href='https://doi.org/10.1016/j.knosys.2025.113962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph anomaly detection (DGAD) has received significant attention due to the dynamic nature of real-world graphical data. As fundamental subgraph structures, motifs play a crucial role in DGAD. However, motif-level DGAD remains insufficiently explored, particularly in terms of its ability to comprehensively capture dynamic graph information. Existing approaches often fail to fully exploit structural and temporal information, thereby limiting their capacity to detect structural and temporal anomalous motifs. To overcome these limitations, we propose S tructural- TE mpor A l M ining (STEAM), a novel framework for motif-level DGAD. STEAM constructs a motif-augmented hypergraph to extract structural features from multiple perspectives, including nodes, edges, and neighborhoods, enabling the detection of structural anomalous motifs. To capture temporal anomalies, a temporal matrix is processed using a fine-grained temporal autoencoder. By integrating structural and temporal features, STEAM effectively detects motif-level anomalies in dynamic graphs. Extensive experiments on six benchmark datasets demonstrate that STEAM outperforms existing state-of-the-art methods. Notably, STEAM achieves a 2.25% improvement in the AUC metric on the UCI Messages dataset, underscoring its superior performance and scalability in motif-level DGAD.},
  archive      = {J_KBS},
  author       = {Changqin Huang and Binghang Yu and Chengling Gao and Yaxin Tu and Fan Jiang and Xiaodi Huang},
  doi          = {10.1016/j.knosys.2025.113962},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113962},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural-temporal mining for motif-level anomaly detection in dynamic graphs},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving knowledge distillation via multi-level normalization and multi-level decoupling. <em>KBS</em>, <em>325</em>, 113958. (<a href='https://doi.org/10.1016/j.knosys.2025.113958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is a method for extracting the knowledge of a teacher network and deliver into a lightweight student network. To solve the problem of poorer performance of the existing logit-based distillation methods than feature-based distillation methods, this study used a matching and coupling method to explore a relatively strong logit distillation method. We propose a type of logit-based method based on an existing multi-level alignment method for logit extraction. We separately categorized the multi-level alignment extracted from logits into target and non-target class alignments. We propose a multi-level decoupled KD (MDKD) method, an optimization method for selecting multi-level normalization, which enables students to acquire appropriate basic logical knowledge from teachers and rationalized training, and further optimized the MDKD method. Through this framework, the flexibility between target and non-target class multi-level alignments was balanced and a reasonable match between the teacher and student was achieved to a certain extent. A large number of experimental results demonstrated that our method is either comparable or exhibited higher performance than traditional logit and mainstream feature extraction methods. Experimental results demonstrated that the MDKD algorithm achieved good performance on the balanced (CIFAR-100, ImageNet-1K, Tiny-ImageNet, and MS-COCO2017) and imbalanced (CIFAR-100-LT and CIFAR-10-LT) datasets. Our code can be found at https://github.com/ye1zheng2han3/MDKD .},
  archive      = {J_KBS},
  author       = {Zhenghan Ye and Wentao Lyu and Qing Guo and Zhijiang Deng and Weiqiang Xu},
  doi          = {10.1016/j.knosys.2025.113958},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113958},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving knowledge distillation via multi-level normalization and multi-level decoupling},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient mining of incremental high utility patterns with negative unit profits over all the accumulated stream data. <em>KBS</em>, <em>325</em>, 113956. (<a href='https://doi.org/10.1016/j.knosys.2025.113956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional high utility pattern mining had considered that items in databases have positive unit profits, but considering negative unit profits is often required in real life. Thus, many algorithms considering both positive and negative unit profits have been proposed in static data environments. Meanwhile, one of the most important parts of data analysis is how to handle the accumulated stream data in real-world systems. However, existing methods considering negative unit profits in a static environment are inadequate for processing data streams, as they require repeated data access, incurring additional resources with multiple data scans. This paper suggests an effective method considering positive and negative unit profits and dynamic databases for high utility stream pattern mining. To avoid storing data in memory and scanning it multiple times, the proposed approach constructs its data structure by performing a single scan of the incremental data without storing it in the memory. Then, through a reconstruction process, it efficiently integrates and manages the new data while optimally maintaining the structures. This methodology enables efficient mining without the loss of significant patterns. Experiments with real and synthetic datasets show that the proposed approach has improved performance to state-of-the-art methods, including adjusted approaches, regarding runtime, memory usage, and scalability. In addition, the proposed method demonstrates enhanced performance than the baseline method in terms of the resources of each process and the number of incremental databases. Further statistical evaluation of the accuracy test shows that the proposed method extracts results without pattern loss or duplication.},
  archive      = {J_KBS},
  author       = {Doyoung Kim and Heonho Kim and Seungwan Park and Hanju Kim and Myungha Cho and Seongbin Park and Taewoong Ryu and Chanhee Lee and Hyeonmo Kim and Unil Yun},
  doi          = {10.1016/j.knosys.2025.113956},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113956},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient mining of incremental high utility patterns with negative unit profits over all the accumulated stream data},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial domain adaptation for cross-user activity recognition via noise diffusion model. <em>KBS</em>, <em>325</em>, 113952. (<a href='https://doi.org/10.1016/j.knosys.2025.113952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is essential for intelligent applications requiring contextual awareness. However, HAR models often face challenges due to data distribution disparities between training and real-world scenarios, particularly across different users. To address this, we propose Diffusion-based Noise-centered Adversarial Learning Domain Adaptation (DNA-DA), a novel framework integrating generative diffusion modeling with adversarial learning for robust cross-user HAR. DNA-DA leverages a tailored network architecture with specialized constraints to align feature distributions across user domains, embedding activity and domain information into noise during diffusion to enhance adaptation. Through adversarial learning, it transforms forward diffusion and reverse denoising into domain alignment phases, enabling robust activity classification. Evaluated on the OPPT, PAMAP2, and DSADS datasets, DNA-DA achieves a 4.0% average accuracy improvement over state-of-the-art methods, with noise-based denoising enhancing data quality. By effectively mitigating distribution mismatches, DNA-DA offers a scalable solution for real-time, user-adaptive HAR systems.},
  archive      = {J_KBS},
  author       = {Xiaozhou Ye and Kevin I-Kai Wang},
  doi          = {10.1016/j.knosys.2025.113952},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113952},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adversarial domain adaptation for cross-user activity recognition via noise diffusion model},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic label relaxation induced discriminative regression for multi-view multi-label classification. <em>KBS</em>, <em>325</em>, 113951. (<a href='https://doi.org/10.1016/j.knosys.2025.113951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the proliferation of multi-view multi-label (MVML) datasets across diverse practical applications, MVML learning has emerged as an active research topic. However, the unique characteristics of these datasets pose numerous challenges, primarily arising from the intricacies of view relationships, complex label correlations, and the underlying intrinsic connections among samples. To address these obstacles and advance the MVML paradigm, we propose a novel approach, termed Dynamic Label Relaxation induced Discriminative Regression (DLRDR), which tackles the MVML classification problem within the framework of discriminant least-squares regression. In DLRDR, a learnable offset matrix is employed to enrich label semantics and promote consistency across views. Additionally, the incorporation of view weights encourages the model to satisfy the complementarity principle. Building upon this foundation, DLRDR further enhances performance by integrating high-order Laplacian information and high-order label correlations through manifold regularization terms. To efficiently solve DLRDR, we provide an effective alternating iteration algorithm. Experimental results on various benchmark datasets validate the superiority of DLRDR over the excellent solutions.},
  archive      = {J_KBS},
  author       = {Jie Zhao and Yitian Xu},
  doi          = {10.1016/j.knosys.2025.113951},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113951},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic label relaxation induced discriminative regression for multi-view multi-label classification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stream feature extraction and semantic similarity for deep hashing image retrieval. <em>KBS</em>, <em>325</em>, 113950. (<a href='https://doi.org/10.1016/j.knosys.2025.113950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hash image retrieval has been receiving increasing attention due to its advantages in speed and accuracy. However, current image retrieval models based on Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) still exhibit limitations in feature extraction. CNNs excel at capturing local features but struggle with modeling global context, whereas Transformers are proficient at extracting global features but are less sensitive to local details. To address these shortcomings, we propose a novel dual-stream feature extraction Vision Transformer for image retrieval, named DSFTH. First, we introduce a Dual-Stream Feature Extraction (DSFE) module designed to enhance the model’s feature extraction capability. This module effectively captures global contextual information by integrating CNNs with attention mechanisms, while preserving strong local feature representation. Furthermore, to improve the semantic expressiveness of the generated hash codes, we propose a new likelihood-based loss function. This loss encourages semantically similar images to produce similar hash codes, ensuring that the learned hash space accurately reflects semantic relationships. Meanwhile, it pushes semantically dissimilar samples apart, maintaining a large distance between their hash codes to prevent semantic ambiguity. This design effectively improves the accuracy and robustness of hash image retrieval. We evaluate DSFTH on four benchmark image retrieval datasets: CIFAR-10, ImageNet, MS-COCO, and NUS-WIDE. Experimental results demonstrate that DSFTH achieves impressive performance, with average accuracies of 95.02%, 93.92%, 93.25%, and 87.51%, respectively. The code is available at https://github.com/LWJ6467/DSFTH .},
  archive      = {J_KBS},
  author       = {Wenjun Li and Shuli Cheng and Anyu Du and Tingjie Liu},
  doi          = {10.1016/j.knosys.2025.113950},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113950},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-stream feature extraction and semantic similarity for deep hashing image retrieval},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty estimation with self-distillation for semi-supervised few-shot classification. <em>KBS</em>, <em>325</em>, 113948. (<a href='https://doi.org/10.1016/j.knosys.2025.113948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised few-shot classification aims to recognize unseen samples within the same classes in the support set by only a few labeled samples and rich unlabeled samples. A heuristic solution is to generate pseudo labels for those unlabeled samples, however, previous methods fail to generate high-quality pseudo labels and class prototype representations. To handle the drawbacks, this paper proposes the U ncertainty E stimation with S elf- D istillation ( UESD ) approach for semi-supervised few-shot classification. It adopts an uncertainty estimation criterion to compute the confidence scores of pseudo-labels based on the probability entropy of neighboring samples. This reduces the influences of those pseudo-labeled samples with lower confidence. Simultaneously, it introduces a masked self-distillation strategy to train a better model, by adding mask occlusions to a few labeled samples in the support set. This encourages the model to learn better class prototype representations under the guidance of self-distillation knowledge. Experimental results on three benchmarks including mini-ImageNet, tiered-ImageNet, and CUB200-2011 demonstrate the superiority of the proposed method.},
  archive      = {J_KBS},
  author       = {Jiajun Chen and Ping Li and Renshu Gu},
  doi          = {10.1016/j.knosys.2025.113948},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113948},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncertainty estimation with self-distillation for semi-supervised few-shot classification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust and adaptive kernelised correlation filter with fuzzy-enhanced template matching and motion-aware target candidate prediction. <em>KBS</em>, <em>325</em>, 113947. (<a href='https://doi.org/10.1016/j.knosys.2025.113947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For time-sensitive visual tracking tasks, the kernelised correlation filter (KCF) is a promising technique that can balance the tracking accuracy and speed. KCF analyses the correlation between the input target candidate region and the matching template, and the position with the highest response value is determined as the target position. In complex situations such as deformation, rotation and fast motion, the target candidate region can be falsely selected, and the matching template containing target feature information can be severely contaminated, resulting in inaccurate tracking results. The inaccurate features are then updated into the subsequent matching templates, leading to a completely corrupted tracking model. This study attempts to systematically address the issues in determining the target candidate region and the matching template. First, three indicators are designed to reveal important information contained in the KCF tracking response matrix, based on which a fuzzy inference approach is developed to evaluate the confidence level of the current matching template. Second, a multi-template strategy is proposed, which adaptively adjusts the template update weight for acceptable confidence levels and completely replaces the original template with a mutation memory template for extremely low confidence levels. Finally, a Kalman filter is designed to incorporate the target motion information to better predict the target candidate region, leading to improved tracking stability in highly dynamic scenarios. The experimental results demonstrate that the proposed approach achieves superior tracking performance on the object tracking benchmark 100 (OTB100) and the unmanned aerial vehicle 123 (UAV123) datasets. On the OTB100 dataset, the proposed approach achieves an accuracy of 72.8% and a success rate of 58.6%, outperforming the KCF by 4.38% and 5.53%, respectively. On the UAV123 dataset, it attains an accuracy of 54.8% and a success rate of 37.1%, with improvements of 0.7% and 0.8% over the KCF.},
  archive      = {J_KBS},
  author       = {Le Yin and Yu Zhong and Ningrui Guo and Wei Huang and Yixin Zhao and Wenjing Xie},
  doi          = {10.1016/j.knosys.2025.113947},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113947},
  shortjournal = {Knowl. Based Syst.},
  title        = {A robust and adaptive kernelised correlation filter with fuzzy-enhanced template matching and motion-aware target candidate prediction},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDRM: A truncated SVD-based dimensionality reduction approach to efficient edge inference in multi-head attention networks. <em>KBS</em>, <em>325</em>, 113946. (<a href='https://doi.org/10.1016/j.knosys.2025.113946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale industrial product detection, the optimization of computing and storage resources becomes a key issue. Most of the existing methods focus on the feature compression of a single dimension or a specific scene, but less consideration is given to how to perform feature selection and compression in high-dimensional data and multi-task scenarios during the process of edge inference. To this end, a Smart Dimensionality Reduction Model (SDRM) with a novel AdaMatrix optimization is proposed to enhance the processing efficiency through dynamic compression and dimensionality reduction of 3D tensor. This model adopts a low-rank decomposition strategy based on truncated singular value decomposition (t-SVD), and combines regularization and gradient descent optimization to achieve progressive data compression. A collaborative optimization framework of t-SVD and gradient descent is constructed to optimize the homogeneous distributed multi-head attention mechanism. It reduces storage requirements while ensuring data accuracy, and utilizes the multi-head attention mechanism to enhance parallel processing capability. Theoretical proofs and various experiments with multifaceted metrics show that the proposed SDRM model outperforms existing related methods in terms of compression ratio, computational complexity and data processing efficiency in electronic component defect detection scenarios.},
  archive      = {J_KBS},
  author       = {Yuze Du and Xiaogang Wang and Haokun Chen and Chenfeng Zhang and Jian Cao and Rajkumar Buyya},
  doi          = {10.1016/j.knosys.2025.113946},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113946},
  shortjournal = {Knowl. Based Syst.},
  title        = {SDRM: A truncated SVD-based dimensionality reduction approach to efficient edge inference in multi-head attention networks},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FBFU-net: Flow branches fusion U-net for predicting flow fields around buildings. <em>KBS</em>, <em>325</em>, 113945. (<a href='https://doi.org/10.1016/j.knosys.2025.113945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban wind effects, including wind-induced damage, can cause significant environmental disruptions, particularly in areas with high-rise buildings. Computational Fluid Dynamics (CFD) simulations offer a viable approach for assessing these impacts, though they face challenges in accuracy and computational efficiency. Recent advancements in machine learning provide opportunities to enhance these simulations. We propose a novel ML-based method, the Flow Branches Fusion U-Net (FBFU-Net), which builds upon the U-Net architecture utilizing Convolutional Neural Networks (CNNs). The network enhances predictions by leveraging distinct processing branches: one dedicated to velocity data and the other to pressure data. The integration of the Multimodal Transfer Module (MMTM), which fuses information from both branches, further improves the performance of FBFU-Net. The experimental results demonstrate the potential of the proposed method as an effective AI-driven tool for CFD-based wind analysis.},
  archive      = {J_KBS},
  author       = {Woo Hyeok Choi and SangUk Hwang and Sang Ryul Park and Seok Hyun Choi and Hyang Ha Lee and Chan Jong Wang and Minjae Shin and Byungjoon Lee},
  doi          = {10.1016/j.knosys.2025.113945},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113945},
  shortjournal = {Knowl. Based Syst.},
  title        = {FBFU-net: Flow branches fusion U-net for predicting flow fields around buildings},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TIRPMiner: An efficient algorithm for mining time interval-related pattern. <em>KBS</em>, <em>325</em>, 113944. (<a href='https://doi.org/10.1016/j.knosys.2025.113944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time Interval-Related Pattern (TIRP) mining, which extracts frequent TIRPs from interval sequences, has gained increasing attention recently and is widely applied across various fields. Compared to Sequential Pattern Mining (SPM), the search space in TIRP mining is significantly larger, making the mining process more complex. Meanwhile, for mining complete TIRPs, current methods primarily rely on the Pattern-Growth algorithm, which stores all occurrences of TIRPs at the tree nodes of a prefix tree (trie) to reduce database scans. However, as the tree depth increases, the number of TIRP occurrences in interval sequences grows significantly, resulting in massive-scale data structures. Additionally, these algorithms lack pruning strategies to terminate the extension of infrequent TIRPs early, further increasing computational complexity. To overcome these challenges, we propose an efficient TIRP mining algorithm for mining complete TIRPs, named TIRPMiner. We developed a position compression algorithm that compresses the positions where TIRPs occur in interval sequences into single integer values (called position index), which reduces memory usage. Additionally, we implemented a method that can incrementally calculate these position indices. To enhance efficiency, we introduced two data structures, the occurrence-list and the v-table, which help minimize decompression operations when calculating relations. Furthermore, we proposed two pruning strategies, Unpromising Candidate TIRP Pruning (UCTP) and Unpromising Candidate Occurrence Pruning (UCOP), to identify infrequent TIRPs early in the scanning process and halt further scanning. Experimental results demonstrate that our algorithm outperforms existing methods on most real and synthetic datasets, and the pruning strategies effectively eliminate unnecessary operations.},
  archive      = {J_KBS},
  author       = {Chunkai Zhang and Huaijin Hao and Ryan Han-Yuan Zhang},
  doi          = {10.1016/j.knosys.2025.113944},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113944},
  shortjournal = {Knowl. Based Syst.},
  title        = {TIRPMiner: An efficient algorithm for mining time interval-related pattern},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid multi-encoder transformer and case-based reasoning for intelligent decision support in high-speed railway vehicle maintenance. <em>KBS</em>, <em>325</em>, 113943. (<a href='https://doi.org/10.1016/j.knosys.2025.113943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent development of artificial intelligence-based methods for predicting high-speed railway malfunctions, the actual maintenance procedure for fixing vehicle breakdown remains highly dependent on human expertise. However, delays in identifying faults and determining appropriate maintenance procedures cause considerable disruptions to railway traffic. In this study, we propose a new solution to enhance the efficiency of fault identification and maintenance decisions during breakdowns in high-speed railway vehicles. We develop a text-to-text generative model that handles handwritten breakdown data and uses a multi-encoder transformer model with case-based reasoning (CBR) to propose a maintenance strategy based on existing knowledge and expertise. Our experimental tests demonstrate the superiority of the proposed method in terms of using historical maintenance actions and fault sentences concurrently compared with baseline approaches. Our findings hold strong potential for improving decision support systems in high-speed railway vehicle maintenance by harnessing the synergy between CBR and generation models to derive actionable insights from maintenance data records.},
  archive      = {J_KBS},
  author       = {Hyung Il Lee and Jong Woo Kim},
  doi          = {10.1016/j.knosys.2025.113943},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113943},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid multi-encoder transformer and case-based reasoning for intelligent decision support in high-speed railway vehicle maintenance},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VANILLA: Validated knowledge graph completion—A normalization-based framework for integrity, link prediction, and logical accuracy. <em>KBS</em>, <em>325</em>, 113939. (<a href='https://doi.org/10.1016/j.knosys.2025.113939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are expressive data structures for integrating and describing heterogeneous data by unifying factual information and domain knowledge. However, under the Open World Assumption (OWA), the absence of facts does not imply falsity—only incompleteness. Inductive learning methods, particularly numerical techniques such as Knowledge Graph Embeddings (KGEs) and Graph Neural Networks (GNNs), are widely used for link prediction and classification tasks in KGs. These models excel at capturing latent patterns and exploiting structural properties at scale. Nevertheless, their performance can be significantly degraded by anomalies in KG representations—semantic inconsistencies and modeling artifacts that arise from unconstrained data integration. Such anomalies obscure the intended meaning of relations, introduce noise, and mislead numerical learning models. To address this issue, we introduce a normalization theory for KGs that enforces semantic consistency through normal forms. These forms restructure KGs to eliminate representational anomalies, ensuring that the data adheres to well-defined semantic constraints. We present VANILLA , a neuro-symbolic framework that combines symbolic rule learning, numerical inductive models, and constraint-based validation. By aligning inductive predictions with normalized, ontology-aware KG structures, VANILLA enables accurate and semantically grounded KG completion. Experimental results show that our approach significantly improves predictive performance while maintaining semantic integrity, demonstrating the value of normalization in hybrid KG learning systems. VANILLA is publicly available on GitHub https://github.com/SDM-TIB/VANILLA .},
  archive      = {J_KBS},
  author       = {Disha Purohit and Yashrajsinh Chudasama and Maria-Esther Vidal},
  doi          = {10.1016/j.knosys.2025.113939},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113939},
  shortjournal = {Knowl. Based Syst.},
  title        = {VANILLA: Validated knowledge graph completion—A normalization-based framework for integrity, link prediction, and logical accuracy},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UMDA-DDSTGN: An unsupervised meta-domain adaptation method using dynamic directed spatial-temporal graph network for EEG-based emotion recognition. <em>KBS</em>, <em>325</em>, 113938. (<a href='https://doi.org/10.1016/j.knosys.2025.113938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) signals, generated by neuronal activity in the cerebral cortex and recorded via electrodes, have become essential in advancing emotion recognition research. However, previous studies have not fully explored the spatial–temporal dynamics of EEG channels. This study introduces an innovative unsupervised meta-domain adaptation method, UMDA-DDSTGN (Unsupervised Meta-Domain Adaptation using Dynamic Directed Spatial-Temporal Graph Network), for EEG-based emotion recognition. The proposed method effectively captures spatial–temporal features by modeling changes in the topological structure of EEG channels in response to emotional stimuli. By constructing a dynamic directed spatial–temporal graph and employing the DDSTGN model for feature extraction, the approach demonstrates superior performance in capturing the intricate patterns of EEG signals. Furthermore, a UMDA strategy is incorporated to improve model generalization and align the feature distributions between source and target domains through unsupervised fine-tuning, thereby addressing cross-subject variability in EEG-based emotion recognition. Extensive experiments on the SEED and SEED-IV datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Chang Gao and Lifan Jia and Jiajun Xu and Pengcheng Yang},
  doi          = {10.1016/j.knosys.2025.113938},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113938},
  shortjournal = {Knowl. Based Syst.},
  title        = {UMDA-DDSTGN: An unsupervised meta-domain adaptation method using dynamic directed spatial-temporal graph network for EEG-based emotion recognition},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DyAtGNN: Dynamic attention graph neural networks for dynamic graph. <em>KBS</em>, <em>325</em>, 113935. (<a href='https://doi.org/10.1016/j.knosys.2025.113935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static graph representation learning are insufficient for capturing the temporal dynamics and evolving nature of graphs over time. Hence, dynamic graph learning is emerging as a highly promising and rapidly advancing field of research. Learning the temporal dynamics that underlie the variability of complex dynamic graphs poses a significant challenge for traditional graph learning. Most of the existing dynamic graph methods incorporate RNN to learn temporal dynamics, but there are limitations in learning depth information and handling node dynamics. In this work, we propose the DyAtGNN, a groundbreaking framework in dynamic graph learning that combines the temporal dynamics learning module and the adaptive structure learning module to learn the dynamics of dynamic graphs effectively. In DyAtGNN, we innovatively propose to simultaneously learn the model parameters and influential nodes through RNN, and combine with a deeper structure learning to effectively adapt to scenarios where nodes frequently change. As a general framework, it supports various tasks such as node regression, node classification and link prediction. Extensive experiments conducted on 8 dynamic graphic datasets have verified that our method outperforms the current baselines in terms of performance. Especially in scenarios with strong dynamic changes, the maximum improvement reaches approximately 67%. Furthermore, studies with 8 ablation models affirm the synergistic benefits of integrating temporal dynamics with adaptive structural learning. The code is accessible at https://github.com/FeihongTan1/DyAtGNN .},
  archive      = {J_KBS},
  author       = {Feihong Tan and Chunhui Zhang and Lei Liu},
  doi          = {10.1016/j.knosys.2025.113935},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113935},
  shortjournal = {Knowl. Based Syst.},
  title        = {DyAtGNN: Dynamic attention graph neural networks for dynamic graph},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ModFusion: Modality feature representation and hierarchical fusion for esophageal lesions segmentation. <em>KBS</em>, <em>325</em>, 113932. (<a href='https://doi.org/10.1016/j.knosys.2025.113932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of esophageal cancer relies heavily on endoscopic screening. Accurately determining the type of cancer requires various imaging modalities. However, due to natural peristalsis, these modal images often fail to capture the same lesion from identical viewpoints. This paper focuses on the ‘pseudo’ single-modal data constructed by combining multimodal images. Under this data setting, conventional segmentation approaches, including paired and single-modal methods, struggle to deliver consistent performance due to inherent modality discrepancies. To address this issue, we propose ModFusion, a framework composed of two modules: the Adaptive Feature Modulation Module (AFMM) and the Stage Fusion Module (SFM). Specifically, the AFMM integrated within the encoder reduces modality-specific variations to produce modality-agnostic feature representations. Meanwhile, the SFM enables hierarchical fusion in the decoder, mitigating the loss of fine-grained details which is always a challenge in segmentation approaches. Experimental results demonstrate that ModFusion outperforms existing models on our curated ‘pseudo’ single-modal data, achieving a lower MAE of 0.68 and a higher mIoU of 2.83%. Additionally, ModFusion exhibits superior performance on several publicly available single-modal datasets.},
  archive      = {J_KBS},
  author       = {Keyu Chen and Zhiyou Yang and Ma Luo and Wei Liu and Yi Mou and Bing Hu and Xianglei Yuan and Wenyu Chen},
  doi          = {10.1016/j.knosys.2025.113932},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113932},
  shortjournal = {Knowl. Based Syst.},
  title        = {ModFusion: Modality feature representation and hierarchical fusion for esophageal lesions segmentation},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TimeParticle: Particle-like multiscale state space models for time series forecasting. <em>KBS</em>, <em>325</em>, 113923. (<a href='https://doi.org/10.1016/j.knosys.2025.113923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is crucial in fields such as transportation and finance, often involving complex nonlinear relationships and long-term dependencies. Recently, state space models (SSM), exemplified by Mamba, have gained attention for their ability to capture these complexities. However, significant research gaps remain in adapting core SSM operators to time series data. To bridge this gap, we propose TimeParticle, a particle-like state space model for time series forecasting. Our key contributions include an innovative multiscale patch modeling approach and improvements to the SSM operator inspired by particle volatility. Specifically, by removing harmonic components in the frequency domain to reduce interference and selecting critical periodic patterns as patch lengths, we decompose the series into different time scales. Utilizing multiscale patch information and inherent trend information of time series, we solve the discretized Schrödinger equation to determine the probability distribution of the series at each time step. Additionally, an MLP layer between channels is applied to strengthen the capture of cross-channel dependencies, thereby improving predictive capability. Extensive experiments on various real-world datasets have demonstrated that TimeParticle outperforms all existing models, achieving state-of-the-art forecasting performance.},
  archive      = {J_KBS},
  author       = {Chaoyang Wang and Guangyu Liu},
  doi          = {10.1016/j.knosys.2025.113923},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113923},
  shortjournal = {Knowl. Based Syst.},
  title        = {TimeParticle: Particle-like multiscale state space models for time series forecasting},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion model in modern detection: Advancing deepfake techniques. <em>KBS</em>, <em>325</em>, 113922. (<a href='https://doi.org/10.1016/j.knosys.2025.113922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake detection remains a challenging task due to the increasing sophistication of AI-generated content, which often exhibits subtle artifacts that are difficult to detect with conventional methods. In the context of AI-generated content the image enhancement plays a crucial role in addressing the challenges by improving the visibility of facial features for facilitating more effective feature extraction. We utilize the DiffPIR diffusion model to enhance frames extracted from both authentic and altered videos processed through GAN architecture. The diffusion model improves image quality, making the enhanced frames appear more realistic and harder to detect by previous detection models. We propose an advanced deep learning CNN model with DenseNet121 and maxpooling with sigmoid for detecting the real and manipulated image frames processed by the diffusion model. The proposed model selects the facial region as an input to the model and uses information and advanced feature extraction techniques to increase the quality of model for detecting authentic and manipulated content. We experimented with a famous individual dataset of 500 videos designed by AIMIP lab. To validate the authenticity of our model, we applied it to the Celeb-DF and DFD datasets and evaluated its performance. Experimental results demonstrate that our model achieves high accuracy on selected datasets of famous individuals, CelebDF, and DFD. The results show that the proposed method outperforms existing state-of-the-art techniques, achieving over 99.91%.},
  archive      = {J_KBS},
  author       = {Fazeela Siddiqui and Jiachen Yang and Shuai Xiao and Muhammad Fahad},
  doi          = {10.1016/j.knosys.2025.113922},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113922},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion model in modern detection: Advancing deepfake techniques},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed3Scale: A cloud-edge-client tri-scale collaborative semi-supervised hierarchical federated learning framework. <em>KBS</em>, <em>325</em>, 113921. (<a href='https://doi.org/10.1016/j.knosys.2025.113921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning (FL) architectures, clients can train models locally without uploading raw data, thereby preserving data privacy. However, challenges such as heterogeneous computational capabilities, non-independent and identically distributed (non-IID) data, and a scarcity of labeled data limit the performance of FL in practical applications. Traditional two-tier FL architectures struggle to effectively address these issues, leading to suboptimal model training performance. To tackle these challenges, we propose a cloud–edge-client tri-scale semi-supervised FL framework (Fed3Scale). This framework leverages the computational capabilities of the cloud, edge servers (ES), and client devices, significantly mitigating the impact of heterogeneous computing power on model training. By uploading only feature-level data and incorporating a homomorphic encryption loss function, the framework further ensures data privacy. Additionally, to address data heterogeneity and the scarcity of labeled data, we introduce an aggregated semi-supervised learning (AggSSL) strategy: ES perform supervised training with their associated clients while engaging in unsupervised model aggregation with other ES, and jointly conduct semi-supervised training with the cloud server (CS). Experimental results show that compared to the best existing baseline method, Fed3Scale achieves a 5.77% improvement in accuracy, providing an efficient and reliable solution for intelligent task processing in heterogeneous clients. Our code is available at https://github.com/luqiwangupc/Fed3Scale .},
  archive      = {J_KBS},
  author       = {Luqi Wang and Shanchen Pang and Zhiyuan Zhao and Xiao He and Kuijie Zhang and Haiyuan Gui and Nuanlai Wang},
  doi          = {10.1016/j.knosys.2025.113921},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113921},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fed3Scale: A cloud-edge-client tri-scale collaborative semi-supervised hierarchical federated learning framework},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep association discovery framework for the multidimensional data: Application to power grid analysis. <em>KBS</em>, <em>325</em>, 113920. (<a href='https://doi.org/10.1016/j.knosys.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of associative relationships is essential for analyzing economic, industrial, and societal issues. However, identifying such relationships in high-dimensional data poses significant challenges, including high computational complexity and limited interpretability, particularly in complex systems such as power grids. To address these issues, we propose CORD, a deep association discovery framework for multidimensional data, designed to uncover relationships between cross-sectional transmission capacity and power grid operational modes. Our approach begins with an initial feature screening based on expert knowledge, followed by a secondary screening using the DBSCAN algorithm enhanced with rank correlation coefficients. We then construct a decision tree model that incorporates an improved K-Means + + clustering algorithm and information gain based on entropy to extract coarse-grained relationships. Furthermore, we develop a deep convolutional neural network integrated with rank correlation coefficients to capture fine-grained associations. Experiments on real-world power grid data demonstrate that the proposed CORD framework effectively uncovers meaningful relationships between transmission capacity and operational modes, providing a robust and interpretable solution for complex system analysis.},
  archive      = {J_KBS},
  author       = {Huaiyuan Liu and Donghua Yang and Jin Yang and Shengwen Zheng and Boran Shen and Hongzhi Wang and Xinglei Chen and Yong Cui and Jun Gu},
  doi          = {10.1016/j.knosys.2025.113920},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113920},
  shortjournal = {Knowl. Based Syst.},
  title        = {A deep association discovery framework for the multidimensional data: Application to power grid analysis},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving cross-lingual representation for semantic retrieval with code-switching. <em>KBS</em>, <em>325</em>, 113919. (<a href='https://doi.org/10.1016/j.knosys.2025.113919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic Retrieval (SR) has become an indispensable part of the FAQ system in the task-oriented question-answering (QA) dialogue scenario. The demand for a cross-lingual smart customer service system for e-commerce platforms and specific business scenarios has been increasing recently Most previous studies directly exploit cross-lingual pre-trained models (PTMs) for multilingual knowledge retrieval, while some also incorporate continual pre-training before fine-tuning PTMs on downstream tasks. However, no matter which schema is used, the previous work ignores to inform PTMs of some features of the downstream task, i.e. train their PTMs without providing any signals related to the downstream task (e.g., SR). To this end, in this work, we propose an Alternative Cross-lingual PTM for SR via code-switching. We are the first to utilize the code-switching approach for cross-lingual SR. Besides, we introduce the novel code-switched continual pre-training instead of directly using the PTMs on the SR tasks. The experimental results show that our proposed approach consistently outperforms the previous SOTA methods on SR and semantic textual similarity (STS) tasks with three business corpora and four open datasets in 20+ languages. Our approach outperforms the strongest baseline over 3.7 points on these datasets on average. The code is available at https://github.com/miradel51/codemix_ptm .},
  archive      = {J_KBS},
  author       = {Mieradilijiang Maimaiti and Yuanhang Zheng and Ji Zhang and Yue Zhang and Wenpei Luo and Kaiyu Huang},
  doi          = {10.1016/j.knosys.2025.113919},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113919},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving cross-lingual representation for semantic retrieval with code-switching},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate numerical prediction strategy (NPS) based on feature weighting and soft computing techniques. <em>KBS</em>, <em>325</em>, 113918. (<a href='https://doi.org/10.1016/j.knosys.2025.113918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction is the basic tool for planning and making decisions under uncertainty. Recently, Artificial Intelligence (AI) as well as its subspecialty Machine Learning (ML) have been employed to analyze historical data to identify rules, patterns, and then use those patterns to make future predictions. ML can be used to predict; (i) future events, which is referred as; Event Prediction (EP), or (ii) future numerical value of a specific variable, which is referred as; Numerical Prediction (NP). Although both EP and NP apply ML procedures, NP is more challenged task than EP as it requires accurate and specific numerical outputs. Based on ML, several NP techniques have been proposed, however, prediction accuracy is still questionable. This paper is the first to present a general strategy for predicting the value of a specific numerical variable based on pre-collected data, which is called Numerical Prediction Strategy (NPS). The proposed NPS has two basic phases, namely; Pre-processing phase (PP) and Numerical Prediction Phase (NPP). During the former, four fundamental tasks are established, which are; Feature Extraction (FE), Feature Balancing & Data Cleaning (FBDC), Feature Selection (FS), and Feature Weighting (FW). FS is carried out using Binary Leopard Seal Optimization (BLSO), while FW is accomplished by using a proposed fuzzy inference engine. On the other hand, NPP is done using a new algorithm called Staged K-Nearest Neighbor (SKNN). SKNN solves the basic KNN deficiency by taking feature weights into consideration during the prediction process. Several experiments have been done to illustrate the efficiency of NPS in different fields, namely; predicting the amount of biogas yields from anaerobic decomposition reactors and the travel time on the international coastal road in Egypt. Results have shown that the prediction accuracy of the proposed NPS will be about 95.08 % in predicting the amount of biogas yields. Also in predicting the travelling time, NPS outperforms recent prediction strategies in terms of prediction Mean Absolute Error (MAE), Root mean square error (RMSE), and Mean Absolute Percentage Error (MAPE). Considering 2050 journeys RMSE, MAE, and MAPE were; 18.71 %, 13.39 %, and 2.23 % respectively, which represents an adequate forecast accuracy.},
  archive      = {J_KBS},
  author       = {Ahmed I. Saleh and Shaimaa A. Hussien},
  doi          = {10.1016/j.knosys.2025.113918},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113918},
  shortjournal = {Knowl. Based Syst.},
  title        = {Accurate numerical prediction strategy (NPS) based on feature weighting and soft computing techniques},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coherence-enhanced language representation learning for sequential recommendations. <em>KBS</em>, <em>325</em>, 113917. (<a href='https://doi.org/10.1016/j.knosys.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the success of pre-trained language models, the recently proposed Text-Only sequential recommendation models aim to learn the language representation of each user from the item interaction sentence, which is the natural language text of a raw historical item interaction sequence. While existing Text-Only solutions have achieved promising results, they fail to address two key challenges: weak logical coherence in item interaction sentence and a trade-off between logical coherence and user interest trends, leading to less satisfactory recommendation performance. Therefore, this study proposes a novel C oherence- E nhanced language representation learning model for sequential Rec ommendations (CeRec). To address the first challenge, CeRec proposes to reorder items in each user interaction sequence based on coherence scores. To balance the logical coherence and user interest trends in the item interaction sentence (i.e., Challenge 2), CeRec introduces a reordering window into the reordering process to ensure that the position of the item is only adjusted within the window to which the item belongs. After the reordering process, the items in every window form a locally coherent subsequence, based on which the long- and short-term interests of the user are carefully learned via the well-designed structures in CeRec. Extensive experiments on four publicly available datasets show that CeRec outperforms the best baseline on the NDCG@10 metric by 5.24%, 13.59%, 17.99%, and 9.20%, respectively. The superiority of CeRec demonstrates that enhancing logical coherence in item interaction sentence of each user is critical to learn their language representations.},
  archive      = {J_KBS},
  author       = {Jia Xu and Haiwei Wu and Pin Lv},
  doi          = {10.1016/j.knosys.2025.113917},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113917},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coherence-enhanced language representation learning for sequential recommendations},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TEQA: Temporal knowledge graph enhanced question answering. <em>KBS</em>, <em>325</em>, 113916. (<a href='https://doi.org/10.1016/j.knosys.2025.113916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the data-driven era, Temporal Knowledge Graphs (TKGs) have emerged as knowledge-driven tools for modeling temporal information. However, existing knowledge-based question answering (KBQA) systems struggle to integrate temporal context with structured knowledge, limiting their decision support capabilities for time-sensitive queries. To address this, we propose the Temporal knowledge graph Enhanced Question Answering (TEQA) framework, which enhances dynamic knowledge representation through optimized temporal context modeling and explainable subgraph reasoning. TEQA comprises three knowledge-aware modules: (1) A temporal context modeling module that extracts temporal-entity relationships from questions to build context graphs; (2) A knowledge-enhanced multimodal embedding network that aligns question semantics with TKGs via joint embedding spaces; (3) A dynamic subgraph reasoner that performs constraint-based knowledge inference using temporal-aware graph pruning. By unifying these components, TEQA generates interpretable decision pathways with confidence estimation. Experiments on CronQuestions and TimeQuestions benchmarks demonstrate TEQA’s superiority, achieving 100% Hits@1/10 on complex queries. Notably, TEQA’s knowledge grounding mechanism provides traceable evidence for predictions, making it viable for time-critical decision support systems in healthcare and finance.},
  archive      = {J_KBS},
  author       = {Qian Liu and Siling Feng and Mengxing Huang},
  doi          = {10.1016/j.knosys.2025.113916},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113916},
  shortjournal = {Knowl. Based Syst.},
  title        = {TEQA: Temporal knowledge graph enhanced question answering},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leading and non-leading prompts: Quantifying gender bias in large language models through BiasBloom corpus. <em>KBS</em>, <em>325</em>, 113915. (<a href='https://doi.org/10.1016/j.knosys.2025.113915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of Artificial Intelligence by non-experts underscores the need to address biases in its outputs, particularly in gendered languages like Spanish, where linguistic features reflect gender. This paper proposes a validated methodology to quantify gender bias in text generated by Large Language Models (LLMs) in Spanish. The approach involves creating gendered seed-word lists, building a Spanish-specific corpus using curated prompts, and analyzing gender polarity and co-occurrences within the generated text. Validated using five state-of-the-art LLMs — GPT-3.5, GPT-4o, Llama 3, Gemini 1.5, and Mixtral8x7b — this study provides a systematic framework for bias detection in Spanish and highlights differences in model performance. By addressing the challenges of bias in gendered languages, this research aims to contribute to the development of equitable AI systems and advances methodologies for bias quantification. The findings highlight gender disparities in LLMs, with masculine and feminine biases shifting depending on the discourse structure. Specifically, the analysis reveals a prevalence of masculine biases in non-leading prompts and feminine biases in leading prompts, underscoring the nuanced ways in which prompt positioning can influence gender representation in model outputs.},
  archive      = {J_KBS},
  author       = {Victoria Muñoz-García and Juan Pablo Consuegra-Ayala and Paloma Moreda},
  doi          = {10.1016/j.knosys.2025.113915},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113915},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leading and non-leading prompts: Quantifying gender bias in large language models through BiasBloom corpus},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-oriented dynamic knowledge distillation for continuous few-shot relation extraction. <em>KBS</em>, <em>325</em>, 113914. (<a href='https://doi.org/10.1016/j.knosys.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Few-Shot Relation Extraction (CFRE) is a task in continual learning that closely mirrors real-world scenarios. This task emphasizes the acquisition of new relations from a limited set of training samples while maintaining the retention of knowledge related to previously learned relations. The main challenges of CFRE include catastrophic forgetting and balancing between stability and adaptability. In existing research, knowledge distillation methods are commonly used to alleviate catastrophic forgetting. However, the knowledge distillation methods currently applied to CFRE tasks, whether single-teacher or multi-teacher models, do not perform data partitioning, which impacts the learning of new relations and limits the recognition performance of old relations. To tackle these challenges, we propose a CFRE model based on Task-Oriented Dynamic Knowledge Distillation (TODKD). Specifically, we designed a dual-level task space separation knowledge distillation method that utilizes different teacher models at various stages to guide the sample training of relations belonging to different task stages, thereby alleviating catastrophic forgetting. To alleviate sample sparsity in few-shot scenarios, we use memory samples as an example and design prompt templates to assist LLMs in producing diverse data samples. Additionally, we designed dynamic weight loss to balance the model’s stability and adaptability effectively, resulting in a more uniform distribution of relation features across different tasks. Comprehensive experiments on the FewRel and TACRED datasets demonstrate that our TODKD model outperforms multiple competitive baseline approaches. Importantly, our model shows a marked enhancement compared to prior state-of-the-art techniques in the final task.},
  archive      = {J_KBS},
  author       = {Hexing Yang and Xuan Zhang and Chen Gao and Weiyi Shang and Kunpeng Du and Wei Cai and Danyang Wang and Tong Li},
  doi          = {10.1016/j.knosys.2025.113914},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113914},
  shortjournal = {Knowl. Based Syst.},
  title        = {Task-oriented dynamic knowledge distillation for continuous few-shot relation extraction},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-theoretic dual memory system for continual learning. <em>KBS</em>, <em>325</em>, 113913. (<a href='https://doi.org/10.1016/j.knosys.2025.113913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to continuously acquire new knowledge from a dynamic environment is fundamental for animal survival and adaptation. This process, known as continual learning (CL), emphasizes learning a sequence of tasks without compromising previously acquired knowledge. A common strategy for CL is to store key data samples from earlier tasks in a fixed-size memory buffer. However, most existing memory-based methods rely on a single buffer, making it difficult to manage newly acquired samples and previously learned samples simultaneously. Inspired by the theory of complementary learning systems (CLS), which distinguishes between fast and incremental learning mechanisms, this paper proposes a novel dual-memory architecture called Information-Theoretic Dual Memory System (ITDMS). The system consists of a fast memory buffer for temporarily storing new samples and a slow memory buffer for retaining key informative data. The fast memory buffer is managed by efficient storage sampling. To enhance the slow memory buffer, this paper introduces a new information-theoretic optimization strategy that selectively retains diverse and informative samples. In addition, a balanced sample selection mechanism is also proposed that automatically identifies and removes redundant samples, thereby freeing up memory space for new data and achieving scalability across more tasks. Our approach has been evaluated through extensive CL experiments. Empirical results demonstrate that the proposed ITDMS can effectively improve learning performance while maintaining memory efficiency.},
  archive      = {J_KBS},
  author       = {RunQing Wu and KaiHui Huang and HanYi Zhang and QiHe Liu and JinYu Guo and JingSong Deng and Fei Ye},
  doi          = {10.1016/j.knosys.2025.113913},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113913},
  shortjournal = {Knowl. Based Syst.},
  title        = {Information-theoretic dual memory system for continual learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series forecasting based on time–frequency transform mixed convolution. <em>KBS</em>, <em>325</em>, 113912. (<a href='https://doi.org/10.1016/j.knosys.2025.113912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models, such as transformers and convolutional neural networks (CNNs), have gained considerable attention in time series forecasting because of their powerful feature-extraction capabilities, end-to-end learning abilities, and strong generalization abilities. However, transformers suffer high computational complexity and insufficient ability to handle local details. Therefore, researchers who specialize in time series forecasting have turned their attention to CNN-based models. Although CNNs excel at capturing local features, they are susceptible to high-frequency noise. Herein, we propose a fusion convolution time series forecasting framework based on time–frequency transform, called Discrete Cosine and Wavelet Transform Network (DCWTNet). First, DCWTNet employs a patch embedding module to slice time series into patches for preserving local semantic information of time series. Next, time domain information is transformed into frequency domain information by combining the discrete cosine transform (DCT) and continuous wavelet transform (CWT), which helps attenuate the effect of high-frequency noise on the model’s generalization ability. Simultaneously, each patch is decomposed and transformed at multiple scales via CWT to retain key amplitude information for capturing local temporal dependencies. In addition, DCT is employed to capture global temporal dependencies of each patch through information compression. A mixed convolutional layer is then used to adaptively balance the importance of global and local dependencies. Finally, interpatch information is integrated for predictions. Extensive experiments demonstrate that DCWTNet outperforms state-of-the-art baselines in predictive performance, particularly in the presence of highly noisy data.},
  archive      = {J_KBS},
  author       = {Jiaxin Dou and Yaling Xun and Haifeng Yang and Jianghui Cai and Yanfeng Li and Shuo Han},
  doi          = {10.1016/j.knosys.2025.113912},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113912},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multivariate time series forecasting based on time–frequency transform mixed convolution},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized deep aerial multi-view stereo network based on gradient balance masked representation learning. <em>KBS</em>, <em>325</em>, 113911. (<a href='https://doi.org/10.1016/j.knosys.2025.113911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV)-based ground scanning and 3D reconstruction can rapidly build terrain-awareness systems, providing essential data for regional planning, safety protection, biological conservation, natural disaster simulation, etc. Multi-view Stereo (MVS) is a 3D reconstruction technique based on feature matching of multiple images. However, large-scale aerial scenes cannot be accurately captured using high-precision structured light acquisition devices to obtain precise depth labels. The generalization of MVS from indoor to aerial scenes remains underexplored. Moreover, when dealing with continuously varying ground information, deep learning models require robust scene perception capabilities to better adapt and generalize. Therefore, we have proposed a multi-task learning framework to develop a generalizable MVS method, jointly training depth estimation of multi-view images and a Mask Auto Encoder (MAE). The optimization of the two tasks mutually constrains each other, making the extracted features more universal and ensuring their generalization ability to different scenarios. To solve the MAE-MVS task compatibility issue, we develop a novel feature extraction module based on sparse CNN. For multi-task training balance, we propose dynamic adaptive multi-task loss weights (DAMW), which adjust training weights in real-time based on the gradient modulus ratio from multi-task loss to the feature pyramid. We conducted performance evaluations on the DTU, WHU MVS, LuoJia MVS, and Tanks and Temples datasets. On the DTU dataset, the overall error was reduced by 0.03 mm. The mean absolute error on the WHU MVS and LuoJia MVS datasets was reduced by 0.011 mm and 0.039 mm, respectively. The test results for Tanks and Temples have been published on the official website. Additionally, the generalization performance from indoor to aerial scenes was enhanced, with the mean absolute error decreasing by 0.148 mm. The experimental results demonstrate that our multi-task learning framework has achieved significant improvements in depth estimation accuracy and cross-scene generalization.},
  archive      = {J_KBS},
  author       = {Shichao Wang and Mingxing Jia and Shijie Chang and Dapeng Niu},
  doi          = {10.1016/j.knosys.2025.113911},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113911},
  shortjournal = {Knowl. Based Syst.},
  title        = {Generalized deep aerial multi-view stereo network based on gradient balance masked representation learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning and population-based discrete state transition algorithm for solving the multi-UAV task allocation problem with complex constraints. <em>KBS</em>, <em>325</em>, 113910. (<a href='https://doi.org/10.1016/j.knosys.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of unmanned aerial vehicle (UAV) technology in the military field has expanded significantly, making the cooperative task allocation problem for multiple UAVs a prominent research focus. This study aims to solve a mixed variable multi-objective UAV cooperative multi-task allocation problem (M-CMTAP) with complex constraints. A novel and effective mixed-variable encoding and feasible solution initialization method is adopted to address this complex problem. To increase the diversity of solutions in the discrete state transition algorithm (DSTA), the concept of population co-evolution is introduced into the DSTA, and reinforcement learning method is used to assist in evolution, leading to the proposal of a reinforcement learning and population-based discrete state transition algorithm (RL-PDSTA). Additionally, four new constraint-handling operators replace those in original DSTA, greatly improving both search efficiency and accuracy. The effectiveness and superiority of RL-PDSTA are validated through various military scenarios, and experimental results demonstrates the algorithm’s high efficiency in constraint handling and rapid iterative computation.},
  archive      = {J_KBS},
  author       = {Xiaojun Zhou and Runsong Xia and Tingwen Huang},
  doi          = {10.1016/j.knosys.2025.113910},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113910},
  shortjournal = {Knowl. Based Syst.},
  title        = {A reinforcement learning and population-based discrete state transition algorithm for solving the multi-UAV task allocation problem with complex constraints},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HP-tracker: A high-performance tracker for small targets in remote sensing. <em>KBS</em>, <em>325</em>, 113909. (<a href='https://doi.org/10.1016/j.knosys.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite video multi-object tracking (MOT) is an extremely challenging task. This is mainly due to the small size of the targets in the video and their high similarity to the background, which makes it easy for trackers to encounter issues such as missed detections and unstable trajectories. To address this problem, we propose a new MOT tracker based on Tracking-by-Detection (TBD), named HP-Tracker. First, we introduce a feature enhancement module based on the differences between targets and the background, called FETBD, and embed it into the tracker to enhance the feature representation of small targets. Then, we propose a detection box prediction algorithm based on historical positions, DPA, and a parameter correction strategy for the Kalman filter based on the fourth-order Runge–Kutta method, RK4-KFPCS, to mitigate trajectory drift caused by missed detections. Meanwhile, considering that some scenarios focus only on dynamic targets, we propose a static target filtering algorithm, STF, to eliminate the interference of static targets on the tracker. Finally, we validate the superiority of HP-Tracker on three large-scale satellite datasets.},
  archive      = {J_KBS},
  author       = {Zhiguo Liu and Yuqi Chen and Lin Wang and Chengsheng Pan},
  doi          = {10.1016/j.knosys.2025.113909},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113909},
  shortjournal = {Knowl. Based Syst.},
  title        = {HP-tracker: A high-performance tracker for small targets in remote sensing},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-performance lightweight network for mining transport belt tear segmentation and degree prediction. <em>KBS</em>, <em>325</em>, 113908. (<a href='https://doi.org/10.1016/j.knosys.2025.113908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing methods of mining transport belt tear segmentation (BTS) and degree prediction (DP) are challenged by the crack shape variation, background interference and lack of field data, so segmentation accuracy and efficiency are low. To alleviate above problems in tear segmentation and degree prediction, an end-to-end BTS and DP network DFPA-Net is proposed. Firstly, we design a double-layer partial convolution as the core lightweight feature extraction algorithm (DPCFE), and integrate it into the encoder and decoder network. The algorithm improves the ability of DFPA-Net to recognize cracks in transport belt images (BI) and to represent different shape features, while reducing overall parameter number and calculation cost about model. Secondly, we propose a large selection kernel efficient channel attention (LSKECA) to capture tear features at different scales and fully extract semantic information concerning belt context. Then, we introduce and use a pixel-attention-guided fusion module (PagFM) to replace simple feature concatenate, which allows DFPA-Net to selectively learn useful tear features from context branches without being inundated by massive detail information. Finally, we traveled to a mining production site and used specific image sensors to collect and construct a high-quality transport belt tearing (TBT) image dataset called Transport Belt-1K, solving the problem regarding unavailability of public datasets. After extensive experiments, it is proved that DFPA-Net is superior to state-of-the-art (SOTA) segmentation method in both performance and lightweight, among which segmentation accuracy of DFPA-Net is as high as 98.3 %, model size is only 2.4 MB, and tear DP accuracy is 98.5 %.},
  archive      = {J_KBS},
  author       = {Hanquan Zhang and Dong Xiao and Jichun Wang and Zhengmin Gu},
  doi          = {10.1016/j.knosys.2025.113908},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113908},
  shortjournal = {Knowl. Based Syst.},
  title        = {A high-performance lightweight network for mining transport belt tear segmentation and degree prediction},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing math reasoning ability of large language models via computation logic graphs. <em>KBS</em>, <em>325</em>, 113905. (<a href='https://doi.org/10.1016/j.knosys.2025.113905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reasoning capabilities of large language models (LLMs) are essential for a wide range of tasks, particularly in the domain of mathematical reasoning. Common chain of thought methods perform well in handling simple reasoning problems, but for complex problems, a single-dimensional chain of thought is inadequate to address multi-layered logical relationships. To tackle this challenge, this paper introduces the concept of a Computation Logic Graph (CLG), designed to enhance the logical reasoning abilities of LLMs when solving complex mathematical problems. The CLG decomposes complex mathematical problems into multiple simple intermediate computational units, and the final answer is obtained through multiple iterations of these units. On the one hand, the CLG improves the model’s ability to decompose and solve complex mathematical problems step-by-step from a global perspective. On the other hand, the local inference process within the CLG helps enhance the model’s accuracy in single step calculations. To develop models with the ability to construct Computation Logic Graphs automatically, we create a dataset of computational logic graphs for complex mathematical problems, called the Computation-intensive Math Logic Graph (CMLG) dataset. We fine-tune several open-source LLMs using the CMLG dataset. Experimental results demonstrate that the proposed CLG method significantly enhances the performance of LLMs in complex mathematical reasoning tasks, outperforming on both the CMLG dataset and six other publicly available datasets from diverse domains.},
  archive      = {J_KBS},
  author       = {Deji Zhao and Donghong Han and Jia Wu and Zhongjiang He and Bo Ning and Ye Yuan and Yongxiang Li and Chao Wang and Shuangyong Song},
  doi          = {10.1016/j.knosys.2025.113905},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113905},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing math reasoning ability of large language models via computation logic graphs},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing knowledge tracing with question-based contrastive learning. <em>KBS</em>, <em>325</em>, 113899. (<a href='https://doi.org/10.1016/j.knosys.2025.113899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) plays a crucial role in online education systems, with the primary goal of monitoring students’ mastery of knowledge during the learning process. Typically, this understanding is assessed through students’ responses to specific questions. Therefore, the manner in which questions are represented is of paramount importance in knowledge tracing. Many current KT methods aim to enhance KT by adding additional features to represent questions. However, this significantly increases the burden and cost of data collection. Conversely, methods that enhance KT using only basic features (questions and concepts) often harbor unreasonable assumptions and lack interpretability in representing the questions. Moreover, they fail to exploit the higher-order relationships between questions, resulting in limited performance. We propose QCKT to solve these problems. QCKT represents questions from two perspectives. First, by leveraging the relationship between questions and concepts, question representations were constructed using concept embedding. We explicitly incorporated the difficulty of questions into this representation to construct interpretable question representations. Second, to uncover higher-order relationships between questions, we constructed a Concept-Aware Question Relationship Graph and utilize a graph encoder on this graph to aggregate the relationships between questions. Finally, based on the assumption of different relationship granularities between questions, we propose five contrastive learning strategies to explore the similarities and differences between these two types of question representations. We evaluated QCKT by extending 13 existing KT methods to six publicly available datasets. Extensive experiments demonstrate that QCKT significantly improves the performance, with many baseline models extended by QCKT exhibiting capabilities surpassing those of state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Xiaoxuan Shen and Fenghua Yu and Yaqi Liu and Ruxia Liang and Qian Wan and Tianhao Yang and Mengtian Shi and Jianwen Sun},
  doi          = {10.1016/j.knosys.2025.113899},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113899},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing knowledge tracing with question-based contrastive learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAdaBoost: An efficient and robust AdaBoost algorithm based on granular-ball structure. <em>KBS</em>, <em>325</em>, 113898. (<a href='https://doi.org/10.1016/j.knosys.2025.113898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive Boosting (AdaBoost) faces significant challenges posed by label noise, especially in multiclass classification tasks. Existing methods either lack mechanisms to handle label noise effectively or suffer from high computational costs due to redundant data usage. Inspired by granular computing, this paper proposes granular adaptive boosting (GAdaBoost), a novel two-stage framework comprising a data granulation stage and an adaptive boosting stage, to enhance efficiency and robustness under noisy conditions. To validate its feasibility, an extension of SAMME, termed GAdaBoost.SA, is proposed. Specifically, first, a granular-ball generation method is designed to compress data while preserving diversity and mitigating label noise. Second, the granular ball-based SAMME algorithm focuses on granular balls rather than individual samples, improving efficiency and reducing sensitivity to noise. Experimental results on some noisy datasets show that the proposed approach achieves superior robustness and efficiency compared with existing methods, demonstrating that this work effectively extends AdaBoost and SAMME.},
  archive      = {J_KBS},
  author       = {Qin Xie and Qinghua Zhang and Shuyin Xia and Xinran Zhou and Guoyin Wang},
  doi          = {10.1016/j.knosys.2025.113898},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113898},
  shortjournal = {Knowl. Based Syst.},
  title        = {GAdaBoost: An efficient and robust AdaBoost algorithm based on granular-ball structure},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale subspace co-clustering network with adaptive multi-scale enhancement for remote sensing scene classification. <em>KBS</em>, <em>325</em>, 113897. (<a href='https://doi.org/10.1016/j.knosys.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With its robust semantic representation and feature extraction capabilities, intelligent scene analysis of remote sensing images using computational intelligence has garnered increasing attention from researchers. However, existing approaches tend to focus predominantly on either local or global feature embedding, often overlooking the distinct advantages of multi-scale representation. This oversight presents two primary challenges: first, remote sensing scenes frequently contain targets of varying scales, and current multi-scale fusion techniques typically treat all scales equally, disregarding the unique contributions of each. Inadequate feature fusion leads to poor feature extractor in the model, thereby affecting classification performance. Second, the complex and diverse nature of remote sensing scenes leads to significant intraclass variance and high interclass similarity. These factors contribute to the poor consistency of data representation and the lack of discriminative power in cluster structures. To address these challenges, we propose a Multi-Scale Subspace Co-Clustering Network with Adaptive Multi-scale Enhancement (MS C 2 Net-AME) to facilitate adaptive fusion across scales and enable the learning of discriminative semantic representations. Specifically, we introduce a Multi-Scale Attention Fusion (MAF) module and a Multi-Scale Subspace Co-Clustering (MSC) module. The MAF module enables adaptive fusion of semantic information across hierarchical features, while the MSC module aggregates joint embedding representations of spatial information across different subspace scales, enhancing the discriminative power of the learned features. Our method demonstrates superior performance over state-of-the-art algorithms on several benchmark datasets, highlighting the efficacy of our proposed approach. The implementation code of MSC 2 Net-AME is publicly available at: https://github.com/yelei/MSC2Net-AME .},
  archive      = {J_KBS},
  author       = {Lei Ye and Zhenping Sun and Changyu Chen and Haiyan Han and Yue Wu},
  doi          = {10.1016/j.knosys.2025.113897},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113897},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-scale subspace co-clustering network with adaptive multi-scale enhancement for remote sensing scene classification},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DHRL4HKG: A dual-hypergraph representation learning for hyper-relational knowledge graphs. <em>KBS</em>, <em>325</em>, 113886. (<a href='https://doi.org/10.1016/j.knosys.2025.113886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyper-relational knowledge graphs (HKGs), consisting of hyper-relational facts (H-Facts), provide a promising approach for representing complex data relations. However, existing methods for HKG representation learning often neglect the one-to-many relationships between attributes and their corresponding values in H-Facts. Furthermore, accurately capturing high-order information (combining the main triple with its qualifiers) remains challenging. To address these issues, we propose Dual-Hypergraph Representation Learning for HKGs (DHRL4HKG). Specifically, we introduce a novel definition of H-Facts that accounts for the one-to-many relationships between attributes and their values. Based on this definition, we construct two types of hypergraphs: an inter-hypergraph, which explores the correlations among different H-facts on HKGs, and an intra-hypergraph, which captures high-order information within individual H-Facts. We then design a hypergraph Transformer encoder to learn the representations of these hypergraphs comprehensively. Extensive experiments on real-world datasets demonstrate that our approach significantly outperforms existing methods for HKG representation learning, particularly in link prediction tasks. Our source code is available at: https://github.com/No24Programmer/DHRL4HKG .},
  archive      = {J_KBS},
  author       = {Jiecheng Li and Xudong Luo and Guangquan Lu and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.113886},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113886},
  shortjournal = {Knowl. Based Syst.},
  title        = {DHRL4HKG: A dual-hypergraph representation learning for hyper-relational knowledge graphs},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial defect impact grounding: A new task addressed with functional-to-visual and grounding-distilled knowledge. <em>KBS</em>, <em>325</em>, 113884. (<a href='https://doi.org/10.1016/j.knosys.2025.113884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new task in the field of industrial defect detection, named industrial defect impact grounding (IDIG). This task requires detection models not only to identify and classify defects but also to align visual defects with textual descriptions of their functional impact. To address the limitations of existing datasets that focus solely on traditional defect detection, we construct a novel dataset containing both visual defects and their corresponding comprehensive functional descriptions, providing a standardized benchmark for future research. Based on this task, we propose an innovative knowledge extraction and utilization framework that leverages two key types of knowledge: functional-to-visual knowledge and grounding-distilled knowledge. The functional-to-visual knowledge is acquired through multimodal large language models (MLLMs), which generate descriptive visual information to supplement original functional descriptions, thereby bridging the gap between textual functionality and visual representation. The grounding-distilled knowledge is obtained through a multimodal knowledge distillation process, distilling multimodal features and decoder output, where a student model learns both functional impact understanding required for the IDIG and the teacher model’s expertise in referring expression comprehension and visual localization. To ensure robust knowledge transfer, we introduce a Student–Teacher Momentum Update (STMU) mechanism that dynamically aligns the parameters between student and teacher models, facilitating stable and effective learning. Experimental results demonstrate that our framework significantly outperforms existing methods in visual-text alignment tasks, establishing a strong baseline for future research in industrial defect detection. The dataset and code is available in GitHub https://github.com/itrues .},
  archive      = {J_KBS},
  author       = {Liuwu Li and Yang Yu and Jiayuan Xie and Yi Cai},
  doi          = {10.1016/j.knosys.2025.113884},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113884},
  shortjournal = {Knowl. Based Syst.},
  title        = {Industrial defect impact grounding: A new task addressed with functional-to-visual and grounding-distilled knowledge},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDPM: Modulating domain-specific prompt memory for multi-domain traffic flow prediction with transformers. <em>KBS</em>, <em>325</em>, 113881. (<a href='https://doi.org/10.1016/j.knosys.2025.113881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain traffic flow prediction aims to develop a versatile model that uses historical traffic data from various sources to forecast future traffic conditions across these individual datasets. Existing deep traffic prediction models typically focus on mining spatial–temporal relationships in a single dataset. However, there are two limitations should be considered: Lack of Model Universality , current traffic prediction research remains constrained by the absence of a universal model adaptable to multiple datasets, restricting performance improvement across diverse scenarios; Underutilized Cross-Dataset Similarities , while existing datasets exhibit both exclusive and shared spatial–temporal patterns, effectively leveraging these common patterns to enhance model performance continues to present technical challenges. To overcome the limitations mentioned above, this study introduces a straightforward yet efficient M odulating D omain-Specific P rompt M emory (MDPM) to model complex spatial–temporal interaction and better leverage similar spatial–temporal patterns across diverse datasets. Specifically, our approach is tailored with three key innovations: (1) A domain-shared encoder incorporating intra-modality Spatial–Temporal Rotary Position Encoder (ST2R) to capture universal patterns; (2) A gate fusion mechanism enhanced by contrastive learning with inter-modality ST2R to optimize spatial–temporal feature alignment; (3) Domain-specific learnable prompt vectors that dynamically guide each transformer layer in capturing unique urban traffic characteristics at node-level temporal granularity. Notably, this architecture achieves state-of-the-art performance without requiring supplementary road network data. Comprehensive experiments conducted on six real-world public traffic datasets show that our proposed method significantly surpasses existing state-of-the-art approaches.},
  archive      = {J_KBS},
  author       = {Zhuang Zhuang and Lingbo Liu and Kan Guo and Xingtong Yu and Heng Qi and Yanming Shen and Baocai Yin},
  doi          = {10.1016/j.knosys.2025.113881},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113881},
  shortjournal = {Knowl. Based Syst.},
  title        = {MDPM: Modulating domain-specific prompt memory for multi-domain traffic flow prediction with transformers},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMFND: In-context multimodal fake news detection with large visual-language models. <em>KBS</em>, <em>325</em>, 113880. (<a href='https://doi.org/10.1016/j.knosys.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent advancements, studies indicate that large language models (LLMs), such as GPT-3.5-turbo, often perform worse than well-trained small models, such as BERT, in fake news detection (FND). Similarly, while large visual-language models (LVLMs) demonstrate exceptional capabilities in visual-language reasoning across diverse cross-modal benchmarks, their performance in FND remains unexplored. This paper examines the FND capabilities of LVLMs in comparison to a small but adeptly trained contrastive language-image pre-training (CLIP) model in a zero-shot setting. The results reveal that LVLMs achieve performance comparable to small models. Building on this, the study further explores the integration of standard in-context learning (ICL) with LVLMs, observing modest yet inconsistent improvements in FND performance. To address these limitations, this paper introduces the I n-context M ultimodal F ake N ews D etection (IMFND) framework, designed to enhance feature extraction for both in-context examples and test inputs. The framework leverages predictions and their associated probabilities, generated by a well-trained small model, to guide LVLMs towards news modalities with higher probabilities. Experimental results across three publicly available FND datasets demonstrate that the IMFND framework significantly enhances the performance of LVLMs, achieving superior accuracy compared to the standard ICL approach.},
  archive      = {J_KBS},
  author       = {Ye Jiang and Yimin Wang},
  doi          = {10.1016/j.knosys.2025.113880},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113880},
  shortjournal = {Knowl. Based Syst.},
  title        = {IMFND: In-context multimodal fake news detection with large visual-language models},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic configuration network based on an improved sampling strategy and bayesian optimization. <em>KBS</em>, <em>325</em>, 113879. (<a href='https://doi.org/10.1016/j.knosys.2025.113879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration network (SCN) is an incremental random learning model that achieves fast convergence through a supervised mechanism, making it well-suited for adapting to variations in data characteristics across different regression and classification tasks. However, due to the inherent limitations of fully connected neural networks, the original random sampling strategy may lead to a decline in SCN’s generalization performance. Bayesian optimization, a global optimization method based on Bayesian statistics and Gaussian processes, can efficiently and accurately identify the optimal hyperparameters for model performance. Based on this, this paper proposes a Bayesian optimization-based stochastic configuration network (BO-SCN) algorithm, which integrates an improved sampling strategy and Bayesian optimization. First, a scaling factor s is introduced as a new hyperparameter into both uniform and normal distribution sampling strategies to ensure that the sampled weight values remain relatively small. Second, Bayesian optimization is employed to automatically select the optimal value of s , and an optimal search range for s is proposed, minimizing manual intervention while maximizing model performance. Finally, the performance of BO-SCN is evaluated on ten benchmark datasets. Experimental results demonstrate that the proposed algorithm not only enhances prediction accuracy and maintains stability but also significantly reduces the complexity of hyperparameter tuning.},
  archive      = {J_KBS},
  author       = {Zihuan Xu and Xia Zhang},
  doi          = {10.1016/j.knosys.2025.113879},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113879},
  shortjournal = {Knowl. Based Syst.},
  title        = {A stochastic configuration network based on an improved sampling strategy and bayesian optimization},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward lightweight image super-resolution via re-parameterized kernel recalibration. <em>KBS</em>, <em>325</em>, 113876. (<a href='https://doi.org/10.1016/j.knosys.2025.113876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the exploration of lightweight image super-resolution (SR) networks has gained increasing attention, propelled by a notable demand to deploy models on devices with constrained computing resources. A common approach to reduce the number of parameters in SR networks is depth-wise convolution. However, this method compromises the model’s expressive power by operating on individual segmented features. To overcome this limitation, we propose a novel kernel recalibration strategy that relates the kernel of one channel to the parameters of other channels, allowing the kernels to shift their focus toward previously unattended sections of the model, rather than being restricted to isolated input channels. Building on this concept, a novel progressive multi-scale recalibration block (PMRB) is proposed to capture more discriminative features across various multi-scale receptive fields. After training, the parameters introduced by the kernel recalibration can be re-parameterized to align with standard convolution, ensuring that the resulting block maintains the same inference costs as the original block while delivering improved performance. Additionally, we introduce a lightweight SR network, referred to as the kernel recalibration-guided network (KRGN), which achieved an optimal balance between efficiency and availability. Extensive experiments validated the competitive performance of the proposed KRGN, achieving state-of-the-art results with significantly fewer parameters requiring only one-third of the computational cost of some leading lightweight methods. The code is available at https://github.com/ZhangDY827/KRGN .},
  archive      = {J_KBS},
  author       = {Dongyang Zhang and Jiachi Liu and Shuang Liang and Xiurui Xie and Qiang Dong and Ke Qin},
  doi          = {10.1016/j.knosys.2025.113876},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113876},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward lightweight image super-resolution via re-parameterized kernel recalibration},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated compositional knowledge graph embedding for communication efficiency. <em>KBS</em>, <em>325</em>, 113873. (<a href='https://doi.org/10.1016/j.knosys.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Embedding (KGE), which automatically capture structural information from Knowledge Graphs (KGs), are essential for enhancing various downstream applications, such as recommender systems. To further improve the effectiveness of KGE models, Federated Knowledge Graph Embedding (FKGE) is introduced. It enables privacy-preserving integration of KGs across multiple organizations. However, existing FKGE frameworks require aggregation of a large global KGE model (embeddings). resulting in significant communication overhead, thereby reducing the efficiency and utility of FKGE in practical scenarios. To address this challenge, we propose Federated Compositional Knowledge Graph Embedding (FedComp), which enhances communication efficiency by leveraging the compositional characteristics of KG entities. In FedComp, we design a lightweight global model that represents shareable latent features of entities. These global latent features are composed into personalized KGE models with local embedding generators on the clients, improving both local adaptability and performance. By this, FedComp can significantly reduce the number of parameters that need to be transmitted. Experimental results show that FedComp outperforms state-of-the-art FKGE frameworks on link prediction accuracy, with only around 1.0% communication overhead compared to counterpart frameworks.},
  archive      = {J_KBS},
  author       = {Zihao Zheng and Borui Cai and Yong Xiang and Yao Zhao and Md Palash Uddin and Keshav Sood},
  doi          = {10.1016/j.knosys.2025.113873},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113873},
  shortjournal = {Knowl. Based Syst.},
  title        = {A federated compositional knowledge graph embedding for communication efficiency},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trajectory planning of mobile robot: A lyapunov-based reinforcement learning approach with implicit policy. <em>KBS</em>, <em>325</em>, 113870. (<a href='https://doi.org/10.1016/j.knosys.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory planning for mobile robots is a crucial aspect of achieving intelligence in many industrial applications. Learning-based approaches are extremely useful for problems involving complex and difficult-to-define rule designs. However, these approaches frequently require a large amount of training data and lack convergence or interpretability. This work proposes a reinforcement learning paradigm that combines implicit policy with Lyapunov theory to solve the problem of mobile robot trajectory planning. Firstly, we develop a weighted asymmetric Lyapunov reward function and provide an analytical solution with modest dynamics as the implicit policy. Then, we propose event-triggered multi-objective policy optimization, an approach that dynamically adjusts optimization objectives based on event-triggered conditions, which organically fuse it into the modified soft Actor-Critic algorithm, thus shrinking the exploration space and enabling iterative improvement of RL policy. We demonstrate that in disturbed and random scenarios, the proposed fusion policy can achieve specialized policy learning and that its convergence, efficiency, and generalization are verifiable. This clearly demonstrates that our approach can be utilized as a foundational paradigm for the design of reinforcement learning reward and motion control in trajectory planning using an end-to-end approach, which has significant advantages in terms of convergence speed and interpretability.},
  archive      = {J_KBS},
  author       = {Jialun Lai and Zongze Wu and Zhigang Ren and Qi Tan and Shengli Xie},
  doi          = {10.1016/j.knosys.2025.113870},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113870},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trajectory planning of mobile robot: A lyapunov-based reinforcement learning approach with implicit policy},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPA-MVSNet: Dynamic context perception multi-view stereo with transformers and data augmentation. <em>KBS</em>, <em>325</em>, 113852. (<a href='https://doi.org/10.1016/j.knosys.2025.113852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Stereo (MVS) technology focuses on recovering three-dimensional structures from images taken at multiple angles. Although advances in deep learning have led to numerous learning-based Multi-view Stereo studies with great success, existing methods still need to flexibly and efficiently match practical features when reconstructing for weak textures, thin objects, and more complex scenes. Therefore, we propose DPA-MVSNet: a dynamic context perception adaptive Multi-view Stereo method. The method dynamically and efficiently filters and refines feature information from coarse layers and integrates relevant features among multi-view images by introducing a Dynamic Context Perception (DCP) module. We use an adaptive Gauss–Newton (AGN) module to refine the depth map, making it smoother. We have also introduced specific data augmentation strategies to enable the model to learn a broader range of data features and enhance its performance under various conditions. These strategies ensure the model remains efficient and accurate even under challenging conditions. All modules of DPA-MVSNet are lightweight, which allows our method not to take up too much memory and add too much runtime. Experiments show that our approach improves performance over current state-of-the-art methods by 13.4% accuracy on the DTU dataset, 6.3% and 6.6% on the Tanks and Temples intermediate and advanced datasets, and 2.8% and 1.2% on the ETH3D training and test datasets, respectively.},
  archive      = {J_KBS},
  author       = {Jianjun Ji and Biao Han and Xinlei Liu and Xuebin Xu and Alimjan Aysa and Kurban Ubul},
  doi          = {10.1016/j.knosys.2025.113852},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113852},
  shortjournal = {Knowl. Based Syst.},
  title        = {DPA-MVSNet: Dynamic context perception multi-view stereo with transformers and data augmentation},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ELAFormer: Early local attention in multi-scale vision transFormers. <em>KBS</em>, <em>325</em>, 113851. (<a href='https://doi.org/10.1016/j.knosys.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers have demonstrated remarkable success in vision tasks and have shown great potential when compared to CNN-based models. However, Transformers tend to prioritize the global context and overlook the local features between patches. Recent studies suggest that initializing the relative position between query and key tokens can limit attention distance, allowing for effective attention to local features without using convolutional blocks, similar to convolutional kernels. Based on this insight, this paper proposes a new hybrid multi-scale model called E fficient L ocal A ttention trans F ormer (ELAFormer). In this model, we propose a Window-based Positional Self-Attention (WPSA) module that focuses on adjacent tokens for short-distance features when querying the key token. Furthermore, we improve the conventional Spatial Reduction Attention (SRA) module by employing Depth-wise Separable (DS) convolution instead of standard down-sampling convolution(DSSRA) for long-distance contexts. By stacking these two modules, extensive experiments demonstrate that our model, with a small size of only 28M, achieves 82.9% accuracy on ImageNet classification with an input size of 224 × 224. Our model outperforms state-of-the-art Transformer models. The small ELAFormer model surpasses the tiny focal transformer by +1.3% mAP with RetinaNet 1x on COCO and +1.8/+2.0% mIoU/MS mIouU with UperNet on ADE20k, serving as a strong backbone for the most challenging computer vision tasks.},
  archive      = {J_KBS},
  author       = {Xin Zhou and Zhaohui Ren and Yongchao Zhang and Zeyu Jiang and Tianzhuang Yu and Hengfa Luo and Shihua Zhou},
  doi          = {10.1016/j.knosys.2025.113851},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113851},
  shortjournal = {Knowl. Based Syst.},
  title        = {ELAFormer: Early local attention in multi-scale vision transFormers},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTIU: A self-supervised grid-enhanced diffusion model for trajectory imputation in unconstrained scenarios. <em>KBS</em>, <em>325</em>, 113848. (<a href='https://doi.org/10.1016/j.knosys.2025.113848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the widespread of location-based services has led to a proliferation of trajectory data, it is often accompanied by the inevitable problem of incomplete data due to various reasons, e.g., sensor failure and privacy concerns. Imputing the incomplete trajectory is critically important to a range of practical applications, e.g., traffic management and emergency response. Most recent proposals on trajectory imputation are designed for the urban scenario where a road network is available, which may not work well in the unconstrained environment scenario. As there are no road networks or predefined paths in the unconstrained environment, existing approaches for trajectory imputation may result in insufficient input data and thus lead to sub-optimal performance. To address this issue, we propose a self-supervised grid-enhanced D iffusion model for T rajectory I mputation in U nconstrained scenarios (DTIU). DTIU includes a diffusion model specifically designed for trajectory imputation tasks. DTIU avoids the problem of insufficient input by using trajectory data as the only input. To contend with missing position information and effectively learn the spatio-temporal correlations, we design a GridFormer based on AutoEncoder with an adaptive grid information enhancement strategy. DTIU adopts a self-supervised training strategy inspired by masked language models, aiming at address the data sparsity issue. Extensive experiments on real data offer insight into the effectiveness of the proposed framework. This marks the first application of diffusion models to tackle trajectory imputation in unconstrained scenarios.},
  archive      = {J_KBS},
  author       = {Zhijing Hu and Hao Yan and Kuihua Huang and Jincai Huang and Zhong Liu and Changjun Fan},
  doi          = {10.1016/j.knosys.2025.113848},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113848},
  shortjournal = {Knowl. Based Syst.},
  title        = {DTIU: A self-supervised grid-enhanced diffusion model for trajectory imputation in unconstrained scenarios},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified data-driven approach under deep reinforcement learning with direct control responses for microgrid operations. <em>KBS</em>, <em>325</em>, 113844. (<a href='https://doi.org/10.1016/j.knosys.2025.113844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrid systems have now seen many integrations with energy storage systems (ESS) and renewable energy sources (RES) to supply cleaner and cheaper energy. A pressing challenge is how to optimally meet the requirements ranging from reducing operational costs and carbon footprints to relieving the grid constraints, alongside the consideration of uncertainties in the supply and demand. To embark on this challenge, this paper proposes a deep reinforcement learning (DRL) approach with direct control responses to optimize multi-objective microgrid operations. First, a new objective function is derived to build a direct response between the control action and the optimization objectives, aiming to improve the learning efficiency. Second, a unified control scheme is designed to study the combined use of past observations and predicted data for microgrid controls. Third, a realistic microgrid model is created to incorporate battery charging and discharging processes with dynamic efficiency and nonlinear battery degradation. Finally, the effectiveness of the proposed approach is validated through various simulations conducted on a US case study, with an additional Norwegian microgrid presented in the supplementary material. The results suggest that the annual reward in the US microgrid can be improved by 139.33% over the baseline (vanilla DQN with a conventional scheme) under perfect predictions, and by 125.45% under noisy predictions.},
  archive      = {J_KBS},
  author       = {Fulong Yao and Wanqing Zhao and Matthew Forshaw and Wenju Zhou},
  doi          = {10.1016/j.knosys.2025.113844},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113844},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified data-driven approach under deep reinforcement learning with direct control responses for microgrid operations},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remaining useful life prediction based on a subdomain adaptation and contextual information compensation network. <em>KBS</em>, <em>325</em>, 113841. (<a href='https://doi.org/10.1016/j.knosys.2025.113841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, subdomain adaptation (SDA) has been widely used to predict the remaining useful life (RUL) of bearings under different working conditions. Although SDA-based methods have achieved accurate predictions, most are still facing challenges, such as fixed subdomain boundaries, the assumption of symmetric domain structures, and ignoring a time-weighted mechanism. These limitations hinder further improvements in prediction accuracy. To address these issues, a subdomain adaptation and contextual information compensation (SDA-CIC) network was proposed that dynamically and adaptively divided subdomains in each training epoch to achieve precise SDA. To validate its effectiveness, hyperparameter analysis, ablation experiments, comparison experiments, and generalization experiments were performed. Experimental results show that the proposed SDA-CIC outperforms the state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Zhiqing Xu and Yee Wei Law and Md Mizanur Rahman and Raufdeen Rameezdeen and Christopher W.K. Chow},
  doi          = {10.1016/j.knosys.2025.113841},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113841},
  shortjournal = {Knowl. Based Syst.},
  title        = {Remaining useful life prediction based on a subdomain adaptation and contextual information compensation network},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kernel-based composite control chart for nonlinear conditionally heteroscedastic time series. <em>KBS</em>, <em>325</em>, 113839. (<a href='https://doi.org/10.1016/j.knosys.2025.113839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel composite control chart that simultaneously estimates conditional volatility and monitors structural anomalies of time series in a single, unified framework. The composite control chart focuses on Phase II analysis of the statistical process control, and is constructed by combining ϵ -support vector regression with the least-squares one-class support vector machine to maximize flexibility and expandability. The control limit is determined by combining the representer theorem, the method of profiling, and the successive convex approximation algorithm, making the design of the composite chart highly modular and adaptable. Numerical analysis reveals that our scheme is highly stable against false alarms, effectively responds to various out-of-control conditions, and retains robust performance under extreme conditions, such as skewed, heavy-tailed time series or those contaminated with innovational outliers. Moreover, the analysis of US cocoa and gold futures financial indices demonstrates that the out-of-control detection ability remains effective even with insufficient training samples and when trained with bootstrap samples.},
  archive      = {J_KBS},
  author       = {Chang Kyeom Kim and Sangyeol Lee},
  doi          = {10.1016/j.knosys.2025.113839},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113839},
  shortjournal = {Knowl. Based Syst.},
  title        = {Kernel-based composite control chart for nonlinear conditionally heteroscedastic time series},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive and locally-guided artificial electric field algorithm for global optimization with aggregative learning. <em>KBS</em>, <em>325</em>, 113835. (<a href='https://doi.org/10.1016/j.knosys.2025.113835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial electric field algorithm (AEFA) is a physics-based metaheuristic where each individual learns from the elite group K b e s t , employing a fully-informed learning strategy with a global neighborhood topology. This approach often leads to premature convergence due to environmental homogeneity. In response, we propose the locally guided artificial electric field algorithm (L-AEFA), which introduces several enhancements. L-AEFA utilizes positional information from historical best, current worst, and other individuals to dynamically determine K b e s t , guiding movements more effectively. It strengthens the electrostatic force with newly constructed K n g h and K b e s t ′ individuals, enhancing exploration and exploitation. Additionally, L-AEFA incorporates a self-adaptive Coulomb’s constant based on individual success and failure history to improve aggregate learning. We also integrate a DE/current-to-pbest/1 mutation strategy to eliminate duplicate individuals. The effectiveness of these enhancements is assessed through an extensive exploration of exploration–exploitation dynamics and diversity alongside a structural study evaluating algorithmic behavior and efficiency. Evaluations on three real parameter benchmark sets (CEC 2017, CEC 2020, CEC 2022) across dimensions (5, 10, 15, 20, 30, 50, 100) demonstrate L-AEFA’s superior performance over seventeen state-of-the-art algorithms, including various AEFA variants, in terms of solution accuracy, convergence speed, and search capability. The source code of L-AEFA is available at https://github.com/ChauhanDikshit/L-AEFA .},
  archive      = {J_KBS},
  author       = {Dikshit Chauhan and Shivani},
  doi          = {10.1016/j.knosys.2025.113835},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113835},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-adaptive and locally-guided artificial electric field algorithm for global optimization with aggregative learning},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal speed and latency-aware task assignment in large-scale embedded system. <em>KBS</em>, <em>325</em>, 113834. (<a href='https://doi.org/10.1016/j.knosys.2025.113834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software deployment is a crucial step for ensuring system efficiency in embedded system design. However, finding an efficient deployment plan has become significantly challenging owing to the increasing size of embedded systems. To address this issue, we formulate the software deployment problem as a combinatorial optimization problem known as the speed- and latency-aware assignment problem (SLAAP). In general, the SLAAP aims to map tasks in the software to computational units in the system such that 1) the data transmission speed between two computational units is no less than the recommended speed in the software, and 2) the latency between any two computational units is no more than the recommended latency in the software. We prove that the problem is NP-hard even when the topological layout of the embedded system follows a simple star shape. Subsequently, we recast the problem into an integer linear programming (ILP) form, enabling it to be solved precisely using ILP solvers. We further develop a learning-based local search algorithm that learns the initial solutions from high-quality historical solutions and integrates the three moving operators to handle large instances. We conducted experiments in both artificial and real-world scenarios using the aerospace Telemetry, Tracking, and Control (TT&C) ground station. The empirical results show that ILP can solve small instances exactly, whereas the learning-based local search algorithm efficiently solves large instances with high precision. We also demonstrate that these algorithms provide high-quality solutions for TT&C services in ground systems.},
  archive      = {J_KBS},
  author       = {Liu Liu and Tian Liu and Jing Sun and Yan Zhang},
  doi          = {10.1016/j.knosys.2025.113834},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113834},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimal speed and latency-aware task assignment in large-scale embedded system},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing low-light image enhancement through deep learning: A comprehensive experimental study. <em>KBS</em>, <em>325</em>, 113827. (<a href='https://doi.org/10.1016/j.knosys.2025.113827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light photography severely degrades the perceptual quality of images, which adversely affects the performance of computer vision algorithms. Deep learning-based low-light image enhancement (LLIE) methods are dominating in improving the quality of degraded and corrupted images taken in non-optimal lighting conditions. Either the designed methods are evaluated on a limited set of test datasets or they are not evaluated for machine vision applications. A detailed examination of the recent developments, their generalization, and their application to computer vision tasks is required. This experimental review highlights the future trend of recent learning-based LLIE methods through statistical analysis, experimentally analyzing their generalization capability on a wide spectrum of test datasets, examining the effectiveness of LLIE in computer vision applications, and discussing a correlation between them. The test data used for the generality of these methods covers diversified scenes/contents as well as complex degradation in real scenarios. Rich variety of full-reference and no-reference metrics are applied to compare the relative performances. Furthermore, the application of enhancement methods in low-light face detection is also validated to examine the effectiveness of these LLIE methods as a preprocessing step in machine vision tasks. The discussion on correlation of experimental results from the perspective of both human and machine vision in the subsequent part provides broader view of the field. This systematic review concludes with the limitations of enhancement methodologies and unresolved issues.},
  archive      = {J_KBS},
  author       = {Muhammad Tahir Rasheed and Hufsa Khan and Junsong Wang and Yan Kang},
  doi          = {10.1016/j.knosys.2025.113827},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113827},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing low-light image enhancement through deep learning: A comprehensive experimental study},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scenario-based self-learning transfer framework for multi-task optimization problems. <em>KBS</em>, <em>325</em>, 113824. (<a href='https://doi.org/10.1016/j.knosys.2025.113824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-task optimization (EMTO), which tackles multi-task optimization problems (MTOPs) simultaneously, is gaining popularity. Yet, there are still two problems that have not been substantively addressed: (1) how to design the strategy to efficiently solve MTOPs in a variety of evolutionary scenarios; (2) how to automatically adjust the designed strategy when solving MTOPs with a variety of evolutionary scenarios. Herein, we find that learning the relationship mapping between the evolutionary scenario and the scenario-specific strategy plays a crucial role for the issues raised, and therefore propose a novel scenario-based self-learning transfer (SSLT) framework. In SSLT, for the first issue, we categorize the scenarios into four possible situations in the MTOP environment, thereby designing a set of corresponding scenario-specific strategies, and we also design an ensemble method to characterize the scenario in terms of intra-task and inter-task scenario features. For the second issue, SSLT adopts the deep Q-network as the relationship mapping model to learn the relationship mapping between the evolutionary scenario and the scenario-specific strategy. We conducted experiments to compare SSLT-based algorithms with state-of-the-art competitors on two sets of MTOPs and real-world interplanetary trajectory design missions. The experimental results confirm the favorable performance of the SSLT-based algorithms against competitors.},
  archive      = {J_KBS},
  author       = {Zhuoming Yuan and Guangming Dai and Lei Peng and Maocai Wang and Zhiming Song and Xiaoyu Chen},
  doi          = {10.1016/j.knosys.2025.113824},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113824},
  shortjournal = {Knowl. Based Syst.},
  title        = {Scenario-based self-learning transfer framework for multi-task optimization problems},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph convolution networks for botnet detection. <em>KBS</em>, <em>325</em>, 113802. (<a href='https://doi.org/10.1016/j.knosys.2025.113802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting botnets is a crucial task in preventing network attacks. However, existing detection techniques fail to effectively capture high-order attack patterns among multiple bots and ignore the class-imbalanced distribution between malicious and benign network flows, making current models vulnerable to detecting botnets with high-order interactions and class-imbalanced data. This motivates us to propose the BHGCN, a novel B otnet detection method leveraging h yper g raph c onvolution n etworks. Firstly, BHGCN employs hypergraphs to model the high-order interconnected associations among various bots. Secondly, BHGCN proposes a two-stage hypergraph convolution neural network to learn comprehensive features of bots from both intra-hyperedge and inter-hyperedge perspectives. Finally, BHGCN incorporates focal cross-entropy loss to mitigate the impact of imbalanced-class data distribution on detection performance. Experimental results validate the superior performance of BHGCN compared to current cutting-edge techniques, showcasing its inspiring detection accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Jing Li and Bingkun Zhao and Guofu Zhao and Jinghong Lan and Jun Zhao and Minglai Shao},
  doi          = {10.1016/j.knosys.2025.113802},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113802},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hypergraph convolution networks for botnet detection},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ES-MRE: Evidence subgraph enhanced reasoning for multimodal relation extraction. <em>KBS</em>, <em>325</em>, 113770. (<a href='https://doi.org/10.1016/j.knosys.2025.113770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of multimodal relation extraction is to identify the semantic relations between two named entities by analyzing linguistic sequences and associated images. However, existing approaches are frequently limited due to inadequate information, which is often attributable to the brevity and ambiguity of the texts. Moreover, these models are easily affected by irrelevant objects during inter-modal alignment, leading to a problem known as error sensitivity. In this paper, we propose the Evidence Subgraph Enhanced Reasoning for Multimodal Relation Extraction (ES-MRE) framework. Specifically, the MLLM-guided Evidence Subgraph Generation (MESG) module is introduced, which leverages the image understanding capabilities of Multimodal Large Language Models (MLLMs) to extract visual and textual entities from image descriptions and original texts. It retrieves the clue paths of different entities in existing Knowledge Graphs (KGs), generating an Evidence Subgraph to provide structural features of inter-entity factual knowledge for relation reasoning. Additionally, we introduce a Multi-image Hierarchical Fusion (MHF) module that treats the generated image as a back-translation of the text, hierarchically fine-grained aligned text and generated images as well as the original image to mitigate the impact of irrelevant objects. Experimental results using the most popular dataset demonstrate the effectiveness of our approach, and ablation studies further validate the contributions of the MESG and MHF modules.},
  archive      = {J_KBS},
  author       = {Wenti Huang and Jiayi Chen and Junjie Li and Yiyu Mao and Ningyi Mao},
  doi          = {10.1016/j.knosys.2025.113770},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113770},
  shortjournal = {Knowl. Based Syst.},
  title        = {ES-MRE: Evidence subgraph enhanced reasoning for multimodal relation extraction},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-gated diffusion policy: Advancing robotic behaviour learning with memory-oriented architectures. <em>KBS</em>, <em>325</em>, 113738. (<a href='https://doi.org/10.1016/j.knosys.2025.113738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning robot behaviour generation policies from human demonstrations represents an intuitive and efficient approach. Modelling this process as a supervised regression task can map observations to actions, substantially enhancing the robot’s task performance. However, the unique characteristics of predicting robotic actions — such as the presence of multi-modal distributions, sequential dependencies and the demand for high precision — distinguishes it from other supervised learning problems. Existing mainstream approaches, including transformer-based and diffusion-based policies, suffer notable challenges, particularly in handling multi-modal and long-horizon tasks. These policies lack dynamic modelling of the associations between past states and current observations, leading to the forgetting or confusion of crucial historical states relevant to current predicted actions, eventually resulting in task failures. To address these challenges, we propose a memory-gated diffusion policy (MDP) for behaviour generation. MDP leverages memory awareness to augment its own memory capability across temporal dimensions, establishing temporal dependencies between crucial historical states and current observations during the encoding stage. In the decoding stage, the policy filters and updates historical memory, ensuring that only the most relevant critical states are considered during each behaviour generation process. In addition, MDP introduces a de-coupling method for the learning and inference sampling process based on score-based diffusion models, allowing for fast sampling strategies that reduce the number of steps required to generate goal-specified behaviours. We conduct extensive experiments across simulated operations, robotic manipulation and real-world environments. The proposed MDP consistently outperforms mainstream models, such as behaviour transformers and diffusion-based policies, demonstrating its effectiveness in goal-conditioned behaviour generation.},
  archive      = {J_KBS},
  author       = {Xiao Huang and Jiwei Hu and Quan Liu and Guangpeng Zhao and Wupeng Deng and Weiling Liu},
  doi          = {10.1016/j.knosys.2025.113738},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113738},
  shortjournal = {Knowl. Based Syst.},
  title        = {Memory-gated diffusion policy: Advancing robotic behaviour learning with memory-oriented architectures},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A visual tracking algorithm based on context constraint and aberration suppression. <em>KBS</em>, <em>325</em>, 113658. (<a href='https://doi.org/10.1016/j.knosys.2025.113658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative Correlation Filter (DCF)-based trackers have achieved significant performances because of their efficient formulation and powerful feature configuration. However, existing approaches are prone to tracking failure when internal and external interference appear simultaneously. To address this issue, we advocate implicitly repressing potential aberrances and incorporating contextual information to enhance the discriminability of the learned filter. Specifically, we restrain potential aberrances by constraining the alteration rate of the response map, thereby suppressing impermanent appearance variations. Moreover, the surroundings of the tracked target are integrated directly into the DCF to further improve filter discriminability, expanding the search regions for more robust tracking. In addition, we demonstrate that the proposed CF model can be efficiently optimized using Alternating Direction Method of Multipliers (ADMM), ensuring that computational efficiency is maintained throughout. Furthermore, we address model degradation by training another CF as a local tracker, which maintains a long-term memory of the target appearance. Finally, the coordination mechanism based on historical responses and feedback to facilitate efficient interaction between them. Extensive experimental results demonstrate the effectiveness and robustness of the proposed tracker compared to other state-of-the-art trackers.},
  archive      = {J_KBS},
  author       = {Yinqiang Su and Lili Su and Fang Xu and Hui Zhao},
  doi          = {10.1016/j.knosys.2025.113658},
  journal      = {Knowledge-Based Systems},
  month        = {9},
  pages        = {113658},
  shortjournal = {Knowl. Based Syst.},
  title        = {A visual tracking algorithm based on context constraint and aberration suppression},
  volume       = {325},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised conversion method of high bit-depth remote sensing images using contrastive learning. <em>KBS</em>, <em>324</em>, 113954. (<a href='https://doi.org/10.1016/j.knosys.2025.113954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, remote sensing images are frequently stored in high bit-depth formats exceeding 10 bits. However, the standard 8-bit format remains the fundamental data format for visualization and deep learning applications. Traditional methods typically rely on manually adjusting the parameter threshold of the tone mapping operator to obtain 8-bit images, resulting in low automation. Although tone mapping methods based on deep learning have gradually supplanted traditional techniques, but such methods are mainly aimed at natural scene images taken by digital cameras. There are problems such as incompatibility between data format and image semantics, and it is difficult to meet the scale dependence of remote sensing image applications. To address these challenges, we propose an unsupervised bit-depth conversion method for remote sensing images that integrates generative adversarial networks with contrastive learning. We draw an analogy between gray value mapping and the motion of thermal field particles, constructing a transformer generator based on thermodynamic principles. Leveraging the analogous characteristics of high and low bit-depth image histograms, we introduce a histogram shape context contrastive loss to regulate the color distribution of the generated images. Furthermore, in light of the large-scale application characteristics of remote sensing images, we propose a post-processing method based on hybrid histogram matching to enhance image quality while generating seamless whole-scene images. We developed relevant datasets and conducted experiments, with results demonstrating that the proposed method achieves superior bit-depth conversion effects compared to existing methods. Code and data can be found at https://github.com/ZzzTD/Bit-depth_conversion .},
  archive      = {J_KBS},
  author       = {Tengda Zhang and Jiguang Dai and Jinsong Cheng},
  doi          = {10.1016/j.knosys.2025.113954},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113954},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unsupervised conversion method of high bit-depth remote sensing images using contrastive learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary-class concrete surface crack detection using a transfer learning model. <em>KBS</em>, <em>324</em>, 113953. (<a href='https://doi.org/10.1016/j.knosys.2025.113953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concrete structure’s cracks can occur as visible or hidden fractures due to various physical, chemical, or structural influences, serving as indicators of potential vulnerabilities. Previous crack detection methods face challenges such as limited robustness, insufficient labeled data, human error, overfitting, and inadequate feature extraction, highlighting the need for improved solutions. The research utilizes four state-of-the-art machine learning models—CNN, Transfer Learning with VGG16, ordinary Inception V3, and proposed Inception V3 —to enhance detection accuracy and reliability. A detailed performance comparison of an ordinary inception V3 model that comprises of flattening and proposed inception V3 model that comprises of global average pooling is carried out in this study. The proposed model achieves an impressive accuracy of 99.61 %, significantly outperforming traditional approaches. By offering a more accurate and reliable method for crack detection, the proposed Inception V3 model enhances the monitoring of structural integrity, contributing to improved safety, reduced maintenance costs, and extended lifespans of concrete infrastructures.},
  archive      = {J_KBS},
  author       = {R. Ritzy and Umadevi V․A․ and K. Girija and Rajeev Rajan},
  doi          = {10.1016/j.knosys.2025.113953},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113953},
  shortjournal = {Knowl. Based Syst.},
  title        = {Binary-class concrete surface crack detection using a transfer learning model},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for feature selection and dimensional analysis: Variational explainable neural networks. <em>KBS</em>, <em>324</em>, 113940. (<a href='https://doi.org/10.1016/j.knosys.2025.113940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the first steps in any data analysis and modelling activity. Choosing the wrong relevant quantities to investigate a given problem can compromise the inference process. The complexity of this task motivates efforts to harness the potential of deep learning to address it. Unfortunately, connectivist tools often struggle to converge on the correct variables. In this work, a new deep learning architecture with a variational layer is presented. The developed algorithms outperform traditional techniques, as shown by a series of numerical tests, covering the most used classes of models. The selection is not only more reliable but also more interpretable. The robustness against noise and the capability of handling sparse data have been investigated in detail. The proposed variational networks can be deployed to perform feature extraction as well and have a particular competitive advantage in applications to high dimensional data. A specific architecture has been developed for dimensional analysis, with the aim of identifying the most suitable dimensionless quantities to model the phenomena under study. The potential of the proposed techniques is confirmed by the analysis of various experimental databases, covering different branches of physics and engineering.},
  archive      = {J_KBS},
  author       = {Riccardo Rossi and Andrea Murari and Michela Gelfusa},
  doi          = {10.1016/j.knosys.2025.113940},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113940},
  shortjournal = {Knowl. Based Syst.},
  title        = {A deep learning framework for feature selection and dimensional analysis: Variational explainable neural networks},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WTC-iPST: A deep learning framework for short-term electric load forecasting with multi-scale feature extraction. <em>KBS</em>, <em>324</em>, 113907. (<a href='https://doi.org/10.1016/j.knosys.2025.113907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting is essential for efficient power system operation, but existing deep learning models struggle to capture the multi-scale features and cyclical fluctuations inherent in short-term load data. This paper introduces a novel deep learning model, Wavelet Transform Convolution-inverted ProbSparse Transformer (WTC-iPST), specifically designed for short-term load forecasting. Unlike existing deep learning models, WTC-iPST leverages Wavelet Transform Convolution (WTConv) for multi-scale feature extraction and integrates Wavelet Kolmogorov-Arnold Networks (Wav-KAN) to enhance the ProbSparse self-attention mechanism, significantly improving the model's ability to capture multi-scale features and cyclical fluctuations inherent in short-term load data. This design addresses the challenge of extracting multi-scale and cyclical features from short-term load data, which existing models struggle with, and strengthens the model's capacity to handle long series. Additionally, WTC-iPST incorporates quantile regression to quantify uncertainty and provide confidence intervals, further enhancing the prediction's reliability and accuracy. Experimental results on real-world datasets demonstrate that WTC-iPST outperforms state-of-the-art forecasting models, with significant improvements over the baseline iTransformer, achieving reductions of up to 16.84 % in RMSE, 18.09 % in MAPE, and 17.65 % in RRMSE, as well as an increase of up to 2.96 % in R². In terms of probabilistic prediction, WTC-iPST consistently maintains a narrow confidence interval with high interval coverage. Moreover, WTC-iPST shows strong performance across various prediction horizons and different distribution substations, highlighting its robustness and adaptability. These results confirm that WTC-iPST provides more accurate and reliable forecasts, making it a valuable tool for power system dispatch and operational planning.},
  archive      = {J_KBS},
  author       = {Yi Ji and Yongyuan Zhu and Siliang Lu and Lixia Yang and Alan Wee-Chung Liew},
  doi          = {10.1016/j.knosys.2025.113907},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113907},
  shortjournal = {Knowl. Based Syst.},
  title        = {WTC-iPST: A deep learning framework for short-term electric load forecasting with multi-scale feature extraction},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary learning of probabilistic logic programs. <em>KBS</em>, <em>324</em>, 113906. (<a href='https://doi.org/10.1016/j.knosys.2025.113906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a logic program that effectively describes input data has been a long-standing goal in Artificial Intelligence, particularly within the field of Inductive Logic Programming. Learning it is even more challenging when information is uncertain, due to the inherent complexity of probabilistic reasoning. In this paper, we propose an approach based on an evolutionary algorithm to learn probabilistic logic programs. Our empirical evaluation shows that the proposed method outperforms existing tools in terms of log-likelihood, AUCROC, and AUCPR, while also providing more compact and interpretable theories.},
  archive      = {J_KBS},
  author       = {Damiano Azzolini},
  doi          = {10.1016/j.knosys.2025.113906},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113906},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evolutionary learning of probabilistic logic programs},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Capturing latent evolution in dynamic graph: A dual-view architecture from spectral perspective. <em>KBS</em>, <em>324</em>, 113904. (<a href='https://doi.org/10.1016/j.knosys.2025.113904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real world, graphs are usually dynamic, this dynamic nature can effectively capture complex relationships and evolution processes. Therefore, dynamic graph learning has a wide range of applications in many fields, such as financial transaction risk assessment, social network analysis, traffic flow prediction, personalized recommendation, etc. Recent works on dynamic graph learning have explored solutions that combine graph neural networks with temporal encoding mechanisms to understand the temporal dependence of graph. However, these works still struggles to simultaneously capture continuous-time evolution and long-range relationships, fails to model explicit spatio-temporal dependencies. To tackle these challenges, our paper proposes a dual-view dynamic graph learning framework. The framework is based on the continuous evolution of node features and structures, combined with spectral graph convolution. It is named as DESP ( D ual-view E volution with S pectral P erspective), for link prediction. Specifically, we interleave ordinary differential equations and input processing steps to parameterize the continuous evolution of node features and eigenvalues of graph in spectral domain respectively. We also combine the self-attention mechanism and spectral graph convolution to learn the global relevance of the graph structure. Therefore, our method can explicitly model the spatio-temporal evolution and long-range dependencies in dynamic graphs. Compared with the existing advanced dynamic graph learning methods, experiments across eight real-world dynamic graph datasets verify DESP’s superior performance on link prediction task. On average, DESP achieved an improvement of 4.69% in terms of the Area Under the Receiver Operating Characteristic Curve (AUC). Our code is available at this repository: https://github.com/oahin88/DESP.},
  archive      = {J_KBS},
  author       = {Qianqian Chen and Jintang Li and Liang Chen},
  doi          = {10.1016/j.knosys.2025.113904},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113904},
  shortjournal = {Knowl. Based Syst.},
  title        = {Capturing latent evolution in dynamic graph: A dual-view architecture from spectral perspective},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CIDNet: Cross-scale interference mining detection network for underwater object detection. <em>KBS</em>, <em>324</em>, 113902. (<a href='https://doi.org/10.1016/j.knosys.2025.113902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection plays a crucial role in advancing marine economics, protecting the environment, and promoting the planet’s sustainable development. Compared to land-based scenes, underwater object detection is often hindered by color deviation and low visibility. To effectively address these interference issues, we propose a Cross-Scale Interference Mining Detection Network (CIDNet). We first extract multidimensional feature representations from the input images using a standard residual network backbone, which uses a deep structure and residual connectivity mechanism. We then refine these features through interference mining and cross-scale feature fusion strategies, and further enhance feature hierarchy levels using adaptive feature mapping optimization. In addition, we introduce three-dimensional convolution combination with a channel dimension unification strategy to enhance the fine-grained representation of hierarchical feature layers. Finally, the refined features are fed into a Task-aligned detection head module, which improves the detection accuracy by optimizing a collaboration between classification and localization tasks through a task-aligned learning strategy. Extensive experiments conducted on the DUO and COCO datasets demonstrate that our method effectively detects hidden objects in realistic underwater scenes and significantly outperforms current state-of-the-art methods in terms of accuracy. The codes and model weights will be available at https://www.researchgate.net/publication/390270613_CIDNet .},
  archive      = {J_KBS},
  author       = {Gaoli Zhao and Kefei Zhang and Liangzhi Wang and Wenyi Zhao and Weidong Zhang},
  doi          = {10.1016/j.knosys.2025.113902},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113902},
  shortjournal = {Knowl. Based Syst.},
  title        = {CIDNet: Cross-scale interference mining detection network for underwater object detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and control of manufacturing service collaboration networks failure under intentional attacks. <em>KBS</em>, <em>324</em>, 113900. (<a href='https://doi.org/10.1016/j.knosys.2025.113900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing service collaboration networks (MSCNs) are networked systems that connect distributed manufacturing resources and services in a virtualized and digital manner, forming a highly collaborative network. However, the openness and inherent uncertainties make MSCNs highly susceptible to both random and intentional attacks. Intentional attacks represent a substantial threat due to their targeted nature, causing severe damage to key nodes and rapidly triggering cascading failures that may result in network paralysis and considerable economic losses. Most existing research focuses on failure analysis and control of complex networks under intentional attacks in a specific domain, which makes the technical reference to MSCNs challenging. Therefore, this paper proposes a failure analysis model and a control approach based on complex network theory, specifically aimed at analyzing and controlling the cascading failure phenomenon of MSCNs under intentional attacks. First, a model for cascading failure propagation and impact assessment in MSCNs is established based on collaborative dependence relationships that capture the dynamics of failure spread during intentional attacks. Subsequently, a failure control method for intentional attacks is proposed, focusing on pre-failure key node identification and post-failure dynamic load distribution. Finally, the methodology is validated through case studies of automotive assembly collaboration networks, emphasizing its performance assessment under intentional attack scenarios. Experimental results demonstrate that the method significantly increases the accuracy of the key node identification and improves network resilience.},
  archive      = {J_KBS},
  author       = {Feng Xiang and Zhuo Fang and Yongping Zhang and Fei Tao},
  doi          = {10.1016/j.knosys.2025.113900},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113900},
  shortjournal = {Knowl. Based Syst.},
  title        = {Analysis and control of manufacturing service collaboration networks failure under intentional attacks},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From words to visuals: Bridging text and visual insights using MetA-MARC framework for enhanced scholarly article categorization. <em>KBS</em>, <em>324</em>, 113896. (<a href='https://doi.org/10.1016/j.knosys.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of technology has led to approximately 28,100 journals disseminating 2.5 million research articles annually, posing significant challenges in locating and categorizing articles of interest. Search engines, citation indexes, and digital libraries often return predominantly irrelevant papers due to limited indexing. Existing classification techniques leveraging content and metadata face challenges such as incomplete data and lack of semantic context. Metadata-based methods frequently rely on statistical metrics that neglect semantic meanings and require subject expertise for threshold setting. To address these issues, we propose Metadata-Driven Attention-Based Multimodal Academic Research Classifier (MetA-MARC) , a framework leveraging the pretrained CLIP model to integrate text and image modalities for enhanced scholarly article classification. MetA-MARC captures semantic and contextual meaning by integrating metadata, OCR-extracted features, and images through CLIP (Contrastive Language-Image Pre-training). It introduces a novel textual inversion approach to map images to pseudo-word tokens in the CLIP embedding space for robust multimodal representations. The framework employs FusionWeave , a multimodal fusion network combining features using concatenation, cross fusion, and attention-based techniques, alongside Modality-Driven Adaptive Re-weighting (MoDAR) to dynamically prioritize relevant features. Experiments on JUCS, ACM, and proprietary CompScholar datasets demonstrate average accuracies of 0.86, 0.84, and 0.8848, respectively, surpassing state-of-the-art methods by up to 4.05%. These results highlight MetA-MARC’s potential as a robust, adaptive tool for automated scholarly article classification, effectively bridging text and visual modalities.},
  archive      = {J_KBS},
  author       = {Abhijit Mitra and Jayanta Paul and Tanis Ahamed and Sagar Basak and Jaya Sil},
  doi          = {10.1016/j.knosys.2025.113896},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113896},
  shortjournal = {Knowl. Based Syst.},
  title        = {From words to visuals: Bridging text and visual insights using MetA-MARC framework for enhanced scholarly article categorization},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A structure-feature dynamic decoupling GNN architecture for link prediction. <em>KBS</em>, <em>324</em>, 113883. (<a href='https://doi.org/10.1016/j.knosys.2025.113883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction aims to forecast the missing links within a graph, which is widely applied in various fields such as recommender systems and drug analysis. Graph Neural Networks (GNNs) have emerged as strong baselines for link prediction due to their ability to simultaneously capture the topological structure and node features of graphs. Moreover, existing approaches use the node features as the initial embedding of nodes and input them into GNNs for message passing and updating. However, these methods assume that the features and topology in graphs are homophonic and do not take into account the possible incompatibility that is common and even very severe in some graphs, harming the performance of GNNs in link prediction. To address this issue, we propose a Structure-Feature Dynamic Decoupling GNN architecture (SFDDGNN), which mainly consists of two decoupled embedding pipelines and the dynamic gate fusion mechanism. Specifically, to avoid the incompatibility, we first utilize a GraphSAGE-based structure encoder to capture the topological structure in one pipeline. Then we construct a graph contrastive learning module to train the node feature embedding in the other pipeline. Finally, we dynamically aggregate the topology and features embedding based on the graph data distribution knowledge. Experimental results on three real-world datasets of link prediction demonstrate that SFDDGNN outperforms the state-of-the-art baselines by up to 3.54% and 6.55% in terms of AP and AUC, respectively.},
  archive      = {J_KBS},
  author       = {Guowang Li and Zhiqiang Pan and Fei Cai and Weijie Chen and Langgao Cheng},
  doi          = {10.1016/j.knosys.2025.113883},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113883},
  shortjournal = {Knowl. Based Syst.},
  title        = {A structure-feature dynamic decoupling GNN architecture for link prediction},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Black-box domain adaptation for cross-domain on-device machinery fault diagnosis via hierarchical debiased self-supervised learning. <em>KBS</em>, <em>324</em>, 113882. (<a href='https://doi.org/10.1016/j.knosys.2025.113882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores black-box domain adaptation (BBDA) for cross-domain on-device machinery fault diagnosis. Specifically, a pre-trained black-box source model is deployed on a cloud platform with only its input-output API accessible, and a randomly initialized target model is trained locally utilizing unlabeled target data on an edge device. In BBDA, neither raw data nor model parameters are transmitted across domains, and the only available supervised information for adaptation is API-queried predictions on unlabeled target data. However, API-queried predictions are inevitably noisy and class-imbalanced due to cross-domain distribution discrepancy and inherent category bias. Directly utilizing them for on-device training easily leads to confirmation bias and exacerbates category bias, thereby severely degrading performance. This paper proposes a hierarchical debiased self-supervised learning framework for BBDA from a novel research perspective of concurrently alleviating both confirmation and category biases. Specifically, debiased knowledge distillation is proposed to gradually enhance discriminability of the randomly initialized target model by providing debiased training predictions. An adaptive category-unbiased sample division strategy is devised to divide unlabeled target data into certain-aware and uncertain-aware sets, enabling fully exploiting intrinsic data structures and utilizing underlying sample relationships within the target domain. On this basis, debiased prototypical self-training is proposed for the certain-aware set to obtain reliable pseudo-labels for self-training, leveraging global semantic structure. Hierarchical neighborhood adaptation is customized for the uncertain-aware set to enforce the cluster assumption for noise refinement, exploiting local clustering structure and utilizing underlying sample relationships. Extensive experiments and analyses on public and practical datasets validate the proposed framework’s superiority in cross-domain generalization performance and practicality in on-device training efficiency.},
  archive      = {J_KBS},
  author       = {Mengliang Zhu and Jie Liu and Yanglong Lu and Zhongxu Hu and Li Yuan and Kaibo Zhou},
  doi          = {10.1016/j.knosys.2025.113882},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113882},
  shortjournal = {Knowl. Based Syst.},
  title        = {Black-box domain adaptation for cross-domain on-device machinery fault diagnosis via hierarchical debiased self-supervised learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abductive learning-guided uncertainty modeling for time series anomaly detection. <em>KBS</em>, <em>324</em>, 113878. (<a href='https://doi.org/10.1016/j.knosys.2025.113878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is essential for enhancing the reliability of complex equipment. With the continuous advancements in digitalization, digital twin technology has emerged as a promising approach for addressing this challenge. Nevertheless, as production processes are dynamically optimized or equipment undergoes adjustments, the behavior of digital twin systems evolves correspondingly. This evolution introduces inherent uncertainties into the time-series data, thereby compromising the effectiveness and accuracy of conventional anomaly detection methods. To address this challenge, this research proposes a knowledge-driven uncertainty-modeling framework for time-series anomaly detection. The framework utilizes both numerical time-series data and textual domain knowledge, integrating them into a unified symbolic representation space. Specifically, the proposed framework involves two key steps: (1) discretizing the continuous time-series data into symbolic sequences and (2) employing a logical reasoning agent to transform domain-specific textual rules into anomalous symbols, thereby constructing a symbolic anomaly library. Subsequently, the anomalous symbols are applied as a sliding window to the symbolized time series data, locating anomalous segments and producing labelled data. For the noise and periodicity inherent in time-series data, the framework employs Gaussian processes (GP) augmented with Fourier transforms to effectively capture stochastic noise and recurring patterns. Finally, a TimesNet network enhanced with Gaussian processes is trained for supervised anomaly detection. Comprehensive experimental evaluations demonstrate the superiority of the proposed approach. Compared to the baseline TimesNet model, the framework achieves an 8.4% improvement in F1-score and a 10.36% increase in recall, showcasing its effectiveness in enhancing anomaly detection performance under uncertain and dynamic conditions.},
  archive      = {J_KBS},
  author       = {Qi Zhang and Mingrui Zhu and Jie Li and Jinsong Bao and Dan Zhang and Lei Chen},
  doi          = {10.1016/j.knosys.2025.113878},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113878},
  shortjournal = {Knowl. Based Syst.},
  title        = {Abductive learning-guided uncertainty modeling for time series anomaly detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WCMamba: Enhancing high-resolution remote sensing image semantic segmentation with pyramid wavelet convolution and SS2D. <em>KBS</em>, <em>324</em>, 113877. (<a href='https://doi.org/10.1016/j.knosys.2025.113877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the spatial resolution of remote sensing images (RSIs) increases, the amount of information contained within these images also expands significantly. Currently, the semantic segmentation of high-resolution remote sensing images (HRSIs) faces several challenges, including complex backgrounds, indistinct object edges, and significant scale variations. Mainstream approaches typically employ implicit attention mechanisms or Transformers to model global dependencies for enhanced semantic segmentation performance. However, these methods often suffer from high computational complexity, making them inefficient in processing HRSIs. In this paper, we propose an effective semantic segmentation model named WCMamba, which is based on an encoder–decoder framework. Specifically, we design the pyramid wavelet convolutional Mamba module (PWCMamba), which comprises the pyramid wavelet convolutional attention residual block (PWCARB) and the enhanced attention visual state space block (EA-VSSBlock). The PWCARB enhances segmentation accuracy by improving the receptive field, extracting multi-scale features, and preserving fine details. Meanwhile, the EA-VSSBlock integrates a 2D-selective-scan (SS2D) mechanism to enhance global perception while concurrently reducing computational complexity. To address the issue of blurred target edges, we have developed the edge detection module (EDM) and incorporated both edge loss and intersection over union (IoU) loss to strengthen edge perception and improve regional consistency. Additionally, we implement a strategy that combines main and auxiliary loss functions to optimize the training process, further enhancing the model’s segmentation performance. Extensive experiments on benchmark datasets (Potsdam and Vaihingen) demonstrate that WCMamba achieves state-of-the-art (SOTA) segmentation performance while retaining moderate computational costs. The code will be made available at https://github.com/one-boy-zc/WCMamba .},
  archive      = {J_KBS},
  author       = {Chao Zhan and Kui Yang},
  doi          = {10.1016/j.knosys.2025.113877},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113877},
  shortjournal = {Knowl. Based Syst.},
  title        = {WCMamba: Enhancing high-resolution remote sensing image semantic segmentation with pyramid wavelet convolution and SS2D},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving audio embeddings with squeeze-and-excitation: Introducing SaEENet. <em>KBS</em>, <em>324</em>, 113875. (<a href='https://doi.org/10.1016/j.knosys.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SaEENet, a novel neural network architecture to generate richer embeddings based on those generated by a pre-trained WavLM-large model and a set of convolutional layers fed by MFCCs. We employ 1D depthwise separable convolutions and GRU layers, and, to the best of our knowledge, we introduce for the first time the use of squeeze-and-excitation (SE) blocks for audio embedding weighting. The use of SE allows the model to assign a higher or lower relevance to each embedding generated from small audio segments and thus discard information generated from voiceless segments or segments with non-relevant information. In addition, we evaluated three different approaches for SE blocks to determine the most useful for the selected tasks. SaEENet outperforms similar models, such as the MEWHEV model, in the language identification, accent identification, and speaker identification tasks, achieving an improvement of 0.9%, 1.41%, and 4.01%, respectively, using 31.73% fewer trainable parameters. The results presented show that individual embeddings have varying effects on performance and that the integration of weighting mechanisms in SaEENet enhances accuracy in several speech classification tasks, highlighting the value of this approach for future applications.},
  archive      = {J_KBS},
  author       = {Andrés Carofilis and Laura Fernández-Robles and Enrique Alegre and Eduardo Fidalgo},
  doi          = {10.1016/j.knosys.2025.113875},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113875},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving audio embeddings with squeeze-and-excitation: Introducing SaEENet},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalizing flow-enhanced gaussian embedding for few-shot knowledge graph completion. <em>KBS</em>, <em>324</em>, 113874. (<a href='https://doi.org/10.1016/j.knosys.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: Few-shot knowledge graph completion (FKGC) aims to infer missing facts of the query triples based on few-shot reference entity pairs. However, existing FKGC approaches often overlook the inherent uncertainty of relations in KGs, as deterministic semantic representations derived from sparse samples may be unreliable. Meanwhile, they neglect both noisy neighbor aggregation and inter-neighbor interactions, as well as the handling of complex relations, which largely limits model performance. This paper aims to overcome these limitations and enhance FKGC performance. Methods: This paper proposes a method incorporated normalizing flow with Gaussian Network for FKGC, namely NFGN. Specifically, we combine normalizing flow-enhanced Gaussian distribution to model the few-shot settings and multi-semantics uncertainty of relations, which learns the uncertain semantics of entity features based on limited data. Then, we introduce the GD-TransE decoder, which incorporates relation uncertainty to handle complex relations. To improve the model’s effectiveness, a gated neighbor encoder is designed to model semantic interactions among neighbors, and control the activation of noisy neighbors through gating thresholds. Novelty: This paper presents the first study that integrates normalizing flows with Gaussian embeddings for FKGC, offering a more robust representation of uncertainty in relations. The proposed method further introduces the gated neighbor encoder and GD-TransE decoder to handle neighborhood noise and complex relationships, thereby overcoming the limitations of existing FKGC methods. Findings: Extensive experiments conducted on three diverse benchmark datasets demonstrate that our method significantly outperforms state-of-the-art performance, achieving improvements of 5.7%, 2.4%, 10.6%, and 6.7% in MRR, Hits@1, Hits@5, and Hits@10, respectively.},
  archive      = {J_KBS},
  author       = {Xu Yuan and Long Chen and Jiaqiang Wang and Yi Guo and Zhengnan Gao and Liang Zhao},
  doi          = {10.1016/j.knosys.2025.113874},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113874},
  shortjournal = {Knowl. Based Syst.},
  title        = {Normalizing flow-enhanced gaussian embedding for few-shot knowledge graph completion},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-privacy-accuracy trade-offs in federated learning for non-IID data with shuffle model. <em>KBS</em>, <em>324</em>, 113872. (<a href='https://doi.org/10.1016/j.knosys.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a novel decentralized machine learning approach that enables multiple edge devices to jointly train models while retaining data locally, thus preserving user privacy. However, several challenges remain in applying FL from theoretical research to practical scenarios, such as high communication overhead and potential privacy leakage of user data. Furthermore, the heterogeneity of data across clients intensifies these issues. Therefore, we propose an enhanced communication-efficient and privacy-preserving FL scheme (ECPFL) which can effectively optimize communication efficiency, strengthen data privacy protection, and mitigate the impact of data heterogeneity. Specifically, inspired by contrastive learning, we design a novel regularization mechanism tailored for local training, which effectively alleviates the adverse effects of data heterogeneity on model performance. Simultaneously, we propose a bidirectional top- k technique to simultaneously reduce uplink and downlink communication overhead. Moreover, we propose a package shuffling mechanism aimed at alleviating the issue of privacy budget explosion in differential privacy and combine it with the subsampling theorem to achieve a double privacy amplification. Finally, we provide a theoretical analysis that confirms the privacy amplification ability of our ECPFL. Furthermore, experimental results show that our method consistently achieves superior performance over several state-of-the-art baselines. In particular, under non-IID data distributions, our approach gains an average accuracy improvement of 3% over FedAvg, with improvements ranging from 5% to 14% in scenarios with high data heterogeneity. Furthermore, our approach also results in a reduction in communication costs exceeding 90%.},
  archive      = {J_KBS},
  author       = {Xiao Di and Xinchun Fan and Lvjun Chen and Min Li and Maolan Zhang},
  doi          = {10.1016/j.knosys.2025.113872},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113872},
  shortjournal = {Knowl. Based Syst.},
  title        = {Communication-privacy-accuracy trade-offs in federated learning for non-IID data with shuffle model},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSMMIL: Multi-scan mamba-based multiple instance learning for whole slide image classification. <em>KBS</em>, <em>324</em>, 113871. (<a href='https://doi.org/10.1016/j.knosys.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple instance learning has emerged as the primary technique in computational pathology for analyzing whole slide images (WSI). It typically emphasizes the most distinguishing instances using an attention mechanism. Despite significant progress, WSI classification still faces challenges, particularly in efficiently extracting discriminative features from long instance sequences that often contain a large amount of redundant or irrelevant information. To address this issue, this study introduces a new approach, named Multi-scan Mamba-based MIL (MSMMIL). The proposed framework introduces a Multi-scan Mamba module, which includes two novel complementary scanning strategies, grid scan and layer scan, an existing original scanning strategy, and three global context attention (GCA) blocks. The three scanning strategies to jointly model directional dependencies, restore structural continuity, and preserve spatial consistency, enabling more effective extraction of discriminative features from long instance sequences. While the lightweight GCA block is devised to learn the feature associations between different instances and amplify the key instances. Experimental results on two publicly available datasets, TCGA-Lung and Camelyon16, show that MSMMIL achieves state-of-the-art performance by ACC and AUC, reaching 89.81%, 95.44% and 92.87%, 96.41%, respectively. The code will be made publicly available on https://github.com/cool-breeze-and-rain/MSMMIL .},
  archive      = {J_KBS},
  author       = {Haiqin Zhong and Meidan Ding and Cheng Zhao and Yongtao Zhang and Tianfu Wang and Baiying Lei},
  doi          = {10.1016/j.knosys.2025.113871},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113871},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSMMIL: Multi-scan mamba-based multiple instance learning for whole slide image classification},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold-aware and sparsity discriminant collaborative representation model and its application to multimode process monitoring. <em>KBS</em>, <em>324</em>, 113869. (<a href='https://doi.org/10.1016/j.knosys.2025.113869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial processes are generally characterized by multiple operating modes from several factors, such as changes in market demand or raw material fluctuations, which pose challenges to traditional process monitoring. Existing multimode process monitoring primarily learns the distinct characteristics in each mode without collaboratively capturing the connections encapsulated across different modes. In this study, a novel multimode process monitoring approach, called the manifold-aware and sparsity discriminant collaborative representation model is proposed, which effectively captures the collaborative representation between and among modes, providing deeper insights into multimodal processes. The between-mode and within-mode affinity matrices were designed by considering the local information of the data to characterize the correlation between modes and the uniqueness of each mode, respectively. To faithfully reveal the characteristics of multimodal processes, a shared representation matrix was constructed to learn the common information among the different modes. Furthermore, the L 1 / 2 norm was imposed on the projection matrix, enabling the proposed approach effective in selecting the key variables for monitoring tasks. On the basis of these distinct model characterizations, the proposed approach is powerful in learning informative representations of data, further enhances the process monitoring capability. In addition, contrastive clustering was introduced to divide the historical modes and identify the running-on modes of the new samples, thereby reducing the online identification time. The monitoring results for both the Tennessee Eastman process and three-phase flow facility demonstrate the effectiveness of the proposed approach, in which fault detection rate was improved by 6 %-26 % in most cases.},
  archive      = {J_KBS},
  author       = {Yuanjian Fu and Fubing Xia and Jinliang Ding and Xue Xu},
  doi          = {10.1016/j.knosys.2025.113869},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113869},
  shortjournal = {Knowl. Based Syst.},
  title        = {Manifold-aware and sparsity discriminant collaborative representation model and its application to multimode process monitoring},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Foundation model-assisted interpretable vehicle behavior decision making. <em>KBS</em>, <em>324</em>, 113868. (<a href='https://doi.org/10.1016/j.knosys.2025.113868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent autonomous driving systems must achieve accurate perception and driving decisions to enhance their effectiveness and adoption. Currently, driving behavior decisions have achieved high performance thanks to deep learning technology. However, most existing approaches lack interpretability, reducing user trust and hindering widespread adoption. While some efforts focus on transparency through strategies like heat maps, cost-volume, and auxiliary tasks, they often provide limited model interpretation or require additional annotations. In this paper, we present a novel unified framework to tackle these issues by integrating ego-vehicle behavior decisions with human-centric language-based interpretation prediction from ego-view visual input. First, we propose a self-supervised class-agnostic object Segmentor module based on Segment Anything Model and 2-D light adapter strategy, to capture the overall surrounding cues without any extra segmentation mask labels. Second, the semantic extractor is adopted to generate the hierarchical semantic-level cues. Subsequently, a fusion module is designed to generate the refined global features by incorporating the class-agnostic object features and semantic-level features using a self-attention mechanism. Finally, vehicle behavior decisions and possible human-centric interpretations are jointly generated based on the global fusion context. The experimental results across various settings on the public datasets demonstrate the superiority and effectiveness of our proposed solution.},
  archive      = {J_KBS},
  author       = {Shiyu Meng and Yi Wang and Yawen Cui and Lap-Pui Chau},
  doi          = {10.1016/j.knosys.2025.113868},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113868},
  shortjournal = {Knowl. Based Syst.},
  title        = {Foundation model-assisted interpretable vehicle behavior decision making},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified cross-source context enhancement model for multi-source fake news detection. <em>KBS</em>, <em>324</em>, 113867. (<a href='https://doi.org/10.1016/j.knosys.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of misinformation across digital platforms poses a serious threat to public information integrity. While existing fake news detection methods have predominantly focused on single-source data, such approaches often fail to address the complexities introduced by multi-source information originating from diverse platforms. Detecting fake news in this multi-source context remains a relatively underexplored challenge. Traditional cross-domain methods typically transfer domain-invariant features using single-source modeling strategies, yet they neglect the rich contextual cues available across sources—an aspect critical for enhancing detection accuracy. To overcome these limitations, we propose a unified framework that effectively captures global contextual information by jointly leveraging intra-source and inter-source interactions. Our model integrates two principal components: (1) a cross-source global context learning module employing a context-augmented transformer to model long-range dependencies among multi-source instances, and (2) a dual-level contrastive learning mechanism that aligns representations at both local and global levels, reducing inconsistencies across feature spaces and source domains. Extensive experiments conducted on publicly available multi-source datasets demonstrate that our method achieves substantial improvements over existing state-of-the-art approaches. Specifically, it yields an approximate 5% gain in classification accuracy compared to leading models such as LIMFA, highlighting the robustness and effectiveness of our framework in advancing multi-source fake news detection.},
  archive      = {J_KBS},
  author       = {Ruiting Dai and Haoran Meng and Zhengdao Yuan and Lisi Mo and Wenwei Zhu and Tao He},
  doi          = {10.1016/j.knosys.2025.113867},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113867},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified cross-source context enhancement model for multi-source fake news detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-token aware graph convolution network with interpretability for long-term multi-station irrigation water level forecasting. <em>KBS</em>, <em>324</em>, 113857. (<a href='https://doi.org/10.1016/j.knosys.2025.113857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water level forecasting is crucial in watershed water resources management, particularly for extreme events such as floods and droughts. However, accurate long-term water level forecasting tasks are highly challenging due to the influence of non-stationary hydrological processes, complex feature variables, and noisy data. To address this issue, this paper proposes an interpretable dual-token aware graph convolutional network (DTAGCN) for long-term multi-station irrigation water level forecasting. As its name implies, the proposed model first embeds the collected multi-source data into temporal and variate tokens, then constructs an adaptive graph learning module to establish learnable adjacency matrices from both spatial and temporal perspectives to capture evolving spatial correlations and multi-scale long-term dependencies. Finally, adaptive expert fusion outputs are obtained by integrating cross-temporal and cross-variate learning representations. Taking Andi Irrigation District as the study object, five metrics (i.e., RMSE, MAE, CORR, NSE, and MAPE) are introduced for comprehensive evaluation against different levels of baseline models. DTAGCN achieves average improvements of 13.01 %, 6.02 %, 2.37 %, and 0.84 % in RMSE, MAE, CORR, and NSE, respectively, in multi-scale multi-station water level forecasting. Overall, the proposed model holds significant reference value for long-term water level forecasting in inland river basins and exhibits potential applications in strategic water conservation planning and extreme event prediction related to climate change.},
  archive      = {J_KBS},
  author       = {Rui Dai and Wanliang Wang and Jing Jie and Jiacheng Chen and Qianlin Ye and Zheng Wang},
  doi          = {10.1016/j.knosys.2025.113857},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113857},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-token aware graph convolution network with interpretability for long-term multi-station irrigation water level forecasting},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal representation fusion method for dense video captioning. <em>KBS</em>, <em>324</em>, 113856. (<a href='https://doi.org/10.1016/j.knosys.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense video captioning aims to locate multiple events from untrimmed videos and generate corresponding captions for each meaningful event. The application of multimodal information(e.g., video, audio) for dense video captioning has recently achieved great success. However, learning the information interactions between different modalities while achieving cross-modal feature alignment is highly challenging for an encoder. Recent studies of several multimodal tasks have shown that multimodal models benefit from shared and individual representations. Thus, in this paper, we propose a novel feature fusion module, which uses shared and individual modality representations to capture commonalities and complementary relationships between modalities. Moreover, the proposed model bridges the gap between shared modality representations, which helps to obtain deeper cross-modal associations for better feature interaction and alignment. Furthermore, to compensate for the limitation that different level proposal heads do not interact sufficiently during event detection, we propose a multilevel information interaction mechanism to dynamically adjust and fuse the information among different level proposal heads in the event detection module. Based on the ActivityNet Captions, subdatasets of ActivityNet Captions and YouCook2, we conducted comprehensive experiments to evaluate the performance of our proposed model. The experimental results show that our model achieves impressive performance compared with state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Haojie Fang and Yonggang Li and Yingjian Li},
  doi          = {10.1016/j.knosys.2025.113856},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113856},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal representation fusion method for dense video captioning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LungCT-NET: An explainable transfer learning-based robust ensemble model for lung cancer diagnosis. <em>KBS</em>, <em>324</em>, 113854. (<a href='https://doi.org/10.1016/j.knosys.2025.113854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer, one of the most prevalent and deadliest diseases, necessitates early detection for patient survival. The low level of contrast between lesions and adjacent lung tissue, coupled with the diverse shapes and structures of lung nodules, poses significant challenges for their accurate identification and classification. Despite the extensive use of machine learning methods, the lack of adequately annotated datasets significantly hampers efficient model training. Moreover, the lack of transparency in deep learning models has led to their perception as “black boxes”, constraining their credibility for end users like radiologists. To address these issues, we present LungCT-NET , a novel transfer learning-based architecture coupled with ensemble learning and explainable AI for binary classification of lung nodules into malignant and benign using lung CT scans. LungCT-NET incorporates essential preprocessing, reconfiguring transfer learning models, and an advanced stacking ensemble strategy utilizing combinations of the top-performing pre-trained models. Several transfer learning algorithms are employed, including VGG-16, VGG-19, MobileNet-V2, InceptionNet-V3, EfficientNet-B0, ResNet152-V2, and DenseNet-121. Extensive experimental analyses have been carried out on the LIDC-DIRI dataset using various performance metrics for evaluation. The findings demonstrate that the suggested framework significantly exceeds state-of-the-art approaches, achieving an accuracy, precision, F1 score and recall of 98.99%, an AUC of 98.15%. Finally, the integrated SHapley Additive exPlanations (SHAP) enhance the grasp of model outcomes, hence increasing confidence in lung cancer prognosis. Therefore, the proposed innovative LungCT-NET can potentially support clinical settings by automating lung nodule classification from low-dose CT scans, aiding physicians and radiologists in prompt, accurate diagnoses.},
  archive      = {J_KBS},
  author       = {MD Zuleyenine Ibne Noman and Kazi Sati and Mohammad Abu Yousuf and Saad Aloteibi and Mohammad Ali Moni},
  doi          = {10.1016/j.knosys.2025.113854},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113854},
  shortjournal = {Knowl. Based Syst.},
  title        = {LungCT-NET: An explainable transfer learning-based robust ensemble model for lung cancer diagnosis},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dictionary learning using novel multiscale context sensitive spectral features for classification of hyperspectral imagery. <em>KBS</em>, <em>324</em>, 113853. (<a href='https://doi.org/10.1016/j.knosys.2025.113853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse representation models for the classification of hyperspectral images have been greatly enhanced by dictionary learning techniques. The effectiveness of these techniques depends on the discriminative power of the patterns used to learn the dictionaries. In this research, to learn quality, discriminative and comprehensive dictionaries, we propose novel features extracted by exploiting singular value decomposition (SVD). Here, SVD is exploited to extract context-sensitive spectral features (CSSF) of the pixel by taking into account its appropriate spatial neighbor pixels. In the proposed technique, multiple CSSFs are extracted by considering spatial neighborhood of the pixel at different scales to learn dictionaries for classification. The effectiveness of the proposed technique is evaluated by comparing it with several state-of-the-art techniques.},
  archive      = {J_KBS},
  author       = {Amos Bortiew and Swarnajyoti Patra and Lorenzo Bruzzone},
  doi          = {10.1016/j.knosys.2025.113853},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113853},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dictionary learning using novel multiscale context sensitive spectral features for classification of hyperspectral imagery},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A key instance-guided frame-to-video information fusion network for thyroid ultrasound video instance segmentation. <em>KBS</em>, <em>324</em>, 113849. (<a href='https://doi.org/10.1016/j.knosys.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video instance segmentation (VIS) in thyroid ultrasound (US) images has the advantages of automatically segmenting nodules and assigning instance labels, which aids in counting nodules and determining the thyroid key plane. However, thyroid US videos are characterized by abundant background noise and echo similarity. Coupled with the continuous variations in the shape of tissue structures along the video stream, it becomes extremely challenging for current mainstream VIS methods to identify the temporal dynamic change features, limiting their performance in segmentation and tracking. To address this issue, this paper proposes a key instance-guided frame-to-video information fusion network (NoVIS) for thyroid US video instance segmentation. First, a frame-level instance information enhancement module is introduced to capture key instance information, constructing robust key instance features and enhancing similarity within the same instance. Second, a key instance-guided global information aggregation module is proposed. This module leverages key instance features to continuously update the global temporal information, aiming to capture the dynamic variation characteristics of structures along the video stream. Finally, a matching mechanism ensures consistency between training and inference, further improving tracking stability. Extensive experiments were conducted on a collected thyroid US video dataset, which demonstrated that NoVIS significantly outperforms other methods in both tracking and segmentation. Specifically, NoVIS achieves an AP of 58.09% and an AP 50 of 81.33%, which are 3.37% and 5.09% higher than those of the baseline method, respectively. Furthermore, the ability of the proposed method to determine the thyroid key plane and count nodules is demonstrated, which is highly valuable for fully automated thyroid clinical diagnosis.},
  archive      = {J_KBS},
  author       = {Guanyuan Chen and Ningbo Zhu and Bin Pu and Guanghua Tan and Hongxia Luo and Kenli Li},
  doi          = {10.1016/j.knosys.2025.113849},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113849},
  shortjournal = {Knowl. Based Syst.},
  title        = {A key instance-guided frame-to-video information fusion network for thyroid ultrasound video instance segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing recommendation via knowledge transfer contrastive in global path networks. <em>KBS</em>, <em>324</em>, 113847. (<a href='https://doi.org/10.1016/j.knosys.2025.113847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning shows significant potential in mitigating performance degradation in recommendation caused by data sparsity and knowledge graph (KG) noise. However, existing methods face two key limitations: (1) heuristic-based structural perturbations for generating contrastive views often overlook knowledge distribution differences between head and tail nodes, leading to the loss of local semantic features; (2) in sparse data scenarios, capturing higher-order semantic associations from global paths remains challenging. To address these issues, we propose a novel Knowledge Transfer Contrastive in Global Path Networks (KTCG). Unlike traditional knowledge transfer paradigms, KTCG employs an unsupervised relation aggregation approach to enhance tail node representations without additional training phases, producing high-quality contrastive views. We design a fine-grained knowledge aggregation mechanism to mine detailed semantic information and collaborative signals from contrastive samples and interactions. Simultaneously, we integrate augmented views with interaction data to construct a global collaborative KG and develop a global path graph neural networks (GNN) to explore complete graph topology. Finally, contrastive learning is applied across local semantic and global topological spaces to filter noise and generate robust knowledge-aware representations. Extensive experiments on three public datasets demonstrate that KTCG outperforms advanced models. Further analysis confirms KTCG’s advantages in representation uniformity and sparse robustness. The code for this study is publicly available at: https://github.com/use159/KTCG .},
  archive      = {J_KBS},
  author       = {Cheng Li and Yong Xu and Xin He and Yujun Zhu and Jinde Cao and Qun Fang},
  doi          = {10.1016/j.knosys.2025.113847},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113847},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing recommendation via knowledge transfer contrastive in global path networks},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAWformer: A cross variable attention with discrete wavelet denoising for multivariate time series forecasting. <em>KBS</em>, <em>324</em>, 113846. (<a href='https://doi.org/10.1016/j.knosys.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting plays an important role in finance, transportation, energy, and healthcare. However, existing Transformer-based models usually focus only on intra- or inter-series dependencies, which limits their ability to capture complex relationships among variables and dynamic patterns within a series, and thus limits their forecasting performance. To address this problem, we propose CAWformer , which achieves accurate prediction by capturing both inter- and intra-sequence features. First, to extract the within-sequence features, we perform multi-scale slicing of the time series and model the sequence fluctuation patterns using an autoregressive shift method, and then apply the autoregressive attention to the shifted data, which allows the model to efficiently identify the key relationships across the time steps and thus enhances its ability to capture the within-sequence features. In addition, to better capture complex relationships between variables, we compute cross-correlations in the frequency domain and use this information to measure interactions between features. This approach allows the model to accurately identify and exploit potential dependencies between variables. Inspired by the theory of decomposition of time series stochastic processes, we address the problem of random noise in residual signals. We decompose the residual terms into signals of different scales by means of the discrete wavelet transform (DWT), and then process the signals in such a way that the model is able to suppress random noise while preserving key details, thus reducing the risk of overfitting. Experiments on several real datasets show that CAWformer’s prediction accuracy is significantly better than existing state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Shiming Fan and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.knosys.2025.113846},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113846},
  shortjournal = {Knowl. Based Syst.},
  title        = {CAWformer: A cross variable attention with discrete wavelet denoising for multivariate time series forecasting},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph contrastive learning based on learnable view generators. <em>KBS</em>, <em>324</em>, 113845. (<a href='https://doi.org/10.1016/j.knosys.2025.113845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning aims to capture graphs’ evolving structure and properties by learning embedded representations of nodes and edges over time. Graph self-supervised learning, particularly graph contrastive learning, has garnered significant attention recently. However, existing dynamic graph contrastive learning methods are vulnerable to data distribution imbalances, leading to model overfitting on active nodes and edges, and they are also prone to capturing meaningless dynamic changes caused by random noise, which degrades the performance and robustness of the model. To alleviate these problems, this paper introduces a Learnable Dynamic Graph Contrastive (LDGC) framework based on a learnable view generator. LDGC combines the learnable graph view generator with an adaptive contrastive learning mechanism, effectively reducing time-related noise in dynamic networks and mitigating data distribution imbalances. First, LDGC constructs two augmented views by embedding the learnable view generator into automatic augmentation strategies, where each graph view generator is trained to produce a distribution of graphs based on the input conditions. Then, a more discriminative dynamic node representation is learned by incorporating both time and node activity information, maximizing the consistency between the node representations of two views during the contrastive learning process. Comprehensive experiments on benchmark datasets for dynamic link prediction validate the model’s effectiveness and demonstrate its superiority over current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Mingrui Zhu and Liqing Qiu and Weidong Zhao},
  doi          = {10.1016/j.knosys.2025.113845},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113845},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic graph contrastive learning based on learnable view generators},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TACSNet: Two-stage alignment cross-modal differential sensing network for concept prediction. <em>KBS</em>, <em>324</em>, 113842. (<a href='https://doi.org/10.1016/j.knosys.2025.113842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept prediction is a fundamental task in smart education, providing essential support for downstream tasks such as teaching assistance, cognitive diagnosis, recommending adaptive test questions, finding similar questions, and intelligent grouping of papers and other teaching services. While current methods primarily focus on math questions in plain text or LaTeX format, there is limited research on concept prediction for multimodal test questions, particularly when characterizing different subject image types. To address this gap, we propose a two-stage aligned cross-modal differential sensing network (TACSNet) for concept prediction. This network aims to effectively fuse images and text by utilizing their complementary information. Our approach begins with a dual-stream feature extraction network with a self-supervised task to encode textual and image features, enhancing image representation through jigsaw puzzle prediction. To address the inconsistency between images and text, we introduce a two-stage cross-modal alignment module. We then employ a differential awareness converged network module to fully integrate the text context and image representation. Finally, a classifier predicts the concepts in the multimodal test questions. Experiments across five datasets demonstrate (1) the effectiveness of our model in multimodal concept prediction and (2) the validity of its components, confirmed through ablation studies and comparative analysis.},
  archive      = {J_KBS},
  author       = {Yuxin Ji and Yongjun Li and Zeyuan Qu and Jiali Wei and Wenhui Sun},
  doi          = {10.1016/j.knosys.2025.113842},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113842},
  shortjournal = {Knowl. Based Syst.},
  title        = {TACSNet: Two-stage alignment cross-modal differential sensing network for concept prediction},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporal-semantic interaction network for multi-frame infrared small target detection. <em>KBS</em>, <em>324</em>, 113840. (<a href='https://doi.org/10.1016/j.knosys.2025.113840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection (IRSTD) remains a challenging task due to factors such as low signal-to-noise ratio, small target size, and frequent background variations. Traditional methods relying on single-frame or simple multi-frame fusion fail to fully model the temporal dynamics of infrared small targets, resulting in high miss or false detection rates. To better capture target motion across multiple frames, we propose a novel Temporal-Semantic Interaction Network (TSI-Net) for multi-frame infrared small target detection. Specifically, TSI-Net integrates an efficient Temporal Feature Extraction Module (TFEM), designed to capture the motion characteristics of targets in consecutive frames. To address the issue of insufficient feature interaction, we develop a Feature Interaction-Aware Module (FIAM), based on a multi-scale semantic interaction Transformer, which enables robust cross-level feature fusion. Furthermore, we propose a multi-task weighted hybrid loss function that balances classification accuracy, region alignment, and pixel-level boundary delineation, thereby further enhancing the overall performance of the network. Extensive experiments on three public datasets demonstrate that the proposed TSI-Net not only significantly improves detection precision for infrared small targets but also enhances robustness against dynamically changing backgrounds. Compared to existing methods, our approach achieves superior performance across various metrics, validating the effectiveness of the proposed TSI-Net. Our code is now available at https://github.com/penny1129/TSINet .},
  archive      = {J_KBS},
  author       = {Shuo Zhuang and Jing Peng and Meibin Qi and Di Wang and Kunyuan Li and Yimin Liu},
  doi          = {10.1016/j.knosys.2025.113840},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113840},
  shortjournal = {Knowl. Based Syst.},
  title        = {A temporal-semantic interaction network for multi-frame infrared small target detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal evidential fusion network for trustworthy PET/CT tumor segmentation. <em>KBS</em>, <em>324</em>, 113838. (<a href='https://doi.org/10.1016/j.knosys.2025.113838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate tumor segmentation in PET/CT images is crucial for computer-aided cancer diagnosis and treatment. The primary challenge lies in effectively integrating the complementary information from PET and CT images. In clinical settings, the quality of PET and CT images often varies significantly, leading to uncertainty in the modality information extracted by networks. To address this challenge, we propose a novel Multi-modal Evidential Fusion Network (MEFN), which consists of two core stages: Cross-Modal Feature Learning (CFL) and Multi-modal Trustworthy Fusion (MTF). The CFL stage aligns features across different modalities and learns more robust feature representations, thereby alleviating the negative effects of domain gap. The MTF stage utilizes mutual attention mechanisms and an uncertainty calibrator to fuse modality features based on modality uncertainty and then fuse the segmentation results under the guidance of Dempster–Shafer Theory. Besides, a new uncertainty perceptual loss is introduced to force the model focusing on uncertain features and hence improve its ability to extract trusted modality information. Extensive comparative experiments are conducted on two publicly available PET/CT datasets to evaluate the performance of our proposed method whose results demonstrate that MEFN significantly outperforms state-of-the-art methods with improvements of 3.10% and 3.23% in DSC scores on the AutoPET dataset and the Hecktor dataset, respectively. More importantly, our model can provide radiologists with credible uncertainty of the segmentation results for their decision in accepting or rejecting the automatic segmentation results, which is particularly important for clinical applications. Our code will be available at https://github.com/QPaws/MEFN .},
  archive      = {J_KBS},
  author       = {Yuxuan Qi and Li Lin and Bin Zhang and Jingya Zhang and Jiajun Wang},
  doi          = {10.1016/j.knosys.2025.113838},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113838},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modal evidential fusion network for trustworthy PET/CT tumor segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ord-MAP criterion: Extending MAP for ordinal classification. <em>KBS</em>, <em>324</em>, 113837. (<a href='https://doi.org/10.1016/j.knosys.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal classification is a machine learning task where the goal is to predict labels with an inherent order. In traditional ordinal classification, the Maximum A Posteriori (MAP) criterion for assigning class labels fails to account for the ordinal structure of the target variable. We introduce Ord-MAP, a novel criterion for ordinal classification, as the most suitable extension of the binary MAP criterion to ordinal data. Unlike the usual approach, which selects the class with the highest probability — a logical choice for nominal classification — Ord-MAP identifies the first class whose cumulative probability exceeds 0.5, explicitly incorporating the class order and minimizing the expected misclassification cost under an order-sensitive loss function. This theoretical advancement addresses the fundamental limitation of existing methods by directly integrating the ordinal nature of the classes into the decision-making process. The theoretical contribution of this study is complemented by a comprehensive empirical evaluation that includes both experiments with real-world datasets and controlled simulations, showing that Ord-MAP outperforms MAP in various scenarios, achieving statistically significant improvement in prediction. Simulations further demonstrate that this improvement is particularly noticeable for centrally located classes, with symmetric gains at both extremes of the ordinal scale. Additionally, as the Shannon entropy of the predicted probability distribution increases — indicating greater uncertainty — the difference in MAE between Ord-MAP and MAP also grows, with Ord-MAP consistently outperforming MAP under moderate to high entropy. These findings highlight the practical benefits and broad applicability of the Ord-MAP criterion, positioning it as a well-founded alternative for ordinal classification tasks.},
  archive      = {J_KBS},
  author       = {Rosario Delgado},
  doi          = {10.1016/j.knosys.2025.113837},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113837},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ord-MAP criterion: Extending MAP for ordinal classification},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel design of reward and epsilon-greedy decay strategy tailored for Q-learning in optimizing local mobile robot path planning. <em>KBS</em>, <em>324</em>, 113836. (<a href='https://doi.org/10.1016/j.knosys.2025.113836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a fundamental task in mobile robotics, requiring efficient navigation while avoiding obstacles. This paper introduces Tailored Reward and Epsilon-Greedy Decay Q-Learning (TRE-QL), a novel enhancement of Q-Learning aimed at improving convergence speed, reward stability, and exploration efficiency. A key contribution is the adaptation of the reward function, which penalizes state revisits, encouraging exploration of new paths. We also propose an epsilon-greedy decay strategy that dynamically adjusts the exploration rate based on cumulative reward, ensuring a smooth transition from exploration to exploitation and stabilizing the agent’s behavior. Experiments in grid environments with obstacle densities of 20%, 30%, and 40% show that TRE-QL outperforms traditional Q-Learning, GA-QL, EnDQN, and O-QL in terms of convergence speed, efficiency, and reward. TRE-QL excels in more complex scenarios, balancing computational efficiency with adaptability. These results demonstrate that TRE-QL offers an effective solution for local path planning, combining reward optimization with an adaptive exploration strategy.},
  archive      = {J_KBS},
  author       = {Marouane Ben-Akka and Camel Tanougast and Camille Diou},
  doi          = {10.1016/j.knosys.2025.113836},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113836},
  shortjournal = {Knowl. Based Syst.},
  title        = {Novel design of reward and epsilon-greedy decay strategy tailored for Q-learning in optimizing local mobile robot path planning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent zero-day attack detection system using unsupervised machine learning for enhancing cyber security. <em>KBS</em>, <em>324</em>, 113833. (<a href='https://doi.org/10.1016/j.knosys.2025.113833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network intrusion attacks have proliferated globally, particularly the new and unknown attacks referred to as zero-day attacks. Zero-day network intrusion attacks are common cyber security threats that attempt to exploit flaws in a network system. Moreover, unsupervised learning techniques are crucial for detecting zero-day network intrusion attacks due to the drawbacks of existing methods, which include reliance on duplicate features and the inability to obtain labeled data. An Intelligent Zero-day Attack Detection System using Unsupervised Machine Learning (ZdAD-UML) model is introduced in this research study to enhance the cybersecurity of IoT networks. Pre-processing is done first to get the gathered data ready for more analysis. This includes data cleaning, Min-max normalization, and one-hot encoding. To minimize the data redundancy and lessen the computational complexity, the significant features are selected using the Hippopotamus Optimization Algorithm (HOA). The Enhanced K-means Clustering-based Weighted Crayfish Auto Encoder (EKC-WCAE) is used in the feature extraction process to extract the network flow features. Subsequently, the anomaly score is calculated and compared with the threshold value to detect potential zero-day attacks. Furthermore, the threshold calculation is accomplished using the Pufferfish Optimization Algorithm (POA). According to the results, the suggested method uses the IoT-23 and CICIoT2023 datasets to produce accuracy rates of 98.65 % and 98.51 % in the 20–80 Test-Train partition. For 30–70 Test-Train partition, the proposed method attained an accuracy of 98.73 % and 98.93 % using IoT-23 and CICIoT2023 datasets, respectively.},
  archive      = {J_KBS},
  author       = {Apoorva Jain and Renu Bagoria and Praveen Arora},
  doi          = {10.1016/j.knosys.2025.113833},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113833},
  shortjournal = {Knowl. Based Syst.},
  title        = {An intelligent zero-day attack detection system using unsupervised machine learning for enhancing cyber security},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-based sentimental analysis using optimized multi-layered deep BiLSTM classifier. <em>KBS</em>, <em>324</em>, 113832. (<a href='https://doi.org/10.1016/j.knosys.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a crucial task in understanding customer opinion and feedback, particularly in the context ofan e-commerce platform. This research addresses the challenge of aspect-based sentiment analysis in text data, where products and reviews contain multipleaspects and sentiments towards each aspect need to be extracted and classified accurately. In this research a novel Collective Intelligence Homing optimization enabled Multi-LayeredBidirectional Long Short-Term Memory (CIHO-Multi-LayeredBiLSTM) is proposed that leverages the influenceof deep learning and optimization techniques to enhance the accuracyof sentiment analysis. A Multi-LayeredBiLSTM can handle text classification taking advantage of the rich information available in the text. By leveraging graph convolution on dependency trees, the model excels in capturing the intricate interplay between sentiments and aspects, leading to enhanced accuracy in sentiment analysis tasks. To enhance the model's performance a CIHOalgorithm is introduced, which fine-tunes the model parameters and improves its ability to capture nuanced sentiment data. The accuracy, sensitivity, and specificity of the CIHO-Multi-LayeredBiLSTM are 97.40 %, 92.60 %, and 98.45 % respectively, with a TP of 80. Likewise, for k-fold 10, the metrics stand at 96.13 %, 96.67 %, and 95.83 %, signifying greater efficacy compared to other conventional approaches. The experimental outcomes reveal the efficiency of the approach in sentiment classification, outperforming the other traditional sentiment analysis methods.},
  archive      = {J_KBS},
  author       = {Lal Babu Purbey and Kamlesh Lakhwani},
  doi          = {10.1016/j.knosys.2025.113832},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113832},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-based sentimental analysis using optimized multi-layered deep BiLSTM classifier},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SENA: Leveraging set-level consistency adversarial learning for robust pre-trained language model adaptation. <em>KBS</em>, <em>324</em>, 113831. (<a href='https://doi.org/10.1016/j.knosys.2025.113831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using pre-trained language models (PLM) to generate embeddings for downstream tasks has achieved great success in recent years. The pre-trained embeddings can be adapted to downstream tasks by encouraging the embedding similarity among samples within the same class through auxiliary tasks with contrastive learning (CL) objectives. However, existing methods face two issues: (i) class imbalance and over-representation caused by instance sampling bias in CL, and (ii) gradient conflicts between auxiliary and downstream tasks. To deal with these issues, we propose a novel approach called se t-level co n sistency a dversarial learning (SENA). Specifically, SENA leverages on two techniques, i.e., instance-to-set function and consistency adversarial learning, to yield task-specific embeddings. To mitigate the issue of instance sampling bias in CL, SENA incorporates set-level discriminative features into individual instance embeddings by employing an instance-to-set function, which are then employed as prototypes for each category in contrastive learning. Additionally, to tackle gradient conflicts between CL and downstream tasks, SENA first identifies the most inconsistent cases and then eliminates the inconsistency in an adversarial learning manner. SENA is validated on GLUE benchmark and three intent classification datasets. Comprehensive experiments demonstrate the effectiveness of SENA on various tasks.},
  archive      = {J_KBS},
  author       = {Jianqi Gao and Jian Cao and Hang Yu and Yonggang Zhang and Zhen Fang},
  doi          = {10.1016/j.knosys.2025.113831},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113831},
  shortjournal = {Knowl. Based Syst.},
  title        = {SENA: Leveraging set-level consistency adversarial learning for robust pre-trained language model adaptation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-integrated optimized cryptographic framework for securing cloud data. <em>KBS</em>, <em>324</em>, 113830. (<a href='https://doi.org/10.1016/j.knosys.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of cloud computing (CC), data security has arisen as a key concern owing to risks connected to centralized storage and third-party data management. Traditional encryption solutions, while successful in some cases, frequently confront scalability, key management, and real-time access control (AC) issues, particularly in remote cloud systems. This research presents a better Blockchain-Integrated Optimized Cryptographic Framework (BIOCF), which aims at data privacy through Paillier Homomorphic Encryption (PHE) and entails a hybrid optimization model- Greylag Goose Optimization (GGO) and Crayfish Optimization (CO)-for dynamic cryptographic key generation and management. The integration of blockchain technologies for decentralized key management, thus allowing for threshold cryptography for key-sharing mechanisms and smart contracts for AC, significantly enhances security and reduces the reliance on centralized authority. Moreover, the cryptographically hashed encrypted data stored on the blockchain offers a strong mechanism for checking data integrity. The developed model is experimentally validated using existing cryptographic model techniques. In BIOCF, the proposed model achieved an extremely low encryption time of about 1.23 s and a decryption time within 1.6 s for data on up to 10 MB. For that, the key generation is recorded in an efficient manner of 0.684 s, along with an overhead of 2.5 s. The resource utilization during the key generation is to be 48.5 %. Highest throughput of up to 140.23 kb/s can also be demonstrated at 250 TPS. The model achieved an MAPE of 4.85 % for encryption time, with an MAE of 0.12, an RMSE of 0.16, and an R² score of 0.842.},
  archive      = {J_KBS},
  author       = {Rekha Gaitond and Gangadhar S. Biradar and Sujata Terdal},
  doi          = {10.1016/j.knosys.2025.113830},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113830},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-integrated optimized cryptographic framework for securing cloud data},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive information flow propagation for visual tracking. <em>KBS</em>, <em>324</em>, 113828. (<a href='https://doi.org/10.1016/j.knosys.2025.113828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively and comprehensively exploiting the information flow contained in video sequences is crucial for visual tracking. However, existing high-performance trackers typically utilize information flow in a simplistic and direct manner. They primarily focus on the spatio-temporal information propagation between adjacent frames and lack evaluation of the transmitted information, leading to suboptimal tracking performance. To address these issues, we propose a novel tracking framework named AIFTrack. Specifically, we introduce a prompt generator with a trigger mechanism to acquire spatio-temporal prompts. The trigger mechanism evaluates the quality of generated prompts, deciding whether to propagate them to the next frame. To establish long-range information flow during tracking, we propose historical information fusion module (HIFM). This module adaptively reinforces current features with multi-frame historical state information of the target, overcoming the shortages of trackers that only focused on context from previous one frame. In addition, the sequence length in previous video-based trackers is generally short due to GPU memory constraints, limiting the exploration of information in video sequences. We propose an innovative model update method that decouples the sequence length from GPU memory limitations. Extensive experimental results demonstrate that our method significantly improves performance across six tracking benchmarks: GOT-10k, LaSOT, LaSOT ext , UAV123, TNL2K, and TrackingNet.},
  archive      = {J_KBS},
  author       = {Junze Shi and Jian Shi and Haibo Luo},
  doi          = {10.1016/j.knosys.2025.113828},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113828},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive information flow propagation for visual tracking},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting spatio-temporal dynamics in aquaculture networks: An extended katz index approach. <em>KBS</em>, <em>324</em>, 113826. (<a href='https://doi.org/10.1016/j.knosys.2025.113826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective surveillance of the distribution of live fish between aquaculture farms is crucial for maintaining food security and preventing disease outbreaks. However, existing conventional models often assume the network is static and do not incorporate other factors that contribute to movement between farms, lacking the ability to accurately predict future movements, especially given the dynamic interactions within aquaculture networks. This study addresses this gap by developing the Edge-Weighted Katz Index (EWKI), an extension of the traditional Katz index that integrates spatial information to improve the accuracy of predicting fish distribution between farms. Using a comprehensive dataset on the distribution of live fish between farms in England and Wales from the year 2010 and 2023, the study evaluates the performance of the EWKI model in comparison to other similarity-based link prediction methods. The results indicate that the EWKI model significantly outperforms other methods, achieving a precision of 92.89%, a recall of 81.09%, and an F1-score of 86.59%, alongside an AUPR of 93.44% and an AUROC of 99.97%. This research has practical implications, as the developed method can accurately predict the distribution of fish between farms, supporting predictions of disease spread and facilitating targeted interventions. Furthermore, the integration of spatial information into the network analysis has broader applications across various fields where understanding and predicting spatially influenced network dynamics are crucial, including transportation networks.},
  archive      = {J_KBS},
  author       = {Michael-Sam Vidza and Marcin Budka and Wei Koong Chai and Mark Thrush and Mickaël Teixeira Alves},
  doi          = {10.1016/j.knosys.2025.113826},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113826},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting spatio-temporal dynamics in aquaculture networks: An extended katz index approach},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level transfer learning for irregular clinical time series prediction. <em>KBS</em>, <em>324</em>, 113825. (<a href='https://doi.org/10.1016/j.knosys.2025.113825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical time series prediction plays a crucial role in precision medicine, enabling early detection of health issues to help formulate effective treatment plans. Most existing studies have focused on capturing irregular temporal dependencies of time series but have overlooked the causes of irregularity. We empirically find that the testing frequency is intimately associated with the patient’s condition. Motivated by this observation, this paper proposes a M ulti- L evel T ransfer L earning framework (MLTL). This framework first categorizes time series based on patient conditions and then performs predictions according to clinical variables (indicators). In particular, we use prediction models that are tailored to various series categories. In addition, we present a pretraining task to capture correlations among indicators to enhance the information density of the series. We further transfer dense representations to models in a fine-tuning manner. To assess the effectiveness of MLTL, we conducted extensive experiments on two clinical benchmark datasets and one real-world dataset. Results demonstrate that MLTL consistently surpasses mainstream regular and irregular prediction methods. In particular, even when 80% of the indicator values are missing from the clinical time series, the MLTL framework achieves a significant 9.4% reduction in mean absolute error, confirming the effectiveness of our transfer learning strategy.},
  archive      = {J_KBS},
  author       = {Xingwang Li and Fei Teng and Minbo Ma and Zhen Qin and Jinhong Guo and Jie Xu and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113825},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113825},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-level transfer learning for irregular clinical time series prediction},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fusion of decomposed fuzzy based decision-making and metaheuristic optimization system for sustainable planning of urban transport. <em>KBS</em>, <em>324</em>, 113823. (<a href='https://doi.org/10.1016/j.knosys.2025.113823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving public transport quality significantly encourages users to shift from private vehicles, helping reduce traffic congestion, noise, and CO 2 emissions in urban areas. Policymakers and researchers focus on identifying the key factors for enhancing public transport quality and finding practical solutions. However, traditional decision-making techniques often encounter limitations, such as difficulty in managing complex and non-linear relationships, inadequate solution space exploration, and defuzzification-caused weight distortion. To overcome these challenges, a novel Decomposed Fuzzy Set based Non-Linear (DFNL) optimization model is developed in this study. With this innovative model, Decomposed Fuzzy (DF) judgments lead straight to precise weights, eliminating information loss and improving precision. A hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and the Simplex Search Method (SSM) is proposed to solve the DFNL model effectively. Furthermore, a ranking technique called Multiplicative form of Multi-Objective Optimization by Ratio Analysis (MULTIMOORA) is incorporated for evaluating the solution for Urban Transport Sustainability (UTS). The proposed assessment is tested on two illustrative examples to demonstrate improved performance. A case study conducted in Kolkata, India, further validates its applicability. Comparative evaluations highlight its advantages over existing methods, while its resilience and stability are confirmed with sensitivity evaluations. By integrating metaheuristic algorithms with advanced group decision-making methodologies, this approach ensures enhanced accuracy of weight, streamlined computational complexity, and adaptability to uncertainty. The study offers practical and actionable insights for policymakers aiming to implement sustainable and resilient urban transport strategies.},
  archive      = {J_KBS},
  author       = {Rishabh Rishabh and Kedar Nath Das},
  doi          = {10.1016/j.knosys.2025.113823},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113823},
  shortjournal = {Knowl. Based Syst.},
  title        = {A fusion of decomposed fuzzy based decision-making and metaheuristic optimization system for sustainable planning of urban transport},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced residual learning framework for graph neural networks based on dual random walk. <em>KBS</em>, <em>324</em>, 113822. (<a href='https://doi.org/10.1016/j.knosys.2025.113822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated outstanding achievements in node classification tasks. Although extensive research has been conducted, prevalent methods primarily focus on feature engineering while paying limited attention to structural information encoded in adjacency matrices. Most current approaches fail to effectively capture both global and local topological properties and often suffer from over-smoothing during information propagation. In this work, we propose an Enhanced Residual Learning Framework for Graph Neural Networks based on Dual Random Walk (ResDW-GNN). This framework employs a dual random walk strategy, combining breadth-first search (BFS) and depth-first search (DFS), where DFS walks preserve key heterogeneity and global connectivity features, BFS walks preserve homogeneity and local structural details. We design a Dual-walk Node Representation (DNR) mechanism that integrates both BFS and DFS walking strategies to capture different structural perspectives. Through this mechanism, we learn DNR-based node-level weights that effectively balance different structural aspects, allowing the model to adaptively focus on important features from both global and local structural patterns. Furthermore, to better integrate multi-scale information and address the over-smoothing problem in GNN, we propose two key architectural components: a Hybrid Residual Connections (HRC) mechanism and an Adaptive Iterative Graph Convolution (AIGC) module. Comprehensive evaluations on nine real-world benchmark datasets demonstrate that our proposed ResDW-GNN achieves state-of-the-art performance, consistently outperforming existing methods across both homophilous and heterophilous graph structures.},
  archive      = {J_KBS},
  author       = {Jin Fan and Zhangyu Gu and Jiajun Yang and Huifeng Wu and Danfeng Sun and Jia Wu},
  doi          = {10.1016/j.knosys.2025.113822},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113822},
  shortjournal = {Knowl. Based Syst.},
  title        = {An enhanced residual learning framework for graph neural networks based on dual random walk},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal data augmentation based on masked modeling for image–text retrieval. <em>KBS</em>, <em>324</em>, 113821. (<a href='https://doi.org/10.1016/j.knosys.2025.113821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of image–text pairs are crucial to train a precise image–text retrieval model. However, in real-world applications, small data is a common problem. As an effective strategy, data augmentation is a natural choice to deal with the small data problem. Although uni-modal data augmentation has obtained a tremendous success, multi-modal data augmentation remains a challenging task due to the semantic consistency preservation difficulty. In this paper, we propose a Multi-modal Data Augmentation framework based on Masked Modeling (MDAMM), which reconstructs the masked parts based on the intact modality and the remaining information in the masked modality by exploiting the inter-modal correlations. Furthermore, we designed a novel metric to quantitatively measure the consistency and diversity of the augmented multi-modal data. We then employ the metric to filter out some augmented data to guarantee the quality of the remaining augmented data. Experimental results on three real-world datasets demonstrate the superiority of our proposed method over traditional uni-modal and other competing multi-modal data augmentation methods.},
  archive      = {J_KBS},
  author       = {Mingyu Wang and Guoqing Chao and Xi Wang and Yongyong Chen and Xijiong Xie and Dianhui Chu},
  doi          = {10.1016/j.knosys.2025.113821},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113821},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modal data augmentation based on masked modeling for image–text retrieval},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PredVSD: Video saliency prediction based on conditional diffusion model. <em>KBS</em>, <em>324</em>, 113820. (<a href='https://doi.org/10.1016/j.knosys.2025.113820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mainstream deep learning methods for video saliency prediction often use 3D CNNs or Vision Transformers as encoder–decoders, relying on task-specific loss functions to implicitly map input frames to saliency maps. However, these methods are limited by their capacity for salient feature expression. In this study, inspired by the recent advances of diffusion models in video processing tasks, we propose a Conditional Diffusion Model for Video Saliency Prediction (PredVSD), which leverages semantic video features and saliency-specific encodings as conditions to capture more representative saliency features from the target data distribution. To effectively integrate multi-scale visual features and saliency priors, we design an auxiliary network, Saliency-PyramidU-Net, allowing the denoising process to focus more on salient regions across the spatial–temporal plane. Extensive experiments confirm PredVSD’s strong performance across visual and audio-visual datasets.},
  archive      = {J_KBS},
  author       = {Chenming Li and Shiguang Liu},
  doi          = {10.1016/j.knosys.2025.113820},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113820},
  shortjournal = {Knowl. Based Syst.},
  title        = {PredVSD: Video saliency prediction based on conditional diffusion model},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully fine-tuned CLIP models are efficient few-shot learners. <em>KBS</em>, <em>324</em>, 113819. (<a href='https://doi.org/10.1016/j.knosys.2025.113819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt tuning, which involves training a small set of parameters, effectively enhances the pre-trained Vision-Language Models (VLMs) to downstream tasks. However, this approach often comes at the cost of flexibility and adaptability when the tuned models are applied to different datasets or domains. In this paper, we revisit the vanilla full fine-tuning for VLMs and show that full fine-tuning is more efficient than prompt tuning under data-limited scenarios. To mitigate the overfitting and catastrophic forgetting issues encountered when fine-tuning the entire VLMs for specific tasks under limited supervision, we propose a framework named CLIP-CITE via designing a discriminative visual-text task, further aligning the visual-text semantics in a supervision manner, and integrating knowledge distillation techniques to preserve the gained knowledge. Extensive experimental results under few-shot learning, base-to-new generalization, domain generalization, and cross-domain generalization settings, demonstrate that our method effectively enhances the performance on specific tasks under limited supervision while preserving the versatility of the VLMs on other datasets.},
  archive      = {J_KBS},
  author       = {Mushui Liu and Bozheng Li and Jun Dan and Ziqian Lu and Zhao Wang and Yunlong Yu},
  doi          = {10.1016/j.knosys.2025.113819},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113819},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fully fine-tuned CLIP models are efficient few-shot learners},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SelfDN: Adaptive self-denoising for multi-view 3D object detection. <em>KBS</em>, <em>324</em>, 113816. (<a href='https://doi.org/10.1016/j.knosys.2025.113816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view 3D object detection has achieved remarkable success comparable to LiDAR-based methods through the detection transformer, with query denoising approaches playing a pivotal role by addressing the challenges of false positives and sample imbalance, thereby significantly enhancing the accuracy and robustness of detection models. However, existing methods rely heavily on handcrafted noise patterns and overlook the spatial characteristics of multi-view 3D detection, which limits the performance of the methods. We present adaptive Self-Denoising (SelfDN), a simple yet effective training framework that automatically generates adaptive noise patterns based on the model’s current training state. In particular, we construct adaptive denoising queries based on a one-to-many assignment between predictions and ground truth during training. Based on these denoising queries, we propose two sampling strategies: Dynamic Noise Sampling (DNS) and Complementary Depth Sampling (CDS). Collectively, these strategies adaptively control both the number of denoising queries and the balance between positive and negative noise samples. The proposed SelfDN approach addresses the limitations of traditional manual denoising techniques through the optimization of adaptive learning states, thereby facilitating the effective mining of challenging and ambiguous samples. As a plug-and-play module, SelfDN can be integrated with existing DETR-like multi-view 3D detectors without any significant impact on computational resources during training. Extensive experiments on nuScenes and Argoverse 2 benchmarks demonstrate the effectiveness of our approach. With the ResNet-50 backbone, SelfDN achieves 47.9% mAP and 56.8% NDS on nuScenes validation set, outperforming previous the state-of-the-art RayDN method by 1.0%. In particular, for the strict distance threshold evaluation (AP 0.5 ), a score of 36.7% AP is observed for the car category, representing a 3.64% improvement over previous methods. On the Argoverse 2 benchmark, SelfDN achieves 23.2% mAP, surpassing RayDN baseline by 0.9%. The code is available at https://github.com/helloworld77/SelfDN .},
  archive      = {J_KBS},
  author       = {Yafei Qi and Menghao Yang and Yongmin Zhang and Bing Xiong and Yaping Liu and Zhaoning Zhang},
  doi          = {10.1016/j.knosys.2025.113816},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113816},
  shortjournal = {Knowl. Based Syst.},
  title        = {SelfDN: Adaptive self-denoising for multi-view 3D object detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAFusion: A general image fusion network with adversarial representation learning. <em>KBS</em>, <em>324</em>, 113815. (<a href='https://doi.org/10.1016/j.knosys.2025.113815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A perceptually adversarial fusion network is proposed to achieve concise and adaptive unsupervised training across various image fusion tasks. The proposed method features the adaptation of pre-trained representations through a novel discriminator, which evaluates the fused image from the generator by distinguishing its representation from a learned representation. A spatial context attention mechanism is proposed to obtain the learned representation by adapting and fusing the representations of the source image. The attention models scene salience, with its adapted representation being discerned by the discriminator, which in turn facilitates the acquisition of the learned representation. Moreover, a feature salience loss function is proposed, which compares the fused image representation with the learned representation through recursive downsampling to refine the generated content from multiple scales. The proposed method is evaluated on multi-focus, multi-exposure, medical, and infrared-visible image fusion tasks through subjective and objective comparisons with state-of-the-art fusion methods, as well as ablation studies. The notable vision effect and favorable numerical metrics of the proposed method achieved in these evaluations demonstrate the effectiveness of adversarial representation learning in enhancing fusion training in the absence of explicit ground truths. The code is released at https://github.com/6xw/PAFusion .},
  archive      = {J_KBS},
  author       = {Xingwang Liu and Kaoru Hirota and Yaping Dai and Bemnet Wondimagegnehu Mersha and Shuai Shao and Jing Wang},
  doi          = {10.1016/j.knosys.2025.113815},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113815},
  shortjournal = {Knowl. Based Syst.},
  title        = {PAFusion: A general image fusion network with adversarial representation learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable segmentation decision tree model for enhanced decision support in roundwood sorting. <em>KBS</em>, <em>324</em>, 113814. (<a href='https://doi.org/10.1016/j.knosys.2025.113814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent industry insights highlight the urgent need for affordable automation and Decision Support Systems (DSSs) in roundwood grading. Existing solutions are often prohibitively expensive or lack the necessary interpretability for practical application. To address these industrial needs, we propose an affordable grading system that emphasizes transparency, fosters user trust, facilitates employee training, and enables effective feature detection in line with trade standards. We introduce the Segmentation Decision Tree (SegDT) classifier—a hybrid-interpretable approach that combines instance segmentation for feature extraction with a decision tree for quality classification. To this end, we use a dataset of 1800 cross-sectional images of roundwood annotated with six different features (including the pith). To provide context, we utilize Gradient-weighted Class Activation Mapping (GradCam) to enhance the explainability of existing Convolutional Neural Networks (CNNs) in roundwood sorting, tackling their black-box nature. We compare the CNN + GradCam model with the SegDT classifier, evaluating both accuracy and explainability. In a quantitative user study, 24 participants evaluated both systems regarding user experience and trust, while also comparing them to a standard dimension-based grading system. The SegDT classifier achieved 80% accuracy in distinguishing three main quality grades, matching the performance of CNN classification models. However, the study revealed a clear user preference for SegDT over the CNN + GradCam prototype. While both approaches improve grading efficiency and accuracy, SegDT stands out for its transparency and usability, making it a strong candidate for industry adoption. For a video summary of this paper, please click here or visit https://youtu.be/A1w1rYWOWxo},
  archive      = {J_KBS},
  author       = {Julia Achatz and Pauline Sailer and Sven Mayer and Mark Schubert},
  doi          = {10.1016/j.knosys.2025.113814},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113814},
  shortjournal = {Knowl. Based Syst.},
  title        = {An explainable segmentation decision tree model for enhanced decision support in roundwood sorting},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid spatio-temporal graph neural network with attention fusion for traffic flow prediction. <em>KBS</em>, <em>324</em>, 113813. (<a href='https://doi.org/10.1016/j.knosys.2025.113813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is a cornerstone of Intelligent Transportation Systems (ITS), enabling data-driven traffic management, congestion mitigation, and urban mobility optimization. However, capturing the complex and dynamic spatio-temporal correlations in real-world traffic networks remains a formidable challenge, especially under non-Euclidean topologies and evolving traffic patterns. To address these limitations, we propose HSTGNN , a H ybrid S patio- T emporal G raph N eural N etwork with Attention Fusion, which integrates static, dynamic, and semantic spatial dependencies with a multi-scale gated temporal attention mechanism in a unified framework. Specifically, the model comprises three novel components: (1) a geographic spatial feature learning module that jointly captures stable and transient spatial relationships through static adaptive and dynamic graph learning; (2) a semantic spatial feature learning module that exploits dynamic time warping and masked attention to identify non-local but functionally similar traffic nodes; and (3) a temporal feature learning module that models complex temporal correlations via gated self-attention. Extensive experiments on six public benchmark datasets, including both flow and speed-based traffic scenarios, demonstrate that HSTGNN consistently outperforms existing state-of-the-art methods in terms of predictive accuracy, robustness, and generalization. Comprehensive ablation and interpretability analyses further validate the effectiveness of each module and highlight the model’s adaptability to dynamic urban traffic conditions. The results indicate that HSTGNN offers a scalable and interpretable solution for real-world traffic prediction.},
  archive      = {J_KBS},
  author       = {Lu Wang and Sunyan Hong and Haiyang Chi and Can Xie and Yirong Zhu and Hanbin Mao},
  doi          = {10.1016/j.knosys.2025.113813},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113813},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid spatio-temporal graph neural network with attention fusion for traffic flow prediction},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Role play: Learning adaptive role-specific strategies in multi-agent interactions. <em>KBS</em>, <em>324</em>, 113811. (<a href='https://doi.org/10.1016/j.knosys.2025.113811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot coordination problem in multi-agent reinforcement learning (MARL), which requires agents to adapt to unseen agents, has attracted increasing attention. Traditional approaches often rely on the self-play (SP) framework to generate a diverse set of policies in a policy pool, which serves to improve the generalization capabilities of the final agent. However, these frameworks may struggle to capture the full spectrum of potential strategies, especially in real-world scenarios that demand agents balance cooperation with competition. In such settings, agents need strategies that can adapt to varying and often conflicting goals. Drawing inspiration from Social Value Orientation (SVO)—where individuals maintain stable value orientations during interactions with others—we propose a novel framework called Role Play (RP). RP employs role embeddings to transform the challenge of policy diversity into a more manageable diversity of roles. It trains a common policy with role embedding observations and employs a role predictor to estimate the joint role embeddings of other agents, helping the learning agent adapt to its assigned role. We theoretically prove that an approximately optimal policy can be achieved by optimizing the expected cumulative reward relative to an approximate role-based policy. Experimental results in both cooperative (Overcooked) and mixed-motive games (Harvest, CleanUp) reveal that RP consistently outperforms strong baselines when interacting with unseen agents, highlighting its robustness and adaptability in complex environments.},
  archive      = {J_KBS},
  author       = {Weifan Long and Wen Wen and Peng Zhai and Lihua Zhang},
  doi          = {10.1016/j.knosys.2025.113811},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113811},
  shortjournal = {Knowl. Based Syst.},
  title        = {Role play: Learning adaptive role-specific strategies in multi-agent interactions},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking deep structures: Anchor-side filtering for efficient multiview clustering on high-order bipartite graphs. <em>KBS</em>, <em>324</em>, 113810. (<a href='https://doi.org/10.1016/j.knosys.2025.113810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based multiview clustering methods have attracted extensive attention due to their effectiveness in capturing intrinsic structures. However, traditional first-order graph methods can characterize only direct neighbourhood relationships and struggle to capture deeper, high-order indirect associations. Directly adopting high-order graph structures, although capable of capturing richer relational information, often introduces redundant and noisy information and incurs increased computational complexity. To address these limitations, this paper presents a high-order graph algorithm that is based on bipartite graphs optimized via an anchor-side graph filtering strategy. Specifically, we utilize high-order bipartite graphs to replace traditional first-order graphs. Through the ”neighbour anchor-point connection” propagation mechanism, high-order bipartite graphs leverage sparse yet reliable initial connections to infer deeper, latent relationships. Additionally, by utilizing connections between small-scale anchors and large-scale data, high-order bipartite graphs significantly reduce computational complexity, which makes them more suitable for large-scale clustering tasks. However, the high-order graph structure inevitably introduces redundancy and noise. To this end, an anchor-side graph filtering strategy is introduced to remove noise and redundancy while preserving the clustering structure; it avoids complex sample-side calculations, thus improving efficiency. Finally, we input the high-quality high-order bipartite graphs from each view into a fusion mechanism to obtain the optimal clustering partitions for each view and apply tensor nuclear norm (TNN) constraints to these partitions to achieve the best clustering results. Extensive experiments have demonstrated the efficiency of our method in terms of time and performance.},
  archive      = {J_KBS},
  author       = {Fei Wang and Gui-Fu Lu},
  doi          = {10.1016/j.knosys.2025.113810},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113810},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unlocking deep structures: Anchor-side filtering for efficient multiview clustering on high-order bipartite graphs},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated graph anomaly detection with large language models. <em>KBS</em>, <em>324</em>, 113809. (<a href='https://doi.org/10.1016/j.knosys.2025.113809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have emerged as powerful tools for graph anomaly detection (GAD). However, designing effective GNN architectures for GAD often demands considerable domain expertise and laborious manual tuning. Although graph neural architecture search (GNAS) has made significant progress in automating the discovery of effective deep architectures, existing GNAS methods are challenging to directly apply to GAD tasks due to the lack of a dedicated search space tailored for GAD and the difficulty in effectively incorporating domain expert knowledge into the model architecture generation process. To address these challenges, this paper proposes an automated graph anomaly detection ( AutoGAD for short) framework. AutoGAD automates the generation of optimal neural network architectures through a predefined search space and an efficient search strategy. Specifically, we first design a novel search space tailored for GAD tasks based on the characteristics of the graph autoencoder framework. Then, we leverage a large language model (LLM) as the controller of GNAS, guiding the LLM to rapidly generate architectures suitable for GAD within the search space through well-designed prompts. Extensive experimental results demonstrate that AutoGAD can generate new architectures that outperform existing GAD models, and its effectiveness is consistently observed across different datasets.},
  archive      = {J_KBS},
  author       = {Jiaqi Yu and Yang Gao and Hong Yang and Zhihong Tian and Peng Zhang and Xingquan Zhu},
  doi          = {10.1016/j.knosys.2025.113809},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113809},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated graph anomaly detection with large language models},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exercise-aware higher-order thinking skills assessment via fine-tuned large language model. <em>KBS</em>, <em>324</em>, 113808. (<a href='https://doi.org/10.1016/j.knosys.2025.113808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Higher-order thinking Skills (HOTS) are complex cognitive skills that go beyond the basic levels of memory and comprehension. It is critical to developing an individual’s critical thinking and problem-solving skills. Current methods for assessing HOTS typically rely on expert judgment or specially designed assessment tasks, which have become well-established and reliable paradigms but are time-consuming and difficult to transfer. Accordingly, this study aims to develop an automated HOTS assessment model that will reduce reliance on experts and enhance efficiency and accuracy. Large language models (LLM) are pre-trained models using deep learning techniques to deal with natural language processing tasks. They have excellent knowledge base and reasoning capabilities, and researchers have applied them to a range of domains. In this paper, we proposed the Exercise-Aware higher-order Thinking skills Assessment (EATA) model based on fine-tuning the LLM. The EATA comprises the Exercise Awareness (EA) and the HOTS Assessment (HA) modules. The EA module includes a pre-trained Text2Vec and a multilayer perceptron (MLP). It integrates the exercise text information with the HOTS labeling information to generate the higher-order exercise embedding matrix. The HA module employs a pre-trained LLM as the underlying network, which takes the student’s learning records with the higher-order exercise embedding as inputs and automatically assesses the student’s HOTS through a fine-tuning technique. In this way, EATA can emulate traditional assessment methods, but replace experts with LLM. It reduces the interference of human factors, thus improving efficiency. To verify the validity of EATA, we collect 43070 online exercise data from 181 undergraduate students in a university. The experiments show that EATA can effectively assess students’ HOTS, indicating the potential value of LLM in HOTS assessment tasks. The implementations are available at https://github.com/xxiongGG/EATA .},
  archive      = {J_KBS},
  author       = {Xiuling He and Xiong Xiao and Jing Fang and Yue Li and Yangyang Li and Ruijie Zhou},
  doi          = {10.1016/j.knosys.2025.113808},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113808},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exercise-aware higher-order thinking skills assessment via fine-tuned large language model},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model-assisted multi-scale hierarchical classification of ECG signals. <em>KBS</em>, <em>324</em>, 113807. (<a href='https://doi.org/10.1016/j.knosys.2025.113807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have been widely applied to electrocardiogram (ECG) classification. Existing research predominantly focuses on single-level classification tasks, while research on multi-level classification tasks remains relatively limited. Considering the hierarchical nature of heart diseases in the ECG dataset, we propose a hierarchical ECG classification model, which consists of two branches: Transformer and Temporal Convolutional Network (TCN). In the Transformer branch, the Fast Fourier Transform (FFT) is employed to extract periodic characteristics of the ECG signals, and the period length is selected as the multi-scale patch size to obtain multi-scale embedding vectors. Moreover, static patient information is transformed into prompt vectors using a pre-trained Large Language Model (LLM), which are integrated with embedding vectors to obtain more comprehensive representation. After integration, a router mechanism is also designed to learn the correlations of intra-scale and inter-scale features using self-attention. In the TCN branch, since ECG signals have complex and rapidly changing characteristics, convolution kernels of different scales are used to fully extract features. The feature vectors extracted from each level of the multi-scale Transformer and multi-scale TCN branches are fused accordingly, enabling the model to capture global and local information, thereby more fully understanding the potential patterns in the ECG signals. Extensive experiments are conducted on two different ECG datasets. The results demonstrate that the proposed model outperforms the competitive baselines in most metrics.},
  archive      = {J_KBS},
  author       = {Qianjiang Chen and Cheng Lian and Bingrong Xu and Quan Zhou and Yixin Su and Zhigang Zeng},
  doi          = {10.1016/j.knosys.2025.113807},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113807},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language model-assisted multi-scale hierarchical classification of ECG signals},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFUDNet: Underwater object detection via spatial-frequency domain modulation with mixture of experts. <em>KBS</em>, <em>324</em>, 113805. (<a href='https://doi.org/10.1016/j.knosys.2025.113805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection plays a crucial role in aquaculture and marine environmental protection. Compared to conventional images, underwater images often suffer from challenges such as low brightness, color distortions, blurred details, and noise. In recent years, frequency-domain techniques have demonstrated significant potential in underwater image processing. Notably, distinct patterns in blur distribution can be observed across the low-frequency and high-frequency components of underwater images from various datasets. In response to these challenges, we propose a novel spatial-frequency domain modulation underwater object detection network, termed SFUDNet. Unlike existing spatial-domain underwater object detection methods, SFUDNet introduces an innovative spatial-frequency decoupling structure with a mixture of expert mechanism, which is implemented through the proposed frequency modulation block (FMB) and spatial-frequency integration (SFI) module. The FMB employs a mixture-of-expert approach to dynamically learn diverse frequency features across different granularities and scales in a sample-adaptive manner, subsequently performing element-wise local feature modulation. Meanwhile, the SFI module effectively integrates frequency-domain features with spatial-domain features, enabling a more comprehensive representation of underwater scenes. Extensive experiments on publicly available underwater datasets demonstrate that SFUDNet achieves state-of-the-art performance, outperforming existing underwater object detection baselines in both detection accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Hu Xu and Ju He and Changsong Pang and Yang Yu},
  doi          = {10.1016/j.knosys.2025.113805},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113805},
  shortjournal = {Knowl. Based Syst.},
  title        = {SFUDNet: Underwater object detection via spatial-frequency domain modulation with mixture of experts},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visually meaningful triple images encryption algorithm based on 2D compressive sensing and multi-region embedding. <em>KBS</em>, <em>324</em>, 113804. (<a href='https://doi.org/10.1016/j.knosys.2025.113804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visually meaningful image encryption methods, with their ability to secure both the content and the visual security of image information, have been widely investigated. However, the existing schemes have limited encryption capacity and usually require carrier data for decryption, which poses significant inconveniences in practical applications. To address these issues, a novel visually meaningful triple images encryption algorithm is raised. First, three plaintext images are measured by two optimized chaotic measurement matrices according to 2D compressive sensing theory. Then, a double-layer Josephus scrambling approach is designed to weaken the strong pixel correlations in the compressed image. To defy the differential attack, the pixel values are diffused along the diagonal direction to make a global change. Finally, the generated ciphertext image is hidden into a color carrier image with a newly developed multi-region embedding strategy based on 3D integer wavelet transform. The damage to the carrier image is greatly reduced by assigning appropriate embedding strength to different coefficient regions based on their characteristics. Through these steps, a meaningful color steganographic image less attractive to attackers is obtained. At the recipient end, the decryption images can be reconstructed without any original carrier data. Experimental results show that the proposed scheme is feasible and robust against various common attacks. Comparisons with related works demonstrate that our scheme exhibits advantages in terms of visual security and reconstruction quality.},
  archive      = {J_KBS},
  author       = {Long-Long Hu and Ming-Xuan Chen and Meng-Meng Wang and Nan-Run Zhou},
  doi          = {10.1016/j.knosys.2025.113804},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113804},
  shortjournal = {Knowl. Based Syst.},
  title        = {Visually meaningful triple images encryption algorithm based on 2D compressive sensing and multi-region embedding},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimum variance weighted broad cascade network structure for imbalanced classification. <em>KBS</em>, <em>324</em>, 113803. (<a href='https://doi.org/10.1016/j.knosys.2025.113803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) are widely used due to their speed and versatility. Despite their efficiency, minority class samples’ accuracy is sometimes overlooked when dealing with severely imbalanced rate data. Traditional weighted BLS only considers the number of samples, and such a fixed weighting leads to poor classification performance. In addition, the original BLS does not take into account the dispersion after its random data mapping. To solve the aforementioned concerns, this study presents a minimum variance broad cascade network. By incorporating the constraint of reduced category variance information and cascading feature nodes and enhancement nodes at each level, the network may extract enough valuable information from the original data while accounting for data dispersion. We use support vector data to describe the hyperplane distribution information of the data in order to further investigate the original data’s distribution. From there, we develop a boundary weighting strategy to further concentrate on the minority class samples whose boundaries are hard to discern. Extensive comparative validation on 20 real-world datasets confirms that our method has significant advantages in dealing with imbalanced data classification problems.},
  archive      = {J_KBS},
  author       = {Wuxing Chen and Zhiwen Yu and Kaixiang Yang and Jun Jiang and Fan Zhang and C.L. Philip Chen},
  doi          = {10.1016/j.knosys.2025.113803},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113803},
  shortjournal = {Knowl. Based Syst.},
  title        = {Minimum variance weighted broad cascade network structure for imbalanced classification},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards spatio-temporal representation learning for EEG classification in motor imagery-based BCI system. <em>KBS</em>, <em>324</em>, 113801. (<a href='https://doi.org/10.1016/j.knosys.2025.113801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of motor imagery (MI), electroencephalography (EEG) signals will vary in the spatial and time domains with a mental motion rehearsal, therefore spatio-temporal representation is useful in providing discriminative information for EEG signals classification. However, due to the nonstationarity of EEG, learning EEG representations is frequently impeded by substantial intra-class variability and limited inter-class differences. It poses a challenge in learning discriminative EEG representations for MI classification. In addition, directly fusing the features from spatial and time domain carries potential risks, as these features from distinct domains may contain redundant or irrelevant information that could impede effective feature extraction. To address these problems, we propose a novel spatio-temporal representation learning framework, named STRLF, to jointly extract the spatial and temporal information of the EEG, thereby improving the MI classification performance. In particular, we leverage a Riemannian network to capture spatial representations and a convolutional neural network to learn temporal representations, both of which are trained to capture class-specific information. Moreover, to improve the discrimination between different categories of the extracted features, a centroid loss is leveraged to enhance the inter-calss differences and reduce the intrasubject nonstationarity. Then, to fuse the representations from spatial and time domain, a group ℓ 1 -norm is used to learn the importance of each domain and a ℓ 2 , 1 -norm is employed to explore the importance of each feature. Considering the importance of domains and features, the most discriminative features will be selected as the final spatio-temporal representation for EEG classification. To evaluate the proposed method, extensive experiments are carried out on a collected EEG dataset and three public EEG datasets, and the results demonstrate the effectiveness and the advantage of our method in MI-based brain-computer interface (BCI) systems.},
  archive      = {J_KBS},
  author       = {Siwei Liu and Jia Zhang and Hanrui Wu and Guoxu Zhou and Qibin Zhao and Jinyi Long},
  doi          = {10.1016/j.knosys.2025.113801},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113801},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards spatio-temporal representation learning for EEG classification in motor imagery-based BCI system},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising diffusion wavelet models for zero-shot medical image translation. <em>KBS</em>, <em>324</em>, 113800. (<a href='https://doi.org/10.1016/j.knosys.2025.113800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models excel in generating high-quality images, yet their application in medical image translation, specifically for cone-beam computed tomography (CBCT) to CT translation, often fails to accurately preserve intricate anatomical details. Conventional methods including GANs and VAEs also struggle with high-quality translation due to the challenges in learning bi-directional CBCT/CT distribution mapping and a lack of robustness to out-of-distribution (OOD) testing data. To address the challenges, we proposed a denoising diffusion wavelet model (DDWM), which only requires learning the CT data distribution in the training process and then performs zero-shot CBCT-to-CT translation through a similarity-bridge-controlled reverse diffusion process. In this process, domain-invariant information (e.g., anatomical structures in medical images) from the source image is fused into the result at each step of the reverse diffusion. Specifically, in our DDWM, we use wavelet transform to decompose the image into different frequency bands, then identify the bands where the source and target domains are most similar (i.e., the domain-invariant information). This information is incorporated into each step of the reverse process, preserving the anatomical structures of the original CBCT image and facilitating structure-faithful translation. Trained on a brain CT dataset (Dataset I) and evaluated on three CBCT-to-CT translation datasets (Datasets I–III) – with Datasets II&III being OOD – DDWM outperformed other state-of-the-art methods across all metrics, including Frechet Inception Distance (FID), Peak Signal-to-Noise Ratios (PSNR), Mean Absolute Error (MAE), and DICE scores, demonstrating superior image translation quality and anatomical fidelity.},
  archive      = {J_KBS},
  author       = {Yunxiang Li and Xianghao Kong and Jiacheng Xie and Greg Ver Steeg and You Zhang},
  doi          = {10.1016/j.knosys.2025.113800},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113800},
  shortjournal = {Knowl. Based Syst.},
  title        = {Denoising diffusion wavelet models for zero-shot medical image translation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDDIP: Efficient single-layer pixel-based metasurface denoising via deep image prior. <em>KBS</em>, <em>324</em>, 113799. (<a href='https://doi.org/10.1016/j.knosys.2025.113799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limited design parameters challenge metasurface design for 5G wave communications. Although many works on multi-layer metasurfaces attempt to address this challenge, they often introduce complexities in arrangement and fabrication. Recently, single-layer pixel-based metasurfaces have become appealing due to their easy integration and diverse design parameter options. However, some existing approaches for single-layer pixel-based metasurface generation may struggle to achieve desired spectral responses. Moreover, certain models lack diversity in pattern generation, leading to the repetitive production of unqualified designs. To tackle these issues, we present a metasurface denoising method based on the deep image prior (DIP), namely MDDIP. MDDIP optimizes metasurface designs without training datasets, and utilizes the response error to guide the network parameter update. In comparative experiments involving 2523 test data, MDDIP achieves a MAE ave of 0.063. The experimental performance indicates that MDDIP outperforms state-of-the-art methods for high-quality metasurface generation.},
  archive      = {J_KBS},
  author       = {Manna Dai and Yang Jiang and Feng Yang and Joyjit Chattoraj and Yingzhi Xia and Xinxing Xu and Weijiang Zhao and My Ha Dao and Yong Liu},
  doi          = {10.1016/j.knosys.2025.113799},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113799},
  shortjournal = {Knowl. Based Syst.},
  title        = {MDDIP: Efficient single-layer pixel-based metasurface denoising via deep image prior},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DviT: Debiased variational inference for multi-modal mutual prompt tuning. <em>KBS</em>, <em>324</em>, 113798. (<a href='https://doi.org/10.1016/j.knosys.2025.113798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal prompt tuning, as an effective manner of adapting pre-trained vision-language models (VLMs) to downstream tasks, has demonstrated superior performance. The tuning, however, often exhibits disjointed or unidirectionally correlated prompts between two modalities, impeding the modeling of their interrelations. To this end, we propose D ebiased v ariational i nference for multi-modal mutual prompt T uning (DviT) to favorably align vision-language representation. In specific, we propose a visual style perturbation strategy to mitigate the contextual bias inherent in the visual modality during vision-to-language prompting. Based on the visual prompts, we further design a debiased variational inference framework to model prompt uncertainty, further improving the generalization of DviT. In addition, an explicit branch-aware coupling mechanism is introduced to ensure language-to-vision prompting. We evaluate the effectiveness of DviT on three typical tasks, i.e. , generalization to novel classes, new target datasets, and unseen domain shifts. The experimental results demonstrate that DviT exhibits promising performance and enhances the model’s generalization across different datasets and domains.},
  archive      = {J_KBS},
  author       = {Feng Guo and Biao Chen and Zhongshu Chen and Zhikun Zheng and Lin Zuo and Wen Li},
  doi          = {10.1016/j.knosys.2025.113798},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113798},
  shortjournal = {Knowl. Based Syst.},
  title        = {DviT: Debiased variational inference for multi-modal mutual prompt tuning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UAV trajectory optimization for visual coverage in mobile networks using matrix-based differential evolution. <em>KBS</em>, <em>324</em>, 113797. (<a href='https://doi.org/10.1016/j.knosys.2025.113797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a novel trajectory optimization approach for an unmanned aerial vehicle (UAV) to achieve efficient visual coverage of terrestrial mobile nodes. Unlike most existing studies, we consider the node mobility and generate a continuous and smooth UAV trajectory, which more suits the practical scenario. We aim to maximize the total number of visually covered nodes during the UAV’s mission, by appropriately designing the UAV’s three-dimensional (3D) flight trajectory. To handle the infinite solution space, we first leverage the Bézier curve method to transform the continuous trajectory optimization problem into a discrete control point selection problem, reducing the computational complexity while preserving the trajectory smoothness. Then, we develop a novel UAV trajectory optimization algorithm by employing the matrix-based differential evolution (MDE) framework, which can maximize the number of visually covered nodes with the reduced computational complexity. Extensive simulation results validate the effectiveness and superiority of our approach, compared with existing arts.},
  archive      = {J_KBS},
  author       = {Riheng Jia and Hengchao Li and Peifa Sun and Zhonglong Zheng and Minglu Li},
  doi          = {10.1016/j.knosys.2025.113797},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113797},
  shortjournal = {Knowl. Based Syst.},
  title        = {UAV trajectory optimization for visual coverage in mobile networks using matrix-based differential evolution},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OH-CMH: Towards cross-modal hashing for streaming data with hierarchical labels and label increment scenario. <em>KBS</em>, <em>324</em>, 113796. (<a href='https://doi.org/10.1016/j.knosys.2025.113796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, hashing has gained increasing attention. In this paper, we study the online hierarchical hashing problem, which fits practical settings. First, in real-world applications, data may be transmitted and collected in a streaming manner. Second, labels often reflect our understanding of the real world, which may imply a label hierarchy. Despite its crucial importance and the value of investigation, online hierarchical hashing remains understudied. We propose a novel method called Online Hierarchical Cross-Modal Hashing (OH-CMH). Our method leverages the hierarchical labels of streaming data for cross-modal retrieval. Additionally, with the elaborate hybrid semantic matrix, OH-CMH can also handle the label increment problem. We conduct experiments on two popular datasets in both experimental settings—with and without label increment. Experimental results demonstrate that our method outperforms state-of-the-art approaches in terms of MAP and other evaluation metrics. Code and data are available at https://github.com/pjunjie/OH-CMH .},
  archive      = {J_KBS},
  author       = {Junjie Peng and Chong-Yu Zhang and Na Wang and Yu-Wei Zhan and Zhen-Duo Chen and Yongxin Wang and Xin Luo and Xin-Shun Xu},
  doi          = {10.1016/j.knosys.2025.113796},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113796},
  shortjournal = {Knowl. Based Syst.},
  title        = {OH-CMH: Towards cross-modal hashing for streaming data with hierarchical labels and label increment scenario},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoTE: Mixture of task-specific experts for pre-trained model-based class-incremental learning. <em>KBS</em>, <em>324</em>, 113795. (<a href='https://doi.org/10.1016/j.knosys.2025.113795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) requires deep learning models to continuously acquire new knowledge from streaming data while preserving previously learned information. Recently, CIL based on pre-trained models (PTMs) has achieved remarkable success. However, prompt-based approaches suffer from prompt overwriting, while adapter-based methods face challenges such as dimensional misalignment between tasks. While the idea of expert fusion in Mixture of Experts (MoE) can help address dimensional inconsistency, both expert and routing parameters are prone to being overwritten in dynamic environments, making MoE challenging to apply directly in CIL. To tackle these issues, we propose a mixture of task-specific experts (MoTE) framework that effectively mitigates the miscalibration caused by inconsistent output dimensions across tasks. Inspired by the weighted feature fusion and sparse activation mechanisms in MoE, we introduce task-aware expert filtering and reliable expert joint inference during the inference phase, mimicking the behaviour of routing layers without inducing catastrophic forgetting. Extensive experiments demonstrate the superiority of our method without requiring an exemplar set. Furthermore, the number of tasks in MoTE scales linearly with the number of adapters. Building on this, we further explore the trade-off between adapter expansion and model performance and propose the Adapter-Limited MoTE. The code is available at https://github.com/Frank-lilinjie/MoTE .},
  archive      = {J_KBS},
  author       = {Linjie Li and Zhenyu Wu and Yang Ji},
  doi          = {10.1016/j.knosys.2025.113795},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113795},
  shortjournal = {Knowl. Based Syst.},
  title        = {MoTE: Mixture of task-specific experts for pre-trained model-based class-incremental learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-saliency guided multi-modal learning for referring video object segmentation. <em>KBS</em>, <em>324</em>, 113786. (<a href='https://doi.org/10.1016/j.knosys.2025.113786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring video object segmentation is an emerging cross-modal task that aims to segment the target object referred to by a language expression in a video clip. Current methods often misidentify or omit referred objects due to their inability to effectively capture intricate multi-modal semantic correspondences in complex scenes. To tackle this problem, we propose a co-saliency guided multi-modal learning method for referring video object segmentation. Specifically, we introduce a co-saliency learning network to explore the co-saliency information of video frames as a prior knowledge to guide the initial localization of the referred object. In addition, we propose a multi-modal semantic alignment module and an inter-frame object interaction module. The former is designed to capture correspondences among multi-modal target instances in complex scenes, while the latter is designed to capture dynamic interaction across video frames. Guided by co-saliency information, this method efficiently aligns multi-modal semantic information and accurately captures the dynamic interaction of objects across video frames. Experimental results on mainstream benchmarks demonstrate that our method significantly improves the segmentation performance of the referred object in complex environments through co-saliency guided multi-modal learning.},
  archive      = {J_KBS},
  author       = {Ying Tong and Xiangfeng Luo and Liyan Ma and Shaorong Xie},
  doi          = {10.1016/j.knosys.2025.113786},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113786},
  shortjournal = {Knowl. Based Syst.},
  title        = {Co-saliency guided multi-modal learning for referring video object segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative pseudo-labeling based adaptive copy-paste supervision for semi-supervised tumor segmentation. <em>KBS</em>, <em>324</em>, 113785. (<a href='https://doi.org/10.1016/j.knosys.2025.113785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) has attracted considerable attention in medical image processing. The latest SSL methods use a combination of consistency regularization and pseudo-labeling to achieve remarkable success. However, most existing SSL studies focus on segmenting large organs, neglecting the challenging scenarios where there are numerous tumors or tumors of small volume. Furthermore, the extensive capabilities of data augmentation strategies, particularly in the context of both labeled and unlabeled data, have yet to be thoroughly investigated. To tackle these challenges, we introduce a straightforward yet effective approach, termed iterative pseudo-labeling based adaptive copy-paste supervision (IPA-CP), for tumor segmentation in CT scans. IPA-CP incorporates a two-way uncertainty based adaptive augmentation mechanism, aiming to inject tumor uncertainties present in the mean teacher architecture into adaptive augmentation. Additionally, IPA-CP employs an iterative pseudo-label transition strategy to generate more robust and informative pseudo labels for the unlabeled samples. Extensive experiments on both in-house and public datasets show that our framework outperforms state-of-the-art SSL methods in medical image segmentation. Ablation study results demonstrate the effectiveness of our technical contributions.},
  archive      = {J_KBS},
  author       = {Qiangguo Jin and Hui Cui and Junbo Wang and Changming Sun and Yimiao He and Ping Xuan and Linlin Wang and Cong Cong and Leyi Wei and Ran Su},
  doi          = {10.1016/j.knosys.2025.113785},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113785},
  shortjournal = {Knowl. Based Syst.},
  title        = {Iterative pseudo-labeling based adaptive copy-paste supervision for semi-supervised tumor segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BM-edit: Background retention and motion consistency for zero-shot video editing. <em>KBS</em>, <em>324</em>, 113784. (<a href='https://doi.org/10.1016/j.knosys.2025.113784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion-based generative models have achieved remarkable progress in zero-shot video editing. However, existing methods still remain two practical limitations: (1) The randomness of the diffusion model makes it difficult to maintain background invariance; (2) Due to the complexity of temporal motion, these methods struggle to achieve consistent control of the target object motion, and may suffer from frame-to-frame flickering. To address these issues, we propose a simple yet effective method called BM-Edit for zero-shot video editing. Specifically, we design an uncertainty-guided background retention mechanism based on Segment and Track Anything to achieve fine control over the background. Furthermore, in order to solve the problem of inaccurate background retention due to object target changes, we adopt a novel progressive fuzzy mask strategy to dynamically adjust the boundary of the target object. Subsequently, to ensure that the target object’s motion of the edited video remains synchronized with the source video, we establish two constraints for the motion relation in different representative spaces: Mahalanobis distance and Inter-frame difference. The former achieves accurate motion synchronization by measuring the Mahalanobis distributions of the source and target videos in the high-dimensional feature space. While the latter maintains the motion consistent by learning the frame-to-frame motion vectors in the source video from the low-dimensional feature space. In this way, our BM-Edit can achieve precise motion synchronization while retaining the background. Extensive experimental results on real-world videos demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_KBS},
  author       = {Xiang Lv and Mingwen Shao and Yecong Wan and Yue Ma and Yuanshuo Cheng and Lingzhuang Meng},
  doi          = {10.1016/j.knosys.2025.113784},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113784},
  shortjournal = {Knowl. Based Syst.},
  title        = {BM-edit: Background retention and motion consistency for zero-shot video editing},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RACE: Robust adaptive and clustering elimination for noisy labels in continual learning. <em>KBS</em>, <em>324</em>, 113783. (<a href='https://doi.org/10.1016/j.knosys.2025.113783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning (CL) aims to incrementally acquire and retain knowledge from sequential tasks while mitigating catastrophic forgetting. However, the presence of noisy labels in real-world data streams severely degrades model performance by propagating biased knowledge across tasks. Existing replay-based methods face limitations in resource-constrained and privacy-sensitive scenarios. To address this, we propose RACE, a novel replay-free framework that integrates noise-robust adaptive fine-tuning and clustering-based label correction to suppress label noise in CL dynamically. The proposed method operates in two synergistic stages: noise-robust adaptive fine-tuning and noise elimination via clustering. The former designed an adaptive cross-entropy (ACE) loss that dynamically weights samples based on prediction confidence. The latter eliminates label noise via clustering by leveraging the pre-trained model’s feature representations. Additionally, to address varying noise levels across tasks, we design a dynamic learning strategy for RACE, enabling flexible balancing of the CL model’s learning performance and efficiency in each task. Extensive experiments on both synthetic noisy datasets (CIFAR-10 and CIFAR-100) and real-world noisy datasets (WebVision and Clothing1M) demonstrate that RACE consistently outperforms existing state-of-the-art methods, particularly under high noise ratios.},
  archive      = {J_KBS},
  author       = {Xiaolong Yang and Guannan Lai and Dan Meng and Xuemei Cao and Xin Yang},
  doi          = {10.1016/j.knosys.2025.113783},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113783},
  shortjournal = {Knowl. Based Syst.},
  title        = {RACE: Robust adaptive and clustering elimination for noisy labels in continual learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust low-pass filtering graph diffusion clustering framework for hyperspectral images. <em>KBS</em>, <em>324</em>, 113782. (<a href='https://doi.org/10.1016/j.knosys.2025.113782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) clustering faces significant challenges due to spectral heterogeneity and complex spatial relationships. Although graph clustering methods enhance spatial information utilization through flexible topological modeling, their isotropic propagation mechanisms risk feature over-smoothing, and multi-layer parameter stacking leads to prohibitive computational costs. To address these limitations, we propose a Robust Low-pass Filtered Graph Diffusion Clustering framework (LFGD) for HSI featuring anisotropic dynamic diffusion and parameter-sharing architecture. Specifically, we design a Cross-Attention Graph Diffusion module (CAGD) that employs a multi-view cross-attention mechanism to integrate node features with high-order structural information into latent representations, while the graph diffusion module enables anisotropic feature propagation with dynamic topology optimization. To extract discriminative spectral features, the Discriminative Spectral Feature Extraction module (DSFE) applies a low-pass graph Laplacian filter to suppress noise interference, followed by a spectral dissimilarity matrix to amplify discriminative characteristics. We further introduce a graph self-supervised loss function to learn more robust feature representations. To our knowledge, this is the first work on hyperspectral image clustering using the graph diffusion network. Extensive experiments strongly demonstrate the effectiveness and robustness of LFGD on three public datasets. The code will be released at https://github.com/ahappyyang/LFGD .},
  archive      = {J_KBS},
  author       = {Aitao Yang and Min Li and Yao Ding and Yaoming Cai and Jie Feng and Yujie He and Yuanchao Su},
  doi          = {10.1016/j.knosys.2025.113782},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113782},
  shortjournal = {Knowl. Based Syst.},
  title        = {A robust low-pass filtering graph diffusion clustering framework for hyperspectral images},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRTNet: Dual-route transformer network for thyroid ultrasound segmentation based on bbox-supervised learning. <em>KBS</em>, <em>324</em>, 113781. (<a href='https://doi.org/10.1016/j.knosys.2025.113781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective : Accurate nodule delineation plays a significant role in the intelligent diagnosis of thyroid disease. However, the labels accessing is difficult since it is time-consuming and laborious. To mitigate the over-dependence of the segmentation accuracy on the labels, we proposed a dual-route transformer network (DRTNet) based on Bbox-supervised learning that only requires the rough bounding rectangle as labels instead of a precise boundary for thyroid ultrasound segmentation. Methods : DRTNet incorporates double-branch foreground class activation mappings (CAMs) into Transformers to combine key areas. Meanwhile, double-branch architecture dynamically adjusts the feature distribution of nodules of different sizes in frequency channels and spatial dimensions, effectively addressing the localization of nodules of different sizes. Moreover, ultrasound prior background-aware pooling (UPBAP) is proposed in both branches to deal with the ambiguous boundary of thyroid nodules. Finally, adaptive uncertainty estimate multi-scale consistency (AUEMC) is proposed to help mitigate the risk of excessive over-fitting because of pseudo annotations, which further guarantees consistency among nodules with diverse resolutions. Results : Substantial improvement of segmentation accuracy is shown on the public thyroid dataset of TN3k and DDTI dataset with Dice similarity coefficient (DSC) of 84.94% and 83.98%, with 95% of the asymmetric Hausdorff distance (HD95) of 27.69 and 29.18, respectively. And our private dataset has a DSC of 84.39% and HD95 of 14.53. Conclusions : The proposed DRTNet used rectangular box labeled for thyroid ultrasound images based on Bbox-supervised learning. The experimental results show that the DRTNet is comparable to these fully supervised methods. Code is available at https://github.com/ccjcv/DRTNet .},
  archive      = {J_KBS},
  author       = {Hui Bi and Chengjie Cai and Jiawei Sun and Shihao Ge and Huazhong Shu and Xinye Ni},
  doi          = {10.1016/j.knosys.2025.113781},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113781},
  shortjournal = {Knowl. Based Syst.},
  title        = {DRTNet: Dual-route transformer network for thyroid ultrasound segmentation based on bbox-supervised learning},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable fully attentional network for multivariate time-series forecasting. <em>KBS</em>, <em>324</em>, 113780. (<a href='https://doi.org/10.1016/j.knosys.2025.113780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanisms have achieved remarkable results across various fields of artificial intelligence. However, in the domain of time series forecasting, the performance of the transformer-based attention models has been questioned. Additionally, previous transformer-based models often lack explainability regarding the influencing variables, which hinders their broader application. To address these issues, we propose a fully attention-based model for multivariate time series forecasting that is explainable. The model comprises two components: (i) a Granger attention block that extracts Granger causality among multiple variables; and (ii) a skip attention block that substitutes the point-wise feed-forward network. To validate the effectiveness of the proposed method, we conducted extensive experiments on datasets from multiple domains. The empirical results demonstrate that our Granger causality-based fully attentional network (GFAN) significantly enhances long-term prediction accuracy compared to other transformer-based models, attributable to its full-attention framework. This underscores the contribution of the attention mechanism to the model’s predictive performance.},
  archive      = {J_KBS},
  author       = {Qilong Wu and Jian Xiao},
  doi          = {10.1016/j.knosys.2025.113780},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113780},
  shortjournal = {Knowl. Based Syst.},
  title        = {An explainable fully attentional network for multivariate time-series forecasting},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Look in different views: Multi-scheme regression guided cell instance segmentation. <em>KBS</em>, <em>324</em>, 113779. (<a href='https://doi.org/10.1016/j.knosys.2025.113779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell instance segmentation constitutes a formidable challenge that involves simultaneous detection and segmentation for individual cell within an image. A multitude of instance segmentation techniques have been applied to address this challenge. Despite notable strides, existing approaches grapple with certain limitations, particularly the accurate localization of cell center points. In scenarios involving densely packed cells, the potential for conflating multiple cells exists, while the identification of elongated cells runs the risk of erroneously recognizing them as multiple entities. To address these issues, we introduce a novel cell instance segmentation network founded on the principles of multi-scheme regression guidance. Our proposed network leverages the versatility of multi-scheme regression guidance, enabling a comprehensive analysis of each cell from multiple perspectives. Specifically, a Gaussian guidance attention mechanism is meticulously crafted to harness Gaussian labels, directing the network’s attention effectively. Subsequently, a point-regression module is integrated to facilitate the precise regression of cell centers. Finally, the outputs from the aforementioned modules were utilized to further bootstrap the instance segmentation process, thereby enhancing its performance. The multi-scheme regression guidance strategy empowers us to harness the distinguishing attributes of different cell regions, notably the central cell region. Thorough experimentation across five benchmark datasets underscores the potency of our approach. Our model outperforms the previous state-of-the-art (SOTA) method by margins of 1.2% and 2.3% (AP50) on DSB2018 and CA2.5, respectively. Similarly, our method surpasses the prior SOTA by 1.5% (AJI) on MoNuSeg and 0.3% lower on CPM17. Notably, our method exhibits a substantial performance leap, boasting a 3.0% higher AP50 on SCIS. These encouraging results collectively demonstrate the effectiveness of our approach. Furthermore, our approach’s interpretability is substantiated through visualization and comprehensive analysis. The source code is available at https://github.com/cv516Buaa/MSRNet .},
  archive      = {J_KBS},
  author       = {Yunmeng Huang and Wenquan Feng and Shuchang Lyu and Guangliang Cheng and Qi Zhao and Lin Li and Lijiang Chen},
  doi          = {10.1016/j.knosys.2025.113779},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113779},
  shortjournal = {Knowl. Based Syst.},
  title        = {Look in different views: Multi-scheme regression guided cell instance segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A foundation model-based framework for unsupervised gaze anomaly detection. <em>KBS</em>, <em>324</em>, 113774. (<a href='https://doi.org/10.1016/j.knosys.2025.113774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional gaze analysis methods for online lecture largely depend on predefined average gaze features and self-reported ground-truths, limiting their ability to obtain real-time status in unsupervised settings. To address this, we propose Gaze-READ (Gaze Representative Embedding and Anomaly Detection), a framework that integrates gaze behavior analysis with unsupervised anomaly detection to systematically identify attention shifts caused by external stimuli. Our approach leverages GazeMTM (Masked Time-Series Modeling of Gaze), which employs MOMENT, a time-series foundation model, to extract gaze embeddings that capture temporal dependencies in eye movements. We establish a baseline for normal gaze behavior using a control group (students without distractions) and apply unsupervised clustering to define representative gaze patterns. By comparing this baseline with gaze data from students exposed to distractors, Gaze-READ detects deviations, flagging them as potential indicators of distraction. Experimental results show that MOMENT GET (further pre-trained MOMENT) improves gaze reconstruction, reducing mean squared error (MSE) by at least 28% compared to its pre-trained version and outperforming baseline linear interpolation for oculomotor event representation. Additionally, Gaze-READ achieves a higher clustering silhouette score (0.38) and a lower Davies–Bouldin Index (0.88) than traditional time-series clustering methods, demonstrating its effectiveness in distinguishing gaze patterns. These findings highlight the potential of our framework to enable automated, real-time engagement tracking in online learning environments, offering a scalable solution for identifying attentional shifts without requiring labeled data.},
  archive      = {J_KBS},
  author       = {Kritika Johari and Jung-Jae Kim and Wei Quin Yow and U-Xuan Tan},
  doi          = {10.1016/j.knosys.2025.113774},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113774},
  shortjournal = {Knowl. Based Syst.},
  title        = {A foundation model-based framework for unsupervised gaze anomaly detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NDRIDC: NMF-based deep representation algorithm for incomplete data clustering. <em>KBS</em>, <em>324</em>, 113771. (<a href='https://doi.org/10.1016/j.knosys.2025.113771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete data clustering is a hot research topic in the field of data mining. Many methods based on incomplete clustering have two issues: (1) their models do not have non-negative constraints; (2) their model building strategies do not consider combining traditional machine learning and deep learning. To address these issues, we proposed the NMF-based deep representation algorithm for incomplete data clustering (NDRIDC). First, the element-based objective function is constructed based on the known elements in the incomplete data matrix with matrix factorization principle. Then the NDRIDC deep network is constructed based on the element update gradient and nonlinear function with non-negative value domain. The learning of the NDRIDC network enables the optimization of the objective function and the filling of missing values. Further, based on the same learning framework, the NDRIDC network is employed to perform low-dimensional representation of the filled matrix. Finally, extensive experiments on regular and large-scale datasets show that our proposed algorithm has good performance.},
  archive      = {J_KBS},
  author       = {Dexian Wang and Zonglin Li and Sha Yang and Tianrui Ren and Pengfei Zhang and Ping Deng and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113771},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113771},
  shortjournal = {Knowl. Based Syst.},
  title        = {NDRIDC: NMF-based deep representation algorithm for incomplete data clustering},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiaDNN: Siamese deep neural network for anomaly detection in user behavior. <em>KBS</em>, <em>324</em>, 113769. (<a href='https://doi.org/10.1016/j.knosys.2025.113769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, insider threat detection become a very challenging task as the identification of anomalies from log data is a complex process. Insider threats are unusual activities raised by authorized users. When compared to the external network attack, the insider threats are much lower and the detection of these malicious behavior is a difficult process. The conventional schemes focus on rule-based approaches but are not flexible and robust. User behavior modelling is essential for this anomaly identification. Thus, this paper proposed an effective approach, the Siamese Deep Neural Network (SiaDNN) for detecting anomalies based on user behavior. Here, the SiaNN is designed by the incorporation of Siamese Convolution Neural Network (SCNN) and Deep Neural Network (DNN). At first, the log file is fed to the user behavior features extraction module, where the administrator, authentication, and comments are extracted. Then, the extracted features are encoded and considered for the evaluation of user behavior patterns. Here, the Frequent Pattern Growth (FP growth algorithm) is used for analyzing user behavior patterns. Subsequently, the proposed SiaDNN is used for conducting Anomaly Detection (AD) based on user behavior. The evaluation results show that the SiaDNN accomplished accuracy, False Positive Rate (FPR), and True Positive Rate (TPR) as 91.136 %, 7.300 %, and 90.703 %. The high-performance results achieved by the devised model indicate that the model is highly robust in identifying anomalous requests correctly based on user behavior. The high accuracy rate indicates that the devised model maintains system integrity and trustworthiness in real-time web services.},
  archive      = {J_KBS},
  author       = {Tejas Patel and Sailesh Suryanarayan Iyer},
  doi          = {10.1016/j.knosys.2025.113769},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113769},
  shortjournal = {Knowl. Based Syst.},
  title        = {SiaDNN: Siamese deep neural network for anomaly detection in user behavior},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairDLA: Improving the fairness-utility trade-off in graph neural networks via dual-level alignment. <em>KBS</em>, <em>324</em>, 113768. (<a href='https://doi.org/10.1016/j.knosys.2025.113768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have paid increasing attention to the fairness issue of graph neural networks (GNNs), which may exhibit discriminatory decision-making for certain groups defined by sensitive attributes such as gender or race. Existing fairness methods on graphs, explicitly or implicitly aligning overall representations among sensitive attribute groups, have made significant progress. However, they fall short in the trade-off between fairness and utility due to overlooking the task subgroup alignment. To address this issue, we propose FairDLA, a fairness-aware GNN framework based on Dual-level Alignment (DLA), including alignment at both sensitive attribute group level and task subgroup level. Firstly, FairDLA disentangles node representations into bias-aware and task-aware components, reducing their mutual interference and thus paving the way for effective DLA. Secondly, FairDLA performs DLA to improve fairness through sensitive attribute group level alignment while preserving utility through task subgroup level alignment. Experiments conducted on five real-world datasets demonstrate that FairDLA achieves a superior trade-off between fairness and utility compared to other state-of-the-art methods. The codes are available at https://github.com/zhenying123/FairDLAnew.git},
  archive      = {J_KBS},
  author       = {Ying Zhen and Yuchang Zhu and Jintang Li and Liang Chen},
  doi          = {10.1016/j.knosys.2025.113768},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113768},
  shortjournal = {Knowl. Based Syst.},
  title        = {FairDLA: Improving the fairness-utility trade-off in graph neural networks via dual-level alignment},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in online credit card data using optimized multi-view heterogeneous graph neural networks. <em>KBS</em>, <em>324</em>, 113767. (<a href='https://doi.org/10.1016/j.knosys.2025.113767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting credit card fraud in real-time has become increasingly important with the rise of electronic transactions. However, existing methods often fail to deliver high accuracy and robustness due to class imbalance and overlapping features. To address these issues, Anomaly Detection in Online Credit Card data using Optimized Multi-view Heterogeneous Graph Neural Networks (AD-OCCD-MHGNN) is proposed. The method begins by applying Fair Synthetic Minority Oversampling Technique (FSMOTE) to balance the dataset. The Multi-observation Fusion Kalman Filter (MFKF) is used to handle missing values and duplicate data. Snow Avalanches Algorithm (SAA) is employed to select the most relevant features. The selected features are fed to Multi-view Heterogeneous Graph Neural Networks (MHGNN) for effectively detecting the online credit card data as fraud and non-fraud. Then MHGNNs parameters are fine-tuned using the Quantum Artificial Hummingbird Algorithm (QAHA). The experimental results on the Credit Card Fraud (CCF) dataset demonstrate that the proposed model significantly outperforms existing methods by achieving 25.60 %, 24.01 % and 26.60 % higher accuracy; 22.45 %, 30.01 % and 26.68 % higher precision; and 28.89 %, 30.65 % and 26.60 % higher f1 score when compared to the existing models. These outcomes demonstrate the frameworks effectiveness for robust and real-time fraud detection in highly imbalanced environments.},
  archive      = {J_KBS},
  author       = {T John Berkmans and S Karthick},
  doi          = {10.1016/j.knosys.2025.113767},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113767},
  shortjournal = {Knowl. Based Syst.},
  title        = {Anomaly detection in online credit card data using optimized multi-view heterogeneous graph neural networks},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-enhanced graph contrastive learning for multimodal recommendation systems. <em>KBS</em>, <em>324</em>, 113766. (<a href='https://doi.org/10.1016/j.knosys.2025.113766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation systems enhance recommendation accuracy through the fusion of different types of information. Graph Contrastive Learning (GCL) has recently been widely applied in recommendation systems. However, the application of GCL mainly focuses on general user–item interactions, and few models apply it to multimodal information learning. This limitation may hinder the full potential of GCL in more complex multimodal scenarios. To address this issue, we propose a N oise- E nhanced G raph C ontrastive L earning for Multimodal Recommendation Systems (NEGCL). As different data augmentation strategies yield distinct outcomes in GCL, we have examined their relative strengths and weaknesses. Introducing innovative contrastive learning into the multimodal information extraction process helps address the limitations of this method in multimodal recommendation, supplemented by an improved transformer for learning in general interactions. A longitudinal comparison of contrastive learning across different methods reveals that noise-based contrastive learning substantially reduces the additional overhead potentially introduced by data augmentation. Furthermore, the introduction of appropriate noise allows contrastive learning to develop more robust nodes. Extensive experiments on three public datasets reveal that NEGCL surpasses previous benchmark models, achieving performance improvements ranging from 8.46% to 11.62% on the Clothing dataset. The source code is publicly available at https://github.com/HubuKG/NEGCL .},
  archive      = {J_KBS},
  author       = {Ke Shi and Yan Zhang and Miao Zhang and Kui Xiao and Xiaoju Hou and Zhifei Li},
  doi          = {10.1016/j.knosys.2025.113766},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113766},
  shortjournal = {Knowl. Based Syst.},
  title        = {Noise-enhanced graph contrastive learning for multimodal recommendation systems},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double relaxed broad learning system for image classification. <em>KBS</em>, <em>324</em>, 113765. (<a href='https://doi.org/10.1016/j.knosys.2025.113765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Broad Learning System (BLS), as a prominent network paradigm, has garnered significant attention across various domains in machine learning due to its remarkable efficiency and impressive performance. Nevertheless, two deficiencies exist when its variants are applied to supervised image classification tasks. First, they generally rely on rigid binary labels, which restricts the approximation procedure and fails to find the best classification margins. Second, using a single transformation matrix in graph-regularized BLS struggles to mitigate the overfitting problem. In this article, we focus on offering more freedom to the graph regularized BLS to explore appropriate margins between samples. Specifically, we learn the adaptive labels from data, and a marginalized constraint is implemented to enhance the distinguishability of the learned labels simultaneously. Subsequently, two distinct transformation matrices are employed for the graph embedding process, with the addition of a novel matrix designed to capture the similar structure between the transformations. The intra-class compactness of samples can be assured through experimental verification. Hence, a novel method named double relaxed BLS (DRBLS) is proposed. Further, with the help of the alternating direction method of multipliers, an efficient iterative approach is developed to find the closed-form solution. Experiments on diverse image classification tasks are conducted to certify the effectiveness of our method compared to state-of-the-art algorithms.},
  archive      = {J_KBS},
  author       = {Zhenhao Qin and Dengxiu Yu and Junwei Jin and C.L. Philip Chen},
  doi          = {10.1016/j.knosys.2025.113765},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113765},
  shortjournal = {Knowl. Based Syst.},
  title        = {Double relaxed broad learning system for image classification},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond EHRs: External clinical knowledge and cohort features for medication recommendation. <em>KBS</em>, <em>324</em>, 113763. (<a href='https://doi.org/10.1016/j.knosys.2025.113763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication recommendation plays an important role in healthcare by supporting clinical decision-making, while rich clinical experiences and knowledge are key factors that contribute to the success of this task. However, existing methods still face certain limitations: the acquisition of clinical experience is confined to the historical records of an individual patient, and encoded clinical knowledge is typically used as coarse auxiliary information to enhance encoded records. To address these limitations, we propose the EX ternal C linical knowl E dge and coho R t F eatures (EXCERF) model for the recommendation task. EXCERF constructs an external Memory Neural Network shared across all patients to capture cohort features tailored to specific patient groups, allowing patients to access relevant clinical experiences distributed across a large cohort. Then the model incorporates clinical knowledge tuples as additional biases to refine interactions between clinically related entities within the self-attention mechanism, concurrently considering detailed clinical and semantic knowledge to build patient representations. Finally, EXCERF integrates representations of multiple admissions with GRU to generate the final recommendation. Experimental results on real-world clinical records demonstrates that EXCERF achieves superior performance and facilitates effective medication recommendation.},
  archive      = {J_KBS},
  author       = {Yanda Wang and Weitong Chen and Lin Yue and Ian Nabney and Dechang Pi},
  doi          = {10.1016/j.knosys.2025.113763},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113763},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond EHRs: External clinical knowledge and cohort features for medication recommendation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of triple extraction and RDF generation using boosted BERT fused attention convolutional bi-directional LSTM with optimization. <em>KBS</em>, <em>324</em>, 113756. (<a href='https://doi.org/10.1016/j.knosys.2025.113756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge and expertise are the two most frequent ways of sharing information in a structured manner. A depth of knowledge is typically made up of triples of Resource Description Frameworks (RDF) that characterize the entities and their relationships. Some of the current limitations include higher computational costs, longer execution times, and more complexity in achieving better results. The machine learning based techniques generate lower performance compared to deep learning approaches. Initially, the data are collected using BBC News, Kaggle, and Lonely Planet datasets. After the collection of data, pre-processing steps like data cleaning, Parts of Speech (PoS) tagging, tokenization, stop word removal, and stemming are applied to the data to enhance further performance. The entity and attribute features are extracted by Boosted Bidirectional Encoder Representations from Transformers (B-BERT). The classification can be performed using fused attention with a convolutional Bidirectional LSTM (AcBL) approach. An improved Bald Eagle Search Optimization (EBesO) algorithm is used to optimize the loss derived from the classification phase to improve model accuracy. The overall performance outcomes of the proposed method attain 99.1 % accuracy on BBC, 99.7 % accuracy on Kaggle, and 99 % accuracy on Lonely Planet. The proposed technique acquires 97.9 % precision on BBC, 98.7 % precision on Kaggle, and 97.9 % precision on Lonely Planet. The F1 score of the proposed methodology accomplishes 97.9 % on BBC, 98.6 % on Kaggle, and 97.8 % on Lonely Planet. Recall that the proposed model achieves 98 % on BBC, 98.5 % on Kaggle, and 97.6 % on Lonely Planet.},
  archive      = {J_KBS},
  author       = {Rubaya Khatun and Arup Sarkar},
  doi          = {10.1016/j.knosys.2025.113756},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113756},
  shortjournal = {Knowl. Based Syst.},
  title        = {Classification of triple extraction and RDF generation using boosted BERT fused attention convolutional bi-directional LSTM with optimization},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdapFedRec: A framework for enhanced federated recommendations with adaptive client aggregation and sampling. <em>KBS</em>, <em>324</em>, 113754. (<a href='https://doi.org/10.1016/j.knosys.2025.113754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of internet technologies highlights the need for efficient information management. Recommendation systems have become crucial, particularly for generating personalized content based on user interactions. However, conventional centralized systems face significant privacy challenges due to the aggregation and storage of user data. This study introduces AdapFedRec, a federated recommendation system framework that enhances privacy and system performance. This framework incorporates an advanced negative sampling approach using cluster analysis for more balanced feature distribution, an interactive clustering weighted method for client-weighted aggregation, and an adaptive differential privacy technique that adjusts noise levels dynamically according to data sensitivity. We evaluated the effectiveness of AdapFedRec using diverse datasets, demonstrating significant improvements in recommendation accuracy and privacy protection compared to traditional methods. The findings suggest that AdapFedRec not only addresses key privacy concerns but also enhances the ability of recommendation systems to deliver personalized content effectively, thus offering substantial theoretical and practical contributions to the field of secure and efficient recommendation systems. Moreover, the adaptable nature of AdapFedRec makes it suitable for application in other recommendation domains, such as e-commerce and healthcare. Its design principles address common challenges like handling high-dimensional and sparse data, which are prevalent in both our experimental datasets and real-world applications. In e-commerce, AdapFedRec’s dynamic negative sampling efficiently distinguishes user preferences, while its adaptive differential privacy ensures robust protection for sensitive data like patient records in healthcare. The framework’s modular architecture allows seamless integration into various recommendation scenarios with minimal modification, ensuring scalability and flexibility across domains.},
  archive      = {J_KBS},
  author       = {Jie He and Xiao Song and Ming Liu and Yong Li},
  doi          = {10.1016/j.knosys.2025.113754},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113754},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdapFedRec: A framework for enhanced federated recommendations with adaptive client aggregation and sampling},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating local and global correlations with mamba-transformer for multi-class anomaly detection. <em>KBS</em>, <em>324</em>, 113740. (<a href='https://doi.org/10.1016/j.knosys.2025.113740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection (UAD) tasks play a vital role in detecting anomaly features from industrial data, and handling these tasks can improve the quality and efficiency of industrial production. Although the transformer-based reconstruction techniques have demonstrated remarkable successes in UAD, their efficacy is still constrained by the quadratic computational complexity and the absence of local information extracted by the convolutional module. To address these issues, this paper proposes a Mamba-Transformer based method (named MTAD) for multi-class anomaly detection. The MTAD method aims to leverage the strengths of Mamba’s long-range modeling capabilities and linear efficiency, while integrating local information into the reconstruction process. To integrate the local information with global information, this paper proposes a MTRec block as the core module of the Mamba-Transformer decoder. Specifically, the MTRec block employs a novel Mamba-Transformer block to reconstruct the global window-partition features, and employs a convolutional module to fuse the global information and local information. Additionally, the Mamba-Transformer block incorporates Mamba block and linear attention module to enhance the global modeling capability and address the quadratic complexity issue. Moreover, the Mamba block arranges and rearranges the feature tokens by a selected scanning method to improve the position-awareness of the model and maintain the spatial continuity. Finally, the reconstructed multi-scale features are aggregated to calculate reconstruction errors with more refined prediction accuracy. Experimental results demonstrate that the proposed method is effective and can surpass the state-of-the-art methods. Code is available at: https://github.com/Mazeqi/MTAD-KBS},
  archive      = {J_KBS},
  author       = {Zeqi Ma and Jiaxing Li and Kaihang Jiang and Wai Keung Wong},
  doi          = {10.1016/j.knosys.2025.113740},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113740},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating local and global correlations with mamba-transformer for multi-class anomaly detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMBD: Backdoor defense via large language model paraphrasing and data voting in NLP. <em>KBS</em>, <em>324</em>, 113737. (<a href='https://doi.org/10.1016/j.knosys.2025.113737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of natural language processing (NLP), backdoor attacks have emerged as a significant security threat. These attacks inject malicious triggers into NLP models, causing them to produce adversarial output while remaining functional under normal input. To eliminate backdoors, existing data-driven defense methods typically transform backdoored samples into normal samples. However, these defenses lack the scalability to adapt effectively to various backdoor attacks. To address this challenge, we propose LLMBD, a novel data-driven backdoor defense method that leverages large language models (LLMs) for paraphrasing. Specifically, LLMBD uses large language models with optimized prompts to paraphrase the input text, eliminating potential backdoors while maintaining semantic integrity and textual fluency. During the training and inference phase, we apply grouping and major voting mechanisms to bypass residual backdoors in the paraphrased dataset. Finally, we validate the robustness and defense effectiveness of LLMBD through comprehensive model evaluations. Experimental results on datasets including SST-2, IMDB, and HSOL under various backdoor attack types (BadNets, AddSent, Synbkd, Stylebkd) show that LLMBD significantly outperforms existing methods such as RAP, STRIP, ParaFuzz, and TextGuard. On the SST-2, HSOL, and IMDb datasets, LLMBD achieves an average ASR drop of 0.278, with the average CACC maintained at 0.897. LLMBD exhibits superior robustness, generalization, and performance preservation without modifications to the backdoored model, providing an efficient and model-agnostic defense strategy against diverse backdoor threats.},
  archive      = {J_KBS},
  author       = {Fei Ouyang and Di Zhang and Chunlong Xie and Hao Wang and Tao Xiang},
  doi          = {10.1016/j.knosys.2025.113737},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113737},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLMBD: Backdoor defense via large language model paraphrasing and data voting in NLP},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMAM: Difficulty-enhanced multi-view attention-based model for knowledge tracing. <em>KBS</em>, <em>324</em>, 113736. (<a href='https://doi.org/10.1016/j.knosys.2025.113736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) models the evolution of learners’ knowledge states through learners’ learning interaction sequences with questions corresponding to various knowledge concepts (KCs). Recently, some KT studies have demonstrated that Attention-based KT models achieve good performance. In our research, we observed that a group effect that existing researches often overlook, and taking the group effect into account may enhance the performance of KT models. Additionally, difficulties of questions can be used to enhance KT model performance. However, existing difficulty-enhanced strategies merge difficulties into knowledge states by simply concatenating their representations, or by simple weighted summation, which may be too simplistic. To address these issues, we propose a new KT model named Difficulty-enhanced Multi-view Attention-based Model (DMAM) for KT, which integrates a Multi-view Attention (MVA) mechanism and an Adaptive Difficulty-enhanced Strategy (ADS). Specifically, MVA generates a new group sequence to represent latent patterns inherent in the group-view and then captures dependencies from both the original sequence and the group sequence, which enables the model to leverage information from the element-view and the group-view, simultaneously. To further enhance the model’s performance, ADS applies feature transformation to extract representations of difficulties of questions and knowledge states, then a sigmoid function is employed to model their complex relations. Finally, adaptive weights are learned to merge these features dynamically. Extensive experiments conducted on four widely used KT datasets demonstrate that DMAM outperforms existing KT models.},
  archive      = {J_KBS},
  author       = {Xiaohan Jiang and Bo Yang and Wei Liu},
  doi          = {10.1016/j.knosys.2025.113736},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113736},
  shortjournal = {Knowl. Based Syst.},
  title        = {DMAM: Difficulty-enhanced multi-view attention-based model for knowledge tracing},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-class separable anchor concept factorization on bipartite graph. <em>KBS</em>, <em>324</em>, 113734. (<a href='https://doi.org/10.1016/j.knosys.2025.113734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept factorization (CF) has gained significant attention in recent years due to its ability to uncover latent structures in data. However, existing CF methods often suffer from excessive computational complexity, typically exhibiting at least quadratic complexity in sample size, which hinders their applicability to large-scale datasets. Additionally, these methods often fail to fully exploit the group structure inherent in the coefficient matrices, limiting their effectiveness in tasks such as clustering and classification. In this paper, we propose a novel and efficient concept factorization method, termed Inter-class Separable Anchor Concept Factorization on Bipartite Graph (ISA-CF), which addresses these limitations. The proposed method achieves linear complexity in both sample size and feature dimension, making it highly scalable and suitable for large-scale data applications. Specifically, ISA-CF enhances inter-class separability of the factor matrices through a sample-anchor-based inter-class separability embedding while simultaneously promoting the grouping structure of the factor matrices within a bipartite graph. Furthermore, we introduce an orthogonal constraint on the coefficient matrix, which not only improves the interpretability of the model but also provides a direct clustering interpretation. Extensive experiments conducted on multiple datasets demonstrate the superior performance of ISA-CF in terms of both clustering accuracy and computational efficiency. The scalability and efficiency of ISA-CF highlight its potential for real-world applications involving massive datasets.},
  archive      = {J_KBS},
  author       = {Pengfei Zhang and Guiyuan Jiang and Kehan Kang and Junyu Dong and Chong Peng},
  doi          = {10.1016/j.knosys.2025.113734},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113734},
  shortjournal = {Knowl. Based Syst.},
  title        = {Inter-class separable anchor concept factorization on bipartite graph},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuCGRN: A dual context-aware model for gene regulatory network prediction from ScRNA-seq data. <em>KBS</em>, <em>324</em>, 113724. (<a href='https://doi.org/10.1016/j.knosys.2025.113724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene Regulatory Networks (GRNs) are crucial for understanding the intricate interactions and analyzing the regulatory mechanisms driving cellular processes. Despite their importance, experimentally validated regulatory interactions remain limited. Furthermore, inferring gene regulatory relationships is inherently challenging due to the presence of indirect interactions, feedback loops, and combinatorial regulation that involve multiple genes. The advent of single-cell RNA sequencing (scRNA-seq) has revolutionized our ability to obtain high-resolution gene expression profiles, providing unprecedented insights into cellular heterogeneity. In this work, we present a novel dual context-aware model for inferring GRNs called DuCGRN. Our approach models validated regulatory interactions as a graph, and leverages single-cell sequencing data to predict unknown regulatory relationships. DuCGRN employs a K-hop aggregation mechanism with multiscale feature extraction, implemented through Graph Neural Networks, to enhance the model’s ability to capture intricate regulatory signals. The K-hop aggregator allows the model to incorporate both immediate and distant regulatory signals by aggregating the influence of multi-hop gene neighbors. Meanwhile, the multiscale feature extractor captures the effects of diverse regulatory mechanisms on target genes. By combining the mechanisms with adversarial training, DuCGRN infers more accurate gene regulatory relationships. Experimental results on seven real-world scRNA-seq datasets demonstrate that DuCGRN effectively learns complex gene regulatory interactions, offering a valuable tool for unraveling the intricate regulatory landscapes underlying cellular processes.},
  archive      = {J_KBS},
  author       = {Dingkui Dong and Weihua Li},
  doi          = {10.1016/j.knosys.2025.113724},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113724},
  shortjournal = {Knowl. Based Syst.},
  title        = {DuCGRN: A dual context-aware model for gene regulatory network prediction from ScRNA-seq data},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain tumor segmentation using optimized depth wise separable convolutional neural network with dense U-net. <em>KBS</em>, <em>324</em>, 113678. (<a href='https://doi.org/10.1016/j.knosys.2025.113678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate brain tumors segmentation of from magnetic resonance imaging (MRI) is essential for the detection of brain cancer, treatment decision and the observation of therapeutic outcomes in patients. Traditional segmentation methods are time-consuming, subjective, and less accurate. Therefore, a reliable automated brain tumor segmentation technique is needed to help radiologists make better decisions. In this paper, Brain tumor segmentation using optimized depth wise separable convolutional neural network with Dense U-Net (BTS-ODSCNN-DU-Net) is proposed. Initially, the input MRI images are amassed from BraTS dataset and the cancer imaging archive data collections (TCIA). The input image is pre-processed by Gaussian filter to eliminate unwanted noises and smoothen the image. The multi scale patch extraction method is employed to extract the statistical features from the pre-processed image. Then, the depth wise separable convolutional neural network with Dense U-Net (DSCNN-DU-Net) is employed for segmenting the image as Enhancing Tumor (ET), Tumor Core (TC) and Whole Tumor (WT). Finally, African vulture optimization algorithm (AvOA) is utilized to optimize the parameter of DSCNN-DU-Net. The BTS-ODSCNN-DU-Net method attains 32.34%, 25.95%, and 33.91% higher dice similarity index and, 32.46%, 27.91% and 25.88% lower Computation time compared with existing approaches, like DFP-Res U Net: convolutional neural network and dilated convolutional feature pyramid for multi model brain tumor segmentation (DFP-ResUNet), K-means clustering based brain tumor segmentation utilizing deep learning and synthetic data augmentation (BTS-KC-DL), and densely connected residual networks with the help of ASPP for brain tumor segmentation (RD2A-BTS) respectively.},
  archive      = {J_KBS},
  author       = {K.G. Revathi and C.P. Shirley and S. Sreethar and Ezhilarasi P},
  doi          = {10.1016/j.knosys.2025.113678},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113678},
  shortjournal = {Knowl. Based Syst.},
  title        = {Brain tumor segmentation using optimized depth wise separable convolutional neural network with dense U-net},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable medical visual question answering via chain of evidence. <em>KBS</em>, <em>324</em>, 113672. (<a href='https://doi.org/10.1016/j.knosys.2025.113672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Visual Question Answering (MedVQA) has delivered success in healthcare, aiming to answer questions about clinical findings from medical images. However, developing models that are evidence-based and can precisely interpret decision-making with medical knowledge remains a crucial objective. To address these challenges, we reframe the MedVQA problem as a task of generating evidence, which is intrinsically consistent with the medical diagnostic interaction process. We introduce Med-CoE, a framework that leverages the chain-of-thought capacity of LLMs along with medical knowledge sources to address the explanation gap in MedVQA tasks. Med-CoE establishes an evidence verification and interpretation mechanism under a three-stage training process with medical knowledge grounding. We pre-train our model on the PMC-OA corpus and generate auto-labeling Chain of Evidences via LLMs prompt and then fine-tune Med-CoE on two benchmarks. Experimental findings show that Med-CoE outperforms state-of-the-art methods by a large margin, e.g., 10.7% on direct-answer task of PMC-VQA and 4.0% on SLAKE.},
  archive      = {J_KBS},
  author       = {Chen Qiu and Ke Huang and Zhiqiang Xie and Maofu Liu and Jinguang Gu and Xiaofen Zong},
  doi          = {10.1016/j.knosys.2025.113672},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113672},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainable medical visual question answering via chain of evidence},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDFP: Data-dependent frequency prompt for source free domain adaptation of medical image segmentation. <em>KBS</em>, <em>324</em>, 113651. (<a href='https://doi.org/10.1016/j.knosys.2025.113651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation addresses the challenge of model performance degradation caused by domain gaps. In the typical setup for unsupervised domain adaptation, labeled data from a source domain and unlabeled data from a target domain are used to train a target model. However, access to labeled source domain data, particularly in medical datasets, can be restricted due to privacy policies. As a result, research has increasingly shifted to source-free domain adaptation (SFDA), which requires only a pretrained model from the source domain and unlabeled data from the target domain data for adaptation. Existing SFDA methods often rely on domain-specific image style translation and self-supervision techniques to bridge the domain gap and train the target domain model. However, the quality of domain-specific style-translated images and pseudo-labels produced by these methods still leaves room for improvement. Moreover, training the entire model during adaptation can be inefficient under limited supervision. In this paper, we propose a novel SFDA framework to address these challenges. Specifically, to effectively mitigate the impact of domain gap in the initial training phase, we introduce preadaptation to generate a preadapted model, which serves as an initialization of target model and allows for the generation of high-quality enhanced pseudo-labels without introducing extra parameters. Additionally, we propose a data-dependent frequency prompt to more effectively translate target domain images into a source-like style. To further enhance adaptation, we employ a style-related layer fine-tuning strategy, specifically designed for SFDA, to train the target model using the prompted target domain images and pseudo-labels. Extensive experiments on cross-modality abdominal and cardiac SFDA segmentation tasks demonstrate that our proposed method outperforms existing state-of-the-art methods. Our code is available online.},
  archive      = {J_KBS},
  author       = {Siqi Yin and Shaolei Liu and Manning Wang},
  doi          = {10.1016/j.knosys.2025.113651},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113651},
  shortjournal = {Knowl. Based Syst.},
  title        = {DDFP: Data-dependent frequency prompt for source free domain adaptation of medical image segmentation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompting large language models with knowledge graphs for question answering involving long-tail facts. <em>KBS</em>, <em>324</em>, 113648. (<a href='https://doi.org/10.1016/j.knosys.2025.113648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Large Language Models (LLMs) are effective in performing various NLP tasks, they still struggle to handle tasks that require extensive, real-world knowledge, especially when dealing with long-tail facts (facts related to long-tail entities). This limitation highlights the need to supplement LLMs with non-parametric knowledge. To address this issue, we analysed the effects of different types of non-parametric knowledge, including textual passage and knowledge graphs (KGs). Since LLMs have probably seen the majority of factual question-answering datasets already, to facilitate our analysis, we proposed a fully automatic pipeline for creating a benchmark that requires knowledge of long-tail facts for answering the involved questions. Using this pipeline, we introduce the LTGen benchmark. We evaluate state-of-the-art LLMs in different knowledge settings using the proposed benchmark. Our experiments show that LLMs alone struggle with answering these questions, especially when the long-tail level is high or rich knowledge is required. Nonetheless, the performance of the same models improved significantly when they were prompted with non-parametric knowledge. We observed that, in most cases, prompting LLMs with KG triples surpasses passage-based prompting using a state-of-the-art retriever. In addition, while prompting LLMs with both KG triples and documents does not consistently improve knowledge coverage, it can dramatically reduce hallucinations in the generated content.},
  archive      = {J_KBS},
  author       = {Wenyu Huang and Guancheng Zhou and Mirella Lapata and Pavlos Vougiouklis and Sebastien Montella and Jeff Z. Pan},
  doi          = {10.1016/j.knosys.2025.113648},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113648},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prompting large language models with knowledge graphs for question answering involving long-tail facts},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive system for single pilot operations triggered by human–machine system performance model. <em>KBS</em>, <em>324</em>, 113647. (<a href='https://doi.org/10.1016/j.knosys.2025.113647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by both economy and technology, single pilot operation (SPO) will be possible in commercial air transportation in the future. In order to maximize the economic benefits brought by SPO, adaptive automation has become a hot spot in current SPO research. Therefore, this paper developed an adaptive system for SPO based on the human–machine system (HMS) performance model trigger. To avoid the uncertainty of performance prediction caused by the subjectivity of analysts and individual differences between operators, this paper adopted the Bayesian network (BN) method to predict HMS performance. This paper firstly designed the SPO adaptive system, which includes the Bayesian network model, adaptive trigger algorithm, and adaptive decision-making algorithm, secondly identified the conditional probability distributions (CPDs) between nodes to achieve the prediction of HMS performance, and finally completed the verification and validation of BN to ensure the credibility of the HMS performance prediction results. To verify the feasibility of the adaptive system, this paper conducted three case studies. The research results show that the adaptive system can assist an onboard single pilot to complete the nominal flight scenarios, most of the environmental off-nominal flight scenarios, and a few system off-nominal flight scenarios by changing the level of automation (LOA).},
  archive      = {J_KBS},
  author       = {Min Li and Yue Luo and Miao Wang and Guoqing Wang},
  doi          = {10.1016/j.knosys.2025.113647},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113647},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive system for single pilot operations triggered by human–machine system performance model},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intent-driven multi-level augmentation with contrastive learning for sequential recommendation. <em>KBS</em>, <em>324</em>, 113606. (<a href='https://doi.org/10.1016/j.knosys.2025.113606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to learn users’ historical behavior to predict items for future interactions. Existing approaches combine deep and contrastive learning to mitigate data sparsity. However, most sequential recommendation methods model from the perspective of items, ignoring the latent intent of the model user. In addition, the current stochastic sequence augmentation introduces significant noise, limiting the model’s ability to fully explore potential user intent. This paper proposes a new framework for multi-level augmentation and noise-balanced sequential recommendation from the user’s latent intent perspective, called Intent-Driven Multi-level Augmentation with Contrastive Learning for Sequential Recommendation (IDMARec). Specifically, we design a data generator with item-specific prompts to generate fake items closer to user preferences to augment the original data. We propose a latent intent learning module to capture users’ latent intents more accurately. Furthermore, a contrastive generative adversarial network module is proposed to optimize the data generator, which can balance the data sparsity and noise problems and improve the model performance. Extensive experimental results on four public datasets validate the superiority of IDMARec over state-of-the-art models. Our code is available at https://github.com/nishawn/IDMARec .},
  archive      = {J_KBS},
  author       = {Shuang Ni and Wei Zhou and Fengji Luo and Yihao Zhang and Jun Zeng and Junhao Wen},
  doi          = {10.1016/j.knosys.2025.113606},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113606},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intent-driven multi-level augmentation with contrastive learning for sequential recommendation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning opposite prompts for weakly supervised video anomaly detection. <em>KBS</em>, <em>324</em>, 113600. (<a href='https://doi.org/10.1016/j.knosys.2025.113600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised video anomaly detection (WSVAD) faces critical challenges in distinguishing ambiguous events due to two scientific limitations: (1) Existing methods that rely exclusively on affirmative text prompts face challenges in scenarios with overlapping visual patterns between normal and abnormal categories, and (2) the inherent temporal modeling deficiency of vision-language models like contrastive language-image pretraining (CLIP) hampers precise localization of anomalies. To address these issues, we propose LOP-VAD, a novel framework that synergizes learnable opposite prompts with temporal context modeling. First, our method introduces dual “yes/no” text prompts to establish bidirectional vision-language alignment, enabling complementary decision boundaries through contrastive semantics. Second, a temporal context attention module is designed to capture both long-range dependencies and local temporal patterns, overcoming CLIP’s static representation limitation. Third, a prompt enhancement mechanism dynamically integrates visual confidence into text embeddings for cross-modal refinement. Extensive experiments across three benchmarks demonstrate state-of-the-art performance. The results validate that explicitly modeling opposite semantics and temporal dynamics significantly enhances the robustness of WSVAD against ambiguous events.},
  archive      = {J_KBS},
  author       = {Helei Qiu and Biao Hou and Yanyu Cui},
  doi          = {10.1016/j.knosys.2025.113600},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113600},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning opposite prompts for weakly supervised video anomaly detection},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic extraction of scale information for interactive measurement of anything in microscopy images. <em>KBS</em>, <em>324</em>, 113578. (<a href='https://doi.org/10.1016/j.knosys.2025.113578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative analysis of microscopy images is crucial for objective measurement and a deep understanding of properties. Amid the surge in biomedical publications, the automatic extraction of scale information has become essential for achieving high-accuracy measurements, ensuring reproducible research, and meeting the high-throughput demands of data mining. However, this vital aspect is often neglected in existing studies. To address this gap, we present an automated system combining two key innovations: (1) YOLO-OCR, a unified trainable model for simultaneous object detection, text detection, and text recognition, and (2) the largest dataset of annotated scale bars with 14,000 real and 5,726 synthesized scientific images. Experiments show that our solution achieves higher precision for scale bar detection (98.0% vs. 96.4% baseline) and scale label recognition (96.6% vs. 93.6% baseline), and reduces computational costs by 5% (44.2 ms vs. 46.5 ms baseline). Furthermore, an online system integrated with Segment Anything for Microscopy (MicroSAM) is developed to help researchers conveniently measure and quantitatively analyze microscopy images.},
  archive      = {J_KBS},
  author       = {Shuo Meng and Shuai Zhang and Xinshuo Liang and Jinlian Hu},
  doi          = {10.1016/j.knosys.2025.113578},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113578},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automatic extraction of scale information for interactive measurement of anything in microscopy images},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural networks prediction approach for knowledge dissemination model considering knowledge media. <em>KBS</em>, <em>324</em>, 113514. (<a href='https://doi.org/10.1016/j.knosys.2025.113514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the subjectivity of manual selection and the time-consuming nature of parameter adjustment, this paper proposes a physics-informed neural networks (PINNs) approach for parameter estimation and prediction of our newly constructed knowledge dissemination model based on the co-evolution of knowledge communities and knowledge media. Firstly, considering the three stages of knowledge perception, knowledge internalization, and knowledge forgetting, the dynamic equation of the susceptible–exposed–infected–recovered-media (SEIRM) model is established. Secondly, in order to address the challenge of unknown model parameters and model prediction in real-life scenarios, the SEIRM model is embedded as prior knowledge into PINNs. Then, the obtained parameters are used to calculate the basic reproduction number R 0 using the next-generation matrix method. The existence and stability of the system’s knowledge-free equilibrium (KFE) and knowledge-endemic equilibrium (KEE) are also demonstrated. Finally, through a series of simulation experiments, the influence mechanisms of learning attitude, knowledge difficulty, and knowledge internalization ability on knowledge dissemination are revealed. The experimental results demonstrate that the trained PINNs can learn the behavior of the unknown knowledge dissemination system and estimate important parameters more accurately than the Livermore solver (LSODA) of fixed parameters. The MAE and MAPE values of the predicted parameters reach approximately 1.75e−04 and 0.03%. Plus, PINNs’ loss value throughout different epochs is typically lower than that of deep neural networks (DNN) under the constraint of limited training data.},
  archive      = {J_KBS},
  author       = {Dan Xia and Min He and Jun Mei and QiuSha Min},
  doi          = {10.1016/j.knosys.2025.113514},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Physics-informed neural networks prediction approach for knowledge dissemination model considering knowledge media},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KERMIT: Knowledge graph completion of enhanced relation modeling with inverse transformation. <em>KBS</em>, <em>324</em>, 113500. (<a href='https://doi.org/10.1016/j.knosys.2025.113500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) revolves around populating missing triples in a knowledge graph using available information. Text-based methods, which depend on textual descriptions of triples, often encounter difficulties when these descriptions lack sufficient information for accurate prediction, an issue inherent to the datasets and not easily resolved through modeling alone. To address this and ensure data consistency, we first use large language models (LLMs) to generate coherent descriptions, bridging the semantic gap between queries and answers. Secondly, we utilize inverse relations to create a symmetric graph, thereby providing augmented training samples for KGC. Additionally, we employ the label information inherent in knowledge graphs (KGs) to enhance the existing contrastive framework, making it fully supervised. These efforts have led to significant performance improvements on the WN18RR, FB15k-237 and UMLS datasets. According to standard evaluation metrics, our approach achieves a 3.0% improvement in Hit@1 on WN18RR and a 12.1% improvement in Hit@3 on UMLS, demonstrating superior performance.},
  archive      = {J_KBS},
  author       = {Haotian Li and Bin Yu and Yuliang Wei and Kai Wang and Richard Yi Da Xu and Bailing Wang},
  doi          = {10.1016/j.knosys.2025.113500},
  journal      = {Knowledge-Based Systems},
  month        = {8},
  pages        = {113500},
  shortjournal = {Knowl. Based Syst.},
  title        = {KERMIT: Knowledge graph completion of enhanced relation modeling with inverse transformation},
  volume       = {324},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel image based approach for mobile android malware detection and classification. <em>KBS</em>, <em>323</em>, 113855. (<a href='https://doi.org/10.1016/j.knosys.2025.113855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely used mobile operating systems is Android. Consequently, it attracts the attention of hackers and is increasingly subjected to intensive attacks. To address this issue, this study proposes a image-based system for detecting Android malware and classifying malware families. The proposed approach has been tested separately on grayscale and RGB images. In similar studies within the literature, two fundamental issues have led to inconsistent and biased results. These issues are: 1) the problem of duplicate data within the datasets used, and 2) the problem of imbalanced data across classes. This study also offers solutions to these two issues. According to obtained results, it is observed that the proposed system achieved state-of-art results compared to previous studies, with an average accuracy of 0.987, precision of 0.987, recall of 0.986, and F1-score of 0.986.},
  archive      = {J_KBS},
  author       = {Muhammed Mutlu Yapici},
  doi          = {10.1016/j.knosys.2025.113855},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113855},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel image based approach for mobile android malware detection and classification},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mahalanobis distance-guided conditional adversarial learning for universal domain adaptation. <em>KBS</em>, <em>323</em>, 113850. (<a href='https://doi.org/10.1016/j.knosys.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of universal domain adaptation (UniDA) is to transfer knowledge between domains as- suming no prior information regarding label space relationship. The main challenge lies in simultaneously detecting private categories of two domains and aligning the distributions of common categories. Previous methods rely on the classifier’s or domain discriminator’s predictions to detect private class samples. How- ever, the predictions may be unreliable because the approach is known to produce overconfident probability estimates for “unknown” samples. Furthermore, these methods barely exploit the alignment method be- tween common categories. Therefore, this paper proposes a novel UniDA approach based on Mahalanobis distance. Specifically, we calculate Mahalanobis distance by using source deep features within a Gaussian discriminant analysis framework, and the Mahalanobis score is determined based on this distance. Target private categories can be identified owing to their smaller scores. Next, we determine the source private cat- egories based on classification results of target common samples via Gaussian discriminant analysis. Finally, we design the Mahalanobis distance-guided conditional adversarial learning to effectively align the multi- modal distributions of both the domains. The proposed method demonstrates state-of-the-art performance in extensive experiments on various UniDA benchmark datasets.},
  archive      = {J_KBS},
  author       = {Cangning Fan and Peng Liu and Wei Zhao},
  doi          = {10.1016/j.knosys.2025.113850},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113850},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mahalanobis distance-guided conditional adversarial learning for universal domain adaptation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain masked reconstruction self-supervised learning for lithology identification using well-logging data. <em>KBS</em>, <em>323</em>, 113843. (<a href='https://doi.org/10.1016/j.knosys.2025.113843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithology identification is crucial in the fields of energy exploration and oil and gas drilling, particularly for unconventional reservoirs, wherein the complexity and high heterogeneity of rock formations pose significant challenges for prospecting and exploration. To address the dual challenges of scarcity of labeled data and low accuracy of lithology identification models, in this study, we proposed a novel dual-domain masked reconstruction self-supervised learning (MR-SSL) framework. This framework comprised two stages: self-supervised pretraining and supervised fine-tuning, to significantly improve the accuracy of lithology identification using only a small number of labeled samples. In the pretraining stage, we designed three innovative tasks: time- and frequency-domain masked reconstruction and time–frequency contrastive learning, with each supported by a specifically designed loss functions. The time- and frequency-domain masked reconstruction tasks achieved multi-dimensional feature modeling through differentiated designs: the former combined cross-depth and cross-parameter dynamic masking strategies to adaptively capture stratigraphic non-stationarity based on periodic analysis, whereas the latter synchronously learned single-parameter specificity and multi-parameter correlation through a shared-private embedding mechanism. These tasks, in conjunction with the time–frequency contrastive learning task, provided the model enhanced complementarity through cross-domain feature consistency constraints. In the supervised fine-tuning stage, the pretrained encoder was frozen, time–frequency features were integrated, and classification head was trained, further enhancing the model’s capability of lithology classification, with respect to the target geological conditions. Experimental validation demonstrated that the MR-SSL model achieved high accuracy of 98.7% and 97.07% for two different oilfield datasets, while using only 20% labeled data, surpassing the performances of conventional supervised and self-supervised methods. The proposed model presents a unique advantage: it enables the deep decoupling and complementary utilization of time–frequency features in logging data through multi-task collaboration, thereby providing an efficient low-label solution for lithology identification for unconventional reservoirs.},
  archive      = {J_KBS},
  author       = {Qingwei Pang and Chenglizhao Chen and Wenhao Li and Shanchen Pang},
  doi          = {10.1016/j.knosys.2025.113843},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113843},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain masked reconstruction self-supervised learning for lithology identification using well-logging data},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics analysis of rumor propagation model in dual-layer heterogeneous social networks considering information coupling effect. <em>KBS</em>, <em>323</em>, 113829. (<a href='https://doi.org/10.1016/j.knosys.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-platform propagation of rumors increases the complexity of propagation paths and presents a significant challenge to governance. This study aims to address the current gaps in the research on cross-platform rumor propagation mechanisms by constructing a model that accurately reflects the characteristics of different platforms and the dynamics of rumor propagation while also providing effective policy recommendations for rumor control. The existing research indicates substantial differences in social attributes and user relationships across various social media platforms. Therefore, this study classifies social media platforms into open- and closed-knit layers based on their social attributes and network topologies, incorporating individual heterogeneity and interlayer coupling-reinforcement effects to establish a rumor propagation model based on dual-layer heterogeneous networks. Using the Microscopic Markov Chain (MMC) method, we conduct a dynamic analysis of the model, derive the threshold for rumor propagation, and explore the influence of various parameters on rumor spread using numerical simulations. The results indicate that rumors spread more rapidly on private social media platforms but achieve a broader scope and larger scale on public platforms. Dynamic changes in group relationships and the interlayer coupling-reinforcement effect among truth spreaders can effectively curb rumor spreading, whereas the coupling effect between rumor spreaders accelerates it. This study provides a theoretical basis for understanding and managing cross-platform rumor propagation, offers scientific support for governments and platforms in formulating effective rumor control strategies, and has significant practical value.},
  archive      = {J_KBS},
  author       = {Xuejun Ding and Qiyu Xing and Wei Deng and Yong Tian},
  doi          = {10.1016/j.knosys.2025.113829},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113829},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamics analysis of rumor propagation model in dual-layer heterogeneous social networks considering information coupling effect},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel fractional kookaburra crayfish optimization algorithm for trusted routing based blockchain in wireless sensor network. <em>KBS</em>, <em>323</em>, 113812. (<a href='https://doi.org/10.1016/j.knosys.2025.113812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Wireless Sensor Network (WSN), the routing procedure is complex and supports data transmission to base stations. However, routing attacks can significantly compromise or disrupt the functionality of WSNs. Furthermore, the majority of routing algorithms are impractical due to the difficulty of effectively determining the reliability of routing nodes. Hence, Fractional Kookaburra Crayfish Optimization (FKCO) is introduced for trusted routing-based blockchain in WSNs. The WSN is first simulated, and then different factors are taken into consideration to build the node data structure. Afterwards, CH selection is carried out based on a hybrid Kookaburra Crayfish Optimization Algorithm (KCOA) considering multi-objectives. The devised KCOA is an incorporation of the Kookaburra Optimization Algorithm (KOA) and Crayfish Optimization Algorithm (COA). Subsequently, blockchain-based routing network-based next-hop selection is performed using FKCO based on link reliability, energy prediction, delay, and distance. The FKCO is the amalgamation of the Fractional Concept (FC) with the proposed KCOA. Furthermore, Deep Q-Network (DQN) is used for energy prediction. Further, the FKCO is analyzed for its efficiency by considering three performance metrics, a delay of 0.600 s, energy of 0.400 J, and distance of 48.068 m.},
  archive      = {J_KBS},
  author       = {M. Lizzy Nesa Bagyam and S. Maheswari},
  doi          = {10.1016/j.knosys.2025.113812},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113812},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel fractional kookaburra crayfish optimization algorithm for trusted routing based blockchain in wireless sensor network},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCS-net: A universal AI-generated visual content detection method based on CLIP. <em>KBS</em>, <em>323</em>, 113806. (<a href='https://doi.org/10.1016/j.knosys.2025.113806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of deep learning-driven image generation technology, AI-generated images have demonstrated significant potential in artistic creation, film and television production, and data augmentation. However, the proliferation of online social media has facilitated the widespread dissemination of generative fake content, thereby posing substantial challenges to social trust and information security. Consequently, the development of efficient and generalizable detection methods for AI-generated images has emerged as a critical research focus. This paper addresses the limitation of current mainstream detection methods, which exhibit restricted generalization capabilities across different generation models and data distributions. We propose a CLIP-based generalized AI-generated image detection method. To fully leverage the superior feature extraction capability of CLIP ViT-L/14, we employ the LoRA lightweight fine-tuning strategy to adapt the model for the task of detecting AI-generated images. Furthermore, auxiliary features are extracted from the LAB and HSV color spaces to enhance the discriminative power of the model. Additionally, we design a semantically-guided concept learning space that aligns image features with semantic features via concept loss, thereby improving detection performance at the semantic level. Experimental results indicate that the proposed method achieves excellent generalization across 20 AI-generated image datasets, with an average accuracy of 84.57 % and an average precision of 92.46 %, surpassing existing sub-optimal methods by 4.34 % and 1.76 %, respectively. Notably, on datasets generated by diffusion models, the accuracy is 9.05 % higher than that of existing methods, validating the robust cross-generation model generalization capability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Haitao Xu and Zhihong Chen and Haiwei Zhang and Lifang Xue and Hao Zhang},
  doi          = {10.1016/j.knosys.2025.113806},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113806},
  shortjournal = {Knowl. Based Syst.},
  title        = {GCS-net: A universal AI-generated visual content detection method based on CLIP},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPFIANet: Three path feature progressive interactive attention learning network for medical image segmentation. <em>KBS</em>, <em>323</em>, 113778. (<a href='https://doi.org/10.1016/j.knosys.2025.113778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of medical image segmentation, medical image segmentation methods with high accuracy and generalization capabilities are crucial for driving personalized healthcare solutions and enhancing patient experience. To address the inherent challenges of difficulty in acquiring complex structural features and weak generalization ability in medical image segmentation, we propose a three-path spatial learning (TPSL) module, which takes advantage of convolutional neural networks (CNNs) to skillfully learn specific details at different scales to acquire better feature representations, and then, we propose a progressive feature cross-fusion (PFCF) module, which aims to dynamically learn feature information under different levels in the encoder, which enhances the feature representation. Finally, we propose the feature interactive attention fusion (FIAF) module, which mixes features from different scales and channels, adaptively learns feature weights and enhances the connection between channel and local spatial information. Based on the above modules, we design a three path feature progressive interactive attention learning network (TPFIANet), which captures image features at different levels and scales. We demonstrate the segmentation performance of TPFIANet on three public datasets and three self-organized datasets. Notably, our TPFIANet also demonstrates amiable segmentation performance on datasets of different modalities while maintaining a lighter architecture.},
  archive      = {J_KBS},
  author       = {Yawu Zhao and Shudong Wang and Yande Ren and Jiehuan Wang and Shaoqiang Wang and Sibo Qiao and Tiyao Liu and Shanchen Pang},
  doi          = {10.1016/j.knosys.2025.113778},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113778},
  shortjournal = {Knowl. Based Syst.},
  title        = {TPFIANet: Three path feature progressive interactive attention learning network for medical image segmentation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive unscented kalman filter –based method for RUL prediction via nonlinear degradation modeling. <em>KBS</em>, <em>323</em>, 113775. (<a href='https://doi.org/10.1016/j.knosys.2025.113775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction based on degradation path is regarded as a core component in prognostics and health management (PHM). Current methods in literature for nonlinear degradation mainly rely on linearization modeling, and a few nonlinear degradation methods based on nonlinear modeling often utilize Wiener process with increment modeling and linear Kalman filter structure, which would make the results biased under strong nonlinearity. This paper proposes an adaptive unscented Kalman filter (UKF)-based prognostic method for RUL prediction in nonlinear degradation systems. To be specific, a general nonlinear state-space model is established for nonlinear degradation path directly to describe the dynamics and nonlinearity of the degradation process instead of increment modelling or linearization. Then, nonlinear UKF structure is used to update the degradation parameters forward once newly observed data is obtained. To capture the uncertainty and variability during degradation process adaptively, a novel Bayesian paradigm, which consists of an improved unscented Rauch-Tung-Striebel Smoother (URTS) and expectation maximization framework, is derived to update the hidden variables and other unknown parameters recursively. Finally, two real-life nonlinear degradation cases consisting of a bearing degradation and a hard disk drive degradation are used to verify the superiority of the proposed method.},
  archive      = {J_KBS},
  author       = {Shan Jiang and Yu Wang and Wen Jian Lu and Yanyang Zi and Ying Yang},
  doi          = {10.1016/j.knosys.2025.113775},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113775},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive unscented kalman filter –based method for RUL prediction via nonlinear degradation modeling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UBMF: Uncertainty-aware bayesian meta-learning framework for fault diagnosis with imbalanced industrial data. <em>KBS</em>, <em>323</em>, 113772. (<a href='https://doi.org/10.1016/j.knosys.2025.113772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis of mechanical equipment involves data collection, feature extraction, and pattern recognition but is often hindered by the imbalanced nature of industrial data, introducing significant uncertainty and reducing diagnostic reliability. To address these challenges, this study proposes the Uncertainty-Aware Bayesian Meta-Learning Framework (UBMF), which integrates four key modules: data perturbation injection for enhancing feature robustness, cross-task self-supervised feature extraction for improving transferability, uncertainty-based sample filtering for robust out-of-domain generalization, and Bayesian meta-knowledge integration for fine-grained classification. Experimental results on ten open-source datasets under various imbalanced conditions, including cross-task, small-sample, and unseen-sample scenarios, demonstrate the superiority of UBMF, achieving an average improvement of 42.22 % across ten Any-way 1–5-shot diagnostic tasks.This integrated framework effectively enhances diagnostic accuracy, generalization, and adaptability, providing a reliable solution for complex industrial fault diagnosis where imbalanced data and dynamic operating conditions severely challenge traditional methods, such as highstakes industries such as wind turbine monitoring, aerospace systems, and automated manufacturing},
  archive      = {J_KBS},
  author       = {Zhixuan Lian and Shangyu Li and Qixuan Huang and Zijian Huang and Haifei Liu and Jianan Qiu and Puyu Yang and Laifa Tao},
  doi          = {10.1016/j.knosys.2025.113772},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113772},
  shortjournal = {Knowl. Based Syst.},
  title        = {UBMF: Uncertainty-aware bayesian meta-learning framework for fault diagnosis with imbalanced industrial data},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual space multi-granular model for multi-interest sequential recommendation. <em>KBS</em>, <em>323</em>, 113764. (<a href='https://doi.org/10.1016/j.knosys.2025.113764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to predict the next item for a user given his historical interaction sequence. Recently, multi-interest and Graph Neural Network (GNN) based paradigms are two new directions in such task. Multi-interest learning encompasses extracting diverse user interests through historical item clustering, while GNN refines user preferences through correlations among historical items. Recent research suggests the synergistic potential of combining these methods to aggregate user preferences at multiple levels, enhancing the accuracy of multi-interest extraction for improved recommendations. However, existing GNN-based multi-interest models can only achieve local smoothing for node embeddings through neighbor information aggregating, thus, they could not match remote items (far-apart items on the item–item graph) even though those remote items show similar local patterns and the items may reflect some niche preferences. It is unreasonable in the context of multi-interest recommendation as the objective is to capture the user’s interests in a more comprehensive manner. To tackle this issue, we propose a D ual S pace M ulti- G ranular Rec ommendation model ( DSMGRec ), where a Graph Deconvolutional Network (GDcN) is designed to disentangle local structure-based patterns of items as their additional embeddings. Then, we adopt a dual framework that combines the traditional GNN with our novel GDcN to encode multi-granular representations for items in the dual space. Such dual item representations can match items by not only their primary patterns but also their secondary patterns. Experiments on four real-world datasets with different densities show that our model outperforms state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Yijun Sheng and Puiieng Lei and Yanyan Liu and Ximing Chen and Qiwen Xu and Zhiguo Gong},
  doi          = {10.1016/j.knosys.2025.113764},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113764},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual space multi-granular model for multi-interest sequential recommendation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal-spectral-spatial synchronization attention-based network for EEG emotion recognition. <em>KBS</em>, <em>323</em>, 113762. (<a href='https://doi.org/10.1016/j.knosys.2025.113762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) provides an objective and precise representation of human emotional states, establishing EEG-based emotion recognition as a pivotal area in affective computing and intelligent systems. Nevertheless, EEG signals contain temporal-spectral-spatial features, exhibiting dynamic variations, frequency-band correlations, and spatial dependencies, with varying resolutions across domains. The challenge lies in adapting to resolution differences between domains, thereby improving the model’s ability to integrate complementary information across these domains. Moreover, processing multi-domain features often leads to complex model structures and excessive feature fusion, resulting in information loss. To tackle these challenges, we propose a unified framework: the Temporal-Spectral-Spatial Synchronization Attention-Based Network, which facilitates efficient modeling of multi-domain data. Specifically, the proposed network consists of a temporal-spectral-spatial attention encoder and a categorical decoder. The encoder adapts to resolution differences across temporal-spectral-spatial domains and synchronizes the fusion of spatiotemporal and spectral data, thus simplifying the model structure. Furthermore, we introduce a gating mechanism to adaptively balance the weights across domains and prevent excessive fusion that results in information loss. Finally, extensive experimental comparisons along with both subjective and objective analyses, demonstrate that our proposed network outperforms state-of-the-art models on the SEED, SEED-IV and DEAP.},
  archive      = {J_KBS},
  author       = {Zhifen Guo and Jiao Wang and Hongchen Luo and Fengbin Ma and Yiying Zhang},
  doi          = {10.1016/j.knosys.2025.113762},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113762},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal-spectral-spatial synchronization attention-based network for EEG emotion recognition},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGE: Semantic-guided generalization enhancement for few-shot learning. <em>KBS</em>, <em>323</em>, 113761. (<a href='https://doi.org/10.1016/j.knosys.2025.113761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of computer vision, learning from limited datasets presents a significant challenge, known as Few-Shot Learning (FSL). Current methodologies have employed semantic information and data augmentation to address insufficient feature representation in limited datasets. However, these approaches often fail to resolve the fundamental data scarcity problem. Additionally, they may inadvertently introduce distributional bias, constraining the utility of semantic features in FSL contexts. To alleviate the issue, in this paper we propose a novel Semantic-guided Generalization Enhancement method (SGE) for FSL. SGE masterfully harnesses robust semantic information by integrating knowledge from diverse pre-trained models. It utilizes semantic cues from class labels to guide both data augmentation and feature extraction processes. Compared to traditional data augmentation techniques, SGE generates augmented samples that are more semantically consistent with the original samples. SGE enables the model to obtain a comprehensive and accurate representation of class characteristics through multifaceted data augmentation of categories. The backbone model adaptively integrates semantic information with image data, and merges the enhanced sample features with the original sample features via a feature fusion module. This allows SGE, guided by semantic cues, to construct a robust class prototype with rich discriminative features. Empirical evidence demonstrates that our framework outperforms state-of-the-art methods across four benchmark assessments. This clearly demonstrates the remarkable efficacy of SGE in leveraging semantic information, thereby exerting a significant influence on FSL. The code is available at https://github.com/zhuyangyang-cjlu/SGE .},
  archive      = {J_KBS},
  author       = {Zijun Zheng and Yangyang Zhu and Heng Wu and Laishui Lv and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.knosys.2025.113761},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113761},
  shortjournal = {Knowl. Based Syst.},
  title        = {SGE: Semantic-guided generalization enhancement for few-shot learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAF-DETR: A dynamic adaptation feature transformer for enhanced object detection in unmanned aerial vehicles. <em>KBS</em>, <em>323</em>, 113760. (<a href='https://doi.org/10.1016/j.knosys.2025.113760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments is challenged by overlapping objects, complex spatial relationships, and dynamic variations in target scales. To address these challenges, the Dynamic Adaptation Feature DEtection TRansformer (DAF-DETR) is proposed as a novel transformer-based model optimized for real-time detection in spatially complex environments. The framework introduces four key innovations. First, a learnable position encoding mechanism is employed in place of fixed positional encoding, enhancing adaptability and flexibility when processing complex spatial layouts. Second, the Resynthetic Network (ResynNet) backbone, which consists of stacked Resynthetic Blocks (ResynBlocks) integrating ResBlock and FasterBlock feature extraction strategies, is designed to optimize multi-scale feature representation and improve computational efficiency. Third, an enhanced feature fusion module is incorporated to strengthen the detection of small, densely packed objects by integrating multi-scale contextual information. Fourth, a dynamic perception module is introduced, utilizing deformable attention to capture complex spatial relationships between overlapping objects. Extensive experiments conducted on the Vision meets Drone 2019 (VisDrone2019) and Tiny Object Detection in Aerial Images (AI-TOD) datasets demonstrate the superiority of DAF-DETR, achieving state-of-the-art detection accuracy while maintaining real-time efficiency. The results confirm its robustness in handling scale variations, occlusions, and spatial complexity, establishing it as a reliable solution for real-world applications such as aerial imagery and crowded scene analysis.},
  archive      = {J_KBS},
  author       = {Baoye Song and Shihao Zhao and Zidong Wang and Weibo Liu and Xiaohui Liu},
  doi          = {10.1016/j.knosys.2025.113760},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113760},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAF-DETR: A dynamic adaptation feature transformer for enhanced object detection in unmanned aerial vehicles},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diff-RCformer: A diffusion-augmented recursive context transformer for image super-resolution. <em>KBS</em>, <em>323</em>, 113758. (<a href='https://doi.org/10.1016/j.knosys.2025.113758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have recently exhibited strong potential in single-image super-resolution (SISR) by effectively modeling complex data distributions and generating high-quality reconstructions. However, existing diffusion-based SISR methods often suffer from excessive iterative steps, resulting in a high computational overhead and slow convergence. In addition, traditional convolutional neural networks and Transformer-based architectures have difficulty in capturing complex global information, thereby limiting the reconstruction quality. To address these issues, we propose Diff-RCformer, which is a novel SISR framework that integrates diffusion-based prior generation with the Recursive Context Transformer (RCformer) to achieve robust and efficient super-resolution. Specifically, we use the diffusion model to generate high-quality prior features for super-resolution by iteratively refining Gaussian noise in a compressed latent space. These prior features are then injected into the RCformer, guiding it to reconstruct the high-resolution image. In the RCformer, we introduce Prior-Guided Recursive Generalization Network (PG-RGN) blocks. These blocks recursively aggregate the input features into representative feature maps, enabling them to adapt flexibly to input features of different dimensions and extract global information through cross-attention. We also combine the PG-RGN with Prior-Guided Local Self-Attention (PG-LSA) to enable the model to capture local detail features accurately and enhance the utilization of the global context. To achieve an optimal combination of local and global features, we propose Adaptive Feature Integration (AFI), which efficiently fuses local and global features across multiple attention layers. Our method also supports cascaded super-resolution, enabling flexible multi-stage refinement, which is particularly useful for complex scenarios. Comprehensive experiments on standard benchmarks indicate that Diff-RCformer surpasses recent state-of-the-art methods both quantitatively and qualitatively. https://github.com/SureT-T/Diff-RCformer},
  archive      = {J_KBS},
  author       = {Shuo Wang and Shuzhen Xu and Cuicui Lv and Chaoqing Ma and Fangbo Cai},
  doi          = {10.1016/j.knosys.2025.113758},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113758},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diff-RCformer: A diffusion-augmented recursive context transformer for image super-resolution},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous modal collaborative training network for human action recognition. <em>KBS</em>, <em>323</em>, 113757. (<a href='https://doi.org/10.1016/j.knosys.2025.113757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Popular skeleton-based action recognition is known for its robustness and lightweight design. However, pure skeleton data often fails to retain critical information because of its inherent constraints. Therefore, multimodal information fusion methods have been introduced into action recognition tasks and have gained significant traction. However, owing to the large volume of data and mismatch between heterogeneous information types, complications emerge when handling different modalities and conducting effective training. To address these issues, we propose the heterogeneous modalities collaborative training network (HM-CTNet). Specifically, we first process red–green–blue (RGB) videos into migration of hand patch (MHP) graphs and global omission information supplement (GOIS) streams to supplement the skeleton data with hand details and human–object interaction details, respectively. Next, we designed a multi-level aggregated spatial graph convolutional network (MAS-GCN) to address the over-smoothing issue in processing skeleton data from the spatio-temporal feature compression perspective while constructing a more effective adjacency matrix to capture spatio-temporal correlation features. Finally, we applied transfer learning to jointly train the skeleton modality data with the processed RGB images to obtain the recognition results. HM-CTNet demonstrates outstanding performance on three benchmark datasets: NTU RGB＋D 60, NTU RGB＋D 120, and Northwestern-UCLA, highlighting the effectiveness of our collaborative training network in fusing heterogeneous multimodal information. Our code is available at: https://github.com/sunbeam-kkt/HM-CTNet .},
  archive      = {J_KBS},
  author       = {Chenglong Xu and Xiao Yun and Yanjing Sun and Kaiwen Dong},
  doi          = {10.1016/j.knosys.2025.113757},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113757},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous modal collaborative training network for human action recognition},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEG emotion recognition based on dynamic temporal causal graph convolutional network. <em>KBS</em>, <em>323</em>, 113752. (<a href='https://doi.org/10.1016/j.knosys.2025.113752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the connectivity characteristics of brain networks, the dynamic evolution in the connectivity relationships between different brain regions throughout time provides information on emotional representation. However, current electroencephalographic (EEG) emotion recognition methods often overlook local density, global sparsity, and temporal causality that are inherent in the connectivity relationships between brain regions. To address these issues, a dynamic temporal–causal graph convolutional network (DTC-GCN) for EEG emotion recognition is proposed herein. The DTC-GCN learns the spatial topology and temporal–causal relationships between EEG channels over a period of time. It takes time-series graphs as the input and is implemented in two stages. In the first stage, the sparse connected dynamic graph convolutional network is used to dynamically learn a locally dense and global sparse brain network. In the second stage, the temporal–causal module is used to construct causal connectivity among EEG channels across different segments. The effectiveness of the proposed model is evaluated by conducting extensive experiments on two publicly available datasets, DEAP and SEED. On the DEAP dataset, the average accuracies of arousal and valence are 95.08% and 94.31%, respectively. On the SEED dataset, the average accuracy is 98.48%. Results indicate that the DTC-GCN outperforms existing state-of-the-art methods. By analyzing the parameters of the DTC-GCN and conducting an interpretability study, we reveal the overall connectivity pattern between EEG channels and the causal relationships between segments within short time intervals.},
  archive      = {J_KBS},
  author       = {Yaru Zhou and Xueying Zhang and Ying Sun and Guijun Chen and Lixia Huang and Haifeng Li},
  doi          = {10.1016/j.knosys.2025.113752},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113752},
  shortjournal = {Knowl. Based Syst.},
  title        = {EEG emotion recognition based on dynamic temporal causal graph convolutional network},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive nested sampling for multi-subregion feature learning. <em>KBS</em>, <em>323</em>, 113751. (<a href='https://doi.org/10.1016/j.knosys.2025.113751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of feature representation learning from Regions of Interest (RoIs) is crucial for RoI-based object detection. Conventional methods, however, often struggle with learning effectiveness when processing objects with complex geometries, non-rigid deformations, or fragmented spatial distributions. This paper studies an improved feature learning algorithm that adaptively captures key semantic subregions of complex RoI-enclosed objects, applies nested sampling to extract feature grids, and ultimately derives highly discriminative feature representations. This approach, termed Adaptive Nested Sampling-Based Multi-Subregion Feature Learning (AdaNest), consists of three core components: Adaptive Multi-Subregion Nested Sampling, Semantic-Separation Assignment Strategy, and Extended Modules. The effectiveness of AdaNest was evaluated on the MS-COCO 2017 dataset, integrated into multiple object detection frameworks. Results show consistent improvements in detection performance, particularly in Faster R-CNN and Cascade R-CNN, with mAP gains of 4.0 and 3.4 points, respectively. Ablation studies confirm the contributions of key components, while visualizations of subregion distributions reveal an additional phenomenon: for detected objects, classification-relevant features concentrate in key object parts, whereas localization-relevant features align with object boundaries. These findings offer insights into semantic feature organization, demonstrating that AdaNest is an efficient and adaptable learning method that enhances object detection performance.},
  archive      = {J_KBS},
  author       = {Xincheng Huang and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.113751},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113751},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive nested sampling for multi-subregion feature learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Make your choice for multimodal knowledge graph completion. <em>KBS</em>, <em>323</em>, 113750. (<a href='https://doi.org/10.1016/j.knosys.2025.113750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) aims to predict missing entities in knowledge graphs by learning effective representations of entities and their relations. Recent advances have explored multimodal KGC by incorporating structural, textual, and visual information. However, two critical challenges remain unresolved: (1) modal heterogeneity, where significant differences in feature distributions across modalities hinder effective fusion; and (2) spatial heterogeneity, where embedding knowledge graphs in a single geometric space fails to capture their complex topological structures. To address these challenges, we propose ChoicE, a unified framework that leverages a mixture of experts (MoE) design for both encoding and decoding. In the encoder, the multimodal chooser preprocesses multiple modalities to derive embedding representations for each modality. These representations are then processed by distinct experts specialized for structural, textual, and visual features, facilitating effective fusion while preserving modality-specific information. In the decoder, the geometric chooser projects the unified multimodal embeddings into Euclidean, complex, or hyperbolic space, dynamically selecting the most appropriate space to model the inference patterns inherent to each query. Extensive experiments on multiple benchmark datasets demonstrate that ChoicE effectively overcomes these dilemmas and achieves state-of-the-art performance in multimodal KGC. The data and code are released at https://anonymous.4open.science/r/ChiocE-master/ .},
  archive      = {J_KBS},
  author       = {Yifan Xue and Shuoyan Ren and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
  doi          = {10.1016/j.knosys.2025.113750},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113750},
  shortjournal = {Knowl. Based Syst.},
  title        = {Make your choice for multimodal knowledge graph completion},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized pixel-aware deep function-mixture network for effective spectral super-resolution. <em>KBS</em>, <em>323</em>, 113743. (<a href='https://doi.org/10.1016/j.knosys.2025.113743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress on spectral super-resolution (SR) mainly focuses on directly mapping an RGB image to its HSI counterpart using deep convolutional neural networks, i.e., non-linearly transform the RGB context within a size-fixed receptive field centered at each pixel to its spectrum using a universal deep mapping function. However, in real scenarios, pixels in HSIs inevitably require size-different receptive fields and distinct mapping functions due to their differences in object category or spatial position, and consequently, these existing methods show limited generalization capacity, especially when the imaging scene is complicated. To tackle this issue, we introduce a pixel-aware deep function-mixture network (PADFMN) for SSR, which consists of a novel class of modules called function-mixture (FM) blocks. Each FM block contains several basis functions, represented by parallel subnets with varying receptive field sizes. Additionally, a separate subnet functions as a mixing function, generating pixel-level weights that linearly combine the outputs of the basis functions. This approach allows the network to dynamically adjust the receptive field size and mapping function for each pixel based on its specific characteristics. Through stacking several such FM blocks together and fusing their intermediate feature representations, we can obtain an effective SSR network with flexibility in learning pixel-wise deep mapping functions as well as better generalization capacity. Moreover, with the aim of employing the proposed PADFMN to cope with two more challenging SSR tasks, including cross-sensor SSR ( i.e., test on RGB image shot by a new sensor with unseen spectral response function) and scale-arbitrary SSR ( i.e., the spectral resolution of HSI to reconstruct can be arbitrarily determined), we extend the core FM blocks to two more generalized versions, namely sensor-guided FM block and scale-guided FM block. The former is able to cast the sensor-related information ( e.g., spectral response function) into guidance via dynamic filters to assist the spectral reconstruction using the basic FM block. This is beneficial for reducing the distribution shift between the training and test images incurred by unseen RGB sensors in terms of establishing the deep mapping function, thus leading to pleasing performance in cross-sensor SSR tasks. On the other hand, the latter encodes the user-determined spectral resolution to control the channel dimension of the feature output by the last basic FM block precisely via dynamically generating corresponding convolution filters, so that the network can reconstruct HSI with an arbitrarily determined scale while keeping the spectrum accuracy. We test the proposed method on three benchmark datasets, and it achieves state-of-the-art performance in SSR, cross-sensor SSR, and scale-arbitrary SSR tasks.},
  archive      = {J_KBS},
  author       = {Jiangtao Nie and Lei Zhang and Chongxing Song and Zhiqiang Lang and Weixin Ren and Wei Wei and Chen Ding and Yanning Zhang},
  doi          = {10.1016/j.knosys.2025.113743},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113743},
  shortjournal = {Knowl. Based Syst.},
  title        = {Generalized pixel-aware deep function-mixture network for effective spectral super-resolution},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated and lightweight recursive kernel optimized network (LReKON) learning model for cervical cancer diagnosis. <em>KBS</em>, <em>323</em>, 113742. (<a href='https://doi.org/10.1016/j.knosys.2025.113742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is the most prevalent long-term illnesses that can be highly affected women around the world. Images from Pap smears are a widely used technology for cervical cancer screening and diagnosis. Even when the contaminated sample is present, human error can lead to false-negative results when examining pap smears. This challenge has been revamped by automated image processing diagnostics, which is crucial in identifying abnormal tissues impacted by cervical cancer. Therefore, the proposed study aims to develop an automated and lightweight cervical cancer diagnosis system, known as, Lightweight Recursive Kernel Optimized Network (LReKON) for fast and accurate cervical cancer diagnosis. The aberrant region has been more accurately segmented from the raw cervical pictures using the Squeeze and Excitation Instance Segmentation Network (SEI-SN) technology. A novel algorithm termed Optimal Hyperplane based Kernel Neural Network (OHyKN) is used to determine the segmented region as either healthy or cancer-affected, depending on the relevant class. This work also employs a novel Hybrid Heap based Diffusion Vector Optimizer (H 2 DVO) technique to enhance the training and testing performance of the classifier and expedite the prediction process. Additionally, the proposed LReKON model's segmentation and classification performance is tested and verified using publicly available benchmarking datasets, including the Mendeley LBC and the SIPaKMed Pap smear image dataset, taking into account a number of factors. The trained LReKON model is best in cervical cancer diagnosis with 99.10 % accuracy, 99 % precision, 98.9 % recall, and 98.9 % F1-score and with an extremely fast inference time of 0.28 s. The SEI-SN segmentation module plays a crucial role in performance enhancement as its removal reduces accuracy to 95.15 %, and the removal of the OHyKN classification module reduces accuracy to 96.25 %. The H2DVO optimization step improves efficiency since its elimination results in an additional inference time of 0.32 s and accuracy of 97.35 %. Moreover, when the three components SEI-SN, OHyKN, and H2DVO are eliminated, accuracy reduces to 93.55 %, defining their combined contribution to segmentation, classification, and optimization.},
  archive      = {J_KBS},
  author       = {G. Saranya and C. Sujatha},
  doi          = {10.1016/j.knosys.2025.113742},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113742},
  shortjournal = {Knowl. Based Syst.},
  title        = {An automated and lightweight recursive kernel optimized network (LReKON) learning model for cervical cancer diagnosis},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMDD: Multi-deliberation based calibration for federated long-tailed learning. <em>KBS</em>, <em>323</em>, 113741. (<a href='https://doi.org/10.1016/j.knosys.2025.113741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a decentralized framework enabling collaborative training of machine learning models across distributed data clients while ensuring privacy protection. Despite its advantages, traditional federated learning faces the global long-tailed imbalance, leading to poor performance by overemphasizing head classes and under-representing tail classes. While planned (pre-hoc) and post-hoc imbalance adjustments have been explored, post-hoc methods often require auxiliary data or suffer from overconfident decision boundaries, which limits their effectiveness. To address the overconfidence and out-of-distribution in existing solutions, we propose a multi-deliberation based post-hoc calibration method (FedMDD) tailored for the federated long-tailed problem. FedMDD calibrates the global decision boundary for balance. It incorporates a local–global feature contrast constraint to generate effective features and uses consistency across client models to deliberate a model-aware margin. This margin promotes a large relative distance between tail classes and the decision boundary, preserving privacy by leveraging model performance without requiring access to local class distributions. Extensive experiments demonstrate that FedMDD outperforms existing methods in balancing decision boundaries and enhancing privacy protection, achieving superior performance on long-tailed data distributions.},
  archive      = {J_KBS},
  author       = {Yiwen Wang and Jiaxin Li and Heye Zhang and Jingfeng Zhang and Feng Wan and Anqi Qiu and Zhifan Gao},
  doi          = {10.1016/j.knosys.2025.113741},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113741},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedMDD: Multi-deliberation based calibration for federated long-tailed learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GLALLM: Adapting LLMs for spatio-temporal wind speed forecasting via global–local aware modeling. <em>KBS</em>, <em>323</em>, 113739. (<a href='https://doi.org/10.1016/j.knosys.2025.113739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the escalating environmental pollution necessitates the worldwide applications of clean energy. As an environmentally friendly energy source, wind energy has gained increasing attention. Nevertheless, the inherent intermittence of wind brings significant challenges to wind energy systems. To ensure stable energy production, it is crucial to achieve accurate wind speed forecasting. Recently, Large Language Model (LLM) based models have emerged as one of the most promising methods for time series forecasting. However, these methods mainly focus on long-term temporal modeling, may omit the short-term spatial dependencies obscured in time series data, potentially resulting in less effective spatio-temporal forecasting performance. To address this limitation, we propose a novel G lobal- L ocal A ware L arge L anguage M odel (GLALLM), which adapts LLMs for spatio-temporal wind speed forecasting via global–local aware modeling. Specifically, we employ a global branch that leverages the strength of LLMs to extract the long-term temporal patterns, while introducing a spatio-temporal hypergraph neural network as a local branch to learn short-term spatial correlations. Moreover, to facilitate the integration of global and local information, we develop a spatio-temporal aware fusion module with meta networks to enhance the complementarity of the two branches. Extensive experiments on several real-world datasets demonstrate the effectiveness of GLALLM.},
  archive      = {J_KBS},
  author       = {Tangjie Wu and Qiang Ling},
  doi          = {10.1016/j.knosys.2025.113739},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113739},
  shortjournal = {Knowl. Based Syst.},
  title        = {GLALLM: Adapting LLMs for spatio-temporal wind speed forecasting via global–local aware modeling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPNet: A dual prototype few-shot semantic segmentation network for crack detection. <em>KBS</em>, <em>323</em>, 113733. (<a href='https://doi.org/10.1016/j.knosys.2025.113733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road crack detection is crucial for maintaining the aesthetics and safety of roads. The varying morphology of cracks often results in insufficient road crack samples, limiting the effectiveness of existing detection methods in few-sample scenarios. Further, when visual samples are insufficient, employing textual information to extract visual information from images is a cutting-edge technology. In this paper, we propose a Dual Prototype Network (DPNet) for few-shot crack detection. Firstly, we introduce an Improved Pixel Weight (IPW) data enhancement to strengthen the foreground and edges of cropped samples, improving learning efficiency in the case of insufficient samples. Next, we design a dual prototype prediction method. Specifically, we employ domain related text input to generate a Language-Image Prototype (LIP) with general domain knowledge through Contrastive Language-Image Pre-training (CLIP). Then, we generate a Support Prototype (SuP) with specialized domain knowledge from crack dataset images. The final prediction is obtained by linearly combining the predictions of the two prototypes. Additionally, we design an Embedding Attention Module (EAM), which leverages the characteristics of the embedding dimension to simultaneously satisfy both spatial and channel attention mechanisms in the transformer structure. Finally, our DPNet achieves superior performance on the FCrack-i and MixCrack few sample datasets, with an average mIoU improvement of 8.52% and 1.44% compared to the baseline. Moreover, we demonstrate the zero-shot capability of DPNet on CFD crack dataset.},
  archive      = {J_KBS},
  author       = {Xiaoming Chen and Zhangyan Zhao and Jingjing Cao and Yuhang Zou and Haipeng Liu},
  doi          = {10.1016/j.knosys.2025.113733},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113733},
  shortjournal = {Knowl. Based Syst.},
  title        = {DPNet: A dual prototype few-shot semantic segmentation network for crack detection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CDC-FSL: A causal de-confounding framework for few-shot learning. <em>KBS</em>, <em>323</em>, 113732. (<a href='https://doi.org/10.1016/j.knosys.2025.113732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Few-Shot Learning (FSL), Out-of-Distribution (OOD) samples often introduce confounders, limiting models’ generalization ability. Existing causal-based FSL approaches adjust for these confounders but typically rely on fixed assumptions derived from prior knowledge. In this work, we argue that confounders should be adaptively learned to suit specific scenarios. To address this, we propose a Structural Causal Model (SCM) that explains how confounders lead to misclassification in FSL, particularly when causal features and confounder features are entangled. Building on this SCM, we introduce the Causal De-Confounding framework for FSL (CDC-FSL), which dynamically learns disentangled representations of causal and confounder features. Using a novel co-learning strategy and back-door adjustment, CDC-FSL mitigates confounding effects during FSL recognition. Extensive experiments on standard benchmarks demonstrate that CDC-FSL achieves state-of-the-art performance in both 1-shot and 5-shot settings. Additionally, it exhibits superior cross-domain transferability, outperforming existing methods across diverse target domains.},
  archive      = {J_KBS},
  author       = {Yue Yin and Jiaoyun Yang and Ning An and Lian Li},
  doi          = {10.1016/j.knosys.2025.113732},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113732},
  shortjournal = {Knowl. Based Syst.},
  title        = {CDC-FSL: A causal de-confounding framework for few-shot learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a dynamic tree-mamba encoder for UAV tracking with vision-language. <em>KBS</em>, <em>323</em>, 113731. (<a href='https://doi.org/10.1016/j.knosys.2025.113731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformer-based natural language specification tracking methods have achieved outstanding results in the field of unmanned aerial vehicle (UAV) tracking. Existing methods often decompose the tracking task into two sub-tasks, for which they propose a tracking block and a grounding block to address each sub-task accordingly. However, this independent handling strategy fails to consider the correlation between tracking and grounding, specifically that natural language can provide semantic information about the target. Additionally, this separate strategy cannot achieve end-to-end training. Therefore, we propose an integrated natural language tracking framework, redefined as a unified task that can automatically track targets through language and visual references. First, we introduce a tree-based Mamba module to effectively model the relationship between vision and language, capable of dynamically generating a tree topology based on input features and spatial relationships. Then, to enhance long-range dependencies without increasing computational costs, we incorporate a linear complexity dynamic programming approach. Finally, in order to improve the appearance change of the target, we design an online updating branch which can provide time clues for the model with the aid of semantic information. Experimental results on multiple datasets demonstrate that our method achieves state-of-the-art tracking performance.},
  archive      = {J_KBS},
  author       = {Guocai Du and Peiyong Zhou and Nurbiya Yadikar and Alimjan Aysa and Kurban Ubul},
  doi          = {10.1016/j.knosys.2025.113731},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113731},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward a dynamic tree-mamba encoder for UAV tracking with vision-language},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deepfake audio detection with spectral features and ResNeXt-based architecture. <em>KBS</em>, <em>323</em>, 113726. (<a href='https://doi.org/10.1016/j.knosys.2025.113726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing prevalence of deepfake audio technologies and their potential for malicious use in fields such as politics and media has raised significant concerns regarding the ability to distinguish fake from authentic audio recordings. This study proposes a robust technique for detecting synthetic audio by leveraging three spectral features: Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Constant Q Cepstral Coefficients (CQCC). These features are processed using an enhanced ResNeXt architecture to improve classification accuracy between genuine and spoofed audio. Additionally, a Multi-Layer Perceptron (MLP)-based fusion technique is employed to further boost the model’s performance. Extensive experiments were conducted using three datasets: the ASVspoof 2019 Logical Access (LA) dataset—featuring text-to-speech (TTS) and voice conversion attacks—the ASVspoof 2019 Physical Access (PA) dataset—including replay attacks—and the ASVspoof 2021 LA, PA and DF datasets. The proposed approach has demonstrated superior performance compared to state-of-the-art methods across all three datasets, particularly in detecting fake audio generated by text-to-speech (TTS) attacks. Its overall performance is summarized as follows: the system achieved an Equal Error Rate (EER) of 1.05% and a minimum tandem Detection Cost Function (min-tDCF) of 0.028 on the ASVspoof 2019 Logical Access (LA) dataset, and an EER of 1.14% and min-tDCF of 0.03 on the ASVspoof 2019 Physical Access(PA) dataset, demonstrating its robustness in detecting various types of audio spoofing attacks. Finally, on the ASVspoof 2021 LA dataset the method achieved an EER of 7.44% and min-tDCF of 0.35.},
  archive      = {J_KBS},
  author       = {Gul Tahaoglu and Daniele Baracchi and Dasara Shullani and Massimo Iuliani and Alessandro Piva},
  doi          = {10.1016/j.knosys.2025.113726},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113726},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deepfake audio detection with spectral features and ResNeXt-based architecture},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning by gradient monitoring for remaining useful lifetime estimation. <em>KBS</em>, <em>323</em>, 113721. (<a href='https://doi.org/10.1016/j.knosys.2025.113721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential addition of tasks in a learning regime leads to catastrophic forgetting of previous knowledge when learning is focused solely on new tasks. This complication can be alleviated by preserving the old data and retraining the network or introducing new networks for corresponding tasks. However, this leads to computation and storage overhead, rendering these solutions impractical in real industrial applications. We introduce a novel Gradient Monitoring (GM) approach to learning incoming tasks and simultaneously preserving old knowledge for predicting the remaining useful life (RUL) of industrial systems. A criterion matrix is formulated to evaluate the relationship between the weights of a network with their corresponding gradients generated during backpropagation. The mean of the criterion, multiplied by a learning factor, generates the threshold for creating a binary masking matrix. We propose two sub-methods of GM namely, Vanilla (VGM) and Momentum (MGM). The binary mask is utilized in VGM whereas, MGM uses the masking memory from previous training iterations along with the binary masks. We perform joint training of task-specific heads using a distillation loss and eliminate the dependency on old datasets. Using theoretical proofs, we demonstrate that GM can greatly reduce backward forgetting of old tasks. We focus our experiments on the RUL estimation of industrial systems and compare our methods with existing frameworks in continual learning (CL). For our CL experiments in RUL estimation, we select the CMAPSS Dataset and the NASA Li-ion Battery dataset, as these datasets offer subsets with varying operational features and diversity in data distribution.},
  archive      = {J_KBS},
  author       = {Sayed Rafay Bin Shah and Andreas Schwung},
  doi          = {10.1016/j.knosys.2025.113721},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113721},
  shortjournal = {Knowl. Based Syst.},
  title        = {Continual learning by gradient monitoring for remaining useful lifetime estimation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFGCN: Decoupled dual-flow dynamic graph convolutional network for multivariate time series forecasting. <em>KBS</em>, <em>323</em>, 113720. (<a href='https://doi.org/10.1016/j.knosys.2025.113720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) is of critical importance in various domains, including climate prediction, financial analysis, and energy management. Multivariate time series data typically exhibit both intra-series and inter-series dependencies, leading to intricate and intertwined relationships. Recently, numerous studies have focused on capturing both types of correlations. Most existing methods adopt a single-flow structure, attempting to capture features from both the time and variable dimensions simultaneously. However, due to the heterogeneous dependencies between the time dimension and variable dimension, single-flow structures are prone to interference in feature learning, making it difficult to effectively model complex dependencies. To address this issue, we propose a decoupled D ual- F low dynamic G raph C onvolutional N etwork (DFGCN) for MTSF, which separately models the intra-series and inter-series dependencies through decoupled feature learning. First, a dual-flow embedding layer is employed to separately represent the features of the time and variable dimensions. Next, we propose a dual-flow dynamic sparse GCN incorporating Pearson correlation, which robustly learns both intra-series and inter-series dynamic dependencies, while effectively reducing the computational cost of the GCN. Then, we introduce a dual-flow global attention layer, which separately learns the global information of inter-series and intra-series dependencies. By combining dynamic sparse GCN and the global attention mechanism, DFGCN is able to effectively model both local and global features in multivariate time series data. Experimental results on multiple real-world datasets show that DFGCN outperforms strong baseline models, with improvements ranging from 2.40% to 19.84%. Ablation experiments further validate the model’s robustness and the effectiveness of its components. Code is available at this repository: https://github.com/junjieyePhD/DFGCN .},
  archive      = {J_KBS},
  author       = {Junjie Ye and Jinhong Li and Rui Su and Sen Yang and Yaqun Huang and Chunna Zhao},
  doi          = {10.1016/j.knosys.2025.113720},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113720},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFGCN: Decoupled dual-flow dynamic graph convolutional network for multivariate time series forecasting},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-guided distillation with uncertainty-driven temperature for incomplete multimodal learning. <em>KBS</em>, <em>323</em>, 113718. (<a href='https://doi.org/10.1016/j.knosys.2025.113718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical multimodal tasks, missing modality data or imbalanced modalities due to challenges in data acquisition have drawn significant attention, as they often lead to a substantial decline in model performance. Recent studies have focused on addressing this problem by learning specific feature representations from different modality combinations or knowledge transfer. However, the modality feature diversity, which determines the model’s ability to characterize decision boundaries and learn robust feature mappings, is usually overlooked during the transfer. To address the problem, a novel method called boundary-guided distillation (BGD) with uncertainty-driven temperature for incomplete multimodal learning is proposed, in which the modal features are diversified by pushing feature vectors toward decision boundaries in the latent feature distribution space through adversarial attack. Based on the enriched modality features, an uncertainty-driven knowledge distillation strategy is designed after theoretical analysis to align the logical ability of the full modality model (teacher) and any incomplete modality model (student), enhancing modal information transfer and reducing prediction errors under missing modality conditions. Extensive experiments on multimodal classification and segmentation tasks demonstrate the effectiveness of BGD, achieving an average accuracy improvement of 1.06% on classification datasets and 1.09% on segmentation datasets.},
  archive      = {J_KBS},
  author       = {Yiye Xu and Ying Chen and Linbo Xie},
  doi          = {10.1016/j.knosys.2025.113718},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113718},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boundary-guided distillation with uncertainty-driven temperature for incomplete multimodal learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized federated learning meets physics-informed neural networks. <em>KBS</em>, <em>323</em>, 113717. (<a href='https://doi.org/10.1016/j.knosys.2025.113717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of domain knowledge into the learning process of artificial intelligence (AI) has received significant attention in the last few years. Most of the approaches proposed so far have focused on centralized machine learning scenarios, with less emphasis on how domain knowledge can be effectively integrated in decentralized settings. In this paper, we address this gap by evaluating the effectiveness of domain knowledge integration in distributed settings, specifically in the context of Decentralized Federated Learning (DFL). We propose the Physics-Informed DFL (PIDFL) architecture by integrating domain knowledge expressed as differential equations. We introduce a serverless data aggregation algorithm for PIDFL, prove its convergence, and discuss its computational complexity. We performed comprehensive experiments across various datasets and demonstrated that PIDFL significantly reduces average loss across diverse applications. The proposed PIDFL framework achieves on average over 40% lower test loss compared with the baseline DFLA , and outperforms benchmark approaches ( FedAvg , SegGos , and Scaffold ) across a variety of datasets. This highlights the potential of PIDFL and offers a promising avenue for improving decentralized learning through domain knowledge integration.},
  archive      = {J_KBS},
  author       = {Gianvincenzo Alfano and Sergio Greco and Domenico Mandaglio and Francesco Parisi and Reza Shahbazian and Irina Trubitsyna},
  doi          = {10.1016/j.knosys.2025.113717},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113717},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decentralized federated learning meets physics-informed neural networks},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing virtualized cloud infrastructures with temporal inductive path neural networks for attack detection. <em>KBS</em>, <em>323</em>, 113715. (<a href='https://doi.org/10.1016/j.knosys.2025.113715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Computing (CC) leverages virtualization to maximize hardware utilization and operating system performance. However, securing virtualized cloud infrastructures against advanced cyberattacks remains a pressing challenge. This paper introduces a novel framework titled Securing Virtualized Cloud Infrastructures with Temporal Inductive Path Neural Networks for Attack Detection (SVCI-TIPNN-AD) to enhance intrusion detection capabilities. The proposed model processes input data from the CSE-CIC-IDS2018 and CICDDoS2019 datasets. Feature extraction is accomplished using the Elliptical Monogenic Wavelet Transform (EMWT), capturing complex attack patterns through improved holoentropy and exponential moving average (EMA) features. These features are subsequently analyzed using Temporal Inductive Path Neural Networks (TIPNN) for attack detection. Since TIPNN lacks an adaptive mechanism for optimal parameter tuning, the Brown Bear Optimization Algorithm (BBOA) is employed to fine-tune the model, significantly improving its detection performance. Evaluation metrics such as accuracy, sensitivity, specificity, false positive rate (FPR), F-measure, and Matthews correlation coefficient (MCC) are used to assess model performance. Comparative analysis shows that SVCI-TIPNN-AD achieves superior results, outperforming existing methods—ADF-SVIC-DBN, OFC-DDoS-AML, and DDoS-AD-SDN—by 28.44 %, 26.75 %, and 24.42 % in accuracy, and by 27.74 %, 23.77 %, and 21.62 % in sensitivity, respectively. These improvements demonstrate that integrating BBOA with TIPNN substantially enhances the accuracy and reliability of attack detection in virtualized cloud infrastructures. Thus, SVCI-TIPNN-AD offers a highly effective solution for strengthening cloud security against evolving cyber threats.},
  archive      = {J_KBS},
  author       = {Arul Selvam P and Tamije Selvy P},
  doi          = {10.1016/j.knosys.2025.113715},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113715},
  shortjournal = {Knowl. Based Syst.},
  title        = {Securing virtualized cloud infrastructures with temporal inductive path neural networks for attack detection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the robustness of graph neural networks against adversarial attacks. <em>KBS</em>, <em>323</em>, 113714. (<a href='https://doi.org/10.1016/j.knosys.2025.113714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that graph neural networks (GNNs) are vulnerable to adversarial attacks, posing significant challenges to their deployment in safety-critical scenarios. This vulnerability has spurred a growing focus on designing robust GNNs. Despite this interest, current advancements have predominantly relied on empirical trial and error, resulting in a limited understanding of the robustness of GNNs against adversarial attacks. To address this issue, we conduct the first large-scale systematic study on the adversarial robustness of GNNs by considering the patterns of input graphs, the architecture of GNNs, and their model capacity, along with discussions on sensitive neurons and adversarial transferability. This work proposes a comprehensive empirical framework for analyzing the adversarial robustness of GNNs. To support the analysis of adversarial robustness in GNNs, we introduce two evaluation metrics: the confidence-based decision surface and the accuracy-based adversarial transferability rate. Through experimental analysis, we derive 11 actionable guidelines for designing robust GNNs, enabling model developers to gain deeper insights. The code of this study is available at https://github.com/star4455/GraphRE .},
  archive      = {J_KBS},
  author       = {Tao Wu and Canyixing Cui and Xingping Xian and Shaojie Qiao and Chao Wang and Lin Yuan and Shui Yu},
  doi          = {10.1016/j.knosys.2025.113714},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113714},
  shortjournal = {Knowl. Based Syst.},
  title        = {Understanding the robustness of graph neural networks against adversarial attacks},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMSRec: Large language model with service network augmentation for web service recommendation. <em>KBS</em>, <em>323</em>, 113710. (<a href='https://doi.org/10.1016/j.knosys.2025.113710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparsity of service interactions has always been a challenge for Web service recommendations. Previous studies have attempted to mitigate the sparsity by integrating service auxiliary information. However, these methods often face noise introduction, lack of auxiliary information, and information quality issues that prevent accurate modeling of developers’ needs. Therefore, a Web service recommendation method based on Large Language Model (LLM) augmented service network is proposed in this paper. The method consists of two modules, including the LLM-based service network enhancement and the LLM-enhanced service semantic information integration. The LLM-based service network enhancement module uses LLM to enhance service interactions from natural language perspective and leverages the extensive knowledge base of LLM to enrich the service auxiliary information. The LLM-enhanced service semantic information integration module aims to integrate the LLM-enhanced service text semantic features with the service structure semantic features captured by the graph neural network for more comprehensive learning of service nodes. In addition, a quality constraint mechanism is designed to reduce the sensitivity to low-quality features, narrow the gap between low-quality text generated by LLM and high-quality service description text, and remove unreliable service interaction noise thereby improving the robustness of service recommendation. Experimental results reveal an improvement of 8.15 % , 9.94 % , and 10.4 % in hit ratio, recall, and precision respectively, compared to the baseline method, validating the effectiveness of the proposed method.},
  archive      = {J_KBS},
  author       = {Qian Peng and Buqing Cao and Xiang Xie and Hongfan Ye and Jianxun Liu and Zhao Li},
  doi          = {10.1016/j.knosys.2025.113710},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113710},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLMSRec: Large language model with service network augmentation for web service recommendation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness-aware feature selection: A causal path approach. <em>KBS</em>, <em>323</em>, 113708. (<a href='https://doi.org/10.1016/j.knosys.2025.113708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-world datasets used for training machine learning models may contain sensitive features such as gender, race, and age, raising concerns about unfair treatment of specific groups or individuals. These concerns can frequently be alleviated by feature selection techniques. However, most existing research primarily focuses on removing statistically correlated features with sensitive attributes, which frequently fails to address the underlying causal relationships that contribute to unfair treatment. In this paper, we propose a novel fairness-aware causal feature selection method (FCFS). By constructing a causal diagram and leveraging Markov blanket theory, we identify the discrimination-prone feature set that undermine the fairness of model decisions, then propose direct and indirect causal discriminatory effect measures for each feature within the set. Features with high discrimination effect are iteratively assigned priority for removal. Experimental results on public datasets, including Adult, Boston, and German, demonstrate that the proposed method, FCFS, achieves an ideal trade-off between accuracy and fairness (measured by EOs, DP, EO, and BAD) compared to existing fairness-aware feature selection methods.},
  archive      = {J_KBS},
  author       = {Wenqiong Zhang and Yun Li and Yue Liu},
  doi          = {10.1016/j.knosys.2025.113708},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113708},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fairness-aware feature selection: A causal path approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SEDyConv: Spatially enhanced multi-dimensional dynamic convolution for medical multi-organ segmentation in CTs. <em>KBS</em>, <em>323</em>, 113707. (<a href='https://doi.org/10.1016/j.knosys.2025.113707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated multi-organ segmentation presents a considerable challenge owing to the diversity of organs and individual variations. Current state-of-the-art deep-learning techniques rely primarily on static kernel weights that are fixed after training, thereby limiting their flexibility in adapting to diverse inputs. In this study, we propose a novel multi-organ segmentation method using a plug-and-play three-dimensional dynamic convolution module. This method is designed to address the challenges posed by the variability of CT scans in contrast to static segmentation models. We uniquely leverage multiple input-dependent attention mechanisms to adjust the coefficients across four dimensions of convolutional kernels dynamically, offering enhanced adaptability. This approach surpasses traditional feature-based dynamic methods in terms of flexibility, which is attributable to the global sharing of kernel parameters and a smaller kernel shape. In addition, we utilize a refined local block to preserve the spatial properties and extend the convolutional kernel space to N dimensions, thereby efficiently enhancing the representational capabilities of the model through higher-dimensional feature fusion. Furthermore, we design dynamic switches to integrate multi-dimensional global and local information adaptively, guiding the model to generate feature maps that closely align with the input characteristics. Visualizations of the dynamic coefficients and features generated by different inputs clearly demonstrate the adaptability of our method. Extensive experiments on four multi-organ segmentation datasets with various labeled organs and scales indicate that our proposed method outperforms other state-of-the-art methods in terms of improving the segmentation accuracy, particularly for organs with complex morphologies or small sizes. Code available at: https://github.com/lihaoqin168/SEDyConv .},
  archive      = {J_KBS},
  author       = {Qin Hao and Long Yu and Shengwei Tian and Cheng Zhou and YingYing Yu and Lei Zhang},
  doi          = {10.1016/j.knosys.2025.113707},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113707},
  shortjournal = {Knowl. Based Syst.},
  title        = {SEDyConv: Spatially enhanced multi-dimensional dynamic convolution for medical multi-organ segmentation in CTs},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-integrated multi-modal LSTM-CNN fusion for high-precision epileptic seizure detection from EEG signals. <em>KBS</em>, <em>323</em>, 113703. (<a href='https://doi.org/10.1016/j.knosys.2025.113703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of epileptic seizure detection, integrating advanced technologies is essential for improving accuracy and efficiency. This study introduces a pioneering approach that combines blockchain technology with a multimodal model, integrating Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) architectures, to improve EEG-based seizure detection. The proposed approach addresses the challenge of accurate seizure detection while ensuring secure and private data management through blockchain technology. We generate spectrograms from EEG data to visualize temporal dynamics, enriching the understanding of neural activity patterns. The proposed model effectively integrates the capabilities of LSTM and CNN to capture both temporal dynamics and spatial features in the EEG data. The results show that the proposed model significantly outperforms standard LSTM and CNN models in all performance metrics, including precision, recall, accuracy, and F1-score. Notable improvements were observed, particularly in multi-class seizure detection tasks: binary (ictal vs. non-ictal), ternary (ictal, preictal, normal), and penta-class (ictal, preictal, interictal, postictal, normal). The proposed model achieved a 38.21% increase in test accuracy and a 39% increase in F1-score compared to the baseline models. For binary, ternary, and penta-class classification, the proposed model achieved accuracies of 0.991, 0.979, and 0.907, respectively. Furthermore, the integration of blockchain technology ensures secure and private data management, addressing critical concerns in medical data handling. The proposed hybrid model shows high precision, versatility, security and highlights the potential to revolutionize epileptic seizure detection and contribute to advances in the broader field of EEG analysis.},
  archive      = {J_KBS},
  author       = {Mahmoud O. Mokhiamar and Abdelrahman Mahmoud and Mohamed I. Eldagla and Yassine Aribi and Ahmed M. Anter},
  doi          = {10.1016/j.knosys.2025.113703},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113703},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-integrated multi-modal LSTM-CNN fusion for high-precision epileptic seizure detection from EEG signals},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time encryption of medical images in IoMT using a novel biometric and chaotic approach. <em>KBS</em>, <em>323</em>, 113697. (<a href='https://doi.org/10.1016/j.knosys.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of digital medical imaging and the Internet of Medical Things (IoMT) has raised significant concerns regarding medical image security and patient privacy. Existing encryption methods often struggle to balance computational efficiency with robust security in IoMT environments. This study introduced a novel image encryption system tailored for medical images in IoMT applications. The proposed algorithm employs a multipart secret key system, combining a cloud-based fingerprint dataset for biometric security with an image-derived key to enhance the sensitivity to changes in the plain image. The secret key serves as the input to a newly designed chaotic map that functions as a pseudorandom number generator. The encryption process integrates random value addition, confusion at both decimal and binary levels, and binary-level diffusion. Performance evaluations demonstrated the highly chaotic nature of the proposed map, achieving a Lyapunov exponent close to 500. Security analysis confirms the scheme’s strong resistance to attacks, high noise and data loss recovery rates, and superior performance compared with existing encryption methods. The algorithm achieved a near-zero correlation coefficient, a number of pixel changing rates of 99.652%, and a unified averaged changed intensity of 33.640%, rendering it highly suitable for real-time deployment on resource-constrained IoMT devices.},
  archive      = {J_KBS},
  author       = {Ali Mansouri and Pin Sun and Chengzhi Lv and Yinghua Zhu and Xudong Zhao and Hongwei Ge and Changkai Sun},
  doi          = {10.1016/j.knosys.2025.113697},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113697},
  shortjournal = {Knowl. Based Syst.},
  title        = {Real-time encryption of medical images in IoMT using a novel biometric and chaotic approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring low-resource weather forecasting with echo state network-based architectures and satellite data. <em>KBS</em>, <em>323</em>, 113692. (<a href='https://doi.org/10.1016/j.knosys.2025.113692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud forecasting plays a crucial role in various fields such as agriculture, energy systems, and air travel. An accurate forecasting system can offer significant benefits by improving decision-making efficiency in these areas. This study investigates the use of Echo State Network (ESN)-based architectures for weather forecasting, focusing on cloud prediction across Central Europe using the CloudCast benchmark, which integrates data from Meteosat satellites and the European Centre for Medium-Range Weather Forecasts (ECMWF) model. Two novel techniques are included in this study, evaluated in two different phases. First, the Multi-Reservoir Weighted ESN (MWESN) architecture is proposed, featuring optimised inter-reservoir connections that enhance both the effectiveness and adaptability of the model. This model is evaluated along with advanced ESN architectures, including Multi-Reservoir ESN, Deep ESN among others. Second, the Error-Guided Regional Training (ERT) method is introduced to minimise the computational resources required for forecasting at the pixel level while maintaining high accuracy. Combined, MWESN and ERT demonstrate a 1.41% improvement in accuracy, effectively capturing complex spatio-temporal dynamics while significantly reducing computational demands compared to existing state-of-the-art methods. Additionally, models are tested on low-resource devices such as Raspberry Pi units, illustrating their feasibility for real-world meteorological applications.},
  archive      = {J_KBS},
  author       = {E. López Ortiz and M. Jiménez and L.M. Soria-Morillo and J.A. Álvarez-García and J.J. Vegas-Olmos},
  doi          = {10.1016/j.knosys.2025.113692},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113692},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploring low-resource weather forecasting with echo state network-based architectures and satellite data},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised network compression based on quantum mutual information for fast change detection. <em>KBS</em>, <em>323</em>, 113691. (<a href='https://doi.org/10.1016/j.knosys.2025.113691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geospatial change detection (CD) identifies multitemporal changes in remote sensing (RS) images captured by satellites or aircrafts over the Earth’s surface. Deep learning (DL) methods often achieve high accuracy in CD task due to its powerful representation ability, but usually at a large computational cost. In fast CD scenarios, lightweight methods are required to access on-board processing. Model compression emerges as a promising solution to address this challenge by reducing model complexity while preserving detection accuracy. However, existing compression methods lacks explainability in sense of high dimensional imaging, which undermines their reliability in CD. Additionally, traditional DL approaches rely on heavy manual annotations, which, however is unsuitable for multi-temporal CD due to the unpredictable, random nature of geospatial changes. Therefore, this paper proposes a Mutual-Information-Guided Compression Network for Fast Change Detection (MICNet). Based on knowledge distillation, MICNet serves as a general CD framework for both bi-temporal hyperspectral images (HSIs) and multispectral images (MSIs). It compresses cumbersome DL models into lightweight models for faster inference while maintaining high accuracy. An explainable low-rank quantum mutual information constraint (LQMIC) is designed to facilitate information transfer between the heavy and the light models. Its effectiveness is theoretically explained and experimentally validated. Moreover, a reliable pseudo-label generation mechanism is proposed for self-supervised learning paradigm. Experiments are conducted on six real-world hyperspectral and multispectral image datasets, including a large-scale very-high-resolution (VHR) dataset. MICNet demonstrates significant reductions in inference time and maintains or even surpasses the accuracy of the heavy models.},
  archive      = {J_KBS},
  author       = {Yadong Zhao and Haonan Wu and Zhao Chen},
  doi          = {10.1016/j.knosys.2025.113691},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113691},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised network compression based on quantum mutual information for fast change detection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing android malware detection via knowledge distillation on homogenized function call graphs. <em>KBS</em>, <em>323</em>, 113687. (<a href='https://doi.org/10.1016/j.knosys.2025.113687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN)-based Android malware detection has demonstrated significant potential for accuracy enhancement. However, existing function call graph (FCG) classification methods face two critical limitations: (1) inherent incompatibility between graph heterogeneity and model homogeneity assumptions, and (2) performance degradation in conventional GNNs when processing large-scale FCGs. This paper introduces a novel Android malware detection method (SIGDroid) that addresses these challenges through two key contributions. First, we propose a heterogeneous-to-homogeneous graph transformation technique that simplifies the structural complexity of the graph by focusing on internal function nodes directly related to malicious behaviors while preserving critical malware-related features, including API calls, permissions, and semantic information. Second, we design a Student-Centered Knowledge Distillation framework on Graphs (SCKDG). Diverging from teacher-centric paradigms, SCKDG prioritizes the student model’s learning requirements through a multi-stage adaptive distillation mechanism. The framework dynamically adjusts knowledge propagation strategies based on the student model’s evolving capabilities, implementing a progressive learning process analogous to personalized educational methodologies. Extensive experiments were conducted on two large-scale datasets, simulating real-world scenarios with nearly 144k samples, and the results were compared against those of eight baseline methods. Compared to existing malware detection methods, our approach demonstrates superior performance over other methods that rely on heterogeneous function call graphs. Compared to standard GNN models, our SCKDG method achieves a maximum F1-score improvement of 2.91%.},
  archive      = {J_KBS},
  author       = {Zhendong Wang and Kaiyi Zhang and Shuxin Yang and Daojing He and Sammy Chan},
  doi          = {10.1016/j.knosys.2025.113687},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113687},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing android malware detection via knowledge distillation on homogenized function call graphs},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity feature alignment network for unsupervised domain adaptation of medical image classification. <em>KBS</em>, <em>323</em>, 113676. (<a href='https://doi.org/10.1016/j.knosys.2025.113676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) techniques address the challenge of domain shift in medical imaging by transferring knowledge from labeled source data to unlabeled target data, accounting for discrepancies in image protocols and patient demographics. However, conventional UDA methods predominantly focus on either coarse-grained feature or fine-grained feature alignment, lacking systematic integration of multi-granular feature alignment. This results in insufficient alignment of semantic information across varying feature granularities and consequently limits their performance. To tackle these issues, we propose a novel UDA framework, the Multi-Granularity Feature Alignment Network (MGFA), comprising two core modules: (1) Dual Feature Disentanglement Learning module (DFDL), which employs disentanglement learning to guide the network in learning discriminative domain-invariant features; and (2) Fine-Grained Feature Alignment module (FGFA), which leverages graph convolution to provide fine-granularity information for feature alignment. Our method has been extensively evaluated on adrenal, pulmonary and bladder cancer diagnostics, bridging the heterogeneity gap across different medical centers. The proposed MGFA outperforms state-of-the-art approaches on three cross-center medical image classification datasets, demonstrating superior generalization and diagnostic performance. Moreover, the MGFA significantly impacts AI-assisted physician diagnosis by providing robust decision support, enhancing diagnostic efficiency, and offering more reliable guidance in complex or challenging cases.},
  archive      = {J_KBS},
  author       = {Kun Yang and Houquan Chen and Yucheng Wang and Wenlong Fan and Kexuan Zhou and Ying Xiong and Qingliang Zhao and Jianing Wang and Shilong Chang and Linyan Xue},
  doi          = {10.1016/j.knosys.2025.113676},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113676},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granularity feature alignment network for unsupervised domain adaptation of medical image classification},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid adaptive modeling using neural networks trained with nonlinear dynamics based features. <em>KBS</em>, <em>323</em>, 113674. (<a href='https://doi.org/10.1016/j.knosys.2025.113674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate models are essential for design, performance prediction, control, and diagnostics in complex engineering systems. Physics-based models excel during the design phase but often become outdated during system deployment due to changing operational conditions, unknown interactions, excitations, and parametric drift. While data-based models can capture the current state of complex systems, they face significant challenges, including excessive data dependence, limited generalizability to changing conditions, and inability to predict parametric dependence. This has led to combining physics and data in modeling, termed physics-infused machine learning, often using numerical simulations from physics-based models. This paper introduces a novel approach that departs from standard techniques by uncovering information from nonlinear dynamical modeling and embedding it in data-based models. The goal is to create a hybrid adaptive modeling framework that integrates data-based modeling with newly measured data and analytical nonlinear dynamical models for enhanced accuracy, parametric dependence, and improved generalizability. By explicitly incorporating nonlinear dynamic phenomena through perturbation methods, the predictive capabilities are more realistic and insightful compared to knowledge obtained from brute-force numerical simulations. In particular, perturbation methods are utilized to derive asymptotic solutions which are parameterized to generate frequency responses. Frequency responses provide comprehensive insights into dynamics and nonlinearity which are quantified and extracted as high-quality features. A machine learning model, trained by these features, tracks parameter variations and updates the mismatched model. The results demonstrate that this adaptive modeling method outperforms numerical gray box models in prediction accuracy and computational efficiency.},
  archive      = {J_KBS},
  author       = {Zihan Liu and Prashant N. Kambali and C. Nataraj},
  doi          = {10.1016/j.knosys.2025.113674},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113674},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid adaptive modeling using neural networks trained with nonlinear dynamics based features},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series clustering based on prediction accuracy of global forecasting models. <em>KBS</em>, <em>323</em>, 113649. (<a href='https://doi.org/10.1016/j.knosys.2025.113649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel model-based time series clustering technique. Rather than fitting a model to each time series in isolation and then clustering the estimated model coefficients, our approach finds partitions where a single model accurately represents the entire group. This strategy exploits the inherent similarity between time series to get better model estimates, resulting in more robust and informative clusters. The models fitted to each partition deviate from the classic, ‘local’ time series model classes such as the ARIMA and instead follow the recent so-called ‘global’ forecasting models or cross-learning paradigm. Global models achieve superior predictive accuracy by fitting a more complex model class to the pool of time series in a dataset. This way, similarity information is better exploited and minor sources of heterogeneity are captured by the increased complexity. The procedure has a key additional main benefit. The problem of selecting the number of clusters, often separate from the partitioning process and subjective to the analyst, is completely solved in our case: the number of clusters that optimizes the predictive accuracy of the underlying global forecasting models should be chosen. In an extensive simulation and real-data study, we provide evidence of this approach outperforming reference techniques in both clustering quality and predictive accuracy. As the procedure is agnostic to the choice of the forecasting model, it can be combined with any model class. We provide examples of interpretation for linear models.},
  archive      = {J_KBS},
  author       = {Ángel López-Oriona and Pablo Montero-Manso and José A. Vilar},
  doi          = {10.1016/j.knosys.2025.113649},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113649},
  shortjournal = {Knowl. Based Syst.},
  title        = {Time series clustering based on prediction accuracy of global forecasting models},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A resilient generative model in few-shot question answering. <em>KBS</em>, <em>323</em>, 113629. (<a href='https://doi.org/10.1016/j.knosys.2025.113629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In few-shot question answering (QA), only a limited number of training cases are available to tune pre-trained language models (PLMs) for fitting to the task objective. Because a PLM often contains a large number of parameters optimized by a pretraining objective, it is difficult to bridge the gap between the two optimization objectives with a few training cases, which leads to the overfitting problem. Furthermore, in the decoding process of a generative model, sometimes rebuilding an answer to a question is more challenging than directly choosing from an input, because the ability to rebuild requires more informative knowledge and may generate hallucinatory outputs. Motivated by the above discussions, we propose a resilient deep model to support the few-shot question answering tasks. Instead of ambitiously optimizing a full generative model with a few training cases, the resilient model contains a partial learning module and an answer choosing module to reduce the problems caused by a lack of training cases. This has the advantage to enhance the few-shot learning in question answering. Our method was evaluated using several few-shot QA public evaluation datasets. It achieves a state-of-the-art performance, considerably outperforming related works.},
  archive      = {J_KBS},
  author       = {Anqi Zou and Yanping Chen and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.knosys.2025.113629},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113629},
  shortjournal = {Knowl. Based Syst.},
  title        = {A resilient generative model in few-shot question answering},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpatialIE: Towards adaptive floating waste detection in unpredictable weather. <em>KBS</em>, <em>323</em>, 113621. (<a href='https://doi.org/10.1016/j.knosys.2025.113621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and subsequent cleanup of floating waste are critical for ecosystem protection. However, existing methods face significant challenges in dealing with unpredictable weather, limiting their generalization capabilities. This paper proposes a novel plug-and-play architecture called Image Enhancer with Spatial Search and Aggregation (SpatialIE) . This architecture includes a novel encoder block (KANsformer) based on KANs and a dynamic decoder module leveraging prompt-based learning. The KANsformer in the encoder enhances the model’s ability to learn complex non-linear relationships in degraded images. At the same time, the Multi-Order-Based Prompt Block in the decoder enables dynamic optimization of feature processing strategies. These components allow SpatialIE to refine detection strategies to accommodate unknown weather conditions adaptively. We integrate SpatialIE with common YOLO detectors in an end-to-end training framework using the FloW-img and Water Surface Object Detection Dataset (WSODD) datasets. Experimental results show that our method delivers outstanding performance across multiple and single degradation scenarios, achieving an optimal balance between detection accuracy and storage efficiency.},
  archive      = {J_KBS},
  author       = {Yifan Yin and Xiufeng Liu and Xu Cheng and Yusen Liu and Tianqing Zhu and Huan Huo},
  doi          = {10.1016/j.knosys.2025.113621},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113621},
  shortjournal = {Knowl. Based Syst.},
  title        = {SpatialIE: Towards adaptive floating waste detection in unpredictable weather},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-StyleMixer: A universal adaptive N-to-one framework for cross-domain data augmentation. <em>KBS</em>, <em>323</em>, 113616. (<a href='https://doi.org/10.1016/j.knosys.2025.113616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing domain generalization (DG) approaches that rely on traditional techniques like the Fourier transform and normalization can extract style information for cross-domain data augmentation by confusing styles to enhance model generalization. However, these one-to-one methods face two significant challenges: (1) They cannot effectively extract pure style information in deep layers, potentially disrupting the ability to learn content information. (2) Due to the unknown purity of the extracted style information, considerable resources are required to find the optimal style-mixing configuration based on manual experience. To address these challenges, we propose a universal N-to-one cross-domain data augmentation framework, named Auto-StyleMixer, which not only extracts purer style information but also adapts to learn style-mixing configurations without any manual intervention. The proposed framework can embed any traditional style extraction techniques and can be integrated as a plug-and-play module into any architecture, whether CNNs or Transformers. Extensive experiments demonstrate the effectiveness of the proposed method, showing that it achieves state-of-the-art performance on five DG benchmarks. The source code is available at https://github.com/Jin-huihuang/AutoStyleMixer .},
  archive      = {J_KBS},
  author       = {Huihuang Zhang and Haigen Hu and Bin Cao and Xiaoqin Zhang},
  doi          = {10.1016/j.knosys.2025.113616},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113616},
  shortjournal = {Knowl. Based Syst.},
  title        = {Auto-StyleMixer: A universal adaptive N-to-one framework for cross-domain data augmentation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free open-set domain adaptation via unknown-aware global–local learning. <em>KBS</em>, <em>323</em>, 113576. (<a href='https://doi.org/10.1016/j.knosys.2025.113576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free open-set domain adaptation (SFODA) seeks to promote target domain learning using a model pre-trained on the source domain, where there are domain and category shifts between two domains. The main challenges in SFODA is to recognize target-known instances as one of the shared classes, while rejecting target-unknown instances as unknown classes. Existing SFODA methods primarily rely on task-specific thresholds to differentiate between known and unknown classes, which is typically complex and lacks the information exploration of unknown classes during the source model generation. To address the aforementioned limitations, we propose a novel SFODA approach called unknown-aware global–local learning (UAGL). Specially, UAGL calibrates the traditional closed-set classifier to an open-set classifier by incorporating a placeholder as an indicator of unknown classes, which avoids the cumbersome adjustment of task-specific thresholds. Moreover, we introduce the class-balanced local consensus clustering technique to induce the target model to form a more compact intra-class and more dispersed inter-class feature space. The entropy-guided adversarial global separation is simultaneously designed to depict clearer classification boundaries between the known and unknown classes. Finally, we conduct a range of experiments to verify the effectiveness and superiority of UAGL in comparison to existing state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qing Tian and Yanzhi Li and Canyu Sun and Xiang Liu},
  doi          = {10.1016/j.knosys.2025.113576},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113576},
  shortjournal = {Knowl. Based Syst.},
  title        = {Source-free open-set domain adaptation via unknown-aware global–local learning},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy layout analysis network: Fine-grained multi-scale tampering detection for complex layout personnel documentation images. <em>KBS</em>, <em>323</em>, 113525. (<a href='https://doi.org/10.1016/j.knosys.2025.113525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale layout content tampering (MLCT) introduces a significant challenge in detecting tampered text within complex layout personnel document images (CLPDImg). Unlike existing methods focused on small-scale tampered text regions, MLCT employs a masking strategy for tampered layout content that alters localized text or paragraphs by restructuring the layout and enlarging the tampered regions. This diversity in tampering increases detection complexity due to the hidden and variable nature of the affected regions. Therefore, we propose a Trustworthy Layout Analysis Network (TLANet) to simultaneously analyse the type and authenticity of each layout element in CLPDImg at a fine-grained level. TLANet enhances tampering feature extraction by using a histogram of oriented gradients (HOG) as a multiview representation while focusing on global layout features. Then, TLANet extracts and aligns multilevel dual-stream features step-by-step based on a multi-scale attention mechanism and designs a multilevel dual-stream fusion module to fuse multimodal features at different levels synchronously, improving the adaptability to detection through complementarity of modal information. TLANet redefines the network paradigm for text tamper detection by modelling a joint optimization task that combines layout content and structural analyses. Thereby, mutual constraints and tight integration between layout analysis and tamper detection results are achieved to clarify the potential scope and pattern influence of MLCT behaviours. In evaluation experiments with state-of-the-art algorithms on the constructed LCTD dataset, TLANet achieves the best results in intersection over the union of 74.93%, recall of 80.10%, and precision of 92.06%, respectively, while outstanding performance in layout analysis and operational efficiency.},
  archive      = {J_KBS},
  author       = {Peisen Wang and Bo Wang and Kaijiang Li and Bing Zhou and Chunyi Guo},
  doi          = {10.1016/j.knosys.2025.113525},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113525},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trustworthy layout analysis network: Fine-grained multi-scale tampering detection for complex layout personnel documentation images},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Road graph generator: Mapping roads at construction sites from GPS data. <em>KBS</em>, <em>323</em>, 113501. (<a href='https://doi.org/10.1016/j.knosys.2025.113501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for inferring roads from GPS trajectories to map construction sites. This task presents a unique challenge due to the erratic and non-standard movement patterns of construction machinery, which significantly diverge from typical vehicular traffic on established roads. Our proposed method first identifies intersections in the road network that serve as critical decision points, and then connects them with edges to produce a graph, which can subsequently be used for planning and task allocation. The method includes several physically meaningful parameters that can be tuned to adapt it to different scenarios. We demonstrate the approach by mapping roads at a real-life construction site in Norway. The method is validated on four increasingly complex segments of the map. In our tests, the method achieved perfect precision and recall in detecting intersections and inferring roads in data with no or low noise, while its performance was reduced in areas with significant noise and consistently missing GPS updates.},
  archive      = {J_KBS},
  author       = {Katarzyna Michałowska and Helga Margrete Bodahl Holmestad and Signe Riemer-Sørensen},
  doi          = {10.1016/j.knosys.2025.113501},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113501},
  shortjournal = {Knowl. Based Syst.},
  title        = {Road graph generator: Mapping roads at construction sites from GPS data},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CODdiff: Prior leading diffusion model for camouflage object detection. <em>KBS</em>, <em>323</em>, 113381. (<a href='https://doi.org/10.1016/j.knosys.2025.113381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Camouflage Object Detection (COD) task poses a significant challenge in distinguishing subtle visual distinctions between camouflaged objects and their surroundings. Existing approaches treat COD as a pixel classification task, initiated from the original input and proceeding to the camouflaged objects’ masks through a coarse-to-fine process in multiple cascading stages. Nevertheless, accomplishing the intricate COD task within just a few stages often proves arduous, and the interoperability of each stage is hard to determine. Drawing inspiration from the success of the Diffusion Probabilistic Model (DPM) in image generation, this paper presents an innovative perspective that regards the COD task as a conditional denoising process. This process initiates with Gaussian noise and utilizes the original image as a condition to attain the final outcomes. To address this idea, we propose CODdiff, a distinctive methodology grounded in the diffusion model. CODdiff comprises two autonomous branches dedicated to acquiring diffusion embedding and semantic prior embedding, respectively. These two forms of embedding information are subsequently amalgamated through a mixing strategy at each reverse step. This amalgamation could effectively suppresses background noise while revealing the mask of camouflaged objects. Extensive experiments conducted across 3 widely utilized datasets attest to CODdiff’s superior performance compared to 17 state-of-the-art approaches, illustrating the generalizability of the proposed model. In summary, CODdiff introduces a novel approach to dissect the COD task’s complexity, transforming it into a repetitive Gaussian noise prediction task empowered by advanced computer vision techniques.},
  archive      = {J_KBS},
  author       = {Hong Zhang and Yixuan Lyu and Tian He and Xuliang Li and Yawei Li and Ding Yuan and Yifan Yang},
  doi          = {10.1016/j.knosys.2025.113381},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113381},
  shortjournal = {Knowl. Based Syst.},
  title        = {CODdiff: Prior leading diffusion model for camouflage object detection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupling hyperspectral imaging and deep learning to detect bloom-forming toxic cyanobacteria in mixed assemblages. <em>KBS</em>, <em>322</em>, 113794. (<a href='https://doi.org/10.1016/j.knosys.2025.113794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyanobacterial blooms, particularly those dominated by toxin-producing species, pose critical risks to ecosystems and public health. Monitoring strategies have evolved significantly in the last decades, but still lack near real-time capabilities for effective risk estimations. This study explores the potential of combining hyperspectral imagery (HSI) with machine learning and deep learning to detect the presence of specific cyanobacterial taxa in complex mixtures, even when present at low proportions. This work simulates a real-world scenario in which different cyanobacterial taxa coexist in varying proportions. A HSI library was created from pure cyanobacterial cultures and combined in binary mixtures of three species representative of bloom-forming potentially toxic cyanobacterial genera: Microcystis aeruginosa, Chrysosporum ovalisporum , and Dolichospermum crassum . Reflectance spectra from the visible to near-infrared (VIS-NIR) range of each image were extracted, randomly grouped and filtered. The resulting spectra were preprocessed and used to develop Random Forest (RF) and Neural Network (NN) classification models intended to classify these mixtures. Hyperparameter optimization was performed to achieve the best configuration. Learning curves and classification metrics were utilized to monitor the overall training process as well as the model performance. The resulting models demonstrated remarkable performance, achieving 91–95 % accuracy in classifying pure and mixed assemblages, and 85–90 % in defining the proportion of each species, with NNs consistently outperforming RFs by 4–6 % in both tasks. Even cyanobacteria present at low proportions (e.g., 6 %) were effectively detected and quantified. These findings have important implications for improving and automating cyanobacterial monitoring and risk assessment in current water management strategies.},
  archive      = {J_KBS},
  author       = {Claudia Fournier and Samuel Cirés and Mohammadmehdi Saberioon and Paula Martín-González and Antonio Quesada},
  doi          = {10.1016/j.knosys.2025.113794},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113794},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coupling hyperspectral imaging and deep learning to detect bloom-forming toxic cyanobacteria in mixed assemblages},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RDFT-CDUN: Image compressed sensing using complex-valued measurement matrix and complex-based deep unfolding network. <em>KBS</em>, <em>322</em>, 113793. (<a href='https://doi.org/10.1016/j.knosys.2025.113793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The commonly used image compressive sensing (CS) approaches predominantly operate in the real domain, and employ random measurement matrices and deep unfolding reconstruction techniques. However, these methods face significant challenges in handling high-dimensional signals owing to the unstructured nature of random matrices and the complicated architectures of deep unfolding networks. In this study, we present a novel image CS scheme that operates within the complex domain to improve the reconstruction accuracy by using a complex measurement matrix and a complex-based unfolding network. Furthermore, we present a novel complex measurement matrix called RDFT, which incorporates random phase encoding (RPE) into the structural discrete Fourier transform (DFT) matrix, thereby enabling efficient and representative measurement values. Furthermore, we propose a complex-based deep unfolding network (CDUN) that employs complex convolutions and ReLU functions to recover the image from these measurement values. The proposed RDFT-CDUN is the first CS framework that operates within the complex domain to the best of our knowledge. It significantly outperforms the existing state-of-the-art algorithms in terms of reconstruction quality. Our code is available at: https://github.com/dwt112/RDFT-CDUN .},
  archive      = {J_KBS},
  author       = {Wenting Ding and Dan Xu and Jinlong Shi and Qiang Qian},
  doi          = {10.1016/j.knosys.2025.113793},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113793},
  shortjournal = {Knowl. Based Syst.},
  title        = {RDFT-CDUN: Image compressed sensing using complex-valued measurement matrix and complex-based deep unfolding network},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond classification and regression: A novel multi-task deep learning framework for driver state understanding in human-machine co-driving system. <em>KBS</em>, <em>322</em>, 113777. (<a href='https://doi.org/10.1016/j.knosys.2025.113777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential component of the intelligent cockpit, the driver monitoring system (DMS) will continuously provide robust and accurate driver state parameters for the human-machine co-driving system. However, single-objective deep learning tasks based on classification and regression find it challenging to adapt to the monitoring of compound and time-varying behaviors. Consequently, this paper presents a multi-task learning framework based on multimodal visual information (MTLF-MVI) for driver state understanding. By learning the driver’s motion and attention characteristics, MTLF-MVI can identify the level of visual-manual distraction (LoVMD) and driving behavior category (DBC). Firstly, two heterogeneous feature encoders are constructed and pre-trained on large human datasets to acquire general knowledge. Then, a novel spatiotemporal decoupling module maps the fused features to the time and space domains. The decoupled spatiotemporal feature vectors are used to generate LoVMD pseudo-labels and perform self-training of the LoVMD recognition module. Finally, a hybrid loss function is employed to optimize the LoVMD and DBC recognition tasks; the spatiotemporal contrastive learning loss function it contains is used to constrain the feature vectors distribution, representing the similarity between normal and abnormal driving. The test results show that the LoVMD output by MTLF-MVI conforms to the prior knowledge of driving behavior, and the classification accuracy of DBC on the unfamiliar test sets 100-Driver-Day, 100-Driver-Night, and SFD reaches 89.61 %, 82.91 %, and 88.59 % respectively. MTLF-MVI has high accuracy, generalization, and multi-task performance and can provide a valuable reference for developing DMS.},
  archive      = {J_KBS},
  author       = {Xia Zhao and Zhao Li and Yong Ma and Yingfeng Cai and Xiaoqiang Sun and Long Chen},
  doi          = {10.1016/j.knosys.2025.113777},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113777},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond classification and regression: A novel multi-task deep learning framework for driver state understanding in human-machine co-driving system},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-machine learning framework for mathematical modeling of supersonic combustion mode transitions across wide speed range. <em>KBS</em>, <em>322</em>, 113773. (<a href='https://doi.org/10.1016/j.knosys.2025.113773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a machine learning framework to characterize combustion mode transitions in scramjets under multi-physics coupling conditions. We propose an Elastic Net Regression-based approach identifying the shock train leading edge and thermal throat evolution as key features, enabling a comprehensive mathematical model. Through high-fidelity flow field data (Mach 4–8) and vortex-velocity-component composite field analysis, we elucidated multi-physics synergy mechanisms. The equivalence ratio critically regulates heat release via fuel penetration depth variations. Shock trains crossing the primary injector triggers thermo-fluidic coupling mutations, leading to combustion mode transitions. In high-speed conditions, mode transitions are suppressed due to insufficient mixing time in multi-point injections. Incorporating Logistic Regression, we developed empirical formulas for the minimum critical equivalence ratio, showing <1 % prediction errors during validation. This research clarifies parameter interactions and overcomes single-factor analysis limitations. A dual-criteria model based on Shock-Throat interactions provides a foundation for active combustion control, and the quantitative critical equivalence ratio enhances safety boundary predictions, ensuring engineering standards compliance. These findings significantly advance scramjet engine optimization.},
  archive      = {J_KBS},
  author       = {Zhiwen Zhong and Ye Tian and Wenyan Song and Jialing Le},
  doi          = {10.1016/j.knosys.2025.113773},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113773},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid physics-machine learning framework for mathematical modeling of supersonic combustion mode transitions across wide speed range},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A radial basis bayesian regularization neural network process for the malaria disease model. <em>KBS</em>, <em>322</em>, 113722. (<a href='https://doi.org/10.1016/j.knosys.2025.113722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose Malaria is one of the dangerous infectious disease produced through Plasmodium parasites, which is transmitted by the bite of a diseased Anopheles mosquito. The aim of this study is to solve the malaria disease model by using one of the stochastic computing neural network structures. The nonlinear system is presented into the populations of the host and vector using the insecticides and treatment. Method A radial basis neural network uses the radial basis in the hidden layer. The performance of optimization is judged via Bayesian regularization for presenting the solutions of the model. The construction of the data is performed through the explicit Runge-Kutta that decreases the mean square error by adjusting the data for authentication 0.12, testing 0.15, and training 0.73. Results The accurateness of designed stochastic technique is observed based on the matching of the obtained and the published solutions. Moreover, the negligible absolute error performances 10 −05 to 10 −07 , and best training values 10 −09 to 10 −12 also support the exactness of the solver. In addition, the capability of the designed scheme is validated through different values based state transition, regression, and error histogram. Novelty The designed stochastic computational radial basis neural network procedure along with the optimization of Bayesian regularization has never been applied before to solve the malaria disease system.},
  archive      = {J_KBS},
  author       = {Zulqurnain Sabir and Tala Ismail and Hussein Sleem and Muhammad Umar and Soheil Salahshour},
  doi          = {10.1016/j.knosys.2025.113722},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113722},
  shortjournal = {Knowl. Based Syst.},
  title        = {A radial basis bayesian regularization neural network process for the malaria disease model},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning approach to edge suggestion for fair information access on social networks. <em>KBS</em>, <em>322</em>, 113719. (<a href='https://doi.org/10.1016/j.knosys.2025.113719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness in information access on social networks has been actively investigated in recent years. Most existing studies on this topic focus on the problem of Fair Influence Maximization (FIM), which aims to select a set of seed nodes such that a propagation campaign initiated by them has fair influence spread across different groups. Although FIM approaches can guarantee fair access to specific information, they cannot resolve the inherent disparities in information access between different groups arising from graph structures. To address this issue, we study the problem of augmenting the graph structure via edge suggestion towards fairer information access at the group level. Specifically, we formulate a new optimization problem called Fair Information Access via Edge Suggestion (FIAES) that identifies a set of at most b non-existing edges to be added into the graph such that they not only maximally increase the total influence spread, but also ensure fairness in the sense that the influence spreads within different groups are proportional to their population sizes. Since FIAES is NP-hard and cannot be approximated within any constant factor, unless P = NP , we propose FIAES-RL, a reinforcement learning-based algorithm for edge selection that strikes a balance between influence and fairness objectives. Finally, with extensive experimentation on four synthetic and real-world networks, we demonstrate that FIAES-RL outperforms several state-of-the-art baseline methods for fairness-aware edge suggestion, reducing inequity in information access while significantly boosting information propagation.},
  archive      = {J_KBS},
  author       = {Fangzheng Wang and Yanhao Wang and Jingjing Wang and Minghao Zhao},
  doi          = {10.1016/j.knosys.2025.113719},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113719},
  shortjournal = {Knowl. Based Syst.},
  title        = {A reinforcement learning approach to edge suggestion for fair information access on social networks},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From the past to the present: A social bot detection method based on spatio-temporal interactive perception. <em>KBS</em>, <em>322</em>, 113712. (<a href='https://doi.org/10.1016/j.knosys.2025.113712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting social bots is crucial in curbing the widespread dissemination of low-quality information. Previous detection methods have primarily modeled interactions between pairs of accounts, overlooking the influence of group interactions. Moreover, traditional methods have often neglected the temporal dimension in social bot detection. This paper proposes BotSTIP, a social bot detection method from the perspective of spatio-temporal interactions within groups of social accounts. Specifically, BotSTIP begins by capturing each account’s earliest and latest activity time, i.e., the account creation and the data acquisition time, on social media and dividing these into fixed time intervals. Within each interval, it constructs a regular graph based on the follower and following relationships among accounts. Then, a community detection algorithm is applied to each time interval to divide the accounts into communities, forming a hypergraph. A hypergraph neural network (HyperGNN) is subsequently used to extract spatial interaction features for each node, while a Transformer is employed to encode the node sequence based on these spatial interaction features, extracting temporal features. These spatio-temporal interaction feature vectors are then used to detect social bots. Extensive experiments on public datasets validate BotSTIP’s performance. The code is available at https://github.com/FengLiuii/BotSTIP .},
  archive      = {J_KBS},
  author       = {Feng Liu and Rui Ma},
  doi          = {10.1016/j.knosys.2025.113712},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113712},
  shortjournal = {Knowl. Based Syst.},
  title        = {From the past to the present: A social bot detection method based on spatio-temporal interactive perception},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward profundity and precision: Reinventing knowledge retrieval capabilities guided by human cognition. <em>KBS</em>, <em>322</em>, 113711. (<a href='https://doi.org/10.1016/j.knosys.2025.113711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-Based Visual Question Answering (KB-VQA) is a task with distinctive challenges in the AI community. It primarily focuses on the integration of multimodal information with knowledge, aiming to deduce reasonable and authentic answers through such an approach. Recently, the superior performance of vision language models (VLMs) seems to bring about a fundamental change in the path of KB-VQA technology development. However, we find that there are still capability bottlenecks in the approach supported by VLMs: 1) Narrow extraction horizon , which manifests in the inadequate utilization of local and global knowledge. 2) Confusion between necessity and reasonableness . Without rigorous thinking and examination, the final answer is greatly affected by unilateral knowledge. Inspired by the dilation and constriction of the pupil when humans observe global perspectives and local information. We develop PiPi , a novel answer-oriented framework for p rofund i ty and p recis i on in KB-VQA, to mimic this physiological effect. In this paper, we employ the small-scale (7B) VLM to extract relevant knowledge based on the connection between local entities and questions and combine global environment knowledge and local entity knowledge to make inferences and answers, respectively. VLM integrates the reasoning and answers based on the first judgment made with another knowledge system to obtain a knowledgeable and thoughtful answer. We conduct extensive experiments on popular public datasets and demonstrate the rationality and effectiveness of PiPi , especially PiPi achieve a new state-of-the-art (SOTA) performance with a 65.56 % accuracy in the OK-VQA, surpassing the previous most outstanding method (+ 4.46 % ).},
  archive      = {J_KBS},
  author       = {Chao Wang and Luning Zhang and Yang Zhou},
  doi          = {10.1016/j.knosys.2025.113711},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113711},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward profundity and precision: Reinventing knowledge retrieval capabilities guided by human cognition},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aligning first, then fusing: A novel weakly supervised multimodal violence detection method. <em>KBS</em>, <em>322</em>, 113709. (<a href='https://doi.org/10.1016/j.knosys.2025.113709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised violence detection refers to the technique of training models to identify violent segments in videos using only video-level labels. Among these approaches, multimodal violence detection, which integrates modalities such as audio and optical flow, holds great potential. Existing methods in this domain primarily focus on designing multimodal fusion models to address modality discrepancies. In contrast, we take a different approach—leveraging the inherent discrepancies across modalities in violence event representation to propose a novel multimodal semantic feature alignment method. This method sparsely maps the semantic features of local, transient, and less informative modalities (such as audio and optical flow) into the more informative RGB semantic feature space. Through an iterative process, the method identifies the suitable non-zero feature matching subspace and aligns the modality-specific event representations based on this subspace, enabling the full exploitation of information from all modalities during the subsequent modality fusion stage. Building on this, we design a new weakly supervised violence detection framework that consists of unimodal multiple-instance learning for extracting unimodal semantic features, multimodal alignment, multimodal fusion, and final detection. Experimental results on benchmark datasets demonstrate the effectiveness of our method, achieving an average precision (AP) of 86.07% on the XD-Violence dataset. Our code is available at https://github.com/xjpp2016/MAVD .},
  archive      = {J_KBS},
  author       = {Wenping Jin and Li Zhu and Jing Sun},
  doi          = {10.1016/j.knosys.2025.113709},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113709},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aligning first, then fusing: A novel weakly supervised multimodal violence detection method},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal consistency types in multimodal social data. <em>KBS</em>, <em>322</em>, 113705. (<a href='https://doi.org/10.1016/j.knosys.2025.113705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media content, such as internet memes or tweets, are nowadays largely or mainly multimodal. Machine learning models often need to jointly process images and text to solve complex tasks such as hate speech detection or sentiment analysis. For example, the misogyny of a meme cannot be accurately predicted while considering the visual and textual modalities separately. Similarly, sentiment annotations for tweets’ images and text can be discordant. Detecting the samples with inconsistent modality contributions is particularly relevant to analyze machine learning model performance and explain classification errors. In this paper, we formalize the types of cross-modal consistency by differentiating between consistent cases and not. Cross-modal consistency denotes whether all modalities agree on the label (i.e., full consistency) or not (i.e., inconsistency). When the visual and textual modalities are discordant, we distinguish the cases in which a joint analysis of multimodal features is sufficient to solve the issue from those requiring a human agreement (i.e., NOR consistency). We also propose a CLIP-based architecture to predict the cross-modal consistency types and identify the modalities causing the inconsistency. The results achieved on benchmark datasets show that cross-modal consistency annotation is cost-effective, i.e., it provides relevant insights into model predictions while requiring a limited extra human effort.},
  archive      = {J_KBS},
  author       = {Lorenzo Vaiani and Luca Cagliero and Paolo Garza and Jason Ravagli},
  doi          = {10.1016/j.knosys.2025.113705},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113705},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-modal consistency types in multimodal social data},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scene-intra deep mining via shifted instance refinement for weakly supervised person search. <em>KBS</em>, <em>322</em>, 113702. (<a href='https://doi.org/10.1016/j.knosys.2025.113702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised person search aims to train a model using only bounding box annotations, i.e., without person identity labels. Existing approaches focus on mitigating the effects of external factors such as occlusion and scale changes on the performance of weakly supervised person search. However, scenarios specific to person search which often contain key information that helps distinguish pedestrians, are disregarded. To solve this issue, this paper proposes an Instance-scene Joint Refinement (IsJR) approach, which aims to refine the Region of Interest (RoI) by shifting inaccurate proposals during the detection process and fully mining the clues related to instances in the scene. In IsJR, a Confidence driven Instance Offset module (CIO) is designed that offsets the proposal in the scene based on its detection confidence score to obtain the offset box and then generates the offset RoI feature. Moreover, a Scene guided Fine-Grained encoder (SFG) is proposed, which not only explores the fine-grained information of pedestrians, but also introduces scene cues to generate multi-view embeddings. In addition, to enhance embedding discriminability, this paper designs a Cluster-outlier Collaborative hard Loss (CoCL), which exploits outliers in clustering results to mine hard samples between different clusters. Extensive experiments are performed on two standard benchmarks, i.e., PRW and CUHKSYSU datasets, and the results indicate that among weakly supervised one-stage person search approaches, our IsJR achieves a state-of-the-art performance.},
  archive      = {J_KBS},
  author       = {Shenghui Yin and Jinjia Peng and Zhen Wang and Huibing Wang},
  doi          = {10.1016/j.knosys.2025.113702},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113702},
  shortjournal = {Knowl. Based Syst.},
  title        = {Scene-intra deep mining via shifted instance refinement for weakly supervised person search},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeakPolyp-SAM: Segment anything model-driven weakly-supervised polyp segmentation. <em>KBS</em>, <em>322</em>, 113701. (<a href='https://doi.org/10.1016/j.knosys.2025.113701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate polyp segmentation is essential for early detection of polyps, which is of significant clinical importance for the prevention of colorectal cancer. Although various fully-supervised deep learning techniques have been developed for polyp segmentation, pixel-wise annotation by physicians during diagnosis is both time-consuming and expensive. Meanwhile, visual foundation models such as the Segment Anything Model (SAM) have demonstrated remarkable performance in general segmentation tasks. However, directly applying SAM to medical segmentation may not yield satisfactory results due to the lack of medical knowledge. In this paper, we propose a novel SAM-driven weakly-supervised polyp segmentation framework (termed WeakPolyp-SAM), which enables a collaborative learning process between our segmentation network and SAM to boost the model performance. Specifically, we propose a Cross-aware Feature Aggregation Network (CFANet) to effectively aggregate cross-level features and leverage global cues for weakly-supervised polyp segmentation. Within CFANet, we propose a Cross-level Fusion Module (CFM) that integrates the adjacent features to enhance the representation capabilities of different resolution features. Additionally, a Local-and-global Context Decoder (LCD) is presented to capture richer features across multiple levels. Moreover, we present a box-augmentation strategy that combines the segmentation maps generated by CFANet with scribble annotations to create more precise prompts. These prompts are then fed into SAM, generating segmentation SAM-driven masks, which provide additional supervision to effectively train CFANet. Furthermore, we present an image-level filtering mechanism to filter out unreliable masks. Experimental results demonstrate that our WeakPolyp-SAM outperforms state-of-the-art weakly-supervised segmentation methods. The scribble-annotated datasets and code will be released at https://github.com/taozh2017/WeakPolyp-SAM .},
  archive      = {J_KBS},
  author       = {Yiming Zhao and Tao Zhou and Yunqi Gu and Yi Zhou and Yizhe Zhang and Ye Wu and Huazhu Fu},
  doi          = {10.1016/j.knosys.2025.113701},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113701},
  shortjournal = {Knowl. Based Syst.},
  title        = {WeakPolyp-SAM: Segment anything model-driven weakly-supervised polyp segmentation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection via exploring reliable instance similarities. <em>KBS</em>, <em>322</em>, 113700. (<a href='https://doi.org/10.1016/j.knosys.2025.113700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-label feature selection methods commonly employ graph regularization to formulate sparse regression objectives based on manifold learning. However, these approaches face two primary challenges. First, they typically rely on fixed similarities derived from the original feature space, which can be unreliable due to irrelevant features. Second, while pseudo-labeling incorporates supervised information, traditional methods often neglect the global similarity structure among instances. To overcome these issues, we propose a two-stage iterative learning method that progressively refines instance similarities, mitigating the influence of irrelevant features. In the first stage (W-stage), we introduce reconstructed labels that integrate both global instance similarities and supervised information, enhancing the model’s capability to capture richer similarity structures among data points. We also integrate instance and label graph regularizations, coupled with an l 2 , 1 -norm constraint, into the objective function to optimize feature weights. In the second stage (S-stage), dynamically updated instance similarities derived from the reduced-dimensional space guide subsequent iterations, facilitating continuous refinement. These two stages collectively form a unified framework that iteratively enhances instance similarities within the reduced feature space while selecting relevant features. Experimental evaluations on 11 datasets demonstrate that our algorithm consistently outperforms eight state-of-the-art methods across six evaluation metrics. Moreover, our method achieves the highest overall performance ranking and exceeds the second-best approach by at least 2.19 ranks for each evaluation metric.},
  archive      = {J_KBS},
  author       = {Cong Guo and Xizhe Wang and Changqin Huang and Yi Wang and Chengling Gao and Xiaodi Huang},
  doi          = {10.1016/j.knosys.2025.113700},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113700},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label feature selection via exploring reliable instance similarities},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel internet of medical things framework for absorbing bioresorbable vascular scaffold towards healthcare monitoring based on improving YOLO paradigms. <em>KBS</em>, <em>322</em>, 113696. (<a href='https://doi.org/10.1016/j.knosys.2025.113696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With cardiovascular disease as the leading cause of morbidity and mortality worldwide, the implantation of bioresorbable coronary stents has become the preferred strategy for treating coronary atherosclerosis. Optical coherence tomography (OCT) technology, with its high-resolution imaging capabilities, has become the primary tool for evaluating these stents. However, manually detecting and analyzing numerous stent instances in OCT images is time-consuming and error-prone, necessitating automated detection methods. In this paper, we propose an innovative framework based on the YOLO structure—YOLO11-CG3W to automatically detect resorbable vascular stents. Specifically, this framework encompasses the entire process from data preparation and preprocessing to deep learning network training, data validation, and testing. During data preparation, cloud-based Hilbert curve indexing is used to improve the efficacy of storage. Subsequently, the YOLO11-CG3W paradigm is put forward to enhance the detection and segmentation capability for Intravascular optical Coherence Tomography (IVOCT) data. In the validation and testing phase, the model successfully predicted new OCT image data and accurately extracted key information about bioresorbable scaffolds. To this end, after conducting related experiments, the results show our framework outperforms most state-of-the-art methods in terms of several indicators, such as mAP and Recall. Besides, this framework not only significantly improves detection accuracy but also contributes to important technological advances in automated monitoring systems for medical Internet of Things (IoT).},
  archive      = {J_KBS},
  author       = {Wangyu Shen and Wen Zhou},
  doi          = {10.1016/j.knosys.2025.113696},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113696},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel internet of medical things framework for absorbing bioresorbable vascular scaffold towards healthcare monitoring based on improving YOLO paradigms},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPMFormer: Simplified physical model-based transformer with cross-space loss for underwater image enhancement. <em>KBS</em>, <em>322</em>, 113694. (<a href='https://doi.org/10.1016/j.knosys.2025.113694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The absorption and scattering of light by water lead to the degradation of underwater images, resulting in image color distortion and blurred details. Recently, Transformer models have been extended to underwater image enhancement (UIE) and seem to have achieved promising results. However, most existing Transformer-based UIE methods overlook the benefits of physical models with underwater characteristics for scene understanding and pose significant challenges for resource-constrained underwater devices (e.g., autonomous underwater vehicles) due to the added computational costs of redesigned attention mechanisms. To bridge this gap, a simple yet novel Transformer framework based on S implified underwater P hysical M odels (SPMFormer) is proposed. Specifically, by introducing physical models, a novel Underwater Enhancement Patch Embedding (UEPE) is designed to preliminarily restore underwater images instead of redesigning attention mechanisms. Secondly, a novel cross-space loss function that incorporates channel-level ratio information from both RGB and LAB color spaces with the frequency domain of the image is proposed, further enhancing image details. Thirdly, a carefully designed lightweight version of SPMFormer has been developed, achieving a remarkable reduction of up to 450 × lower network parameters and computations, which is critical for underwater devices. Finally, extensive experiments on three benchmark datasets show that our SPMFormer efficiently achieves the best performance compared to other transformer-based methods in qualitative and quantitative metrics. The usability and generalizability of SPMFormer have been demonstrated by our cross-dataset and real-world ocean experiment results.},
  archive      = {J_KBS},
  author       = {Zhuohao Li and Qichao Chen and Jianming Miao},
  doi          = {10.1016/j.knosys.2025.113694},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113694},
  shortjournal = {Knowl. Based Syst.},
  title        = {SPMFormer: Simplified physical model-based transformer with cross-space loss for underwater image enhancement},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-aware bike flow prediction framework with dynamic edge fusion and memory integration. <em>KBS</em>, <em>322</em>, 113693. (<a href='https://doi.org/10.1016/j.knosys.2025.113693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-Sharing Systems (BSSs) have become a popular solution to urban sustainability concerns, providing affordable and environmentally friendly transportation. However, modeling and predicting shared-bike flow patterns are essential for developing intelligent transportation systems and facilitating city management. Despite the existence of several inflow and outflow prediction models, certain unresolved issues remain, including the inability to differentiate and capture heterogeneous dynamic relationships within daily flows, and the suboptimal utilization of historical flow data for forecasting. To address these limitations, we propose MVRC (Multi-View Relational Framework based on Clustering), a novel deep-learning framework for precise inflow and outflow prediction. The MVRC framework models three types of heterogeneous dynamic flow relationships during different periods of the day. Initially, we introduce a novel clustering method to group nearby stations exhibiting similar patterns, followed by creating a dynamic memory module to store and update edge attributes based on the time of day. Furthermore, the dynamic edge fusion mechanism effectively integrates heterogeneous, time-evolving flow features, capturing their varying impacts. To further enhance the model’s capabilities, an offline component that leverages historical data is incorporated, improving performance during testing. Extensive experiments conducted on real datasets from New York City and Washington, D.C., demonstrate the superior prediction efficiency and framework effectiveness of the MVRC framework compared to existing state-of-the-art techniques. These results highlight the practicality and efficacy of MVRC in terms of prediction accuracy and stability.},
  archive      = {J_KBS},
  author       = {Taha M.Rajeh and Tianrui Li and Zhpeng Luo and Muhammad Hafeez Javed and Fares Alhaek},
  doi          = {10.1016/j.knosys.2025.113693},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113693},
  shortjournal = {Knowl. Based Syst.},
  title        = {Time-aware bike flow prediction framework with dynamic edge fusion and memory integration},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reward guidance for reinforcement learning tasks based on large language models: The LMGT framework. <em>KBS</em>, <em>322</em>, 113689. (<a href='https://doi.org/10.1016/j.knosys.2025.113689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent uncertainty in the environmental transition model of Reinforcement Learning (RL) necessitates a delicate balance between exploration and exploitation. This balance is crucial for optimizing computational resources to accurately estimate expected rewards for the agent. In scenarios with sparse rewards, such as robotic control systems, achieving this balance is particularly challenging. However, given that many environments possess extensive prior knowledge, learning from the ground up in such contexts may be redundant. To address this issue, we propose L anguage M odel G uided reward T uning ( LMGT ), a novel, sample-efficient framework. LMGT leverages the comprehensive prior knowledge embedded in Large Language Models (LLMs) and their proficiency in processing non-standard data forms, such as wiki tutorials. By utilizing LLM-guided reward shifts, LMGT adeptly balances exploration and exploitation, thereby guiding the agent’s exploratory behavior and enhancing sample efficiency. We have rigorously evaluated LMGT across various RL tasks and evaluated it in the embodied robotic environment Housekeep. Our results demonstrate that LMGT consistently outperforms baseline methods. Furthermore, the findings suggest that our framework can substantially reduce the computational resources required during the RL training phase.},
  archive      = {J_KBS},
  author       = {Yongxin Deng and Xihe Qiu and Jue Chen and Xiaoyu Tan},
  doi          = {10.1016/j.knosys.2025.113689},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113689},
  shortjournal = {Knowl. Based Syst.},
  title        = {Reward guidance for reinforcement learning tasks based on large language models: The LMGT framework},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online task-free continual learning via discrepancy mechanism. <em>KBS</em>, <em>322</em>, 113688. (<a href='https://doi.org/10.1016/j.knosys.2025.113688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task Free Continual Learning (TFCL) involves training a deep neural network in a dynamic changing environment defined by unpredictable probabilistic data representation changes. Catastrophic forgetting, which occurs when the network’s weights are replaced following training, is the main factor of performance degeneration in the TFCL. We develop a theoretical framework that accounts for the forgetting process in a continual learning model by deriving the generalization bounds when learning new data while preserving the previously learnt data representations. The theoretical analysis indicates that by dynamically creating new trainable submodels when new information becomes available, can address the challenges of catastrophic forgetting. We then propose the Online Discrepancy Distance Learning (ODDL) model, which expands model’s architecture by evaluating the difference between what was learned by the components of a mixture model and a memory buffer storing the newly available data for training. We then also develop a sample selection approach based on a proposed discrepancy distance, which stores only those samples deemed critical to the learning of the model, ensuring the learning of diverse information. The proposed methodology outperforms other static and dynamic expansion models in various TFCL applications.},
  archive      = {J_KBS},
  author       = {Fei Ye and Adrian G. Bors},
  doi          = {10.1016/j.knosys.2025.113688},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113688},
  shortjournal = {Knowl. Based Syst.},
  title        = {Online task-free continual learning via discrepancy mechanism},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective multi-view representation learning for single-view attributed graph clustering. <em>KBS</em>, <em>322</em>, 113675. (<a href='https://doi.org/10.1016/j.knosys.2025.113675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in graph convolutional networks (GCNs) have increasingly used graph attention mechanisms for generating embedded feature representations for graph clustering. However, regardless of whether multi-view or single-view clustering is used, owing to the sensitivity of graph attention mechanisms to structural noise, the obtained embedded feature representations often lack robustness. Furthermore, with single-view data, existing multi-view clustering methods lose their collaborative potential when relying on a single-view graph structure, making it challenging to generate effective multi-view representations. To address these issues, this study proposes a novel single-view attributed graph clustering model - S2M, which learns effective multi-view feature embeddings. We propose a flexible and controllable data enhancement method for single-view data that constructs a multi-view graph while reducing the impact of structural noise. Subsequently, we introduce a novel approach that leverages node predictions to guide multi-view feature fusion, enabling the learning of clustering-oriented representations and deriving target distribution from high-confidence nodes. In addition, we improve clustering robustness through cross-coding, leveraging the consistency and collaboration of embeddings across multiple view branches. Extensive experiments on benchmark datasets confirm that the proposed method delivers superior clustering performance, surpassing state-of-the-art approaches. This code is available at https://github.com/hengliusky/S2M_Clustering .},
  archive      = {J_KBS},
  author       = {Heng Liu and Weizhi Zhao and Zhou Bao and Mingquan Ye and Caifeng Shan},
  doi          = {10.1016/j.knosys.2025.113675},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113675},
  shortjournal = {Knowl. Based Syst.},
  title        = {Effective multi-view representation learning for single-view attributed graph clustering},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-encoding enhancement: A screen-shooting resistant watermarking scheme with feature enhancement and hybrid distortion simulation. <em>KBS</em>, <em>322</em>, 113673. (<a href='https://doi.org/10.1016/j.knosys.2025.113673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based screen shooting watermarking is critical for digital copyright protection, yet existing methods predominantly focus on spatial-domain embedding while neglecting frequency-domain potentials, leading to compromised robustness and visual quality. We propose a cascaded Post-Encoding Enhancement (PEE) framework that hierarchically decouples spatial-frequency features through two key components: (1) a message-adaptive pre-encoder for primary embedding, and (2) an Encoded Feature Separation and Enhancement Network (EFSEN) explicitly optimizing low-frequency components to balance imperceptibility and robustness. To address real-world shooting distortions, we further develop a Batch-Intra Hybrid Distortion (BIHD) simulator integrating multi-type distortions with a Batch-aware Attention Mechanism (BAM) for context-sensitive assignments. Experiments demonstrate our framework achieves a 6.3 dB PSNR improvement over state-of-the-art learning-based methods with over 96.8% extraction accuracy under varying shooting conditions.},
  archive      = {J_KBS},
  author       = {Zhuangjifei Liu and Jiaohua Qin and Xuyu Xiang and Yuanjing Luo and Yun Tan},
  doi          = {10.1016/j.knosys.2025.113673},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113673},
  shortjournal = {Knowl. Based Syst.},
  title        = {Post-encoding enhancement: A screen-shooting resistant watermarking scheme with feature enhancement and hybrid distortion simulation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NuSegDG: Integration of heterogeneous space and gaussian kernel for domain-generalized nuclei segmentation. <em>KBS</em>, <em>322</em>, 113641. (<a href='https://doi.org/10.1016/j.knosys.2025.113641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-generalized nuclei segmentation refers to the generalizability of models to unseen domains based on knowledge learned from source domains and is challenged by various image conditions, cell types, and stain strategies. Recently, the Segment Anything Model (SAM) has made great success in universal image segmentation by interactive prompt modes (e.g., point and box). Despite its strengths, the original SAM presents limited adaptation to medical images. Moreover, SAM requires providing manual bounding box prompts for each object to produce satisfactory segmentation masks, so it is laborious in nuclei segmentation scenarios. To address these limitations, we propose a domain-generalizable framework for nuclei image segmentation, abbreviated to NuSegDG. Specifically, we first devise a Heterogeneous Space Adapter (HS-Adapter) to learn multi-dimensional feature representations of different nuclei domains by injecting a small number of trainable parameters into the image encoder of SAM. To alleviate the labour-intensive requirement of manual prompts, we introduce a Gaussian-Kernel Prompt Encoder (GKP-Encoder) to generate density maps driven by a single point, which guides segmentation predictions by mixing position prompts and semantic prompts. Furthermore, we present a Two-Stage Mask Decoder (TSM-Decoder) to effectively convert semantic masks to instance maps without the manual demand for morphological shape refinement. Based on our experimental evaluations, the proposed NuSegDG demonstrates state-of-the-art performance in nuclei semantic and instance segmentation, exhibiting superior domain generalization capabilities. The source code is available at https://github.com/xq141839/NuSegDG .},
  archive      = {J_KBS},
  author       = {Zhenye Lou and Qing Xu and Zekun Jiang and Xiangjian He and Chenxin Li and Zhen Chen and Yi Wang and Maggie M. He and Wenting Duan},
  doi          = {10.1016/j.knosys.2025.113641},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113641},
  shortjournal = {Knowl. Based Syst.},
  title        = {NuSegDG: Integration of heterogeneous space and gaussian kernel for domain-generalized nuclei segmentation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSTM new gate for computing the efficiency on inputdata. <em>KBS</em>, <em>322</em>, 113622. (<a href='https://doi.org/10.1016/j.knosys.2025.113622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognized learning ability of neural networks (NNs) is determined by their training process. The NN data-dependent nature makes that their success depends to a large extent on the quality of the training data sets. This paper addresses the selection of the best training sets for Long Short Time Models (LSTMs) in real-life contexts. If such selection from a theoretical standpoint is already complex, it becomes challenging when addressed for real scenarios, where effectiveness should be replaced by efficiency (i.e., effectiveness in the shortest possible time and without increasing the computational cost). Our proposal revolves around the introduction, definition and structuring of a new LSTM gate : the efficiency gate , that applies to those inputs that have passed the forget gate. The efficiency gate is responsible for ensuring that training advances only with the best inputs in the sense that the corresponding outputs match as closely as possible with a target value (best estimators). For this purpose, new mathematical results will be demonstrated here in order to prove that our efficiency gate is mathematically feasible. We also fully describe how the new gate joins the LSTM operation, blending in with it. The consequence of such natural integration is that the computational effort is practically unchanged. Our methodology also allows the user to set the admissible error thresholds (which are different in each real scenario) as part of the setting options.},
  archive      = {J_KBS},
  author       = {Julia García Cabello and Santiago Carbó-García},
  doi          = {10.1016/j.knosys.2025.113622},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113622},
  shortjournal = {Knowl. Based Syst.},
  title        = {LSTM new gate for computing the efficiency on inputdata},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alpha entropy search for new information-based bayesian optimization. <em>KBS</em>, <em>322</em>, 113612. (<a href='https://doi.org/10.1016/j.knosys.2025.113612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) methods based on information theory have obtained state-of-the-art results in several tasks. These techniques rely on the Kullback–Leibler (KL) divergence to compute the acquisition function. We introduce a novel information-based class of acquisition functions for BO called Alpha Entropy Search (AES). AES is based on the alpha-divergence, which generalizes the KL-divergence. Iteratively, AES selects the next evaluation point as the one whose associated target value has the highest level of dependency with respect to the location and associated value of the global maximum of the optimization problem. Dependency is measured in terms of the alpha-divergence, as an alternative to the KL-divergence. Intuitively, this favors evaluating the objective function at the most informative points about the global maximum. The alpha-divergence has a free parameter α , which determines the behavior of the divergence, balancing local and global differences. Therefore, different values of α result in different acquisition functions. AES acquisition lacks a closed-form expression. However, we propose an efficient and accurate approximation using a truncated Gaussian distribution. In practice, the value of α can be chosen by the practitioner, but here we suggest using a combination of acquisition functions obtained by simultaneously considering a range of α values. We provide an implementation of AES in BOTorch and we evaluate its performance in synthetic, benchmark, and real-world experiments involving the tuning of the hyper-parameters of a deep neural network. These experiments show that AES performance is competitive with other information-based acquisition functions such as JES, MES, or PES.},
  archive      = {J_KBS},
  author       = {Daniel Fernández-Sánchez and Eduardo C. Garrido-Merchán and Daniel Hernández-Lobato},
  doi          = {10.1016/j.knosys.2025.113612},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113612},
  shortjournal = {Knowl. Based Syst.},
  title        = {Alpha entropy search for new information-based bayesian optimization},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale joint learning with negative sample mining for non-autoregressive machine translation. <em>KBS</em>, <em>322</em>, 113610. (<a href='https://doi.org/10.1016/j.knosys.2025.113610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Autoregressive Transformer (NAT) is a family of text generation models designed to reduce decoding latency by predicting entire sequences in parallel. Unlike the Autoregressive Transformer (AT), which generates tokens sequentially, NAT models enable significantly faster inference. However, this parallel decoding process introduces challenges, particularly the “multi-modality problem”, where multiple valid translation references interfere with each other, leading to incoherent outputs and degraded translation quality. To address these challenges, we propose a novel training framework that integrates “Negative Sample Mining” and “Multi-Scale Joint Learning”. Negative Sample Mining utilizes a pretrained AT model to generate multiple translation references, treating them as negative samples. These negative samples serve as contrastive learning signals, helping the NAT model distinguish between the ground truth and competing references, thereby mitigating the impact of multi-modality. Building upon this, we introduce a new loss function that incorporates both token-level positive samples and sentence-level negative samples. This dual-objective optimization not only rewards the model for accurate predictions but also penalizes overly similar translation references, improving its ability to differentiate between competing outputs. With a single-pass parallel decoding process, our method achieves high-quality translation with a 14×–15× Speedup. Experimental results demonstrate that our proposed framework significantly enhances NAT’s ability to model dependencies between target tokens, leading to improved translation quality. Evaluations on WMT benchmarks show that our approach consistently outperforms existing NAT baseline models, achieving state-of-the-art performance across all translation directions. Specifically, our method surpasses the previous best systems by 0.2 to 0.64 BLEU points, further advancing the capabilities of NAT.},
  archive      = {J_KBS},
  author       = {Xiangyu Qu and Guojing Liu and Liang Li},
  doi          = {10.1016/j.knosys.2025.113610},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113610},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-scale joint learning with negative sample mining for non-autoregressive machine translation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-views emotional knowledge extraction for emotion recognition in conversation. <em>KBS</em>, <em>322</em>, 113601. (<a href='https://doi.org/10.1016/j.knosys.2025.113601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion Recognition in Conversation (ERC) is a challenging task due to the scarcity and dispersion of contextual information across utterances. Most existing methods attempt to integrate comprehensive information to enhance utterance semantics, which, however, also introduces noise and irrelevant content, misleading the model and limiting its potential in emotion recognition. To this end, we introduce the concept of Conversational Clique (ConvClique) and propose CC-ERC, a multi-view emotional knowledge extraction method designed to capture the most relevant emotional cues within the ConvClique from complementary perspectives and collaboratively predict utterance emotions. Specifically, CC-ERC comprises two modules: 1) the Utterance Spatial Relationship (USR) module, which predicts emotions by modeling structural correlations among utterances, and 2) the Emotion Temporal Relationship (ETR) module, which captures emotion sequence patterns to determine utterance emotions. These modules are integrated to obtain the final prediction, contributing to the robustness and accuracy of emotion recognition. The effectiveness of CC-ERC is validated on three widely used ERC datasets, evaluated in both online and offline settings. Compared to the state-of-the-art methods, CC-ERC achieves average improvements of 0.63% in accuracy and 0.94% in weighted F1 scores. Ablation studies further validate the significance of ConvClique-based knowledge extraction and demonstrate the effectiveness of the USR and ETR modules in modeling utterance structural correlations and emotion sequence patterns.},
  archive      = {J_KBS},
  author       = {Zhongquan Jian and Daihang Wu and Shaopan Wang and Jiezhou He and Junfeng Yao and Kunhong Liu and Qingqiang Wu},
  doi          = {10.1016/j.knosys.2025.113601},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113601},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-views emotional knowledge extraction for emotion recognition in conversation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aligning large language models with human preferences using historical text edits. <em>KBS</em>, <em>322</em>, 113566. (<a href='https://doi.org/10.1016/j.knosys.2025.113566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning large language models with human values (to be helpful, harmless, honest) requires high-quality, comprehensive human preference datasets. However, the substantial cost of creating such datasets often limits their size and scope, hindering preference learning research and limiting open-source model development. In our research, we propose EditPrefs, a cost-effective method that uses historical text edits to create preference datasets without manual data labeling or distilling preferences from strong language models. Our method automatically builds the dataset while capturing genuine human preferences expressed through text revisions. The method constructs the dataset by treating the revised text as a response preferred over the original text and generates matching instructions using a language model. To validate EditPrefs, we applied it to Wikipedia article revisions and extensively evaluated the resulting dataset’s performance. The Zephyr-7b- β -SFT model aligned with our dataset performed on par with models trained on manually curated datasets. Additionally, a reward model trained on our dataset captured more nuanced human preferences and outperformed models trained on widely used datasets built through crowd-sourcing, manual annotation, or distillation from large language models. These findings validate the effectiveness of our approach, highlighting its potential for creating larger, more diverse, and potentially multilingual or domain-specific preference datasets.},
  archive      = {J_KBS},
  author       = {Jan Majkutewicz and Julian Szymański},
  doi          = {10.1016/j.knosys.2025.113566},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113566},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aligning large language models with human preferences using historical text edits},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phototropic growth algorithm: A novel metaheuristic inspired from phototropic growth of plants. <em>KBS</em>, <em>322</em>, 113548. (<a href='https://doi.org/10.1016/j.knosys.2025.113548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel optimization algorithm called the Phototropic Growth Algorithm (PGA), which takes its inspiration from the growth patterns of plant cells in response to sunlight. The proposed algorithm has been evaluated on two benchmark test function suites, the CEC 2017 and CEC 2020, and compared to other established metaheuristic-optimization algorithms based on the quality of the solutions obtained. The effectiveness of PGA is further demonstrated by testing it on six challenging engineering design problems with constraints, showcasing its robustness in solving real-world problems with unknown search spaces. Simulation results show that PGA outperforms other competitive algorithms by consistently generating superior solutions and demonstrates strong potential for solving complex optimization tasks using a nature-inspired approach.},
  archive      = {J_KBS},
  author       = {Vijay Kumar Bohat and Fatma A. Hashim and Harshit Batra and Mohamed Abd Elaziz},
  doi          = {10.1016/j.knosys.2025.113548},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113548},
  shortjournal = {Knowl. Based Syst.},
  title        = {Phototropic growth algorithm: A novel metaheuristic inspired from phototropic growth of plants},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RGB-D visual object tracking with transformer-based multi-modal feature fusion. <em>KBS</em>, <em>322</em>, 113531. (<a href='https://doi.org/10.1016/j.knosys.2025.113531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additional depth information benefits the performance of tracking methods in the complex scenarios characterized by background clutter and occlusion; thus, the visual object tracking (VOT) using RGB-D videos has been widely discussed. However, the existing RGBD trackers neglect long-range interactive information between RGB and depth videos, limiting the further improvement. In this study, two transformer-based modules are proposed to mine the interactive information between two modalities and improve the RGB-D tracker’s performance based on the enhanced features of the learned interactive information. A multi-modal feature enhancement (MFE) module combining the intra and inter information from the RGB and depth features is proposed. In addition, a multi-model fusion module, which integrates interactive information across tokens in the two modalities in the fused feature, is introduced. Building upon these modules, a new RGB-D object tracking method, RDT-TEF, is proposed. The comprehensive experiments considered three object tracking datasets, i.e., CDTB, DepthTrack and VOT-RGBD2022. The results indicate that the proposed tracker achieves better performance.},
  archive      = {J_KBS},
  author       = {Long Gao and Yuze Ke and Wanlin Zhao and Yang Zhang and Yan Jiang and Gang He and Yunsong Li},
  doi          = {10.1016/j.knosys.2025.113531},
  journal      = {Knowledge-Based Systems},
  month        = {7},
  pages        = {113531},
  shortjournal = {Knowl. Based Syst.},
  title        = {RGB-D visual object tracking with transformer-based multi-modal feature fusion},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph neural network for remote sensing hyperspectral image super-resolution. <em>KBS</em>, <em>321</em>, 113755. (<a href='https://doi.org/10.1016/j.knosys.2025.113755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the thriving development of deep learning, the hyperspectral image (HSI) super-resolution (SR) technology has made significant progress. Existing methods often ignore the task orientation of network learning and the global distribution characteristics of the structural and semantic features in images, leading to spatial and spectral distortions. To address these issues and achieve a more comprehensive information representation, we propose a feature fusion method based on a hypergraph neural network and convolutional neural network (HG-CNet). Specifically, we constructed a three-layer hypergraph based on texture features (T), spectral clustering (S), and positional relationships (P), called TSP, and designed a hypergraph attention module (HGAM). The constructed hypergraph imposes a unique learning tendency on the network, enabling it to exploit the feature spaces specific to the HSI SR task better. In addition, we constructed a multi-order spatial interaction module (MSIM) to realize cross-guidance and fusion of different types of features in the network. To the best of our knowledge, this is the first application of hypergraph neural networks for solving an HSI SR task. An extensive comparison of the experimental results on three public datasets demonstrated that HG-CNet performed better than other cutting-edge models.},
  archive      = {J_KBS},
  author       = {Chi Chen and Yongcheng Wang and Yuxi Zhang and Ning Zhang and Hao Feng and Dongdong Xu},
  doi          = {10.1016/j.knosys.2025.113755},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113755},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hypergraph neural network for remote sensing hyperspectral image super-resolution},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimisation of multilayer perceptron neural network using five novel metaheuristic algorithms for the prediction of wear of excavator bucket teeth. <em>KBS</em>, <em>321</em>, 113753. (<a href='https://doi.org/10.1016/j.knosys.2025.113753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous exposure of excavator bucket teeth to abrasive materials during excavation causes wear, leading to frequent replacements and unplanned downtime. Therefore, developing reliable models for accurately predicting bucket teeth wear is crucial for effective maintenance strategies. In this study, novel hybrid artificial intelligence models are introduced to achieve accurate predictions of excavator bucket teeth wear. These models were built on the Multilayer Perceptron Neural Network (MLPNN) and optimised using five metaheuristic optimisation techniques: Whale Optimisation Algorithm (WOA), Particle Swarm Optimisation (PSO), Ant Lion Optimisation (ALO), Grey Wolf Optimisation (GWO), and Genetic Algorithm (GA). These optimisation techniques improved the effectiveness of the MLPNN model by adjusting its weights and biases. The accuracy of the optimised models, along with the standalone MLPNN models, was assessed using six statistical indicators: coefficient of determination (R 2 ), relative root mean square error (RRMSE), mean absolute error (MAE), correlation coefficient (R), root mean square error (RMSE) and mean absolute percentage error (MAPE). Additionally, the Bayesian Information Criterion was employed to choose the top-performing predictive method. The statistical results confirmed the superior performance of the ALO-MLPNN hybrid model, which achieved the lowest error values for RMSE (0.22007), RRMSE (0.00597), MAE (0.10014), and MAPE (0.26704), alongside high values for R² (0.99962) and R (0.99981). Additionally, ALO-MLPNN recorded the lowest Bayesian Information Criterion (BIC) value of -245.53662, reinforcing its effectiveness in predicting on-site wear of excavator bucket teeth. These findings emphasise the model’s strong potential to enhance the accuracy of AI-based wear prediction systems.},
  archive      = {J_KBS},
  author       = {Godwin Ativor and Victor Amoako Temeng and Yao Yevenyo Ziggah},
  doi          = {10.1016/j.knosys.2025.113753},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113753},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimisation of multilayer perceptron neural network using five novel metaheuristic algorithms for the prediction of wear of excavator bucket teeth},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning-based dynamic multi-objective optimization approach for integrated timetabling and vehicle scheduling. <em>KBS</em>, <em>321</em>, 113735. (<a href='https://doi.org/10.1016/j.knosys.2025.113735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic integrated timetabling and vehicle scheduling (D-ITVS) is essential for mitigating the negative impacts of service disruptions. It involves multiple rescheduling stages, with inherent optimization similarities across these stages. However, existing optimization approaches for the D-ITVS problem have not systematically exploited these similarities, overlooking the potential for decision knowledge from previous stages to inform the current stage. To address this gap, this paper proposes a reinforcement learning-based dynamic multi-objective optimization approach (RL-DMOA), which focuses on transferring decision knowledge between rescheduling stages. This approach models the optimization process of each rescheduling stage in the D-ITVS problem as a Markov decision process, incorporating a state space with vehicle information, action space for vehicle assignment, and a multi-objective reward function. A multi-objective deep reinforcement learning (M-DRL) agent is employed within the RL-DMOA to select actions based on the state at each decision point. The agent is constructed on a multi-objective deep Q-learning network (M-DQN), with a Q-value adjustment layer incorporated to prevent the selection of invalid actions. To select optimal actions while balancing the conflicts among multiple objectives, the M-DRL agent applies a non-dominated sorting selection strategy. Experimental results demonstrate that the proposed RL-DMOA is capable of generating timetables and vehicle schedules with reduced costs, enhanced robustness, and improved convergence and diversity across all rescheduling stages. By balancing operational costs and passenger service quality, these improvements benefit transit operators, and during daily operations, passengers enjoy reduced travel costs and enhanced service reliability.},
  archive      = {J_KBS},
  author       = {Yindong Shen and Wenliang Xie},
  doi          = {10.1016/j.knosys.2025.113735},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113735},
  shortjournal = {Knowl. Based Syst.},
  title        = {A reinforcement learning-based dynamic multi-objective optimization approach for integrated timetabling and vehicle scheduling},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-enhanced LSTM framework for robust malicious traffic detection in industrial control systems. <em>KBS</em>, <em>321</em>, 113725. (<a href='https://doi.org/10.1016/j.knosys.2025.113725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial control systems (ICS) play a vital role in ensuring the safe and efficient operation of critical infrastructures, including power grids, pipelines, and water treatment facilities. The detection of malicious traffic in ICS environments is inherently difficult due to the complexity and diversity of traffic characteristics. In this paper we propose a novel approach of malicious traffic classification in ICS by harnessing the strengths of both the Long Short-Term Memory (LSTM) model and Transformer architecture. Considering the temporal nature of ICS traffic data, we integrate Transformer's embedding and encoder layers into our model to effectively extract sequential features. Additionally, we focus on meticulous feature engineering of the ICS flow dataset, which is essential for accurately capturing feature relevance during model training. Besides, we employ a composite correlation calculation method as imputation matrix, ensuring that the model training is robust and the feature relationships are accurately represented. Extensive experiments are carried on the SCADA flow dataset, which includes a variety of scenarios from natural gas pipelines and water tanks, predominantly based on the Modbus protocol. Our model's performance is benchmarked against seven other models. The results show that our hybrid model outperforms the other methods, making it a promising solution for identifying malicious flows in industrial control systems.},
  archive      = {J_KBS},
  author       = {Fang Wang and Yuxuan Liu and Zhongyuan Qin and Fang Dong},
  doi          = {10.1016/j.knosys.2025.113725},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113725},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transformer-enhanced LSTM framework for robust malicious traffic detection in industrial control systems},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized anti-interference dynamic integral neural network approach for dementia prediction in health care. <em>KBS</em>, <em>321</em>, 113723. (<a href='https://doi.org/10.1016/j.knosys.2025.113723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's is the most common progressive neurological illness, particularly affecting those with mild cognitive impairment. Raising awareness and promoting early diagnosis are crucial to reducing Alzheimer's impact. Advances in machine learning offer promising tools for early prediction. In this manuscript, an Optimized Anti-Interference Dynamic Integral Neural Network Approach for Dementia Prediction in Health Care (DPHC-AIDINN) is proposed. The process begins with collecting OASIS dataset images, pre-processed using the Surface Normal Gabor Filter (SNGF) to remove noise. Shape features like Digital Bending Energy, Circularity Ratio, Rectangularity, and Convexity are then extracted. Using the Child Drawing Development Optimization Algorithm (CDDO), 12 key features are selected and fed into the Anti-Interference Dynamic Integral Neural Network (AIDINN) for dementia classification. To enhance accuracy, the Humboldt Squid Optimization Algorithm (HSOA) optimizes AIDINN, improving classification of demented and non-demented cases. This optimization boosts classification accuracy, with DPHC-AIDINN implemented in Python. The proposed strategy’s performance was evaluated using performance criteria like precision, recall, accuracy, specificity, F1-score, error rate and ROC. DPHC-AIDINN excels in early dementia prediction, achieving 99.39 % accuracy for demented and 99.85 % for non-demented cases. It enhances precision, recall, and F1-score by 97.69 %, cuts errors by 44.97 %, and improves the ROC curve by 96.59 %, outperforming existing methods, such as Classification of Alzheimer’s disease using MRI data based on Deep Learning Techniques (CAD-MRI-SVM), Classification of Vascular Dementia on magnetic resonance imaging using deep learning architectures (VD-MRI-CNN), and Classifying Dementia Severity Using MRI Radiomics Analysis of the Hippocampus and Machine Learning (CDS-MRI-XGB).},
  archive      = {J_KBS},
  author       = {B P Pradeep Kumar ( Professor ) and Ravikumar J and Shankar B B and Manjunath Kamath K},
  doi          = {10.1016/j.knosys.2025.113723},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113723},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized anti-interference dynamic integral neural network approach for dementia prediction in health care},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next-gen IoT security using polar codes-based cryptography for malware defence through quantum self-attention neural network. <em>KBS</em>, <em>321</em>, 113716. (<a href='https://doi.org/10.1016/j.knosys.2025.113716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of the Internet of Things (IoT) has increased security concerns, particularly regarding malware threats. The static and dynamic analysis of malware signatures and behaviour patterns used by current malware detection technologies are time-consuming and have proven to be ineffective for unknown malware detection in real-time. This paper proposes a Next-Gen IoT Security using Polar Codes-based Cryptography for Malware Defense through Quantum Self-Attention Neural Network (NGIT-PCBC-MD-QSANN) for enhancing malware detection and secure data transmission in IoT environments. The framework integrates advanced pre-processing using Multi-Aspect Co-Attentional Collaborative Filtering (MAACF) to address the data irregularities and employs the Signed Cumulative Distribution Transform (SCDT) for extracting contextual features and trust rating. After extraction, the malware detection is performed using Quantum Self-Attention Neural Network (QSANN). It leverages quantum-inspired mechanisms for accurate classification of attacks such as DoS, probe, anomaly and R2L. The Polar Codes-based Cryptography (PCBC) is used with cryptographic key optimization managed by the Multi-Objective Fitness Dependent Optimizer Algorithm (MOFDOA) to ensure secure communication. The experimental results demonstrates high accuracy of 99.5 %, precision of 96 % and low error rate of 5 % when compared with existing methods such as: Enhancement of IoT device security with an Improved Elliptic Curve Cryptography algorithm and malware detection utilizing deep LSTM: High-Confidence Computing (EIDS-IECC-MDUL), An Advance Encryption and Attack Detection Framework for Securing Smart Cities Data in Blockchain using Deep Learning Approach:Wireless Personal Communications (AE-ADF-SSCD-BUDL), an optimized hybrid deep neural network architecture for intrusion detection in real‐time IoT networks (AOH-DNNA-IDRIN) respectively.},
  archive      = {J_KBS},
  author       = {Swati Kumari},
  doi          = {10.1016/j.knosys.2025.113716},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113716},
  shortjournal = {Knowl. Based Syst.},
  title        = {Next-gen IoT security using polar codes-based cryptography for malware defence through quantum self-attention neural network},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESARSA-MRFO-FS: Optimizing manta-ray foraging optimizer using expected-SARSA reinforcement learning for features selection. <em>KBS</em>, <em>321</em>, 113695. (<a href='https://doi.org/10.1016/j.knosys.2025.113695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease prediction with the help of computers has achieved significant progress in this area; however, it still requires a more accurate identification of each data feature. In the past few years, ML-based medical diagnoses have become increasingly dependent on the datasets rather than the algorithms. Consequently, the more features in a dataset, the more difficult the model training process will be. A feature selection (FS) strategy can be used to eliminate unwanted features before the training in order to improve the model performance. Due to the great increase in the number of features, FS causes a complex combinatorial problem, which is NP-hard. The primary goal of this research is to create a novel framework for improving the Manta-ray Foraging Optimizer (MRFO) algorithm’s performance. By the method of exploration–exploitation toggle adjustments, this process becomes the most efficient one by using the Expected State–action-reward-state–action (ESARSA) reinforcement learning strategy. The study employed 12 datasets as well as two classifiers (K-Nearest-Neighbor and Decision-Tree), both with and without hyperparameter adjustment. The study compared the performances of three feature selection methods: no feature selection, the original MRFO algorithm, and the proposed ESARSAMRFO-FS algorithm. The results revealed that ESARSA-MRFO-FS is the most effective of the three algorithms with classifiers and optimization scenarios. Besides, experiments comparing MRFO and ESARSA-MRFO performance on 44 benchmarks are presented in the article. In five functions, ESARSA-MRFO outperforms MRFO. These results confirm that the proposed method is efficient for feature selection in medical diagnosis because of its accuracy and low processing costs.},
  archive      = {J_KBS},
  author       = {Yousry AbdulAzeem and Hossam Magdy Balaha and Amna Bamaqa and Mahmoud Badawy and Mostafa A. Elhosseini},
  doi          = {10.1016/j.knosys.2025.113695},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113695},
  shortjournal = {Knowl. Based Syst.},
  title        = {ESARSA-MRFO-FS: Optimizing manta-ray foraging optimizer using expected-SARSA reinforcement learning for features selection},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HPM-GMN: Hierarchical pooling multi-level graph matching network. <em>KBS</em>, <em>321</em>, 113677. (<a href='https://doi.org/10.1016/j.knosys.2025.113677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex structure of graphs and the rich latent information they entail, calculating the similarity of graphs has always been a challenging problem. Several critical questions have yet to be fully explored: (i) how to thoroughly exploit the abundant information within each graph from diverse angles and granularities, and (ii) how to facilitate sufficient interaction and integration of these varied information types across graphs. To tackle these issues, we introduce HPM-GMN, a hierarchical siamese neural network. It comprises five key components: (i) DiffKPool, a pooling component that extracts essential nodes and inductive subgraphs from each graph; (ii) NCE, which captures node count information across different hierarchies; (iii) CHMN, a Cross-Hierarchy Matching Network for modeling graph interactions; (iv) GPEN, which integrates multiple graph features to generate stage embeddings for each graph; and (v) SEBlock, a channel attention mechanism that adjusts weights within the CHMN’s multi-head attention mechanism. Components (i) and (ii) progressively enrich node types, providing additional information to address challenge (i). Components (iii), (iv), and (v) offer innovative approaches for the rational allocation and fusion of multi-information weights, shedding light on challenge (ii). Extensive experiments on three challenging benchmarks – Linux, AIDS, and IMDBMulti – demonstrate that HPM-GMN outperforms state-of-the-art graph similarity estimation methods.},
  archive      = {J_KBS},
  author       = {Yue Huang and Shengfa Miao and Jing Zou and Yongkang Mu and Yuling Tian and Jian Wang and Yesen Liu and Kuang Li and Puming Wang and Xin Jin and Shaowen Yao},
  doi          = {10.1016/j.knosys.2025.113677},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113677},
  shortjournal = {Knowl. Based Syst.},
  title        = {HPM-GMN: Hierarchical pooling multi-level graph matching network},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated feature engineering for automated machine learning. <em>KBS</em>, <em>321</em>, 113671. (<a href='https://doi.org/10.1016/j.knosys.2025.113671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated feature engineering (AutoFE) and automated machine learning (AutoML) can both be used in a machine learning project to improve the efficiency of a data scientist. In recent years, different algorithms have been developed for both sub fields independently of each other. In this study, the use of AutoFE in combination with AutoML has been evaluated for the first time to determine if AutoFE can increase the model accuracy, while not increasing the computation time. A data fusion meta-learning approach was extended, generalized, and applied to an AutoFE method and then further combined with a pre-existing AutoML method. In the meta-learning approach, more than 150 online data sets were used to create models that recommended the best operator to apply to a certain feature. Using twelve evaluation data sets, we show that combining AutoFE and AutoML is indeed valuable. The accuracy measure used was increased on average by 0.54% compared to using AutoML alone. For multiple data sets, the use of AutoFE significantly outperformed a strategy in which no feature engineering was done, while in the remaining data sets it never significantly performed worse. Therefore, it can be concluded that it is beneficial to combine this computationally efficient AutoFE method with AutoML.},
  archive      = {J_KBS},
  author       = {Casper de Winter and Flavius Frasincar and Bart de Peuter and Vladyslav Matsiiako and Enzo Ido and Jasmijn Klinkhamer},
  doi          = {10.1016/j.knosys.2025.113671},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113671},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated feature engineering for automated machine learning},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open set label noise learning with robust sample selection and margin-guided module. <em>KBS</em>, <em>321</em>, 113670. (<a href='https://doi.org/10.1016/j.knosys.2025.113670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the remarkable success of deep neural networks (DNNs) in computer vision is largely due to large-scale, high-quality labeled datasets. Training directly on real-world datasets with label noise may result in overfitting. The traditional method is limited to deal with in-distribution (ID) label noise, where noisy training data has true class labels within the known label space. However, there are some real-world datasets containing out-of-distribution (OOD) label noise, meaning that some samples belong to an unknown class outside the known label space. To address the OOD label noise problem, we introduce a method based on Robust Sample Selection and Margin-Guided Module (RSS-MGM). Firstly, unlike the prior clean sample selection approach, which only selects a limited number of clean samples, a robust sample selection module combines small loss selection and high-confidence sample selection to obtain more clean samples. Secondly, to efficiently distinguish OOD label noise and ID ones, margin functions are designed to filter OOD data and ID data. Thirdly, different processing methods are selected for different types of samples in order to fully utilize the data’s prior information and optimize the whole model. Furthermore, extensive experimental results with noisy labeled data from benchmark datasets and real-world datasets, such as CIFAR-100N-C, CIFAR80N-O, WebFG-469, and Food101N, indicate that our approach outperforms many state-of-the-art label noise learning methods. Especially, it can more accurately divide OOD label noise and ID ones.},
  archive      = {J_KBS},
  author       = {Yuandi Zhao and Qianxi Xia and Yang Sun and Zhijie Wen and Liyan Ma and Shihui Ying},
  doi          = {10.1016/j.knosys.2025.113670},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113670},
  shortjournal = {Knowl. Based Syst.},
  title        = {Open set label noise learning with robust sample selection and margin-guided module},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-distribution detection in heterogeneous graphs via energy propagation. <em>KBS</em>, <em>321</em>, 113667. (<a href='https://doi.org/10.1016/j.knosys.2025.113667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are proven effective in extracting complex node and structural information from graph data. While current GNNs perform well in node classification tasks within in-distribution (ID) settings, real-world scenarios often present distribution shifts, leading to the presence of out-of-distribution (OOD) nodes. OOD detection in graphs is a crucial and challenging task. Most existing research focuses on homogeneous graphs, but real-world graphs are often heterogeneous, consisting of diverse node and edge types. This heterogeneity adds complexity and enriches the informational content. To the best of our knowledge, OOD detection in heterogeneous graphs remains an underexplored area. In this context, we propose a novel methodology for OOD detection in heterogeneous graphs (OODHG) that aims to achieve two main objectives: (1) detecting OOD nodes and (2) classifying all ID nodes based on the first task’s results. Specifically, we learn representations for each node in the heterogeneous graph, calculate energy values to determine whether nodes are OOD, and then classify ID nodes. To leverage the structural information of heterogeneous graphs, we introduce a meta-path-based energy propagation mechanism and an energy constraint to enhance the distinction between ID and OOD nodes. Extensive experimental findings substantiate the simplicity and effectiveness of OODHG, demonstrating its superiority over baseline models in OOD detection tasks and its accuracy in ID node classification.},
  archive      = {J_KBS},
  author       = {Tao Yin and Chen Zhao and Xiaoyan Liu and Minglai Shao},
  doi          = {10.1016/j.knosys.2025.113667},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113667},
  shortjournal = {Knowl. Based Syst.},
  title        = {Out-of-distribution detection in heterogeneous graphs via energy propagation},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep feature and category confidence consistency learning for long-tailed sonar image recognition. <em>KBS</em>, <em>321</em>, 113663. (<a href='https://doi.org/10.1016/j.knosys.2025.113663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has shown revolutionary potential in sonar image recognition. Nonetheless, real-world sonar images often exhibit a long-tailed distribution, where most samples belong to a few dominant categories, while tail categories suffer from data scarcity. This imbalance leads to prediction bias toward head categories, degrading recognition performance for tail categories. Traditional methods primarily focus on high-level task-specific features, neglecting low-level features in shallow network layers and failing to leverage macroscopic category hierarchy information effectively. To address these issues, we propose the Deep feature and Category confidence Consistency learning for Long-tailed Sonar image recognition (DCCLS). Our method integrates variable scale spatial mixture and global feature mixture augmentation within a dual-branch decoupling learning framework. Additionally, we propose deep feature and category confidence consistency regularization loss functions to ensure consistency across different mixture augmentations. Our method not only enhances the discriminative ability of feature representations across multiple layers of the model but also improves the balance of macro-level predictive tendencies. Extensive experiments on four long-tailed sonar datasets with varying imbalance factors and two general benchmark datasets demonstrate that our method outperforms existing state-of-the-art approaches across various evaluation metrics. On the challenging MDWD-ALT-200 dataset, our method achieves a 2.29 % accuracy improvement over the best long-tailed learning method and a 16.15 % improvement over the baselines. The proposed DCCLS has the potential to reduce human intervention and enhance the effectiveness of intelligent sonar systems in complex underwater environments.},
  archive      = {J_KBS},
  author       = {Jia-yi Han and Jian-wei Liu and Peng-qi Wu and Zhi-han Liu},
  doi          = {10.1016/j.knosys.2025.113663},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113663},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep feature and category confidence consistency learning for long-tailed sonar image recognition},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VIKCSE: Visual-knowledge enhanced contrastive learning with prompts for sentence embedding. <em>KBS</em>, <em>321</em>, 113659. (<a href='https://doi.org/10.1016/j.knosys.2025.113659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning high-quality text representations is a fundamental task in natural language processing. Existing methods attempt to enhance sentence representation by incorporating more external non-linguistic knowledge, thereby alleviating the anisotropy of output sentence representations. However, due to the disparity in modalities, integrating visual knowledge into text requires specific methods to seamlessly fuse visual and textual features, which presents new challenges. In this paper, we propose the Vi sual- K nowledge enhanced C ontrastive learning with prompts for S entence E mbedding ( VIKCSE ) method to investigate how pre-trained language models can more efficiently integrate cross-modal external semantic knowledge. Initially, the method utilizes a pre-trained multimodal contrastive model to extract visual semantic features from publicly available image–text datasets, thereby constructing a visual knowledge base. Then, we proposed a prompt-based text contrastive learning model, which uses designed templates to generate sentence semantic embedding. It then retrieves matching visual features from the visual knowledge base, together with the original guided semantic sentence embedding, and participates in contrastive loss computing. We take BERT and RoBERTa, the two fundamental models, as examples and evaluate the performance of VIKCSE on both the Semantic Textual Similarity (STS) task and downstream transfer tasks. Compared to similar existing work, VIKCSE achieves an average Spearman correlation improvement of 2.79% on STS tasks, demonstrating superior performance. The code is available at https://github.com/AdamRain/VIKCSE .},
  archive      = {J_KBS},
  author       = {Rui Cao and Yihao Wang and Hong Yan and Jie Ren and Jie Zheng and Jianfen Yang and Ling Gao},
  doi          = {10.1016/j.knosys.2025.113659},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113659},
  shortjournal = {Knowl. Based Syst.},
  title        = {VIKCSE: Visual-knowledge enhanced contrastive learning with prompts for sentence embedding},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-invariant multi-granularity feature learning for generalizable person re-identification. <em>KBS</em>, <em>321</em>, 113656. (<a href='https://doi.org/10.1016/j.knosys.2025.113656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the rapid advancements in deep learning, domain generalization person re-identification (DG-ReID) has emerged as a practical and challenging task. The objective of DG-ReID is to leverage knowledge acquired from the visible domain to effectively address domain conflict issues encountered in unknown domains. Although existing methods mitigate variations in domain styles through normalization operations, they tend to overlook potential loss of discriminative information caused by these operations, and fail to prioritize extraction of multi-granularity distinctive features. Hence, this paper introduces the Protective Fine-grained Information Extraction Network (PFIEN), a novel DG-ReID framework that aims to preserving fine-grained information while extracting domain-invariant and discriminative features for effective domain generalization. Specifically, the carefully designed Normalization Alleviation Module (NAM) employs the specialized channel attention mechanism to guide instance normalization operations, ensuring the preservation of identity information during normalization. Then, the Part-Relationship Feature Extraction (PRFE) module is leveraged to effectively capture intricate relationships among different body parts. Finally, the Part Alignment Module (PAM) is introduced into the model to generate precise alignment mappings between distinct body parts and facilitate the discernment of nuances among diverse person patterns. These three modules are seamlessly integrated to yield multiple fine-grained visual fusion features. Within both single-source and multi-source DG-ReID settings, the proposed approach can surpass the state-of-the-art in multiple DG-ReID tasks. Code will be made public at https://github.com/CQNU-ZhangLab/PFIEN .},
  archive      = {J_KBS},
  author       = {Wenfeng Zhang and Xiangfei Cao and Lei Huang and Dengwei Yan and Qibing Qin and Wei Hu},
  doi          = {10.1016/j.knosys.2025.113656},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113656},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-invariant multi-granularity feature learning for generalizable person re-identification},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of language-grounded multimodal 3D scene understanding. <em>KBS</em>, <em>321</em>, 113650. (<a href='https://doi.org/10.1016/j.knosys.2025.113650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging task bridging vision and language, Language-grounded Multimodal 3D Scene Understanding (3D-LMSU) has attracted significant interest across various domains, such as robot navigation and human–computer interaction. It aims to generate detailed and precise responses to textual queries related to 3D scenes. Despite the popularity and effectiveness of existing methods, the absence of a comprehensive survey hampers further development. In this study, we present the first systematic survey of recent progress in addressing this gap. We start with a concise overview of the background, including the problem definition and available benchmark datasets. Subsequently, we introduce a novel taxonomy that provides a comprehensive classification of existing methods based on technologies and tasks. We then present the evaluation metrics for each task, along with the performance results of various methods. Furthermore, we offer insightful discussions from three critical perspectives: data, framework, and training. Finally, we conclude the paper by highlighting several promising avenues for future research. This study synthesizes the field and guides researchers toward further exploration.},
  archive      = {J_KBS},
  author       = {Ruilong Ren and Xinyu Zhao and Weichen Xu and Jian Cao and Xinxin Xu and Xing Zhang},
  doi          = {10.1016/j.knosys.2025.113650},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113650},
  shortjournal = {Knowl. Based Syst.},
  title        = {A survey of language-grounded multimodal 3D scene understanding},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human–object interaction detector with unsupervised domain adaptation. <em>KBS</em>, <em>321</em>, 113646. (<a href='https://doi.org/10.1016/j.knosys.2025.113646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–object interaction (HOI) detection constitutes a foundational challenge in fine-grained visual scene understanding. While mainstream HOI detection frameworks rely on supervised training of deep neural networks with extensive labeled datasets, such data-intensive paradigms face practical limitations due to the high annotation and costs in real-world applications. To tackle this problem, it is a natural idea to leverage data from a well-labeled domain (source domain) to improve the performance for the domain of interest (target domain). However, the domain shift problem renders it non-trivial to transfer knowledge between different domains. In this paper, we propose a novel Domain-Adaptive HOI Detection Framework that effectively bridges domain gaps and achieves robust performance on unlabeled target domains by leveraging knowledge from labeled source domains. Specifically, our method aims to align features on both the map-level and sequence-level to learn domain-invariant features, and minimize the interaction-aware feature discrepancy by learning prototypical patterns of action relationship. To this end, we introduce a new adversarial training schema that uses a CutMix strategy to minimize the domain shift of map-level feature representations from the feature backbone. We then delve into feature distribution alignment and pursue sequence-level domain-invariant features from the transformer encoder by designing a token-based feature alignment. In addition, we design a memory bank to minimizes the distance between each inter-class interaction feature with homogeneous relationship, and maximizes the discrepancy between inter-class interaction features with heterogenous relationship. Extensive experiments on multiple benchmarks demonstrate that our proposed framework significantly outperforms prior supervised learning methods and achieves the superior performance.},
  archive      = {J_KBS},
  author       = {Yamin Cheng and Zhekai Duan and Hualong Huang and Zhi Wang},
  doi          = {10.1016/j.knosys.2025.113646},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113646},
  shortjournal = {Knowl. Based Syst.},
  title        = {Human–object interaction detector with unsupervised domain adaptation},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for job shop scheduling problems: A comprehensive literature review. <em>KBS</em>, <em>321</em>, 113633. (<a href='https://doi.org/10.1016/j.knosys.2025.113633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL), which integrates the strengths of reinforcement learning (RL) with deep neural networks, has garnered significant attention in the context of job shop scheduling problems (JSP), flexible job shop scheduling problems (FJSP), and their various extensions. This paper provides a comprehensive review and critical commentary on recent advancements in the application of DRL to JSP, FJSP, and related variants. It summarizes the design approaches for state and action spaces, with a focus on the selection of neural network architectures such as multi-layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN), attention mechanisms, Transformer, and graph neural network (GNN) for effective state feature extraction. Additionally, the paper introduces the concept of the alignment model (e.g., pointer network) for end-to-end learning. Furthermore, the paper categorizes benchmark-based training into three main approaches: instance-by-instance, instance class, and size-agnostic, and provides a comparative analysis of results from classical JSP studies. Finally, it discusses future research directions and emerging trends. This review serves as a valuable reference for further research on DRL-based production scheduling problems, particularly in the selection of neural network architectures, design of state and action spaces, definition of RL methods, and experimental setups.},
  archive      = {J_KBS},
  author       = {Lingling Lv and Chunjiang Zhang and Jiaxin Fan and Weiming Shen},
  doi          = {10.1016/j.knosys.2025.113633},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113633},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep reinforcement learning for job shop scheduling problems: A comprehensive literature review},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KALD: A knowledge augmented multi-contrastive learning model for low resource abusive language detection. <em>KBS</em>, <em>321</em>, 113619. (<a href='https://doi.org/10.1016/j.knosys.2025.113619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Warning: This paper contains insulting statements that may cause discomfort for readers. With the development of online social media, quite a few methods focus on automatic Abusive Language Detection (ALD), which requires numerous annotations as the basis for reliable classifier training. However, the labor-intensive, expensive, and time-consuming data labeling process brings difficulties to the acquisition of the annotations. Although some studies have improved the model performance in the absence of labeled data by studying cross-domain generalization and semi-supervised learning, there is still a lack of specific research on making full use of prior knowledge to improve detection effectiveness in the context of limited resources. To solve this problem, we propose a K nowledge A ugmented abusive L anguage D etection framework (KALD), to fully utilize three kinds of prior knowledge: lexical knowledge, sample knowledge, and category knowledge. First, lexicon knowledge is injected into the language model to promote its focus on abusive keyword by context reconstruction. Meanwhile Lexicon-based data augmentation is used to obtain reasonable positive samples necessary for contrastive learning. Subsequently Joint optimization of multi-contrastive learning is applied to encourage language models to learn stable sample-level and in-class representations. The following tasks are performed on the four public datasets to verify the validity of the proposed method (a) ALD (b) semi-supervised ALD And (c) cross-domain abusive language generalization. For semi-supervised ALD, the proposed framework has an average improvement of 2.19% with different sample size settings compared to the most advanced baseline approach and 3.58% compared to the basic language model. For cross-domain abusive language generalization, the proposed framework has an average improvement of 2.58% and 3.42% compared with the most advanced baseline approach and the basic language model, separately.},
  archive      = {J_KBS},
  author       = {Rui Song and Fausto Giunchiglia and Yingji Li and Jian Li and Jingwen Wang and Hao Xu},
  doi          = {10.1016/j.knosys.2025.113619},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113619},
  shortjournal = {Knowl. Based Syst.},
  title        = {KALD: A knowledge augmented multi-contrastive learning model for low resource abusive language detection},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards context-aware convolutional network for image restoration. <em>KBS</em>, <em>321</em>, 113579. (<a href='https://doi.org/10.1016/j.knosys.2025.113579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration (IR) is a long-standing task to recover a high-quality image from its corrupted observation. Recently, Transformer-based algorithms and some attention-based convolutional neural networks (CNNs) have presented promising results on several IR tasks. However, existing convolutional residual building modules for IR encounter limited ability to map inputs into high-dimensional and non-linear feature spaces, and their local receptive fields have difficulty in capturing long-range context information like Transformer. Besides, CNN-based attention modules for IR either face static abundant parameters or have limited receptive fields. To address the first issue, we propose an efficient residual star module (ERSM) that includes context-aware ”star operation” (element-wise multiplication) to contextually map features into exceedingly high-dimensional and non-linear feature spaces, which greatly enhances representation learning. To further boost the extraction of contextual information, as for the second issue, we propose a large dynamic integration module (LDIM) which possesses an extremely large receptive field. Thus, LDIM can dynamically and efficiently integrate more contextual information that helps to further significantly improve the reconstruction performance. Integrating ERSM and LDIM into an U-shaped backbone, we propose a context-aware convolutional network (CCNet) with powerful context-aware ability for contextual high-dimensional mapping and abundant contextual information. Extensive experiments show that our CCNet with low model complexity achieves superior performance compared to other state-of-the-art IR methods on several IR tasks, including image dehazing, image motion deblurring, and image desnowing.},
  archive      = {J_KBS},
  author       = {Fangwei Hao and Ji Du and Weiyun Liang and Jing Xu and Xiaoxuan Xu},
  doi          = {10.1016/j.knosys.2025.113579},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113579},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards context-aware convolutional network for image restoration},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoDeST: A dataset for multi domain scientific title generation. <em>KBS</em>, <em>321</em>, 113557. (<a href='https://doi.org/10.1016/j.knosys.2025.113557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Title generation is a crucial task in scientific writing, serving as the first point of contact for readers and impacting an article’s visibility and citation frequency. In this paper, we present a novel multi-domain and multilingual dataset, MoDeST ( M ulti- D omain S cientific T itle Generation), designed to advance research in scientific title generation. Unlike existing datasets, which are often limited to a single language or domain, MoDeST includes both English and Turkish titles across various academic disciplines, such as social sciences, medical science, science and engineering, and more. We explore the challenges of generating concise and informative titles using different sources (keywords, abstract, and full article) and evaluate the performance of large language models (LLMs) in zero-, few-shot and supervised fine-tuning (SFT) settings. We conduct human evaluation and calculate correlations between human judgement and automatic metrics, identifying the most effective evaluation metric for assessing title quality. Experiments show that fine-tuning significantly improves LLM performance for title generation, with LLaMA-3.1 8B, 70B, Aya-expanse 8B, and 32B achieving scores of 40.12, 45.21, 45.31, and 47.22 for Turkish, and 45.10, 49.10, 40.02, and 48.54 for English, respectively. Moreover, we find that abstract is the most effective input source for generating titles. Additionally, we analyse domain-specific challenges and the impact of cross-lingual generation, highlighting the need for tailored models for different domains. Our dataset, with its broad representation, ensures applicability across various academic disciplines, enhancing its utility for multi-domain and multilingual title generation while also benefiting the broader NLP community and related tasks.},
  archive      = {J_KBS},
  author       = {Necva Bölücü and Yunus Can Bilge and Dilber Çetintaş and Zehra Yücel},
  doi          = {10.1016/j.knosys.2025.113557},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113557},
  shortjournal = {Knowl. Based Syst.},
  title        = {MoDeST: A dataset for multi domain scientific title generation},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing fertilizer recommendations in precision agriculture: A novel defuzzification approach with adaptive intelligent optimization. <em>KBS</em>, <em>321</em>, 113550. (<a href='https://doi.org/10.1016/j.knosys.2025.113550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the critical need for advancing and innovating defuzzification methods in fuzzy inference systems (FISs) for optimal fertilizer recommendation in precision agriculture. Precision agriculture, aimed at sustainable and efficient food production, relies heavily on accurate fertilizer application. Traditional methods often result in over- or under-fertilization, leading to economic losses and environmental pollution. Fuzzy inference systems have shown promise in decision-making for precision agriculture, but the accuracy of fertilizer recommendations hinges on the defuzzification method. This paper introduces a novel framework, the adaptive intelligent fertilizer optimization system (AIFOS), comprising three phases. The first phase enhances the FIS through adaptive membership function design, specifically employing Gaussian membership functions. The second phase introduces data-driven defuzzification innovation, in which parameters are optimized through a hybrid optimization algorithm called hybrid somersault panda search optimization (HSPSO), which combines red panda optimization (RPO) and manta ray foraging optimization (MRFO). A multi-objective fitness function is explored to address yield maximization, cost optimization, and environmental impact. The third phase focuses on adaptive knowledge update and feedback, integrating reinforcement learning techniques for real-time learning and adaptation. The proposed framework aims to significantly improve the accuracy, robustness, and sustainability of fertilizer recommendations in precision agriculture.},
  archive      = {J_KBS},
  author       = {M. Harikumaran and P. Vijayalakshmi},
  doi          = {10.1016/j.knosys.2025.113550},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113550},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing fertilizer recommendations in precision agriculture: A novel defuzzification approach with adaptive intelligent optimization},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized memory-augmented deep unfolding network with blockchain-based data preserving cyber security in internet of things. <em>KBS</em>, <em>321</em>, 113536. (<a href='https://doi.org/10.1016/j.knosys.2025.113536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of the Internet of Things (IoT) ecosystem brings critical security risks, creating challenges for safeguarding enterprises and consumers. To enhance IoT security, this paper proposes an innovative cyber-attack detection framework that combines blockchain-based data preservation with deep learning. Data integrity is strengthened through a Proof of Transaction (PoTx)-based blockchain technique, securing data before classification. The Memory-Augmented Deep Unfolding Network (MADUN) is employed to identify diverse cyber-attacks, including adversarial, poisoning, evasion attacks, service scanning, denial of service (DoS), keylogging, and data theft. Unlike conventional models, the MADUN classifier is optimized using the Bitterling Fish Optimization Algorithm (BFOA), achieving precise parameter tuning for improved classification accuracy. The experimental results show that the proposed MADUN-BC CS-IoT framework outperforms existing approaches, such as DL-DCA-IoT, ICA-ML-IoT, and VEL-CAD-IoT in terms of accuracy, precision, recall, specificity, F1-score, RoC, and computational efficiency. These improvements underscore the efficacy of the MADUN-BC CS-IoT technique in advancing secure IoT network operations.},
  archive      = {J_KBS},
  author       = {Sundaravadivazhagan Balasubramanian and Robin Cyriac and Saleem Raja Abdul Samad and R. Karthikeyan and V. Balamurugan},
  doi          = {10.1016/j.knosys.2025.113536},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113536},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized memory-augmented deep unfolding network with blockchain-based data preserving cyber security in internet of things},
  volume       = {321},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical treatment of fractional order buruli ulcer and cholera model by using neural network approach. <em>KBS</em>, <em>320</em>, 113713. (<a href='https://doi.org/10.1016/j.knosys.2025.113713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose The purpose of these investigations is to design a neuro computing solver based on the Levenberg-Marquardt backpropagation neural network for the fractional order confection Buruli ulcer and cholera model, which is divided into ten different categories. Method The numerical solutions of the Buruli ulcer and cholera model are obtained through the reliable stochastic approach. A dataset based Adam scheme is designed that implemented to decrease the mean square error by splitting the data 12%, 12% for both endorsement and testing, while 76% is applied for training. Three cases based on the fractional order values 0.5, 0.7 and 0.9 are used to present the numerical performances of the model. The structure of neural network contains twelve neurons, single layer, and log-sigmoid transfer function for the Buruli ulcer and cholera model. Results The precision of the proposed scheme is checked using the comparison of the outputs, best validation performances around 10 –06 to 10 –07 , and small absolute error as 10 –04 to 10 –06 . Moreover, the some test performances based on taking different proportional indices are programmatic to validate the dependability of the solver. Novelty The proposed Levenberg-Marquardt backpropagation neural network approach together with twelve neurons, single layer, and log-sigmoid transfer function is applied first time for the fractional order Buruli ulcer and cholera model.},
  archive      = {J_KBS},
  author       = {Zulqurnain Sabir and M A Abdelkawy and Muhammad Asif Zahoor Raja and M․ R. Ali},
  doi          = {10.1016/j.knosys.2025.113713},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113713},
  shortjournal = {Knowl. Based Syst.},
  title        = {Numerical treatment of fractional order buruli ulcer and cholera model by using neural network approach},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ForestryBERT: A pre-trained language model with continual learning adapted to changing forestry text. <em>KBS</em>, <em>320</em>, 113706. (<a href='https://doi.org/10.1016/j.knosys.2025.113706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient utilization and enhancement of the growing volume of forestry-related textual data is crucial for advancing smart forestry. Pre-trained language models (PLMs) have demonstrated strong capabilities in processing large unlabeled text. To adapt a general PLM to a specific domain, existing studies typically employ a single target corpus for one-time pre-training to incorporate domain-specific knowledge. However, this approach fails to align with the dynamic processes of continuous adaptation and knowledge accumulation that are essential in real-world scenarios. Here, this study proposes ForestryBERT, a BERT model that is continually pre-trained on three Chinese forestry corpora comprising 204,636 texts (19.66 million words) using a continual learning method called DAS. 1 We evaluate the model on both text classification and extractive question answering tasks using five datasets for each task. Experimental results show that ForestryBERT outperforms five general-domain PLMs and further pre-trained PLMs (without DAS) across eight custom-built forestry datasets. Moreover, PLMs using DAS exhibit a forgetting rate of 0.65, which is 1.41 lower than PLMs without DAS, and demonstrate superior performance on both new and old tasks. These findings indicate that ForestryBERT, based on continual learning, effectively mitigates catastrophic forgetting and facilitates the continuous acquisition of new knowledge. It expands its forestry knowledge by continually absorbing new unlabeled forestry corpora, showcasing its potential for sustainability and scalability. Our study provides a strategy for handling the growing volume of forestry text during PLM construction, a strategy that is also applicable to other domains.},
  archive      = {J_KBS},
  author       = {Jingwei Tan and Huaiqing Zhang and Jie Yang and Yang Liu and Dongping Zheng and Xiqin Liu},
  doi          = {10.1016/j.knosys.2025.113706},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113706},
  shortjournal = {Knowl. Based Syst.},
  title        = {ForestryBERT: A pre-trained language model with continual learning adapted to changing forestry text},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing task incremental continual learning: Integrating prompt-based feature selection with pre-trained vision-language model. <em>KBS</em>, <em>320</em>, 113704. (<a href='https://doi.org/10.1016/j.knosys.2025.113704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task incremental continual learning is pivotal for the evolution of general artificial intelligence, enabling models to progressively acquire and integrate new knowledge. However, enhancing model plasticity while ensuring stability remains one of the most significant challenges in this field. In this study, we propose a task incremental continual learning method based on a vision-language model (TICL-VLM), which exhibits both high plasticity and good stability. First, the image encoder from a pre-trained vision-language model (VLM) is adopted for robust feature extraction, and a novel task-prompt-based feature selection module is designed to enhance the plasticity of the proposed model. Additionally, a class description constraint is introduced to further improve the performance of the method. To ensure excellent stability, we freeze the parameters of the VLM's image and text encoders and introduce distinct feature selection and classification modules for each incremental task. Furthermore, a specific dataset (LFDDE) is constructed to comprehensively evaluate the performance of task incremental continual learning algorithms. Extensive experiments have been conducted on both the LFDDE and the well-known CIFAR-100 datasets. The experimental results clearly demonstrate significant improvements in maintaining stability while efficiently incorporating new knowledge with our method.},
  archive      = {J_KBS},
  author       = {Lie Yang and Haohan Yang and Xiangkun He and Wenhui Huang and Chen Lv},
  doi          = {10.1016/j.knosys.2025.113704},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113704},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing task incremental continual learning: Integrating prompt-based feature selection with pre-trained vision-language model},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSN-DTA: A multi-scale node adaptive graph neural network for interpretable drug-target binding affinity prediction. <em>KBS</em>, <em>320</em>, 113699. (<a href='https://doi.org/10.1016/j.knosys.2025.113699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting drug-target affinity (DTA) is crucial in drug discovery and drug repositioning research. Graph neural networks (GNN) have been widely applied in this field. However, the current models based on GNN cannot extract the drug molecular substructure information well, and the substructure often plays an important role in DTA. Additionally, the node features in graphs rely on manual configuration, which is insufficient to fully represent the information inherent in drug molecules. Therefore, we presented MSN-DTA, a multi-scale node-adaptive graph neural network for interpretable DTA prediction. Specifically, this study introduced a multi-scale graph isomorphic network (MSGIN), which uses multi-layer graph isomorphic neural encoders to extract multi-level structural information from drugs using dense connection settings. In addition, a sequence information generation module is designed to adaptively obtain the drug node feature representation, so that the model can learn rich drug feature information. The experiments on two benchmark datasets, Davis and KIBA, have demonstrated the advantages of MSN-DTA in DTA prediction. Furthermore, to simulate the real experimental environment, we designed a DTA blind test experiment. MSN-DTA was more stable and accurate than baseline methods in predicting new drug-target binding affinity. The drug atom node information obtained by the node adaptation method designed in this paper can help the model to better distinguish the drug molecules with similar structures. This approach enhanced the generalization ability of DTA prediction models, which may assist researchers in further improving the representation of drug molecular graphs.},
  archive      = {J_KBS},
  author       = {Jianxin Wang and Pengju Ding and Yongxin Zhu and Xin Gao and Xu Yu and Bin Yu},
  doi          = {10.1016/j.knosys.2025.113699},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113699},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSN-DTA: A multi-scale node adaptive graph neural network for interpretable drug-target binding affinity prediction},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage graph spatiotemporal model with domain-class alignment for fault diagnosis under multi-source long-tailed distributions. <em>KBS</em>, <em>320</em>, 113698. (<a href='https://doi.org/10.1016/j.knosys.2025.113698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical engineering, monitoring data often follow multi-domain long-tailed distributions (MDLT), where label imbalance, domain shift, and cross-domain label divergence are deeply intertwined, posing significant challenges for intelligent fault diagnosis. To address these, we propose a novel two-stage decoupled graph spatiotemporal network guided by a balanced domain-class alignment loss. This framework introduces domain-class pairs and constructs a domain-class transferability graph using distance metrics. Building upon this, we propose an intensified Balanced Domain-Class Distribution Alignment (iBoDA) loss, which strengthens the similarity of intra-domain and cross-domain features within the same class while attenuating the similarity across different classes. This loss function calibrates and aligns domain-class distributions in imbalanced datasets, enhancing generalization for out-of-distribution samples. Furthermore, we design a multi-source fusion two-stage decoupled graph spatiotemporal network to extract domain-invariant, noise-resistant representations by capturing multi-dimensional spatiotemporal dependencies. Extensive experiments on three MDLT datasets, benchmarked against 15 state-of-the-art algorithms, validate the method's effectiveness, robustness, and computational efficiency in addressing MDLT challenges in industrial fault diagnosis.},
  archive      = {J_KBS},
  author       = {Qianwen Cui and Shuilong He and Jinglong Chen and Chao Li and Chaofan Hu},
  doi          = {10.1016/j.knosys.2025.113698},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113698},
  shortjournal = {Knowl. Based Syst.},
  title        = {A two-stage graph spatiotemporal model with domain-class alignment for fault diagnosis under multi-source long-tailed distributions},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kernel contextual fuzzy rule model based on conditional input space partitioning driven by data reconstruction in autoencoder and randomization-based neural networks. <em>KBS</em>, <em>320</em>, 113679. (<a href='https://doi.org/10.1016/j.knosys.2025.113679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Rule-based Models (FRMs) have attracted significant interest in the field of machine learning owing to their modular architecture, robust design methodologies, and sound interpretability. This study introduces a novel Kernel Contextual Fuzzy Rule Model (KCFRM) designed to cope with regression tasks. A Kernel Contextual Fuzzy Clustering (KCFC) algorithm is proposed for conditional partitioning of the input space. Specifically, we incorporate the Mercer kernel into context fuzzy clustering to enhance the abilities of the model to distinguish, extract, and amplify useful features via nonlinear mapping, thereby generating more suitable information granules. Additionally, we employ an autoencoder’s “encoding-decoding” mechanism to extract differences between data patterns and subsequently transform these into KCFC contexts via a conversion function, therefore leading to the creation of high-quality fuzzy sets. In the conclusion portion of fuzzy rules, conventional numerical or linear functions struggle to adequately describe the complex behavior present in local fuzzy regions. To mitigate this, we incorporate a Randomization-based Neural Network (RANN), capable of providing superior approximation capabilities and substantial computational efficiency. RANN overcomes traditional method constraints in representing complex behaviors within the fuzzy region. The inclusion of RANN results in more accurate and efficient conclusions for fuzzy rules. The uniqueness of this study lies in its holistic approach to designing fuzzy models with KCFC and RANN, improving the expressiveness of the rules and enhancing the generalization of the models. KCFRM’s performance is assessed using various publicly available machine learning datasets, with experimental results underscoring its effectiveness and performance enhancements.},
  archive      = {J_KBS},
  author       = {Congcong Zhang and Sung-Kwun Oh and Zunwei Fu and Witold Pedrycz},
  doi          = {10.1016/j.knosys.2025.113679},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113679},
  shortjournal = {Knowl. Based Syst.},
  title        = {Kernel contextual fuzzy rule model based on conditional input space partitioning driven by data reconstruction in autoencoder and randomization-based neural networks},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing quantum support vector machine for healthcare applications using custom feature maps. <em>KBS</em>, <em>320</em>, 113669. (<a href='https://doi.org/10.1016/j.knosys.2025.113669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum support vector machine (QSVM), based on the principles of quantum mechanics has revolutionized complex data processing tasks in several healthcare applications. Feature maps play a crucial role in transforming input data into a higher-dimensional space, enabling QSVM to capture intricate patterns and improve classification performance. This study intends to further enhance the performance of the QSVM by introducing five new custom feature maps. Furthermore, the study assesses the performance of these enhancements to the QSVM by empirically validating it for classification on four medical open-source datasets. The performance of QSVM using the custom feature maps is also compared with two standard feature maps (ZFeatureMap and ZZFeatureMap) available in Qiskit framework. The results indicate that custom feature maps outperform standard ones with an increase of up to 5% in Area Under Receiver Operating Characteristic Curve (AUC) values, 18% in F1-score, and 25% in Matthews Correlation Coefficient (MCC) values.},
  archive      = {J_KBS},
  author       = {Riya Bansal and Nikhil Kumar Rajput and Megha Khanna},
  doi          = {10.1016/j.knosys.2025.113669},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113669},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing quantum support vector machine for healthcare applications using custom feature maps},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RG4LDL: Renormalization group for label distribution learning. <em>KBS</em>, <em>320</em>, 113666. (<a href='https://doi.org/10.1016/j.knosys.2025.113666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is an effective paradigm to address label ambiguity by modeling the relevance of multiple labels to an instance. However, existing LDL methods suffer from challenges such as high model complexity, slow convergence, and limited availability of label distribution-annotated training data. To tackle these issues, we propose RG4LDL, a novel framework that integrates the renormalization group (RG) principle with LDL for the first time. RG4LDL employs a restricted Boltzmann machine (RBM)-based neural network to iteratively extract relevant degrees of freedom, thereby optimizing feature learning and improving predictive accuracy. By combining unsupervised RG learning and supervised LDL prediction in an end-to-end manner, RG4LDL achieves both efficiency and effectiveness. Experimental results on 13 real-world datasets and a synthetic toy dataset demonstrate that RG4LDL significantly outperforms state-of-the-art LDL methods in terms of predictive accuracy and computational efficiency. These results highlight the potential of RG4LDL as a benchmark solution for label distribution learning tasks.},
  archive      = {J_KBS},
  author       = {Chao Tan and Sheng Chen and Jiaxi Zhang and Zilong Xu and Xin Geng and Genlin Ji},
  doi          = {10.1016/j.knosys.2025.113666},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113666},
  shortjournal = {Knowl. Based Syst.},
  title        = {RG4LDL: Renormalization group for label distribution learning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning model with dynamic scoring-based client selection for diabetes diagnosis. <em>KBS</em>, <em>320</em>, 113662. (<a href='https://doi.org/10.1016/j.knosys.2025.113662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy-preserving paradigm in distributed machine learning that enables clients to collaboratively train models without sharing their raw data. However, the variety of client data, device setups, and network conditions provides serious difficulties for FL systems. Random client sampling in such environments often leads to suboptimal outcomes, including lower model accuracy, slower convergence rates, and reduced fairness. To address these issues, this study proposes a dynamic client selection mechanism based on a scoring system that evaluates clients based on three key parameters: accuracy, loss, and execution time. We propose a scoring-based framework for adaptive client selection in federated learning (FL) and implement it in an ML-driven diabetes detection system. Evaluations with 200 communication rounds demonstrate improved global and local model performance, faster convergence, and optimized resource utilization. The framework dynamically selects clients, improving execution efficiency and addressing key FL challenges, including data heterogeneity, fairness, communication overhead, and privacy. Our findings highlight its potential for scalable and efficient FL in healthcare applications while paving the way for future advancements in adaptive client selection.},
  archive      = {J_KBS},
  author       = {Shamim Ahmed and M. Shamim Kaiser and Sudipto Chaki and Saad Aloteibi and Mohammad Ali Moni},
  doi          = {10.1016/j.knosys.2025.113662},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113662},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning model with dynamic scoring-based client selection for diabetes diagnosis},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph representation learning via edge temporal states modeling and structure-reinforced transformer. <em>KBS</em>, <em>320</em>, 113661. (<a href='https://doi.org/10.1016/j.knosys.2025.113661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of time-evolving networks has rendered dynamic graph representation learning increasingly crucial for real-world applications, as existing approaches that combine recurrent neural networks (RNNs) with graph neural networks (GNNs) face two critical limitations: insufficient modeling of edge temporal states and their impact on node feature evolution, along with the inherent over-smoothing problem of GNNs that impedes effective extraction of global structural features. To address these challenges, we introduce the R ecurrent S tructure-reinforced G raph T ransformer (RSGT), a novel framework that advances dynamic graph representation learning through two key innovations. First, it introduces a principled approach to explicitly model edge temporal states using differentiated edge types and weights derived from sequential snapshot analysis, effectively integrating temporal dynamics into the graph’s topological structure. Second, it designs a structure-reinforced graph transformer that leverages a recurrent learning paradigm to capture comprehensive node representations, simultaneously encoding both local connectivity patterns and global structural features while preserving temporal evolution characteristics. Comprehensive experiments on four real-world datasets demonstrate RSGT’s superior performance in discrete dynamic graph representation learning, consistently outperforming existing methods in dynamic link prediction tasks.},
  archive      = {J_KBS},
  author       = {Shengxiang Hu and Guobing Zou and Song Yang and Shiyi Lin and Yanglan Gan and Bofeng Zhang},
  doi          = {10.1016/j.knosys.2025.113661},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113661},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic graph representation learning via edge temporal states modeling and structure-reinforced transformer},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level skeleton self-supervised learning: Enhancing 3D action representation learning with large multimodal models. <em>KBS</em>, <em>320</em>, 113660. (<a href='https://doi.org/10.1016/j.knosys.2025.113660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-Supervised Learning (SSL) has proven effective in skeleton-based action understanding, drawing increasing research attention. Previous studies mainly focus on capturing the relationship between joints and skeleton sequences through joint-level masked motion modeling and sequence-level contrastive learning. However, these methods overlook subtle semantic connections between similar movements, leading to poor feature discrimination of such actions and impacting downstream task performance. In this paper, we propose a Multi-Level Skeleton Self-Supervised Learning (MLS 3 L) framework that integrates joint, sequence, and semantic-level SSL in a complementary manner for fine-grained action understanding. Specifically, We first design topology-based mask reconstruction for joint-level SSL and tempo-independent contrastive learning for sequence-level SSL. For semantic-level SSL, we leverage pre-trained Large Multimodal Models (LMMs) to generate discriminative text descriptions for action sequences. Then, we design a weighted soft alignment algorithm to align text descriptions with the corresponding skeletons. This semantic-level representation distillation significantly enhances the ability to distinguish between similar actions. Furthermore, we propose a multi-level collaboration strategy to enable SSL tasks at different levels to jointly learn versatile representations of various granularity, leading to improved learning of action representation features. Our method demonstrates exceptional performance on various downstream tasks, validated on NTU RGB+D, NTU RGB+D 120, and PKUMMD datasets.},
  archive      = {J_KBS},
  author       = {Tian He and Yang Chen and Xu Gao and Ling Wang and Rui Huang and Hong Cheng},
  doi          = {10.1016/j.knosys.2025.113660},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113660},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-level skeleton self-supervised learning: Enhancing 3D action representation learning with large multimodal models},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupled signed link prediction method based on graph neural network. <em>KBS</em>, <em>320</em>, 113657. (<a href='https://doi.org/10.1016/j.knosys.2025.113657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed networks, as models that can comprehend the strength of relationships, have been receiving growing attention. However, existing graph neural network-based models neglect the rich interactive information between these links. In this paper, we propose a novel graph neural network framework for signed link prediction, namely the decoupled graph attention network (DecGAT). We address the problem of signed link decoupling by breaking it into two components: node feature decoupling and neighbor feature decoupling. This approach embeds positive and negative links in separate spaces for better interpretability. Using the attention mechanism, we introduce a node-level decoupling process to capture the impact of target node features on signed links, along with two edge-level decoupling processes to assess interactions between target nodes and their neighbors. These processes aggregate node feature information to enhance the model’s representation. Our experiments on various public datasets and real-world scenarios show that DecGAT outperforms other methods in signed link prediction.},
  archive      = {J_KBS},
  author       = {Zhiheng Zhou and Guiying Yan},
  doi          = {10.1016/j.knosys.2025.113657},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113657},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decoupled signed link prediction method based on graph neural network},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FACT: Federated adaptive cross training. <em>KBS</em>, <em>320</em>, 113655. (<a href='https://doi.org/10.1016/j.knosys.2025.113655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) facilitates distributed model development to aggregate multiple confidential data sources. The information transfer among clients can be compromised by distributional differences, i.e., by non-i.i.d. data. A particularly challenging scenario is the federated model adaptation to a target client without access to annotated data. We propose Federated Adaptive Cross Training (FACT), which uses the implicit domain differences between source clients to identify domain shifts in the target domain. In each round of FL, FACT cross initializes a pair of source clients to generate domain specialized representations which are then used to enforce a domain invariant data representation. We empirically show that FACT outperforms both state-of-the-art federated and non-federated models on three popular multi-source–single-target benchmarks, and achieves highly competitive performance on single-source–single-target experiments. We further study FACT’s behavior with respect to communication restrictions and the number of participating clients.},
  archive      = {J_KBS},
  author       = {Stefan Schrod and Jonas Lippl and Andreas Schäfer and Michael Altenbuchinger},
  doi          = {10.1016/j.knosys.2025.113655},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113655},
  shortjournal = {Knowl. Based Syst.},
  title        = {FACT: Federated adaptive cross training},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards realistic single image shadow generation: A two-stage method with inharmonious localization and dual-dilated shadow pixel filtering. <em>KBS</em>, <em>320</em>, 113654. (<a href='https://doi.org/10.1016/j.knosys.2025.113654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shadow generation is a challenging task that directly affects the realism of synthesized images. Existing methods for shadow generation require additional masks as auxiliary information and overlook the spatial variation within the shadow area, resulting in costly manual annotation and false shadows. This paper proposes a new two-stage shadow generation method that can construct realistic images without laborious data annotation. Firstly, we adopt the inharmonious localization network to fully utilize the information differences between the image’s shadow-free regions and other regions to achieve single-image shadow shape prediction. Secondly, we propose a dual-dilated shadow pixel filtering network (DSFNet), which effectively utilizes the adjacent regions of each pixel through dual-scale image filtering and fusion to learn the spatial-variant property. Extensive experiments on DESOBA demonstrate that the proposed method achieves state-of-the-art performance.},
  archive      = {J_KBS},
  author       = {Xianhe Cheng and Ye Lin and Xinxin Shi and Lihua Zhang},
  doi          = {10.1016/j.knosys.2025.113654},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113654},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards realistic single image shadow generation: A two-stage method with inharmonious localization and dual-dilated shadow pixel filtering},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoAPT: Context attribute words for prompt tuning. <em>KBS</em>, <em>320</em>, 113653. (<a href='https://doi.org/10.1016/j.knosys.2025.113653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel prompt tuning method called CoAPT (Context Attribute words in Prompt Tuning) for few/zero-shot image classification. The core motivation is that attributes are descriptive words with rich information about a given concept. Thus, we aim to enrich text queries of existing prompt tuning methods, improving alignment between text and image embeddings in CLIP embedding space. To do so, CoAPT integrates attribute words as additional prompts within learnable prompt tuning and can be easily incorporated into various existing prompt tuning methods. To facilitate the incorporation of attributes into text embeddings and the alignment with image embeddings, soft prompts are trained together with an additional meta-network that generates input-image-wise feature biases from the concatenated feature encodings of the image–text combined queries. Our experiments demonstrate that CoAPT leads to considerable improvements for existing baseline methods on several few/zero-shot image classification tasks, including base-to-novel generalization, cross-dataset transfer, and domain generalization. Our findings highlight the importance of combining hard and soft prompts and pave the way for future research on the interplay between text and image latent spaces in pre-trained models.},
  archive      = {J_KBS},
  author       = {Gun Lee and Subin An and Sungyong Baik and Soochahn Lee},
  doi          = {10.1016/j.knosys.2025.113653},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113653},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoAPT: Context attribute words for prompt tuning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based unsupervised prompt learning for SAM in leaf disease segmentation. <em>KBS</em>, <em>320</em>, 113652. (<a href='https://doi.org/10.1016/j.knosys.2025.113652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, leaf disease segmentation is crucial for crop disease management and yield improvement. Since most deep learning-based segmentation models require extensive annotations, pursuing unsupervised methods becomes a practical solution. Although advanced models like the Segment Anything Model (SAM) can produce precise class-agnostic masks without annotations, their reliance on human-interactive prompts limits their utility to unsupervised disease segmentation tasks. To address this limitation, we present UPLS, a novel three-stage framework that leverages unsupervised prompt learning to enable SAM for leaf disease segmentation. This method employs unsupervised contrastive learning to progressively segment leaf and disease areas and automatically generate disease prompts for SAM. Concretely, for fine and intricate lesions, we utilize an improved high-frequency attention mechanism to extract high-frequency features from the leaf area, and construct contrastive losses between global priors and foreground/background features. Furthermore, we devise a strategy to automatically generate disease-related prompts from the segmented leaf and initial lesion regions, enabling SAM to refine disease boundaries without human intervention. Experiments on three public plant disease segmentation datasets show that UPLS outperforms existing non-fully supervised segmentation methods in accuracy and robustness. Source code is available at https://github.com/Tianluda/UPLS .},
  archive      = {J_KBS},
  author       = {Luda Tian and Yingchun Yuan and Qing En and Wei Ma and Guanghui Zhang and Fangfang Liang},
  doi          = {10.1016/j.knosys.2025.113652},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113652},
  shortjournal = {Knowl. Based Syst.},
  title        = {Attention-based unsupervised prompt learning for SAM in leaf disease segmentation},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AT-diff: An adversarial diffusion model for unrestricted adversarial examples generation. <em>KBS</em>, <em>320</em>, 113645. (<a href='https://doi.org/10.1016/j.knosys.2025.113645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has seen widespread application in many fields. However, the emergence of adversarial examples has revealed a critical vulnerability, making them susceptible to potential attacks. Although numerous adversarial attack methods have been proposed, they are often constrained by certain constraints. Most current adversarial attack methods are based on addition of perturbations, which are confined to clean examples and fail to generate diverse and natural adversarial examples. Moreover, owing to the additional perturbations, these methods exhibit limited robustness against adversarial defenses, such as image denoising. To tackle these challenges, this paper proposed a three-stage attack framework based on an adversarial diffusion model, named AT-Diff (Adversarial Transfer on Diffusion model). Firstly, to address the issue of inadequate robustness in traditional adversarial examples, we utilize a diffusion model to learn the adversarial example distribution of the target model and generate highly realistic adversarial examples from scratch without any additional perturbations, thereby significantly enhancing their performance under defense measures. Additionally, we design a Temporal Adaptive Loss (TAL) function, which dynamically adjusts the visual loss and the adversarial loss according to the current time step, ensuring that the generated adversarial examples gradually enhance their adversarial efficacy while maintaining high visual quality. Extensive experiments conducted on MNIST, Fashion-MNIST and CIFAR-10 datasets have shown that our method attains noteworthy results in imperceptibility, while also exhibiting stronger robustness.},
  archive      = {J_KBS},
  author       = {Chengsheng Yuan and Jingfa Pang and Jianwei Fei and Xinting Li and Zhihua Xia},
  doi          = {10.1016/j.knosys.2025.113645},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113645},
  shortjournal = {Knowl. Based Syst.},
  title        = {AT-diff: An adversarial diffusion model for unrestricted adversarial examples generation},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granularity fusion transformer: Learning multi-granularity patterns for time-series forecasting. <em>KBS</em>, <em>320</em>, 113644. (<a href='https://doi.org/10.1016/j.knosys.2025.113644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data consist of continuous observations collected over time. Theoretically, time series data form a continuous trajectory, but in practice, the actual data used in the real-world are discrete time series obtained by sampling from a continuous trajectory. By considering the sampling interval, it is possible to collect data with different levels of information, referred to as granularity in time series data. Most existing studies assume single-granularity, which leads to failure in capturing variability occurring at different levels of granularity. To address these issues, we propose the Granularity Fusion Transformer (GFT), which addresses characteristics at different granularity levels. GFT estimates multi-granularity data by simultaneously considering the information of period and phase at the single-granularity level. To merge granularities that are segregated into different levels, we propose a patch-wise cross-attention based Granularity Fusion Encoder. Extensive experiments on six datasets demonstrate that the proposed method outperformed benchmark models by reducing MSE by 35.27 % and MAE by 22.80 % , thereby achieving more accurate predictions closer to the actual values. These results highlight the usefulness of multi-granularity in time series forecasting tasks.},
  archive      = {J_KBS},
  author       = {Jinwoo Park and Hyeongwon Kang and Seunghun Han and Pilsung Kang},
  doi          = {10.1016/j.knosys.2025.113644},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113644},
  shortjournal = {Knowl. Based Syst.},
  title        = {Granularity fusion transformer: Learning multi-granularity patterns for time-series forecasting},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedLGMatch: Federated semi-supervised learning via joint local and global pseudo labeling. <em>KBS</em>, <em>320</em>, 113642. (<a href='https://doi.org/10.1016/j.knosys.2025.113642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bulk of existing Federated Learning (FL) algorithms pay attention to supervised setting and assume that clients have fully labeled data. However, it may be impractical for all clients to obtain plenty of labels due to high annotation costs. Hence, the Federated Semi-Supervised Learning (FSSL) as a promising paradigm has better prospect in many realistic applications (e.g. medical scenario). Under Labels-at-Server scenario, most pseudo labeling based FSSL approaches use only the global model to generate pseudo-labels for unlabeled data, while the local models are ignored. When the local data distribution is much more different from the central server (e.g., Non-IID setting), the generated pseudo-labels may contain much noise, thus, resulting in more serious confirmation bias. To tackle the crucial issue, a novel Federated Semi-Supervised Learning via Joint Local and Global Pseudo Labeling (FedLGMatch) framework is proposed in this paper. The prominent advantage of the proposed FedLGMatch is that it allows local models trained in the last communication round to assist global model in generating pseudo-labels, which successfully emphasizes more clean pseudo-label learning at each client. Experimental results also show that FedLGMatch achieves significant performance improvements than other state-of-the-art models on the standard benchmark datasets.},
  archive      = {J_KBS},
  author       = {Qing Zhao and Jielei Chu and Zhaoyu Li and Wei Huang and Zhipeng Luo and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113642},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113642},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedLGMatch: Federated semi-supervised learning via joint local and global pseudo labeling},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainability-based graph augmentation for out-of-distribution robustness in digital pathology. <em>KBS</em>, <em>320</em>, 113640. (<a href='https://doi.org/10.1016/j.knosys.2025.113640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whole slide images (WSIs), which are high-resolution digital representations of tissue samples, present significant challenges for processing because of their gigapixel scale. Recent studies show that graph neural networks (GNNs), which leverage neighborhood information, can enhance cancer classification accuracy in WSIs. However, GNN performance is affected by out-of-distribution (OOD) data, which occurs when the training and testing data are from different sources. Detecting OOD samples in graph data is especially challenging due to its complexity, which makes GNNs vulnerable to performance degradation. To address this issue, we propose a novel data augmentation framework to improve GNN robustness against OOD samples. Our approach augments node features by sampling important subgraphs, simulating potential OOD scenarios during training. Experiments on three public WSI datasets demonstrate significant improvements in graph classification tasks on OOD samples. In this work, one dataset serves as the in-distribution benchmark, while the others represent OOD scenarios. These results highlight the potential of data augmentation to enhance GNN robustness against OOD samples, improving cancer classification in WSIs.},
  archive      = {J_KBS},
  author       = {Saba Heidari Gheshlaghi and Milan Aryal and Nasim Yahya Soltani and Masoud Ganji},
  doi          = {10.1016/j.knosys.2025.113640},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113640},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainability-based graph augmentation for out-of-distribution robustness in digital pathology},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sequential mixing fusion network for enhanced feature representations in multimodal sentiment analysis. <em>KBS</em>, <em>320</em>, 113638. (<a href='https://doi.org/10.1016/j.knosys.2025.113638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis exploits multiple modalities to understand a user’s sentiment state from video content. Recent work in this area integrates features derived from different modalities. However, current multimodal sentiment datasets are typically small with limited cross-modal interaction diversity, for which simple feature fusion mechanisms can lead to modality dependence and model overfitting. Consequently, how to augment diverse cross-modal samples and use non-verbal modalities to dynamically enhance text feature representations is still under-explored. In this paper, we propose a sequential mixing fusion network to tackle this research challenge. Using speech text content as a primary source, we design a sequential fusion strategy to maximise the feature expressiveness enhanced by auxiliary modalities, namely facial movements and audio features, and a random feature-level mixing algorithm to augment diverse cross-modality interactions. Experimental results on three benchmark datasets show that our proposed approach significantly outperforms current state-of-the-art methods, while demonstrating strong robustness capability when dealing with a missing modality.},
  archive      = {J_KBS},
  author       = {Chenchen Wang and Qiang Zhang and Jing Dong and Hui Fang and Gerald Schaefer and Rui Liu and Pengfei Yi},
  doi          = {10.1016/j.knosys.2025.113638},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113638},
  shortjournal = {Knowl. Based Syst.},
  title        = {A sequential mixing fusion network for enhanced feature representations in multimodal sentiment analysis},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information diffusion over cyber–physical conjoined networks: An immunity perspective. <em>KBS</em>, <em>320</em>, 113637. (<a href='https://doi.org/10.1016/j.knosys.2025.113637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are currently in an era characterized by an explosion of information, where individuals’ immune responses to information diffusion are becoming increasingly prevalent. However, the stochastic nature of these immune responses significantly diminishes the accuracy of diffusion size predictions. Moreover, the integration of physical and cyber networks in real-world scenarios amplifies the heterogeneity of information immunity’s impact on diffusion, further complicating the situation. Herein, we propose a model for information diffusion from an immunity perspective to predict diffusion size over cyber–physical conjoined networks (CPCNs). First, we construct a CPCN to capture the heterogeneity in information diffusion influenced by immunity. Next, we develop an information immunity-oriented stochastic diffusion model (II-SDM) based on temporal point process (TPP) theory. This model effectively captures the stochastic dynamics of information immunity over time by deriving the probability distribution of diffusion size over CPCNs, thereby minimizing the biases that are common in traditional deterministic approaches. Finally, we introduce a long short-term memory-based intensity prediction method (LSTM-IPM) to learn event intensities from historical data sequences. Numerical simulations and experimental results show that our method predicts immunity-oriented information diffusion size over CPCNs with greater accuracy.},
  archive      = {J_KBS},
  author       = {Jing Chen and Dianjie Lu and Fuwei Li and Jie Tian and Guijuan Zhang},
  doi          = {10.1016/j.knosys.2025.113637},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113637},
  shortjournal = {Knowl. Based Syst.},
  title        = {Information diffusion over cyber–physical conjoined networks: An immunity perspective},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-way heterogeneity model for dynamic spatiotemporal traffic flow prediction. <em>KBS</em>, <em>320</em>, 113635. (<a href='https://doi.org/10.1016/j.knosys.2025.113635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is a key component in intelligent transportation systems (ITS) and is crucial for prospective traffic flow management. There are complex spatiotemporal dependencies in traffic flow. Dynamic graph convolutional networks are developed to capture these spatiotemporal dependencies. These networks demonstrate commendable prediction performance across various scenarios. However, the sporadic occurrence of non-periodic anomalies, such as traffic accidents, remains challenging. These anomalies are paramount for traffic management despite their infrequency. The existing model does not address anomalies, leading to poor prediction performance under abnormal conditions. To address this issue, we propose a two-way heterogeneity model integrated into the existing dynamic graph convolutional network. Our model uses static and dynamic heterogeneity to control message propagation in graph convolution network to accurately model normal and abnormal spatiotemporal traffic dynamics. Consequently, our model enhances the accuracy and reliability of traffic flow prediction, particularly in unexpected scenarios. Extensive experiments on benchmark datasets demonstrate that the two-way heterogeneity model can reduce the prediction error of abnormal conditions.},
  archive      = {J_KBS},
  author       = {Heng Zhang and Zhizhe Lin and Hai Xie and Jinglin Zhou and Youyi Song and Teng Zhou},
  doi          = {10.1016/j.knosys.2025.113635},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113635},
  shortjournal = {Knowl. Based Syst.},
  title        = {Two-way heterogeneity model for dynamic spatiotemporal traffic flow prediction},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “Are the current topic modeling evaluation metrics enough?” mitigating the limitations of topic modeling evaluation metrics using a multi-perspective game theoretic approach. <em>KBS</em>, <em>320</em>, 113634. (<a href='https://doi.org/10.1016/j.knosys.2025.113634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic Modeling (TM) helps extract and organize information from large amounts of textual data by discovering semantic topics from documents. In this article, we delve into issues of topic quality evaluation , responsible for driving the advances in the TM field by assessing the overall quality of the topic generation process. Traditional TM metrics capture the quality of topics by strictly evaluating the words that make up the topics, either syntactically (e.g., NPMI, TF-IDF Coherence) or semantically (e.g., WEP). Here, we investigate whether we are approaching the limits of what the current evaluation metrics can assess regarding TM quality. For this, we perform a comprehensive experimental evaluation, considering three widely used datasets (ACM, 20News, WOS and Books) for which a natural organization of the collection’s documents into semantic classes (topics) does exist. We contrast the quality of topics generated by four traditional and state-of-the-art TM techniques (i.e., LDA, NMF, CluWords, BERTopic and TopicGPT) with each collection’s “natural topic structure”. Our results show that, despite the importance of the current metrics, they could not capture some important idiosyncratic aspects of the TM task, in the case, the capability of the topics to induce a structural organization of the document space into distinct semantic groups, indicating the need for new metrics that consider such aspects. In this sense, we propose incorporating metrics commonly used to evaluate clustering algorithms into the TM evaluation process, relying on some commonalities between TM and clustering tasks. Results highlight the effectiveness of clustering metrics in distinguishing the results of TM techniques when compared to the datasets’ ground truth (class organization). However, adopting additional evaluation metrics implies expanding the analysis space. Thus, as a third contribution, we propose consolidating the various metrics into a unified framework, using Game Theory for decision-making, specifically Multi-Attribute Utility Theory (MAUT), which evaluates options based on weighted preferences across multiple criteria, on which the closer to 1, the greater the agreement between the criteria. Our experimental results demonstrate that MAUT allows a more precise assessment of TM quality. The CluWords achieved the best MAUT values for 20News, ACM and WOS collections (i.e., 0.9913, 0.9571 and 0.8684, respectively). While there is a high level of agreement between the metrics in the ACM collection, indicating CluWords as the best solution, there is a low divergence between the metrics in the WOS collection. In this case, evaluating each metric individually would lead to different conclusions, but MAUT shows us that CluWords is the most consistent as a whole, highlighting the benefits of exploring word embeddings for text representations and matrix factorization strategies to induce topics.},
  archive      = {J_KBS},
  author       = {Antônio Pereira and Felipe Viegas and Diego Roberto Colombo Dias and Elisa Tuler and Ana Cláudia Machado and Guilherme Fonseca and Marcos André Gonçalves and Leonardo Rocha},
  doi          = {10.1016/j.knosys.2025.113634},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113634},
  shortjournal = {Knowl. Based Syst.},
  title        = {“Are the current topic modeling evaluation metrics enough?” mitigating the limitations of topic modeling evaluation metrics using a multi-perspective game theoretic approach},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised multi-label feature selection via partial label correlation and feature self-representation. <em>KBS</em>, <em>320</em>, 113632. (<a href='https://doi.org/10.1016/j.knosys.2025.113632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-label feature selection (MLFS), semi-supervised learning can effectively reduce the labeling cost and alleviate the negative impacts caused by labeling noise. However, there are complex inherent correlations among labels in multi-label data. Existing semi-supervised MLFS methods fail to fully exploit the limited label information to assist the learning process of pseudo-labels, limiting the accuracy and reliability of pseudo-labels during model training. To address this issue, we design a manifold regularization term based on partial label correlations and integrate it with the instance manifold to jointly guide the learning process of pseudo-labels. In addition, we develop a sparse formulation for feature self-representation to capture dynamic feature correlations. Moreover, we introduce latent representation learning to explore the latent supervisory information within these dynamic feature correlations. Combining all these ingredients, we propose a novel semi-supervised MLFS method named PLCFS (Semi-supervised MLFS via partial label correlation and feature self-representation). Moreover, we theoretically demonstrate the convergence of PLCFS. Finally, extensive experimental results on multiple datasets show that, when 20% of the training samples are labeled, compared with existing advanced methods, PLCFS has achieved an overall performance improvement of 1.06%–4.15% in terms of the average precision metric.},
  archive      = {J_KBS},
  author       = {Yao Zhang and Jun Tang and Ziqiang Cao},
  doi          = {10.1016/j.knosys.2025.113632},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113632},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised multi-label feature selection via partial label correlation and feature self-representation},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive deep metric learning with harmonized loss and nearest proxy alignment for low-dimensional representation. <em>KBS</em>, <em>320</em>, 113631. (<a href='https://doi.org/10.1016/j.knosys.2025.113631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Metric Learning (DML) plays a critical role in learning discriminative embedding spaces for tasks such as classification, retrieval, and dimensionality reduction. However, most existing methods rely on formulations such as pair-based or triplet-based losses, or proxy-based approximations that represent each class globally. They fail to provide effective discriminative information for hard-to-classify samples, lack the flexibility to adapt to inhomogeneous subclasses, and are highly affected by dominant samples. This makes the training process ineffective at distinguishing hard-to-classify samples or noise, resulting in suboptimal low-dimensional embeddings. To address these issues, we proposes an innovative Adaptive Deep Metric Learning framework, ADML_HNPA, which integrates a harmonized loss term that promotes separation of hard-to-classify samples and a nearest-proxy alignment term that improves intra-class compactness by emphasizing local structure. Specifically, we employ the log-ex approximation to define explicit objective for maximizing the margin between nearest neighbor within the same class and nearest neighbor from different class. We also define the objective for nearest proxy alignment. After that, we propose an adaptive parameter adjustment strategy to tune the parameters. Finally, extensive experiments are conducted on various datasets to demonstrate the superior of ADML_HNPA.},
  archive      = {J_KBS},
  author       = {Jingwei Chen and Jingqing Cheng and Xiaoxiao Wang and Xiaohua Xu and Feiping Nie},
  doi          = {10.1016/j.knosys.2025.113631},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113631},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive deep metric learning with harmonized loss and nearest proxy alignment for low-dimensional representation},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-temporal image fusion empowered convolutional neural networks for recognition of 9 common mice actions. <em>KBS</em>, <em>320</em>, 113628. (<a href='https://doi.org/10.1016/j.knosys.2025.113628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of complex behaviors and social interactions necessitates precise and efficient methodologies for the recognition and tracking of animal actions. However, existing methods such as depth perception and wearable devices for mice behavior recognition pose risks of physical harm to the subjects and exhibit limited applicability across species with low precision. To redress these deficiencies, this paper proposes the multi-temporal image fusion empowered Convolutional Neural Networks (CNN), aimed at achieving accurate and efficient recognition of nine common mice actions. In this study, we employ mice at various time points as subjects and employ a multi-temporal approach to process image sequences, integrating various frame difference extraction techniques to address the limitations inherent in single-frame prediction for capturing dynamic changes in actions. Subsequently, we utilize a Deformable Convolution Network (DCN) in conjunction with multi-stacked residual units to enhance the feature extraction capacity of the CNN, particularly focusing on mice action contours, while mitigating the risk of overfitting. Furthermore, we investigate the efficacy of fused images derived from varying frame differences in representing the nine actions, culminating in the establishment of a robust mice action recognition model through ensemble learning techniques. Experimental findings demonstrate an impressive precision rate of 92.9% in recognizing mice actions. The proposed method effectively eliminates background interference and exhibits superior generalization and adaptability properties.},
  archive      = {J_KBS},
  author       = {Jian Li and Chen Du and Yuliang Zhao and Peng Shan and Xingqi Wang and Huawei Zhang and Ying Wang},
  doi          = {10.1016/j.knosys.2025.113628},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113628},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-temporal image fusion empowered convolutional neural networks for recognition of 9 common mice actions},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporal kernel for time series forecasting. <em>KBS</em>, <em>320</em>, 113623. (<a href='https://doi.org/10.1016/j.knosys.2025.113623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, time series forecasting (TSF) has been widely discussed due to its potential to improve our life in weather, electricity system and healthcare. Recurrent neural networks and attention-based models are considered to be the mainstream solutions for TSF tasks. However, these rigid and computationally intensive models often underperform on real-world datasets especially when dealing with complex time series. Their training time becomes prohibitively long for large-scale time series. Besides, the batch data used to train the model only contains general and local statistics, which is usually stationary and monotonic (i.e., the data does not continuously reverse derivatives). Such data has poor representation ability to reveal non-local and long-range characteristics of time series distribution. In reality, many real-world time series exhibit non-stationary distributions with non-local statistics. To address these limitations, this paper proposes a temporal kernel to flexibly enhance the representation ability of classic neural networks for TSF tasks. Specifically, our method comprises three core components: (1) a kernel machine is derived from the attention mechanism by introducing the kernel method to capture important features of time series; (2) a spectral mixed kernel mapping is presented to construct the temporal kernel, which can capture non-local and long-range characteristics of time series distribution; (3) a Bayesian learning paradigm is applied to efficiently optimize non-convex temporal kernel networks. We also provide a theoretical analysis of the approximation bound of the temporal kernel. Extensive experiments on real-world datasets demonstrate the effectiveness of our approach across a wide range of settings.},
  archive      = {J_KBS},
  author       = {Weimin Bai and Hui Xue},
  doi          = {10.1016/j.knosys.2025.113623},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113623},
  shortjournal = {Knowl. Based Syst.},
  title        = {A temporal kernel for time series forecasting},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local high-order structure-aware graph neural network for motif prediction. <em>KBS</em>, <em>320</em>, 113618. (<a href='https://doi.org/10.1016/j.knosys.2025.113618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motifs, serving as fundamental building blocks in complex networks, refer to small, frequently occurring connected subgraphs. Unlike link prediction, motif prediction focuses on whether a given set of nodes will form a particular type of motif and has achieved much more attention. Motif prediction holds significant research value and demonstrates broad application potential across various fields, such as financial default prediction and social network recommendation. However, existing research methods are relatively limited and have largely overlooked the crucial role of local higher-order correlations among nodes and the enclosing subgraph-level structural information in motifs. To overcome these challenges, we propose a novel L ocal H igh-order S tructure-aware G raph N eural N etwork for motif prediction, named LHSGNN. It comprehensively predicts motifs from the perspectives of both the node level and subgraph level. LHSGNN incorporates local higher-order correlations among nodes to learn node embeddings. Then, it labels nodes from the views of node roles and distance metrics to capture complex structural information in enclosing subgraph-level motifs. Comprehensive experiments conducted on real-world datasets demonstrate the effectiveness of our LHSGNN.},
  archive      = {J_KBS},
  author       = {Wen Yang and Xiang Li and Bin Wang and Jianpeng Qi and Zhongying Zhao and Peilan He and Yanwei Yu},
  doi          = {10.1016/j.knosys.2025.113618},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113618},
  shortjournal = {Knowl. Based Syst.},
  title        = {Local high-order structure-aware graph neural network for motif prediction},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond protection: Unveiling neural network copyright trading. <em>KBS</em>, <em>320</em>, 113617. (<a href='https://doi.org/10.1016/j.knosys.2025.113617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of deep learning has transformed data into invaluable intellectual property, encapsulated within trained neural network models. While copyright protection mechanisms exist, the lack of a secure, standardized platform for trading these intellectual assets limits their commercial potential. This study introduces a blockchain-based framework designed to invigorate the trading ecosystem for neural network model copyrights. A key innovation is our advanced watermarking technique, specifically developed for neural networks. This method embeds copyright information directly into the model architecture during training, providing robust protection against unauthorized use and modifications. Additionally, we have developed a decentralized blockchain marketplace tailored for the peer-to-peer exchange of authenticated model copyrights. This platform utilizes smart contracts to ensure secure, seamless copyright ownership transfers, enabling fluid exchanges within a trustless environment. By integrating cutting-edge watermarking technology with a decentralized trading venue, our framework establishes a market infrastructure that treats neural network models as a new class of freely tradable digital assets, thereby accelerating AI innovation and adoption across various sectors.},
  archive      = {J_KBS},
  author       = {Xuemei Yuan and Hewang Nie},
  doi          = {10.1016/j.knosys.2025.113617},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113617},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond protection: Unveiling neural network copyright trading},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating over-smoothing in graph neural networks for node classification through adaptive early embedding and biased DropEdge procedures. <em>KBS</em>, <em>320</em>, 113615. (<a href='https://doi.org/10.1016/j.knosys.2025.113615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are widely used for tasks involving graph-structured data across various fields, including computer vision, biology, social media, and traffic prediction. Despite their substantial success, increasing the depth of GNNs can impair the discriminability of node representations, leading to a decline in performance for node classification tasks. This challenge is partly attributed to a phenomenon known as over-smoothing. This paper introduces an Adaptive Early Embedding (AEE) procedure between Graph Convolutional Network (GCN) layers. This method adaptively halts the aggregation of neighboring nodes before the final layer of the main network. By reducing the over-smoothing of node embeddings, we enhance the distinguishability of the data. Another important contribution of this work is using the inter-class Biased DropEdge (BDE) procedure, which effectively propagates beneficial information. The proposed model based on AEE+BDE can be integrated with baseline message-passing GNN models to mitigate over-smoothing challenges. Our experiments show that the proposed model outperforms baseline models. Additionally, we provide theoretical evidence supporting the effectiveness of the AEE and BDE procedures for node classification tasks.},
  archive      = {J_KBS},
  author       = {Fateme Hoseinnia and Mehdi Ghatee and Mostafa Haghir Chehreghani},
  doi          = {10.1016/j.knosys.2025.113615},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113615},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mitigating over-smoothing in graph neural networks for node classification through adaptive early embedding and biased DropEdge procedures},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OD-DDA: Real-time object detector with dual dynamic adaptation in variable scenes. <em>KBS</em>, <em>320</em>, 113611. (<a href='https://doi.org/10.1016/j.knosys.2025.113611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection becomes challenging in variable scenarios, such as when object features change and cluttered backgrounds. We propose an object detector with dual dynamic adaptation (OD-DDA) to address these issues and enhance network performance in complex environments. First, we introduce a dynamic feature adaptation (DFA) module at each stage of the network, utilizing large kernel depthwise separable convolutions to capture multiscale contextual information, thereby enhancing the feature extraction capability of the model and effectively addressing object variations across different scenarios. Next, we design a dynamic fine-grained weight adaptation (DFGWA) module, which could selectively learn the fine-grained features of an image and calculate the corresponding weights before feature aggregation, thereby reducing interference among features and enhancing the model’s responsiveness to targets. Through the synergy of these modules, OD-DDA can flexibly handle the challenges faced during the detection of objects in complex scenarios and significantly improve the inference speed. We conduct rigorous experimental comparisons on five datasets, and the results show that OD-DDA exhibits excellent performance in different scenarios. Especially on the UAVDT dataset, A P 50 reaches 37.9% and FPS reaches 87.5, proving its ability to balance speed and accuracy.},
  archive      = {J_KBS},
  author       = {Mengmei Sang and Shengwei Tian and Long Yu and Xin Fan and Zhezhe Zhu},
  doi          = {10.1016/j.knosys.2025.113611},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113611},
  shortjournal = {Knowl. Based Syst.},
  title        = {OD-DDA: Real-time object detector with dual dynamic adaptation in variable scenes},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep embedded clustering approach for detecting trend class using time-series sensor data. <em>KBS</em>, <em>320</em>, 113609. (<a href='https://doi.org/10.1016/j.knosys.2025.113609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis plays a crucial role in identifying patterns within large, high-dimensional datasets. However, existing clustering techniques struggle with effective representation learning, particularly in handling spatial-temporal dependencies in sensor data. This paper proposes a novel Deep Embedded Spatial Clustering (DESC) approach for trend class detection in Advanced Differential Interferometry Synthetic Aperture Radar (A-DInSAR) time-series data. The proposed methodology integrates an Improved Principal Component Analysis Network (PCAnet) for dimensionality reduction, an autoencoder-based deep clustering framework, and the Osprey Optimization Algorithm (OOA) for optimizing cluster centroids. The main contribution of this study is presenting a novel deep-embedded clustering framework that effectively captures spatial-temporal trends in A-DInSAR datasets. The proposed improved PCAnet model preserves essential feature representations while reducing dimensionality. An optimization strategy using the OOA enhances clustering performance and accuracy. In order to improve the understanding of satellite features, a trend detection method that reconstructs ground deformation signals using linear regression is presented. The proposed approach outperforms existing clustering approaches, with lower RMSE (0.45 %), MSE (0.20), MAE (0.4 %), and MAPE (8 %), exhibiting higher clustering accuracy and trend detection performance. These findings validate the efficiency of the proposed method in accurately identifying deformation patterns in geospatial datasets.},
  archive      = {J_KBS},
  author       = {Lakshmi Prasanthi Malyala and Sivaneasan Bala Krishnan and KVenkata Prasad and Prasun Chakrabarti},
  doi          = {10.1016/j.knosys.2025.113609},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113609},
  shortjournal = {Knowl. Based Syst.},
  title        = {A deep embedded clustering approach for detecting trend class using time-series sensor data},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive transformer network for long tail classification. <em>KBS</em>, <em>320</em>, 113607. (<a href='https://doi.org/10.1016/j.knosys.2025.113607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of big data, multi-label text classification presents considerable challenges, most notably the long-tail problem, wherein a small number of labels account for the majority of instances, while the vast majority of labels occur only rarely. This imbalance creates a critical bias in classification models, leading to suboptimal performance on tail labels that significantly impacts applications such as recommender systems and search engines. We present CTN-LT (Contrastive Transformer Network for Long Tail Classification), a novel dual-encoder architecture that combines adapted loss functions, contrastive learning and reframes the multi-label text classification as a semantic similarity task to specifically enhance tail label performance. Our method achieves state-of-the-art performance on tail labels while maintaining competitive performance on head labels across multiple benchmark datasets. The model demonstrates superior few-shot and zero-shot capabilities, making it particularly valuable for dynamic environments where new categories frequently emerge. We release our code at https://github.com/jmelsbach/CTN-LT .},
  archive      = {J_KBS},
  author       = {Johannes Melsbach and Frederic Haase and Sven Stahlmann and Stefan Hirschmeier and Detlef Schoder},
  doi          = {10.1016/j.knosys.2025.113607},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113607},
  shortjournal = {Knowl. Based Syst.},
  title        = {Contrastive transformer network for long tail classification},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFA: Spatial-frequency adversarial attack method. <em>KBS</em>, <em>320</em>, 113602. (<a href='https://doi.org/10.1016/j.knosys.2025.113602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks can successfully fool deep neural networks (DNNs) by perturbing the input, and adversarial examples help evaluate the defensive capabilities of DNNs. In black-box scenarios, adversarial examples exhibit low transferability against normally trained and defensive models. In this paper, we propose a Spatial Frequency Adversarial Attack (SFA), which operates in both spatial and frequency domains. Specifically, in the spatial domain, inspired by Stochastic Average Gradient (SAG) optimization, we leverage historical information to create an initial neighborhood sampling example and then sample nearby it to propose an Average Historical Gradient Sample Method (AHGSM), optimizing and stabilizing the gradient update direction while introducing high-frequency perturbations. In the frequency domain, we make a groundbreaking discovery that JPEG compression affects normally trained and adversarially trained models differently. Next, We validate this hypothesis by examining the frequency-domain characteristics of effective adversarial examples. Finally, we propose a two-stage attack SFA by integrating JPEG compression as a frequency-based attack with spatial-based AHGSM. Abundant experiments on the ImageNet dataset show that SFA significantly improves the transferability of adversarial examples against both normally and adversarially trained models, establishing it as a state-of-the-art attack in spatial and frequency domains.},
  archive      = {J_KBS},
  author       = {Jiawei Tang and Shifa Liu and Jiaxuan Wei},
  doi          = {10.1016/j.knosys.2025.113602},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113602},
  shortjournal = {Knowl. Based Syst.},
  title        = {SFA: Spatial-frequency adversarial attack method},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VIS4SL: A visual analytic approach for interpreting and diagnosing shortcut learning. <em>KBS</em>, <em>320</em>, 113598. (<a href='https://doi.org/10.1016/j.knosys.2025.113598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shortcut learning, a phenomenon where deep neural networks inadvertently learn irrelevant features, has been extensively discussed due to its impact on model generalization and unexpected failures. Interpreting and diagnosing shortcut learning is challenging due to its diverse manifestations and multiple influencing factors. To assist data scientists in these tasks, we introduce VIS4SL, an interactive visual analytics approach that harnesses both human intelligence and computational power. VIS4SL integrates a perturbation-based method with comprehensive visualizations to facilitate an understandable analysis of learned features. We also present a set of comparative visualizations that allow for the evaluation of model explanations against robust proxies, particularly human explanations, to quantify the degree of shortcut learning and assess model components. Two case studies, involving natural image classification and visualization classification, demonstrate the efficacy of VIS4SL in practical applications. Our findings reveal that the model uses the orientation of bars to differentiate between bar charts and Pareto charts. Furthermore, we explore how interactive visualizations enhance data scientists’ understanding of shortcut learning, enabling the development of more precise deep learning models.},
  archive      = {J_KBS},
  author       = {Xiyu Meng and Tan Tang and Yuhua Zhou and Zihan Yan and Dazhen Deng and Yongheng Wang and Yuhan Wu and Yingcai Wu},
  doi          = {10.1016/j.knosys.2025.113598},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113598},
  shortjournal = {Knowl. Based Syst.},
  title        = {VIS4SL: A visual analytic approach for interpreting and diagnosing shortcut learning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weight-aware tasks for evaluating knowledge graph embeddings. <em>KBS</em>, <em>320</em>, 113596. (<a href='https://doi.org/10.1016/j.knosys.2025.113596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embeddings encode knowledge by representing entities and relations through vectors or matrices and have been widely employed in conjunction with deep learning to address a diverse range of problems. The effectiveness of knowledge-driven tasks is intrinsically dependent on the quality of these embeddings. To enhance embedding quality, weight information has been incorporated to develop weight-aware knowledge graph embeddings. However, existing weight-aware knowledge graph embedding models are still evaluated using weight-agnostic tasks, indiscriminately treating all triples while disregarding the global weight distribution of the knowledge graph. To bridge this gap, we introduce weight-aware tasks specifically designed for knowledge graph embeddings, namely weight-aware link prediction and weight-aware triple classification , aiming to provide a more comprehensive evaluation of embedding models on weighted knowledge graphs. To validate the effectiveness of the proposed evaluation protocols, we present a general framework, WaExt , which extends conventional deterministic knowledge graph embedding models into their weight-aware counterparts. Extensive evaluations on four classical knowledge graph embedding models and three weighted knowledge graphs, it is demonstrated that the superiority of the proposed weight-aware evaluation protocol. Moreover, the WaExt framework WaExt achieves competitive performance, outperforming existing methods. The implementation is publicly available at: https://github.com/Diison/WaExt .},
  archive      = {J_KBS},
  author       = {Wei-Kun Kong and Xin Liu and Teeradaj Racharak and Guanqun Sun and Qiang Ma and Le-Minh Nguyen},
  doi          = {10.1016/j.knosys.2025.113596},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113596},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weight-aware tasks for evaluating knowledge graph embeddings},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of video action recognition based on deep learning. <em>KBS</em>, <em>320</em>, 113594. (<a href='https://doi.org/10.1016/j.knosys.2025.113594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Action Recognition (VAR) involves identifying and classifying human actions from video data. Deep Learning (DL) has revolutionised VAR, significantly enhancing its accuracy and efficiency. However, large-scale practical applications of VAR using DL remain limited, underscoring the need for further research and innovation. Thus, this survey provides a comprehensive overview of recent advancements in DL-based VAR. Specifically, we summarise the key DL architectures for VAR, including two-stream networks, 3D-CNNs, RNNs, LSTMs, and Attention Mechanisms, and analyse their strengths, limitations, and benchmark performances. The survey also explores the diverse applications of DL-based VAR, such as surveillance, human–computer interaction, sports analytics, healthcare, and education, while presenting a detailed summary of commonly used datasets and evaluation metrics. Moreover, critical challenges, such as computational demands and the need for robust temporal modelling, are identified, along with potential future directions. This paper is a valuable resource for researchers and practitioners striving to advance VAR using DL techniques by systematically presenting concepts, methodologies, and trends.},
  archive      = {J_KBS},
  author       = {Ping Gong and Xudong Luo},
  doi          = {10.1016/j.knosys.2025.113594},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113594},
  shortjournal = {Knowl. Based Syst.},
  title        = {A survey of video action recognition based on deep learning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGCI2L: Adversarial graph contrastive information invariant learning. <em>KBS</em>, <em>320</em>, 113571. (<a href='https://doi.org/10.1016/j.knosys.2025.113571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL) is one type of self-supervised learning framework aiming to learn invariant information from different graph views or variations. The key challenge lies in how to learn useful representations while discarding redundant information behind the data graph. To this end, we propose a new Adversarial Graph Contrastive Information Invariant Learning (AGCI 2 L) model that can preserve invariant information of graphs useful to downstream tasks and also minimize irrelevant information. This is achieved by designing a novel adversarial learning module that mimics human cognition’s invariant learning processes amid changes. Specifically, first, the model uses two encoders to generate two diverse graph encodings by minimizing their mutual information. This can help differentiate invariant information from redundant information contained in the two encodings. Then, by leveraging the Information Bottleneck theory, we extract the invariant information from the learned encodings. Finally, we use a new contrastive learning module to further refine the learned graph representations. To validate our model, we adopt node classification as the downstream task tested with social networks. Extensive experiments across multiple datasets compared with ten existing methods demonstrate the efficacy of our model.},
  archive      = {J_KBS},
  author       = {Zhicheng Gao and Zhipeng Luo and Hongjun Wang and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113571},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113571},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGCI2L: Adversarial graph contrastive information invariant learning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal representation learning in offline visual reinforcement learning. <em>KBS</em>, <em>320</em>, 113565. (<a href='https://doi.org/10.1016/j.knosys.2025.113565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world reinforcement learning (RL) applications contend with high-dimensional visual observations contaminated by confounding factors, which induce spurious correlations and obscure decision-relevant information. Compounding this issue, the inability to interact online necessitates reliance on pre-collected datasets, thereby hampering a deeper understanding of complex environment structures. In this work, by focusing on the causal rather than spurious correlations in the input and explicitly distinguishing between task-related and task-irrelevant elements of the causal variables, we propose a mask-based algorithm for learning task-related minimal causal state representations, namely MMCS. Specifically, MMCS guides the decoupling of minimal causal variables through mask network partitioning and jointly enforcing conditional independence and causal sufficiency, thereby eliminating unnecessary dependencies between variables and uncovering causal dependency structures. More importantly, MMCS is decoupled from downstream policy learning, and can function as a plug-in method compatible with any offline reinforcement learning algorithm. Empirical results on the Visual-D4RL benchmark demonstrate that MMCS significantly improves performance and sample efficiency in downstream policy learning. In addition, its robust performance in various distraction environments highlights the potential of MMCS to improve the generalizability of offline RL, especially under conditions of limited data and visual distractions. Code is available at https://github.com/DMU-XMU/MMCS.git .},
  archive      = {J_KBS},
  author       = {Yaru Zhang and Kaizhou Chen and Yunlong Liu},
  doi          = {10.1016/j.knosys.2025.113565},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113565},
  shortjournal = {Knowl. Based Syst.},
  title        = {Causal representation learning in offline visual reinforcement learning},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSTM-ARIMA as a hybrid approach in algorithmic investment strategies. <em>KBS</em>, <em>320</em>, 113563. (<a href='https://doi.org/10.1016/j.knosys.2025.113563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on building an algorithmic investment strategy employing a hybrid approach that combines LSTM and ARIMA models referred to as LSTM-ARIMA. This unique algorithm uses LSTM to produce final predictions but boosts the results of this RNN by adding the residuals obtained from ARIMA predictions among other inputs. The combination of LSTM and ARIMA leverages the strengths of both models, with LSTM effectively capturing non-linear patterns in the data, while ARIMA contributes by modeling linear relationships and accounting for autocorrelations, thereby enhancing the overall predictive power and accuracy of the hybrid model. The base LSTM-ARIMA strategy was then compared to RandomForest-ARIMA and Buy&Hold strategy. The algorithm is tested across three equity indices (S&P 500, FTSE 100, and CAC 40) using daily frequency data spanning from January 2000 to August 2023. The architecture of testing is based on the walk-forward procedure which is applied for the hyperparameter tunning phase that uses Random Search and backtesting the algorithms. The selection of the optimal model is determined based on adequately selected performance metrics combining focused on risk-adjusted return measures. We considered two strategies for each algorithm: Long-Only and Long-Short to present the situation of two various groups of investors with different investment policy restrictions. For each strategy and equity index, we compute the performance metrics and visualize the equity curve to identify the best strategy with the highest modified information ratio (( I R ∗ ∗ )). The findings conclude that the LSTM-ARIMA algorithm outperforms all the other algorithms across all the equity indices which confirms the strong potential behind hybrid ML-TS (machine learning - time series) models in searching for the optimal algorithmic investment strategies.},
  archive      = {J_KBS},
  author       = {Kamil Kashif and Robert Ślepaczuk},
  doi          = {10.1016/j.knosys.2025.113563},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113563},
  shortjournal = {Knowl. Based Syst.},
  title        = {LSTM-ARIMA as a hybrid approach in algorithmic investment strategies},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CL-HOI: Cross-level human–object interaction distillation from multimodal large language models. <em>KBS</em>, <em>320</em>, 113561. (<a href='https://doi.org/10.1016/j.knosys.2025.113561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–object interaction (HOI) detection often relies on labor-intensive annotations, but multimodal large language models (MLLMs) show potential for recognizing and reasoning about image-level interactions. However, MLLMs are typically computationally heavy and lack instance-level HOI detection capabilities. In this paper, we propose a cross-level HOI distillation (CL-HOI) framework that distills instance-level HOI detection from MLLMs, expanding HOI detection without labor-intensive and expensive manual annotations. Our approach uses CL-HOI as a student model to distill HOIs from a teacher MLLM in two stages: context distillation, where a visual-linguistic translator (VLT) converts visual information into linguistic form, and interaction distillation, where an interaction cognition network (ICN) facilitates interaction reasoning. Contrastive distillation losses transfer image-level context and interactions to the VLT and ICN for instance-level HOI detection. Evaluations on the HICO-DET and V-COCO datasets show that our method outperforms existing weakly supervised approaches, demonstrating its effectiveness in HOI detection without manual annotations.},
  archive      = {J_KBS},
  author       = {Jianjun Gao and Chen Cai and Ruoyu Wang and Wenyang Liu and Kim-Hui Yap and Kratika Garg and Boon Siew Han},
  doi          = {10.1016/j.knosys.2025.113561},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113561},
  shortjournal = {Knowl. Based Syst.},
  title        = {CL-HOI: Cross-level human–object interaction distillation from multimodal large language models},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A residual graph reinforcement learning for budgeted influence maximization. <em>KBS</em>, <em>320</em>, 113553. (<a href='https://doi.org/10.1016/j.knosys.2025.113553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Budgeted Influence Maximization (BIM) problem has been widely applied like critical node identification, social media marketing, and rumor suppression. Nowadays, the networks exhibit significant variations in both structure and scale. Graph Reinforcement Learning (GRL)-based methods are commonly employed to solve the BIM problems. However, the GRL-based methods suffer from lower performance in spread effect with diverse structures and scales. This limitation arises from their inability to effectively capture and leverage the intricate relationships within local neighborhood structures. To address this, we propose a novel R esidual G raph R einforcement L earning (RGRL)-based framework, which incorporates three key designs: (1) A network partitioning mechanism based on community detection algorithms to identify dense subgraphs; (2) A hybrid framework combining global training with subgraph execution to enhance the search capability of RGRL, particularly for effectively learning both subgraph-level and global neighborhood information; and (3) A residual graph neural network that captures global information and subgraphs neighborhood information for better selecting the seed node. We evaluate our proposed RGRL model alongside five baseline methods on four open-source datasets of varying sizes. The experimental results demonstrate that RGRL achieves the maximum improvements in IC, LT, and SIS information propagation models, with increases of up to 11.21%, 60.80%, and 12.91%, respectively.},
  archive      = {J_KBS},
  author       = {Lizhen Ou and Xueyan Tang and Wentong Cai and Wenjie Tang},
  doi          = {10.1016/j.knosys.2025.113553},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113553},
  shortjournal = {Knowl. Based Syst.},
  title        = {A residual graph reinforcement learning for budgeted influence maximization},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level prompting: Enhancing model performance through hierarchical instruction integration. <em>KBS</em>, <em>320</em>, 113545. (<a href='https://doi.org/10.1016/j.knosys.2025.113545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent remarkable advancements in artificial intelligence language models, various instruction prompting techniques have been introduced across natural language processing tasks to maximize model utility and enhance performance. To address the issues of excessive generalization or over-segmentation in conventional instruction prompt design, we propose a novel framework that integrates two complementary types of instruction: granular instruction and holistic instruction. Granular instruction is an explicit prompt that provides the unique attributes of individual queries, effectively leveraging the inherent information within each query. Holistic instruction provides a structured prompt that embodies the typical characteristics of similar queries, offering a broader perspective that facilitates the extension of existing knowledge and insights. We used various pre-trained language models to validate the proposed framework to address downstream tasks that demand deep understanding and implicit knowledge. The comparative analysis demonstrated significant performance improvements. Additionally, we clearly illustrated its practical effectiveness through diverse quantitative evaluations and case studies. This study proposes a new approach to instruction prompt design, demonstrating its broad applicability to various downstream tasks and its potential to improve language model performance.},
  archive      = {J_KBS},
  author       = {Geonyeong Son and Misuk Kim},
  doi          = {10.1016/j.knosys.2025.113545},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113545},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-level prompting: Enhancing model performance through hierarchical instruction integration},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intuition meets analytics: Reasoning implicit aspect-based sentiment quadruplets with a dual-system framework. <em>KBS</em>, <em>320</em>, 113534. (<a href='https://doi.org/10.1016/j.knosys.2025.113534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implicit sentiments pose a challenge to aspect sentiment quad prediction (ASQP), and replicating human cognitive processes is essential for understanding them. However, existing methods fail to model from a human cognitive perspective, leading to limited performance. Inspired by the dual-process theory in psychology, which identifies two distinct but synergistic modes of reasoning–intuitive and analytic, we present a straightforward and effective strategy-level approach: Du al S ystem-based R easoning framework with Intuitive R eactions (D uSR 2 ). This framework includes the Intuitive System based on intuitive reactions and the Analytic System based on complex reasoning. Specifically, we first employ commonsense reasoning tools to estimate human intuitive reactions to enhance the original text, enriching semantic information. Then we integrate the enhanced text with analytic instruction, conducting complex reasoning to capture implicit sentiments. Experimental results show that D uSR 2 significantly advances the state-of-the-art performance on four datasets of ASQP task. Detailed evaluation confirms the effectiveness, universality, and robustness of D uSR 2 in handling various scenarios.},
  archive      = {J_KBS},
  author       = {Zewen Bai and Yuanyuan Sun and Changrong Min and Junyu Lu and Haohao Zhu and Liang Yang and Hongfei Lin},
  doi          = {10.1016/j.knosys.2025.113534},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113534},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intuition meets analytics: Reasoning implicit aspect-based sentiment quadruplets with a dual-system framework},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D-STANet: A delay-enhanced spatio-temporal attention network for traffic prediction. <em>KBS</em>, <em>320</em>, 113533. (<a href='https://doi.org/10.1016/j.knosys.2025.113533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the accelerating pace of global urbanization, accurate traffic flow prediction has become crucial for alleviating congestion and optimizing resource allocation. However, existing methods often fail to effectively capture the complex spatio-temporal dependencies inherent in traffic data, which limits predictive accuracy. To address this challenge, we propose the D-STANet, which is an innovative traffic flow prediction model that integrates spatio-temporal attention mechanisms with a delay-aware module. Specifically, D-STANet leverages the spatio-temporal attention mechanism to adaptively select the most relevant features across different temporal and spatial scales, thereby capturing complex spatio-temporal dependencies. Additionally, the proposed delay-aware module is designed to model the temporal delay effects in traffic flow data, as predictions are not only dependent on current flow data, but also influenced by fluctuations in past traffic states. Furthermore, D-STANet incorporates a graph attention mechanism to enhance its ability to respond to dynamic changes. This module automatically adjusts the weight of each node in the graph based on the degree of association between nodes in the traffic flow data, further improving the model’s ability to capture traffic flow variations. Experimental results demonstrate that D-STANet outperforms all baseline models across multiple metrics, particularly on the HZME dataset, where its superior ability to model spatio-temporal dependencies is evident. Specifically, D-STANet achieves improvements of 31.71%, 20.48% and 5.06% in MAE, RMSE and MAPE, respectively, compared to DMSTGCN. The model’s exceptional performance in sparse traffic networks further underscores its robustness and reliability in complex traffic environments.},
  archive      = {J_KBS},
  author       = {Jiqiang Tang and Junjie Yang and Yuanqiong Zhang},
  doi          = {10.1016/j.knosys.2025.113533},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113533},
  shortjournal = {Knowl. Based Syst.},
  title        = {D-STANet: A delay-enhanced spatio-temporal attention network for traffic prediction},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-augmented encoder for few-shot deep intent recognition in air traffic control. <em>KBS</em>, <em>320</em>, 113524. (<a href='https://doi.org/10.1016/j.knosys.2025.113524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the negative effects of human operators in the open-world air traffic control (ATC), the artificial intelligence (AI) system and human hybrid architecture have drawn considerable attention. As the core of the computer interaction model, the few-shot intent recognition to capture the scarce and implicit purpose and intentions of human operators (“gestalt”) from controller-pilot instructions is still a non-trivial issue. This study presents an end-to-end Knowledge-augmented Few-shot Intent Recognition (KaFIR) scheme to address the intrinsic challenges in achieving unified and effective feature representation in the few-shot setting. On the strength of the fine-tuned language model as a basic encoder, the task-oriented module is further designed to incorporate two unsupervised models for a better knowledge-augmented instruction representation to avoid overfitting. Specifically, a duality-augmented contrastive learning model and a dictionary-based masked language model are proposed, exploiting the global and the local prior semantics from the read-back sentence pattern and the highly related keywords, respectively. This study performs extensive experiments on two real-world ATC instruction datasets collected in China and verifies the superior performance of the proposed KaFIR scheme compared with the state-of-the-art baselines, including fine-tuned language models and feature-augmented models. Results demonstrate the promising prospects of integrating the AI system as the auxiliary tool into various human-in-the-loop ATC tasks.},
  archive      = {J_KBS},
  author       = {Yi Hui and Yang Yang and Shengsheng Qian and Kaiquan Cai},
  doi          = {10.1016/j.knosys.2025.113524},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113524},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-augmented encoder for few-shot deep intent recognition in air traffic control},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UV gaussians: Joint learning of mesh deformation and gaussian textures for human avatar modeling. <em>KBS</em>, <em>320</em>, 113470. (<a href='https://doi.org/10.1016/j.knosys.2025.113470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing photo-realistic drivable human avatars from multi-view image sequences has been a popular and challenging topic in the field of computer vision and graphics. While existing NeRF-based methods can achieve high-quality novel view rendering of human models, both training and inference processes are time-consuming. Recent approaches have utilized 3D Gaussians to represent the human body, enabling faster training and rendering. However, they undermine the importance of the mesh guidance and directly predict Gaussians in 3D space with coarse mesh guidance. This hinders the learning procedure of the Gaussians and tends to produce blurry textures. Therefore, this paper proposes UV Gaussians, which models the 3D human body by jointly learning mesh deformations and 2D UV-space Gaussian textures. The method utilizes the embedding of UV map to learn Gaussian textures in 2D space, leveraging the capabilities of powerful 2D networks to extract features. Additionally, through an independent Mesh network, the approach optimizes pose-dependent geometric deformations, thereby guiding Gaussian rendering and significantly enhancing rendering quality. A new dataset of human motion has been collected and processed, which includes multi-view images, scanned models, parametric model registration, and corresponding texture maps. Experimental results demonstrate that the proposed method achieves state-of-the-art synthesis of novel view and novel pose. The code and data will be made available as open-source.},
  archive      = {J_KBS},
  author       = {Yujiao Jiang and Qingmin Liao and Xiaoyu Li and Li Ma and Qi Zhang and Chaopeng Zhang and Zongqing Lu and Ying Shan},
  doi          = {10.1016/j.knosys.2025.113470},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113470},
  shortjournal = {Knowl. Based Syst.},
  title        = {UV gaussians: Joint learning of mesh deformation and gaussian textures for human avatar modeling},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive zero-shot relational learning for knowledge graph completion. <em>KBS</em>, <em>320</em>, 113425. (<a href='https://doi.org/10.1016/j.knosys.2025.113425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) involves enhancing existing factual knowledge by automatically inferring missing links between entities. However, they are limited to inferring relations for entity-pairs that have corresponding samples in the graph. In this paper, we endeavor to identify relations without training examples. To this end, we learn relation embeddings from textual descriptions and utilize a conditional variational autoencoder (C-VAE) to connect these descriptions with the corresponding entity-pair embeddings. However, two problems still persist: first, the embeddings of different relations are entangled, leading to the inability to discriminate between different relations; second, entity-pair embeddings are contaminated with impurities that decrease the accuracy of predictions for novel relations. This study introduces contrastive learning for zero-shot relational learning (CZRL). To better distinguish between different relations, we train a feature encoder with specifically designed contrastive losses. To eliminate noise, we propose a contrastive denoising autoencoder module to isolate the relevant information of entity-pair embeddings from irrelevant information. On two public datasets — Wiki, and NELL — the proposed model demonstrates the performance improved at least 10% compared to baseline models based on evaluation metrics such as MRR, Hit@1, and Hit@5.},
  archive      = {J_KBS},
  author       = {Zhiyi Fang and Hang Yu and Changhua Xu and Zhuofeng Li and Jie Ying and Shaorong Xie},
  doi          = {10.1016/j.knosys.2025.113425},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113425},
  shortjournal = {Knowl. Based Syst.},
  title        = {Contrastive zero-shot relational learning for knowledge graph completion},
  volume       = {320},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced CLKAN-RF framework for robust anomaly detection in unmanned aerial vehicle sensor data. <em>KBS</em>, <em>319</em>, 113690. (<a href='https://doi.org/10.1016/j.knosys.2025.113690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous flight and real-time control of unmanned aerial vehicles (UAVs) critically rely on onboard sensors, which are susceptible to mechanical and environmental disruptions. Sensor anomalies pose substantial risks to UAV safety, emphasizing the importance of anomaly detection (AD) methods. However, AD remains challenging due to the scarcity of real anomaly data and the intricate spatiotemporal dependencies in sensor readings, often obscured by random noise and interference. This paper presents an enhanced framework based on one-dimensional convolutional neural network (1D CNN), long short-term memory network (LSTM) and Kolmogorov-Arnold network (KAN) with residual filtering (CLKAN-RF), utilizing multivariate sensor data without labeled information. First, a correlation analysis is employed to avoid the negative impact of irrelevant parameters on model training. Second, a multiple regression model is designed to comprehensively extract spatial-temporal relationships using 1D CNN and LSTM, while KAN is incorporated to non-linearly process the complex patterns and optimize the learned features with high accuracy. To address the issue of random noise, a bi-directional adaptive exponentially weighted moving average (Bi-AEWMA) scheme is introduced to smooth residuals, complemented by an adaptive dynamic thresholding mechanism to further enhance detection performance. Finally, extensive experiments on real UAV sensor data highlight the superiority of the proposed CLKAN-RF framework, which improves the true positive rate and overall accuracy by an average of 6.43 % and 7.63 %, respectively, while reducing the false positive rate by an average of 11.96 % compared to existing methods, demonstrating its potential application in UAV prognostics and health management.},
  archive      = {J_KBS},
  author       = {Chuanjiang Li and Wenhui Xie and Bing Zheng and Qian Yi and Lei Yang and Bingtao Hu and Chengxin Deng},
  doi          = {10.1016/j.knosys.2025.113690},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113690},
  shortjournal = {Knowl. Based Syst.},
  title        = {An enhanced CLKAN-RF framework for robust anomaly detection in unmanned aerial vehicle sensor data},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A gate-enhanced neuro additive graph neural network via knowledge distillation for CTR prediction. <em>KBS</em>, <em>319</em>, 113668. (<a href='https://doi.org/10.1016/j.knosys.2025.113668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The click-through rate (CTR) prediction is a crucial task in commercial recommender systems and online advertising platforms. Recent studies have revealed shortcomings in CTR optimization, particularly in their ability to effectively identify and interpret the abnormal or latent feature interactions obscured by user behaviors. In this paper, a novel CTR prediction model is developed in two stages. The first stage formulates a gate-enhanced neuro additive graph neural network (GNAGNN), by dynamically capturing the complex interactions between features in different input environments, the adaptability of the model to the importance of features is significantly improved. While the second stage utilizes the knowledge distillation framework, enabling GNAGNN to effectively learn from a gated ensemble of existing CTR models. Unlike most higher-order feature interaction models that rely on deep neural networks, our method avoids high-complexity matrix computation and significantly reduces the computational overhead. Specifically, the framework adopts a dynamic parametric mechanism to determine the weight of the model involved in the prediction through the continuous action vector, and then achieve the accurate prediction of each advertisement impression. Eventually, comprehensive experiments carried out on two public datasets convincingly demonstrate that GNAGNN significantly outperforms the state-of-the-art baselines, and it can offer precise and interpretable understandings into features and their interactions while reducing computational costs.},
  archive      = {J_KBS},
  author       = {Fei Guan and Jing Yang and Chenxia Jin},
  doi          = {10.1016/j.knosys.2025.113668},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113668},
  shortjournal = {Knowl. Based Syst.},
  title        = {A gate-enhanced neuro additive graph neural network via knowledge distillation for CTR prediction},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain fake news detection method based on generative adversarial network and graph network. <em>KBS</em>, <em>319</em>, 113665. (<a href='https://doi.org/10.1016/j.knosys.2025.113665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of misinformation in today's digital era poses significant challenges, with fake news detection becoming critical to mitigate economic losses and social instability. Despite extensive research efforts, most existing approaches are tailored for single-domain fake news detection, struggling with data distribution discrepancies and domain shifts when applied to multi-domain scenarios. This limitation underscores the urgent need for solutions that address the complexities of cross-domain detection. Here, we propose a novel framework MFGAG that synergistically integrates adversarial networks and graph neural networks with emotional, stylistic, and semantic features to enable precise domain localization. By leveraging these features, the framework effectively models intricate relationships among news articles within the same temporal context, addressing the challenges posed by multi-domain datasets. Experimental evaluations demonstrate that our approach outperforms state-of-the-art methods, achieving an average accuracy improvement of 3.3 percentage points for single-domain news and nearly 1 percentage point for mixed-domain data, culminating in an overall accuracy of 93.1 %. The code involved in this study is publicly available on website https://github.com/SWLee777/MFGAG .},
  archive      = {J_KBS},
  author       = {Xuefeng Li and Jian Wei and Chensu Zhao and Xiaqiong Fan and Yuhang Wang},
  doi          = {10.1016/j.knosys.2025.113665},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113665},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain fake news detection method based on generative adversarial network and graph network},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on knowledge drift based on interaction matching. <em>KBS</em>, <em>319</em>, 113664. (<a href='https://doi.org/10.1016/j.knosys.2025.113664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drift detection is a fundamentally challenging task in data-driven decision-making; however, traditional distribution-based methods for data drift detection fail to adequately capture the characteristics of knowledge-centric data-driven decision-making. Thus, exploring knowledge-based data drift detection methods has extensive practical value. Herein, we consider If-Then rules as the knowledge representation framework, focusing on changes in the quantity and quality of knowledge and utilizing the interaction matching of rules as a measure of knowledge differentiation. First, we propose the concept of forward and reverse rule (trust) drift and introduce a knowledge drift detection model based on interaction matching (named rule knowledge drift detection [RKDD]). The basic features of RKDD are analyzed and discussed. Second, using statistical theory, we discuss the convergence characteristics of rule knowledge and propose a knowledge drift detection model that utilizes interaction matching within the framework of sampling (named sample-rule knowledge drift detection [S-RKDD]). Finally, we compare and analyze the effectiveness of RKDD using three University of California Irvine (UCI) datasets. Theoretical analysis and experimental results demonstrate that RKDD possesses good structural characteristics and interpretability, enabling the integration of decision awareness into the decision-making process through simple parameter adjustments, thereby enriching the existing data drift detection theory to a certain extent.},
  archive      = {J_KBS},
  author       = {Yuanjian Lin and Yongwang Duan and Chenxia Jin and Fachao Li},
  doi          = {10.1016/j.knosys.2025.113664},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113664},
  shortjournal = {Knowl. Based Syst.},
  title        = {Research on knowledge drift based on interaction matching},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new multi-tree genetic programming approach to feature construction in high-dimensional classification. <em>KBS</em>, <em>319</em>, 113643. (<a href='https://doi.org/10.1016/j.knosys.2025.113643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification, as a key task in machine learning, has been widely studied. However, with the rapid advancement of information technology, features in classification tasks increasingly exhibit low discriminability and strong redundancy. And the classification data has gradually changed from low-dimensional data to high-dimensional data. These characteristics not only significantly increase the complexity of the classification model training, but also lead to a decline in the generalization ability of the classification model. How to reduce the number of original features and improve their differentiation becomes the key to improve the classification accuracy. Feature construction stands out as a crucial data processing technique for enhancing data quality. Genetic Programming (GP) has found extensive applications in feature construction due to its flexibility and strong interpretability. However, the existing GP-based feature construction methods suffer from the interference of redundant and irrelevant features in the face of high-dimensional data. By eliminating irrelevant and redundant features, reducing the search space of GP can aid in constructing more discriminative features. Motivated by this, we propose a GP algorithm that combines feature selection with feature construction for high-dimensional classification. During the evolution of GP, a subtree archive is introduced to store promising subtrees and these subtrees assist the generation of offspring. The experimental results show that the proposed method can achieve better classification performance than single-tree and multi-tree GP methods.},
  archive      = {J_KBS},
  author       = {Ke Chen and Mingyang Dao and Ying Bi and Jing Liang and Zhenlong Wu and Peng Wang},
  doi          = {10.1016/j.knosys.2025.113643},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113643},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new multi-tree genetic programming approach to feature construction in high-dimensional classification},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing personalized trip recommendations with attractive route analysis and graph attention auto-encoder. <em>KBS</em>, <em>319</em>, 113639. (<a href='https://doi.org/10.1016/j.knosys.2025.113639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized trip recommendations aim to offer an itinerary featuring various points of interest (POIs) to the user. Many previous works search POIs only according to their popularity. However, the routes between the POIs are attractive to visitors, and some of these routes are very popular. This kind of route, which enhances the user experience, is referred to as AR. In this paper, we investigate attractive routes in order to enhance personalized trip recommendation. We introduce TRAR, a personalized underlineTrip R ecommender with POIs and A ttractive R outes, which is comprised of three components: AR discovery, AR evaluation, and trip recommendation. We propose two methods for AR discovery: one focuses on discovering AR by analyzing the Gini coefficient and the popularity of POIs, the other is to discover AR with the help of graph attention auto-encoder (GATE). In order to discover more attractive routes for users to improve their user experience, we take the structure information of a travel graph into consideration to extract the features of routes; then we introduce GATE to AR discovery. In the AR evaluation, we estimate attractive routes’ rating scores and preferences by applying the gravity model in a category space. To enhance user experience, TRAR balances the trade-off between user experience and time cost by recommending trips that include attractive routes. The experimental results indicate that the proposed TRAR is superior to other state-of-the-art algorithms.},
  archive      = {J_KBS},
  author       = {Jiqing Gu and Chao Song and Wenjun Jiang and Li Lu and Ming Liu},
  doi          = {10.1016/j.knosys.2025.113639},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113639},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing personalized trip recommendations with attractive route analysis and graph attention auto-encoder},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal decomposition and attribute correlation differentiation at multiple scales: A graph imputation network for incomplete multivariate time series. <em>KBS</em>, <em>319</em>, 113636. (<a href='https://doi.org/10.1016/j.knosys.2025.113636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, incomplete time series are common, often complicating subsequent data mining processes. Time series data often exhibits complex temporal and attribute dependencies, and how to fully explore and leverage these relationships to accurately impute missing values in multivariate time series has long been a concern. To this end, based on graph networks, we propose a graph imputation model that uses temporal decomposition and attribute correlation differentiation at multiple scales (GITAM), aiming to impute missing values by deeply mining and modeling the temporal dynamics and attribute correlations of incomplete time series. Specifically, we design a multi-scale learning and decomposition module to extract multiple significant periods and decompose the sequence into multiple trend and seasonal components, clearly revealing long-term trends and fluctuations at various scales. A temporal graph is then designed to capture the temporal dependencies within and across time scales, ensuring accurate temporal representation during imputation. For the attribute dimension, the model constructs a heterogeneous graph that differentiates homogeneous and heterogeneous correlations, accurately modeling interactions between attributes to enhance imputation accuracy. Finally, we employ a spatial-temporal synchronous graph convolution module to capture both temporal and attribute features of the sequence in a single convolution step. This model aggregates historical and adjacent attribute information of missing values at multiple scales, allowing the clear extraction of trend and seasonal features despite the presence of missing data and enabling accurate imputation. Numerical experiments on various real-world datasets demonstrate that GITAM outperforms baseline methods across multiple missing data scenarios.},
  archive      = {J_KBS},
  author       = {Ditong Chen and Liyong Zhang and Xiaochen Lai and Wei Lu and Zhuohan Li},
  doi          = {10.1016/j.knosys.2025.113636},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113636},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal decomposition and attribute correlation differentiation at multiple scales: A graph imputation network for incomplete multivariate time series},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model based system with causal inference and chain-of-thoughts reasoning for traffic scene risk assessment. <em>KBS</em>, <em>319</em>, 113630. (<a href='https://doi.org/10.1016/j.knosys.2025.113630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating potential traffic scene risks is crucial for the decision-making process in autonomous driving systems. Large Language Models (LLMs), due to their advanced scene understanding and reasoning capabilities, offer a new paradigm for decision-making in autonomous driving. However, when used to evaluate traffic scene risks, LLM faces challenges of model hallucination and slow inference speed. Therefore, we have developed a TrafficRiskGPT-based system. Initially, we designed the TrafficRiskGPT model, which is a large language model specifically used for traffic scene risk reasoning. Its core is based on the LLaMA3-8B model, and it incorporates a large amount of traffic risk datasets for LoRA (Low-Rank Adaptation) fine-tuning, enabling the model to deeply understand traffic scene risks. On this basis, we designed a system around the TrafficRiskGPT model. The system establishes a knowledge base based on traffic scene risks and incorporated HNSW (Hierarchical Navigable Small World graphs) method to improve the retrieval efficiency of the knowledge base, introduces vLLM technology to improve the system’s inference speed, and constructs a comprehensive risk evaluation metric to assess the system’s performance on traffic scene risks. Finally, we designed a CI-CoT (Causal Inference Chain-of-Thought) technique, allowing the system to gradually evaluate the traffic risks associated with each decision, thereby reducing model hallucinations and slow inference speed issues. Our experiments show that in the same scenarios, in terms of vehicle collision rates, our method reduces the rate by 7.3% compared to GPT4o-mini, significantly reduces outputs irrelevant to traffic scene risks, and improves model inference speed by a factor of 3.62.},
  archive      = {J_KBS},
  author       = {Wuchang Zhong and Jinglin Huang and Maoqiang Wu and Weinan Luo and Rong Yu},
  doi          = {10.1016/j.knosys.2025.113630},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113630},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language model based system with causal inference and chain-of-thoughts reasoning for traffic scene risk assessment},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved proximal policy optimization for UAV tracking in complex environments. <em>KBS</em>, <em>319</em>, 113627. (<a href='https://doi.org/10.1016/j.knosys.2025.113627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) operating in urban environments face critical challenges in dynamic field of view (FOV) management and obstacle avoidance. To address these issues, this paper proposes an improved Proximal Policy Optimization algorithm (I-PPO) that integrates seven key enhancements, including reward scaling, gradient clip, and others. This algorithm improves sample efficiency and reduces policy oscillation in complex environments, in which we have developed a three-dimensional simulation environment capable of multi-terrain parametric modeling that integrates weather-related FOV attenuation models and intelligent dynamic obstacle modules. Focusing on the tracking task, the study designs a reward function based on a hierarchical penalty system and priority rules. This approach ensures operational safety while maximizing target vehicle visibility, thereby optimizing agent performance under environmental uncertainties. Experimental results demonstrate that in plain environments, I-PPO yields a 2.9-fold increase in mean cumulative reward and extends target tracking duration by a factor of 2.7 compared to the standard PPO. In hilly terrain, I-PPO maintains reward performance comparable to its plain environment baseline, exhibiting merely a 2% performance degradation, confirming terrain adaptability. In mountainous terrain, while it shows a 12% reward reduction versus hilly terrain, it exhibits a 38.9% reduction in reward variance (measured by IQR) compared to Discrete Soft Actor–Critic (DSAC), this demonstrates significant robustness enhancement. In scenarios with 10 intelligent dynamic obstacles, the algorithm achieves stable convergence within 984 time units and demonstrates equivalent robustness under weather-induced FOV attenuation across multi-terrain environments. Furthermore, Theoretical analysis confirms the method’s compliance with policy gradient convergence requirements.},
  archive      = {J_KBS},
  author       = {Tao Zhang and Qingyan Zhou and Yue Zheng and Huiwen Yu},
  doi          = {10.1016/j.knosys.2025.113627},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113627},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improved proximal policy optimization for UAV tracking in complex environments},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement and opposition-based learning enhanced weighted mean of vectors algorithm for global optimization and feature selection. <em>KBS</em>, <em>319</em>, 113626. (<a href='https://doi.org/10.1016/j.knosys.2025.113626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel optimization algorithm that integrates reinforcement learning (RL) and opposition-based learning (OBL) mechanisms with the weighted mean of vectors algorithm (INFO). The OBL has proven effective in enhancing optimization algorithms, the lack of adaptive selection mechanisms often leads to suboptimal performance. The proliferation of OBL variants poses significant challenges in selecting appropriate mechanisms for specific optimization problems, as each variant exhibits distinct characteristics and performance patterns across different problem landscapes. This research addresses this limitation by introducing a novel RL framework for OBL selection. The proposed QLOBL INFO algorithm employs Q-learning to adaptively select among five OBL variants, enabling dynamic strategy adaptation during the optimization process. The algorithm's performance has been extensively evaluated using the CEC2022 benchmark suite, real-world feature selection problems, and constrained optimization problems. These results demonstrate that RL-based adaptive OBL selection represents an effective approach for enhancing optimization performance, particularly in complex optimization landscapes and real-world applications.},
  archive      = {J_KBS},
  author       = {İlker Gölcük and Fehmi Burcin Ozsoydan and Esra Duygu Durmaz},
  doi          = {10.1016/j.knosys.2025.113626},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113626},
  shortjournal = {Knowl. Based Syst.},
  title        = {Reinforcement and opposition-based learning enhanced weighted mean of vectors algorithm for global optimization and feature selection},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning model for automated colorectal cancer detection using local and global feature extraction. <em>KBS</em>, <em>319</em>, 113625. (<a href='https://doi.org/10.1016/j.knosys.2025.113625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) ranks among the most lethal malignancies globally, underscoring the importance of timely and precise diagnosis. Although histopathological examination remains the clinical gold standard, the intricate morphology of tissue samples and inter-observer variability drive the need for robust automated methods. To address these challenges, this paper presents a hybrid deep learning model that integrates InceptionNeXt blocks, enhanced Swin Transformer blocks, and a Residual Multi-Layer Perceptron (ResMLP). In the initial stages, InceptionNeXt blocks employ multi-branch convolutions to capture nuclear morphology, glandular structures, and stromal textures, particularly benefiting limited training data scenarios. Subsequent layers utilize enhanced Swin Transformer blocks with window-based self-attention and shifted windows, effectively modeling long-range dependencies. The ResMLP component further refines feature representation via residual learning. Comprehensive evaluations on two benchmark CRC datasets—NCT-CRC HE-100K and Kather-5K—demonstrated accuracies of 99.96 % and 99.06 %, respectively, outperforming 10 state-of-the-art CNN and 10 ViT-based models. Additionally, Grad-CAM visualizations highlight the critical regions influencing classification decisions, enhancing model interpretability. These results establish the proposed method as a reliable, generalizable, and clinically viable solution for automated CRC detection.},
  archive      = {J_KBS},
  author       = {Ishak Pacal and Omneya Attallah},
  doi          = {10.1016/j.knosys.2025.113625},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113625},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid deep learning model for automated colorectal cancer detection using local and global feature extraction},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geo-FuB: A method for constructing an operator-function knowledge base for geospatial code generation with large language models. <em>KBS</em>, <em>319</em>, 113624. (<a href='https://doi.org/10.1016/j.knosys.2025.113624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of spatiotemporal data and the increasing demand for geospatial modeling have driven the automation of these tasks with large language models (LLMs) to enhance research efficiency. However, general LLMs often encounter hallucinations when generating geospatial code due to a lack of domain-specific knowledge on geospatial functions and related operators. The retrieval-augmented generation (RAG) technique, integrated with an external operator-function knowledge base, provides an effective solution to this challenge. To date, no widely recognized framework exists for building such a knowledge base. This study presents a comprehensive framework for constructing the operator-function knowledge base, leveraging semantic and structural knowledge embedded in geospatial scripts. The framework consists of three core components: Function Semantic Framework Construction (Geo-FuSE), Frequent Operator Combination Statistics (Geo-FuST), and Combination and Semantic Framework Mapping (Geo-FuM). Geo-FuSE employs techniques like Chain-of-Thought (CoT), TF-IDF, t-SNE, and Gaussian Mixture Models (GMM) to extract semantic features from scripts; Geo-FuST uses Abstract Syntax Trees (AST) and the Apriori algorithm to identify frequent operator combinations; Geo-FuM combines LLMs with a fuzzy matching algorithm to align these combinations with the semantic framework, forming the Geo-FuB knowledge base. The instance of Geo-FuB, named GEE-FuB, has been developed using 154,075 Google Earth Engine scripts and is available at https://github.com/whuhsy/GEE-FuB . Based on a set of well-defined evaluation metrics introduced in this study, the GEE-FuB construction achieved an overall accuracy of 88.89 %, demonstrating a 31 % to 34 % reduction in hallucinations compared to mainstream LLMs without external knowledge integration. This research introduces a novel approach to knowledge mining and knowledge base construction specifically tailored for geospatial code generation tasks, broadening the applications of knowledge base construction and providing valuable theoretical insights, practical examples, and data resources for related research fields.},
  archive      = {J_KBS},
  author       = {Shuyang Hou and Anqi Zhao and Jianyuan Liang and Zhangxiao Shen and Huayi Wu},
  doi          = {10.1016/j.knosys.2025.113624},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113624},
  shortjournal = {Knowl. Based Syst.},
  title        = {Geo-FuB: A method for constructing an operator-function knowledge base for geospatial code generation with large language models},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLAN: A dual attention network for effective land cover classification in remote sensing. <em>KBS</em>, <em>319</em>, 113620. (<a href='https://doi.org/10.1016/j.knosys.2025.113620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of remote sensing (RS), the demand for accurate land cover classification (LCC) has intensified due to various environmental challenges such as deforestation and urbanization. Conventional approaches often rely on shallow features for classification, limiting their effectiveness in capturing spatial patterns and diverse land cover types. In response, this study introduces a novel LCC approach utilizing a convolutional neural network (CNN) equipped with a dual land cover attention segment. The proposed module integrates channel attention (CA) and spatial attention mechanisms (SA) to enhance the discriminative capabilities of deep models. Leveraging inter-channel and inter-spatial relationships, the dual attention module enables the identification of various land cover types, spatial patterns, and color variations. Through thorough experimentation, the InceptionV3 feature extractor was identified as the optimal backbone for the proposed network architecture. Furthermore, to address the challenge of diverse land cover types, highly curated datasets are utilized. Additionally, to optimize model efficiency and reduce size, an improved model compression approach is employed. The effectiveness of the proposed Dual Land Cover Attention Network (DLAN) was evaluated through extensive experimentation, demonstrating superior performance compared to conventional methods. The results indicate the potential of DLAN in advancing LCC tasks, facilitating detailed agricultural zoning, environmental monitoring, and urban planning at a regional scale.},
  archive      = {J_KBS},
  author       = {Muhammad Fayaz and L. Minh Dang and Hyeonjoon Moon},
  doi          = {10.1016/j.knosys.2025.113620},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113620},
  shortjournal = {Knowl. Based Syst.},
  title        = {DLAN: A dual attention network for effective land cover classification in remote sensing},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RCLMuFN: Relational context learning and multiplex fusion network for multimodal sarcasm detection. <em>KBS</em>, <em>319</em>, 113614. (<a href='https://doi.org/10.1016/j.knosys.2025.113614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm typically conveys emotions of contempt or criticism by expressing a meaning that is contrary to the speaker’s true intent. Accurately detecting sarcasm aids in identifying and filtering undesirable information on the Internet, thereby mitigating malicious defamation and rumor-mongering. Nonetheless, automatic sarcasm detection remains a challenging task for machines, as it critically depends on intricate factors such as relational context. Existing multimodal sarcasm detection methods focus on introducing graph structures to establish entity relationships between text and image while neglecting to learn the relational context between text and image, which is crucial evidence for understanding the meaning of sarcasm. In addition, the meaning of sarcasm evolves across different contexts, but current methods may struggle to accurately model such dynamic changes, thereby limiting the generalization ability of the models. To address the aforementioned issues, we propose a relational context learning and multiplex fusion network (RCLMuFN) for multimodal sarcasm detection. First, we employ four feature extractors to comprehensively extract features from raw text and images, aiming to excavate potential features that may have been previously overlooked. Second, we propose a relational context learning module to learn the contextual information of text and images and capture the dynamic properties through shallow and deep interactions. Finally, we propose a multiplex feature fusion module to enhance the model’s generalization by effectively integrating multimodal features derived from diverse interaction contexts. Extensive experiments on two multimodal sarcasm detection datasets show that RCLMuFN achieves state-of-the-art performance.},
  archive      = {J_KBS},
  author       = {Tongguan Wang and Junkai Li and Guixin Su and Yongcheng Zhang and Dongyu Su and Yuxue Hu and Ying Sha},
  doi          = {10.1016/j.knosys.2025.113614},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113614},
  shortjournal = {Knowl. Based Syst.},
  title        = {RCLMuFN: Relational context learning and multiplex fusion network for multimodal sarcasm detection},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IFTrans: A few-shot classification method for consumer fraud detection in social sensing. <em>KBS</em>, <em>319</em>, 113608. (<a href='https://doi.org/10.1016/j.knosys.2025.113608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer fraud detection using deep learning and social sensing has achieved significant progress. However, the inherent complexity and ambiguity of social sensing data constrain the effectiveness of existing few-shot classification methods in detecting unforeseen fraudulent behavior. To address these limitations, we propose a novel few-shot classification method designed specifically for consumer fraud detection. Our approach integrates an instance-level semantic relevance module and a feature-level fine-grained semantic relevance module, enabling the effective capture of semantic correlations between support sets and input samples while distinguishing fine-grained inter-class differences. This design allows for the detection of unforeseen fraudulent behaviors using a minimal number of support instances from the target domain without requiring fine-tuning or retraining. Experimental results demonstrate that our method surpasses state-of-the-art few-shot classification approaches in consumer fraud detection. Furthermore, we constructed a new dataset with nearly ten times more fraud samples than existing datasets, providing a solid foundation for advancing research in this domain.},
  archive      = {J_KBS},
  author       = {Shanyan Lai and Junfang Wu and Chunyang Ye and Zheyun Wu and Zhiwei Ma and Hui Zhou},
  doi          = {10.1016/j.knosys.2025.113608},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113608},
  shortjournal = {Knowl. Based Syst.},
  title        = {IFTrans: A few-shot classification method for consumer fraud detection in social sensing},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized e-learning resource recommendation using multimodal-enhanced collaborative filtering. <em>KBS</em>, <em>319</em>, 113605. (<a href='https://doi.org/10.1016/j.knosys.2025.113605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized learning resource recommendation is a prominent research area in the field of e-learning, allowing learners to find appropriate resources that align with their specific learning needs. The continuous development and optimization of online learning platforms have resulted in an increasing amount of e-learning resources and learner data. This poses challenges to the existing e-learning resource recommendation approaches, most of which rely on conventional collaborative filtering (CF) exclusively. Their efficiency is constrained owing to the utilization of a sole modality or a limited subset of modalities for the recommendation. To address these challenges, this study proposes a multimodal-enhanced CF approach in e-learning. Our approach uses various modalities for modeling, including learners’ learning records, human–computer interaction patterns, and information related to the resources. It integrates techniques such as matrix factorization for the joint learner–resource pattern modeling, clustering for grouping similar learners, and the long short-term memory network for capturing the temporal dynamics of learning activities. Comprehensive experiments are conducted to evaluate the efficiency of the proposed approach, and to determine its optimal setup for a deep understanding of the contributions of each component.},
  archive      = {J_KBS},
  author       = {Xinwei Zhai and Yuanyuan Wang and Luwen Liang and Kangzhong Wang and Fengchun Pei and Eugene Yujun Fu},
  doi          = {10.1016/j.knosys.2025.113605},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113605},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized e-learning resource recommendation using multimodal-enhanced collaborative filtering},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient black-box adversarial attacks via alternate query and boundary augmentation. <em>KBS</em>, <em>319</em>, 113604. (<a href='https://doi.org/10.1016/j.knosys.2025.113604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing query-based black-box attacks use surrogate models as transferable priors to improve query efficiency. However, these methods still suffer from high query times and complexity due to the following three reasons. First, they usually use a transfer-based strategy to find a starting point, which is not conducive to fast optimization. Second, most of them exploit transferable priors in a complex way that severely constrains query efficiency. Third, their performance usually depends on the number of surrogate models and the more surrogate models, the better the performance. To this end, we propose an optimization framework based on fusion attack and boundary augmentation, which make full use of transfer prior and query feedback to achieve a more effective and efficient attack. Specifically, we first use the surrogate model to conduct a warm-up attack guided by query feedback, which provides a better starting point for fast optimization. Then, we introduce a data-augmentation-based transferable attack into query-based method for alternative query. Since the alternate attack framework can quickly find out the adversarial area of the target model, it improves the query efficiency. Finally, we design a decision boundary enhancement strategy to make the decision boundary of the model more diverse. This strategy can reduce the number of surrogate models used yet still achieve competitive performance. To validate the effectiveness of the proposed method, we conduct experiments with three victim models on the ImageNet dataset. Extensive experiment results show that our method achieves favorable performance against the state-of-the-art methods. While the proposed method gets a 100% attack success rate, the query times can be reduced by several orders of magnitude.},
  archive      = {J_KBS},
  author       = {Jiatian Pi and Fusen Wen and Fen Xia and Ning Jiang and Haiying Wu and Qiao Liu},
  doi          = {10.1016/j.knosys.2025.113604},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113604},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient black-box adversarial attacks via alternate query and boundary augmentation},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSPT: Two-step prompt tuning for class-incremental novel class discovery. <em>KBS</em>, <em>319</em>, 113603. (<a href='https://doi.org/10.1016/j.knosys.2025.113603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, models often encounter a sequence of unlabeled new tasks, each containing unknown classes. This paper explores class-incremental novel class discovery (class-iNCD), which requires maintaining previously learned knowledge while discovering novel classes. We consider a more realistic and also more challenging scenario, which has a small number of initial known classes and a large number of unlabeled tasks, with the additional requirement of data privacy protection. A simple yet effective approach, Two-Step Prompt Tuning (TSPT), is proposed. TSPT tackles class-iNCD through prompt tuning, which is rehearsal-free and plug-and-play, protecting data privacy and significantly reducing the number of trainable parameters. TSPT consists of two main steps: (1) novel class discovery, which initializes the classifier using uniform clustering, and uses intra- and inter-sample consistency learning to discover novel classes; and, (2) knowledge fusion, where the prompt learned in the previous step is adapted as task-specific prompt, and additional optimal prompts are selected from a prompt pool to integrate knowledge from both old and new classes. Experiments on three datasets demonstrated the effectiveness of TSPT.},
  archive      = {J_KBS},
  author       = {Jiayu An and Zhenbang Du and Herui Zhang and Dongrui Wu},
  doi          = {10.1016/j.knosys.2025.113603},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113603},
  shortjournal = {Knowl. Based Syst.},
  title        = {TSPT: Two-step prompt tuning for class-incremental novel class discovery},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive frequency-domain enhanced deep model driven by heterogeneous networks for medical image segmentation. <em>KBS</em>, <em>319</em>, 113599. (<a href='https://doi.org/10.1016/j.knosys.2025.113599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate medical image segmentation necessitates precise localization of global structures and local boundaries due to the high variability in lesion shapes and sizes. However, existing models are limited by conventional spatiotemporal features and single-network architectures, which restrict the simultaneous captures of semantic information and boundary details, thereby challenging generalizable medical image segmentation. To overcome these limitations, we propose a heterogeneous network-driven adaptive frequency-domain enhanced deep model(AFDSeg). First, we introduce the Frequency Domain Adaptive High-Frequency Feature Selection(FAHS) module, which adaptively extracts high-frequency features to enhance contour and detail representation while integrating spatiotemporal and frequency-domain features for improved consistency. Additionally, Prototype-Guided Low-Frequency Feature Aware(PFLA) and Local High-Frequency Salient-Feature Denoising (LHSD) modules are developed, which extract discriminative low-frequency features while suppressing local noise in high-frequency components, thereby facilitating efficient multi-scale feature fusion. Furthermore, the Multi-Level Prototype Feature Refinement(MPFR) Module is introduced to align low- and high-dimensional features during decoding and enhance semantic consistency. Finally, a heterogeneous network framework capable of accommodating multiple network architecture for medical image segmentation is proposed. Our method achieves mDice scores of 93.91%, 88.64%, 91.27%, 90.74%, and 81.38% on the Kvasir-SEG, BUSI, ISIC-2017, ACDC, and Synapse datasets, respectively, and attains 92.09%, 93.50%, and 83.92% in cross-domain experiments on three unseen datasets (Kvasir Capsule-SEG, BUS42, and M&Ms). Our approach consistently outperforms state-of-the-art methods on both benchmark and cross-domain datasets. Extensive quantitative and qualitative experiments demonstrated that AFDSeg accurately segments global structures and local details while maintaining superior generalization, underscoring its clinical significance. The Code is available at https://github.com/promisedong/AFDSeg .},
  archive      = {J_KBS},
  author       = {Dong Liu and Jin Kuang},
  doi          = {10.1016/j.knosys.2025.113599},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113599},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive frequency-domain enhanced deep model driven by heterogeneous networks for medical image segmentation},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AUSAM: Adaptive unified segmentation anything model for multi-modality tumor segmentation and enhanced detection in medical imaging. <em>KBS</em>, <em>319</em>, 113588. (<a href='https://doi.org/10.1016/j.knosys.2025.113588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor segmentation in medical imaging is critical for diagnosis, treatment planning, and prognosis, yet remains challenging due to limited annotated data, tumor heterogeneity, and modality-specific complexities in CT, MRI, and histopathology. Although the Segment Anything Model (SAM) shows promise as a zero-shot learner, it struggles with irregular tumor boundaries and domain-specific variations. We introduce the Adaptive Unified Segmentation Anything Model (AUSAM) . This novel framework extends SAM’s capabilities for multi-modal tumor segmentation by integrating an intelligent prompt module, dynamic sampling, and stage-based thresholding. Specifically, clustering-based prompt learning (DBSCAN for CT/MRI and K-means for histopathology) adaptively allocates prompts to capture challenging tumor regions, while entropy-guided sampling and dynamic thresholding systematically reduce annotation requirements and computational overhead. Validated on diverse benchmarks—LiTS (CT), FLARE 2023 (CT/MRI), ORCA, and OCDC (histopathology)—AUSAM achieves state-of-the-art Dice Similarity Coefficients (DSC) of 94.25%, 91.84%, 87.59%, and 91.84%, respectively, with significantly reduced data usage. As the first framework to adapt SAM for multi-modal tumor segmentation, AUSAM sets a new standard for precision, scalability, and efficiency. It is offered in two variants: AUSAM-Lite for resource-constrained environments and AUSAM-Max for maximum segmentation accuracy, thereby advancing medical imaging and clinical decision-making.},
  archive      = {J_KBS},
  author       = {Suraj Sood and Saeed Alqarni and Syed Jawad Hussain Shah and Yugyung Lee},
  doi          = {10.1016/j.knosys.2025.113588},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113588},
  shortjournal = {Knowl. Based Syst.},
  title        = {AUSAM: Adaptive unified segmentation anything model for multi-modality tumor segmentation and enhanced detection in medical imaging},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-aware and static context network for large-scale 3D place recognition. <em>KBS</em>, <em>319</em>, 113577. (<a href='https://doi.org/10.1016/j.knosys.2025.113577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D point cloud-based place recognition enables robots to obtain precise global positions without GPS, correct trajectory drift in SLAM, and recover from the kidnapped robot problem. However, in outdoor environments, the presence of moving objects can cause occlusions in point clouds and introduce noise into the data, leading to localization failures. To address this issue, we propose a Dynamic-Aware and Static Context Network (DASC-Net) for large-scale 3D place recognition. Our approach leverages the spatio-temporal consistency of point cloud sequences to accurately segment dynamic objects while incorporating static point cloud context to compensate for feature loss caused by noise interference or occlusions from dynamic objects, thereby enhancing robustness and generalization. Specifically, DASC-Net adopts a two-stage strategy: first, it introduces a coarse-to-fine moving object segmentation method to effectively eliminate dynamic noise; second, it utilizes spatial context association and multi-scale feature aggregation to improve static feature representation and matching. Extensive experimental results demonstrate that DASC-Net outperforms existing place recognition approaches, particularly in dynamic scenes.},
  archive      = {J_KBS},
  author       = {Ming Liao and Xiaoguang Di and Maozhen Liu and Teng Lv and Xiaofei Zhang and Runwen Zhu},
  doi          = {10.1016/j.knosys.2025.113577},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113577},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic-aware and static context network for large-scale 3D place recognition},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-layer residual spiking neural network with adaptive threshold leaky integrate-and-fire neuron and learnable surrogate gradient. <em>KBS</em>, <em>319</em>, 113575. (<a href='https://doi.org/10.1016/j.knosys.2025.113575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the Leaky Integrate-and-Fire (LIF) neuron model has demonstrated its outstanding performance in simulating basic neuronal functions, it has certain limitations when it comes to capturing the advanced adaptive behaviors in biological neurons, particularly the phenomenon of neural adaptation. Biological neurons gradually reduce their firing activity in response to repeated and continuous stimulation, the phenomenon mainly depends on the dynamic adjustment of their firing thresholds. In order to express the characteristic, this paper introduces the Adaptive Threshold Leaky Integrate-and-Fire (AT-LIF) neuron model. The neuron includes a learnable parameter that dynamically adjusts the firing threshold according to the repetitive or high-frequency firing response of the neuron, thereby effectively preventing the neuron from over-activating. In order to deal with the non-differentiable backpropagation of neurons, this paper proposes an Adaptive Surrogate Gradient Scaling (ASG-S) method, which modifies the conventional approach of fixed surrogate gradient widths by introducing a learnable scaling factor. Furthermore, the ASG-S method dynamically adjusts the size of the surrogate gradient near the threshold based on the gap between the membrane potential and spike of neuron, thereby enhancing the efficiency of neuronal connections. This method alleviates the gradient vanishing problem commonly encountered with traditional rectangular surrogate gradients, especially in deep networks. Finally, this paper proposes a Cross-Layer Residual Connection Network, this network establishes residual connections between different residual blocks, facilitating the cross-layer flow and fusion of information, thereby reducing information loss within the network and enhancing the model's learning capacity and inference performance.},
  archive      = {J_KBS},
  author       = {Qingsong Ai and Yingnan Yang and Mincheng Cai and Kun Chen and Quan Liu and Li Ma},
  doi          = {10.1016/j.knosys.2025.113575},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113575},
  shortjournal = {Knowl. Based Syst.},
  title        = {A cross-layer residual spiking neural network with adaptive threshold leaky integrate-and-fire neuron and learnable surrogate gradient},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness and social bias quantification in large language models for sentiment analysis. <em>KBS</em>, <em>319</em>, 113569. (<a href='https://doi.org/10.1016/j.knosys.2025.113569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have enhanced various Natural Language Processing (NLP) tasks, including text generation and classification. However, studies reveal that LLMs exhibit social biases, such as associating certain occupations with specific genders. While previous research has focused on bias in text generation, limited attention has been given to text classification, such as sentiment analysis. This study quantifies social bias in sentiment analysis using five open-source LLMs: BERT, GPT-2, LLaMA-2, Falcon, and MistralAI, fine-tuned on two large social media datasets, the first one is related to nuclear energy, while the second dataset is general and contains tweets related to various subjects. We conducted approximately 1,500 prompt experiments with variations in words reflecting energy source, gender, politics, age, and ethnicity. A fair language model should provide the same sentiment for both prompts; differing sentiments would indicate bias. Explainable methods were employed to analyze how words related to the five subjects (energy, gender, politics, age, ethnicity) contributed to the sentiment. Findings show that social bias persists in LLMs for sentiment analysis, and while fine-tuning can enhance fairness, it does not always eliminate bias, particularly regarding age groups.},
  archive      = {J_KBS},
  author       = {Mohammed I. Radaideh and O. Hwang Kwon and Majdi I. Radaideh},
  doi          = {10.1016/j.knosys.2025.113569},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113569},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fairness and social bias quantification in large language models for sentiment analysis},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CyMoDiff: Dimensional cycle diffusion for unsupervised 2D-to-3D motion retargeting. <em>KBS</em>, <em>319</em>, 113568. (<a href='https://doi.org/10.1016/j.knosys.2025.113568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing evidence of the effectiveness of diffusion models in the field of human pose and motion, we introduce diffusion models into the 2D-to-3D motion retargeting task for the first time, proposing the CyMoDiff framework, which employs a novel two-stage motion retargeting paradigm: 3D estimation + limb scaling. By leveraging our proposed dimensional cycle mechanism, CyMoDiff enables unsupervised training using 2D videos, thereby eliminating the need for paired 3D motion and motion type annotations. Specifically, the diffusion model within CyMoDiff diffuses limb scaling factors from noise, whereas the dimensional cycle mechanism constrains the generation space of 3D motion while disentangling motion features, thereby ensuring the plausibility of the retargeted motion. Our approach addresses the error propagation issues inherent in traditional two-stage 3D estimation + kinematics pipelines and the insufficient disentanglement of body structure and motion observed in one-stage methods. Experimental results indicate that CyMoDiff outperforms state-of-the-art approaches on both synthetic and in-the-wild datasets.},
  archive      = {J_KBS},
  author       = {Yachuan Wang and Bin Zhang and Hao Yuan},
  doi          = {10.1016/j.knosys.2025.113568},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113568},
  shortjournal = {Knowl. Based Syst.},
  title        = {CyMoDiff: Dimensional cycle diffusion for unsupervised 2D-to-3D motion retargeting},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring formal defeasible reasoning of large language models: A chain-of-thought approach. <em>KBS</em>, <em>319</em>, 113564. (<a href='https://doi.org/10.1016/j.knosys.2025.113564'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defeasible reasoning, critical for commonsense reasoning and uncertainty handling, has garnered significant attention in AI community. This interest is particularly pronounced in the development and evaluation of Large Language Models (LLMs), which often involve reconciling inconsistent and incomplete knowledge. However, it remains uncertain whether LLMs possess generalizable defeasible reasoning abilities. Besides, the lack of a formal defeasible reasoning benchmark and appropriate evaluations limits further exploration in this domain. In this study, we aim to investigate the capacity of LLMs for defeasible reasoning, particularly within the framework of formal defeasible logic. Specifically, we select the popular defeasible logic framework, DeLP, as the basis for evaluating the LLMs’ defeasible logical reasoning capabilities. We initially create a synthetic dataset comprising logical programs that encompass a variety of DeLP programs with differing depths of reasoning. To address the challenges encountered during inference, we introduce a Chain-of-Thought (CoT) framework that prompts LLMs to conduct formal deduction and engage in multi-step defeasible reasoning, thereby enhancing problem-solving performance. Employing this argumentative solving approach, we observe that LLMs struggle to manage defeasible information effectively. This observation raises questions about whether contemporary LLMs possess reasoning abilities comparable to human intelligence, challenging the reliable deployment and advancement of AI systems in real-world scenarios.},
  archive      = {J_KBS},
  author       = {Zhaoqun Li and Chen Chen and Mengze Li and Beishui Liao},
  doi          = {10.1016/j.knosys.2025.113564},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113564},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploring formal defeasible reasoning of large language models: A chain-of-thought approach},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A low-dimensional cross-attention model for link prediction with applications to drug repurposing. <em>KBS</em>, <em>319</em>, 113562. (<a href='https://doi.org/10.1016/j.knosys.2025.113562'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction, a key technique for knowledge graph completion, has advanced with transformer-based encoders utilizing high-dimensional embeddings and self-attention mechanisms. However, these approaches often result in models with excessive parameters, poor scalability, and substantial computational demands, limiting their practical applicability. To address these limitations, this paper introduces a low-dimensional link prediction model that leverages cross-attention for improved efficiency and scalability. Our approach employs low-dimensional embeddings to capture essential, non-redundant information about entities and relations, significantly reducing computational and memory requirements. Unlike self-attention, which models interactions within a single set of embeddings, cross-attention in our model captures complex interactions between entities and relations in a compact, low-dimensional space. Additionally, a streamlined decoding method simplifies computations, reducing processing time without compromising accuracy. Experimental results show that our model outperforms most state-of-the-art link prediction models on two public datasets, WN18RR and FB15k-237. Compared to these top-performing methods, our model contains only 18.1 % and 25.4 % of the parameters of these comparable models, while incurring a performance loss of merely 2.4 % and 3.1 %, respectively. Furthermore, it achieves an average 72 % reduction in embedding dimensions compared to five leading models. A case study on drug repurposing further illustrates the model's potential for real-world applications in knowledge graph completion.},
  archive      = {J_KBS},
  author       = {Geng-jing Chen and Gong-de Guo and S. Lorraine Martin and Hui Wang},
  doi          = {10.1016/j.knosys.2025.113562},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113562},
  shortjournal = {Knowl. Based Syst.},
  title        = {A low-dimensional cross-attention model for link prediction with applications to drug repurposing},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HiLINK: Hierarchical linking of context-aware knowledge prediction and prompt tuning for bilingual knowledge-based visual question answering. <em>KBS</em>, <em>319</em>, 113556. (<a href='https://doi.org/10.1016/j.knosys.2025.113556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based visual question answering (KBVQA) is a representative visual reasoning task that leverages external knowledge for question answering in situations where predicting the correct answer using only image and query data is difficult. In addition to KBVQA, various visual reasoning tasks have been actively studied for their potential to improve visual understanding by combining text and image modalities effectively. However, these tasks have primarily focused on high-resource languages, such as English. In contrast, studies on low-resource languages remain comparatively rare. To mitigate this research gap, we propose HiLINK, which utilizes multilingual data to enhance KBVQA performance in various languages. In this study, we use the BOK-VQA dataset to design the following key methodologies: We propose an end-to-end model that eliminates the need for a knowledge graph embedding-based training network by learning relationships between triplet knowledge components within prompts directly using Link-Tuning. We propose the HK-TriNet and HK-TriNet+ methodologies to perform triplet prediction based on contextualized knowledge relationships. Finally, we apply the frozen training approach as an alternative to conventional encoder joint training to improve the efficiency and performance of bilingual learning. HiLINK exhibits outstanding performance on the BOK-VQA dataset in three language configurations: bilingual, English, and Korean, outperforming the GEL-VQA method by +19.40%, +12.01%, and +11.30%, respectively. Furthermore, the effectiveness of the proposed method is validated based on a comprehensive analysis of bilingual embedding spaces, both visually and numerically. We expect this study to inspire future research on this topic and encourage practical applications of improved vision-language models.},
  archive      = {J_KBS},
  author       = {Hyeonki Jeong and Taehyeong Kim and Wooseok Shin and Sung Won Han},
  doi          = {10.1016/j.knosys.2025.113556},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113556},
  shortjournal = {Knowl. Based Syst.},
  title        = {HiLINK: Hierarchical linking of context-aware knowledge prediction and prompt tuning for bilingual knowledge-based visual question answering},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSTVI: Multi-scale time-variable interaction for multivariate time series forecasting. <em>KBS</em>, <em>319</em>, 113551. (<a href='https://doi.org/10.1016/j.knosys.2025.113551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) is widely used in economic forecasting, weather forecasting, public health monitoring and other fields. It involves multiple univariate series, and these series have complex interrelations at different scales. However, existing models lack the ability to capture multi-scale relationships among these variables, which limits the forecasting accuracy. Additionally, they typically treat time and variable modeling separately, making it difficult to fully grasp the deeper connections between them. To address these limitations, we propose a novel multi-scale framework called MSTVI, M ulti- S cale T ime- V ariable I nteraction model. MSTVI employs a pyramid-like hierarchical structure to efficiently capture and integrate features at different scales. At each level, a well-designed T ime- V ariable I nteraction (TVI) module is employed to model complex relationships across both the time and variable dimensions simultaneously. The TVI module introduces a novel compression interaction mechanism to compress data along the time and variable dimensions, extract key information, and integrate it through a cross-interaction process to model time series, and it is generic enough to be plugged into an existing model to improve performance. MSTVI demonstrates superior performance across seven real-world benchmarks. Additionally, MSTVI’s architecture ensures that both time and memory complexities scale linearly with the sequence length L and the number of variables M , achieving O ( L ) and O ( M ) . Our code can be found in: https://github.com/liuquangao.},
  archive      = {J_KBS},
  author       = {Quangao Liu and Ruiqi Li and Maowei Jiang and Wei Yang and Chen Liang and Longlong Pang and Zhuozhang Zou},
  doi          = {10.1016/j.knosys.2025.113551},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113551},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSTVI: Multi-scale time-variable interaction for multivariate time series forecasting},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-driving information theory-based compositional distributional semantics: A case study on spanish song lyrics. <em>KBS</em>, <em>319</em>, 113549. (<a href='https://doi.org/10.1016/j.knosys.2025.113549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Song lyrics pose unique challenges for semantic similarity assessment due to their metaphorical language, structural patterns, and cultural nuances - characteristics that often challenge standard natural language processing (NLP) approaches. These challenges stem from a tension between compositional and distributional semantics: while lyrics follow compositional structures, their meaning depends heavily on context and interpretation. The Information Theory-based Compositional Distributional Semantics framework offers a principled approach by integrating information theory with compositional rules and distributional representations. We evaluate eight embedding models on Spanish song lyrics, including multilingual, monolingual contextual, and static embeddings. Results show that multilingual models consistently outperform monolingual alternatives, with the domain-adapted ALBERTI achieving the highest F1 macro scores (78.92 ± 10.86). Our analysis reveals that monolingual models generate highly anisotropic embedding spaces, significantly impacting performance with traditional metrics. The Information Contrast Model metric proves particularly effective, providing improvements up to 18.04 percentage points over cosine similarity. Additionally, composition functions maintaining longer accumulated vector norms consistently outperform standard averaging approaches. Our findings have important implications for NLP applications and challenge standard practices in similarity calculation, showing that effectiveness varies with both task nature and model characteristics.},
  archive      = {J_KBS},
  author       = {Adrián Ghajari and Alejandro Benito-Santos and Salvador Ros and Víctor Fresno and Elena González-Blanco},
  doi          = {10.1016/j.knosys.2025.113549},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113549},
  shortjournal = {Knowl. Based Syst.},
  title        = {Test-driving information theory-based compositional distributional semantics: A case study on spanish song lyrics},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransfficFormer: A novel transformer-based framework to generate evasive malicious traffic. <em>KBS</em>, <em>319</em>, 113546. (<a href='https://doi.org/10.1016/j.knosys.2025.113546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) and deep learning (DL) have significantly improved the detection accuracy of contemporary Network Intrusion Detection Systems (NIDS), yet they remain susceptible to adversarial attacks. Current attacks against ML/DL-based NIDS primarily focus on altering feature vectors, thereby overlooking the discrete and irreversible nature of network traffic packets, which significantly limits its practical applicability. To address these challenges, we propose TransfficFormer to generate adversarial attack traffic that combines heuristic algorithm and transformer. We train a Transformer-based generator by transforming source-space features into discrete sequence autoregressive models. The three-layer particle swarm optimization algorithm with random and perception factor is utilized to optimize the generation of adversarial mutation malicious traffic with reversible metadata feature vectors. Furthermore, the discriminator feedback probability is fine-tuned using reinforcement learning strategies, ensuring the preservation of both malicious intent and normal communication functionality within the generated traffic. Comprehensive experiments demonstrate that Transfficformer can autonomously generate mutant malicious traffic, effectively evading various ML/DL-based NIDS with minimal overhead. The practicality of the generated mutant traffic is validated in the NSFOCUS cyber range.},
  archive      = {J_KBS},
  author       = {Wenbiao Du and Jingfeng Xue and Xiuqi Yang and Wenjie Guo and Dujuan Gu and Weijie Han},
  doi          = {10.1016/j.knosys.2025.113546},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113546},
  shortjournal = {Knowl. Based Syst.},
  title        = {TransfficFormer: A novel transformer-based framework to generate evasive malicious traffic},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Positional trace encoding for next activity prediction in event logs. <em>KBS</em>, <em>319</em>, 113544. (<a href='https://doi.org/10.1016/j.knosys.2025.113544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of log data, generated by running processes in many application domains, enables organizations to identify opportunities for operational improvements. For instance, in healthcare, analyzing patient treatment logs can optimize care pathways; in manufacturing, production line logs can reveal bottlenecks; and in customer service, ticket resolution logs can streamline response protocols. One key analytical task is predicting the next activity in a process, which supports operational decision-making through better resource allocation and proactive response to customer needs. In this paper, we solve the next activity prediction task by exploiting a novel positional encoding approach that is based on sliding windows. This approach allows us to consider both a way to adapt to changes in the data distribution, and exploit positional information of the activities in the traces. The method proposed in this paper, called OREO, takes into account these aspects through a positional encoding tightly coupled with specific types of deep neural network architectures. The results on eight real-world process logs show the superiority of the models exploiting OREO encoding over state-of-the-art approaches, confirming our initial intuition of benefits gained by combining a time-window based model with positional information.},
  archive      = {J_KBS},
  author       = {Antonio Pellicani and Michelangelo Ceci},
  doi          = {10.1016/j.knosys.2025.113544},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113544},
  shortjournal = {Knowl. Based Syst.},
  title        = {Positional trace encoding for next activity prediction in event logs},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed observer-based formation control and obstacle avoidance of nonholonomic mobile robots with input saturation. <em>KBS</em>, <em>319</em>, 113542. (<a href='https://doi.org/10.1016/j.knosys.2025.113542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of distributed observer-based formation control and collision avoidance for multi-robot systems with input saturation. Different from existing approaches where accurate robot poses are assumed to be available, a novel distributed observer-based control framework is developed, which can deal with the failure to fulfill safety constraints caused by pose estimation errors, ensuring both formation maintenance and collision avoidance. The proposed method can be applied to any kind of pose observer satisfying a mild requirement, and at the same time, it can adaptively deal with estimation inaccuracies using function approximation and does not need prior knowledge of the weight upper bounds in approximation. Additionally, in contrast to common position-only CBF-based methods, both position and orientation are considered simultaneously, which offers more control flexibility to ensure coordination and safety in environments with static and dynamic obstacles. Furthermore, the framework decentralizes traditional safety conditions into distributed constraints, which allows independent computation for each robot. Particularly, to address infeasibility issues caused by multiple CBF constraints, relaxation parameters are introduced in safety barrier certificates, broadening the feasible solution space in the quadratic program. Finally, the effectiveness and advantage of the proposed framework are validated by numerical simulation and comparison studies.},
  archive      = {J_KBS},
  author       = {Siqi Wang and Heng Wang and Yulong Wang and Qing Li},
  doi          = {10.1016/j.knosys.2025.113542},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113542},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distributed observer-based formation control and obstacle avoidance of nonholonomic mobile robots with input saturation},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning hierarchical scene graph and contrastive learning for object goal navigation. <em>KBS</em>, <em>319</em>, 113532. (<a href='https://doi.org/10.1016/j.knosys.2025.113532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of object goal navigation (ObjNav) requires the agent to locate the given target object within a complex dynamic scene. To successfully accomplish the task, the agent needs to well understand the scenes, make executable decisions with less steps, avoid collisions, and successfully navigate to the target. As a result, efficient environmental perception and scene graph-inspired path planning is important to successfully accomplish the ObjNav task. In this paper, we present a hierarchical scene graph (HSG) contrastive learning, which consists of (1) a multimodal graph mixer that aligns the visual and textual information using open-vocabulary detector with GLIP. It can be regarded as an “eagle eye” to perceive target-related frontiers and suppress irrelevant information, and (2) a graph constructer that takes observed RGBD images to incrementally build a hierarchical scene graph. It acts as the “brain” that memorizes the common scene layout, (3) an action control contrastive learning that takes the graph contextual relationships as input to predict optimal actions to the target. It is treated as the “limbs” of the agent, coordinating and correcting incorrect movements. On the task of ObjNav, experiments on Gibson, HM3D, MP3D, and ProcTHOR demonstrate that navigation plans from the HSG framework achieve significantly higher success rates than existing map-based method, indicating the feasibility of executing navigation utilizing commonsense knowledge from language models leading efficient semantic exploration. Code is available at https://github.com/luosword/HSG4VN .},
  archive      = {J_KBS},
  author       = {Jian Luo and Jian Zhang and Bo Cai and Yaoxiang Yu and Aihua Ke},
  doi          = {10.1016/j.knosys.2025.113532},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113532},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning hierarchical scene graph and contrastive learning for object goal navigation},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Radial adaptive node embedding hashing for cross-modal retrieval. <em>KBS</em>, <em>319</em>, 113522. (<a href='https://doi.org/10.1016/j.knosys.2025.113522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of multimedia data on social networks, efficient and accurate cross-modal retrieval has become essential. Cross-modal hashing methods offer advantages such as fast retrieval speed and low storage cost. However, unsupervised deep cross-modal hashing methods often struggle with semantic misalignment and noise, limiting their effectiveness in capturing fine-grained relationships across modalities. To address these challenges, we propose Radial Adaptive Node Embedding Hashing (RANEH), designed to enhance semantic consistency and retrieval efficiency. Specifically, the semantic meta-similarity construction module reconstructs identity semantics using a similarity matrix, ensuring that hash codes retain modality-specific features. The radial adaptive hybrid coding method employs FastKAN as an encoder to map features into a shared hash space, maintaining semantic consistency across modalities. Lastly, the broadcasting node embedding unit leverages the Fast Kolmogorov–Arnold network to capture deep modality relationships, improving semantic alignment and node embedding accuracy. Experiments on the NUS-WIDE, MIRFlickr, and MSCOCO datasets show that RANEH method consistently outperforms state-of-the-art unsupervised cross-modal hashing methods in accuracy and efficiency. The codes are available at https://github.com/YunfeiChenMY/RANEH .},
  archive      = {J_KBS},
  author       = {Yunfei Chen and Renwei Xia and Zhan Yang and Jun Long},
  doi          = {10.1016/j.knosys.2025.113522},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113522},
  shortjournal = {Knowl. Based Syst.},
  title        = {Radial adaptive node embedding hashing for cross-modal retrieval},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From local verification to global reasoning: Exploiting slot-accompanying update for improved slot selection. <em>KBS</em>, <em>319</em>, 113521. (<a href='https://doi.org/10.1016/j.knosys.2025.113521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of dialogue-state tracking (DST) is to determine the current state of a dialogue by analysing the entire preceding dialogue context. Nonetheless, current approaches frequently fail to account for the significance of concurrent updates, where related slots must be updated simultaneously based on their historical relationships, even in the absence of explicit signals in the current dialogue turn. To address this limitation, we introduce From Local Verification to Global Reasoning (FLV2GR), an innovative method that improves slot-update selection by combining local verification of present dialogue details with global reasoning over historical dialogue data. Our approach utilizes a graph neural network (GNN) to model and infer interdependencies between slots, enabling the identification of accompanying update relationships that are frequently overlooked by other approaches. This comprehensive selection mechanism improves the precision of slot updates, thereby enhancing overall DST performance. The FLV2GR model establishes a new performance benchmark on the MultiWOZ 2.1, 2.2, and 2.4 datasets, showcasing its effectiveness in capturing both local and global dialogue dynamics for more precise and reliable DST. 1},
  archive      = {J_KBS},
  author       = {Bing Qian and Jinyu Guo and Qiwei Wang and Kai Shuang},
  doi          = {10.1016/j.knosys.2025.113521},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113521},
  shortjournal = {Knowl. Based Syst.},
  title        = {From local verification to global reasoning: Exploiting slot-accompanying update for improved slot selection},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-distribution monocular depth estimation with local invariant regression. <em>KBS</em>, <em>319</em>, 113518. (<a href='https://doi.org/10.1016/j.knosys.2025.113518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular Depth Estimation (MDE) aims to produce a high-quality depth map from a single RGB image. Recent advancements in deep learning have led to notable improvements in MDE through end-to-end manner. However, most existing approaches primarily focus on MDE using clean input data, neglecting the challenges posed by Out-of-Distribution (OoD) corrupted data in the real-world scenarios. This oversight limits the generalization and robustness of advanced MDE models, resulting in unpredictable errors. To tackle this issue, in this paper, we propose an OoD MDE model that employs local invariant regression. Specifically, we introduce a novel HOG (Histogram of Oriented Gradients) consistency loss function, which utilizes local invariant feature regression to capture robust local geometric structures and enhance robustness to the common corruptions in a self-supervised manner. Additionally, we present a novel Cascaded Iterative Enhancement network (CIE-Depth), designed to accurately and robustly predict monocular depth maps through adaptive hierarchical interaction in a coarse-to-fine manner. Extensive experiments demonstrate that our method achieves highly competitive performance against state-of-the-art techniques on the KITTI, NYUv2, SUN RGBD and underwater FLSea datasets. Further evaluations highlight the robustness of our approach when applied to the corrupted KITTI-C and NYUv2-C datasets.},
  archive      = {J_KBS},
  author       = {Yeqi Hu and Yuan Rao and Hui Yu and Gaige Wang and Hao Fan and Wei Pang and Junyu Dong},
  doi          = {10.1016/j.knosys.2025.113518},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113518},
  shortjournal = {Knowl. Based Syst.},
  title        = {Out-of-distribution monocular depth estimation with local invariant regression},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating edge features and complementary attention mechanism for drug response prediction. <em>KBS</em>, <em>319</em>, 113508. (<a href='https://doi.org/10.1016/j.knosys.2025.113508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting drug response in cancer cell lines is a vital field in precision medicine, supporting personalized treatment planning, optimizing drug selection, and enhancing the accuracy and effectiveness of cancer therapies. Although graph neural network-based models for drug response prediction have made significant progress in performance, they often focus solely on learning node embeddings while overlooking adjacency relationships between cell lines, limiting the model’s ability to capture inter-cell line adjacency information. To address this limitation, we propose a novel model that constructs edge features by measuring similarity between cell lines and their k-nearest neighbors, integrating these edge features with a node-edge complementary attention mechanism. This approach enables the model to dynamically incorporate node and edge information, achieving complementary and collaborative feature learning. Such a design substantially improves the accuracy and biological interpretability of drug response prediction. Furthermore, to enhance the independence and complementarity of node and edge features, we introduce a complementary loss mechanism in the model and design a topology updating module that performs dynamic feature updates via neighborhood aggregation, effectively capturing and utilizing multi-omics data. We conduct comprehensive experiments on the Genomics of Drug Sensitivity in Cancer and the Cancer Cell Line Encyclopedia, which contains various diseases such as esophageal carcinoma, stomach adenocarcinoma, colon adenocarcinoma and rectal adenocarcinoma, the results demonstrate that our model outperforms current state-of-the-art methods in cancer drug response prediction.},
  archive      = {J_KBS},
  author       = {Chuang Li and Minhui Wang and Chang Tang and Yanfeng Zhu},
  doi          = {10.1016/j.knosys.2025.113508},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113508},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating edge features and complementary attention mechanism for drug response prediction},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary mask tuning on gradient: Towards multi-data question answering. <em>KBS</em>, <em>319</em>, 113505. (<a href='https://doi.org/10.1016/j.knosys.2025.113505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained language models have been widely applied in question-answering tasks. To achieve better generalization on unseen datasets, several previous studies often trained a single model on multiple datasets. However, owing to the noise and distribution differences among various datasets, the model tends to excessively adjust its weights during training on multiple datasets. This deviation from the initial pretraining state results in excellent performance on specific data but overfitting on other datasets. Ultimately, the model loses its ability to generalize to new data. In this paper, from the perspective of imposing constraints on model weights, we propose a novel fine-tuning method, binary mask tuning (BMT). We employ a carefully designed binary mask vector that is closely related to the data distribution to mask the gradient generated by backpropagation, achieving precise alignment of the subspace parameters required to fit the data from a huge parameter space. This approach aimed to enhance the adaptability of the model to the data distribution and improve parameter efficiency via more targeted fine-tuning. Our experiments demonstrate that BMT is not only effective in mitigating the tendency of the model to excessively adjust its weights but also in better capturing cross-dataset regularities and dataset-specific attributes in question-answering tasks across different datasets.},
  archive      = {J_KBS},
  author       = {Chuanyang Gong and Zhihua Wei and Ping Zhu and Duoqian Miao},
  doi          = {10.1016/j.knosys.2025.113505},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113505},
  shortjournal = {Knowl. Based Syst.},
  title        = {Binary mask tuning on gradient: Towards multi-data question answering},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor graph based connectivity peaks clustering. <em>KBS</em>, <em>319</em>, 113498. (<a href='https://doi.org/10.1016/j.knosys.2025.113498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering by fast search and find of density peaks (DPC), a classic density-based algorithm, excels in identifying clusters of arbitrary shape. However, it struggles in recognizing complex structures due to challenges in selecting density peaks and allocating non-central points. To address these issues, we propose an anchor graph based connectivity peaks clustering method which is the connection between anchor graph and density-based clustering, called AG-CPC. Firstly, it introduces a new concept of connectivity by analyzing the divergence and discreteness of neighborhood adjacency graph to detect low-density clusters and border points. Secondly, a robust two-stage assignment strategy using an adaptive parent–child relationships based on data distribution characteristics, is proposed to reduce the wrong allocation of non-central points. Lastly, a local method for constructing anchor graphs is introduced, combined with fuzzy connectivity and boundary domains of clusters, to scale down the anchor graphs and establish the connection among anchor points. The experiments demonstrate the efficiency and stability of the proposed algorithm compared to state-of-the-art algorithms on synthetic, real-world, and image datasets.},
  archive      = {J_KBS},
  author       = {Mingjie Cai and Jiangyuan Wang and Feng Xu and Qiong Liu and Hamido Fujita},
  doi          = {10.1016/j.knosys.2025.113498},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113498},
  shortjournal = {Knowl. Based Syst.},
  title        = {Anchor graph based connectivity peaks clustering},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably bounded prompting prior network for universal compressed sensing magnetic resonance imaging. <em>KBS</em>, <em>319</em>, 113485. (<a href='https://doi.org/10.1016/j.knosys.2025.113485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressed sensing magnetic resonance imaging (CSMRI) aims to reconstruct MR images from undersampled k -space data. Existing deep unrolling CSMRI methods unfold iterative algorithms into deep neural networks, demonstrating superior reconstruction performance. However, they still face several limitations: ( i ) The prior networks used in deep unrolling methods are often empirically designed, lacking interpretability and hindering further theoretical analysis. ( i i ) These methods require training for each sampling setting (e.g. sampling mode and sampling ratio), which incurs significant storage costs. To address these challenges, we propose PDSNet, a network inspired by a double sparsity model, which is both provable and interpretable. As a prior network, PDSNet is integrated into a deep unrolling framework to solve the universal CSMRI task. This enables our method to use a single model to address the compressed sensing MRI problem across various sampling settings. Specifically, PDSNet is built on a double sparsity model using tight frames, and the thresholds for shrinking frame coefficients are adaptively generated by a dedicated threshold-generating sub-network (TGNet). In TGNet, we introduce an information fusion module that effectively captures both global and regional features. Additionally, a prompt block is designed to learn discriminative information across different sampling settings, enabling high-quality reconstructions for each setting using a single model. Experimental results demonstrate that our method achieves superior reconstruction performance. On the theoretical side, we provide explicit proof that PDSNet satisfies bounded properties and further show that the corresponding iterative algorithm converges to a fixed point.},
  archive      = {J_KBS},
  author       = {Baoshun Shi and Zheng Liu and Kexun Liu and Yueming Su},
  doi          = {10.1016/j.knosys.2025.113485},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113485},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provably bounded prompting prior network for universal compressed sensing magnetic resonance imaging},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective generative replay with strong memory for continual learning. <em>KBS</em>, <em>319</em>, 113477. (<a href='https://doi.org/10.1016/j.knosys.2025.113477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning enables artificial neural networks (ANNs) to recognize samples derived from unknown classes while maintaining high classification accuracy for known classes. A classic continual learning approach involves storing data acquired from previously learned tasks and replaying it alongside new tasks in subsequent training sessions. However, data storage may not be feasible due to privacy or security concerns. To address this issue, we propose a effective approach for retaining a strong memory of past tasks within the utilized model. Our method integrates visual saliency-based feature enhancement with a generative replay strategy that captures past task information using visual saliency cues. Specifically, we integrate an adaptive sparse convolutional network module into a generative model, where adaptive sparse convolutional layers select task-relevant features and reduce the number of redundant computations and storage. Experiments show that our method reduces computational overhead by approximately 8% compared to the baseline method. Additionally, since sparse convolution can lead to the loss of global contextual information, we incorporate a bottleneck attention module to improve the feature representations, resulting in an accuracy improvement of the model in the CIFAR-100 task from 26.90% to 27.50%. Finally, to classify unobserved data not included in the training set, we introduce an adaptive mask (AM) module. In the CIFAR-100 20-stage task, the model accuracy improved from 16.05% (ASC only) to 20.31%, and the number of parameter calculations is reduced by 5.1%. This method effectively addresses data retention challenges while enhancing performance and provides a promising solution for privacy-preserving continual learning.},
  archive      = {J_KBS},
  author       = {Jing Yang and Xinyu Zhou and Yao He and Qinglang Li and Zhidong Su and Xiaoli Ruan and Changfu Zhang},
  doi          = {10.1016/j.knosys.2025.113477},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Effective generative replay with strong memory for continual learning},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDIR: Domain-disentangled invariant representation learning for tailored predictions. <em>KBS</em>, <em>319</em>, 113422. (<a href='https://doi.org/10.1016/j.knosys.2025.113422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional training methods often struggle to scale effectively with large datasets due to significant distributional differences. Domain generalization (DG) aims to address the challenge of generalizing across multiple-source domains and improving performance in unknown target domains. While many DG methods, such as domain-invariant representation (DIR) learning, excel in handling significant distribution shifts, they often sacrifice performance on in-distribution (IID) data. This trade-off is crucial in real-world applications with uncertain distribution shifts, spanning both out-of-distribution (OOD) and IID scenarios. To address this, we identify DIR’s limitation in neglecting task-relevant non-domain-invariant information, termed Domain-Orthogonal Invariant (DOI) information. We propose the Domain-Disentangled Invariant Representation (DDIR) learning, which retains DOI information without introducing redundancy. Our method introduces an information disentanglement loss to extract domain-invariant and different DOI information within a single backbone, achieving lower spatial complexity. Moreover, during inference, we propose optimal DOI selection approaches for individual target samples to avoid utilizing redundant DOI information, enabling tailored predictions for each target sample. Experiments demonstrate DDIR’s effectiveness in enhancing generalization performance across IID and OOD scenarios.},
  archive      = {J_KBS},
  author       = {Yuan Ma and Yang Gu and Xin Qin and Shuai Guo and Feiyi Fan and Fan Dong and Yiqiang Chen},
  doi          = {10.1016/j.knosys.2025.113422},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113422},
  shortjournal = {Knowl. Based Syst.},
  title        = {DDIR: Domain-disentangled invariant representation learning for tailored predictions},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFC: Time–frequency contrasting network for wearable-based human activity recognition. <em>KBS</em>, <em>319</em>, 113373. (<a href='https://doi.org/10.1016/j.knosys.2025.113373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) using sensor data has significantly progressed with various supervised learning architectures, including both traditional CNN/LSTM models and the more recent Transformer-based models. A primary challenge in supervised learning is the requirement for extensive, accurately labeled training data. Self-supervised methods, particularly those employing contrastive learning, offer an innovative solution to this challenge by leveraging unlabeled data. In this study, we introduce a novel self-supervised learning method named Time–Frequency Contrasting (TFC) for limited labeled data in HAR, rooted in the principles of contrastive learning and Bayesian structural time series. This approach interprets sensor data as a combination of time-domain trends, frequency-domain cycles, and error noise. Our objective is to learn a universal representation so as to enhance the performance of human activity recognition in downstream tasks. This is achieved by minimizing the impact of redundant noise and leveraging time-domain prior knowledge to learn time-domain trend features and utilizing frequency-domain prior knowledge to acquire frequency-domain cycle features, respectively. After fine-tuning, TFC achieved Macro F1-scores of 86.39, 95.44, and 80.27 on three publicly available datasets, namely MotionSense, USC-HAD, and UCI-HAR. Additionally, it obtained a F1-score of 97.64 on a custom-built dataset called BARD. Our extensive experiment demonstrate that TFC markedly improves self-supervised activity recognition tasks, especially in scenarios with limited labeled data.},
  archive      = {J_KBS},
  author       = {Zhenzhen Huang and Jiukai Deng and Shengzhi Wang and Chaogang Tang and Shuo Xiao},
  doi          = {10.1016/j.knosys.2025.113373},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113373},
  shortjournal = {Knowl. Based Syst.},
  title        = {TFC: Time–frequency contrasting network for wearable-based human activity recognition},
  volume       = {319},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGDAAN-nets: A local and global domain adversarial attention neural networks for EEG emotion recognition. <em>KBS</em>, <em>318</em>, 113613. (<a href='https://doi.org/10.1016/j.knosys.2025.113613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive research is being conducted worldwide on emotion recognition, which is a crucial technology in affective computing. Electroencephalogram (EEG) signals are widely employed in emotion recognition owing to their ease of discernibility and high accuracy. Effectively harnessing the spatial-temporal-spectral features of EEG signals is essential for realizing accurate emotion classification due to their low signal-to-noise ratio. In this study, we proposed an EEG emotion recognition algorithm based on local and global domain adversarial attention neural networks, called LGDAAN-Nets, to address the problems of cross-subject EEG emotion recognition. Firstly, we constructed a ConvLSTM block with residual structures as a spatial-temporal-spectral feature to fully exploit the temporal relationship, spatial structure, and spectral information of the input spatial-temporal matrix and spatial-spectral matrix in the network. We then introduced a self-attention module as a supplementary component to the feature extractor, which integrates the long-range and multilevel dependencies of the cross-modal emotion features. This facilitates the learning of complementary information from different feature patterns and enhances the emotion recognition capability of the model. Lastly, we built a local-global domain discriminator using two local domain discriminators that reduce the distribution differences under different feature patterns and capture the locally invariant features of the EEG signals. The global domain discriminator minimizes the global differences in the fused features between the source and target domains, which improves the robustness and generalization performance of the model. The proposed method was comprehensively tested on the SEED, SEED-IV, and DEAP datasets and demonstrated superior performance over most existing emotion recognition methods. Additionally, experiments were also conducted on a self-collected EEG-based emotion dataset that included 20 subjects, which further validated the proposed model's performance in cross-dataset emotion recognition. The source code is available at: https://github.com/cvmdsp/LGDAAN-Nets .},
  archive      = {J_KBS},
  author       = {Yanling An and Shaohai Hu and Shuaiqi Liu and Xinrui Wang and Zhihui Gu and Yudong Zhang},
  doi          = {10.1016/j.knosys.2025.113613},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113613},
  shortjournal = {Knowl. Based Syst.},
  title        = {LGDAAN-nets: A local and global domain adversarial attention neural networks for EEG emotion recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-data driven generalized zero-shot learning for multi-agent bearing compound fault diagnosis. <em>KBS</em>, <em>318</em>, 113595. (<a href='https://doi.org/10.1016/j.knosys.2025.113595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent fault diagnosis for both single and compound faults face a huge challenge due to the scarce training compound fault data. Utilizing the coupling relationship between single-fault and compound fault, the generalized zero-shot learning (GZSL) method can recognize unseen compound faults with the data of seen single faults. However, the current GZSL approaches have the following critical issues: the constructed fault semantics deviate from actual features, and the training model is heavily influenced by the seen data of diverse single faults. Therefore, a new semantic construction method is proposed by training a semantic mapping model via the simulated data to enhance the consistency between the generated and actual semantics. Moreover, an improved multi-agent deep reinforcement learning (MADRL) collaborative diagnosis network is proposed to improve the classification ability, which assigns each agent a diagnostic subtask for a specific component by customizing the interactive environment. Finally, a multi-agent GZSL bearing fault diagnosis framework is established. The effectiveness and advantages of the framework are validated using three bearing datasets for the GZSL diagnosis tasks.},
  archive      = {J_KBS},
  author       = {Yi Qin and Xiwen Liu and Xin Li and Yongfang Mao},
  doi          = {10.1016/j.knosys.2025.113595},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113595},
  shortjournal = {Knowl. Based Syst.},
  title        = {Simulation-data driven generalized zero-shot learning for multi-agent bearing compound fault diagnosis},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The animated oat optimization algorithm: A nature-inspired metaheuristic for engineering optimization and a case study on wireless sensor networks. <em>KBS</em>, <em>318</em>, 113589. (<a href='https://doi.org/10.1016/j.knosys.2025.113589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel metaheuristic algorithm called the Animated Oat Optimization Algorithm (AOO) is proposed, inspired by the natural behavior of Animated Oat in the environment. AOO simulates 3 unique behaviors of Animated Oat: (i) seed dispersal through natural elements such as wind, water, and animals; (ii) under the influence of hygroscopic movement, the primary awn of Animated Oat seeds undergoes distortion and rotation, enabling the entire seed to roll and propagate; and (iii) during the rolling propagation, energy is stored upon encountering obstacles, triggering a propulsion mechanism under certain conditions to further disperse the seeds. To evaluate the algorithm's capabilities in exploration and exploitation, we utilized the CEC2022 test suite, which comprises 12 functions. Comparative analysis with 9 well-known optimization algorithms demonstrates that AOO exhibits superior competitiveness. Furthermore, we extend our evaluation to five widely-used engineering design problems to confirm the algorithm's performance in these domains. Finally, we combined AOO with DV-Hop to validate its competitiveness and effectiveness in experiments on node localization in 3-dimensional Wireless Sensor Networks. These results demonstrate AOO's ability to tackle complex optimization challenges and its potential as a reliable optimizer for practical engineering applications. Source codes of AOA are publicly available at https://github.com/robingit77/Animated-Oat-Optimization-Algorithm-AOO- and https://seyedalimirjalili.com/morealgorithms .},
  archive      = {J_KBS},
  author       = {Ruo-Bin Wang and Rui-Bin Hu and Fang-Dong Geng and Lin Xu and Shu-Chuan Chu and Jeng-Shyang Pan and Zhen-Yu Meng and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.113589},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113589},
  shortjournal = {Knowl. Based Syst.},
  title        = {The animated oat optimization algorithm: A nature-inspired metaheuristic for engineering optimization and a case study on wireless sensor networks},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMOTE-based data augmentation for accurate classification of neutron halo nuclei: A machine learning approach in nuclear physics. <em>KBS</em>, <em>318</em>, 113580. (<a href='https://doi.org/10.1016/j.knosys.2025.113580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neutron halo nuclei exhibit unique structural features—such as extended matter distributions, large interaction cross sections, and unusually low separation energies—that offer valuable insights into the nature of nuclear forces, stability limits, and astrophysical nucleosynthesis. Traditional analytical methods face challenges in accurately characterizing these exotic systems, highlighting the need for advanced computational techniques. In this study, we propose a machine learning–based framework that leverages Synthetic Minority Over-sampling Technique (SMOTE)-based data augmentation to address class imbalance in neutron halo classification tasks. A comprehensive evaluation is conducted on eight widely used algorithms—AdaBoost, XGBoost, C5.0, Generalized Linear Models (GLM), k -Nearest Neighbors ( k NN), Naive Bayes, Random Forest, and Support Vector Machines (SVM)—, assessing their predictive performance and computational efficiency. The results demonstrate that AdaBoost and XGBoost provide superior accuracy and stability, offering a robust approach to identifying potential neutron halo candidates. Additionally, we develop an interactive Shiny application for real-time classification, thereby strengthening the connection between data-driven methodologies and nuclear structure research. Overall, this work underscores the importance of data augmentation in nuclear physics and highlights the potential of machine learning-driven strategies for the automated identification of exotic halo nuclei, paving the way for more in-depth exploration of nuclear stability and structure.},
  archive      = {J_KBS},
  author       = {Cafer Mert Yeşilkanat and Serkan Akkoyun},
  doi          = {10.1016/j.knosys.2025.113580},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113580},
  shortjournal = {Knowl. Based Syst.},
  title        = {SMOTE-based data augmentation for accurate classification of neutron halo nuclei: A machine learning approach in nuclear physics},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced dynamic deep Q-network for federated learning scheduling policies on IoT devices using explanation-driven trust. <em>KBS</em>, <em>318</em>, 113574. (<a href='https://doi.org/10.1016/j.knosys.2025.113574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Internet of Things (IoT) and edge computing have led to rapid growth in the number of IoT devices generating extensive volumes of data at the network edge. Efficiently scheduling tasks on these devices, particularly under strict latency constraints in federated learning (FL) environments, poses substantial challenges. In this paper, we propose a novel trust-energy-aware scheduling framework specifically designed for latency-constrained federated edge computing scenarios. Our innovative strategy integrates Dynamic Deep Q-Network (Dynamic-DQN) reinforcement learning with Local Interpretable Model-agnostic Explanations (LIME), enabling dynamic, real-time assessment of device trustworthiness with interpretability and transparency. This combined approach allows the framework to intelligently allocate tasks to IoT devices, explicitly optimizing for reduced latency, improved energy efficiency, and enhanced system reliability. Extensive experimental evaluations confirm that our proposed method substantially outperforms conventional reinforcement learning and heuristic scheduling algorithms, demonstrating significant reductions in latency, superior energy management, and improved scalability. These results underscore the robustness and practical effectiveness of our framework in addressing critical FL challenges.},
  archive      = {J_KBS},
  author       = {Gaith Rjoub and Hanae Elmekki and Jamal Bentahar and Witold Pedrycz and Sofian Kassaymeh and Shahed Bassam Almobydeen and Rachida Dssouli},
  doi          = {10.1016/j.knosys.2025.113574},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113574},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced dynamic deep Q-network for federated learning scheduling policies on IoT devices using explanation-driven trust},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crop-paste and diffusion-based semi-supervised segmentation network for metal defect detection. <em>KBS</em>, <em>318</em>, 113573. (<a href='https://doi.org/10.1016/j.knosys.2025.113573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal defect semantic segmentation is a crucial process for classifying and locating defects during the industrial production process, which holds paramount importance in elevating the quality of metal products. Recently, deep learning has exhibited impressive capabilities in identifying and segmenting defects on metal surfaces. However, the prevalent use of fully supervised segmentation techniques demands a substantial amount of annotated data for effective model training, which is hard to obtain in real scenarios. Additionally, most defects of metal products exhibit indistinct edge details, which hinders precise defect localization. In this study, a Crop-Paste and diffusion-based semi-supervised segmentation network (CPDNet) is proposed to identify pixel-level defects on metal surfaces by utilizing data that are both labeled and unlabeled. Firstly, a semi-supervised training method Crop-Paste is proposed to facilitate the learning of comprehensive semantic features from an extensive of unlabeled images and a restricted set of labeled images. Secondly, a frequency-directed diffusion model is proposed to recover high frequency features of defects to generate more accurate segmentation results. Lastly, an edge aware module is proposed in Sobel mean-teacher (M-T) UNet to improve the boundary information representation associated with defects. The experimental results on four datasets related to metal surface defects and a multimodal dataset show that CPDNet achieves a better performance in comparison with those state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Lixiang Zhao and Jianbo Yu},
  doi          = {10.1016/j.knosys.2025.113573},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113573},
  shortjournal = {Knowl. Based Syst.},
  title        = {Crop-paste and diffusion-based semi-supervised segmentation network for metal defect detection},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient uncertainty measure with dynamic update mechanisms. <em>KBS</em>, <em>318</em>, 113572. (<a href='https://doi.org/10.1016/j.knosys.2025.113572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive adoption of information technology, the data we encounter today is frequently dynamic and subject to change over time. To facilitate timely decision-making, it is crucial to possess a measure that can swiftly identify and continuously update the inherent uncertainty present in the data. In this paper, we present a measure of weighted uncertainty, referred to as WCE, and investigate methods for its dynamic updating within information systems. Initially, the granularity of the universe is established based on binary relations derived from each attribute, which is subsequently utilized to assign weights. Following this, we employ conditional entropy to assess the uncertainty level of the target concept concerning each attribute. Ultimately, the overall uncertainty of the information system is computed by weighting the uncertainty associated with each attribute. To enhance the intuitiveness and simplicity of dynamic updates for weighted uncertainty more intuitive and straightforward, we transform the WCE into matrix form. We then delve into the dynamic updating mechanism, examining how the core matrices are modified in response to variations in data volume or attributes. Finally, numerical experiments conducted on UCI datasets demonstrate that the proposed WCE measure is responsive to diverse data changes. Its updating approach for dynamic information systems can significantly reduce time consumption.},
  archive      = {J_KBS},
  author       = {Yingying Sun and Jusheng Mi},
  doi          = {10.1016/j.knosys.2025.113572},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113572},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient uncertainty measure with dynamic update mechanisms},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAPEW: Towards robust collaborative filtering with graph contrastive learning. <em>KBS</em>, <em>318</em>, 113570. (<a href='https://doi.org/10.1016/j.knosys.2025.113570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL) has shown excellent performance in Collaborative Filtering (CF), one of the most widely used techniques in efficient recommender systems. However, existing GCL-based CF methods suffer from node degree disparity, feature oversmoothing, difficulty in distinguishing hard negative samples, and semantic loss. To address these problems, this paper proposes a novel graph contrastive learning method for robust CF, named D egree- A ware P ropagation and E ntropy- W eighted contrastive loss (DAPEW). DAPEW introduces a degree-aware propagation mechanism to dynamically adjust the influence of initial embeddings, adjacency matrix products, and degree matrix products on the final embeddings, which can effectively handle node degree disparity and alleviate feature oversmoothing. DAPEW also designs an entropy-weighted contrastive loss, which introduces entropy weights to better distinguish hard negative samples and enhance the model’s discriminative ability and robustness. Experimental results show that DAPEW outperforms the existing GCL-based CF methods on several real-world datasets. Compared with existing GCL-based methods, DAPEW improves Recall@40 and NDCG@40 by 0.24% ∼ 25.88% and 0.14% ∼ 26.18% across four different datasets, respectively.},
  archive      = {J_KBS},
  author       = {Kuiyu Zhu and Tao Qin and Haoxing Liu and Chenxu Wang and Pinghui Wang},
  doi          = {10.1016/j.knosys.2025.113570},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113570},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAPEW: Towards robust collaborative filtering with graph contrastive learning},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic fractal equilibrium optimizer with X-shaped dynamic transfer function for solving large-scale feature selection problems. <em>KBS</em>, <em>318</em>, 113567. (<a href='https://doi.org/10.1016/j.knosys.2025.113567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale feature selection (FS) is an important task in the field of data extraction and machine learning. Its core goal is to identify and screen out the feature subset that is most critical to the prediction target from the extensive initial attribute collection, in a bid to improve the efficiency and generalization of the model and reduce the computational complexity. A stochastic fractal equilibrium optimizer based on X-shaped dynamic transfer function is targeted for large-scale feature selection. Among them, the X-shaped transfer function is designed based on the scaling and flip changes of the basic transfer functions, and then the parameters related to the number of iterations in the equilibrium optimizer (EO) are further used as time-varying factors to dynamically change the X-shaped transfer function. The flower-shaped transfer function and dynamic flower-shaped transfer function are extended. At the same time, EO is optimized and improved by using the diffusion and updating process in the stochastic fractal search. To assess the efficacy and dominance of the designed FS method, 20 large-scale datasets were picked from UCI datasets for experiments, and SFEO-TF with the best performance was selected and set against 8 other intelligent optimization approaches. The experimental results show that the designed dynamic time-varying X-shaped transfer function is effective as well as the EO based on stochastic fractal search. Among them, in the two groups of controlled experiments, SFEO-TF has the best performance in performance metric and categorization precision, and even the performance of SFEO-TF set against 8 other intelligent optimization approaches in the minimum fitness value of all 20 large-scale datasets has reached the minimum value.},
  archive      = {J_KBS},
  author       = {Yu-Liang Qi and Yu-Wei Song and Jie-Sheng Wang and Yu-Cai Wang and Shi Li and Si-Yu Jin and Zi-Rui Xu},
  doi          = {10.1016/j.knosys.2025.113567},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113567},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stochastic fractal equilibrium optimizer with X-shaped dynamic transfer function for solving large-scale feature selection problems},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive aggregation for federated learning using representation ability based on feature alignment. <em>KBS</em>, <em>318</em>, 113560. (<a href='https://doi.org/10.1016/j.knosys.2025.113560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has been successfully used in the Internet of Things (IoT) scenarios. However, the data among IoT devices are usually Non-IID (Identically and Independently Distributed), this data heterogeneity will severely affect the convergence rate of the global model and even result in a significant decrease in model accuracy. To address this problem, this paper proposes a federation adaptive aggregation algorithm based on the representation capabilities under feature alignment. Prior to federation training, the server computes initial feature anchors using the global model with Xavier uniform initialization, thus making it more responsive to data features. During client training, the feature alignment method updates all client models within the uniform feature space using enhanced feature anchors, thus reducing the impact of data heterogeneity between clients. A weight scaling factor related to the representation capability is introduced during the server federated aggregation process to adaptively aggregate local model parameters in the presence of data heterogeneity. Extensive experiments were conducted on popular image datasets, namely MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100. The experimental results demonstrate that our method significantly improves the convergence speed of the global model and the model performance, and at the same time effectively mitigates the detrimental effects of data heterogeneity.},
  archive      = {J_KBS},
  author       = {Fujun Pei and Yunpeng Xie and Mingjie Shi and TianTian Xu},
  doi          = {10.1016/j.knosys.2025.113560},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113560},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive aggregation for federated learning using representation ability based on feature alignment},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint multi-layer network and coupling redundancy minimization for semi-supervised EEG-based emotion recognition. <em>KBS</em>, <em>318</em>, 113559. (<a href='https://doi.org/10.1016/j.knosys.2025.113559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing high-level cognitive functions like emotion involves dynamic interaction among multiple brain regions. Interactions involving within- and cross-frequency couplings across these regions are paramount in supporting brain functions. Existing emotion recognition models predominantly focus on within-frequency couplings. However, they lack the incorporation of cross-frequency couplings and within-frequency interactions, essential for providing a comprehensive representation of emotional states. To address this limitation, we propose a novel semi-supervised model for emotion recognition that incorporates a multi-layer network and coupling redundancy minimization (JMNCRM) into a unified framework. First, we construct a generalized multi-layer network that embeds rich coupling information about within- and cross-frequency couplings through cosine similarity of features. Then, without increasing the feature dimensionality, the multi-layer network is incorporated into a discriminative linear regression model as a redundant minimum regularization term. During the optimization process, our model selects the most discriminative and non-redundant feature subsets for emotion recognition while retaining the rich structural, discriminative, and coupling information of electroencephalogram (EEG) data in the learned projection subspace. Extensive experimental results on two public datasets and our music-evoked emotion dataset demonstrate that the JMNCRM model outperforms other state-of-the-art algorithms regarding classification performance. Additionally, the intrinsic activation patterns revealed by JMNCRM are consistent with emotional cognition. The code for JMNCRM will be available at https://github.com/czxyhll/JMNCRM .},
  archive      = {J_KBS},
  author       = {Liangliang Hu and Daowen Xiong and Congming Tan and Zhentao Huang and Yikang Ding and Jiahao Jin and Yin Tian},
  doi          = {10.1016/j.knosys.2025.113559},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113559},
  shortjournal = {Knowl. Based Syst.},
  title        = {Joint multi-layer network and coupling redundancy minimization for semi-supervised EEG-based emotion recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified black-winged kite optimizer based on chaotic maps for global optimization of real-world applications. <em>KBS</em>, <em>318</em>, 113558. (<a href='https://doi.org/10.1016/j.knosys.2025.113558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization algorithms play a critical role in solving complex engineering and medical imaging optimization problems. However, existing metaheuristic techniques often suffer from premature convergence, inefficient exploration, and imbalance between exploration and exploitation. To address these limitations, this paper proposes the Modified Black-Winged Kite Optimizer (M-BWKO), an enhanced version of the standard BWKO algorithm. M-BWKO incorporates six key improvements: a top-k elite leader strategy, adaptive chaos weighting, diversity-aware chaos reactivation, chaotic index-based selection, adaptive Cauchy mutation, and a hybrid migration rule combining chaotic perturbations, Cauchy mutation, and directional updates. The selected M-BWKO variant, Tent-BWKO (TT-BWKO), is evaluated on the CEC-2022 benchmark suite, achieving up to 22.04 % improvement over BWKO and 99.99 % over other state-of-the-art optimizers, with average gains of 6.30 % and 22.13 %, respectively. These results are statistically validated using the Wilcoxon rank-sum test ( p < 0.05), confirming the robustness of the approach. TT-BWKO is further tested on real-world engineering design problems—including Welded Beam, Tension/Compression Spring, and Pressure Vessel—resulting in notable reductions in material cost. It also performs effectively on large-scale Traveling Salesman Problem instances (100, 150, 200 cities), demonstrating strong route optimization and stability. In medical image segmentation, TT-BWKO yields superior PSNR, SSIM, and FSIM scores, confirming its versatility and effectiveness across diverse domains.},
  archive      = {J_KBS},
  author       = {Hanaa Mansouri and Karim Elkhanchouli and Nawal Elghouate and Ahmed Bencherqui and Mohamed Amine Tahiri and Hicham Karmouni and Mhamed Sayyouri and Hassane Moustabchir and S.S. Askar and Mohamed Abouhawwash},
  doi          = {10.1016/j.knosys.2025.113558},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113558},
  shortjournal = {Knowl. Based Syst.},
  title        = {A modified black-winged kite optimizer based on chaotic maps for global optimization of real-world applications},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Particle swarm optimization algorithm based on teaming behavior. <em>KBS</em>, <em>318</em>, 113555. (<a href='https://doi.org/10.1016/j.knosys.2025.113555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional particle swarm optimization algorithms have some shortcomings, such as low convergence precision, slow convergence speed, and susceptibility to falling into local optima when solving complex optimization problems. To address these issues, this paper proposes a new particle swarm optimization algorithm that incorporates teamwork. Specifically, we introduce the concept of teamwork, and divide the particles into multiple teams and selecting team leaders. The particles can fully utilize the team’s prompt information to guide the search process. The team leader updates the search direction of its particles through the generation of information factors, thus giving the algorithm better global search capabilities. The position and behavior of the team leader affect the search behavior of other particles, reducing the risk of falling into local optimal solutions. In addition, to further improve the algorithm’s efficiency, we propose adaptive adjustment of information factors and learning factors. This adaptive adjustment mechanism enables the algorithm to adjust parameters flexibly according to the characteristics of the problem and the current search state, thereby accelerating convergence speed and improving convergence precision. To verify the performance of the proposed algorithm, we make an empirical analysis on 27 different test functions, the shortest path problem and the optimal SINR value problem for UAV deployment. The experimental results show that the proposed algorithm has obvious advantages in convergence accuracy and convergence speed. Compared with other algorithms, this algorithm can find a better solution faster and converge to the global optimal solution more stably.},
  archive      = {J_KBS},
  author       = {Yu-Feng Yu and Ziwei Wang and Xinjia Chen and Qiying Feng},
  doi          = {10.1016/j.knosys.2025.113555},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113555},
  shortjournal = {Knowl. Based Syst.},
  title        = {Particle swarm optimization algorithm based on teaming behavior},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical progressive network for polarized image fusion based on significant polarization information. <em>KBS</em>, <em>318</em>, 113554. (<a href='https://doi.org/10.1016/j.knosys.2025.113554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polarization image fusion is a crucial area within image fusion, focusing on combining information from various polarization states to enhance image details, contrast, and other features. However, some existing algorithms often fail to fully exploit the information from different polarization angles, making it challenging to comprehensively and accurately extract key polarization features. This limitation hinders the ability of these algorithms to capture and exploit complementary information between the source images. To address these challenges, we propose a novel fusion method based on a hierarchical progressive polarization image fusion network guided by significant polarization information. First, we introduce a method for extracting significant polarization information to identify polarization features that complement the intensity image. This extracted information is then incorporated into the loss function to better constrain the network, ensuring that it captures complementary features from the source images effectively. In terms of fusion strategy, a hierarchical progressive fusion approach is introduced to better integrate the features of both images. The first layer uses differential attention to ensure the effective extraction and fusion of salient features. The second layer employs the cross-progressive fusion method to gradually integrate the complementary information from the source images, preserving global features while enhancing local details, thereby balancing both global and local information. Experimental results demonstrate that the proposed method achieves superior fusion performance across multiple datasets. Additionally, the method exhibits fewer network parameters and lower computational complexity, ensuring high operational efficiency while maintaining excellent performance.},
  archive      = {J_KBS},
  author       = {Mengxin Gong and Jie Li and Mengqian Chen and Chipeng Cao and Runrun Zou},
  doi          = {10.1016/j.knosys.2025.113554},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113554},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical progressive network for polarized image fusion based on significant polarization information},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal meso-granularity selection for classification based on bayesian optimization. <em>KBS</em>, <em>318</em>, 113552. (<a href='https://doi.org/10.1016/j.knosys.2025.113552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-granularity formal concept analysis is a research field that integrates granular computing and formal concept analysis. It provides valuable opportunities to analyze problems at multiple levels of granularity, which has been becoming a key tool for data mining and knowledge discovery. In multi-granularity formal concept analysis, it is an important challenge to select the optimal granularity. Existing methods for optimal granularity selection typically focus on a single granularity of attributes, without considering meso-granularity layers or the combination of different attribute granularities. Furthermore, these methods fail to reduce redundant attributes effectively. This paper aims to solve this issue and further improve the performance of classification. Specifically, we first introduce the meso-granularity class-attribute blocks to address these limitations. Then, we introduce information gain and design an optimal meso-granularity selection algorithm by combining meso-granularity class-attribute blocks with decision information. Furthermore, we propose the concept of core attributes and define their internal and external significance, which is beneficial for attribute reduction. Finally, the optimal meso-granularity combination is selected by using Bayesian optimization, which improves the efficiency of the meso-granularity combination for classification. The effectiveness of the proposed model is validated through experiments on real-world datasets. The experimental results demonstrate that the proposed model outperforms existing methods, achieving the best classification performance among the compared methods. All codes have been released at https://github.com/yqlinux/OMSFC .},
  archive      = {J_KBS},
  author       = {Qiangqiang Chen and Mengyu Yan and Jinhai Li and Xizhao Wang},
  doi          = {10.1016/j.knosys.2025.113552},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113552},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimal meso-granularity selection for classification based on bayesian optimization},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action-prompt: A unified visual prompt and fusion network for enhanced video action recognition. <em>KBS</em>, <em>318</em>, 113547. (<a href='https://doi.org/10.1016/j.knosys.2025.113547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition is a crucial task in video understanding and has garnered significant attention from researchers. However, while most existing methods exploit spatiotemporal and motion features for action recognition, these methods fail to consider that the fusion of different features cannot fully adapt to this task. To address this issue, we designed a prompt block named the Prompt Learning Layer (PLL), which is a plug-and-play module that can be inserted into a backbone to learn visual prompts for action recognition tasks. Additionally, we propose the Spatio-Temporal and Motion Fusion Module (STMF), which utilizes innovative extraction and fusion strategies to enhance the complementarity between the different features. The STMF comprises two main modules: the Bidirectional Motion Difference Module (BiMDM), which deals with bidirectional motion features, and the Spatio-Temporal Adaptive Module (STAM), which deals with spatio-temporal features in an adaptive approach. Finally, the experimental results demonstrate that our proposed method outperforms the state-of-the-art performance on the Kinetics-400, Something–Something V1 and V2 datasets.},
  archive      = {J_KBS},
  author       = {Linxi Li and Mingwei Tang and Shiqi Qing and Yanxi Zheng and Jie Hu and Mingfeng Zhao and Si Chen},
  doi          = {10.1016/j.knosys.2025.113547},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113547},
  shortjournal = {Knowl. Based Syst.},
  title        = {Action-prompt: A unified visual prompt and fusion network for enhanced video action recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-water-modelling (Meta-WaM): A new framework for increasing applicability of digital water modelling. <em>KBS</em>, <em>318</em>, 113543. (<a href='https://doi.org/10.1016/j.knosys.2025.113543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water Modelling (WaM) faces numerous challenges to increase its social usefulness. To boost its applicability, a broader and more robust methodological framework fis needed to face the most important WaM challenges. This research aims to provide a broad and stochastic framework, called Meta-Water-Modelling (Meta-WaM), through a surrogate model approach based on the main WaM challenges. Conceptually, this is performed through a compartmental modelling type. The Meta-WaM potential is highlighted through a detailed development of the challenge modelling “Uncertainty through a Predictive development from the Stochastic Hydrology, UPSH”; one of the seven challenges that Meta-WaM addresses. An exhaustive analytical framework on the key factors of Uncertainty, Variability and Randomness was developed. Regarding numerical results, on one hand, when a model data contains maximum uncertainty, it is recommended its analysis with 100 % chance through a causal approach (Causality). This provides an average degree of uncertainty incorporation (quality) of 36.88 %. Data set with high variability should be appropriately modelled through Multivariate approach (100 % chance), with a quality of 36.15 %. In the case of samples for modelling with high randomness, the results are not as definitive. Here the highest percentage of recommendation is in favour of the non-parametric approaches (57.14 %), with a quality of 42.03 %, in line with the data characteristics. UPSH module has been able to highlight that the randomness parameter is a crucial issue to improve hydrological behaviour. Ultimately, Meta-WaM aims to become a comprehensive stochastic decision support system to improve the applicability of water modelling developments.},
  archive      = {J_KBS},
  author       = {José-Luis Molina and Santiago Zazo and Fernando Espejo},
  doi          = {10.1016/j.knosys.2025.113543},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113543},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta-water-modelling (Meta-WaM): A new framework for increasing applicability of digital water modelling},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MESN: A multimodal knowledge graph embedding framework with expert fusion and relational attention. <em>KBS</em>, <em>318</em>, 113541. (<a href='https://doi.org/10.1016/j.knosys.2025.113541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is essential for knowledge graph completion and downstream applications. However, in multimodal knowledge graphs, this task is particularly challenging due to incomplete and noisy multimodal data, which often fails to capture semantic relationships between entities. While existing methods attempt to integrate multimodal features, they frequently overlook relational semantics and cross-modal dependencies, leading to suboptimal entity representations. To address these limitations, we propose MESN, a novel multimodal embedding framework that integrates relational and multimodal signals through semantic aggregation and neighbor-aware attention mechanisms. MESN selectively extracts informative multimodal features via adaptive attention and expert-driven learning, ensuring more expressive entity embeddings. Additionally, we introduce an enhanced ComplEx-based scoring function, which effectively combines structured graph interactions with multimodal information, capturing both relational and feature diversity. Extensive experiments on standard multimodal datasets confirm that MESN significantly outperforms baselines across multiple evaluation metrics. Our findings highlight the importance of relational guidance in multimodal embedding tasks, paving the way for more robust and semantically-aware knowledge representations.},
  archive      = {J_KBS},
  author       = {Ban Tran and Thanh Le},
  doi          = {10.1016/j.knosys.2025.113541},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113541},
  shortjournal = {Knowl. Based Syst.},
  title        = {MESN: A multimodal knowledge graph embedding framework with expert fusion and relational attention},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “CoreNet: Leveraging context-aware representations via MLP networks for CTR prediction” [Knowledge-based systems volume 312 (15 march 2025) start page 9th/10th – End page 9th/10th / article 113154]. <em>KBS</em>, <em>318</em>, 113540. (<a href='https://doi.org/10.1016/j.knosys.2025.113540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_KBS},
  author       = {Khoi N.P. Dang and Thu Thuy Tran and Ta Cong Son and Tran Tien Anh and Duc Anh Nguyen and Nguyen Van Son},
  doi          = {10.1016/j.knosys.2025.113540},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113540},
  shortjournal = {Knowl. Based Syst.},
  title        = {Corrigendum to “CoreNet: Leveraging context-aware representations via MLP networks for CTR prediction” [Knowledge-based systems volume 312 (15 march 2025) start page 9th/10th – End page 9th/10th / article 113154]},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dp-M3D: Monocular 3D object detection algorithm with depth perception capability. <em>KBS</em>, <em>318</em>, 113539. (<a href='https://doi.org/10.1016/j.knosys.2025.113539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the limitations of monocular 3D object detection in depth information and perception ability, we introduce a novel monocular 3D object detection algorithm, Dp-M3D, equipped with depth perception capabilities. To effectively model long-range feature dependencies during the fusion of depth maps and image features, we introduce a Transformer Feature Fusion Encoder (TFFEn). TFFEn integrates depth and image features, enabling more comprehensive long-range feature modeling. This enhances depth perception, ultimately improving the accuracy of 3D object detection. To enhance the detection ability of truncated objects at the edges of an image, we propose a Feature Enhancement method based on Deformable Convolution (FEDC). FEDC leverages depth confidence guidance to determine the deformation offset of the 3D bounding box, aligning features more effectively and improving depth perception. Furthermore, to address the issue of anchor box ranking, where candidate boxes with accurate depth predictions but low classification confidence are suppressed, we propose a Depth-perception Non-Maximum Suppression (Dp-NMS) algorithm. Dp-NMS refines the selection process by incorporating the product of classification confidence and depth confidence, ensuring that candidate boxes are ranked effectively and the most suitable detection box is retained. Experimental results on the challenging KITTI 3D object detection dataset demonstrate that the proposed method achieves A P 3 D scores of 23.41 %, 13.65 %, and 12.91 % in the easy, moderate, and hard categories, respectively. Our approach outperforms state-of-the-art monocular 3D object detection algorithms based on image and image-depth map fusion, with particularly significant improvements in detecting edge-truncated objects.},
  archive      = {J_KBS},
  author       = {Peicheng Shi and Xinlong Dong and Runshuai Ge and Zhiqiang Liu and Aixi Yang},
  doi          = {10.1016/j.knosys.2025.113539},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113539},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dp-M3D: Monocular 3D object detection algorithm with depth perception capability},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abnormal-region-aware multi-modal feature fusion for medical report generation. <em>KBS</em>, <em>318</em>, 113538. (<a href='https://doi.org/10.1016/j.knosys.2025.113538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated report generation alleviates the burden on doctors by providing assistance in writing reports. To make the produced reports more accurate and professional, previous studies have incorporated memory-driven network and cross-modal feature alignment into the model training process. However, the reports generated by the methods employed in these studies still fall short in providing comprehensive description of abnormal regions. Moreover, despite consciously mining the knowledge embedded in the text, high-level semantic knowledge is neglected by them. Therefore, we proposed a Multi-modal Feature Fusion (MFF) model integrated with Abnormal Region Awareness (ARA) to alleviate the issues above. Firstly, the MFF extracts knowledge in reports from both word and sentence levels, memorizes it, and injects it into visual features. Secondly, the ARA constructs class activation maps from input images and uses them as weights to obtain specific discriminant regions and make the unimportant regions attended less but reserved. An attention module is then used to ensure that the model notices these regions when generating reports. Comprehensive experiments on two public radiology datasets prove the efficacy of our proposed method.},
  archive      = {J_KBS},
  author       = {Yan Gao and Zhiwei Ni and Wentao Liu and Liping Ni and Ling Xin and Linbo Hu and Li Zhang},
  doi          = {10.1016/j.knosys.2025.113538},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113538},
  shortjournal = {Knowl. Based Syst.},
  title        = {Abnormal-region-aware multi-modal feature fusion for medical report generation},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSNet: Predicting drug-side effect frequencies via dual-graph ensemble and similarity learning. <em>KBS</em>, <em>318</em>, 113537. (<a href='https://doi.org/10.1016/j.knosys.2025.113537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug safety remains a critical concern in healthcare, making the accurate prediction of drug-side effect frequencies essential for risk-benefit assessments. Recent advancements in graph neural network-based methods for predicting drug-side effect frequencies have shown significant promise. However, the inherent complexity of drug molecular structures, often characterized by multi-ring and long-chain substructures, poses a challenge. Mainstream graph-based approaches are limited in expressive power and suffer from low information transmission efficiency, which hampers the ability to capture deep structural features. Additionally, the sparsity of drug-side effect interaction networks restricts the effective utilization of similarity information between drugs and side effects, substantially degrading prediction quality. To address these challenges, we propose a novel framework for predicting drug-side effect frequencies, termed DSNet. By integrating multi-source heterogeneous features to construct embedding representations, and designing a Dual-Graph Ensemble Network with residual connections, DSNet enhances the capture of local, subtle features of drug molecules while preserving global structural consistency. To mitigate the sparsity limitations of drug-side effect interaction networks, we introduce a Structural Consistency Preservation Loss, which ensures that critical information is retained in the low-dimensional space. Additionally, we propose a Temperature-Adaptive Similarity Loss to dynamically adjust the sharpness of the similarity distribution between drugs and side effects. Experimental results on the SIDER dataset demonstrate that DSNet significantly improves prediction performance in both warm-start and cold-start scenarios. Furthermore, molecular docking experiments targeting tigecycline further validate the effectiveness of DSNet in predicting drug-side effect frequencies.},
  archive      = {J_KBS},
  author       = {Qiuyu Long and Nan Zhao and Haifeng Liu},
  doi          = {10.1016/j.knosys.2025.113537},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113537},
  shortjournal = {Knowl. Based Syst.},
  title        = {DSNet: Predicting drug-side effect frequencies via dual-graph ensemble and similarity learning},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven prototype refinement for few-shot fine-grained recognition. <em>KBS</em>, <em>318</em>, 113535. (<a href='https://doi.org/10.1016/j.knosys.2025.113535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in deep learning have made image classification rival human performance with sufficient data and supervision. However, in domains with limited visual samples and high labeling costs, enabling AI systems to learn efficiently from few examples is challenging. This challenge is compounded in fine-grained categories, where subtle differences and scarce samples hinder robust representation extraction. To address this, we propose the Knowledge-Driven Prototype Refinement (KDPR) framework, which enhances few-shot fine-grained recognition by integrating prior knowledge from text. KDPR simulates human focus on discriminative foreground regions to extract refined views, forming a dual-branch learning framework alongside original images. It also constructs an unsupervised adjacency graph among visual instances and uses graph neural networks to improve category representation robustness. Additionally, a knowledge transfer-based image recognizer integrates prior text embeddings with global semantics directly into visual recognition, providing extra semantic guidance. To optimize knowledge-to-vision mapping, an auxiliary spatial prototype calibration aligns prototype representations across multiple spaces. Extensive experiments on three fine-grained datasets and two popular backbones demonstrate the effectiveness and state-of-the-art performance of our approach, especially in 1-shot learning. The source code is available at: https://github.com/HHU-JialeChen/KDPRNet .},
  archive      = {J_KBS},
  author       = {Jiale Chen and Feng Xu and Xin Lyu and Tao Zeng and Xin Li and Shangjing Chen},
  doi          = {10.1016/j.knosys.2025.113535},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-driven prototype refinement for few-shot fine-grained recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal distributed subsampling for expected shortfall regression via neyman-orthogonal score. <em>KBS</em>, <em>318</em>, 113529. (<a href='https://doi.org/10.1016/j.knosys.2025.113529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive data bring a big challenge for analysis, and subsampling as an effective solution can significantly reduce the computational burden and maintain estimation efficiency. Expected Shortfall Regression (ESR) studies the impact of covariates on the tail expectation of response and explores the heterogeneous effects of the covariates. For joint linear quantile and expected shortfall regression models, we study the optimal subsampling method for ESR based on the Neyman-orthogonal score to reduce sensitivity with respect to nuisance parameters in quantile regression. When the massive data are stored in different sites, we further propose a distributed optimal subsampling method for the ESR. Asymptotic properties of the resultant estimators are established and the two-step algorithms are proposed for practical implementation. Extensive simulations and applications to Protein Tertiary Structure and Beijing Air Quality datasets show satisfactory performance of the proposed estimators.},
  archive      = {J_KBS},
  author       = {Xing Li and Lei Wang and Heng Lian},
  doi          = {10.1016/j.knosys.2025.113529},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113529},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimal distributed subsampling for expected shortfall regression via neyman-orthogonal score},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient grid-based path planning approach using improved artificial bee colony algorithm. <em>KBS</em>, <em>318</em>, 113528. (<a href='https://doi.org/10.1016/j.knosys.2025.113528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grid-based path planning with large solution spaces, is considered computationally hard because of the computational time required to examine all possible paths. Many algorithms have been developed to solve this problem, one of which is the artificial bee colony (ABC) algorithm, known for its strong search capabilities. In this paper, an improved artificial bee colony algorithm (IABC), designed to achieve a balance between exploitation and exploration by integrating two mechanisms, is proposed. First, a path linearization strategy that eliminates unnecessary corners in the planned path within the grid environment is integrated. Second, a local search strategy is employed to enhance the convergence speed of ABC and improve its ability to find the global optimum solution. To evaluate the performance of IABC, it is first compared with the basic ABC in environments of the same size and demonstrates improvements in the range of 7%–14% in terms of path length. Secondly, the contributions of the two improvement strategies are analyzed through ablation studies. Thirdly, IABC is tested for scalability by running it in environments of varying sizes, achieving improvements in the range of 19%–20%. Fourthly, IABC is compared with the advanced ABC variants, achieving improvements in the range of 2%–32%. Fifthly, IABC is compared with the well-known and recent advanced algorithms, achieving improvements starting from 2%. Finally, IABC is evaluated against the results from recent studies in the literature, showing improvements of up to 37%. These results demonstrate that IABC is an effective method for solving grid-based path planning problems.},
  archive      = {J_KBS},
  author       = {Mustafa Yusuf Yildirim and Rustu Akay},
  doi          = {10.1016/j.knosys.2025.113528},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113528},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient grid-based path planning approach using improved artificial bee colony algorithm},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional robustness analysis for optimizing complex systems. <em>KBS</em>, <em>318</em>, 113527. (<a href='https://doi.org/10.1016/j.knosys.2025.113527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes the development of a metric for the analysis of operational robustness in systems, focusing on performance, complexity, and stability as key components. The methodology integrates these factors, enabling the assessment of the system’s ability to meet its design requirements, its internal dynamics and external interactions, and its capacity to return to equilibrium after disturbances. The metric is applied in three case studies: an intensive care unit, process scheduling in operating systems, and traction and braking in electric vehicles. The results show that, in scenarios with higher robustness, the contributions of performance, complexity and stability are balanced, with performance contributing around 30% and complexity and stability each contributing approximately 35%. In contrast, scenarios with lower robustness exhibit greater variation in the contributions of these components. These findings suggest that the proposed metric is an efficient tool for both quantitative and qualitative analyses, providing more detailed perspectives for decision making in complex systems.},
  archive      = {J_KBS},
  author       = {João Ricardo B. Paiva and Viviane M. Gomes Pacheco and Júnio Santos Bulhões and Clóves Gonçalves Rodrigues and António Paulo Coimbra and Wesley Pacheco Calixto},
  doi          = {10.1016/j.knosys.2025.113527},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113527},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multidimensional robustness analysis for optimizing complex systems},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency and inconsistency guided multi-view subspace clustering based on low-rank tensor and comprehensive similarity. <em>KBS</em>, <em>318</em>, 113523. (<a href='https://doi.org/10.1016/j.knosys.2025.113523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering methods have gained significant attention in recent years owing to their ability to explore the data’s low-dimensional subspace structure. Most existing subspace clustering methods focus on learning consensus and specific representations under the self-representation principle, but there are still two shortcomings. First, subspace clustering methods usually neglect preserving the local structure of the data. While a few methods notice this, they construct predefined similarity graphs by measuring the Euclidean distance of sample pairs, which cannot sufficiently capture the local structure of the data information. Secondly, some methods ignore the high-order information between views. This study proposes a multi-view clustering method called consistency and inconsistency-guided multi-view subspace clustering based on low-rank tensor and comprehensive similarity (CIMSC-LTCS) to overcome these shortcomings. In particular, we decompose the self-representation matrix of each view into the consistent part and the inconsistent part to explicitly capture cross-view consistency and inconsistency. Further, the high-order information between views of the consistent representation is explored by low-rank tensor learning. Moreover, the optimal comprehensive consensus similarity graph is adaptively learned by simultaneously considering the direct similarity relation and latent similarity relation between sample pairs, and the comprehensive consensus similarity graph is used to guide the learning of the consistent representation matrices to preserve the local structure of the data better. The method integrates consistency and inconsistency decomposition, comprehensive similarity learning, and low-rank representation tensor learning into one framework. Finally, extensive experiments are conducted on fifteen benchmark multi-view datasets, which demonstrate the superiority of the proposed method.},
  archive      = {J_KBS},
  author       = {Yutong Yan and Hongmei Chen and Tengyu Yin and Yong Mi and Shi-Jinn Horng and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.113523},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113523},
  shortjournal = {Knowl. Based Syst.},
  title        = {Consistency and inconsistency guided multi-view subspace clustering based on low-rank tensor and comprehensive similarity},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-aware prototype augmentation and dual-level knowledge distillation for non-exemplar class-incremental hashing. <em>KBS</em>, <em>318</em>, 113520. (<a href='https://doi.org/10.1016/j.knosys.2025.113520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing methods are extensively applied in image retrieval for their efficiency and low storage demands. Recently, deep incremental hashing methods have addressed the challenge of adapting to new classes in non-stationary environments, while ensuring compatibility with existing classes. However, most of these methods require old-class samples for joint training to resist catastrophic forgetting, which is not always feasible due to privacy concerns. This constraint underscores the need for Non-Exemplar Class-Incremental Hashing (NECIH) approaches, designed to retain knowledge without storing old-class samples. In NECIH methodologies, hash prototypes are commonly employed to maintain the discriminability of hash codes. However, these prototypes often fail to represent old-class distribution accurately, causing confusion between old and new classes. Furthermore, traditional instance-level knowledge distillation techniques are insufficient for efficiently transferring the structural information inherent in the feature space. To tackle these challenges, we introduce a novel deep incremental hashing approach called Boundary-aware P rototype A ugmentation and Dual-level Knowledge D istillation for NEC IH (PADIH). PADIH comprises three key components: the Prototype-based Code Learning (PCL) module, the Boundary-aware Prototype Augmentation (BPA) module, and the Dual-level Knowledge Distillation (DKD) module. Specifically, the PCL module learns discriminative hash codes for new classes, while the BPA module augments the old-class prototypes into pseudo codes, with an emphasis on the distribution boundaries. Moreover, the DKD module integrates both instance-level and relation-level knowledge distillation to facilitate the transfer of comprehensive information between models. Extensive experiments conducted on four benchmarks across twelve incremental learning situations demonstrate the superior performance of PADIH.},
  archive      = {J_KBS},
  author       = {Qinghang Su and Dayan Wu and Bo Li},
  doi          = {10.1016/j.knosys.2025.113520},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113520},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boundary-aware prototype augmentation and dual-level knowledge distillation for non-exemplar class-incremental hashing},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt-matching synthesis model for missing modalities in sentiment analysis. <em>KBS</em>, <em>318</em>, 113519. (<a href='https://doi.org/10.1016/j.knosys.2025.113519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal sentiment analysis, commentary videos often lack certain sentences or frames, leaving gaps that may contain crucial sentiment cues. Current methods primarily focus on modal fusion, overlooking the uncertainty of missing modalities, which results in underutilized data and less complete and less accurate sentiment analysis. To address these challenges, we propose a prompt-matching synthesis model to handle missing modalities in sentiment analysis. First, we develop unimodal encoders using prompt learning to enhance the model’s understanding of inter-modal relationships during feature extraction. Learnable prompts are introduced before textual modalities, while cross-modal prompts are applied to acoustic and visual modalities. Second, we implement bidirectional cross-modal matching to minimize discrepancies among shared features, employing central moment discrepancy loss across multiple modalities. A comparator is designed to infer features based on the absence of one or two modalities, allowing for the synthesis of missing modality features from available data. Finally, the synthesized modal features are integrated with the initial features, optimizing the fusion loss and central moment discrepancy loss to enhance sentiment analysis accuracy. Experimental results demonstrate that our method achieves strong performance on multiple datasets for multimodal sentiment analysis, even with uncertain missing modalities.},
  archive      = {J_KBS},
  author       = {Jiaqi Liu and Yong Wang and Jing Yang and Fanshu Shang and Fan He},
  doi          = {10.1016/j.knosys.2025.113519},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113519},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prompt-matching synthesis model for missing modalities in sentiment analysis},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deepnet-based surgical tools detection in laparoscopic videos. <em>KBS</em>, <em>318</em>, 113517. (<a href='https://doi.org/10.1016/j.knosys.2025.113517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has revolutionized significant advances in image classification, especially in Medical image (MI) processing. Surgical Data Science (SDS) has been developed as a scientific research field that aims to improve the health status of patients. Laparoscopic videos possess a highly significant information source that is integrally present in minimally invasive surgeries. Recognizing surgical tools based on the videos has promoted greater interest because of their significance. In most existing research, single-tool detection is carried out, but multiple-tool recognition is not concentrated well. However, multiple-tool recognition poses numerous challenges, including diverse lighting conditions, the appearance of multiple instruments in different representations, tissue blood, etc. Also, the detection speed of learning methodology is very low because of inherent complexities and improper handling of huge amounts of data. The proposed research introduces a novel DeepNet-Tool for automatic multi-tool classification in laparoscopy videos to address these existing challenges. This paper focuses on solving the spatial-temporal issues in detecting Surgical Tools (STs). The proposed model is implemented in Python, and the overall accuracy is 97.36 % with the Cholec80 dataset, 98.67 % with the EndoVis dataset, 99.73 % on EndoVis and 98.67 % on LapGyn4, respectively. Experimental outcomes of the proposed DeepNet-Tool showed higher effectiveness compared with other deep learning methods on the ST classification task. Thus, the proposed model has revealed the potential for clinical use in accurate ST classification.},
  archive      = {J_KBS},
  author       = {Praveen SR Konduri and G Siva Nageswara Rao},
  doi          = {10.1016/j.knosys.2025.113517},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113517},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deepnet-based surgical tools detection in laparoscopic videos},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient salient object detection via U-shape architecture search. <em>KBS</em>, <em>318</em>, 113515. (<a href='https://doi.org/10.1016/j.knosys.2025.113515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art (SOTA) deep learning architectures for salient object detection (SOD) are predominantly handcrafted, with many methods adapting successful classification backbones for SOD tasks. In this work, we aim to design more efficient architectures specifically tailored for SOD, accommodating both RGB and RGB-D input modalities. Leveraging neural architecture search (NAS), we uncover unique characteristics of SOD by proposing a novel U-shaped search space. This design integrates bottom-up and top-down pathways, enhanced by interconnecting links between them. To further optimize the complexity distribution across these pathways, we introduce a per-complexity importance measure. The resulting architectures, NASAL and NASAL-D (targeting RGB and RGB-D SOD, respectively), achieve an improved trade-off between accuracy and computational efficiency. Extensive experiments on multiple popular benchmarks demonstrate that our models consistently outperform existing methods in both effectiveness and efficiency.},
  archive      = {J_KBS},
  author       = {Zhi-Ang Liu and Jiang-Jiang Liu},
  doi          = {10.1016/j.knosys.2025.113515},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113515},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards efficient salient object detection via U-shape architecture search},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge and semantic collaboration framework with cross coordination attention for co-saliency detection. <em>KBS</em>, <em>318</em>, 113513. (<a href='https://doi.org/10.1016/j.knosys.2025.113513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract—Co-salient object detection (CoSOD) aims to identify salient objects that appear concurrently in a set of related images. The existing CoSOD methods emphasize mining consensus clues, while tend to overlook the implicit edge and semantic information expressed at various levels of image features. To address this limitation, we propose a novel edge and semantic collaboration framework (ESCF). ESCF employs high-level features to align semantic information from highly activated salient regions, while utilizing low-level features to refine edge contours for improved clarity. To eliminate distracting elements within images, we introduce a cross coordination attention module (CCAM) that calibrates channel weights in each parallel branch using global information. By leveraging interactive learning across various feature layers, the model improves its capacity to capture position sensitive details, effectively minimizing noise in the process. Furthermore, we design a consensus learning module (CLM) that focuses on spatial and channel information across multi-scale features in parallel, allowing it to extract consensus clues from the generated multivariate attention maps, which in turn helps the network infer co-salient targets and ultimately guide it towards accurate predictions. We evaluate our method on three challenging CoSOD benchmark datasets using four widely recognized metrics, and experimental results demonstrate that our approach outperforms existing CoSOD methods.},
  archive      = {J_KBS},
  author       = {Qiaohong Chen and Qihang Wang and Xian Fang and Qi Sun and Jinchao Zhu},
  doi          = {10.1016/j.knosys.2025.113513},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113513},
  shortjournal = {Knowl. Based Syst.},
  title        = {Edge and semantic collaboration framework with cross coordination attention for co-saliency detection},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confidence-enhanced dual-space semantic alignment for partial multi-view incomplete multi-label classification. <em>KBS</em>, <em>318</em>, 113507. (<a href='https://doi.org/10.1016/j.knosys.2025.113507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Multi-Label Classification (MvMLC), a combination of multi-view learning and multi-label classification, has garnered significant research interest for its ability to leverage multiple perspectives in assigning multiple labels to samples. However, MvMLC frequently encounters challenges in real-world scenarios where missing views and labels arise from incomplete data collection, sensor failures, or costly and time-consuming manual annotations. Although existing methods have attempted to tackle these problems, they often fall short in addressing the challenge of semantic informativeness discrepancies among views, primarily due to the varying reliability and importance of the information provided by different views. To conquer these challenges, we propose a C onfidence-Enhanced D ual-Space S emantic A lignment (CDSA) framework. Different from previous works that rely on static contribution allocations for view embedding, we introduce a dynamic confidence-weighting (DCW) mechanism that quantifies each view’s reliability relative to the downstream task through task-specific confidence estimation to balance the differences in information quality among views. Moreover, to further address semantic discrepancies across views, we present the label-informed semantic alignment (LSA) method, which minimizes the inconsistencies between the semantic structure across samples and their inherent structure, achieving the coherence of semantic structure and reducing misalignment issues. Finally, we designed a dual-space (the original space and the confidence-mapped space) strategy. This strategy effectively integrates DCW and LSA by enabling LSA to operate efficiently in both spaces, contributing to more reliable model performance, even with incomplete or low-quality data. Extensive experiments on five benchmark datasets show that CDSA outperforms many leading methods on incomplete data.},
  archive      = {J_KBS},
  author       = {Jiarui Chen and Wulin Xie and Mengqing Wang and Yinghao Ye and Xiaohuan Lu},
  doi          = {10.1016/j.knosys.2025.113507},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Confidence-enhanced dual-space semantic alignment for partial multi-view incomplete multi-label classification},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepIFSAC: Deep imputation of missing values using feature and sample attention within contrastive framework. <em>KBS</em>, <em>318</em>, 113506. (<a href='https://doi.org/10.1016/j.knosys.2025.113506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values of varying patterns and rates in real-world tabular data pose a significant challenge in developing reliable data-driven models. The most commonly used statistical and machine learning methods for missing value imputation may be ineffective when the missing rate is high and not random. This paper explores row and column attention in tabular data as between-feature and between-sample attention in a novel framework to reconstruct missing values. The proposed method uses CutMix data augmentation within a contrastive learning framework to improve the uncertainty of missing value estimation. The performance and generalizability of trained imputation models are evaluated in set-aside test data folds with missing values. The proposed framework is compared with 11 state-of-the-art statistical, machine learning, and deep imputation methods using 12 diverse tabular data sets. The average performance rank of our proposed method demonstrates its superiority over the state-of-the-art methods for missing rates between 10% and 90% and three missing value types, especially when the missing values are not random. The quality of the imputed data using our proposed method is compared in a downstream patient classification task using real-world electronic health records. This paper highlights the heterogeneity of tabular data sets to recommend imputation methods based on missing value types and data characteristics.},
  archive      = {J_KBS},
  author       = {Ibna Kowsar and Shourav B. Rabbani and Yina Hou and Manar D. Samad},
  doi          = {10.1016/j.knosys.2025.113506},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113506},
  shortjournal = {Knowl. Based Syst.},
  title        = {DeepIFSAC: Deep imputation of missing values using feature and sample attention within contrastive framework},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on integrating large language models with knowledge-based methods. <em>KBS</em>, <em>318</em>, 113503. (<a href='https://doi.org/10.1016/j.knosys.2025.113503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of artificial intelligence has led to marked progress in the field. One interesting direction for research is whether Large Language Models (LLMs) can be integrated with structured knowledge-based systems. This approach aims to combine the generative language understanding of LLMs and the precise knowledge representation systems by which they are integrated. This article surveys the relationship between LLMs and knowledge bases, looks at how they can be applied in practice, and discusses related technical, operational, and ethical challenges. Utilizing a comprehensive examination of the literature, the study both identifies important issues and assesses existing solutions. It demonstrates the merits of incorporating generative AI into structured knowledge-base systems concerning data contextualization, model accuracy, and utilization of knowledge resources. The findings give a full list of the current situation of research, point out the main gaps, and propose helpful paths to take. These insights contribute to advancing AI technologies and support their practical deployment across various sectors.},
  archive      = {J_KBS},
  author       = {Wenli Yang and Lilian Some and Michael Bain and Byeong Kang},
  doi          = {10.1016/j.knosys.2025.113503},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113503},
  shortjournal = {Knowl. Based Syst.},
  title        = {A comprehensive survey on integrating large language models with knowledge-based methods},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). @LM DeceptionNet: A multimodal approach for efficient transfer learning-based deception detection. <em>KBS</em>, <em>318</em>, 113499. (<a href='https://doi.org/10.1016/j.knosys.2025.113499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In terms of deception detection, traditional contact-based techniques often require collecting physiological signals, which can negatively impact device accuracy and participant comfort. While multimodal features extracted from audio and video modalities have been shown to outperform human observers on public datasets, the generalizability of existing audio and visual-based deception detection methods in different scenarios remains insufficiently explored. To narrow this gap, this work proposes a novel domain knowledge transfer learning method for deception detection in cross-scenario applications, which enhances its generalization and adaptability. Additionally, we designed a multimodal framework that filters out irrelevant information from other modalities when a particular modality yields reliable results, further improving overall system accuracy and robustness. We evaluate the proposed method on different public datasets, achieving promising generalizability results with consistent enhancements using four variations and networks. Apart from this, the proposed @LM DeceptionNet demonstrates better generalization capacity in computational efficiency, feature extraction, and adaptability compared to a larger model when employing fewer parameters.},
  archive      = {J_KBS},
  author       = {Yuanya Zhuo and Vishnu Monn Baskaran and Lillian Yee-Kiaw Wang and Raphaël C.-W. Phan},
  doi          = {10.1016/j.knosys.2025.113499},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113499},
  shortjournal = {Knowl. Based Syst.},
  title        = {@LM DeceptionNet: A multimodal approach for efficient transfer learning-based deception detection},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph-guided network with adaptive evaluation and improvement for disturbed sensors in fault-tolerant soft sensor modeling. <em>KBS</em>, <em>318</em>, 113497. (<a href='https://doi.org/10.1016/j.knosys.2025.113497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in harsh environments, sensors frequently encounter disturbances, causing prevalent deviations and drift in measured values from true values. The disturbed measurement brings extra difficulty for soft sensing, since the performance of most existing methods depends heavily on the assumption that the data is accurate and disturbance-free. Considering the above difficulty, this paper proposes a graph-guided network with adaptive evaluation and improvement (GAEI) to achieve fault-tolerant soft sensor modeling. First, an adaptive evaluation strategy is proposed to calculate sensor reliability, which is developed from two aspects. For instantaneous noise, a pointwise analysis considering the intra-variable temporal dependencies is performed. For continuous drift, the graph structure comparison that reflects the inter-variable dependencies is established, which can deal with additive deviation, static multiplicative deviation, and time-varying multiplicative deviation. Second, a specific message passing operator is designed within a graph neural network. It aims to effectively exploit information from trusted variables, thereby improving the quality of various deviations. Finally, the evaluation and improvement have an end-to-end structure, providing an adaptive solution to reduce the influence of disturbances. The effectiveness of GAEI is sufficiently demonstrated in a real cement production process.},
  archive      = {J_KBS},
  author       = {Liyuan Kong and Chunjie Yang and Siwei Lou and Yaoyao Bao and Xiaoke Huang and Li Chai},
  doi          = {10.1016/j.knosys.2025.113497},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113497},
  shortjournal = {Knowl. Based Syst.},
  title        = {A graph-guided network with adaptive evaluation and improvement for disturbed sensors in fault-tolerant soft sensor modeling},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based predictable deep transfer network for soft sensing of dynamic industrial processes. <em>KBS</em>, <em>318</em>, 113495. (<a href='https://doi.org/10.1016/j.knosys.2025.113495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their advantages in high-level abstract feature extraction, stacked auto-encoders and their supervisory variants have been widely used to develop soft sensors for industrial processes. However, since they fail to provide analytical solutions for the autoregression embedded in networks, the difficulty in modeling the temporal correlation in latent features of supervisory stacked auto-encoders greatly increases. Moreover, the normal assumption for the design of soft sensors of an independent, identical distribution does not hold when there are changes in the training and testing data. Thus, a graph-based, predictable, deep transfer network (GPDTN) for soft sensing of dynamic industrial processes is proposed. To effectively learn the dynamic information of past data, a new loss function is proposed to reconstruct the data and simultaneously learn the predictable latent space using joint mutual information and graph embedding. Then, using deep domain adaptation, a new regular term of dynamic alignment is added to narrow the differences of the predictive information between source and target domains, enabling the graph-based predictable structure to be adaptable to concept drift in dynamic processes. Finally, the performance and effectiveness of the GPDTN-based soft sensors are demonstrated through experimental results on the industrial debutanizer and sulfur recovery unit.},
  archive      = {J_KBS},
  author       = {Zhengxuan Zhang and Xu Yang and Jian Huang and Yuri A.W. Shardt},
  doi          = {10.1016/j.knosys.2025.113495},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph-based predictable deep transfer network for soft sensing of dynamic industrial processes},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning via classifier similarity-based clustering and bi-level optimization. <em>KBS</em>, <em>318</em>, 113494. (<a href='https://doi.org/10.1016/j.knosys.2025.113494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has emerged as a promising strategy for addressing privacy concerns in today’s data silos. However, the performance of traditional FL may suffer from non-independent and identically distributed (Non-IID) conditions. To overcome this challenge, some recent works have explored personalized federated learning (PFL). However, they either consider a single global model for knowledge aggregation, which is a potential bottleneck to handle highly divergent scenarios, or formulate multiple global models, which requires considerable computational overhead. Some of them even have a risk of privacy leakage. In this paper, we propose a novel PFL algorithm named PFedCSCBO, which achieves Personalized Federated Learning via Classifier Similarity-based Clustering and Bi-Level Optimization. It exploits affinity propagation (AP) clustering algorithm based on local classifier similarity to transform the Non-IID condition into multiple IID problems, and employs bi-level optimization for personalization. Furthermore, we introduce an initialization for newcomers to enhance the practicality of PFedCSCBO. Experimental results on several real-world datasets with significant statistical divergence in both convex and non-convex cases show that, our proposed PFedCSCBO outperforms the state-of-the-art methods across various metrics.},
  archive      = {J_KBS},
  author       = {Weiwen Zhang and Yifeng Jiang and Ziyu Liu},
  doi          = {10.1016/j.knosys.2025.113494},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113494},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized federated learning via classifier similarity-based clustering and bi-level optimization},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free unsupervised domain adaptation through trust-guided partitioning and worst-case aligning. <em>KBS</em>, <em>318</em>, 113493. (<a href='https://doi.org/10.1016/j.knosys.2025.113493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In source-free unsupervised domain adaptation (SFUDA) tasks, adapting to the target domain without directly accessing the source domain data and relying solely on a pre-trained source domain model and the target domain data is a common challenge. Existing approaches often rely on pseudo-labeling techniques for intra-class clustering to achieve global alignment of classes. However, the presence of noise can lead to incorrect clustering results. In this paper, we introduce a novel approach referred to as Trust-guided Partitioning and Worst-case Aligning (TPWA). We assess the reliability of pseudo-labels by computing the similarity difference between the class centers corresponding to the pseudo-labels and the centers of the most similar classes. Based on this, we perform partitioning and then conduct intra-class clustering only on high-trustworthy samples. We also train a worst-case classifier to predict correctly on high-trustworthy samples and make as many mistakes as possible on low-trustworthy samples, and then adversarially trains feature extractors to align low-trustworthy samples to high-trustworthy samples. This approach leverages the structural information present in the high-trustworthy sample set, improving the robustness of the adaptation. Additionally, we also consider enforcing prediction consistency among neighboring samples to further constrain the pseudo-labels. Extensive experiments demonstrate the superiority of our method in SFUDA tasks.},
  archive      = {J_KBS},
  author       = {Qing Tian and Lulu Kang},
  doi          = {10.1016/j.knosys.2025.113493},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113493},
  shortjournal = {Knowl. Based Syst.},
  title        = {Source-free unsupervised domain adaptation through trust-guided partitioning and worst-case aligning},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a runtime-condition model for proactive intelligent products using knowledge graphs and embedding. <em>KBS</em>, <em>318</em>, 113484. (<a href='https://doi.org/10.1016/j.knosys.2025.113484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern manufacturing processes’ increasing complexity and variability demand advanced systems capable of real-time monitoring, adaptability, and data-driven decision-making. This paper introduces a novel runtime condition model to enhance interoperability, data integration, and decision support within intelligent manufacturing environments. The model encapsulates key manufacturing elements, including asset management, relationships, key performance indicators (KPIs), capabilities, data structures, constraints, and configurations. A key innovation is the integration of a knowledge graph enriched with embedding techniques, enabling the inference of missing relationships, dynamic reasoning, and predictive analytics. The proposed model was validated through a case study conducted in collaboration with TQC Automation Ltd., using their MicroApplication Leak Test System (MALT). A dataset of over 9,000 unique test configurations demonstrated the model’s capabilities in representing runtime conditions, managing operational parameters, and optimising test configurations. The enriched knowledge graph facilitated advanced analyses, providing actionable insights into test outcomes and enabling proactive decision-making. Empirical results showcase the model’s ability to harmonise diverse data sources, infer missing connections, and improve runtime adaptability. This study highlights the potential of combining runtime modelling with knowledge graphs to address the challenges of modern manufacturing. Future research will explore the model’s application to additional domains, integration with larger datasets, and the use of machine learning for enhanced predictive capabilities.},
  archive      = {J_KBS},
  author       = {Fan Mo and Hamood Ur Rehman and Miriam Ugarte and Angela Carrera-Rivera and Nathaly Rea Minango and Fabio Marco Monetti and Antonio Maffei and Jack C. Chaplin},
  doi          = {10.1016/j.knosys.2025.113484},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113484},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of a runtime-condition model for proactive intelligent products using knowledge graphs and embedding},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary bayesian optimization for automated circuit sizing. <em>KBS</em>, <em>318</em>, 113483. (<a href='https://doi.org/10.1016/j.knosys.2025.113483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated circuit sizing using Artificial Intelligence is a rapidly increasing area of interest, primarily thanks to its potential to accelerate product time-to-market and enhance employee satisfaction. A host of methods, rooted in different fundamental research philosophies, have been devised for this class of problems. While some of them perform well in terms of convergence speed, robustness has generally been given less attention. In this study we propose a novel automatic circuit sizing framework called Evolutionary Bayesian Optimization (EBO). It is a hybrid method combining the strengths of evolutionary computation techniques and Bayesian Optimization. EBO takes full advantage of parallel simulation infrastructure, by inherently using large batches of simulations. Our method is especially designed for multi-objective problems. Thus, it can optimize a large variety of circuits without the need of constructing figure of merit functions. Moreover, the strong emphasis on exploring the high-dimensional space of design variables ensures that EBO is robust and reliable across varying levels of problem complexity. We compare our framework with two state-of-the-art methods having different underlying philosophies and with arguably the most promising multi-objective evolutionary algorithm for this class of problems on four circuits: two proprietary voltage regulators, an open-source voltage regulator, and an open-source operational amplifier. The results show that EBO is superior to the other considered methods with regard to convergence speed and robustness. Generally, it can save between 30% and 70% circuit simulations compared to the next best performing method. Furthermore, EBO is the only method that finds circuit configurations that meet the specifications for all the considered circuits.},
  archive      = {J_KBS},
  author       = {Cătălin Vişan and Mihai Boldeanu and Georgian Nicolae and Horia Cucu and Corneliu Burileanu and Andi Buzo},
  doi          = {10.1016/j.knosys.2025.113483},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evolutionary bayesian optimization for automated circuit sizing},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CharFormer: Character-oriented attention network for string edit distance. <em>KBS</em>, <em>318</em>, 113482. (<a href='https://doi.org/10.1016/j.knosys.2025.113482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {String similarity computation plays a crucial role in numerous real-world applications, such as similarity search and sequence alignment. String Edit Distance (SED) is a representative similarity metric that effectively measures the similarity between strings. However, its quadratic complexity makes the computation of SED challenging, especially for large datasets. Consequently, in recent years, an increasing number of algorithms have adopted deep learning techniques to accelerate SED computation. However, we observe that existing methods often employ a bi-encoder framework to learn the features of individual strings, which leads to neglect of the matching information across strings. Moreover, these methods fail to fully leverage subsequence information and the sampling space. To this end, we propose a character-oriented attention network named CharFormer to learn the computation of SED. Specifically, CharFormer operates at the character granularity, leveraging both the intra-sequence information of individual input strings and the inter-sequence information between them to learn the representations of characters and strings. Subsequently, CharFormer uses two prediction heads to simultaneously utilize these two types of information to predict the similarity between strings. Additionally, we incorporate the similarity between substrings to provide extra supervision and design a novel sampling method to fully exploit the sampling space. Extensive experiments demonstrate the superiority of CharFormer over state-of-the-art algorithms and the efficacy of the proposed methods.},
  archive      = {J_KBS},
  author       = {Xijuan Liu and Haobo Wei and Peilun Yang and Haiyang Hu},
  doi          = {10.1016/j.knosys.2025.113482},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113482},
  shortjournal = {Knowl. Based Syst.},
  title        = {CharFormer: Character-oriented attention network for string edit distance},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diachronic semantic encoding based on pre-trained language model for temporal knowledge graph reasoning. <em>KBS</em>, <em>318</em>, 113479. (<a href='https://doi.org/10.1016/j.knosys.2025.113479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph Reasoning (TKGR) aims to infer missing facts at specific timestamps. However, most existing methods primarily focus on the local and global evolutionary characteristics of temporal knowledge graphs (TKG), often neglecting the inherent semantic information of historical facts. The oversight limits the understanding of the diachronic evolution of facts, thereby limiting the ability to predict future missing facts. To address these issues, we propose a TKGR model with D iachronic S emantic E ncoding based on a P re-trained language model, called DSEP . It uses a pre-trained language model (PLM) to learn the evolutionary characteristics of historical related facts of the entity or relation to be predicted, so as to enhance the understanding of historical facts by the graph encoder used to capture the local evolutionary characteristics of the temporal knowledge graph. Additionally, to further narrow the prediction scope, DSEP incorporates historical fact correlation matrix in its prediction results. Experimental results on four benchmark datasets demonstrate that DSEP significantly improves the performance of relation prediction in temporal knowledge graphs, with an average improvement of 20.9% in MRR 1 .},
  archive      = {J_KBS},
  author       = {Yunteng Deng and Jia Song and Zhongliang Yang and Yilin Long and Li Zeng and Linna Zhou},
  doi          = {10.1016/j.knosys.2025.113479},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113479},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diachronic semantic encoding based on pre-trained language model for temporal knowledge graph reasoning},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRADA: Prompt-guided representation alignment and dynamic adaption for time series forecasting. <em>KBS</em>, <em>318</em>, 113478. (<a href='https://doi.org/10.1016/j.knosys.2025.113478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting endeavors to construct models capable of predicting future values and trends grounded in historical observations. However, current LLM-based approaches migrate the inference power of LLM to the time series forecasting through prompt guidance, but ignore the modality gap between time series and natural language. This gap arises from the fact that time series have periodic and non-periodic patterns that are not present in natural language, hindering the capabilities of LLM-based models. In addition, the potential statistical property drift in time series makes the model rely on spurious correlation features, limiting the capture of spatio-temporal dependencies. To tackle the unique problems, we introduce the Prompt-guided Representation Alignment and Dynamic Adaption (PRADA) method, which harnesses multi-view Text-Series Adaptive Alignment (TSAA) guided by learnable prompts to capture the representations of different patterns. Specifically, we first decompose the input time series into different components and align orthogonal prompts consisting of learnable context vectors with time series embeddings independently for LLM’s input adaption. Furthermore, the time-frequency dual constraint is introduced to empower the model to capture the overlooked label autocorrelation from both the time and frequency domains. Through multi-view adaptive alignment guided by learnable prompts, PRADA is able to dynamically model spatio-temporal dependencies and adapt to the semantic gap between time series and natural language, which enables LLM-based models to obtain more robust times series representations in real scenarios. Experiments on multiple public datasets demonstrate the state-of-the-art (SOTA) performance of PRADA in time series forecasting. The code will be available at https://github.com/HowardLiu28/PRADA .},
  archive      = {J_KBS},
  author       = {Yinhao Liu and Zhenyu Kuang and Hongyang Zhang and Chen Li and Feifei Li and Xinghao Ding},
  doi          = {10.1016/j.knosys.2025.113478},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113478},
  shortjournal = {Knowl. Based Syst.},
  title        = {PRADA: Prompt-guided representation alignment and dynamic adaption for time series forecasting},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor multi-subspace learning for robust tensor-based multi-view clustering. <em>KBS</em>, <em>318</em>, 113476. (<a href='https://doi.org/10.1016/j.knosys.2025.113476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor-based multi-view clustering (TMVC) has garnered considerable attention for its efficacy in managing data that originate from multiple perspectives. However, the presence of noise in empirical datasets often undermines the reliability and robustness of the affinity matrices generated through these methods. To address this challenge, we introduce an innovative approach termed tensor multi-subspace learning (TMSL). Our methodology commences with the employment of a typical TMVC method to produce self-representation matrices for each view. Nevertheless, the affinity matrix derived from these self-representation matrices frequently falls short of the desired levels of dependability and robustness. To uncover the intrinsic architecture of the data within the tensor subspace, we harness the concept of tensor low-rank representation. This enables us to extract a higher-dimensional representation of multi-view data, thereby yielding a multi-subspace representation tensor that is both reliable and robust. These two stages are then seamlessly integrated into a unified framework and are resolved by employing the augmented Lagrangian algorithm. Notably, the TMSL method also serves as an effective post-processing strategy capable of being applied to various TMVC methods to augment their performance. Empirical evidence has established that TMSL outperforms other contemporary methods, and the post-processing strategy has proven to be an effective unified approach that can be extended to other TMVC methods.},
  archive      = {J_KBS},
  author       = {Bing Cai and Gui-Fu Lu and Guangyan Ji and Yangfan Du},
  doi          = {10.1016/j.knosys.2025.113476},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113476},
  shortjournal = {Knowl. Based Syst.},
  title        = {Tensor multi-subspace learning for robust tensor-based multi-view clustering},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Systems of implications obtained using the carve decomposition of a formal context. <em>KBS</em>, <em>318</em>, 113475. (<a href='https://doi.org/10.1016/j.knosys.2025.113475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Carve algorithm uses a divide-and-conquer strategy to compute the concept lattice of a formal context. The decomposition phase of the Carve algorithm discovers hierarchical structure in an amenable formal context, which the synthesis phase then exploits to construct the concept lattice from those of the component sub-contexts. In this paper, the problem of computing a sound and complete set of attribute implications via a refinement of the Carve decomposition is studied. Indeed, a set of rules is devised to obtain a set of valid implications which is proved to be complete. The refined decomposition and these rules are implemented in the novel Carve+ algorithm, whose runtime compares favorably with direct computation of the Duquenne–Guigues base of implications via the NextClosure algorithm.},
  archive      = {J_KBS},
  author       = {Domingo López-Rodríguez and Manuel Ojeda-Hernández and Tim Pattison},
  doi          = {10.1016/j.knosys.2025.113475},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113475},
  shortjournal = {Knowl. Based Syst.},
  title        = {Systems of implications obtained using the carve decomposition of a formal context},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BSDSGANet: Bidirectional skip-stored dual-stream gated attention network for multivariate time series classification. <em>KBS</em>, <em>318</em>, 113474. (<a href='https://doi.org/10.1016/j.knosys.2025.113474'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Networks (ESNs) are popular in Time Series Classification (TSC) due to their high-dimensional stochastic projections. However, due to the echo state at the current step is susceptible to the preceding step, the existing ESNs struggle to capture the long-term temporal dependencies. Furthermore, most of them only employ the unidirectional storage to capture the sequence information, which fails to fully consider the impact of the past and future moments simultaneously. To address these issues, we propose an advanced method called B idirectional S kip-stored D ual- S tream G ated A ttention Net work ( BSDSGANet ) for Multivariate Time Series Classification (MTSC). Specifically, to roundly exploit the sequence information, a Bidirectional Skip-Stored Encoder (BSSE) is designed to enrich the temporal context by integrating past and future information. Then, a Dual-Stream Gated Attention Learner (DSGAL) mechanism is incroporated, which employs a Gated Recurrent Self-Attention (GRSA) module to learn the long-term dependencies and variable relationships. Meanwhile, a Multi-Scale Gated Attention (MSGA) module is developed to extract more important features from multiple scales. Extensive experiments conducted on eighteen benchmark MTSC datasets show that BSDSGANet outperforms five traditional methods and twelve deep learning models.},
  archive      = {J_KBS},
  author       = {Yugen Yi and Panpan Zhao and Hui Sheng and Min Liu and Shicheng Li and Jiangyan Dai and Jun Kong and Shaojie Qiao},
  doi          = {10.1016/j.knosys.2025.113474},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113474},
  shortjournal = {Knowl. Based Syst.},
  title        = {BSDSGANet: Bidirectional skip-stored dual-stream gated attention network for multivariate time series classification},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AITL-net: An adaptive interpretable transfer learning network with robust generalization for liver cancer recognition. <em>KBS</em>, <em>318</em>, 113473. (<a href='https://doi.org/10.1016/j.knosys.2025.113473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography is a widely-used method for diagnosing liver cancer. The diagnostic accuracy is heavily dependent on the expertise of the clinicians. Artificial intelligence-assisted diagnostic methods based on transfer learning (TL) can reduce subjective errors and improve both the diagnostic accuracy and efficiency. However, poor generalization and lack of interpretability limit the accuracy of these methods. In this study, a novel adaptive interpretable transfer learning network (AITL-Net) that features robust generalization, interpretability, and high accuracy is proposed. Interpretability is achieved during training when the AITL-Net incorporates an adaptive feedback mechanism that employs fuzzy feature entropy to configure the hidden neurons and fully connected layers of the classifier interpretably. Additionally, AITL-Net integrates an inter-layer cross-temporal dynamic attention mechanism that dynamically updates the attention weights based on cross-layer temporal feature correlations, enabling the model to better extract representative attention and linear features, thereby enhancing accuracy. Finally, the accuracy and generalization are further improved with a temporal convolutional skip memory mechanism that is developed to effectively capture multilevel temporal features and dependencies over extended periods. Compared with state-of-the-art methods, AITL-Net exhibited outstanding performance on private and public liver datasets, achieving accuracies of 86.26 % and 96.82 %, respectively. It also excelled in recognition tasks across diverse diseases and medical imaging data with strong generalization. In conclusion, AITL-Net is a promising clinical auxiliary diagnostic tool that offers superior performance, generalization, and interpretability. It also provides novel insights into the interpretability of TL models during training, rather than relying on post-hoc interpretations of black-box models during testing.},
  archive      = {J_KBS},
  author       = {Haipeng Zhu and Guoying Wang and Zhihong Liao and Wenliang Zhang},
  doi          = {10.1016/j.knosys.2025.113473},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113473},
  shortjournal = {Knowl. Based Syst.},
  title        = {AITL-net: An adaptive interpretable transfer learning network with robust generalization for liver cancer recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond trivial edges: A fractional approach to cohesive subgraph detection in hypergraphs. <em>KBS</em>, <em>318</em>, 113472. (<a href='https://doi.org/10.1016/j.knosys.2025.113472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs can capture high-order relationships in complex systems, yet large hyperedges often dilute cohesive structures by incorporating loosely related nodes. To address this, we propose a fraction-based cohesive subgraph model, called the ( k , g , p ) -core, which extends existing support-based frameworks by introducing a user-defined fraction threshold. This threshold effectively filters out hyperedges deemed too large to convey meaningful connections, thereby emphasising high-quality, context-specific relationships. We devise two algorithms – Naïve and Advanced – to efficiently compute the ( k , g , p ) -core. The Advanced algorithm leverages lazy update strategies to avoid repeated neighbour recalculations, reducing computational overhead. Experimental evaluations on real-world datasets show that our method not only preserves the accuracy of cohesive subhypergraph discovery but also improves computational efficiency by over 50% compared to baseline approaches. Our findings demonstrate the importance of fraction-based constraints in refining subhypergraph discovery, opening avenues for more robust hypergraph analysis in domains such as recommendation systems, anomaly detection, and community detection.},
  archive      = {J_KBS},
  author       = {Hyewon Kim and Woocheol Shin and Dahee Kim and Junghoon Kim and Sungsu Lim and Hyun Ji Jeong},
  doi          = {10.1016/j.knosys.2025.113472},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113472},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond trivial edges: A fractional approach to cohesive subgraph detection in hypergraphs},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing named entity recognition with external knowledge from large language model. <em>KBS</em>, <em>318</em>, 113471. (<a href='https://doi.org/10.1016/j.knosys.2025.113471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the powerful capabilities of large language models (LLMs), our work enhances the Named Entity Recognition (NER) task by incorporating external knowledge generated with LLMs. We identify two primary challenges: generating external knowledge with sufficient breadth and training the extraction model with the large amount of non-entities. To fully exploit entity features derived from external knowledge, our work establishes robust connections between the quality of external knowledge from LLMs and the utilization of external knowledge within the extraction model. First, we introduce an entity linking strategy that enhances the comprehensiveness of the external knowledge generated by LLMs, thereby improving the extraction model’s understanding of relevant entities. Second, we propose an optimal self-training strategy for selecting pseudo labels, which effectively filters out non-entity interference. This enables the extraction model to better leverage entity-related expressions presented in the external knowledge. Through thorough experiments, we demonstrate the high performance of our method against three distinct benchmarks, each compared to varying external knowledge sources. Further analysis reveals that our proposed external knowledge and training strategies significantly enhance the ability of the extraction model to identify entity features.},
  archive      = {J_KBS},
  author       = {Qi Li and Tingyu Xie and Jian Zhang and Ke Ma and Jiayuan Su and Kaixiang Yang and Hongwei Wang},
  doi          = {10.1016/j.knosys.2025.113471},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing named entity recognition with external knowledge from large language model},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IFDepth: Iterative fusion network for multi-frame self-supervised monocular depth estimation. <em>KBS</em>, <em>318</em>, 113467. (<a href='https://doi.org/10.1016/j.knosys.2025.113467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised monocular depth estimation has gained prominence due to its training efficiency and applicability in autonomous systems. However, existing methods often exhibit limitations in preserving depth relationships in texture-homogeneous scenes and recovering fine-grained structural details. We present IFDepth, an iterative multi-frame depth prediction framework that refines coarse depth estimates through synergistic integration of optical flow features and multi-scale contextual information. Our architecture introduces three key components: (1) a Motion Feature Encoder (MFE) for spatiotemporal motion pattern extraction, (2) a Feature-Depth Cross Attention Layer (FCAL) enabling cross-modal feature interaction, and (3) a Gated Recurrent Unit (GRU)-based refinement module that progressively enhances predictions without computationally expensive 3D volume operations. Through iterative feature fusion, IFDepth effectively recovers occluded regions and high-frequency details while maintaining geometrically consistent depth ordering. Extensive experiments on KITTI, Cityscapes, and Robotcar datasets demonstrate state-of-the-art performance, particularly in preserving scene details and accurate depth ordering, outperforming existing monocular training approaches.},
  archive      = {J_KBS},
  author       = {Lizhe Wang and Qi Liang and Yu Che and Lanmei Wang and Guibao Wang},
  doi          = {10.1016/j.knosys.2025.113467},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113467},
  shortjournal = {Knowl. Based Syst.},
  title        = {IFDepth: Iterative fusion network for multi-frame self-supervised monocular depth estimation},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated feature reconstruction with collaborative star networks. <em>KBS</em>, <em>318</em>, 113463. (<a href='https://doi.org/10.1016/j.knosys.2025.113463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federal learning provides a secure platform for sharing sensitive data, yet imposes stringent requirements on the data. Non-IID data often cannot fully enjoy the convenience it offers. When clients possess divergent feature sets, retaining only the common features is a prevalent yet suboptimal practice. This paper proposes a novel omnidirectional federated learning framework that employs a Star collaboration network designed to leverage independent information from client nodes for feature reconstruction of other clients. It establishes an approximate distribution network, reinforcing feature correlations while overcoming data isolation seen in traditional federal learning. Additionally, homomorphic encryption is utilized to ensure data security throughout the transmission process. Experimental evaluations on structured datasets demonstrate that the reconstructed prediction results closely approximate those under the condition of complete data, confirming the effectiveness of the Star network in data completion and multi-party prediction scenarios.},
  archive      = {J_KBS},
  author       = {Yihong Zhang and Yuan Gao and Maoguo Gong and Hao Li and Yuanqiao Zhang and Sijia Zhang},
  doi          = {10.1016/j.knosys.2025.113463},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113463},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated feature reconstruction with collaborative star networks},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FactorVQVAE: Discrete latent factor model via vector quantized variational autoencoder. <em>KBS</em>, <em>318</em>, 113460. (<a href='https://doi.org/10.1016/j.knosys.2025.113460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces FactorVQVAE, the first integration of the Vector Quantized Variational Autoencoder (VQVAE) into factor modeling, providing a novel framework for predicting cross-sectional stock returns and constructing systematic investment portfolios. The model employs a two-stage architecture to improve the extraction and utilization of latent financial factors. In the first stage, an encoder–decoder-quantizer compresses high-dimensional input data into discrete latent factors through vector quantization, addressing posterior collapse and ensuring distinct representations. In the second stage, an autoregressive Transformer captures sequential dependencies among these latent factors, enabling precise return predictions. Empirical results in the CSI300 and S&P500 markets demonstrate FactorVQVAE’s superior performance. The model achieves the best Rank IC and Rank ICIR scores, surpassing the state-of-the-art latent factor models in varying market conditions. In portfolio evaluations, FactorVQVAE consistently excels in both Top- k Drop- n and Long–Short strategies, translating predictive accuracy into robust investment performance. In particular, it delivers the highest risk-adjusted returns, highlighting its ability to balance returns and risks effectively. These findings position FactorVQVAE as a significant advancement in integrating modern deep learning methodologies with financial factor modeling. Its adaptability, robustness, and exceptional performance in portfolio investment establish it as a promising tool for systematic investing and financial analytics.},
  archive      = {J_KBS},
  author       = {Namhyoung Kim and Seung Eun Ock and Jae Wook Song},
  doi          = {10.1016/j.knosys.2025.113460},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113460},
  shortjournal = {Knowl. Based Syst.},
  title        = {FactorVQVAE: Discrete latent factor model via vector quantized variational autoencoder},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label multi-modal classification of movie scenes. <em>KBS</em>, <em>318</em>, 113459. (<a href='https://doi.org/10.1016/j.knosys.2025.113459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Movie trailers are an essential part of a film’s promotional campaign, serving as a glimpse of what the movie has to offer. They are crafted by carefully selecting key scenes that encapsulate the movie’s genre and engage the audience. Automated trailer generation requires a reliable method to discriminate between different genres of movie scenes. In this study, we present a system that accurately and precisely classifies scenes based on their genre, which can be used later to produce genre-specific trailers for different target audiences. To accomplish this, we collected a dataset of labeled movie scenes, which were used to train a deep learning network for multi-label classification. The model was trained on both visual and audio features and their combination. We also introduced a new technique called Maximum Gap Thresholding to select a subset of labels for prediction in multi-label classification problems. Our results demonstrate that the proposed model outperforms humans in classifying movie scenes into their respective genres. We compared the model’s performance with human perception and observed that it demonstrated superior performance. This study provides a promising approach for automated trailer generation and could improve the effectiveness of film marketing campaigns.},
  archive      = {J_KBS},
  author       = {Irmak Türköz Soykök and H. Altay Güvenir},
  doi          = {10.1016/j.knosys.2025.113459},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113459},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label multi-modal classification of movie scenes},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D2AP: Double debiasing with adaptive proxies for domain generalization in noisy environment. <em>KBS</em>, <em>318</em>, 113458. (<a href='https://doi.org/10.1016/j.knosys.2025.113458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Generalization (DG) methods commonly rely on multiple source domains with correct annotations, while it is usually difficult to obtain a large amount of clean source samples in practice, which greatly limits their application in real noisy environments. Hence, we consider a more realistic setting of Noisy Domain Generalization (NDG), which learns with noisy data from multiple source domains. A simple solution is to introduce previous noise learning strategies into individual domains to detect and correct the noisy samples independently. However, knowledge from other domains can also help the noise detection and correction for the current domain. Moreover, there will be domain bias of domain imbalance in clean samples after noise detection, and confirmation bias of inaccurate pseudo-labels in noisy samples after noise correction, which greatly affect the learning performance. To this end, we propose a novel Double Debiasing method with Adaptive Proxies (D2AP) for NDG learning. In D2AP, an adaptive sample disentangling module is first developed with multi-scale Gaussian Mixture Model, so as to enable a mutual noise disentangling across domains. Further, double debiasing is proposed with the assistance of adaptive proxies, in order to make domain-invariant prototypes less sensitive to domain imbalance, and calibrate the pseudo-labels for noisy data, so as to address the both biases. Finally, empirical results over three benchmark datasets demonstrate the effectiveness of our D2AP.},
  archive      = {J_KBS},
  author       = {Yunyun Wang and Xiaodong Liu and Yi Guo},
  doi          = {10.1016/j.knosys.2025.113458},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113458},
  shortjournal = {Knowl. Based Syst.},
  title        = {D2AP: Double debiasing with adaptive proxies for domain generalization in noisy environment},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDC-swap: An efficient face swapping framework based on feature disentangling consistency. <em>KBS</em>, <em>318</em>, 113457. (<a href='https://doi.org/10.1016/j.knosys.2025.113457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face swapping images with high quality are critical for video production, privacy protection, and forgery detection, etc. In face swapping technology, one kernel element is the disentanglement of identity and attribute information. However, due to their deep entanglement in the latent space, effectively enhancing disentangling ability remains challenging. To tackle this challenge, this paper proposes the feature disentangling consistency: by executing the face swapping process (i.e., disentangling and recombining the identity and attribute information of two face images) in a pipeline twice, the generated twice-swapped images should be consistent with the original images. First, a new evaluation method (named FDC-Evaluation) is proposed to assess model performance according to disentangling consistency, which can be reflected in identity-attribute or image-level consistency. Meanwhile, to handle the limitation of missing ground truth, we introduce the FDC-Evaluation into original face swapping network, and propose a highly scalable and lightweight swapping framework (named FDC-Swap). Experiments demonstrate that the FDC-Evaluation overcomes traditional evaluation limitations, such as cognitive differences in identity-attribute features, identity assessment unfairness due to choices of identity encoders in training and evaluation, and operational complexity due to attribute feature diversity. Meanwhile, the FDC-Swap framework effectively enhances the performance of various existing face swapping networks. Code available at https://github.com/tzjoyzx/FDC_Swap .},
  archive      = {J_KBS},
  author       = {Jue Tian and Chunya Zhao and Yang Liu and Yanping Chen},
  doi          = {10.1016/j.knosys.2025.113457},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113457},
  shortjournal = {Knowl. Based Syst.},
  title        = {FDC-swap: An efficient face swapping framework based on feature disentangling consistency},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EAEFA-R: Multiple learning-based ensemble artificial electric field algorithm for global optimization. <em>KBS</em>, <em>318</em>, 113453. (<a href='https://doi.org/10.1016/j.knosys.2025.113453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adjusting the search behaviors of swarm-based algorithms is crucial for solving real-world optimization challenges. Researchers have developed ensemble strategies and self-adaptive mechanisms to enhance the optimization ability of individual algorithms by balancing global and local search capabilities. Inspired by these advancements, this paper proposes a physics-based artificial electric field algorithm with three improvement strategies and an attraction–repulsion operator (EAEFA-R) to enhance diversity and escape local optima. These strategies are probabilistically selected using a dynamic adaptation mechanism. The effectiveness of EAEFA-R is assessed through extensive analysis of exploration-exploitation dynamics and diversity, and it is evaluated on two real-parameter test suites, CEC 2017 and CEC 2022, across 10, 20, 30, 50, and 100-dimensional search spaces. Compared to fifteen state-of-the-art algorithms, including AEFA variants and other optimization algorithms, EAEFA-R demonstrates superior solution accuracy, convergence rate, search capability, and stability performance. The overall ranking highlights its exceptional potential for solving challenging optimization problems, outperforming other state-of-the-art algorithms across various dimensions. The MATLAB source code of EAEFA-R is available at https://github.com/ChauhanDikshit .},
  archive      = {J_KBS},
  author       = {Dikshit Chauhan and Anupam Yadav and Rammohan Mallipeddi},
  doi          = {10.1016/j.knosys.2025.113453},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113453},
  shortjournal = {Knowl. Based Syst.},
  title        = {EAEFA-R: Multiple learning-based ensemble artificial electric field algorithm for global optimization},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial decoupling domain generalization network for cross-scene hyperspectral image classification. <em>KBS</em>, <em>318</em>, 113432. (<a href='https://doi.org/10.1016/j.knosys.2025.113432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-scene hyperspectral image classification tasks have widely applied domain adaptation (DA) methods. However, DA typically adapts to the specific target scene during training and requires retraining for new scenes. In contrast, recent domain generalization (DG) methods aim to transfer directly to unseen domains, eliminating the requirement for target data during training. Popular DG methods achieve reliable generalization performance by expanding the source distribution. However, since hyperspectral images contain implicit non-causal components, such as label-independent environmental features, the extended samples generated by the source inevitably introduce undesirable inductive biases, which cause the learning of spurious correlations. To address these issues, we design a novel DG network with adversarial decoupling and unbiased semantic extension. Specifically, we first develop a homogeneous dual-branch encoder based on latent adversarial disentanglement, which helps to separate label-dependent causal components and weakly related components and is also applied to simulate domain gaps. Secondly, to decrease the preference of generated samples on category-irrelevant components, we adopt domain-specific instance shuffling to synthesize extension domains so that the new domain can preserve intrinsic causal information while expanding semantic coverage. Furthermore, to augment domain-invariant features to combat spurious correlations, we propose a multi-attribute representation strategy that learns diverse heterogeneous features through inter-domain unsupervised reconstruction and intra-domain supervised aggregation. Extensive experiments were conducted on four datasets, the ablation study shows the effectiveness of the proposed modules, and the comparative analysis with the advanced DG algorithms shows our superiority in the face of various spectral and category shifts. The codes is available from the website: https://github.com/HUOWUMO/ADNet_KBS .},
  archive      = {J_KBS},
  author       = {Hanqing Zhao and Lianlei Lin and Junkai Wang and Sheng Gao and Zongwei Zhang},
  doi          = {10.1016/j.knosys.2025.113432},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113432},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adversarial decoupling domain generalization network for cross-scene hyperspectral image classification},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-embedded large language models for emergency triage. <em>KBS</em>, <em>318</em>, 113431. (<a href='https://doi.org/10.1016/j.knosys.2025.113431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency departments (EDs) are crucial to healthcare but face persistent overcrowding. The Emergency Severity Index (ESI) triage system is vital for prioritizing patients based on acuity and resource needs but relies heavily on the subjective judgment of medical staff, leading to inconsistencies. This study developed a Sequential Domain and Task Adaptation (SDTA) framework for enhancing ED triage accuracy and consistency using large language models (LLMs). By training LLMs on clinical data and ESI-specific tasks, we significantly improved their performance compared to traditional prompt-engineered models, achieving accuracy levels comparable to or exceeding those of experienced emergency physicians. Notably, the fine-tuned models achieved high accuracy and perfect recall for high-risk cases. These findings highlight the potential of adapted LLMs to standardize triage decisions and reduce variability, thus offering a solution to alleviate overcrowding and enhance patient care outcomes.},
  archive      = {J_KBS},
  author       = {Qingyang Shen and Xiaozhi Zhang and Haomin Ren and Quan Guo and Zhang Yi},
  doi          = {10.1016/j.knosys.2025.113431},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-embedded large language models for emergency triage},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEMNet: A degradation difference enabled multi-stage network for multiple degradation image restoration. <em>KBS</em>, <em>318</em>, 113426. (<a href='https://doi.org/10.1016/j.knosys.2025.113426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring images affected by multiple types of degradation is a challenging and active area, requiring simultaneous handling of various forms of corruption and maintaining semantic context and spatial details while effectively managing network complexity. To advance the performance of multiple degradation image restoration tasks, we introduce a Degradation Difference Enabled Multi-stage Network (DEMNet), which can efficiently restore images affected by various types of degradation, including noise, rain, and haze. Three key contributions are provided by the proposed method: First, we introduce a unique three-stage architecture in DEMNet to balance capturing fine spatial details and the preservation of crucial contextual information. Second, we present a degradation difference enabled contrastive loss as a guidance mechanism for a degradation difference encoder. This loss function facilitates the accurate extraction of degradation-specific information, thus enhancing restoration. Finally, to balance channel features and spatial details, we propose a spatial-channel integration block, which improves the overall representation of the restored image with improved comprehensiveness and accuracy. By integrating these innovative modules, our DEMNet performs favorably against the latest approaches in multiple degradation image restoration while significantly reducing the number of parameters. Furthermore, DEMNet also exhibits excellent performance in single degradation image restoration, showcasing its versatility and effectiveness across various degradation types. Extensive experimental evaluations confirm the superiority of the proposed method.},
  archive      = {J_KBS},
  author       = {Yutong Yang and Xiaofeng Wang and Xin Lin and Honggang Chen},
  doi          = {10.1016/j.knosys.2025.113426},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113426},
  shortjournal = {Knowl. Based Syst.},
  title        = {DEMNet: A degradation difference enabled multi-stage network for multiple degradation image restoration},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FishDetectLLM: Multimodal instruction tuning with large language models for fish detection. <em>KBS</em>, <em>318</em>, 113418. (<a href='https://doi.org/10.1016/j.knosys.2025.113418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aquatic species play crucial roles in global ecosystems but are increasingly threatened by factors such as overfishing, coastal development and climate change. Existing deep learning methods address these challenges by employing powerful networks and large-scale, diverse datasets, separately tackling species recognition and trait identification during ongoing monitoring. However, they often exhibit limited generalization ability. Inspired by the human ability to quickly identify fish species and their locations with just a glance at an underwater image or scene, we introduce FishDetectLLM—a framework built on the lightweight TinyLLaVA architecture. FishDetectLLM utilizes the powerful reasoning capabilities and vast world knowledge of large language models (LLMs) to address the fish detection problem, providing both fish classification results and predicted bounding boxes for fish. Specifically, we create instruction dialogues for fish detection that connect fish taxonomy with classification descriptions and map location descriptions to the corresponding coordinates of bounding box in the input images from the recently released large-scale FishNet dataset. Then, we pretrain and fine-tune FishDetectLLM to achieve fish detection using the created dataset, leveraging the principle of augmenting human knowledge. Our results show that FishDetectLLM significantly outperforms existing multimodal LLMs and task-specific methods. Unlike conventional detection architectures that struggle to generalize beyond the training data, FishDetectLLM exhibits strong generalization capabilities, achieving robust performance on unseen data. This innovation paves the way for future applications of MLLMs in full research and offers valuable tools for the conservation of fish biodiversity.},
  archive      = {J_KBS},
  author       = {Jiaxin Zhu and Shibai Yin and Xin Liu and Xingyang Wang and Yee-Hong Yang},
  doi          = {10.1016/j.knosys.2025.113418},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113418},
  shortjournal = {Knowl. Based Syst.},
  title        = {FishDetectLLM: Multimodal instruction tuning with large language models for fish detection},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging label semantics and meta-label refinement for multi-label question classification. <em>KBS</em>, <em>318</em>, 113412. (<a href='https://doi.org/10.1016/j.knosys.2025.113412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate annotation of educational resources is crucial for effective personalized learning and resource recommendation in online education. However, fine-grained knowledge labels often overlap or share similarities, making it difficult for existing multi-label classification methods to differentiate them. The label distribution imbalance due to the sparsity of human annotations further intensifies these challenges. To address these issues, this paper introduces RR2QC, a novel Retrieval Reranking method to multi-label Question Classification by leveraging label semantics and meta-label refinement. First, RR2QC improves the pre-training strategy by utilizing semantic relationships within and across label groups. Second, it introduces a class center learning task to align questions with label semantics during downstream training. Finally, this method decomposes labels into meta-labels and uses a meta-label classifier to rerank the retrieved label sequences. In doing so, RR2QC enhances the understanding and prediction capability of long-tail labels by learning from meta-labels that frequently appear in other labels. Additionally, a mathematical LLM is used to generate solutions for questions, extracting latent information to further refine the model’s insights. Experimental results show that RR2QC outperforms existing methods in Precision@K and F1 scores across multiple educational datasets, demonstrating its effectiveness for online education applications. The code and datasets are available at https://github.com/78Erii/RR2QC .},
  archive      = {J_KBS},
  author       = {Shi Dong and Xiaobei Niu and Rui Zhong and Zhifeng Wang and Mingzhang Zuo},
  doi          = {10.1016/j.knosys.2025.113412},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113412},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging label semantics and meta-label refinement for multi-label question classification},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flat tree-based transformer for nested named entity recognition. <em>KBS</em>, <em>318</em>, 113405. (<a href='https://doi.org/10.1016/j.knosys.2025.113405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested Named Entity Recognition (nested NER), which aims to extract entities from overlapping spans, is a challenging task in natural language processing. Recently, span-based methods have achieved the best performance in this task by modeling the one-dimensional text sequence as a two-dimensional matrix. However, existing span-based methods are hard to accurately identify entity boundaries due to the interference of confusing spans, and they also fail to consider nested entity dependency relationships. To address these limitations, we propose a novel Flat Tree-based Transformer that utilizes the constituency parsing tree to assist nested NER. Specifically, we first employ the constituency parsing tree to generate candidate spans and only tree nodes are selected as potential entities, which can eliminate confusing spans and obtain a clearer and more discrete distribution of the entity boundaries. Then the Flat Tree-based Transformer leverages two self-attention units to capture nested dependency relationships among candidate spans, incorporating parsing tree structure while not affecting the Transformer’s parallelizability. Extensive experiments on five widely-adopted datasets demonstrate our proposed method performs better than previous state-of-the-art baselines methods.},
  archive      = {J_KBS},
  author       = {Hongli Mao and Xian-Ling Mao and Hanlin Tang and Xiaoyan Gao and Chun Xu and Heyan Huang},
  doi          = {10.1016/j.knosys.2025.113405},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113405},
  shortjournal = {Knowl. Based Syst.},
  title        = {A flat tree-based transformer for nested named entity recognition},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HEPI: High-reward experience-assisted policy iteration in deep reinforcement learning. <em>KBS</em>, <em>318</em>, 113384. (<a href='https://doi.org/10.1016/j.knosys.2025.113384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has achieved remarkable success in addressing decision-making and control tasks. However, it frequently encounters the obstacle of sample inefficiency, which impedes its practical deployment and effectiveness in real-world settings. To mitigate this limitation, we introduce High-reward Experiences-assisted Policy Iteration (HEPI), an off-policy DRL algorithm. HEPI emphasizes the importance of high-reward experiences, akin to how humans tend to reflect on pivotal experiences. In addition to the standard experience replay buffer, a dedicated temporary buffer is implemented to store the high-reward experiences. Throughout the training process, the agent selectively samples from these buffers to ensure the effective exploitation of high-reward experiences. We conduct an empirical evaluation of HEPI across a range of tasks in the OpenAI Gym environment. The simulation outcomes demonstrate that HEPI surpasses MA-TD3, a state-of-the-art approach, in both final performance and sample efficiency. Notably, for four OpenAI Gym tasks, HEPI achieves an average increase of 5% in cumulative rewards and 35% in sample efficiency. The source code is available at https://github.com/ShengGit/HEPI .},
  archive      = {J_KBS},
  author       = {Liming Xin and Shijie Chu and Yuehua Liu and Bin Sheng},
  doi          = {10.1016/j.knosys.2025.113384},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113384},
  shortjournal = {Knowl. Based Syst.},
  title        = {HEPI: High-reward experience-assisted policy iteration in deep reinforcement learning},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised domain generalization with clustering and contrastive learning combined mechanism. <em>KBS</em>, <em>318</em>, 113364. (<a href='https://doi.org/10.1016/j.knosys.2025.113364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization (DG) is essential in numerous tasks and strives to obtain a well-generalized model under multi-source data distributions. However, achieving the requirement that all data have precise annotations in real-life deployment poses a significant challenge. Therefore, we turn to semi-supervised domain generalization (SSDG), which relaxes this requirement from full annotation to limited annotation. The task presents two challenging issues: (1) learning pseudo-labels for unlabeled data under multi-source data distributions, and (2) effectively utilizing a minority of labeled data alongside a majority of unlabeled data to extract robust feature representations. To address these challenges, we propose an innovative approach that employs a collaborative mechanism of clustering and contrastive learning (CMCC) for high-quality pseudo-labels. Specifically, we use clustering to select high-confidence unlabeled samples and subsequently enhance the reliability of their pseudo-labels using contrastive learning. Furthermore, we introduce discrete Fourier transform (DFT)-based consistency learning (DCL) to enable the model to focus on domain-invariant features hidden in the phase information by mixing the amplitude spectra of two random images, thereby mitigating the domain shift issue. Comprehensive experiments conducted on two standard DG benchmark datasets with limited annotations validate the effectiveness of the proposed approach.},
  archive      = {J_KBS},
  author       = {Surong Ying and Xinghao Song and Hongpeng Wang},
  doi          = {10.1016/j.knosys.2025.113364},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113364},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised domain generalization with clustering and contrastive learning combined mechanism},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subspectrum mixup-based adversarial attack and evading defenses by structure-enhanced gradient purification. <em>KBS</em>, <em>318</em>, 113357. (<a href='https://doi.org/10.1016/j.knosys.2025.113357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transferable adversarial attacks against deep neural networks (DNNs) have attracted significant attention. Attackers can use adversarial examples crafted on substitute models to attack unknown target models, highlighting the importance of boosting transferability. However, the transferability of adversarial examples produced by current methods remains relatively weak. In this paper, we first propose an iterative attack based on frequency subspectrum mixup input transformation (FSMA), considering the sensitivity difference of model decision to different frequency components. Specifically, we evenly divide the discrete cosine transform spectra of noisy original image and auxiliary image into four disjoint subspectra respectively, and perform a mixup on each pair of subspectra to obtain diversified inputs to stabilize the perturbation update direction. Secondly, given the different noise phenomena in gradients of normally trained models and defenses, and the resulting gradient structure ambiguity, a structure-enhanced gradient purification strategy (SEGP) is proposed. By narrowing the difference between normal gradient and defense gradient, the success rate of adversarial examples in evading defenses is improved. We use convolutional neural network (CNN) and Transformer-based image classifiers as substitute models to craft adversarial examples. Plentiful experiments on ImageNet-compatible dataset prove the effectiveness of the proposed FSMA and SEGP. The latter can be combined with other attacks involving multi-sample average gradient processes to improve their success rate in breaking defenses. We also conduct a quantitative analysis of subspectrum mixup, illustrating the effectiveness of performing mixup on all subspectra. Our code is available at https://github.com/Rhiannon-lucky/FSMA .},
  archive      = {J_KBS},
  author       = {Han Cao and Qindong Sun and Rong Geng and Xiaoxiong Wang},
  doi          = {10.1016/j.knosys.2025.113357},
  journal      = {Knowledge-Based Systems},
  month        = {6},
  pages        = {113357},
  shortjournal = {Knowl. Based Syst.},
  title        = {Subspectrum mixup-based adversarial attack and evading defenses by structure-enhanced gradient purification},
  volume       = {318},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection method of surveillance video based on global-local information. <em>KBS</em>, <em>317</em>, 113530. (<a href='https://doi.org/10.1016/j.knosys.2025.113530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of detecting anomalies in videos is usually regarded as a Multi-Instance Learning problem under the weak supervisory approach. While existing methods have shown superior performance, most of them ignore the connection between global and local information in the video. They only model normal or abnormal segments with the highest anomaly score. As a result, the ability to generalize such hard-to-distinguish abnormal behaviors as small-amplitude abnormal events or large-amplitude normal events (e.g., accelerated running or stealing) is poor. To address this problem, a global-local based hard-to-categorize anomaly detection network is proposed. This network utilizes channel features, spatio-temporal features and motion information features of video clips to capture global and local feature information in videos to distinguish abnormal and normal events. Secondly, a global-local based anomaly ranking loss function is designed using a Multi-Task Learning approach, which increases the focus on hard-to-distinguish samples and reduces the over-learning of easy-to-categorize samples. In addition, based on the loss function, a score range scaling strategy is proposed, by which the classification boundary between anomalous and normal examples is shortened, making the model more sensitive to less obvious anomalous samples. It shows higher robustness on hard-to-categorize anomalous scenarios such as light interference, small motion changes, etc. On the UCF-Crime dataset, the AUC reaches 83.9 %, an increase of 1.6 % over the original model. It provides new ideas in the field of anomaly detection.},
  archive      = {J_KBS},
  author       = {Yuwei Wu and Haifeng Sang and Fei Li},
  doi          = {10.1016/j.knosys.2025.113530},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113530},
  shortjournal = {Knowl. Based Syst.},
  title        = {Anomaly detection method of surveillance video based on global-local information},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing IoT data collection through federated learning and periodic scheduling. <em>KBS</em>, <em>317</em>, 113526. (<a href='https://doi.org/10.1016/j.knosys.2025.113526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) describes a system of interlinked devices, sensors, and intelligent systems that facilitate intricate management in smart homes, industries, and cities. The devices constantly gather basic information like temperature, humidity, geographical location, and energy consumption to facilitate analytics and decision-making. However, traditional data collection methods, such as direct information transfer to a central server, face significant challenges regarding bandwidth use, energy efficiency, data security, reliability, and overall performance. These methods require robust communication infrastructures, often leading to network resource overexploitation due to raw data transmission. Although edge computing, fog computing, fedHGL, and centralized learning methods are considered modern techniques offering some advantages, they still require complex infrastructures and have the same difficulties processing heterogeneous or big datasets. Periodic scheduling is a new paradigm for federated learning, where the data will be processed locally, and only the updated model weights will be transferred to the central server. This approach significantly reduces bandwidth and energy consumption and facilitates faster model updates, enhancing the overall performance of IoT networks. Simulation results demonstrate that our proposed federated learning approach outperforms the other considered approaches on both MNIST and RT-IoT2022 datasets. It achieves on MNIST an accuracy improvement of 12 %, a reduction in convergence time of 22 %, and a bandwidth usage reduction of 21 %; and on RT-IoT2022, an accuracy enhancement of 9 %, a convergence time reduction of 18 %, and a bandwidth usage reduction of 25 %, confirming its overall superiority for IoT systems.},
  archive      = {J_KBS},
  author       = {Darya AzharShokoufeh and Nahideh DerakhshanFard and Fahimeh RashidJafari and Ali Ghaffari},
  doi          = {10.1016/j.knosys.2025.113526},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113526},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing IoT data collection through federated learning and periodic scheduling},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elucidating spatiotemporal chromatin dynamics with multi-stage differential variations from hi-C. <em>KBS</em>, <em>317</em>, 113516. (<a href='https://doi.org/10.1016/j.knosys.2025.113516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-throughput sequencing such as Hi-C captures spatiotemporal chromatin interactions, revealing the intricate interplays within transcriptional regulation and chromatin dynamics during cellular reprogramming and developmental processes. However, the forecast on chromatin dynamics in successive developmental stages remains challenging due to the inherent complexity of spatial and temporal patterns in Hi-C data across developmental stages. Towards such a direction, we present StarMie, a deep learning framework that integrates the spatiotemporal-aware module and the multi-stage differential variation module to predict high-throughput chromatin interactions in next developmental stages. Our comprehensive evaluation demonstrates that StarMie outperforms existing methods and sufficiently captures discriminative spatial and temporal dependencies as well as inter-stage-level variations of chromatin interactions. Moreover, the dual importance of both spatial and temporal information in Hi-C data is observed in parameter analysis. Ablation studies also confirm the essential role of each component in StarMie. Furthermore, five cross-species case studies support StarMie's cross-species generalizability and its capability to extract universal chromatin interaction patterns in different developmental stages. In-depth analysis demonstrates that StarMie uncovers conserved genomic logic in cardiac development and disease. Overall, this work paves a new approach for exploring genome reprogramming and development through predictive modeling of Hi-C dynamics.},
  archive      = {J_KBS},
  author       = {Zhongshen Li and Jixiang Yu and Shen You and Leyi Wei and Qiuzhen Lin and Xiangtao Li and Ka-Chun Wong},
  doi          = {10.1016/j.knosys.2025.113516},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113516},
  shortjournal = {Knowl. Based Syst.},
  title        = {Elucidating spatiotemporal chromatin dynamics with multi-stage differential variations from hi-C},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotion-assisted multi-modal personality recognition using adversarial contrastive learning. <em>KBS</em>, <em>317</em>, 113504. (<a href='https://doi.org/10.1016/j.knosys.2025.113504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal personality recognition integrates text, audio, and video information to accurately identify personality traits, offering significant value in fields like human–computer interaction. However, existing methods face feature extraction, noise removal, and modal alignment challenges. These issues impact recognition accuracy and model robustness. To address these issues, we propose an E motion- A ssisted multi-modal P ersonality R ecognition using adversarial C ontrastive learning (EAPRC). EAPRC leverages text, audio, and image data, incorporating emotional information to enhance recognition accuracy and robustness through adversarial training. The model reduces inter-modal noise using adversarial sample generation and employs joint class propagation contrastive learning to extract discriminative feature representations. For emotion-based assistance, EAPRC uses emotion feature-guided fusion and emotion score decision fusion to exploit the correlation between emotions and personality traits fully. It further improves the accuracy and stability of multi-modal personality recognition. Experimental results on the ChaLearn First Impressions and ELEA datasets demonstrate that EAPRC performs effectively, validating its capability in multi-modal personality recognition tasks.},
  archive      = {J_KBS},
  author       = {Yongtang Bao and Yuzhen Wang and Yutong Qi and Qing Yang and Ruijun Liu and Liping Feng},
  doi          = {10.1016/j.knosys.2025.113504},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113504},
  shortjournal = {Knowl. Based Syst.},
  title        = {Emotion-assisted multi-modal personality recognition using adversarial contrastive learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameterized data-free knowledge distillation for heterogeneous federated learning. <em>KBS</em>, <em>317</em>, 113502. (<a href='https://doi.org/10.1016/j.knosys.2025.113502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has emerged as a widely adopted and effective method for addressing two challenges of heterogeneous federated learning: Data heterogeneity causes client drift, which makes model convergence slow and model accuracy decrease, and personalized requirements of heterogeneous clients are ignored, which cannot be satisfied by a single global model. However, most existing knowledge distillation-based federated learning schemes are constrained by two fundamental limitations: They rely on public datasets for knowledge distillation, forming an impractical assumption for real-world scenarios, and the model personalization process employs a unified redundant teacher model, which conflicts with the diverse data distribution characteristics among heterogeneous clients. Therefore, we propose a parameterized data-free knowledge distillation, addressing the impractical dependency on public datasets and the static single knowledge transfer bottleneck through global view knowledge extraction without public datasets and an adaptive personalized teacher model. Specifically, the server learns a conditional distribution to extract knowledge about the global view of ground-truth data distributions and then uses the acquired knowledge as an inductive bias to enhance the generalization performance of local models. Additionally, the server calculates the knowledge contribution of each local model based on the similarity of the average data representation and aggregates a personalized teacher model that contains more positive transfer knowledge for each client. Experimental validation shows that the proposed scheme improves local test accuracy by up to 69.55%, 47.56%, and 18.76% on the Mnist, EMnist, and CelebA datasets, respectively, while reducing communication rounds across varying degrees of data heterogeneity compared to state-of-the-art schemes.},
  archive      = {J_KBS},
  author       = {Cheng Guo and Qianqian He and Xinyu Tang and Yining Liu and Yingmo Jie},
  doi          = {10.1016/j.knosys.2025.113502},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113502},
  shortjournal = {Knowl. Based Syst.},
  title        = {Parameterized data-free knowledge distillation for heterogeneous federated learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrepancy learning guided hierarchical fusion network for multi-modal recommendation. <em>KBS</em>, <em>317</em>, 113496. (<a href='https://doi.org/10.1016/j.knosys.2025.113496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal recommender systems aim to generate accurate recommendations for users by leveraging the user behaviors and the modal information of items, which is typically achieved using a multi-modal fusion mechanism that is mainly categorized into early fusion and late fusion strategies. The former strategy occurs in the feature extraction stage and the latter occurs after a decision is made based on each modality. However, these strategies are effective only in limited scenarios because of the discrepancies between modalities. In addition, existing methods for extracting user behavior features generally ignore noisy interactions prompted by user’s unintentional behaviors and popularity trends, which leads to suboptimal recommendations. To address the aforementioned issues, we propose a novel framework called D iscrepancy learning G uided H ierarchical fusion Net work ( DGHNet ), that comprises four components, i.e., a cross-modal alignment fusion, a multi-modal discrepancy learning, a multi-graph construction, and a hierarchical fusion network. In detail, we first apply an early fusion strategy to generate cross-modal features. Then, we quantify the discrepancies between different modalities using multi-modal discrepancy learning. After that, we construct multiple graphs to discover implicit structural information and capture user behavior preferences using a popularity-aware pruning strategy. Finally, we design a hierarchical fusion network to learn comprehensive representations of users and items using the quantified results and constructed multi-graph. Extensive experiments on three public datasets, i.e., Baby , Sports , and Clothing , validate the superiority of DGHNet over state-of-the-art baselines, where the improvements are particularly noticeable on the large-scale dataset.},
  archive      = {J_KBS},
  author       = {Yuzhuo Dang and Zhiqiang Pan and Xin Zhang and Wanyu Chen and Fei Cai and Honghui Chen},
  doi          = {10.1016/j.knosys.2025.113496},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Discrepancy learning guided hierarchical fusion network for multi-modal recommendation},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing unmanned marine vehicle path planning: A fractal-enhanced chaotic grey wolf and differential evolution approach. <em>KBS</em>, <em>317</em>, 113481. (<a href='https://doi.org/10.1016/j.knosys.2025.113481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient path planning is challenging for optimizing the trajectory of uncrewed marine vehicles navigating complex environments. However, when the global optimum is zero, path planning optimization encounters a significant challenge, a major shortcoming of the grey wolf optimizer (GWO). This study intentionally integrates multiple approaches to present a comprehensive methodology called fractal-enhanced chaotic GWO (FECGWO) in conjunction with differential evolution (DE) to fill this research gap. This method uses DE to strengthen the local search or exploitation phases, chaotic maps to improve the exploration phase, and fractals to fine-tune the transition between the two phases. In addition to testing against 46 sophisticated benchmark maps, this study carries out practical experimentation over commonly utilized meta-heuristic algorithms to comprehensively evaluate the proposed hybrid model's performance (FECGWO-DE). This thorough evaluation demonstrates notable advancements in unmanned marine vehicle path planning. The evaluation criteria include path length, consistency, time complexity, and success rate. These metrics illustrate the statistical significance of the novel methodology's improvements. The study demonstrates that FECGWO can precisely identify the best routes in given test maps, offering insightful information for developing path planning optimization—especially concerning unmanned marine vehicles.},
  archive      = {J_KBS},
  author       = {Chaoyang Zhu and Yassine Bouteraa and Mohammad Khishe and Diego Martín and Francisco Hernando-Gallego and Thavavel Vaiyapuri},
  doi          = {10.1016/j.knosys.2025.113481},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113481},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing unmanned marine vehicle path planning: A fractal-enhanced chaotic grey wolf and differential evolution approach},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balance recovery and collaborative adaptation approach for federated fault diagnosis of inconsistent machine groups. <em>KBS</em>, <em>317</em>, 113480. (<a href='https://doi.org/10.1016/j.knosys.2025.113480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to data privacy concerns and long-distance communication overhead, federated learning-based intelligent diagnosis offers a promising solution for ensuring the efficiency and reliability of machine groups in data decentralization. However, the data information from different machine nodes in a group are often inconsistent, leading to two key challenges in current federated intelligent diagnosis research: (1) data imbalance especially with respect to unseen faults, which causes the diagnosis model to become skewed, and (2) label space shifts across machine nodes, resulting in significant misalignment between the local and global distributions. As a consequence, the global diagnosis model struggles to effectively recognize unseen and under-represented fault states, and is often under-generalized to other machine nodes, especially when only a limited number of labeled samples are available. To address these challenges, this article presents a balance recovery and collaborative adaptation (BRCA) framework for federated intelligent diagnosis. The BRCA framework utilizes a central server to capture the inconsistent distribution information from each machine node, and further solves the Wasserstein barycenter to create a global distribution that carries complementary information. This barycenter is then broadcast to the client side to guide local model updates. At each client, convolutional autoencoders are constrained to supplement synthetic data for unseen and under-represented fault states, helping to restore a balanced decision boundary. Moreover, local distributions are aligned with the global barycenter through the designed adaptation trajectory that directionally ties subcategories with the same label. This is expected to correct discrepancies caused by label space shifts. The proposed BRCA is demonstrated in two federated intelligent diagnosis cases: one involving diverse machine-used bearings and the other involving different planetary gearboxes. The results show that BRCA can mitigate the performance degradation caused by data inconsistency, and achieve higher diagnosis accuracy than existing federated methods on other machine nodes even when there are very few labeled samples available.},
  archive      = {J_KBS},
  author       = {Bin Yang and Yaguo Lei and Naipeng Li and Xiang Li and Xiaosheng Si and Chuanhai Chen},
  doi          = {10.1016/j.knosys.2025.113480},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113480},
  shortjournal = {Knowl. Based Syst.},
  title        = {Balance recovery and collaborative adaptation approach for federated fault diagnosis of inconsistent machine groups},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STSE: Spatio-temporal state embedding for knowledge graph completion. <em>KBS</em>, <em>317</em>, 113469. (<a href='https://doi.org/10.1016/j.knosys.2025.113469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explicit integration of temporal and geospatial features into knowledge graphs enables more precise characterization of knowledge dynamics across temporal and geographic dimensions, while simultaneously amplifying the complexity of inferring missing facts in spatio-temporal knowledge graphs (STKGs). To address these dual challenges in Spatio-Temporal Knowledge Graph Completion (STKGC), we present STSE (Spatio-Temporal State Embedder), an innovative embedding framework that systematically coordinates relational semantics with spatial-temporal continuum modeling. Our technical contributions manifest through three key innovations: (1) A novel descriptive form that enhances practicality by distinguishing head/tail entity locations in tuples; (2) A geometry-aware embedding space that dynamically fuses spatial grids and temporal slices through spatio-temporal states, enabling robust reasoning on heterogeneous graphs; (3) An enhanced encoder that captures complex spatio-temporal contextual relationships between entities using modified Transformer and ResNet architectures. Experimental validation across three benchmark datasets (YAGO11k-ST, Wikidata12k-ST, ICEWS05-ST) demonstrates STSE's superiority, achieving 3.8 % Mean Reciprocal Rank ( MRR ) improvement in time prediction and 7.1 % Hits@10 enhancement in spatial location reasoning compared to state-of-the-art baselines. This methodological breakthrough establishes three implementable principles for STKGC: (1) geometric consistency constraints during fusion operations, (2) spatio-temporal difference capturing across heterogeneous relationships, (3) cross-domain applications ranging from epidemiological spread prediction to urban mobility pattern mining. © 2025 Elsevier Science. All rights reserved},
  archive      = {J_KBS},
  author       = {Xiaoyu Ji and Yibing Cao and Jiangshui Zhang and Xinke Zhao},
  doi          = {10.1016/j.knosys.2025.113469},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113469},
  shortjournal = {Knowl. Based Syst.},
  title        = {STSE: Spatio-temporal state embedding for knowledge graph completion},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized contrastive learning for generalized zero-shot image classification. <em>KBS</em>, <em>317</em>, 113466. (<a href='https://doi.org/10.1016/j.knosys.2025.113466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) aims to learn a model on known classes that can adapt to a test set comprising both known and unknown classes. Recent GZSL research in image classification has made significant progress by utilizing representation learning techniques. However, the challenge of generating discriminative representations for fine-grained classes with close relevance remains unresolved. To address this problem, we introduce a Decentralized Contrastive Learning (DCL) framework that seamlessly integrates a nested Wasserstein GAN (WGAN) with decentralized contrastive representation learning. Our nested WGAN incorporates the representation learning module within the discriminator, enabling the model to simultaneously train the representations and differentiate them in a synergistic manner. Moreover, our decentralized contrastive learning module enhances the discriminative nature of representations by preserving calibration based on class information without additional parameters during training. We further provide theoretical analysis for DCL, uncovering its superiority in learning discriminative representations and its robustness in handling mixed features. Experiments on show that DCL outperforms the state-of-the-art models by margins of about 3%, 4% and 3% on CUB, SUN and aPY datasets.},
  archive      = {J_KBS},
  author       = {Ya Chen and Zhihao Zhang and Pei Wang and Feng Tian},
  doi          = {10.1016/j.knosys.2025.113466},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113466},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decentralized contrastive learning for generalized zero-shot image classification},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative edge-driven social IoT service recommender framework utilizing multi-agent deep reinforcement learning. <em>KBS</em>, <em>317</em>, 113465. (<a href='https://doi.org/10.1016/j.knosys.2025.113465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Internet of Things (SIoT) recommender systems are designed to enhance the functionality and efficiency of the Internet of Things (IoT) by incorporating social networking principles. They can recommend services, devices, or actions based on the social friendships and interactions between IoT devices and their users. Today, edge-driven, Multi-Agent Deep Reinforcement Learning (MADRL)-based recommender systems offer significant advantages for optimizing friendship paths and improving SIoT network navigability. Utilizing edge computing, these systems process cached services in proximity to their source, thereby improving real-time decision-making and decreasing latency. The edge-driven aspect distributes computational load, reducing central server dependency and enhancing scalability and resilience. On the other hand, MADRL enables adaptive learning from complex SIoT user interactions and network dynamics, ensuring contextually relevant and personalized recommendations. This approach improves network navigability by dynamically optimizing routes and efficiently utilizing network resources through distributed learning. Overall, these recommender systems provide scalable, adaptive, and efficient recommendations, fostering stronger social connections and improving the functionality of SIoT ecosystems. In this article, we have developed an innovative edge-driven, MADRL-based SIoT recommender framework that surpasses the performance of the leading baselines. By leveraging the decentralized processing power of edge computing and sophisticated MADRL-oriented algorithms, the suggested framework significantly enhances the optimization of SIoT friendship paths and network navigability. Extensive experimental results demonstrate that our approach achieves superior accuracy, efficiency, and scalability compared to existing state-of-the-art methods, thereby offering more personalized and contextually relevant service recommendations while reducing delay and improving real-time decision-making in dynamic SIoT environments.},
  archive      = {J_KBS},
  author       = {Babak Farhadi and Parvaneh Asghari and Azadeh Zamanifar and Hamid Haj Seyyed Javadi},
  doi          = {10.1016/j.knosys.2025.113465},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113465},
  shortjournal = {Knowl. Based Syst.},
  title        = {An innovative edge-driven social IoT service recommender framework utilizing multi-agent deep reinforcement learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning of quasi-nonlinear long-term cognitive networks using iterative numerical methods. <em>KBS</em>, <em>317</em>, 113464. (<a href='https://doi.org/10.1016/j.knosys.2025.113464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-nonlinear Long-term Cognitive Networks (LTCNs) are an extension of Fuzzy Cognitive Maps (FCMs) for simulation and prediction problems ranging from regression and pattern classification to time series forecasting. In this extension, the quasi-nonlinear reasoning allows the model to escape from unique fixed-point attractors, while the unbounded weights equip the network with improved approximation capabilities. However, training these neural systems continues to be challenging due to their recurrent nature. Existing error-driven learning algorithms (metaheuristic-based, regression-based, and gradient-based) are either computationally demanding, fail to fine-tune the recurrent connections, or suffer from vanishing/exploding gradient issues. To bridge this gap, this paper presents a learning procedure that employs numerical iterative optimizers to solve a regularized least squares problem, aiming to enhance the precision and generalization of LTCN models. These optimizers do not require analytical knowledge about the Jacobian or the Hessian and were carefully chosen to address the inherent challenges of training recurrent neural networks. They are devoted to solving nonlinear optimization problems using trust regions, linear or quadratic approximations, and interpolations between the Gauss–Newton and gradient descent methods. In addition, we explore the model’s performance for several activation functions including piecewise, sigmoid, and hyperbolic variants. The empirical studies indicate that the proposed learning procedure outperforms state-of-the-art algorithms to a significant extent.},
  archive      = {J_KBS},
  author       = {Gonzalo Nápoles and Yamisleydi Salgueiro},
  doi          = {10.1016/j.knosys.2025.113464},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113464},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning of quasi-nonlinear long-term cognitive networks using iterative numerical methods},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved dynamic time warping for fire safety emergency response: A robust and interpretable extension. <em>KBS</em>, <em>317</em>, 113462. (<a href='https://doi.org/10.1016/j.knosys.2025.113462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification (MTSC) has gained considerable attention in the fire safety industry, enabling the development of specialized algorithms based on the unique characteristics of fire-related time series. Traditional feature representation techniques (e.g., SAX, DTW) often incur high computational costs, offer limited interpretability, and focus primarily on shape information. Moreover, many TSC algorithms struggle with robustness under distributional shifts across diverse fire environments. We propose a new algorithm that strengthens robust feature representations and modeling, enabling groupwise feature importance analysis for fire classification. Our approach captures both shape and amplitude information, along with first-order differences, by integrating SAX and DTW with random SAX baselines and masks to remove potential noise. We then apply a sequence of groupwise logistic classifiers, using penalties on dimensionally grouped features to capture group effects. Numerical experiments on specific fire safety scenarios and the UEA MTS Archive confirm the model’s robustness and interpretability. Furthermore, we have developed AI-driven software that helps first responders detect burning materials from gas emissions, guided by the Emergency Response Guidebook (ERG). This integrated solution equips emergency teams with essential tools for timely and informed fire response.},
  archive      = {J_KBS},
  author       = {Yaoyu Zhang and Huilei Wang and Fuyu Wang and M. Hamed Mozaffari and Yoon Ko and Nour Elsagan and Chi-Guhn Lee},
  doi          = {10.1016/j.knosys.2025.113462},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113462},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improved dynamic time warping for fire safety emergency response: A robust and interpretable extension},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal motion and spatial enhanced appearance with transformer for video-based person ReID. <em>KBS</em>, <em>317</em>, 113461. (<a href='https://doi.org/10.1016/j.knosys.2025.113461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For video-based person Re-Identification (Re-ID), how to efficiently extract temporal motion features and spatial appearance features from video sequences is a key issue. Conventional approaches focus on modelling the entire video spatio-temporal features, ignoring the inherent differences between temporal motion features (e.g., gait) that change over time and spatial appearance features (e.g., clothing) that are stable over time in terms of attributes. Because of their different sensitivities in real-world scenarios, conventional approaches often lose critical fine-grained features. To address these issues, we propose a T emporal M otion and spatial E nhanced A ppearance with T ransformer-based (T 2 MEA) framework for modelling spatial–temporal video discriminative representations. Specifically, (1) Dual-Branch Architecture: The content branch emphasises extracting the overall structure of the video using the spatial–temporal aggregation (STA) module from a global view, whereas the fovea branch focuses on gaining local fine-grained spatio-temporal features. (2) Zero-Parameter Design: the [CLS] Token Channel Shift Interaction (TCSI) module captures the dynamic features and static features between adjacent frames without additional parameters; the Spatial Patches Shift Enhancing (SPSE) module is introduced to enhance appearance features within frame to address occlusion and illumination changes without additional parameters. (3) Spatial–Temporal Interaction: The Cross-Attention Aggregation (CAA) module is proposed to interact between temporal and spatial features and further enrich the spatial–temporal feature representation for video sequences. Extensive experiments on three public Re-ID benchmarks (MARS, iLIDS-VID, and PRID-2011) demonstrate that the proposed framework outperforms several state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Haifei Ma and Canlong Zhang and Enhao Ning and Chai Wen Chuah},
  doi          = {10.1016/j.knosys.2025.113461},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113461},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal motion and spatial enhanced appearance with transformer for video-based person ReID},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PPTformer: A novel hybrid model for enhanced long-term time series forecasting with extreme value focus. <em>KBS</em>, <em>317</em>, 113456. (<a href='https://doi.org/10.1016/j.knosys.2025.113456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term time series forecasting (LTSF) is crucial for strategic planning and the development of early warning systems. While recent models have shown promise, they struggle to capture long-term dependencies and forecast critical points like peaks and valleys. To address this, we present PPTformer, a novel model that combines ensemble learning and specialized modules to enhance the precision of extreme value forecasting. PPTformer includes a peak-valley forecasting module for recognizing and predicting extreme features, a partition and detrending preprocessing module to isolate complex patterns and highlights intrinsic properties to the forefront, and a time-lag attention convolutional encoder module adept at capturing long-term dependencies. Furthermore, PPTformer breaks away from the traditional encoder-decoder paradigm by adopting a streamlined architecture that replaces the decoder with a linear projection layer, effectively overcoming the limitations of traditional models. Extensive tests on 9 real-world datasets show that PPTformer outperforms both traditional and state-of-the-art models on 6 datasets, and performs second best on the remaining datasets, demonstrating its effectiveness for practical real-world LTSF applications.},
  archive      = {J_KBS},
  author       = {Jian Liu and Junkang Guo and Lei Gao and Yuhang Wang and Aolei Liu and Xin Zhang},
  doi          = {10.1016/j.knosys.2025.113456},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113456},
  shortjournal = {Knowl. Based Syst.},
  title        = {PPTformer: A novel hybrid model for enhanced long-term time series forecasting with extreme value focus},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity and consistency graph learning guided multi-view unsupervised feature selection. <em>KBS</em>, <em>317</em>, 113455. (<a href='https://doi.org/10.1016/j.knosys.2025.113455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view unsupervised feature selection has gained considerable attention lately because of its potential to enhance the performance of clustering and classification tasks, as well as improve the efficiency and interpretability of algorithms by selecting critical features from unlabeled heterogeneous data views. The existing feature selection algorithms based on graph learning mostly focus on directly using the initialized graphs to obtain a consensus graph. However, this ignores the potential cross-view diversity that may be induced by view-specific characteristics, corruptions, or noise. To address this issue, a novel and efficient algorithm is proposed that uses the Diversity and Consistency graph learning to guide Multi-view unsupervised Feature Selection (DCMFS). It is a unified optimization model that includes cross-view diversity and multi-view consistency graph learning, fusing the multiple consistent graphs to obtain a pure consensus graph, sparse feature selection, and learning optimal clustering structure graph. An efficient alternating iterative algorithm is designed to solve the optimization problem, and the convergence of the algorithm is verified through theoretical analysis and experimental results. Extensive experiments on eight benchmark datasets show the superiority and effectiveness of DCMFS compared to nine representative algorithms. DCMFS has been successfully applied to single-cell multi-omics data and identified many marker genes.},
  archive      = {J_KBS},
  author       = {Hanxiao Xu and Da Xu and Yusen Zhang},
  doi          = {10.1016/j.knosys.2025.113455},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113455},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diversity and consistency graph learning guided multi-view unsupervised feature selection},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised high-uncertainty deep canonical variate analysis for fault diagnosis in blast furnace ironmaking. <em>KBS</em>, <em>317</em>, 113454. (<a href='https://doi.org/10.1016/j.knosys.2025.113454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blast furnace ironmaking process (BFIP) is of paramount importance in the steel industry. Reliable fault diagnosis for BFIP is crucial to ensure production safety, improve efficiency and quality, reduce costs, and maximize resource utilization. However, establishing effective fault diagnosis models is hindered by challenges including non-linearity, dynamics, widespread noise, and the scarcity of labeled data alongside an abundance of unlabeled data. To address these issues, this paper proposes a new fault diagnosis method for BFIP called semi-supervised high-uncertainty deep canonical variate analysis (SHDCVA). The proposed algorithm consists of three main parts, including (1) high-uncertainty nonlinear dynamic feature capture, (2) robust semi-supervised framework construction, and (3) model solving and parameter optimization. Firstly, a high-uncertainty deep canonical variate representation method is proposed from a probabilistic perspective, which can capture high-uncertainty nonlinear dynamic characteristics. The high-uncertainty property can effectively deal with data noise and enhance the reliability of downstream fault diagnosis model. Moreover, this paper proposes a robust semi-supervised classification framework that can efficiently utilize limited labeled samples and a large amount of unlabeled samples. The supervised part controls the release of labeled samples by training signal annealing method (TSA) to prevent overfitting, while the unsupervised part enforces model smoothing by applying adversarial perturbations to enhance robustness. Subsequently, an efficient computational method is devised to generate adversarial perturbations and the overall objective is constructed. Finally, the effectiveness of SHDCVA is confirmed through a practical case study utilizing genuine BFIP data.},
  archive      = {J_KBS},
  author       = {Yuelin Yang and Chunjie Yang and Xiongzhuo Zhu and Hanwen Zhang and Haifeng Zhang and Zhiqi Su and Siwei Lou},
  doi          = {10.1016/j.knosys.2025.113454},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised high-uncertainty deep canonical variate analysis for fault diagnosis in blast furnace ironmaking},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTSE-net: Resource-efficient convolutional and TF-transformer network for speech enhancement. <em>KBS</em>, <em>317</em>, 113452. (<a href='https://doi.org/10.1016/j.knosys.2025.113452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are powerful tools in real-time speech enhancement (SE) since they automatically learn high-level feature representations from raw audio, resulting in significant advancements. Therefore, demand for resource-efficient DNNs for speech enhancement is increasing, mainly using embedded systems. Still, a lightweight and resource-efficient DNN with optimal speech enhancement performance is a challenging task. Dual-path attention-driven architectures have shown notable performance in SE, primarily because of their ability to capture time and frequency dependencies. This paper proposes a resource-efficient SE using a codec-based dual-path time–frequency transformer (CTSE-Net) to improve noisy speech and apply it to speech recognition tasks. The proposed SE employs a codec (coder–decoder) architecture with feature calibration in skip connections to obtain fine-grained frequency components. The codec is interconnected using a dual-path time–frequency transformer incorporating time and frequency attentions. The encoder encodes a time–frequency (T–F) representation derived from the distorted compressed speech spectrum, whereas the decoder estimates the compressed magnitude spectrum of enhanced speech. Further, dedicated speech activity detection (SAD) is employed to identify speech segments in the input signals. By distinguishing speech from background noise or silence, the SAD block provides important information to the decoder for target speech enhancement. The proposed resource-efficient approach ensures attention across time–frequency and distinguishes speech from background noise, leading to more effective denoising and enhancement. Experiments indicate that CTSE-Net shows robust noise reduction and contributes to accurate speech recognition. On the benchmark VCTK+DEMAND dataset, the proposed CTSE-Net demonstrates better SE performance, achieving notable improvements in ESTOI (33.69%), PESQ (1.05), and SDR (11.36 dB) over the noisy mixture.},
  archive      = {J_KBS},
  author       = {Nasir Saleem and Sami Bourouis and Hela Elmannai and Abeer D. Algarni},
  doi          = {10.1016/j.knosys.2025.113452},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113452},
  shortjournal = {Knowl. Based Syst.},
  title        = {CTSE-net: Resource-efficient convolutional and TF-transformer network for speech enhancement},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer feature fusion and coarse-to-fine label learning for semi-supervised lesion segmentation of lung cancer. <em>KBS</em>, <em>317</em>, 113451. (<a href='https://doi.org/10.1016/j.knosys.2025.113451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung lesion segmentation is essential for medical diagnosis, and prognosis evaluation. However, the significant expense of pixel-level annotations limits the availability of labeled data and brings challenges in precise segmentation. Semi-supervised learning (SSL) presents a promising alternative by leveraging a large volume of unlabeled samples to reduce dependence on labeled data. Although previous works had made some progresses, SSL still faces two major challenges: (1) inadequate robustness of consistency learning in ambiguous regions, and (2) inefficient utilization of information from noisy pseudo-labels. To overcome these challenges, we propose a novel SSL segmentation framework, named Multi-layer Feature Fusion and Coarse-to-fine Label Learning for Semi-supervised Lesion Segmentation of Lung Cancer (MCL 3 S). The framework incorporates Multi-layer Feature Fusion (MFF), which introduces random perturbations into features during the embedding-to-pixel transition, enhancing segmentation robustness in ambiguous regions. Furthermore, we propose two additional modules: Pixel-level Pattern Relocalization Module (PPRM) to capture fine-grained local contextual information, and Ambiguity Perceptual Learning (APL) to extract valuable insights from noisy pseudo-labels by focusing on uncertainty regions. Experimental results demonstrate that MCL 3 S achieves significant performance improvements over seven state-of-the-art semi-supervised segmentation approaches on two in-house lung cancer datasets and one public dataset. The implementation code will be publicly available at https://github.com/Pahoia/MCL3S .},
  archive      = {J_KBS},
  author       = {Jiale Chen and Siyang Feng and Yanfen Cui and Chuansong Fan and Huan Lin and Xinjun Bian and Lingqiao Li and Zhenbing Liu and Zaiyi Liu and Rushi Lan and Xipeng Pan},
  doi          = {10.1016/j.knosys.2025.113451},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113451},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-layer feature fusion and coarse-to-fine label learning for semi-supervised lesion segmentation of lung cancer},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph fusion with neural ordinary differential equations for the predictive maintenance of electromechanical equipment. <em>KBS</em>, <em>317</em>, 113450. (<a href='https://doi.org/10.1016/j.knosys.2025.113450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Maintenance is the primary strategy for optimizing operational efficiency and reducing the maintenance costs of electromechanical equipment. However, existing Predictive Maintenance approaches suffer from significant shortcomings, such as the inability to learn the dynamic evolution of fault and maintenance events within massive, heterogeneous datasets and the lack of effective models to handle this complex data. To address these issues, we propose a temporal knowledge graph (TKG) reasoning method. First, we construct a TKG based on an ontology defined by the heterogeneous data features of electromechanical equipment. Second, we propose a Dynamic Graph Embedding model, which captures the dynamic evolution of the non-equal-interval events in the TKG by combining neural ordinary differential equations with a graph convolutional neural network. Furthermore, we design a Dynamic Hawkes Transformer to identify the evolutionary process and predicting future events based on historical fault and maintenance data. Finally, we use elevators as a case study to compare the proposed method with other advanced methods and demonstrate its effectiveness in TKG reasoning. Our proposed method excels in fault and maintenance event prediction, as well as time prediction, for electromechanical equipment.},
  archive      = {J_KBS},
  author       = {Jiawei Lu and Hanyuan Chen and Jianwei Chen and Zhongcheng Xiao and Ren Li and Gang Xiao and Qibing Wang},
  doi          = {10.1016/j.knosys.2025.113450},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113450},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal knowledge graph fusion with neural ordinary differential equations for the predictive maintenance of electromechanical equipment},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain UAV pose estimation: A novel attempt in UAV visual localization. <em>KBS</em>, <em>317</em>, 113449. (<a href='https://doi.org/10.1016/j.knosys.2025.113449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of depth estimation algorithms and continuous improvements in devices such as LiDAR and depth cameras, the acquisition of high-quality 3D models has become increasingly accessible. This progress opens up new opportunities for leveraging cross-domain matching between images and point clouds to estimate the pose of Unmanned Aerial Vehicles (UAVs) for visual localization. In this context, we propose a novel cross-domain descriptor that facilitates the fusion and matching of features across modalities. Building upon this approach, we designed a dual-branch UAV localization pipeline that incorporates an object detection strategy to extract more reliable feature points from the scene. Additionally, we constructed two new datasets specifically tailored for UAV-based aerial applications. The first dataset is manually annotated and focuses on training and evaluating object detection models from an aerial perspective, while the second dataset contains approximately 1.7 million 2D-3D correspondences from diverse scenarios, offering a rich collection of training and evaluation samples. Extensive experiments on public UAV datasets demonstrate that, compared to existing descriptors, our method not only achieves superior pose estimation accuracy through a coarse-to-fine image matching strategy but also enables robust pose estimation by directly matching images and point clouds to obtain accurate 2D-3D correspondences. Moreover, the incorporation of object detection strategies significantly enhances pose estimation accuracy and demonstrates increased resilience to interference in complex environments. Our datasets and code will be publicly available at https://github.com/lwhhhh13/Cross-Domain-UAV-Pose-Estimation .},
  archive      = {J_KBS},
  author       = {Wenhao Lin and Tao Liu and Kan Ren and Qian Chen},
  doi          = {10.1016/j.knosys.2025.113449},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain UAV pose estimation: A novel attempt in UAV visual localization},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VC-mamba: Causal mamba representation consistency for video implicit understanding. <em>KBS</em>, <em>317</em>, 113437. (<a href='https://doi.org/10.1016/j.knosys.2025.113437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, spatiotemporal representation learning based on deep learning has driven the advancement of video understanding. However, existing methods based on convolutional neural networks (CNNs) and Transformers still face limitations in understanding implicit information in complex scenes, particularly in capturing dynamic changes over long-range spatiotemporal data and inferring hidden contextual information in videos. To address these challenges, we propose VC-Mamba, a video implicit understanding model based on causal Mamba representation consistency. By segmenting explicit texture information into token features and leveraging the linear Mamba framework to capture long-range spatiotemporal interactions, we introduce the spatiotemporal motion Mamba block for motion perception. This block includes a multi-head temporal length Mamba to enhance cross-frame motion consistency and a bidirectional gated space Mamba to capture the inter-frame dependencies of feature tokens. Through the analysis of both explicit and implicit spatiotemporal interactions, VC-Mamba effectively captures long-range spatiotemporal representations. Additionally, we design an attention mask perturbation strategy based on causal invariance constraints to optimize the existing selective spatiotemporal mask mechanism. By progressively enhancing the causal strength of related features, this strategy analyzes implicit causal chains in videos, improving the model’s resistance to interference from weakly causal features and enhancing the robustness and stability of implicit information understanding. Finally, we conducted extensive experiments on several datasets, including short-term action recognition and long-term video reasoning tasks. The results demonstrate that VC-Mamba matches or surpasses state-of-the-art models, particularly in capturing long-range spatiotemporal interactions and causal reasoning, proving its effectiveness and generalization in video implicit understanding tasks.},
  archive      = {J_KBS},
  author       = {Yishan Hu and Jun Zhao and Chen Qi and Yan Qiang and Juanjuan Zhao and Bo Pei},
  doi          = {10.1016/j.knosys.2025.113437},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113437},
  shortjournal = {Knowl. Based Syst.},
  title        = {VC-mamba: Causal mamba representation consistency for video implicit understanding},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging evolutionary algorithms with a dynamic weighted search space approach for fraud detection in healthcare insurance claims. <em>KBS</em>, <em>317</em>, 113436. (<a href='https://doi.org/10.1016/j.knosys.2025.113436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The healthcare industry has been suffering from fraud in many facets for decades, resulting in millions of dollars lost to fictitious claims at the expense of other patients who cannot afford appropriate care. As such, accurately identifying fraudulent claims is one of the most important factors in a well-functioning healthcare system. However, over time, fraud has become harder to detect because of increasingly complex and sophisticated fraud scheme development, data unpreparedness, as well as data privacy concerns. Moreover, traditional methods are proving increasingly inadequate in addressing this issue. To solve this issue a novel evolutionary dynamic weighted search space approach (DW-WOA-SVM) is presented in the current study. The approach has different levels that work simultaneously, where the optimization algorithm is responsible for tuning the Support Vector Machine (SVM) parameters, applying the weighting procedure for the features, and using a dynamic search space to adjust the range values. Tuning the parameters benefits the performance of SVM, and the weighting technique makes it updated with importance and lets the algorithm focus on data structure in addition to optimization objectives. The dynamic search space enhances the search range during the process. Furthermore, large language models have been applied to generate the dataset to improve the quality of the data and address the lack of good dimensionality, helping to enhance the richness of the data. The experiments highlighted the superior performance of this proposed approach than other algorithms.},
  archive      = {J_KBS},
  author       = {Mohammad Tubishat and Dina Tbaishat and Ala’ M. Al-Zoubi and Abed-Elalim Hraiz and Maria Habib},
  doi          = {10.1016/j.knosys.2025.113436},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging evolutionary algorithms with a dynamic weighted search space approach for fraud detection in healthcare insurance claims},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning for anomaly detection in hierarchical subgraph. <em>KBS</em>, <em>317</em>, 113435. (<a href='https://doi.org/10.1016/j.knosys.2025.113435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in attribute graphs is a crucial task in various domains, such as cybersecurity, finance, and social networks. However, existing methods face challenges due to the sparse connectivity of anomalous nodes and the irregular distribution of features, which often leads to unstable outcomes and reduced detection accuracy. Traditional contrastive learning methods struggle to capture subtle differences in large-scale graphs, while subgraph-based learning approaches, although more detailed, suffer from instability and inefficiency due to the randomness in neighbor selection. To address these challenges, we propose a novel method called contrastive learning for anomaly detection in hierarchical subgraph (CLADHS). Our approach constructs hierarchical subgraphs for each target node, generating both positive and negative subgraphs to capture detailed local relationships effectively. We employ a global virtual node to represent the overall graph context, integrating both global and local perspectives. An attention-based aggregation mechanism is used to capture relationships between the target node and its neighbors, and contrastive learning is applied to distinguish between positive and negative subgraphs. To further enhance the model’s robustness, we introduce noise into the positive subgraph’s feature representation and employ Kullback–Leibler (KL) divergence loss to guide the model in learning stable and generalizable representations. Our experiments demonstrate that CLADHS significantly outperforms the state-of-the-art anomaly detection algorithms across multiple datasets, showcasing its adaptability and superior performance in identifying anomalies within complex graph structures. The source code is publicly available at https://github.com/csjywu1/CLADHS .},
  archive      = {J_KBS},
  author       = {Jiayang Wu and Wensheng Gan and Jiahao Zhang and Philip S. Yu},
  doi          = {10.1016/j.knosys.2025.113435},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Contrastive learning for anomaly detection in hierarchical subgraph},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical influential node identification in multi-agent networks based on triangular recursive compression. <em>KBS</em>, <em>317</em>, 113434. (<a href='https://doi.org/10.1016/j.knosys.2025.113434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of influential nodes in complex networks is a core research topic in the field of network science. Existing methods often rely on the topological features of static networks, which struggle to fully capture the characteristics of nodes in dynamic networks. To address this issue, this paper proposes a hierarchical control node selection algorithm based on triangular recursive compression and control influence index (HTRCI) to identify influential nodes and enhance network stability accurately. Firstly, the control influence index is introduced, integrating multiple attributes such as node energy level and neighbor variation rate to evaluate node importance comprehensively. Additionally, an efficient triangle detection algorithm based on intersection matrices is designed to improve the extraction efficiency of triangular features. To address the influence overlap caused by shared nodes and edges within triangular structures, this paper proposes a triangle control node selection method incorporating a conflict resolution mechanism. In non-triangular regions, this paper designs a non-triangular structure control node identification algorithm based on coverage maximization, which regulates the distribution of control nodes by introducing a repulsion mechanism. Furthermore, a hierarchical control node selection strategy is proposed to iteratively compress the management regions of control nodes, reducing the number of control nodes and improving the global control efficiency of the network. In NS3 simulations, the proposed algorithm is evaluated on six real-world networks and compared with eight state-of-the-art algorithms. The results demonstrate that the HTRCI algorithm exhibits significant advantages in terms of information transmission rate and network stability, validating its superiority and applicability in complex dynamic networks.},
  archive      = {J_KBS},
  author       = {Yonggang Li and Zhili Xiao and Ang Gao and Weinong Wu and Errong Pei},
  doi          = {10.1016/j.knosys.2025.113434},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical influential node identification in multi-agent networks based on triangular recursive compression},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fear-constrained personalized and anthropomorphic reinforcement learning for autonomous car-following. <em>KBS</em>, <em>317</em>, 113433. (<a href='https://doi.org/10.1016/j.knosys.2025.113433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving safe, personalized and anthropomorphic driving performance remain challenges for autonomous driving especially in the car-following scenario. “NeuroAI”, which combined neuroscience, brain science and psychology with artificial intelligence (AI), has shown great potential to enhance the performance of AI systems. Drawing inspiration from “NeuroAI”, we present a fear-constrained personalized and anthropomorphic (FCPA) reinforcement learning (RL) for autonomous car-following. Firstly, the fear model of the ego vehicle driver in the car-following scenario is established. And then, the fear thresholds of the drivers with different driving styles are determined through analyzing the collected driving data. Finally, the FCPA-RL algorithm is proposed to realize safe, personalized and anthropomorphic autonomous car-following by keeping the fear within corresponding thresholds and designing the reward function based on the probability density functions (PDF) of time headway (THW). Through experimental tests, we demonstrate that FCPA-RL effectively enhances safety during training, ​achieves personalized and anthropomorphic autonomous car-following​, and ​exhibits robust generalization​ across diverse driving scenarios beyond existing approaches. Furthermore, the results also reveal that FCPA-RL not only ​learns human drivers’ behavioral characteristics​ but also ​has potential to surpass human-level driving performance.},
  archive      = {J_KBS},
  author       = {Yufei Zhang and Liang Wu and Zijian Cai and Wenxiao Ma and Xinlun Leng and Wenyuan Sun and Zitong Shan},
  doi          = {10.1016/j.knosys.2025.113433},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fear-constrained personalized and anthropomorphic reinforcement learning for autonomous car-following},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-UAV cooperative path planning based on novel rotation artificial potential fields. <em>KBS</em>, <em>317</em>, 113429. (<a href='https://doi.org/10.1016/j.knosys.2025.113429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative path planning for multiple unmanned aerial vehicles (Multi-UAVs) is important for coordinated operations in rescue, logistics, and agriculture. Existing methods for multi-UAV cooperative path planning often fail to adapt to rapidly changing environments or require substantial computational resources. To address these challenges, we propose an efficient method for Adaptive Multi-UAV Cooperative Path Planning (AMCPP) to adapt to complex and dynamic environments, which enables multi-UAVs to navigate with minimal flight time and path length. The proposed AMCPP first uses a novel Rotational Artificial Potential Field (RAPF) to calculate the angle difference between the UAVs, target position, and obstacles, which plans navigable, collision-free paths in dynamic scenarios. The proposed RAPF method introduces rotational forces to guide UAVs to fly avoiding obstacles and reduce the risk of getting trapped in local minima. To improve the precision and flexibility of path planning, we normalize these RAPF factors to a continuous space. Then, the Multi-Agent Reinforcement Learning (MARL) method is employed in the continuous space to optimize the RAPF parameters, so as to improve the success rate of UAV navigation in complex environments. Extensive experiments across various scenarios demonstrate that the proposed method outperforms state-of-the-art (SOTA) methods in terms of success rate, average reward, and average path length.},
  archive      = {J_KBS},
  author       = {Huidong Liu and Xianlei Long and Yong Li and Jinjin Yan and Mingyan Li and Chao Chen and Fuqiang Gu and Huayan Pu and Jun Luo},
  doi          = {10.1016/j.knosys.2025.113429},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113429},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive multi-UAV cooperative path planning based on novel rotation artificial potential fields},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stream autoencoder for channel-level multi-scale feature extraction in hyperspectral unmixing. <em>KBS</em>, <em>317</em>, 113428. (<a href='https://doi.org/10.1016/j.knosys.2025.113428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional hyperspectral imagery presents significant challenges for accurate unmixing due to spectral variability, limited spatial resolution, and noise. Traditional unmixing approaches often rely on spatial multi-scale processing, leading to redundant computations and suboptimal feature representations. In response to these challenges, we propose a novel Channel Multi-Scale Dual-Stream Autoencoder (CMSDAE) that innovatively integrates channel-level multi-scale feature extraction with dedicated spectral information guidance. By leveraging Channel-level Multi-Scale Perception Blocks and a Hybrid Attention-Aware Feature Block, CMSDAE efficiently captures diverse and robust spectral-spatial features while significantly reducing computational redundancy. Extensive experiments on both synthetic and real-world datasets demonstrate that CMSDAE not only improves unmixing accuracy and robustness against noise but also offers enhanced computational efficiency compared to state-of-the-art methods. This work provides new insights into spectral-spatial modeling for hyperspectral unmixing, promising more reliable and scalable analysis in challenging remote sensing applications.},
  archive      = {J_KBS},
  author       = {Yuquan Gan and Yong Wang and Qiuyu Li and Yiming Luo and Yihong Wang and Yushan Pan},
  doi          = {10.1016/j.knosys.2025.113428},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113428},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-stream autoencoder for channel-level multi-scale feature extraction in hyperspectral unmixing},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fusion network for multi-modality medical image registration with progressive feature alignment. <em>KBS</em>, <em>317</em>, 113427. (<a href='https://doi.org/10.1016/j.knosys.2025.113427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing medical image fusion methods rely on well-aligned source images; however, they tend to produce artifacts when dealing with misaligned images. Additionally, significant differences between modalities pose major challenges for the registration of multimodal images. To address these issues, we have designed a progressive feature registration fusion network, called PFRFusion. Specifically, we first designed a Progressive Feature Alignment Registration (PFAR) network for registering multimodal medical images. In PFAR, a Progressive Refinement Module (PRM) performs multi-layer registration to predict the displacement vector field between the moving image and the target image, ultimately reconstructing the aligned medical image. Subsequently, we developed a Shared Information Module (SIM) to extract shared information between different modalities and supplemented it with a corresponding loss function to mitigate the disturbance caused by modality differences during registration. These two modules work synergistically to achieve accurate image registration. Furthermore, we proposed a Dual-Branch Feature Fusion (DBFF) network that simultaneously considers modality-specific features and modality-shared features. This method is capable of capturing richer features from the registered images, thereby generating high-quality fused images. Extensive experiments demonstrate that our proposed PFRFusion outperforms the current state-of-the-art methods in fusing misaligned medical images. Our code is publicly available at https://github.com/Jy1-Xu/PFRFusion .},
  archive      = {J_KBS},
  author       = {Aimei Dong and Jingyuan Xu and Long Wang},
  doi          = {10.1016/j.knosys.2025.113427},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113427},
  shortjournal = {Knowl. Based Syst.},
  title        = {A fusion network for multi-modality medical image registration with progressive feature alignment},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q-learning-driven accelerated iterated greedy algorithm for multi-scenario group scheduling in distributed blocking flowshops. <em>KBS</em>, <em>317</em>, 113424. (<a href='https://doi.org/10.1016/j.knosys.2025.113424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the distributed blocking flowshop group scheduling problem under multiple processing time scenarios and due dates (DBFGSP_UPT). Initially, a mathematic model is formulated to achieve a balance between the mean and standard deviation of total tardiness across various scenarios, and its correctness is validated via the Gurobi solver. Next, an accelerated iterated greedy algorithm integrated with Q-learning selection mechanism ( Q A I G ) is proposed. The Q A I G involves: a rapid evaluation method, tailored for the total tardiness criterion by using a hierarchical approach, which is first proposed to significantly reduce the time complexity of the insertion-based method; a self-calibrating parameter method, which dynamically selects appropriate numbers of groups to be destroyed, is designed to improve the diversity of solutions; and a Q-learning mechanism is integrated into the local search strategy framework to facilitate the selection of high-quality local search schemes. Finally, we conduct a comparative analysis across 810 test instances. Comprehensive numerical experiments and comparative analyses demonstrate that the proposed Q A I G surpasses existing state-of-the-art algorithms in terms of the average relative percentage increase.},
  archive      = {J_KBS},
  author       = {Zhen Li and Yuting Wang and Yuyan Han and Kaizhou Gao and Junqing Li},
  doi          = {10.1016/j.knosys.2025.113424},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113424},
  shortjournal = {Knowl. Based Syst.},
  title        = {Q-learning-driven accelerated iterated greedy algorithm for multi-scenario group scheduling in distributed blocking flowshops},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAICL-DSC: Retrieval-augmented in-context learning for dialogue state correction. <em>KBS</em>, <em>317</em>, 113423. (<a href='https://doi.org/10.1016/j.knosys.2025.113423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue State Tracking (DST) is a crucial component of task-oriented dialogue systems. However, most DST methods face the issue of error propagation, which limits the response success rate of dialogue systems. Therefore, some researchers have proposed Dialogue State Correction (DSC) methods to correct errors in the dialogue state predicted by the DST model, thereby mitigating the error propagation issue in DST. Although these methods have achieved impressive improvements, they still cannot effectively correct all types of errors and may introduce new errors during the correction process. To address this issue, we propose Retrieval-Augmented In-Context Learning for Dialogue State Correction (RAICL-DSC), which can correct errors of the same type in the target sample under the guidance of in-context examples of specific types. Specifically, to better correct the target samples, we use a simulator to generate in-context example databases with examples of correcting errors. Next, we used the retriever and evaluator to find the most relevant in-context examples from the databases based on the semantics and error types of the target sample. Finally, we use these in-context examples to assist the state corrector in correcting the predicted dialogue state in the target sample. The experiment demonstrates that the proposed method not only effectively corrects the erroneous predictions of the DST model but also shows excellent potential in correcting annotation errors in the MultiWOZ dataset.},
  archive      = {J_KBS},
  author       = {Haoxiang Su and Hongyan Xie and Jie Shi and Di Wu and Liting Jiang and Hao Huang and Zhongjiang He and Yongxiang Li and Ruiyu Fang and Jianyu Zhao and Shuangyong Song},
  doi          = {10.1016/j.knosys.2025.113423},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113423},
  shortjournal = {Knowl. Based Syst.},
  title        = {RAICL-DSC: Retrieval-augmented in-context learning for dialogue state correction},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Planar-mirror reflection imaging learning based seagull optimization algorithm for global optimization and feature selection. <em>KBS</em>, <em>317</em>, 113420. (<a href='https://doi.org/10.1016/j.knosys.2025.113420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seagull optimization algorithm (SOA) exhibits certain weaknesses such as poor accuracy and a tendency to stagnate in local optimal solutions when solving complex optimization problems. This paper suggests an enhanced variant of SOA, referred to as planar-mirror reflection imaging learning based SOA (PRIL-SOA), to address these limitations. First, we present the novel nonlinear strategies for adjusting the employing variable A and control parameter B are presented to achieve a balance between global and local search capabilities. Second, a modified position update equation is devised that incorporates velocity components and personal history best positions, thereby enhance solution precision. Third, a new PRIL strategy is introduced to maintain diversity and prevent premature convergence. To validate the performance of PRIL-SOA, we conduct a series of benchmark tests, including 23 classical functions and a feature selection problem involving 21 datasets are used. The results indicate that PRIL-SOA consistently outperforms basic SOA and other meta-heuristics. The average search success rate of PRIL-SOA on benchmark test problems is 91.3 %, with 21 out of 23 problems achieving the theoretical optimal value. Compare with SOA, mountain gazelle optimizer (MGO), whale optimization algorithm (WOA), hunger games search (HGS), HHO-based joint opposite selection (HHO-JOS), modified SCA (MSCA), and exploration-enhanced GWO (EEGWO), the average success rates of PRIL-SOA is better to 86.95 %, 78.26 %, 82.61 %, 65.22 %, 56.52 %, 60.87 %, and 4.35 %, respectively.},
  archive      = {J_KBS},
  author       = {Wen Long and Hui Jiao and Yang Yang and Ming Xu and Mingzhu Tang and Tiebin Wu},
  doi          = {10.1016/j.knosys.2025.113420},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113420},
  shortjournal = {Knowl. Based Syst.},
  title        = {Planar-mirror reflection imaging learning based seagull optimization algorithm for global optimization and feature selection},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IDEAL: A malicious traffic detection framework with explanation-guided learning. <em>KBS</em>, <em>317</em>, 113419. (<a href='https://doi.org/10.1016/j.knosys.2025.113419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The credibility of deep learning models is crucial for network security tasks. Ensuring that these models make reasonable decisions based on truly relevant features is key to enhancing their credibility. Explanation supervision, which guides models to reason rationally by adding supervision to model explanations, has shown promising results in terms of improving overall model performance. However, the complexity of cyberattack characteristics and packet structures increases the difficulty of integrating explanation supervision and makes it challenging to obtain human annotations that encode domain knowledge concerning cyberattacks. In this paper, we propose a general framework called mal I cious traffic D etection with E xpl A nation-guided L earning (IDEAL). This framework integrates explanation supervision techniques into malicious traffic detection for the first time, enables researchers to supervise model explanations based on domain knowledge, and jointly optimizes the task and explanation losses. As a result, both the detection performance and explainability of the model improve. In addition, to address the problem of obtaining human annotations, we propose an automatic explanation annotation generation method based on the expert-defined detection rules of the famous Snort firewall. We conduct extensive experiments on the CIC-IDS-2017 and TON_IoT datasets. The experimental results show that, with only approximately 1% of the training data used for explanation supervision, our proposed IDEAL method significantly improves upon the detection performance and explainability of the state-of-the-art models. In addition, IDEAL is applicable across different neural network architectures and exhibits considerable robustness to incomplete low-quality manual annotations.},
  archive      = {J_KBS},
  author       = {Huiting Jia and Bo Lang and Xiangyu Li and Yuhao Yan},
  doi          = {10.1016/j.knosys.2025.113419},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113419},
  shortjournal = {Knowl. Based Syst.},
  title        = {IDEAL: A malicious traffic detection framework with explanation-guided learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDF-FND: A dynamic fusion model for multimodal fake news detection. <em>KBS</em>, <em>317</em>, 113417. (<a href='https://doi.org/10.1016/j.knosys.2025.113417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection has received increasing attention from researchers in recent years, especially in the area of multimodal fake news detection involving both text and images. However, many previous studies have simply fed the semantic features of both text and image modalities into a binary classifier after applying basic concatenation or attention mechanisms, where these features often contain a significant amount of inherent noise. This, in turn, leads to both intra- and inter-modal uncertainty. In addition, while methods based on simple concatenation of the two modalities have achieved notable results, they often ignore the drawback of applying fixed weights across modalities, which causes some high-impact features to be ignored. To address these issues, we propose a novel semantic-level m ultimodal d ynamic f usion framework for f ake n ews d etection ( MDF-FND ). To the best of our knowledge, this is the first attempt to develop a dynamic fusion framework for semantic-level multimodal fake news detection. Specifically, our model consists of two main components: (1) the U ncertainty E stimation M odule ( UEM ), which is an uncertainty modeling module that uses a multi-head attention mechanism to model intra-modal uncertainty, and (2) the D ynamic F usion N etwork, which is based on Dempster–Shafer evidence theory ( DFN ) and is designed to dynamically integrate the weights of both text and image modalities. To further enhance the dynamic fusion framework, a graph attention network is employed for inter-modal uncertainty modeling before DFN. Extensive experiments have demonstrated the effectiveness of our model across three datasets, with a performance improvement of up to 4% on the Twitter dataset, achieving state-of-the-art performance. We also conducted a systematic ablation study to gain insights into our motivation and architectural design. Our model is publicly available at https://github.com/CoisiniStar/MDF-FND .},
  archive      = {J_KBS},
  author       = {Hongzhen Lv and Wenzhong Yang and Yabo Yin and Fuyuan Wei and Jiaren Peng and Haokun Geng},
  doi          = {10.1016/j.knosys.2025.113417},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113417},
  shortjournal = {Knowl. Based Syst.},
  title        = {MDF-FND: A dynamic fusion model for multimodal fake news detection},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ITransMamba: A lightweight spatio-temporal network based on long-term traffic flow forecasting. <em>KBS</em>, <em>317</em>, 113416. (<a href='https://doi.org/10.1016/j.knosys.2025.113416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction constitutes a fundamental component of intelligent traffic management systems. Existing Transformer-based models for traffic flow prediction often suffer from insufficiently effective channel mixing strategies and the presence of redundant, irrelevant information in long-term historical data, which undermines prediction accuracy. To overcome these limitations, the iTransMamba model is introduced, integrating a Transformer encoder-decoder framework with a frequency-domain channel mixing module. Specifically, the encoder employs the iTransformer architecture to capture inter-channel dependencies and temporal features, while the decoder incorporates a selective structured space model (SSM) mechanism to filter out redundant historical data and efficiently compress long-term information. The frequency-domain channel mixing module utilizes the Einstein matrix, computed through the Einstein fast Fourier transform (EinFFT) method, to enhance channel correlation and achieve optimal mixing. Experimental evaluations demonstrate that, at a time step interval of 5 min, iTransMamba outperforms existing baselines across prediction horizons of 12, 24, 48, and 96 steps. The model achieves this superior performance with a parameter count below 6 M and a floating-point operation cost of 27 G, significantly lower than other state-of-the-art (SOTA) models offering effective long-term traffic flow prediction solutions.},
  archive      = {J_KBS},
  author       = {Jianrong Cao and Xing Sheng and Junzhe Zhang and Zongtao Duan},
  doi          = {10.1016/j.knosys.2025.113416},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113416},
  shortjournal = {Knowl. Based Syst.},
  title        = {ITransMamba: A lightweight spatio-temporal network based on long-term traffic flow forecasting},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge memory graph convolution network for cross-domain recommendation. <em>KBS</em>, <em>317</em>, 113415. (<a href='https://doi.org/10.1016/j.knosys.2025.113415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommender systems (CDR) address the data sparsity issue by leveraging information from relevant domains. Nowadays, graph neural networks (GNNs) are widely employed to capture higher-order collaborative relationships, further enhancing the effectiveness of CDR in tackling data sparsity. However, GNN-based CDR methods still face challenges in modeling comprehensive user preferences: (1) existing methods relying solely on GNNs struggle to capture fine-grained user preferences (e.g., attribute level) due to limitations in semantic information decomposition; (2) the learned embeddings are highly abstract, making them difficult to understand and interpret; (3) the optimal performance of existing methods typically bottlenecks at layers 2 ∼ 4, which is caused by the inherent over-smoothing problem of GNNs. To address these challenges, we propose a method called Knowledge Memory Graph convolution network for Cross-Domain Recommendation (KMGCDR). Specifically, we incorporate an encyclopedic knowledge graph (KG) to enrich the semantic understanding of user behavior. Then, we extend the GNN-based model with a knowledge-enhanced memory network that can store external KG information, aiming to capture user’s fine-grained preferences in an interpretable manner. This design can also widen the gap between the low-correlation data and reduce the smoothness of the graph representation. To our best knowledge, this is the first attempt to employ a memory network to address the over-smoothing problem in CDR. Extensive experiments on real-world datasets demonstrate the superiority of KMGCDR. Compared to the best-performing SOTA baseline method in six cross-domain scenarios, KMGCDR achieves an average of 10.07% and 5.55% improvements on Amazon and Facebook datasets, respectively.},
  archive      = {J_KBS},
  author       = {Yuhan Wang and Qing Xie and Mengzi Tang and Zhifeng Bao and Lin Li and Yongjian Liu},
  doi          = {10.1016/j.knosys.2025.113415},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113415},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge memory graph convolution network for cross-domain recommendation},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFGNet: Salient-feature-guided real-time building extraction network for remote sensing images. <em>KBS</em>, <em>317</em>, 113413. (<a href='https://doi.org/10.1016/j.knosys.2025.113413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building extraction is crucial for interpreting remote-sensing images. However, existing methods struggle to balance accuracy with inference speed, limiting their support for high concurrency and real-time processing. Although recent approaches have improved segmentation, significant hurdles remain in feature lightweighting, capturing salient features, and ensuring semantic coherence across different characteristics. This paper presents a salient-feature-guided real-time building extraction network (SFGNet), designed to investigate and integrate salient information, such as semantics, details, and borders, thereby improving segmentation performance. First, an effective feature extraction module called Dual-branch Cascade Module (DCM) was developed to extract relevant channel information by learning the shallow details and boundary features of buildings. Additionally, an Offset Feature Alignment Module (OFAM) is designed to minimize the feature offset in both high- and low-frequency connection zones to capture detail and contour edge feature information. A lightweight Context Feature Aggregation Module (CFAM) was implemented in the decoder stage to consolidate local and global features. Finally, a novel hybrid loss function was designed to address the imbalance in single-view, high-density distributions. On the three public datasets (Massachusetts Builds, WHU Aerial Image, and Potsdam Dataset), our model achieves mIoU scores of 75.45%, 89.40%, and 93.16%, respectively. Furthermore, an additional cross-domain experiment on an external untrained real dataset demonstrated outstanding generalization performance. With only 2.397 M parameters, the model reaches an 130.62 FPS, outperforming current state-of-the-art models in terms of both segmentation accuracy and inference speed. These results demonstrate the potential of SFGNet for real-time building segmentation. The Code is available at https://github.com/gasking/SFGNet .},
  archive      = {J_KBS},
  author       = {Jin Kuang and Dong Liu},
  doi          = {10.1016/j.knosys.2025.113413},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113413},
  shortjournal = {Knowl. Based Syst.},
  title        = {SFGNet: Salient-feature-guided real-time building extraction network for remote sensing images},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSciSum: Detailed summarization of long scientific documents. <em>KBS</em>, <em>317</em>, 113409. (<a href='https://doi.org/10.1016/j.knosys.2025.113409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A summary is frequently considered by academics as a viable alternative to long scientific documents. Prior studies generally required well-annotated training datasets such as arXiv and PubMed, using abstracts from articles as supervised signals. However, these gold summaries merely provide a cursory overview of the subject matter, lacking crucial detailed information, such as datasets, evaluation metrics and model performance, which are essential for both academics and the general public. To address this problem, we propose DSciSum, an extract-then-generate framework that utilizes the zero-shot capabilities and a superior semantic understanding of large language models (LLMs). This approach focuses on previously overlooked details, thereby generating more human-related summaries. Moreover, an innovative LLM-based evaluation criterion is designed as a substitute for traditional metrics, providing a more meaningful and professional assessment for scientific summarization. Specifically, DSciSum first selects salient sentences containing both general and detailed information using a statistics-based heuristic approach. Thereafter, it pretrains and finetunes LLMs to acquire the generator tailored for scientific summarization. Finally, G-SciEval is designed to provide a human-related evaluation of scientific summarization from a deep semantic perspective. Experimental results show that DSciSum outperforms both the reference and state-of-the-art models on arXivCap.},
  archive      = {J_KBS},
  author       = {Ran Liu and Xian-Ling Mao and Heyan Huang},
  doi          = {10.1016/j.knosys.2025.113409},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113409},
  shortjournal = {Knowl. Based Syst.},
  title        = {DSciSum: Detailed summarization of long scientific documents},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-local sparse unmixing based hyperspectral change detection with unsupervised deep clustering. <em>KBS</em>, <em>317</em>, 113408. (<a href='https://doi.org/10.1016/j.knosys.2025.113408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSIs) are now widely utilized in change detection (CD) tasks because of their rich spectral signatures. As for detecting and discriminating fine spectral change between different types, hyperspectral unmixing (HU) methods investigate changes into a subpixel-level so as to distinguish the endmember within each pixel. However, current HU models cannot directly utilize the correlation difference information between temporal HSIs during unmixing. This paper proposes a hyperspectral sparse unmixing CD model, which directly extracts the changed endmembers of the difference matrix and uses their abundance to represent the change information. To improve the unmixing accuracy, a non-local mean strategy has been integrated into the HU model, incorporating the non-local spatial information of HSIs. But this comes at the cost of increased computational demands. To further expedite non-local sparse unmixing, we apply an unsupervised deep clustering for homogeneous region segmentation to reduce the search space of non-local mean regularizer, where pixels in the same region possess spectral similarity. A split&merge strategy is employed to infer the number of homogeneous regions. For the generated abundance maps of each endmember, we adopt a self-adaptive abundance truncation strategy to search the optimal threshold for accumulating abundance matrix and retaining the changed regions. Finally, both the experimental results and theoretical analysis confirm the robustness, potential, and validity of our method across multiple HSI datasets.},
  archive      = {J_KBS},
  author       = {Tianqi Gao and Maoguo Gong and Xiangming Jiang and Yue Zhao and Hao Liu and Yan Pu},
  doi          = {10.1016/j.knosys.2025.113408},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113408},
  shortjournal = {Knowl. Based Syst.},
  title        = {A non-local sparse unmixing based hyperspectral change detection with unsupervised deep clustering},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering personalized document partition via intention-aware deep document clustering. <em>KBS</em>, <em>317</em>, 113407. (<a href='https://doi.org/10.1016/j.knosys.2025.113407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of diverse text mining applications, users are increasingly seeking personalized document clustering results. However, existing methods have two main issues. The first is the failure to consider a user grouping intention during document representation learning, which hinders the generation of intention-aware representations. The second issue is the absence of user grouping intention guidance in the clustering process, which makes the clustering result difficult to meet the individual needs of users. In this paper, we propose an intention-aware deep personalized document clustering (IPDC) model, that considers user grouping preferences from the two aspects of representation learning and clustering, to discover document partitions. Specifically, we designed the intention-aware contrastive auto-encoder (ICAE) and intent-regularized document clustering (IDC) modules. ICAE aimed to learn intention-aware representations by considering both the document’s own characteristics, guided by the auto-encoder framework, and user grouping intention, captured through an intention-guided contrastive learning strategy. IDC aims to guide the clustering process based on user grouping intention by designing an intention-regularized strategy. Through comprehensive experiments, we demonstrate that our proposed model consistently outperforms state-of-the-art techniques. Notably, we show that different grouping intentions in the same dataset generate different cluster results.},
  archive      = {J_KBS},
  author       = {Le Xu and Ruina Bai and Ruizhang Huang and Lina Ren and Yongbin Qin},
  doi          = {10.1016/j.knosys.2025.113407},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113407},
  shortjournal = {Knowl. Based Syst.},
  title        = {Discovering personalized document partition via intention-aware deep document clustering},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pruning-enabled dynamic influence maximization using antlion optimization. <em>KBS</em>, <em>317</em>, 113406. (<a href='https://doi.org/10.1016/j.knosys.2025.113406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is a widely studied topic in social network analysis that gives a reliable basis to select top nodes (seed set) to maximize the influence. IM has several real-world applications, such as advertising, political campaigns, profit maximization, etc. Existing literature suggests several algorithms for IM, including nature-inspired algorithms. In addition, most of the algorithms in IM consider static social networks. Existing studies show that antlion optimization (ALO) is known for its exploration abilities, and existing work in IM does not utilize it. Further, overlap influence reduces the overall influence in the network. To address the mentioned issues, for dynamic social networks, the proposed work suggests a novel algorithm (DALO-IM) for IM using ALO. The suggested strategy utilizes the previous computation during the dynamic traversal of the network. Further, this work suggests a prune-based strategy to overcome the problem of overlap influence. The experiments were conducted on eight datasets. The result analysis shows that the influence using the proposed algorithm is higher than the top-performing benchmark algorithm. Furthermore, this work conducted the ablation study to show the effectiveness of the suggested pruning strategy.},
  archive      = {J_KBS},
  author       = {Sunil Kumar Meena and Shashank Sheshar Singh and Kuldeep Singh},
  doi          = {10.1016/j.knosys.2025.113406},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113406},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pruning-enabled dynamic influence maximization using antlion optimization},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERD-net: Modeling entity and relation dynamics for temporal knowledge graph reasoning. <em>KBS</em>, <em>317</em>, 113404. (<a href='https://doi.org/10.1016/j.knosys.2025.113404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) has garnered significant attention and applications due to its immense potential and impact in event prediction. Existing approaches primarily focus on learning low-dimensional embeddings of entities and relations to predict valid triples. Despite notable advancements, these methods face challenges such as inadequate modeling of relation dynamics and limited exploration of non-repeated patterns. To address these issues, we propose the Entity and Relation Dynamic representation learning Network (ERD-Net), a novel framework that combines dynamic representation learning with a copy-generation mechanism to enhance TKG reasoning. ERD-Net begins by learning intrinsic embeddings for entities and relations, capturing their time-invariant properties. These embeddings are subsequently frozen during the dynamic learning phase to ensure stability. In the dynamic representation learning stage, we extend beyond entity dynamics to explore relation dynamics, distinguishing between global and local categories to evaluate their distinct contributions. Furthermore, a copy-generation mechanism is introduced in the decoder, enabling simultaneous modeling of both historical repeated patterns and novel non-repeated patterns. Comprehensive experiments on public benchmarks validate the efficacy of our approach. The results demonstrate that ERD-Net achieves state-of-the-art performance in TKG reasoning by effectively integrating dynamic representation learning with copy-generation mechanisms. Notably, our findings reveal that improving the prediction of non-repeated patterns can significantly enhance performance, highlighting a promising direction for future research in TKG reasoning.},
  archive      = {J_KBS},
  author       = {Longquan Liao and Linjiang Zheng and Fengwen Chen and Jiaxing Shang and Xu Li and Wengang Li},
  doi          = {10.1016/j.knosys.2025.113404},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113404},
  shortjournal = {Knowl. Based Syst.},
  title        = {ERD-net: Modeling entity and relation dynamics for temporal knowledge graph reasoning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised sentence-based aspect category and sentiment classification. <em>KBS</em>, <em>317</em>, 113403. (<a href='https://doi.org/10.1016/j.knosys.2025.113403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis extracts the sentiment of content creators, enabling users to easily gain valuable insights from such data. Most existing methods rely on supervised learning approaches using labeled data. However, the retrieval of such labeled training data is difficult and expensive, especially for new domains and/or languages. This work focuses on simultaneously detecting aspect categories and sentiment polarities for a given sentence in a weakly-supervised setting. Two methods are proposed that combine an unsupervised labeling algorithm with a neural network architecture. The first proposed two-step model (SB-ASC) takes seed sentences as input for the labeling algorithm. By leveraging the power of pre-trained Sentence-BERT embeddings, the method is able to understand the contextual meaning of sentences to create a high-quality labeled dataset. This dataset is used by a class imbalance-robust BERT-based neural network that jointly learns latent features of aspect categories and the corresponding sentiment. The second proposed method (WB-ASC) uses the same neural network structure but takes seed words instead of seed sentences as input for the labeling algorithm. We conclude that SB-ASC outperforms WB-ASC as well as baselines and state-of-the-art weakly-supervised methods for aspect sentiment detection, achieving F1 scores for aspect category detection of 71.35%, 86.99%, and 73.86%, and F1 scores for sentiment classification of 89.24%, 89.98%, and 75.58% for the SemEval 2016 restaurant-5, restaurant-3, and laptop datasets, respectively. Furthermore, using domain-specific contextual language models boosts performance.},
  archive      = {J_KBS},
  author       = {Olaf Wallaart and Flavius Frasincar and Finn van der Knaap},
  doi          = {10.1016/j.knosys.2025.113403},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113403},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly-supervised sentence-based aspect category and sentiment classification},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine and deep learning for the prediction of nutrient deficiency in wheat leaf images. <em>KBS</em>, <em>317</em>, 113400. (<a href='https://doi.org/10.1016/j.knosys.2025.113400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nutrient deficiency in wheat plants can lead to diseases and important losses in yield. These diseases can be visually detected on wheat leaf images. We perform the image classification as nutrient controlled or deficient, using a collection of 57 machine learning classifiers programmed in 4 different programming languages, applied on color texture features extracted from the images. We also use other 90 methods under the Caret automated R classification framework on the same features. Furthermore, we use 62 deep learning networks under three frameworks applied on the leaf images in three settings: trained from the scratch, fine-tuning of pretrained networks and classification of deep and shallow features extracted by deep networks. The radial basis function (RBF) neural network achieves the best performance, with kappa and accuracy of 57% and 81.2%, and with a low false positive rate (11.1%), while pretrained deep networks and classification of shallow features achieve 40% and 47%, respectively. Since nutrient deficiency is a continuous concept, ranging from 0% to 100%, and a sharp categorization into controlled and deficient may always be relative, these results identify the RBF network as an accurate approach for the detection of nutrient deficiency in wheat leaves.},
  archive      = {J_KBS},
  author       = {Manisha Sanjay Sirsat and Diego Isla-Cernadas and Eva Cernadas and Manuel Fernández-Delgado},
  doi          = {10.1016/j.knosys.2025.113400},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113400},
  shortjournal = {Knowl. Based Syst.},
  title        = {Machine and deep learning for the prediction of nutrient deficiency in wheat leaf images},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoSD: Collaborative stance detection with contrastive heterogeneous topic graph learning. <em>KBS</em>, <em>317</em>, 113399. (<a href='https://doi.org/10.1016/j.knosys.2025.113399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stance detection seeks to identify the viewpoints of individuals either in favor or against a given target or a controversial topic. Current advanced neural models for stance detection typically employ fully parametric softmax classifiers. However, these methods suffer from several limitations, including lack of explainability, insensitivity to the latent data structure, and unimodality, which greatly restrict their performance and applications. To address these challenges, we present a novel collaborative stance detection framework called (CoSD) which leverages contrastive heterogeneous topic graph learning to learn topic-aware semantics and collaborative signals among texts, topics, and stance labels for enhancing stance detection. During training, we construct a heterogeneous graph to structurally organize texts and stances through implicit topics via employing latent Dirichlet allocation. We then perform contrastive graph learning to learn heterogeneous node representations, aggregating informative multi-hop collaborative signals via an elaborate Collaboration Propagation Aggregation (CPA) module. During inference, we introduce a hybrid similarity scoring module to enable the comprehensive incorporation of topic-aware semantics and collaborative signals for stance detection. Extensive experiments on two benchmark datasets demonstrate the state-of-the-art detection performance of CoSD, verifying the effectiveness and explainability of our collaborative framework.},
  archive      = {J_KBS},
  author       = {Yinghan Cheng and Qi Zhang and Chongyang Shi and Liang Xiao and Shufeng Hao and Liang Hu},
  doi          = {10.1016/j.knosys.2025.113399},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113399},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoSD: Collaborative stance detection with contrastive heterogeneous topic graph learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph contrastive learning via coarsening: A time and memory efficient approach. <em>KBS</em>, <em>317</em>, 113398. (<a href='https://doi.org/10.1016/j.knosys.2025.113398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL), training the graph neural networks encoder by contrasting different views in a self-supervised way, has demonstrated remarkable efficacy in graph representation learning. However, most existing GCL approaches tend to be time- and memory-consuming because they require extensive node contrasts across the entire original graph. To address this, we present CGCL, a fast graph contrastive learning approach based on graph coarsening. It aims to train an encoder on coarse graphs with lower time and memory costs while performing comparably to one trained on the original graph. Specifically, we coarsened the original graph into a series of highly-informative, smaller-tractable coarse graphs to reduce their scale. We then designed a multi-scale contrastive learning paradigm in the multi-granularity space, incorporating coarse-coarse and coarse-fine contrast to efficiently capture global and hierarchical information. CGCL accelerates model training while ensuring that the learned node representations are comprehensive. Extensive experiments towards node classification on seven real world datasets demonstrate that CGCL can achieve competitive performance with lower time and memory costs. In particular, on the ogbn-mag dataset, compared to state-of-the-art methods, CGCL reduces time consumption by up to 89.06% and memory usage by up to 50.56%, while maintaining comparable performance.},
  archive      = {J_KBS},
  author       = {Ziwei Du and Tao Wang and Zhen Yang and Jie Chen and Zhen Duan and Shu Zhao},
  doi          = {10.1016/j.knosys.2025.113398},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113398},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph contrastive learning via coarsening: A time and memory efficient approach},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing code domain insights: Enhancing programming knowledge tracing with large language models. <em>KBS</em>, <em>317</em>, 113396. (<a href='https://doi.org/10.1016/j.knosys.2025.113396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) evaluates students’ mastery of knowledge by analyzing their historical interactions with exercises and predicts their performance on subsequent tasks. Although traditional KT methods have begun to focus on the assessment of programming skills, they are limited by the bottleneck of manually annotating knowledge concepts (KCs) and the inadequacy of constructing relationships between these points. To address this issue, we propose a K nowledge T racing method E nhanced by the powerful C ode insight capabilities of Large Language Models (CEKT) . Specifically, we designed three different prompt tuning strategies for Large Language Models (LLMs) to comprehensively construct Q-matrices that cover KCs and their relationships across various programming domains and exercises. Additionally, we developed a knowledge graph integrating three dimensions to express the complex relationships between KCs in a fine-grained manner, thereby providing a more accurate assessment of students’ knowledge mastery. Furthermore, we established a graph attention network among KCs to promote interaction between representations of similar syntactic KCs, enhancing the inference capability of students’ programming knowledge state and the effectiveness of KT. Through this approach, we achieved high-quality and interpretable knowledge state inference and demonstrated outstanding performance in predicting student outcomes. Our work highlights a potential future research direction for prompt-tuned LLMs in the KT domain, emphasizing high interpretability and efficiency. For broader research purposes, we have prepared to release our data and source code at https://github.com/xinjiesun-ustc/CEKT , encouraging further innovation in this field.},
  archive      = {J_KBS},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Shuanghong Shen and Lina Yang and Hui Li},
  doi          = {10.1016/j.knosys.2025.113396},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113396},
  shortjournal = {Knowl. Based Syst.},
  title        = {Harnessing code domain insights: Enhancing programming knowledge tracing with large language models},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating signal pairing evaluation metrics with deep learning for wind power forecasting through coupled multiple modal decomposition and aggregation. <em>KBS</em>, <em>317</em>, 113394. (<a href='https://doi.org/10.1016/j.knosys.2025.113394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate prediction of wind power is critical for achieving dynamic equilibrium in economic energy scheduling, storage allocation, and generation planning within power systems. To address the challenges of excessive modal decomposition components and low prediction efficiency resulting from the chaotic, intermittent, and non-stationary nature of wind power signals, a sophisticated prediction method integrating aggregate modal decomposition with a hybrid network model is proposed. Preliminarily, the wind power sequence is decomposed into several primary components using CEEMDAN, and these components are paired to form primary aggregation components, excluding the main trend component. Subsequently, the components of the primary aggregation that exceed the critical threshold of relative sample entropy are re-aggregated and re-decomposed by VMD. Finally, the primary trend component is combined with the prediction of LSTM, the primary aggregation components are estimated through the integration of BiLSTM, and the secondary decomposition components are measured by Attention-BiLSTM. These predictive values are then reconstructed to obtain wind power forecasts. Experimental analysis on a wind power dataset has shown that the proposed approach outperforms other models, significantly enhancing prediction efficiency and accuracy.},
  archive      = {J_KBS},
  author       = {Yunbing Liu and Jiajun Dai and Guici Chen and Qianlei Cao and Feng Jiang and Wenbo Wang},
  doi          = {10.1016/j.knosys.2025.113394},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113394},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating signal pairing evaluation metrics with deep learning for wind power forecasting through coupled multiple modal decomposition and aggregation},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMDConv: Fast multi-attention dynamic convolution via speed-accuracy trade-off. <em>KBS</em>, <em>317</em>, 113393. (<a href='https://doi.org/10.1016/j.knosys.2025.113393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial convolution is fundamental in constructing deep Convolutional Neural Networks (CNNs) for visual recognition. While dynamic convolution enhances model accuracy by adaptively combining static kernels, it incurs significant computational overhead, limiting its deployment in resource-constrained environments such as federated edge computing. To address this, we propose Fast Multi-Attention Dynamic Convolution (FMDConv), which integrates input attention, temperature-degraded kernel attention, and output attention to optimize the speed-accuracy trade-off. FMDConv achieves a better balance between accuracy and efficiency by selectively enhancing feature extraction with lower complexity. Furthermore, we introduce two novel quantitative metrics, the Inverse Efficiency Score and Rate-Correct Score, to systematically evaluate this trade-off. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that FMDConv reduces the computational cost by up to 49.8% on ResNet-18 and 42.2% on ResNet-50 compared to prior multi-attention dynamic convolution methods while maintaining competitive accuracy. These advantages make FMDConv highly suitable for real-world, resource-constrained applications.},
  archive      = {J_KBS},
  author       = {Tianyu Zhang and Fan Wan and Haoran Duan and Kevin W. Tong and Jingjing Deng and Yang Long},
  doi          = {10.1016/j.knosys.2025.113393},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113393},
  shortjournal = {Knowl. Based Syst.},
  title        = {FMDConv: Fast multi-attention dynamic convolution via speed-accuracy trade-off},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FSPDF: Few-shot learning with progressive dual-domain feature fusion via self-supervised learning. <em>KBS</em>, <em>317</em>, 113389. (<a href='https://doi.org/10.1016/j.knosys.2025.113389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) aims to develop models that can generalise to new tasks using only a few labelled examples. Recently, feature fusion methods have achieved great success in FSL by aggregating features from different sources. However, these methods generally rely on efficient feature extractors to capture the intrinsic patterns of the data and focus solely on single-domain spatial features. In this paper, we propose a progressive dual-domain feature fusion strategy via self-supervised learning (FSPDF). FSPDF consists of dual-domain feature learning (DFL) and dual-domain feature fusion (DFF) and leverages progressive dual-domain fusion to address the issue of insufficient feature representation. The DFL strategy obtains an efficient feature extractor through a dual-domain self-supervised module, optimising generalisation to new data and fully extracting dual-domain features. The DFF strategy leverages the previously obtained feature extractor and incorporates discrete wavelet transform to enrich and fuse dual-domain features, providing a more diverse feature representation. The effectiveness of FSPDF is demonstrated across three commonly used benchmark FSL datasets. For instance, in the 5-way 1-shot setting, FSPDF improves performance by 3.47% on CUB-200-2011 and 1.05% on miniImageNet. Code is available at https://github.com/fhqxa/FSPDF .},
  archive      = {J_KBS},
  author       = {Dongqing Li and Jie Jin and Linhua Zou and Hong Zhao},
  doi          = {10.1016/j.knosys.2025.113389},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113389},
  shortjournal = {Knowl. Based Syst.},
  title        = {FSPDF: Few-shot learning with progressive dual-domain feature fusion via self-supervised learning},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Document-level event extraction from italian crime news using minimal data. <em>KBS</em>, <em>317</em>, 113386. (<a href='https://doi.org/10.1016/j.knosys.2025.113386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction from unstructured text is a critical task in natural language processing, often requiring substantial annotated data. This study presents an approach to document-level event extraction applied to Italian crime news, utilizing large language models (LLMs) with minimal labeled data. Our method leverages zero-shot prompting and in-context learning to effectively extract relevant event information. We address three key challenges: (1) identifying text spans corresponding to event entities, (2) associating related spans dispersed throughout the text with the same entity, and (3) formatting the extracted data into a structured JSON. The findings are promising: LLMs achieve an F1-score of approximately 60% for detecting event-related text spans, demonstrating their potential even in resource-constrained settings. This work represents a significant advancement in utilizing LLMs for tasks traditionally dependent on extensive data, showing that meaningful results are achievable with minimal data annotation. Additionally, the proposed approach outperforms several baselines, confirming its robustness and adaptability to various event extraction scenarios.},
  archive      = {J_KBS},
  author       = {Giovanni Bonisoli and David Vilares and Federica Rollo and Laura Po},
  doi          = {10.1016/j.knosys.2025.113386},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113386},
  shortjournal = {Knowl. Based Syst.},
  title        = {Document-level event extraction from italian crime news using minimal data},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet-based dual discriminator GAN for image super-resolution. <em>KBS</em>, <em>317</em>, 113383. (<a href='https://doi.org/10.1016/j.knosys.2025.113383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution (SR) is a multi-objective optimization problem that requires a balance between fidelity and perceptual quality. Existing SR methods often overemphasize fidelity or perceptual quality at the expense of the other, leading to blurred results or artifacts. To address both fidelity and perceptual quality comprehensively, we propose the wavelet-based dual discriminator SR (WDDSR) model. WDDSR achieves a superior perceptual-distortion trade-off by optimizing the global consistency and local details. Specifically, WDDSR contains a wavelet-domain semantic discriminator ( D s e m a n t i c ) and texture discriminator ( D t e x t u r e ). For D s e m a n t i c , we propose the semantic-guided wavelet attention block that leverages semantic information from ground truth images for global guidance to ensure global semantic consistency and structural coherence. For D t e x t u r e , we propose the spatial-wavelet texture extraction block, which adaptively captures texture and edge features across multiple scales and directions, enhancing local detail restoration and reducing artifacts. In addition, we redesign the loss function for WDDSR to better facilitate the training process. We compared WDDSR with existing state-of-the-art (SOTA) GAN-based SR methods for classical and real-world SR tasks. Extensive experiments were conducted to validate the effectiveness of the proposed method. In classical SR tasks, the perceptual-oriented WDDSR outperformed the SOTA approach (SeD) in terms of the LPIPS by 5% on average, and the fidelity-oriented WDDSR outperformed the second-best approach (PDASR) in terms of the PSNR by 0.048 dB on average. In real-world SR tasks, WDDSR also achieved comparable or even superior performance. Moreover, our method does not introduce additional computational overhead during the inference process.},
  archive      = {J_KBS},
  author       = {Yifan Xu and You Zhou and Hongbin Ma and Haitao Yang and Haoyu Wang and Sailong Zhang and Xiaowei Li},
  doi          = {10.1016/j.knosys.2025.113383},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113383},
  shortjournal = {Knowl. Based Syst.},
  title        = {Wavelet-based dual discriminator GAN for image super-resolution},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularized autoencoder based discriminative least square regression for image classification. <em>KBS</em>, <em>317</em>, 113380. (<a href='https://doi.org/10.1016/j.knosys.2025.113380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of its efficient performance, least squares regression (LSR), which utilizes a discriminative projection for image classification, has gained significant attention. However, these two deficiencies limit its performance in real-world applications. Initially, existing LSR-based methods only consider global or local data, thereby reducing the robustness of the model. Secondly, the similarities within the same class are often neglected. Thus, we propose a regularized autoencoder based discriminative least squares regression (RADLSR) method to improve image classification. First, we integrate label relaxation LSR with an encoder-decoder framework to preserve global information in projection learning. Second, we consider the local relationship of the data as a complement to the relaxed autoencoder, helping to explore the complete structural information. Finally, we directly constrain the relaxed labels to be similar within the same class and incorporate the ε -dragging technique. This approach enhances the intra-class compactness and inter-class separability of the projected samples, resulting in a robust and highly discriminative model In addition, we develop an iteration optimization algorithm based on the alternating direction method of multipliers (ADMM) to solve RADLSR. Experiments on various benchmark datasets demonstrated that our RADLSR method can achieve superior classification results compared to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jianqiang Song and Zhonghua Liu and Zhao Dong and Suling Gao and Junping Yang and Fuge Zhao},
  doi          = {10.1016/j.knosys.2025.113380},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113380},
  shortjournal = {Knowl. Based Syst.},
  title        = {Regularized autoencoder based discriminative least square regression for image classification},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention driven long short term memory based multi-attribute feature learning for shot boundary detection. <em>KBS</em>, <em>317</em>, 113379. (<a href='https://doi.org/10.1016/j.knosys.2025.113379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shot boundary detection is a crucial task in video analysis because it assistsin identifying the transitions between different shots that are fundamental for understanding video structure, editing, and content retrieval. Traditional methods for shot boundary detection often struggle to capture both subtle and complex changes in visual appearance and motion, leading to inaccurate or incomplete detection. This research introduces a novel shot boundary detection method using Siamese Style Networks with Canonical Appearance Pooling (SSN CAP), Motion Squeeze Network (MSN), and Attention-based Dilated LSTM (AtDLSTM). SSN CAP improves appearance feature extraction by using canonical appearance pooling, which preserves fine-grained features. MSN is used to extract motion features from keyframes, resulting in a thorough comprehension of dynamic variations. AtDLSTM combines dilated LSTM and attention mechanisms, significantly improving shot boundary detection accuracy. Experimental results demonstrate the superiority of the proposed method, achieving 100 % accuracy across various shot types (fade in, fade out, dissolve, cut) compared to other methods like Long Short Term Memory (LSTM), Recurrent Neural Network (RNN), and Deep CNN (DCNN). The integrated technique takes advantage of the strengths of appearance and motion features, resulting in a reliable solution for precise shot boundary detection in video processing.},
  archive      = {J_KBS},
  author       = {Swati ChaitandasHadke ( PhD Scholar ) and Ravi Mishra ( Professor ) and Rushikesh Tukaramji Bankar ( Assistant Professor ) and Sharda Amardas Chhabria ( Associate Professor ) and Shrikant Prakash Chavate ( Assistant Professor ) and Latika Shyam Pinjarkar ( Associate Professor )},
  doi          = {10.1016/j.knosys.2025.113379},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113379},
  shortjournal = {Knowl. Based Syst.},
  title        = {An attention driven long short term memory based multi-attribute feature learning for shot boundary detection},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative multi-view collaborative optimization framework for weighted naive bayes. <em>KBS</em>, <em>317</em>, 113378. (<a href='https://doi.org/10.1016/j.knosys.2025.113378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite its simplicity and efficiency, Naive Bayes (NB) assumes that attributes are conditionally independent, which may limit its performance in some real-world applications. Existing methods construct label views to capture latent data characteristics, and the class probabilities estimated from these views are equally fused to predict the class label for each instance. However, each view contributes differently to classification due to varying information content. Thus, we propose an innovative Multi-view Collaborative Optimization framework for Weighted Naive Bayes (MCOWNB). In MCOWNB, multiple Super Parent-One-Dependence Estimators (SPODEs) and K-Nearest Neighbors (KNN) classifiers are used to predict class labels, creating two label views that reveal latent classification information. These views are then concatenated with the raw data to generate an augmented view. Next, to reduce the risk of overfitting during the fusion process, we incorporate a regularization term based on data characteristics. Finally, we established a multi-view collaborative optimization framework consisting of local optimization module, view assessment module, and global optimization module. This framework dynamically adjusts the weights of each view in the fusion process based on the evaluation results of local optimization for each view. Extensive experiments have demonstrated that MCOWNB outperforms other existing state-of-the-art NB weighting algorithms.},
  archive      = {J_KBS},
  author       = {Xiaoliang Zhou and Yongli Wang and Li Zhang and Anqi Huang and Xiaoli Wang},
  doi          = {10.1016/j.knosys.2025.113378},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113378},
  shortjournal = {Knowl. Based Syst.},
  title        = {An innovative multi-view collaborative optimization framework for weighted naive bayes},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HKMCNN: Heat kernel mesh-based convolutional neural networks. <em>KBS</em>, <em>317</em>, 113375. (<a href='https://doi.org/10.1016/j.knosys.2025.113375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have achieved remarkable results in various computer vision and pattern recognition applications. However, in computer graphics and geometry processing, the focus is on non-Euclidean structured meshed surfaces. Since CNNs operate based on Euclidean domains, the fundamental operations of CNNs, such as convolution and pooling, are not well defined in non-Euclidean domains. To address this issue, we propose a novel mesh representation named Heat Kernel Mesh (HKM), which utilizes the heat diffusion on the non-Euclidean domain. The HKM represents a meshed surface as a spatio-temporal graph signal, sampled on the edges of the mesh at each time interval with a Euclidean-like structure. Furthermore, we propose the Heat Kernel Mesh-Based Convolutional Neural Network (HKMCNN), where convolution, pooling, and attention mechanism are designed based on the property of our representation and operate on edges. For the fine-grained classification, we propose distance Heat Kernel Mesh (dHKM) that can identify discriminant features with the HKMCNN to represent a mesh. Extensive experiments on mesh classification and segmentation demonstrate the effectiveness and efficiency of the proposed HKMCNN.},
  archive      = {J_KBS},
  author       = {Tingting Li and Yunhui Shi and Junbin Gao and Jin Wang and Baocai Yin},
  doi          = {10.1016/j.knosys.2025.113375},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113375},
  shortjournal = {Knowl. Based Syst.},
  title        = {HKMCNN: Heat kernel mesh-based convolutional neural networks},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fish disease detection in aquaculture using pseudo hamiltonian neural network optimized with philippine eagle optimization algorithm. <em>KBS</em>, <em>317</em>, 113374. (<a href='https://doi.org/10.1016/j.knosys.2025.113374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nutrition security in aquaculture is seriously threatened by fish illnesses. It is still difficult to detect sick fish in aquaculture at an early stage due to a lack of infrastructure. To identify the contaminated fish as soon as possible to stop the sickness from spreading is most essential. To overcome these complications, Fish Disease Detection in Aquaculture using Pseudo Hamiltonian Neural network Optimized with Philippine Eagle Optimization Approach (FDD-PHNN-PEOA) are proposed. Initially, input images are gathered from the Salmon Scan Dataset. Afterward, images are given to pre-processing. In pre-processing by using Deep Attentional Guided Image Filtering (DAGIF) it magnify, resize, converts color space and enhances input images. After that, the pre-processed images undergo segmentation process. Here, it is segmenting the infected area of the fishes by utilizing Unpaired Multi-View Graph Clustering (UMVGC). The segmented image is fed to the feature extraction process. Here, statistical features, like variance, mean, standard deviation and grey-level co-occurrence matrix features includes contrast, correlation, energy is extracted based Synchro spline-kernelled chirplet extracting transform (SKCET). Finally, the extracted features are given to Pseudo Hamiltonian Neural Network (PHNN) optimized by Philippine Eagle Optimization Algorithm (PEOA) for detecting fish disease as Fresh Salmon fish and Infected Salmon fish of the images. The proposed FDD-PHNN-PEOA approach is implemented in Python. The performance of the FDD-PHNN-PEOA approach attains 21.51 %, 52.38 %, and 21.51 % higher accuracy, 28 %, 50 %, and 21.51 % higher precision and 15.85 %, 23.37 %, and 23.37 % low false negative rate when compared to the existing techniques.},
  archive      = {J_KBS},
  author       = {Prasanna kumar M and Saravana Kumar K and Karthikeyan P and Sureshkumar C},
  doi          = {10.1016/j.knosys.2025.113374},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113374},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fish disease detection in aquaculture using pseudo hamiltonian neural network optimized with philippine eagle optimization algorithm},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent recurrent neural network driven secured routing protocol for vehicular ad hoc networks. <em>KBS</em>, <em>317</em>, 113371. (<a href='https://doi.org/10.1016/j.knosys.2025.113371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Ad hoc Networks (VANETs) that are deliberated as a subgroup of Mobile Ad hoc Networks (MANETs) can be applied in the field of transportation, especially in Intelligent Transportation Systems (ITS). This work not only considers security but also provides optimal density aware routing protocol to overcome the disconnection problem. Initially, Ensemble long short-term memory (ELSTM) is proposed to identify malicious nodes by considering trust values and other node parameters like data forwarding rate, residual energy, packet loss factor coverage, and link quality. The proposed ELSTM improves generalization, lowers false positives, and combines several LSTM models to increase the accuracy and robustness of malicious node identification through the use of an ensemble approach. Furthermore, it uses incremental learning to ensure flexibility in varying network conditions, enabling model updates without the need for full retraining. The proposed protocol employs a coati optimization algorithm for effective routing after identifying the malicious node using ELSTM. This algorithm reduces the frequency of link disconnections in VANET by optimizing the trust value of vehicles, degree of connection, and shortest distance as the primary objective of routing. The proposed work is executed in the NS-2.35 tool and verified with simulated experiments over state-of-the-art methods. The packet delivery ratio of the proposed routing protocol method is increased to 81%, and the end-to-end delay is reduced to 0.17sec. Additionally, the suggested methods successfully identify the malicious node with an accuracy of 98.6%, which is empirically demonstrated by matching with existing methods.},
  archive      = {J_KBS},
  author       = {K. Bagirathan and N. Saravanan and K. Vijayabhaskar and Sivasankar C},
  doi          = {10.1016/j.knosys.2025.113371},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113371},
  shortjournal = {Knowl. Based Syst.},
  title        = {An intelligent recurrent neural network driven secured routing protocol for vehicular ad hoc networks},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask learning network with interactive fusion for surgical instrument segmentation. <em>KBS</em>, <em>317</em>, 113370. (<a href='https://doi.org/10.1016/j.knosys.2025.113370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of surgical robots has enhanced the capabilities of minimally invasive surgery by providing surgeons with increased precision, dexterity, and control during operations. Accurate segmentation of surgical instruments in endoscopic images is critical to achieving these goals, as it allows surgical robots to precisely identify the instrument position and orientation, thereby reducing the risk of errors and ensuring safer and more successful procedures. However, the complexity of the surgical environment poses significant challenges to the accurate segmentation of surgical instruments, such as mirror reflections of surgical instruments, instrument occlusions, and motion disturbances. To address these issues, this paper presents an innovative multitask learning network with interactive fusion to increase the automatic segmentation accuracy and robustness of surgical instruments in endoscopic images during minimally invasive surgeries. Specifically, to effectively handle the diverse lighting conditions and dynamic environments encountered during surgeries, the proposed model leverages a combination of transformer and convolutional neural network (CNN) architectures to effectively extract both the global and local features of surgical instruments. Moreover, to enhance the boundary perception capability of surgical instruments within the context of endoscopic images, the proposed model incorporates an attention-guided multitask learning structure consisting of a main decoder focused on segmenting the instruments and an auxiliary edge decoder aimed at delineating the boundaries of the instruments. In addition, a dual attention enhancement (DAE) block is introduced, which employs attention mechanisms in different directions to enhance the network’s focus on key features while suppressing irrelevant features. Furthermore, given the diverse nature of surgical tools and their interactions within the surgical site, an atrous pyramid attention (APA) block is introduced to improve the network’s adaptability to the various shapes and sizes of surgical instruments. Experimental evaluations on two surgical instrument datasets demonstrate that the proposed model achieves superior segmentation performance, validating its effectiveness and highlighting its potential to advance the field of robotic-assisted minimally invasive surgery.},
  archive      = {J_KBS},
  author       = {Mengqiu Song and Yunkai Li and Yanhong Liu and Lei Yang},
  doi          = {10.1016/j.knosys.2025.113370},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113370},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multitask learning network with interactive fusion for surgical instrument segmentation},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProNet: A contrastive propagation network for multimodal lifelong clustering. <em>KBS</em>, <em>317</em>, 113349. (<a href='https://doi.org/10.1016/j.knosys.2025.113349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in real-world applications are often presented in diverse formats, providing a rich and comprehensive description of instances. Multimodal Clustering (MMC) mines and integrates the complex correlations among these modalities in an unsupervised manner to improve clustering performance. With numerous real-world applications, the number of modalities has gradually increased over time. However, most existing MMC methods focus on scenarios with a fixed number of modalities and cannot cope with the incremental multimodal data. Considering the rich inter-modal correlations and potential knowledge flows in multimodal data, we propose a contrastive Propagation Network (ProNet) for multimodal lifelong clustering. It jointly considers Global Correlation Reservation (GCR) among all modalities and Local Knowledge Transfer (LKT) between neighboring modalities within a unified framework. When a new modality arrives, we contrast the feature of the new modality with its global neighbors in all existing modalities to achieve GCR, which is realized by maintaining a dynamic feature library. Next, we design a self-supervised distillation strategy to enable the previous modality to guide the learning of the new modality, which implies knowledge transfer between neighboring modalities. The cooperation of GCR and LKT ensures that the model efficiently performs the clustering task for each new modality while continuously learning and accumulating inter-modal correlations. The experimental results on multiple real-world datasets demonstrate that ProNet outperforms many state-of-the-art MMC methods.},
  archive      = {J_KBS},
  author       = {Yiqiao Mao and Zirui Hu and Qiang Guo and Xiaoqiang Yan and Yangdong Ye},
  doi          = {10.1016/j.knosys.2025.113349},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113349},
  shortjournal = {Knowl. Based Syst.},
  title        = {ProNet: A contrastive propagation network for multimodal lifelong clustering},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESTformer: Transformer utilising spatiotemporal dependencies for electroencephalogram super-resolution. <em>KBS</em>, <em>317</em>, 113345. (<a href='https://doi.org/10.1016/j.knosys.2025.113345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Towards practical applications of Electroencephalography (EEG), lightweight acquisition devices garner significant attention. However, EEG channel selection methods are commonly data-sensitive and cannot establish a unified sound paradigm for EEG acquisition devices. Through reverse conceptualisation, we formulated EEG applications in an EEG super-resolution (SR) manner, but suffered from high computation costs, extra interpolation bias, and few insights into spatiotemporal dependency modelling. To this end, we propose ESTformer, an EEG SR framework that utilises spatiotemporal dependencies based on the transformer. ESTformer applies positional encoding methods and a multihead self-attention mechanism to the space and time dimensions, which can learn spatial structural correlations and temporal functional variations. ESTformer, with the fixed mask strategy, adopts a mask token to upsample low-resolution (LR) EEG data in the case of disturbance from mathematical interpolation methods. On this basis, we designed various transformer blocks to construct a spatial interpolation module (SIM) and a temporal reconstruction module (TRM). Finally, ESTformer cascades the SIM and TRM to capture and model the spatiotemporal dependencies for EEG SR with fidelity. Extensive experimental results on two EEG datasets show the effectiveness of ESTformer against previous state-of-the-art methods, demonstrating the versatility of the Transformer for EEG SR tasks. The superiority of the SR data was verified in an EEG-based person identification and emotion recognition task, achieving a 2% to 38% improvement compared with the LR data at different sampling scales.},
  archive      = {J_KBS},
  author       = {Dongdong Li and Zhongliang Zeng and Zhe Wang and Hai Yang},
  doi          = {10.1016/j.knosys.2025.113345},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113345},
  shortjournal = {Knowl. Based Syst.},
  title        = {ESTformer: Transformer utilising spatiotemporal dependencies for electroencephalogram super-resolution},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized fingerprint crime detection using robust deformed convolutional neural network for 5G network secure smart cities. <em>KBS</em>, <em>317</em>, 113342. (<a href='https://doi.org/10.1016/j.knosys.2025.113342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint analysis plays an important role in forensic investigations, it assists law enforcement agencies in identifying suspects and solving criminal cases. With the advancement of deep learning and computer vision technologies, innovative approaches are continuously developed to improve the accuracy and efficiency of fingerprint crime detection systems. In this manuscript, Optimized Fingerprint Crime Detection using a Robust Deformed Convolutional Neural Network for 5 G network secure smart cities (FCD-RDCNN) is proposed. Here, the images are gathered from SokotoConventry dataset. Then the image is fed to the pre-processing phase. During the pre-processing phase, Sliding Innovation Filter (SIF) is used to standardize image sizes and conversion to tensors. The feature extraction process is done using Random Quantum Circuits Transform (RQCT). The extracted features are fed into Robust Deformed Convolutional Neural network (RDCNN) for classifying original images (OI) and forged images (FI). Sand Cat Swarm Optimization (SCSO) is used to enhance RDCNN for the classification of finger print crime detection. The proposed FCD-RDCNN is implemented in Python. The FCD-RDCNN is evaluated under some metrics: Accuracy, Precision, Recall, F1-score and Entropy. Finally, the performance of the proposed FCD-RDCNN technique achieves 15.17 %, 17.42 %, and 19.25 % better accuracy, 16.35 %, 18.62 % and 20.11 % better precision and 17.45 %, 18.72 % and 19.19 % better F1-score when compared to the existing models respectively.},
  archive      = {J_KBS},
  author       = {Dr. Krishnakumar K and Dr. Smitha G L and Dr. Gnana Soundari A and Dr. Dhanalakshmi R and Dr. Kesavan R},
  doi          = {10.1016/j.knosys.2025.113342},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113342},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized fingerprint crime detection using robust deformed convolutional neural network for 5G network secure smart cities},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharpening deep graph clustering via diverse bellwethers. <em>KBS</em>, <em>317</em>, 113322. (<a href='https://doi.org/10.1016/j.knosys.2025.113322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering has attracted increasing attention in data analysis recently, which leverages the topology structure and attributes of graph to divide nodes into different groups. Most existing deep graph clustering models, however, have compromised performance due to a lack of discriminative representation learning and adequate support for learning diverse clusters. To address these issues, we proposed a Diversity-promoting Deep Graph Clustering (DDGC) model that attains the two essential clustering principles of minimizing the intra-cluster variance while maximizing the inter-cluster variance. Specifically, DDGC iteratively optimizes the node representations and cluster centroids. First, DDGC maximizes the log-likelihood of node representations to obtain cluster centroids, which are subjected to a differentiable diversity regularization term to force the separation among clusters and thus increase inter-cluster variances. Moreover, a minimum entropy-based clustering loss is proposed to sharpen the clustering assignment distributions in order to produce compact clusters, thereby reducing intra-cluster variances. Extensive experimental results demonstrate that DDGC achieves state-of-the-art clustering performance and verifies the effectiveness of each component on common real-world datasets. Experiments also verify that DDGC can learn discriminative node representations and alleviate the over-smoothing issue.},
  archive      = {J_KBS},
  author       = {Peiyao Zhao and Xin Li and Yuangang Pan and Ivor W. Tsang and Mingzhong Wang and Lejian Liao},
  doi          = {10.1016/j.knosys.2025.113322},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113322},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sharpening deep graph clustering via diverse bellwethers},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Textual semantics enhancement adversarial hashing for cross-modal retrieval. <em>KBS</em>, <em>317</em>, 113303. (<a href='https://doi.org/10.1016/j.knosys.2025.113303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised cross-modal hashing seeks to embed rich semantic information into binary hash codes, thereby enhancing semantic discrimination. Despite substantial advancements in cross-modal semantic learning, two critical challenges remain: (1) the fine-grained semantic information inherent in individual words within text contents is underutilized; and (2) more efficient constraints are required to mitigate the distributional heterogeneity across modalities. To overcome these issues, we introduce a T extual S emantics E nhancement A dersarial H ashing method, abbreviated as TSEAH , aimed at further improving hashing retrieval performance. Our approach introduces an effective textual semantics enhancement strategy involving a Bag-of-Words Self-Attention (BWSA) mechanism, which accentuates fine-grained semantics from textual content. This mechanism facilitates the transfer of fine-grained semantic knowledge from texts to images. Furthermore, we incorporate an adversarial hashing strategy within the cross-modal hashing learning process to ensure semantic distribution consistency across different modalities. Importantly, our solution achieves impressive results without the need for complex visual-language pre-training models. Comparative evaluations across three commonly used datasets demonstrate that our method achieves outstanding average accuracy: 90.41 % on MIRFLICKR-25K, 82.86 % on NUW-SIDE, and 83.53 % on MS COCO, outperforming the state-of-the-art baselines by a significant margin ranging from 1.97 % to 2.51 % .},
  archive      = {J_KBS},
  author       = {Lei Zhu and Runbing Wu and Deyin Liu and Chengyuan Zhang and Lin Wu and Ying Zhang and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.113303},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113303},
  shortjournal = {Knowl. Based Syst.},
  title        = {Textual semantics enhancement adversarial hashing for cross-modal retrieval},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical mode decomposition with multivariable time series feature learning for QoS prediction. <em>KBS</em>, <em>317</em>, 113174. (<a href='https://doi.org/10.1016/j.knosys.2025.113174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, predicting quality of service (QoS) for Web services has been an essential topic in services computing. However, existing QoS prediction approaches typically treat each QoS record as a basic unit without taking the intrinsic properties of the time-series QoS records into account. In fact, a QoS time series is not a smooth distribution but rather a hybrid sequence with multiple frequency features. As a result, we propose AE-mLSTM, a hybrid QoS forecasting method that combines the empirical mode decomposition (EMD) model and the multivariable LSTM model. In addition, AE-mLSTM employs an attention mechanism for multi-task learning, which can learn the shared representation of different tasks and jointly predict the tasks of QoS and timing direction. Experiments conducted on two real-world datasets demonstrate that our approach outperforms several state-of-the-art QoS prediction methods.},
  archive      = {J_KBS},
  author       = {Yuqi Zhao and Bing Li and Jian Wang and Xiuqing Chen and Yiming Xiong and Zhen Zhang},
  doi          = {10.1016/j.knosys.2025.113174},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113174},
  shortjournal = {Knowl. Based Syst.},
  title        = {Empirical mode decomposition with multivariable time series feature learning for QoS prediction},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure data sharing framework with AESMO enabled key generation in consortium blockchain based E-government system. <em>KBS</em>, <em>317</em>, 113160. (<a href='https://doi.org/10.1016/j.knosys.2025.113160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information and Communication Technologies (ICT) has been rapidly utilized by the Electronic government (E-government) recently to deliver public services effectively and transparently to different entities and organizations. E-government preserves confidential data regarding citizens, business organizations and various other industries. The traditional E-government systems are centralized and they are easily exposed to a single point of failure. Moreover, the failure just affects the system in terms of both economically and socially. To enable a smart government, information must be distributed between governmental sections. Nonetheless, obstructing the attackers from acquiring confidential data ring is considered a huge obstacle. Hence, a safe and decentralized E-government system based on consortium blockchain advancement using Artificial Ecosystem Spider Monkey Optimization (AESMO)_based PrivPresKey Gen is introduced in this research for privacy-preserved data sharing. The protection system uses diverse security characteristics, such as encryption, hashing parameters, polynomials, and XOR to safeguard E-government information. More importantly, the optimal key is created by employing the AESMO algorithm, which is an integration of Artificial Ecosystem-based Optimization (AEO) and Spider Monkey Optimization (SMO). It is observed that the AESMO_based PrivPresKey Gen technique has gained low computational time and memory usage of 0.199sec and 31Mb, respectively.},
  archive      = {J_KBS},
  author       = {Amol V. Dhumane and Nihar Ranjan and Mubin Tamboli and Jayashree R. Prasad and Rajesh S. Prasad},
  doi          = {10.1016/j.knosys.2025.113160},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113160},
  shortjournal = {Knowl. Based Syst.},
  title        = {A secure data sharing framework with AESMO enabled key generation in consortium blockchain based E-government system},
  volume       = {317},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-machine collaborative health estimation of industrial robot based on fuzzy self-attention network and manifold cluster. <em>KBS</em>, <em>316</em>, 113430. (<a href='https://doi.org/10.1016/j.knosys.2025.113430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health estimation techniques (HETs) are critical to guarantee the operating safety of industrial robot. However, many academics have emphasized their defects in terms of estimation and prioritization for robot health condition. This article is aimed to develop a new human-machine collaborative method by combining fuzzy self-attention network and manifold fuzzy c -means to remedy the inherent limitations of the HETs. In this method, a fuzzy self-attention network is proposed to construct the fault status membership function of each extracted symptom parameter as a single assessment model, and the fault probability distributions are calculated and formulated into the hesitation fuzzy number (HFN). Then, these HFNs are aggregated as the collective hesitation fuzzy estimation matrix, and the health representation is deduced to reflect the robot health condition by the hesitation fuzzy hybrid weighted average operator. Finally, the manifold fuzzy c -means is devised to identify the robot health degree for the hierarchical operation and maintenance decisions. A self-built industrial robot test platform is applied for the effectiveness validation, and results indicate that the proposed method is more reliable and practical for health management.},
  archive      = {J_KBS},
  author       = {Weixiong Jiang and Qi Deng and Jun Wu and Yan Zhou and Haiping Zhu},
  doi          = {10.1016/j.knosys.2025.113430},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113430},
  shortjournal = {Knowl. Based Syst.},
  title        = {Human-machine collaborative health estimation of industrial robot based on fuzzy self-attention network and manifold cluster},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-hop path reasoning of temporal knowledge graphs based on generative adversarial imitation learning. <em>KBS</em>, <em>316</em>, 113421. (<a href='https://doi.org/10.1016/j.knosys.2025.113421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph reasoning aims to address the incompleteness of temporal knowledge graphs by reasoning unknown facts from known facts. Multi-hop path reasoning method based on reinforcement learning (RL) enhances the interpretability of results in temporal knowledge graph reasoning. However, this approach faces two challenges. Firstly, current methods simply embed time information and splice it with other information, proving ineffective in addressing future timestamps and presenting challenges in effectively modeling time information during the reasoning process. Secondly, the method based on reinforcement learning requires the manual setting of a precise reward function to adapt to specific datasets. The setting of the reward function significantly impacts the reasoning results of the model. To solve the above two challenges, we introduce relative time encoding and generative adversarial imitation learning. For the first challenge, we use relative time encoding to capture time information and give reinforcement learning agents better guidance according to the relative time information. For the second challenge, we propose a multi-hop path reasoning method for temporal knowledge graphs based on generative discriminant imitation learning. Our approach regards the reasoning strategy of reinforcement learning as the generator and the reward function as the discriminator. Through the interplay between the discriminator and the generated model, the reasoning model undergoes competitive training. Meanwhile, by adaptively adjusting reasoning strategy and reward function, our approach can learn more reasonable reasoning strategies in complex environments. Experimental results on four benchmark datasets show that our method improves the existing multi-hop path reasoning methods based on reinforcement learning without artificially setting reward functions.},
  archive      = {J_KBS},
  author       = {Luyi Bai and Qianwen Xiao and Lin Zhu},
  doi          = {10.1016/j.knosys.2025.113421},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113421},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-hop path reasoning of temporal knowledge graphs based on generative adversarial imitation learning},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced speech emotion recognition utilizing optimized equivariant quantum convolutional neural network for accurate emotional state classification. <em>KBS</em>, <em>316</em>, 113414. (<a href='https://doi.org/10.1016/j.knosys.2025.113414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-computer interaction frequently involves speech-emotion recognition (SER), which finds extensive use in domains like education, healthcare, and elder care. Researchers have to face difficulties in creating high-accuracy SER systems, even with advances in model identification and speech emotion feature extraction. To overcome these issues, in this manuscript Advanced SER utilizing an optimized Equivariant quantum convolutional neural network for Accurate Emotional State Classification (SER- EQCNN-ESC) was proposed. Initially, the input speech data is collected from the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS). The collected input data is then fed to pre-processing using Bellman filtering (BF) to remove noise and normalize the collected input data. Then the extracted features are fed to the Single Candidate Optimizer (SCO) to choose the best speech emotion characteristics. After that, the selected features are fed into the Equivariant Quantum Convolutional Neural Network (EQCNN) for SER and classified as Neutral, Happiness, Sadness, Anger, Fear, Disgust, Surprise, and calm. Generally, EQCNN does not express adapting optimization strategies to determine the finest parameters to ensure accurate recognition and classification of Speech emotion (SE). The performance of the proposed SER-EQCNN-ESC technique attains 18.80 %, 23.21 %, and 33.52 % higher accuracy, 19.41 %, 22.91 %, and 33.02 % higher precision contrasted with existing techniques like Automatic speech emotion detection using a hybrid of gray wolf optimizer and naïve Bayes (ASER-GWO NB), Modulation spectral features for speech emotion recognition using deep neural networks (SER-DNN) and A parallel-model speech emotion recognition network based on feature clustering (SER-FC-MDNN) models respectively.},
  archive      = {J_KBS},
  author       = {Balachandran G and Ranjith S and Jagan G C and Chenthil T R},
  doi          = {10.1016/j.knosys.2025.113414},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113414},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced speech emotion recognition utilizing optimized equivariant quantum convolutional neural network for accurate emotional state classification},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A NeRF-based technique combined depth-guided filtering and view enhanced module for large-scale scene reconstruction. <em>KBS</em>, <em>316</em>, 113411. (<a href='https://doi.org/10.1016/j.knosys.2025.113411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and high-quality rendering of large-scale geographic scenes is crucial in the field of virtual geographic environment. Neural Radiance Field (NeRF), as a novel and cutting-edge view synthesis technique, has the great simplicity of process and the higher fidelity of rendering effect. However, when applied to large scenes, constrained by the network performance and the lack of 3D geometric model, NeRF still needs to be improved in terms of the visual sharpness of modeling results and the recognition ability of geometric features. In this paper, a depth-guided filtering method is designed for punishing the noise and visual artifacts in radiance field. In addition, a view enhanced module is proposed, which fuses adjacent high-quality reference views to greatly improve the clarity of rendered images. Moreover, on two public large-scale geographic datasets and our constructed campus dataset, extensive experiments have shown that our method not only achieves better high-quality reconstruction results than traditional explicit modeling methods, but also exceeds the common implicit modeling methods 6.91 % at most in reconstruction accuracy.},
  archive      = {J_KBS},
  author       = {Xiang Wen and Kai Sun and Tao Chen and Zhao Wang and Jiangfeng She and Qiang Zhao and Yuzheng Guan and Shusheng Zhang and Jiakuan Han},
  doi          = {10.1016/j.knosys.2025.113411},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113411},
  shortjournal = {Knowl. Based Syst.},
  title        = {A NeRF-based technique combined depth-guided filtering and view enhanced module for large-scale scene reconstruction},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFD-former: Time-frequency domain fusion decoders for effective and robust fault diagnosis under time-varying speeds. <em>KBS</em>, <em>316</em>, 113410. (<a href='https://doi.org/10.1016/j.knosys.2025.113410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on fault diagnosis using deep learning methodologies is crucial for ensuring the safety and efficiency of industrial systems. In recent years, numerous analytical approaches have been developed for processing time-domain signals, frequency-domain signals, and time-frequency analysis. This study demonstrates that time-frequency domain fusion decoders exhibit remarkable effectiveness and robustness in fault diagnosis applications. We propose TFDFormer, a novel fault diagnosis framework built on two key designs. First, we introduce a lightweight encoder based on the CNN-Transformer structure, to extract signal features from both time and frequency domains, ensuring precise alignment across these domains. Additionally, we develop a contrastive learning loss function specifically tailored for time-frequency domain embeddings to enhance the model's performance. Second, we employ cross-attention mechanism in the decoder to facilitate efficient feature fusion, enabling seamless integration of domain-specific information. To validate the effectiveness of domain fusion and the diagnostic accuracy of TFDFormer, we evaluate it across three prominent fault diagnosis scenarios: fault diagnosis under time-varying speeds, domain generation fault diagnosis, and fault diagnosis on small-scale datasets. The experiments reveal that time-frequency domain fusion decoders significantly enhance model's capabilities in addressing complex diagnostic tasks. TFDFormer consistently outperforms state-of-the-art methods in terms of accuracy, robustness, generalization, and computational efficiency, demonstrating its superiority in fault diagnosis applications.},
  archive      = {J_KBS},
  author       = {Ruichen Ma and Jinglong Chen and Yong Feng and Zitong Zhou and Jingsong Xie},
  doi          = {10.1016/j.knosys.2025.113410},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113410},
  shortjournal = {Knowl. Based Syst.},
  title        = {TFD-former: Time-frequency domain fusion decoders for effective and robust fault diagnosis under time-varying speeds},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale motion-aware and spatial–temporal-channel contextual coding network for learned video compression. <em>KBS</em>, <em>316</em>, 113401. (<a href='https://doi.org/10.1016/j.knosys.2025.113401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video compression performance is significantly dependent on accurate motion prediction and efficient entropy coding. However, most current learned video compression methods rely on pre-trained optical flow networks or simplistic lightweight models for motion estimation, which fail to fully leverage the spatial–temporal characteristics of video sequences. This often brings higher bit consumption and distortion in reconstructed frames. Additionally, these methods frequently overlook the rich contextual information present within feature channels that could enhance entropy modeling. To address these issues, we propose a motion-aware and spatial–temporal-channel contextual coding-based video compression network (MASTC-VC). Specifically, we introduce a multiscale motion-aware module (MS-MAM) that estimates effective motion information across both spatial and temporal dimensions in a coarse-to-fine manner. We also propose a spatial–temporal-channel contextual module (STCCM) which optimizes entropy coding by exploiting latent representation correlations, leading to bit savings from spatial, temporal and channel perspectives. On top of it, we further introduce an uneven channel grouping scheme to strike a balance between computational complexity and rate–distortion (RD) performance. Extensive experiments demonstrate that MASTC-VC outperforms previous learned models across three benchmark datasets. Notably, our method achieves an average 10.15% BD-rate savings compared to H.265/HEVC (HM-16.20) using the PSNR metric and average 23.93% BD-rate savings against H.266/VVC (VTM-13.2) using the MS-SSIM metric.},
  archive      = {J_KBS},
  author       = {Yiming Wang and Qian Huang and Bin Tang and Xin Li and Xing Li},
  doi          = {10.1016/j.knosys.2025.113401},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113401},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiscale motion-aware and spatial–temporal-channel contextual coding network for learned video compression},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long kernel distillation in human activity recognition. <em>KBS</em>, <em>316</em>, 113397. (<a href='https://doi.org/10.1016/j.knosys.2025.113397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most human activity recognition (HAR) models prioritize achieving high recognition rates with deep neural networks, often at the expense of increased computational complexity, which significantly limits their practical deployment on embedded devices. Knowledge distillation, a technique where “dark knowledge” is transferred from larger models to smaller ones, presents a promising solution to this challenge. However, existing distillation methods overlook two critical issues: (1) teacher models with limited receptive fields inherently constrain model performance, and (2) current distillation techniques fail to transfer an adequate amount of activity-related knowledge. To address these limitations, this paper pioneers the exploration of long-kernel HAR models as teacher models, empowering short-kernel HAR models with enhanced perceptual capabilities. Additionally, we propose a novel multi-teacher knowledge distillation algorithm that adaptively transfers richer and more diverse activity-related knowledge from multiple long-kernel networks to the student model. Extensive experiments conducted on three public benchmark datasets demonstrate consistent performance improvements (up to 4.15%) for the student model, while maintaining its lightweight design.},
  archive      = {J_KBS},
  author       = {Minghui Yao and Dongzhou Cheng and Lei Zhang and Li Wang and Hao Wu and Aiguo Song},
  doi          = {10.1016/j.knosys.2025.113397},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113397},
  shortjournal = {Knowl. Based Syst.},
  title        = {Long kernel distillation in human activity recognition},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view feature embedding via shared and specific structural contrastive learning. <em>KBS</em>, <em>316</em>, 113395. (<a href='https://doi.org/10.1016/j.knosys.2025.113395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature embedding (MvFE) is a powerful technique for addressing the challenges posed by high-dimensional multi-view data. In recent years, contrastive learning (CL) has gained significant attention due to its superior performance. However, existing CL-based methods primarily focus on promoting consistency between any two cross views, thereby overlooking the diversity among views and impeding the simultaneous exploration of both consistency and complementarity. In this study, we propose a novel MvFE method called shared and specific structural contrastive learning (S3CL), which constructs shared and specific losses to capture both shared and specific potential structural information in multi-view data. Additionally, S3CL introduces a novel view-weighting mechanism that adaptively assigns weights to each specific losses, enabling a discriminative treatment of each view based on its uniqueness and importance in the feature embedding process. Moreover, to fully explore the view-specific structures while avoiding the emergence of pseudo-structures, a residual mechanism of incomplete fitting is employed in S3CL. Experimental results on five real-world datasets validate the superior performance of our proposed method compared to existing approaches.},
  archive      = {J_KBS},
  author       = {Yi Li and Ruojin Zhou and Ling Jing and Hongjie Zhang},
  doi          = {10.1016/j.knosys.2025.113395},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113395},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view feature embedding via shared and specific structural contrastive learning},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F3: Fair federated learning framework with adaptive regularization. <em>KBS</em>, <em>316</em>, 113392. (<a href='https://doi.org/10.1016/j.knosys.2025.113392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, ensuring high accuracy while maintaining fairness across heterogeneous clients presents a significant challenge. Existing approaches often fail to adequately balance these objectives, especially in non-IID environments. To address this issue, we propose an adaptive regularization framework, F 3 , which dynamically adjusts the balance between global accuracy and fairness during training. Our method introduces two fairness metrics—variance and mean absolute deviation (MAD)—to quantify performance disparities among clients. By incorporating these metrics into the loss function, we enable adaptive tuning of the regularization parameter to maintain global performance while minimizing client imbalances. Extensive experiments across diverse datasets and heterogeneous environments demonstrate that our approach significantly improves both accuracy and fairness, outperforming baseline methods such as FedAvg and FairFed. These results highlight the potential of F 3 to achieve a more balanced and robust federated learning system.},
  archive      = {J_KBS},
  author       = {Jiaming Pei},
  doi          = {10.1016/j.knosys.2025.113392},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113392},
  shortjournal = {Knowl. Based Syst.},
  title        = {F3: Fair federated learning framework with adaptive regularization},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KCM-net: Kinematic continuity-aware multi-relational cross-attention interaction network for video-based human pose and mesh reconstruction. <em>KBS</em>, <em>316</em>, 113391. (<a href='https://doi.org/10.1016/j.knosys.2025.113391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing 3D poses and meshes from monocular video sequences is a task fraught with difficulties. On the one hand, it is difficult to fully extract temporal motion information, which leads to a lack of smoothness and consistency between frames. On the other hand, there is a mismatch between joint-driven poses and vertex-guided meshes, that is, joint information cannot be accurately mapped to the corresponding vertices of the mesh. Given this, we propose a kinematic continuity-aware multi-relational cross-attention interaction network (KCM-Net) to obtain 3D human poses and meshes by capturing temporal coherence features among video frames and mining relationships between joints and vertices. Firstly, we extract temporal motion features and mid-frame 3D poses to provide accurate information for subsequent operations. Secondly, the successive cross-attention mechanisms are adopted to construct multiple interactions between joints and vertices, thus obtaining the coarse human mesh. Finally, a constrained strategy based on the intrinsic correlation of vertices is introduced to further refine spatial features of the mesh. The proposed KCM-Net outperforms previous state-of-the-art techniques on 3DPW, Human3.6M and MPI-INF-3DHP datasets. Among them, it achieves 83.6 mm under MPVE (7.3% improvement) and 6.4 mm/s 2 under ACCEL (9.9% improvement) on the challenging 3DPW dataset, which indicates superior results in both intra-frame accuracy and inter-frame temporal coherence.},
  archive      = {J_KBS},
  author       = {Hehao Zhang and Zhengping Hu and Shuai Bi and Jirui Di and Zhe Sun},
  doi          = {10.1016/j.knosys.2025.113391},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113391},
  shortjournal = {Knowl. Based Syst.},
  title        = {KCM-net: Kinematic continuity-aware multi-relational cross-attention interaction network for video-based human pose and mesh reconstruction},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end multi-task reinforcement learning-based UAV swarm communication attack detection and area coverage. <em>KBS</em>, <em>316</em>, 113390. (<a href='https://doi.org/10.1016/j.knosys.2025.113390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative end-to-end multi-task reinforcement learning framework designed to enhance the security and operational stability of UAVs in complex communication attacks environments. In scenarios involving multiple UAV coverage, the framework classifies attack types and predicts UAV behaviors, which enables rapid response and compromised data recovery. First, a spatiotemporal attention mechanism is employed to strengthen the network by capturing temporal dependencies in the communication data and improving the recognition of hybird attack mode, thereby facilitating the integration of detection and repair. Second, the causal inference mechanism introduced in this study extracts true causal relationships from interference, which ensures the accuracy and stability of action predictions for area coverage under attack conditions. Finally, the entire process is modeled as a multi-task Markov decision process, optimizing overall decision-making efficiency. Additionally, the dynamic pheromone induction mechanism is proposed to realize the adaptive regional cooperative coverage of multiple UAVs. The experimental results demonstrate that the proposed algorithm can effectively detect hybrid attacks and predict UAV actions, protecting the multi-UAV cooperative area coverage.},
  archive      = {J_KBS},
  author       = {Jin Yu and Ya Zhang and Changyin Sun},
  doi          = {10.1016/j.knosys.2025.113390},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113390},
  shortjournal = {Knowl. Based Syst.},
  title        = {End-to-end multi-task reinforcement learning-based UAV swarm communication attack detection and area coverage},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal multi-view continual dictionary learning with graph diffusion. <em>KBS</em>, <em>316</em>, 113388. (<a href='https://doi.org/10.1016/j.knosys.2025.113388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning has emerged as a crucial domain within artificial intelligence, aiming to mimic the human-like capability to learn from sequential data over time without succumbing to catastrophic forgetting. However, conventional continual learning methods have largely ignored the need of spatial knowledge retention across multiple views, focusing primarily on temporal aspects alone. This oversight is particularly significant in the scenario, where scarcely-annotated data is perpetually captured from different spatial views. To address these issues, we propose an effective Spatial–Temporal Knowledge Retention (STKR) strategy. It integrates label propagation, temporal continual learning, and spatial graph diffusion with a learnable dictionary to enhance the handling of multi-view data streams with insufficient annotations. In STKR, we propose a View-Specific Knowledge Retention (VSKR) mechanism with the Continual Pairwise Rehearsal Ranking (CPRR) strategy. The CPRR strategy secures a compact repository of labeled data within an adaptable dictionary. The VSKR strategy ensures the dictionary can be tuned by observing the correlations within an expansive pool of unlabeled data via label propagation, circumventing the need for costly annotation. Besides, the learnable dictionary can continually learn discriminative features and absorb new knowledge from streamlined data to address catastrophic forgetting. Moreover, we integrate cross-view graph diffusion to minimize the disparity of spatial knowledge retention across multiple views. This integration aims to ensure robust knowledge retention not only temporally but also spatially, maintaining knowledge preservation coherence and consistency across varying spatial views. Extensive experiments verified the effectiveness of the STKR approach for multi-view continual learning tasks.},
  archive      = {J_KBS},
  author       = {Sheng Wu and Jinlai Zhang},
  doi          = {10.1016/j.knosys.2025.113388},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113388},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatiotemporal multi-view continual dictionary learning with graph diffusion},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical reinforcement learning framework for multi-UAV combat using leader–follower strategy. <em>KBS</em>, <em>316</em>, 113387. (<a href='https://doi.org/10.1016/j.knosys.2025.113387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-UAV air combat is a complex task involving multiple autonomous UAVs, an evolving field in both aerospace and artificial intelligence. This paper aims to enhance adversarial performance through collaborative strategies. Previous approaches predominantly discretize the action space into predefined actions, limiting UAV maneuverability and complex strategy implementation. Others simplify the problem to 1v1 combat, neglecting the cooperative dynamics among multiple UAVs. To address the high-dimensional challenges inherent in six-degree-of-freedom space and improve cooperation, we propose a hierarchical framework utilizing the Leader-Follower Multi-Agent Proximal Policy Optimization (LFMAPPO) strategy. Specifically, the framework is structured into three levels. The top level conducts a macro-level assessment of the environment and guides execution policy. The middle level determines the angle of the desired action. The bottom level generates precise action commands for the high-dimensional action space. Moreover, we optimize the state-value functions by assigning distinct roles with the leader–follower strategy to train the top-level policy, followers estimate the leader’s utility, promoting effective cooperation among agents. Additionally, the incorporation of a target selector, aligned with the UAVs’ posture, assesses the threat level of targets. Finally, simulation experiments validate the effectiveness of our proposed method.},
  archive      = {J_KBS},
  author       = {Jinhui Pang and Jinglin He and Noureldin Mohamed Abdelaal Ahmed Mohamed and Changqing Lin and Zhihui Zhang and Xiaoshuai Hao},
  doi          = {10.1016/j.knosys.2025.113387},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113387},
  shortjournal = {Knowl. Based Syst.},
  title        = {A hierarchical reinforcement learning framework for multi-UAV combat using leader–follower strategy},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Serialized attention and masked residual network structure for free-form image inpainting. <em>KBS</em>, <em>316</em>, 113385. (<a href='https://doi.org/10.1016/j.knosys.2025.113385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting aims to reconstruct the integrity of an image by filling in damaged regions, and has attracted widespread interest in computer vision field. Many previous approaches tend to utilize codec-based descending and ascend sampling methods for feature propagation, or simply add attention matching to assist feature learning. However, this mechanism will result in a large amount of information redundancy, leading to poor redrawing, structural distortion, or content inconsistency. To address these changeling issues, this paper proposes a serialized attention (SA) module to bolster the capacity of capturing global information. And then, we design a masked residual (MR) architecture to enhance the decoding network's efficiency in integrating the features output from encoding network. Our MR module is also helpful to reduce the information redundancy of the decoding network. In addition, we design a new discriminator structure from the point of view of mask prediction. Experimental results across various public datasets indicate that our method has robust inpainting capabilities for random mask, outperforming the existing state-of-the-art in both quantitative metrics and visual appraisals. The program codes will be released at website: https://github.com/Ethereal256/SAMR .},
  archive      = {J_KBS},
  author       = {Jinlong Tang and Kai He and Mingjuan Tian and Ziqi Yang and Shuai Yuan},
  doi          = {10.1016/j.knosys.2025.113385},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113385},
  shortjournal = {Knowl. Based Syst.},
  title        = {Serialized attention and masked residual network structure for free-form image inpainting},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiDAR-assisted image restoration for extreme low-light conditions. <em>KBS</em>, <em>316</em>, 113382. (<a href='https://doi.org/10.1016/j.knosys.2025.113382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research into enhancing images captured under low-light conditions has been a focus for several years. However, most existing image restoration techniques primarily address RGB-only images, overlooking the potential benefits of integrating additional modalities. With advancements in handheld technology, capturing images alongside depth data has become easily accessible through devices like smartphones. This presents a significant opportunity to explore the role of depth data in improving image quality in low-light environments. In this study, we introduce a novel dataset named LED ( L ow-light Image E nhanced with D epth Map), consisting of 1365 entries. Each entry includes a low-light image, its corresponding normal-light counterpart, and an associated depth map. To the best of our knowledge, LED is the first low-light image enhancement dataset that incorporates depth information. Building on this dataset, we propose model named DERNet with three innovative technologies to integrate depth data into the low-light image enhancement process. First, we utilize depth maps to extract precise edge details, improving object boundary clarity in low-light images. Second, we introduce a multi-scale multimodal fusion module, which combines features from both the image and depth map to enhance image quality. Third, we develop a multi-task refinement network that leverages an estimated illumination map to further refine the enhancement process. Experimental results demonstrate that our method achieves over a 0.52 improvement in PSNR compared to unimodal approaches and exceeds multimodal methods by nearly 0.3 with much less total parameters, highlighting the effectiveness of our approach. Moreover, our comprehensive ablation studies show that our method can be flexibly combined with previous approaches to enhance their accuracy, and our model demonstrates greater efficiency compared to previous methods.},
  archive      = {J_KBS},
  author       = {Zhen Wang and Yaozu Wu and Dongyuan Li and Guang Li and Peide Zhu and Ziqing Zhang and Renhe Jiang},
  doi          = {10.1016/j.knosys.2025.113382},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113382},
  shortjournal = {Knowl. Based Syst.},
  title        = {LiDAR-assisted image restoration for extreme low-light conditions},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human attention guided multiagent hierarchical reinforcement learning for heterogeneous agents. <em>KBS</em>, <em>316</em>, 113377. (<a href='https://doi.org/10.1016/j.knosys.2025.113377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imperative for coordination among intelligent machines has popularized cooperative multiagent reinforcement learning (MARL) in AI research. However, compared to the well-explored homogeneous agent cooperation, heterogeneous agents with different attributes or behaviors are more prevalent in practical scenarios yet they have received relatively little attention. Due to the heterogeneity of agents and the diversity of relationships, learning efficient coordination among heterogeneous agents is particularly challenging, suffering from the curse of dimensionality and the start-up problem. To tackle these challenges, we propose a novel method that connects humans and agents under a hierarchical structure to guide the learning of MARL agents. Drawing inspiration from knowledge transfer among diverse human individuals, we consider human attention as a general pattern that can be applied to heterogeneous agents. Instead of relying on comprehensive step-by-step demonstrations, we utilize fuzzy logic to capture the abstraction and vagueness within suboptimal human guidance. To avoid negative knowledge transfer, we leverage human attention as an auxiliary source through hyper-networks, allowing agents to selectively adapt to the proposed human prior knowledge. The proposed method is agnostic to specific MARL methods and can be flexibly integrated with diverse algorithms. We conduct experiments on challenging tasks within the StarCraft Multiagent Challenge (SMAC) and SMACv2 environments, and the empirical results demonstrate that our method can improve existing methods in several heterogeneous scenarios.},
  archive      = {J_KBS},
  author       = {Dingbang Liu and Fenghui Ren and Jun Yan and Guoxin Su and Shohei Kato and Wen Gu and Minjie Zhang},
  doi          = {10.1016/j.knosys.2025.113377},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113377},
  shortjournal = {Knowl. Based Syst.},
  title        = {Human attention guided multiagent hierarchical reinforcement learning for heterogeneous agents},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representation distribution matching and dynamic routing interaction for multimodal sentiment analysis. <em>KBS</em>, <em>316</em>, 113376. (<a href='https://doi.org/10.1016/j.knosys.2025.113376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of distribution discrepancies between modalities, underutilization of representations during fusion, and homogenization of fused representations in cross-modal interactions, we introduce a cutting-edge multimodal sentiment analysis (MSA) framework called representation distribution matching interaction to extract and interpret emotional cues from video data. This framework includes a representation distribution matching module that uses an adversarial cyclic translation network. This aligns the representation distributions of nontextual modalities with those of textual modalities, preserving semantic information while reducing distribution gaps. We also developed the dynamic routing interaction module, which combines four distinct components to form a routing interaction space. This setup efficiently uses modality representations for a more effective emotional learning. To combat homogenization, we propose the cross-modal interaction optimization mechanism. It maximizes differences in fused representations and enhances mutual information with target modalities, yielding more discriminative fused representations. Our extensive experiments on the MOSI and MOSEI datasets confirm the effectiveness of our MSA framework.},
  archive      = {J_KBS},
  author       = {Zuhe Li and Zhenwei Huang and Xiaojiang He and Jun Yu and Haoran Chen and Chenguang Yang and Yushan Pan},
  doi          = {10.1016/j.knosys.2025.113376},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113376},
  shortjournal = {Knowl. Based Syst.},
  title        = {Representation distribution matching and dynamic routing interaction for multimodal sentiment analysis},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable CNN-based model for mass classification in mammography. <em>KBS</em>, <em>316</em>, 113372. (<a href='https://doi.org/10.1016/j.knosys.2025.113372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mammography is the primary screening method for lesion visualization and detecting early potentially cancerous changes in breast tissue. The application of deep learning based computer-aided diagnosis (CADx) systems to mammography mass classification poses several challenges: confounding information is learned by a deep learning model, and it can be difficult for mammographic readers to understand how and why it makes a specific decision. In this work, we present a framework for interpretable convolutional neural network-based mammographic abnormality classification. In addition to predicting whether a mass lesion is benign or malignant, our work aims to follow the reasoning processes of mammographic readers in detecting clinically relevant semantic features, such as the shape characteristics of the mass. The framework includes model training that incorporates a combination of data with original images and data with pixel-wise annotations, leading to improved performance of the model. The proposed training method based on DenseNet121 achieved an improved accuracy of 86 . 1 ± 3 . 4 % compared to 67 . 9 ± 3 . 8 % for the original model on mass classification. The results show the proposed method highlighted the classification-relevant parts of the image, whereas the original method highlighted healthy tissue and confounding information. An interpretable algorithm is developed that explains the model using features representing specific clinical characteristics, thereby aiding in prediction. This allows mammographic readers to verify the model’s output for plausibility instead of relying on it blindly.},
  archive      = {J_KBS},
  author       = {Guobin Li and Mou Zhou and Yu Fu and Nashid Alam and Erika Denton and Reyer Zwiggelaar},
  doi          = {10.1016/j.knosys.2025.113372},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113372},
  shortjournal = {Knowl. Based Syst.},
  title        = {An interpretable CNN-based model for mass classification in mammography},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident local similarity graphs for unsupervised feature selection on incomplete multi-view data. <em>KBS</em>, <em>316</em>, 113369. (<a href='https://doi.org/10.1016/j.knosys.2025.113369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing instances in multi-view data often introduce inconsistencies and distort data distribution across views, posing significant challenges for learning similarity graphs in incomplete multi-view feature selection methods. Current methods either pre-compute view-specific similarity graphs based on the mean-filled multi-view data or jointly learn the similarity graphs while imputing missing data. However, these methods fail to fully exploit the complementary information of multi-view data to enhance the confidence of similarity graphs. Moreover, some methods suffer from cubic computational complexity concerning data dimensions, rendering them impractical for high-dimensional datasets. To address these issues, this paper proposes a novel method, termed C onfident L ocal S imilarity G raphs for Unsupervised Feature Selection on Incomplete Multi-view Data ( CLSG ). The proposed CLSG first generates intact latent representations in an intact latent space to capture the full information of multi-view data, followed by recovering missing data by mapping latent representations back into the data space. Then, CLSG learns dual-level local similarity graphs, including a cross-view similarity graph based on latent representations and view-specific similarity graphs derived from view-specific data representations. To enhance the confidence of view-specific similarity graphs, CLSG leverages the cross-view similarity graph to fine-tune view-specific similarity graphs and models the noise introduced by missing data using l 1 norm. These confident similarity graphs facilitate the learning of neighborhood-smoothed missing data while aiding in identifying salient features. Finally, an efficient optimization algorithm with computational complexity scaling linearly with data dimensions is developed. Extensive experiments on six datasets with varying missing rates demonstrate the superior performance of the proposed CLSG.},
  archive      = {J_KBS},
  author       = {Hong-Wei Yu and Jun-Yun Wu and Jian-Sheng Wu and Weidong Min},
  doi          = {10.1016/j.knosys.2025.113369},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113369},
  shortjournal = {Knowl. Based Syst.},
  title        = {Confident local similarity graphs for unsupervised feature selection on incomplete multi-view data},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adversarial neural network with reliable pseudo-labels iteration for cross-subject EEG emotion recognition. <em>KBS</em>, <em>316</em>, 113368. (<a href='https://doi.org/10.1016/j.knosys.2025.113368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) for electroencephalography (EEG) plays an important role in cross-subject emotion recognition. However, traditional DA methods are often limited by target domain complexities, leading to inaccurate knowledge transfer. Recent advances in subdomain adaptation, which focuses on dividing data into subdomains using pseudo-labels, have shown promise, but still rely on the quality of the generated pseudo-labels. To address this issue, we propose a novel approach, a Domain Adversarial Neural Network with Reliable Pseudo-Label Iteration (DANN-RPLI), for cross-subject emotion recognition. This method assumes that high-quality samples are close to the center and stable under perturbations. Thus, we introduced a reliable pseudo-label generation strategy with an iterative process and increased the confidence in the selected labels using perturbations. A domain adversarial network was further used to confuse subdomains, enabling a more effective cross-domain emotion representation. Our method achieved state-of-the-art results on the SEED, SEED-IV, and DEAP datasets. The superior stability of the algorithm was proven through parameter comparison experiments. Furthermore, this study reduces the impact of unreliable pseudo-labels on EEG measurements and provides a new solution for emotion recognition in practical EEG-BCI scenarios.},
  archive      = {J_KBS},
  author       = {Xiangyu Ju and Jianpo Su and Sheng Dai and Xu Wu and Ming Li and Dewen Hu},
  doi          = {10.1016/j.knosys.2025.113368},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain adversarial neural network with reliable pseudo-labels iteration for cross-subject EEG emotion recognition},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kinematic modelling and closed-loop control of a novel soft continuum robot. <em>KBS</em>, <em>316</em>, 113367. (<a href='https://doi.org/10.1016/j.knosys.2025.113367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, soft continuum robots (SCRs) have gained a lot of attention due to their excellent adaptability and reliability, and various new soft materials have been proposed to give more possibilities for the design of SCRs. However, characteristics such as large deformations and geometric nonlinearities of soft materials make the modeling and control of SCRs challenging. In this paper, a novel soft continuum robot (NSCR) consisting of four origami structure units is proposed. The origami structure units are designed using the Kresling origami pattern, and the units are endowed with capacities for contraction/extension and bending through three stable state characteristics of the Kresling origami. Based on the constant curvature assumption, the kinematic model of NSCR is established using the D-H method. A closed-loop model-free control system is proposed by using the vision system to acquire the real-time position data of the NSCR. Meanwhile, a multi-strategy improved horned lizard optimization algorithm (MHLOA) is designed to optimally select the parameters of the control system, which dramatically improves the control performance of the system. The optimization ability and improvement effect on the control system of the MHLOA algorithm are verified by test functions, simulations and experiments. The relevant experiment results show that the proposed kinematic model can finely describe the motion of the NSCR. The closed-loop model-free control system can also control the NSCR to reach the target position or trajectory under acceptable errors, and make the NSCR has excellent performance in terms of repeatability accuracy.},
  archive      = {J_KBS},
  author       = {Baiyi Wang and Haozhi Sun and Jinhong Du and Zhongwen Yi and Xinhua Liu and Dezheng Hua and Zhixiong Li and Sumika Chauhan and Govind Vashishtha},
  doi          = {10.1016/j.knosys.2025.113367},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113367},
  shortjournal = {Knowl. Based Syst.},
  title        = {Kinematic modelling and closed-loop control of a novel soft continuum robot},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deblur-aware gaussian splatting simultaneous localization and mapping. <em>KBS</em>, <em>316</em>, 113366. (<a href='https://doi.org/10.1016/j.knosys.2025.113366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) has achieved remarkable progress by integrating techniques from the Novel View Synthesis (NVS) for scene reconstruction. Therefore, Performance evaluation typically involves comparing input and synthesized images and has become standard practice. However, input images commonly contain blur, leading to a paradox where the closer the rendered images fit to the inputs, the more the reconstruction process is biased towards the blurry data. To address this challenge, we introduce the first deblur-aware SLAM system that employs a Gaussian surfel representation. Our approach automatically identifies frames with blurring and simulates the blurring effect by averaging multiple images rendered from diverse viewpoints during exposure. Additionally, we leverage prior depth and normal information from a monocular depth estimator to enhance the quality of three dimension reconstruction. Experiments on real-world datasets, TUM-RGBD and ScanNet, demonstrate that our superior RGB-only method outperforms existing approaches in mapping, even when compared to RGB-D methods. Furthermore, we have also evaluated other components beyond the deblur module on the Replica dataset and demonstrated competitive performance. The source code is available at https://github.com/Howie-Ye/DAGS .},
  archive      = {J_KBS},
  author       = {Xiaofei Qin and Haoying Ye and Changxiang He and Xuedian Zhang},
  doi          = {10.1016/j.knosys.2025.113366},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113366},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deblur-aware gaussian splatting simultaneous localization and mapping},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OSASformer: A transformer-based model for OSAS screening via multi-source representation fusion. <em>KBS</em>, <em>316</em>, 113365. (<a href='https://doi.org/10.1016/j.knosys.2025.113365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive sleep apnoea syndrome (OSAS) is a common and serious condition that leads to intermittent hypoxia and increases the risk of various health complications, such as cardiovascular diseases and metabolic dysfunction. Traditional OSAS diagnosis based on polysomnography is costly, time-consuming, and impractical for widespread early screening. Recent advancements in wearable devices equipped with photoplethysmography sensors offer a promising alternative for more accessible OSAS screening. However, existing machine learning methods based on single-modality data often struggle with noise and class imbalance, limiting their effectiveness. In this paper, we propose a novel multi-source data fusion framework, designed to improve OSAS detection by integrating shapelet-based and knowledge-based representations. Our method introduces a Transformer-based dual-branch network, OSASformer, which fuses these representations to improve OSAS detection performance. Additionally, we introduce balanced batch sampling, a new technique to address the class imbalance problem commonly encountered in OSAS datasets. We evaluate our model on a large-scale real-world dataset of 46,081 records collected from 60 volunteers using wearable PPG devices. The experimental results demonstrate that OSASformer significantly outperforms baseline models in various evaluation metrics. Our method’s effectiveness has also been validated by its runner-up position in the JDHealth Global Medical AI Competition, positioning it for real-world deployment.},
  archive      = {J_KBS},
  author       = {Yuanyuan Hou and Bin Wang and Chengxi Zhang and Qiang Wang and Jiang Li and Pingping Meng and Yongxiang Zhang and Chao Han and Feng Hong and Tong Zhang},
  doi          = {10.1016/j.knosys.2025.113365},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113365},
  shortjournal = {Knowl. Based Syst.},
  title        = {OSASformer: A transformer-based model for OSAS screening via multi-source representation fusion},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive graph transformer with future interaction modeling for multi-agent trajectory prediction. <em>KBS</em>, <em>316</em>, 113363. (<a href='https://doi.org/10.1016/j.knosys.2025.113363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the trajectories of traffic agents is essential for autonomous systems such as self-driving cars and social robots to guarantee safety in crowded scenarios. Capturing social interactions between agents and generating informative future features bring great challenges to accurate trajectory prediction. To this end, this paper proposes a novel multi-agent trajectory prediction model called AGTFI based on the adaptive graph transformer and future interaction modeling. First, an adaptive graph transformer (AGT) proficient at extracting node and edge features is introduced to capture the complex social interactions between traffic agents. Moreover, a two-stage prediction approach is devised where the first stage is devoted to generating pre-estimated future motion features by bidirectional corrected GRU (BCGRU) and the second stage further incorporates future social interactions into BCGRU to reduce prediction errors. Quantitative and qualitative evaluations of AGTFI on benchmark datasets, including ETH-UCY, SDD, and INTERACTION demonstrate the effectiveness of our model. Ablation studies are conducted to verify the rationale behind the model components.},
  archive      = {J_KBS},
  author       = {Xiaobo Chen and Junyu Wang and Fuwen Deng and Zuoyong Li},
  doi          = {10.1016/j.knosys.2025.113363},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113363},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive graph transformer with future interaction modeling for multi-agent trajectory prediction},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel structure fusion for community detection in heterogeneous graphs via disrupting heterophily. <em>KBS</em>, <em>316</em>, 113362. (<a href='https://doi.org/10.1016/j.knosys.2025.113362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing community detection methods of heterogeneous graphs focus on homophilous heterogeneous graphs, which generally use GNNs and HGNNs. In heterogeneous graphs with heterophily, the two nodes connected by metapaths often have different labels, and existing methods result in representation collapse among nodes from different communities. To address the challenges posed by structural heterophily and to enhance the strength of homophily, an unsupervised community detection method with multilevel structure fusion oriented by homophily, called SFCDH, is proposed. This method demonstrates a strong generalization capabilities across various homophilous and heterophilous heterogeneous graphs. Specifically, SFCDH consists of two modules named hierarchical structure fusion module based on homophily ratio sampling and the unsupervised graph representation learning module based on generative and contrastive learning. The first module constructs a fine-grained high-order fusion graph based on the network homophily and divides the community into multi-granularity via a hierarchical abstraction tree to improve the generalization ability of the model to different metapath subgraphs. Subsequently, the second module uses contrastive loss based on community prototypes to guide the graph in generating dynamic masks and enhances the ability of SFCDH to learn attributes and complex semantics by using graph autoencoder. Ultimately, node embeddings at the metapath level and the tree level are combined to achieve multilevel structural fusion for unsupervised community detection. Extensive experiments on six publicly available datasets demonstrate the superiority of SFCDH over state-of-the-art baselines. Notably, in the heterophilous heterogeneous graph IMDB, SFCDH outperforms the second-place model by 11% in accuracy, which further validating its effectiveness.},
  archive      = {J_KBS},
  author       = {Mengying Dai and Weimin Li and Xinyi Zhang and Fangfang Liu and Mingjun Xin and Can Wang},
  doi          = {10.1016/j.knosys.2025.113362},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113362},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multilevel structure fusion for community detection in heterogeneous graphs via disrupting heterophily},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beta distribution-based monogamous pairs genetic algorithm for knowledge transfer in many-task optimization. <em>KBS</em>, <em>316</em>, 113361. (<a href='https://doi.org/10.1016/j.knosys.2025.113361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking aims to solve multiple independent optimization tasks simultaneously by excavating a population’s implicit parallelism. However, negative knowledge transfer (i.e., the performance of the target domain deteriorates after receiving information from the source domain) slows down the evolution of a task, even in the presence of positive knowledge transfer. To address this issue, a many-task monogamous pairs genetic algorithm (MTMopGA) with dynamic knowledge and intensity selection strategies is proposed to encourage positive knowledge transfer while reducing negative transfer effects between tasks. Specifically, the transfer behavioural patterns exhibited in the reproductive outcomes (between the source and the target tasks) are accommodated in a statistical model by assuming a Beta distribution. We then combine the results with a scalable task similarity measure, which considers both the decision space, and the objective space to estimate online the strength of future transfers between tasks. In addition, multiple crossover strategies are introduced to improve the solution quality. The efficacy of the proposed framework is evaluated through an extensive benchmark suite, as well as a real-world search-based software engineering (SBSE) application. The results indicate that the proposed framework can achieve efficient dynamic transfer. Insightful information into the influence of knowledge transfer is also discussed from the lens of biology.},
  archive      = {J_KBS},
  author       = {Ting Yee Lim and Choo Jun Tan and Yi Wen Kerk and Li Zhang and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.113361},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113361},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beta distribution-based monogamous pairs genetic algorithm for knowledge transfer in many-task optimization},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STATrack: Spatio-temporal adaptive transformer with consistency-aware memory distillation for visual tracking. <em>KBS</em>, <em>316</em>, 113360. (<a href='https://doi.org/10.1016/j.knosys.2025.113360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking poses significant challenges due to complex variations in appearance, occlusions, and diverse motion patterns in real-world scenarios. This research presents STATrack, a novel tracking framework based on the Transformer architecture, aimed at addressing these challenges through three key contributions: (1) the Adaptive Spatio-Temporal Consistency Attention (ASTCA) module, which employs parallel attention mechanisms to effectively align and integrate multi-scale features, enhancing the model’s adaptability to appearance changes; (2) the Spatio-Temporal Memory Distillation Network (STMDN), which efficiently manages dynamic memory to retain and refine target-specific information across frames; and (3) the Spatio-Temporal Consistency (STC) loss, which enforces temporal coherence, significantly reducing tracking jitter and improving trajectory stability. Comprehensive experiments across seven challenging benchmarks demonstrate that STATrack achieves state-of-the-art performance, with 76.4% AO on GOT-10k, 72.7% AUC on LaSOT, and 84.7% AUC on TrackingNet, while maintaining real-time processing efficiency at 38 FPS. These results highlight the effectiveness of STATrack in enhancing tracking robustness and accuracy, establishing it as a promising solution for practical applications in visual tracking.},
  archive      = {J_KBS},
  author       = {Yongjun Wang and Xiaohui Hao},
  doi          = {10.1016/j.knosys.2025.113360},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113360},
  shortjournal = {Knowl. Based Syst.},
  title        = {STATrack: Spatio-temporal adaptive transformer with consistency-aware memory distillation for visual tracking},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient method for mining top-k multi-level high utility itemsets. <em>KBS</em>, <em>316</em>, 113359. (<a href='https://doi.org/10.1016/j.knosys.2025.113359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High utility itemset mining (HUIM) is employed for analysing user behaviour. It is an extended form of frequent itemset mining. Top-k HUIM provides a solution to the challenge of determining a suitable minimum utility threshold. Although HUIM algorithms have been improved and implemented with high performance, mining hierarchical data has not received considerable attention. The memory and runtime requirements of top-k HUIM algorithms on hierarchical databases remain high. This study proposes a method, called top-k multi-level high utility itemset (TK-MLHUI) mining, to make mining more efficient. The method uses several strategies, including sub-tree and local utility, to reduce the search space by applying stricter upper bounds. Any level of hierarchical data may be used with the upper bounds. It also suggests an approach for reducing the data required for scanning through various strategies, including combining items on lists at mining levels and updating promising items. Furthermore, a strategy to efficiently raise the threshold using the utility list of items is introduced. Experiments using various databases allow for the measurement of the method's performance. Compared with a previous method - mlTKO, TK-MLHUI decreases execution time by more than 3700 times while also using less memory.},
  archive      = {J_KBS},
  author       = {Loan T.T. Nguyen and N.T. Tung and Bay Vo},
  doi          = {10.1016/j.knosys.2025.113359},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113359},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient method for mining top-k multi-level high utility itemsets},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGCT: Enhancing temporal knowledge graph reasoning through extrapolated historical fact extraction. <em>KBS</em>, <em>316</em>, 113358. (<a href='https://doi.org/10.1016/j.knosys.2025.113358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrapolation on Temporal Knowledge Graphs (TKGs) poses a critical obstacle, garnering significant attention in the academic sphere due to its far-reaching implications across various domains and areas of study. Predicting upcoming events through the analysis of historical data involves a complex task that requires the integration of structural patterns from historical graph data and temporal dynamics, which has been the focus of various recent research efforts. However, existing methods face significant limitations. Many approaches fail to effectively differentiate the importance of historical knowledge, leading to suboptimal message passing. Others struggle to capture both local and global temporal dependencies simultaneously, resulting in incomplete temporal representations. Moreover, conventional embedding techniques often overlook dynamic positional information, which is crucial for robust forecasting. To mitigate these issues, we introduce a forecasting framework for TKGs, History Graph Convolution Transformer (HGCT), which enhances graph embedding by integrating a time-aware self-attention mechanism and convolution operation. This methodology combines a Fact Graph Transformer to organize historical knowledge into a structured framework coming with a Temporal Convolutional Transformer that leverages an innovative positional encoding strategy to distill temporal patterns from historical snapshots, thereby enriching the representation of time series data. Our work introduces a refined ConvTransE variant, named Query-ConvTransE, optimized for query-based information processing, which is consolidated into the decoding component. Evaluation of this approach across a diverse range of six benchmark datasets reveals a performance boost, marked by a 4.33 % increase in Hit@k metric and by a 3.84 % increase in Mean Reciprocal Rank metric relative to the state-of-the-art.},
  archive      = {J_KBS},
  author       = {Hoa Dao and Nguyen Phan and Thanh Le and Ngoc-Trung Nguyen},
  doi          = {10.1016/j.knosys.2025.113358},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113358},
  shortjournal = {Knowl. Based Syst.},
  title        = {HGCT: Enhancing temporal knowledge graph reasoning through extrapolated historical fact extraction},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating statistical significance and discriminative power in pattern discovery. <em>KBS</em>, <em>316</em>, 113356. (<a href='https://doi.org/10.1016/j.knosys.2025.113356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern discovery plays a central role in knowledge acquisition across multiple domains. Actionable patterns must meet rigorous statistical significance criteria and, in the presence of target variables, further uphold discriminative power. This work addresses the underexplored area of guiding pattern discovery by integrating statistical significance and discriminative power criteria into state-of-the-art algorithms while preserving pattern quality. We also address how pattern quality thresholds, imposed by some algorithms, can be rectified to accommodate these additional criteria. To assess the proposed methodology, we select the triclustering task as the guiding pattern discovery case and extend well-known greedy and multi-objective optimization triclustering algorithms, δ -Trimax and TriGen, with various merit functions, such as Mean Squared Residual (MSR), Least Squared Lines (LSL), and Multi Slope Measure (MSL). Results from three case studies show the role of the proposed methodology in discovering patterns with pronouncedly higher discriminative power and statistical significance without quality deterioration, highlighting the relevance of combining these criteria to guide the underlying searches and aid knowledge discovery. Although the proposed methodology is motivated over multivariate time series data, it is straightforwardly extensible to pattern discovery tasks involving multivariate, N-way (N > 3), transactional, and sequential data structures. Availability: The code is freely available at https://github.com/JupitersMight/MOF_Triclustering},
  archive      = {J_KBS},
  author       = {Leonardo Alexandre and Rafael S. Costa and Rui Henriques},
  doi          = {10.1016/j.knosys.2025.113356},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113356},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating statistical significance and discriminative power in pattern discovery},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ambiguity-aware and high-order relation learning for multi-grained image–text matching. <em>KBS</em>, <em>316</em>, 113355. (<a href='https://doi.org/10.1016/j.knosys.2025.113355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image–text matching is crucial for bridging the semantic gap between computer vision and natural language processing. However, existing methods still face challenges in handling high-order associations and semantic ambiguities among similar instances. These ambiguities arise from subtle differences between soft positive samples (semantically similar but incorrectly labeled) and soft negative samples (locally matched but globally inconsistent), creating matching uncertainties. Furthermore, current methods fail to fully utilize the neighborhood relationships among semantically similar instances within training batches, limiting the model’s ability to learn high-order shared knowledge. This paper proposes the Ambiguity-Aware and High-order Relation learning framework (AAHR) to address these issues. AAHR constructs a unified representation space through dynamic clustering prototype contrastive learning, effectively mitigating the soft positive sample problem. The framework introduces global and local feature extraction mechanisms and an adaptive aggregation network, significantly enhancing full-grained semantic understanding capabilities. Additionally, AAHR employs intra-modal and inter-modal correlation matrices to investigate neighborhood relationships among sample instances thoroughly. It incorporates GNN to enhance semantic interactions between instances. Furthermore, AAHR integrates momentum contrastive learning to expand the negative sample set. These combined strategies significantly improve the model’s ability to discriminate between features. Experimental results demonstrate that AAHR outperforms existing state-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets, considerably improving the accuracy and efficiency of image–text matching. The code and model checkpoints for this research are available at https://github.com/Image-Text-Matching/AAHR .},
  archive      = {J_KBS},
  author       = {Junyu Chen and Yihua Gao and Mingyuan Ge and Mingyong Li},
  doi          = {10.1016/j.knosys.2025.113355},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113355},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ambiguity-aware and high-order relation learning for multi-grained image–text matching},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-guided dynamic mouth motion capturing for person-generic talking face generation. <em>KBS</em>, <em>316</em>, 113354. (<a href='https://doi.org/10.1016/j.knosys.2025.113354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of person-generic Talking Face Generation (TFG) is to reconstruct realistic facial motions for arbitrary speakers consistent with a given speech. Previous generation methods struggle to focus on the content of lip movements. Although the introduction of the additional lip-reading pre-training model can address this problem, it often leads to a decline in visual quality, thereby diminishing the significance of the enhancement. To address this issue, we present MouthMotion, a framework that incorporates a novel textual branch to enhance visual feature extraction and compels motion learning to focus specifically on the mouth region. With the assistance of a carefully designed mouth-related text prompt, MouthMotion employs a mouth motion learning module based on Contrastive Language-Image Pre-training (CLIP) to learn mouth motions from different face frames. This process is supervised by a cosine similarity loss. To effectively fuse motion, face and speech latent codes within a joint learning space, we propose a motion-face learning module and a motion–speech learning module. We evaluate MouthMotion on the LRS2 and LRW datasets in terms of visual quality (PSNR, SSIM), lip sync (LSE-C, LSE-D), and reading intelligibility (WER, ACC) to validate the mouth motion capturing capabilities. Extensive qualitative and quantitative experiments demonstrate the superiority of our proposed method over other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Ke Liu and Jiwei Wei and Ruiqi Yuan and Ruikun Chai and Shiyuan He and Zeyu Ma and Yang Yang},
  doi          = {10.1016/j.knosys.2025.113354},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113354},
  shortjournal = {Knowl. Based Syst.},
  title        = {Text-guided dynamic mouth motion capturing for person-generic talking face generation},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-wise federated unlearning: Harnessing active forgetting with teacher–student memory generation. <em>KBS</em>, <em>316</em>, 113353. (<a href='https://doi.org/10.1016/j.knosys.2025.113353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy concerns associated with machine learning models have driven research into machine unlearning, which aims to erase the memory of specific target training data from already trained models. This issue also arises in federated learning, creating the need to address the federated unlearning problem. However, federated unlearning remains a challenging task. On the one hand, current research primarily focuses on unlearning all data from a client, overlooking more fine-grained unlearning targets, e.g., class-wise and sample-wise removal. On the other hand, existing methods suffer from imprecise estimation of data influence and impose significant computational or storage burden. To address these issues, we propose a neuro-inspired federated unlearning framework based on active forgetting, which is independent of model architectures and suitable for fine-grained unlearning targets. Our framework distinguishes itself from existing methods by utilizing new memories to overwrite old ones. These new memories are generated through teacher–student learning. We further utilize refined elastic weight consolidation to mitigate catastrophic forgetting of non-target data. Extensive experiments on benchmark datasets demonstrate the efficiency and effectiveness of our method, achieving satisfactory unlearning completeness against backdoor attacks.},
  archive      = {J_KBS},
  author       = {Yuyuan Li and Jiaming Zhang and Yixiu Liu and Chaochao Chen},
  doi          = {10.1016/j.knosys.2025.113353},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113353},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-wise federated unlearning: Harnessing active forgetting with teacher–student memory generation},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WatchoutPed: A dataset and model for vulnerable pedestrian anticipation in surveillance videos. <em>KBS</em>, <em>316</em>, 113352. (<a href='https://doi.org/10.1016/j.knosys.2025.113352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the crucial challenge of Vulnerable Pedestrian Anticipation (VPA) in urban environments, utilizing surveillance video data to enhance pedestrian safety. VPA is crucial for identifying pedestrians in potentially dangerous situations, such as walking alongside roads or crossing crosswalks, where the risk of vehicular collisions is elevated. To advance research in this field, we introduce two primary components: the WatchoutPed dataset and the Vulnerable Pedestrian Anticipation Network (VPANet), a baseline network especially designed for VPA. The WatchoutPed dataset has been meticulously enriched with extensive annotations through an innovative auto-labeling technique that integrates ground region analysis with pedestrian state estimation, thus providing a solid foundation for VPA research. Complementing this, the VPANet is engineered to process visual and non-visual inputs extracted from past frames in surveillance footage, enabling it to predict the future state of pedestrians as either safe or unsafe. Tested on the WatchoutPed dataset, VPANet achieves an impressive 89% accuracy, outperforming current methods. Furthermore, we demonstrate the effectiveness of our auto-labeling approach. Notably, the accuracy of VPANet, when trained with the auto-generated annotations from the WatchoutPed, closely parallels that achieved with human-verified annotations, with a negligible variance of less than 1%. The broader implications of our work are significant for the development of smart urban safety infrastructures. Integrating these insights into intelligent crosswalk systems could greatly enhance the monitoring of pedestrian activity near crosswalks, enabling the timely alerting of drivers to the presence of vulnerable pedestrians, and thereby proactively preventing potential vehicular accidents.},
  archive      = {J_KBS},
  author       = {Je-Seok Ham and Dae Hoe Kim and Jinyoung Moon},
  doi          = {10.1016/j.knosys.2025.113352},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113352},
  shortjournal = {Knowl. Based Syst.},
  title        = {WatchoutPed: A dataset and model for vulnerable pedestrian anticipation in surveillance videos},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable TabNet transformer-based on google vizier optimizer for anomaly intrusion detection system. <em>KBS</em>, <em>316</em>, 113351. (<a href='https://doi.org/10.1016/j.knosys.2025.113351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly Intrusion Detection Systems (AIDS) in the Internet of Things (IoT) environments have been revolutionized by the beginning of Artificial Intelligence (AI) techniques. For example, deep learning (DL) models and transformer models can sift through and learn from vast amounts of big data to detect complex and complicated intrusion patterns. The current work presents a TabNet model tuned with Google OSS Vizier-hyperparameters tuning service-to increase the model’s performance for AIDS tasks. The TabNet showed great promise due to its detection and capacity to handle numerical and categorical data. We implemented experimentation based on benchmark datasets, NSL-KDD, CICIoT2023, and RT_IoT2022 and the model has evaluated its efficacy in both binary and multi-classification types. The experimental results of our evaluation in binary classification are 99.9%, 99.92%, and 99.16% on NSL-KDD, CICIoT2023, and RT_IoT2022 datasets, respectively. While for multi-classification, they are 98.29%, 98.43%, 98.10% for NSL-KDD, CICIoT2023, and RT_IoT2022 datasets, respectively. Moreover, this work also incorporates using of Explainable AI (XAI) techniques, specifically the SHapley Additive exPlanations (SHAP) function to illustrate the contribution of individual features to the model’s predictions and decisions. The combination of perceptive explanations of XAI with the optimized TabNet’s powerful feature learning presents a major advancement in the development of highly effective, and interpretable AIDS.},
  archive      = {J_KBS},
  author       = {Ibrahim A. Fares and Mohamed Abd Elaziz},
  doi          = {10.1016/j.knosys.2025.113351},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113351},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainable TabNet transformer-based on google vizier optimizer for anomaly intrusion detection system},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ada-matcher: A deep detector-based local feature matcher with adaptive weight sharing. <em>KBS</em>, <em>316</em>, 113350. (<a href='https://doi.org/10.1016/j.knosys.2025.113350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing point-to-point correspondence between image pairs through local feature matching is essential for many vision applications. Recently, detector-based feature matching methods leveraging deep learning have achieved a balance between accuracy and computational efficiency, gaining broad attention. To enhance matching performance or reduce storage requirements, these approaches focus on improving the Transformer structure for more effective feature aggregation. Unlike these studies, the present study explores the impact of Transformer block numbers on the matching performance. Theoretically, increasing the number of Transformer modules can enhance matching accuracy, but this also results in a proportional increase in the model size, making the matcher unsustainable with limited resources. To address this, this study introduces Ada-Matcher, a detector-based deep local feature matching framework that improves accuracy while maintaining model capacity. Ada-Matcher incorporates an adaptive weight sharing mechanism, allowing dynamic weight sharing among adjacent Transformer blocks, thus mitigating the storage overhead associated with deep network structures. Complementing this, lightweight feature transformations are applied to each Transformer block, enriching feature diversity and boosting matching performance. Furthermore, Ada-Matcher uses a novel mask-attention technology, focusing on critical task features and dynamically masking irrelevant information to enhance the model generalization ability. Rigorous empirical evaluations indicate that Ada-Matcher exhibits superior performance across various benchmark tests. The code and data related to this work are publicly available at https://github.com/zfj-mc/ada-matcher .},
  archive      = {J_KBS},
  author       = {Fangjun Zheng and Chuqing Cao and Ziyang Zhang and Tao Sun and Jinhang Zhang and Lijun Zhao},
  doi          = {10.1016/j.knosys.2025.113350},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113350},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ada-matcher: A deep detector-based local feature matcher with adaptive weight sharing},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised distributional and contrastive learning model for image anomaly detection. <em>KBS</em>, <em>316</em>, 113348. (<a href='https://doi.org/10.1016/j.knosys.2025.113348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a critical task in computer vision and machine learning, which aims to detect anomalies that are away from the distribution of normal data. Prevalent methods perform anomaly detection via pretraining the model or constructing pretext tasks based on instance-level contrastive learning. However, they ignore the underlying distribution of features for normal data, which is crucial for detecting anomalies. In this paper, we propose a self-supervised distributional and contrastive learning model for anomaly detection. For distributional modeling, based on the augmented dataset with given rotated images, we propose to model latent features of normal sample set under each rotation transformation via a Gaussian Mixture Model (GMM). By the proposed GMM clustering loss, we maximize the probability of data to the GMM model with rotation that is applied to the data, and minimize its probability to the GMMs of other rotations. For contrastive learning, we discriminate augmented features via rotation-based contrastive learning that constructs positive pairs augmented from the same instance under the same rotation and negative pairs augmented from different instances under rotations. Our approach jointly conducts distributional modeling of image features considering feature clustering properties, and discriminative learning of features in a self-supervised way. We also design detection scores from different modules to detect anomalies. Extensive experiments on image datasets ( e.g ., CIFAR-10, CIFAR-100 and ImageNet-30) demonstrate that our method achieves favorable performance compared with several state-of-the-art methods on unsupervised image anomaly detection tasks. Ablation studies demonstrate the effectiveness of the key modules in our model.},
  archive      = {J_KBS},
  author       = {Yannan Pu and Jian Sun and Niansheng Tang and Zongben Xu},
  doi          = {10.1016/j.knosys.2025.113348},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113348},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised distributional and contrastive learning model for image anomaly detection},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing spatiotemporal prediction through the integration of mamba state space models and diffusion transformers. <em>KBS</em>, <em>316</em>, 113347. (<a href='https://doi.org/10.1016/j.knosys.2025.113347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced architecture for spatiotemporal prediction MAD , integrating Ma mba modules with D iffusion Transformers for efficient spatiotemporal modeling. The model consists of three phases: encoding, reconstruction, and prediction. Initially, the encoder transforms raw spatiotemporal data into compact latent embeddings. In the reconstruction phase, the Mamba module processes these embeddings through normalization and bidirectional state space models, generating reconstructed representations which are then decoded to restore the input data. The prediction phase utilizes the Diffusion Transformer to model spatiotemporal features, incorporating time embeddings and leveraging self-attention mechanisms to capture complex spatiotemporal dependencies. Finally, the model jointly trains the reconstruction and prediction paths to achieve high-precision spatiotemporal forecasts. Experimental results demonstrate the model’s superior performance across various spatiotemporal prediction tasks, validating its effectiveness and robustness. Our codes are available at https://github.com/Hanson1331/KBS-MAD .},
  archive      = {J_KBS},
  author       = {Hansheng Zeng and Yuqi Li and Ruize Niu and Chuanguang Yang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.113347},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113347},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing spatiotemporal prediction through the integration of mamba state space models and diffusion transformers},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative study of category incremental learning algorithms for arrhythmia detection. <em>KBS</em>, <em>316</em>, 113346. (<a href='https://doi.org/10.1016/j.knosys.2025.113346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time arrhythmia detection plays a crucial role in saving patients’ lives. Traditional arrhythmia detection systems rely on offline learning, requiring model retraining whenever the disease database is updated or new class data is introduced, which incurs high computational costs. Additionally, in the arrhythmia detection task, the continuous expansion of electrocardiogram (ECG) data classes and changes in data distribution pose significant challenges for model training. To address the challenges posed by new class ECG data, this paper proposes two class-incremental learning algorithms: the Class-Incremental Broad Learning System Based on Class-Intra Constraints (CICC Based CIBLS) and the Class-Incremental Broad Learning System Based on Preset Class Space (PCS Based CIBLS). The CICC Based CIBLS dynamically updates model weights by establishing class-intra constraints between new and existing classes, ensuring algorithm stability when handling new classes. On the other hand, the PCS Based CIBLS provides efficient class expansion capabilities by presetting the class space and adjusting model weights with an incremental learning algorithm. The two algorithms address different challenges: one optimises for computational efficiency, while the other ensures model stability, providing flexible solutions for various application scenarios. In particular, facing the challenges of continuous class expansion and shifting data distributions in ECG data, this paper further introduces an Adaptive Decision Threshold Shifting Strategy (ADTSS). This strategy dynamically adjusts the positive decision threshold based on class ratios, ensuring that the model maintains balance across all class data during the decision-making process. Experimental results demonstrate the significant potential of the proposed methods in arrhythmia detection, with comprehensive evaluations conducted on datasets with different structures, further validating their effectiveness.},
  archive      = {J_KBS},
  author       = {Jianchao Feng and Yujuan Si and Yu Zhang and Xin Chen},
  doi          = {10.1016/j.knosys.2025.113346},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113346},
  shortjournal = {Knowl. Based Syst.},
  title        = {An innovative study of category incremental learning algorithms for arrhythmia detection},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient algorithms for optimal path planning of unmanned aerial vehicles in complex three-dimensional environments. <em>KBS</em>, <em>316</em>, 113344. (<a href='https://doi.org/10.1016/j.knosys.2025.113344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents three spherical vector-based optimization techniques, namely the spherical vector-based spider wasp optimizer (SSWO), the spherical vector-based secretary bird optimization algorithm (SSBOA), and the spherical vector-based improved spider wasp optimizer (SISWO), to properly plan UAV trajectories in 3D complicated environments with various threats. SISWO is based on combining some SBOA stages with SWO to benefit from their strengths in dealing with local optima and accelerating convergence speed. Six scenarios generated in Christmas Island, Australia, are used to assess the effectiveness of the proposed algorithms in optimizing four different objectives, including path optimality, threat cost, flight height, and smooth cost. In addition, they are compared to seven recent and well-established algorithms according to several performance metrics. According to the experimental results, both SISWO and SSBOA could outperform all other algorithms in most scenarios, demonstrating that they are more effective at precisely planning the UAV flight path in complex 3-D environments. Quantitatively, in terms of Friedman’s mean rank, SISWO could achieve an average rank of 2.04 for all scenarios, followed by SSBOA with 2.27.},
  archive      = {J_KBS},
  author       = {Mohamed Abdel-Basset and Reda Mohamed and Karam M. Sallam and Saber Elsayed},
  doi          = {10.1016/j.knosys.2025.113344},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113344},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient algorithms for optimal path planning of unmanned aerial vehicles in complex three-dimensional environments},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond outlier removal: Integrated ensemble matching for accurate image keypoint correspondence. <em>KBS</em>, <em>316</em>, 113343. (<a href='https://doi.org/10.1016/j.knosys.2025.113343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel two-tier matching approach for robust feature correspondence and geometric transformation estimation in computer vision tasks. Our method combines sub-descriptor matching and multi-descriptor ensembling to significantly improve the accuracy and reliability of keypoint correspondences across images. Our approach is evaluated on both classic hand-crafted algorithms and deep learning-based methods using the HPatches, IMC2022, and YFCC100M datasets. We use a pretrained network and enhance it to incorporate additional descriptor heads optimized for our matching strategy. The two-tier matching strategy enables direct geometric transformation estimation without separate outlier removal in many cases, potentially streamlining computer vision pipelines. Results demonstrate that our approach substantially outperforms traditional single-descriptor methods, achieving over 95% correct matches for classic algorithm combinations and up to 96% for our enhanced learning-based approaches. Our approach can establish reliable correspondences without making any assumption about the mathematical relation between the matches. Additionally, we explore applications of our method in scene matching.},
  archive      = {J_KBS},
  author       = {Javid Norouzi and Mohammad Sadegh Helfroush and Alireza Liaghat and Habibollah Danyali},
  doi          = {10.1016/j.knosys.2025.113343},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113343},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond outlier removal: Integrated ensemble matching for accurate image keypoint correspondence},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based statement level vulnerability detection by cross-modal fine-grained features capture. <em>KBS</em>, <em>316</em>, 113341. (<a href='https://doi.org/10.1016/j.knosys.2025.113341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software vulnerability detection is crucial for computer systems. The use of fusion information from the source and assembly code can improve the performance of deep learning-based vulnerability detection; however, the bimodal fine-grained alignment information has not been fully utilized in existing methods. Therefore, we propose a cross-modal fine-grained feature capture method based on Transformers for statement-level vulnerability detection. First, we apply a slice generation method based on cross-slicing of bimodal code to obtain bimodal slices. Second, we propose a bimodal-based slice purification method that can effectively shorten the length of source code slices, thereby reducing the impact of vulnerability-unrelated statements on the detection performance. In addition, we replace the information in assembly code that is not conducive to semantic understanding with more easily understandable information, which allows the model to accurately capture the vulnerability features in assembly code. Finally, the fine-grained aligned and purified bimodal code slices are input into the bimodal Transformer model, which can not only capture the vulnerability features within the statements of the bimodal code but also capture the long-term dependencies between statements through context. Compared with existing SOTA methods, the proposed method achieved an average improvement of 6.5% in IOU on the real-world project dataset.},
  archive      = {J_KBS},
  author       = {Wenxin Tao and Xiaohong Su and Yekun Ke and Yi Han and Yu Zheng and Hongwei Wei},
  doi          = {10.1016/j.knosys.2025.113341},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113341},
  shortjournal = {Knowl. Based Syst.},
  title        = {Transformer-based statement level vulnerability detection by cross-modal fine-grained features capture},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stand-in model protection: Synthetic defense for membership inference and model inversion attacks. <em>KBS</em>, <em>316</em>, 113339. (<a href='https://doi.org/10.1016/j.knosys.2025.113339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membership inference and model inversion attacks present a substantial risk to the security of neural network models and their training data. Current defense methods often rely on strategies such as noise addition or regularization. However, these approaches either prove ineffective against advanced attacks or fail to strike a satisfactory balance between fidelity and effectiveness. To tackle this challenge, we propose Stand-in Model Protection (SMP) as a countermeasure, establishing a fake target for potential adversaries. The name “SMP” reflects our approach of training a model on a synthetic dataset to serve as a stand-in for the original model. In SMP, we leverage a label-directed diffusion model (LDM) trained on the original dataset to generate the synthetic dataset. Subsequently, we employ the original classifier model to filter the synthetic data, discarding entries that do not meet a predefined confidence score threshold. Following this filtration process, we train the stand-in model using the filtered synthetic dataset and release it publicly, offering only label-only access. In this setup, the adversary can solely access the stand-in model, remaining unaware of the original model or dataset. Consequently, any attacks launched by the adversary are redirected towards the falsified target, namely the synthetic dataset. We demonstrate that the synthetic dataset achieves δ -PAC security if the Fréchet inception distance between the synthetic and original datasets exceeds a predetermined threshold. In this context, δ -PAC security refers to the property whereby any hypothesis test aimed at determining the source dataset of a fixed number of samples drawn from either the synthetic or original dataset exhibits at least δ error probability.},
  archive      = {J_KBS},
  author       = {Huajie Chen and Tianqing Zhu and Shouling Ji and Wanlei Zhou},
  doi          = {10.1016/j.knosys.2025.113339},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113339},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stand-in model protection: Synthetic defense for membership inference and model inversion attacks},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teacher privileged distillation: How to deal with imperfect teachers?. <em>KBS</em>, <em>316</em>, 113338. (<a href='https://doi.org/10.1016/j.knosys.2025.113338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm of learning using privileged information leverages privileged features present at training time, but not at prediction, as additional training information. The privileged learning process is addressed through a knowledge distillation perspective: information from a teacher learned with regular and privileged features is transferred to a student composed exclusively of regular features. While most approaches assume perfect knowledge for the teacher, it can commit mistakes. Assuming that, we propose a novel privileged distillation framework with a double contribution. Firstly, a designed function to imitate the teacher when it classifies correctly and to differ in cases of misclassification. Secondly, an adaptation of the cross-entropy loss to appropriately penalize the instances where the student outperforms the teacher. Its effectiveness is empirically demonstrated on datasets with imperfect teachers, significantly enhancing the performance of state-of-the-art frameworks. Furthermore, necessary conditions for successful privileged learning are presented, along with a dataset categorization based on the information provided by the privileged features.},
  archive      = {J_KBS},
  author       = {Mario Martínez-García and Iñaki Inza and Jose A. Lozano},
  doi          = {10.1016/j.knosys.2025.113338},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113338},
  shortjournal = {Knowl. Based Syst.},
  title        = {Teacher privileged distillation: How to deal with imperfect teachers?},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next-generation IIoT security: Comprehensive comparative analysis of CNN-based approaches. <em>KBS</em>, <em>316</em>, 113337. (<a href='https://doi.org/10.1016/j.knosys.2025.113337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) presents a range of benefits but also introduces security vulnerabilities. This paper systematically compares different deep learning model structures for IIoT intrusion detection. Four Convolutional Neural Network (CNN) classifiers are implemented, including hybrid CNN-GRU, 1D Xception, and 1D Resnet models. The evaluation focuses on robustness and generalizability across two datasets to assess overall performance and detection rates. To handle imbalanced data, preprocessing involves PCA feature selection and hybrid resampling techniques. Furthermore, we design a distributed training process for massive datasets and continuous learning, enabling efficient large-scale processing. For the experimental evaluation, we make use of two datasets with multi-label classification tasks and analyze performance metrics of different models in terms of their detection abilities and efficiency. The proposed methods demonstrate strong performance, successfully identifying even rare attacks. In addition, we conduct a performance comparison with existing publications that utilize the same datasets, confirming that our models are on par with state-of-the-art IIoT models.},
  archive      = {J_KBS},
  author       = {Huiyao Dong and Igor Kotenko and Dmitry Levshun},
  doi          = {10.1016/j.knosys.2025.113337},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113337},
  shortjournal = {Knowl. Based Syst.},
  title        = {Next-generation IIoT security: Comprehensive comparative analysis of CNN-based approaches},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling for cloud manufacturing with uncertain events by hierarchical reinforcement learning and attention mechanism. <em>KBS</em>, <em>316</em>, 113335. (<a href='https://doi.org/10.1016/j.knosys.2025.113335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud manufacturing provides a platform for many-to-many scheduling of consumer tasks assigned to service providers. The dynamics and uncertainties of the cloud environment pose stringent requirements on the real-time performance and generalizability of scheduling algorithms. Moreover, the continuous variations in environmental states, task scale, and service statuses further complicate decision-making. However, existing dynamic scheduling methods, primarily developed to address static environments and constant scales, fall short of addressing the escalating volatility and complexity of real-world scheduling. To achieve near-real-time decision-making, a deep hierarchical reinforcement learning framework incorporating attention mechanisms and pointer networks is proposed for multi-objective dynamic scheduling in cloud manufacturing. This framework divides the scheduling problem into three subproblems (optimization objectives, manufacturing tasks, and service selection) and leverages a hierarchical structure to realize a three-step scheduling decision-making process. The proposed framework comprises three encoder–decoder-based agents, each corresponding to a subproblem and collaborating to achieve the overall decision. The agents utilize the multi-head attention mechanism to extract inter-task and inter-service relationships, enhancing decision precision and environmental adaptability. Additionally, the pointer network is incorporated into each agent, endowing the proposed framework with generalizability when inserting new tasks (or services) or removing existing ones. Experimental results across nine dynamic scenarios demonstrate that our framework outperforms five deep reinforcement learning algorithms and three meta-heuristics in terms of scheduling performance and runtime. Results from six out-of-training-scale instances further indicate that our framework exhibits superior generalization and scalability.},
  archive      = {J_KBS},
  author       = {Jianxiong Zhang and Yuming Jiang and Bing Guo and Tingting Liu and Dasha Hu and Jinbo Zhang and Yifei Deng and Hao Wang and Jv Yang and Xuefeng Ding},
  doi          = {10.1016/j.knosys.2025.113335},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113335},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic scheduling for cloud manufacturing with uncertain events by hierarchical reinforcement learning and attention mechanism},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable artificial intelligence (XAI) in glaucoma assessment: Advancing the frontiers of machine learning algorithms. <em>KBS</em>, <em>316</em>, 113333. (<a href='https://doi.org/10.1016/j.knosys.2025.113333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating machine learning (ML) into healthcare has rapidly advanced, necessitating precise and reliable explanatory mechanisms, especially in critical areas such as glaucoma detection and analysis. This systematic review examines how Explainable Artificial Intelligence (XAI) enhances the transparency and comprehensibility of machine learning algorithms for glaucoma detection. By emphasizing XAI, the review aims to demonstrate its critical importance in a field where accuracy and trust are essential. To evaluate the effectiveness of XAI in conjunction with ML, this review meticulously assesses various XAI methodologies for their ability to clarify the intricate workings of ML models. The analysis is grounded in examining well-known medical imaging datasets geared towards glaucoma detection, providing a focused overview of XAI’s role in interpreting complex ML decisions in a healthcare context. Findings from the review indicate that applying XAI techniques has significantly improved clinician trust in ML-driven decisions by making the decision-making processes more transparent and comprehensible. This enhancement in trust is attributed to XAI’s ability to provide deeper insights into the logic and reasoning behind ML algorithms, thereby facilitating a better understanding of their outcomes. Although the application of XAI in glaucoma detection and analysis has shown promising improvements in clinician trust and the transparency of ML models, there remains a critical need for more comprehensive research. Such studies would aim to fully ascertain the long-term impacts of XAI-enhanced ML on healthcare outcomes, particularly in glaucoma analysis, where the stakes for accurate and understandable diagnostic tools are incredibly high.},
  archive      = {J_KBS},
  author       = {Sonia Farhana Nimmy and Omar K. Hussain and Ripon K. Chakrabortty and Sajib Saha},
  doi          = {10.1016/j.knosys.2025.113333},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113333},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainable artificial intelligence (XAI) in glaucoma assessment: Advancing the frontiers of machine learning algorithms},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-tuning decomposition strategy in cooperative co-evolutionary algorithms for high-dimensional feature selection. <em>KBS</em>, <em>316</em>, 113327. (<a href='https://doi.org/10.1016/j.knosys.2025.113327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing trend of high-dimensional problems in multidisciplinary domains such as healthcare, finance, and bioinformatics, highlights the importance of dimensionality reduction techniques to manage data complexity. Among the available approaches, feature selection has been used recurrently, as it enhances the predictive performance and interpretability of machine learning models by selecting a subset of discriminative features. However, traditional feature selection algorithms often struggle with large-scale datasets due to The Curse of Dimensionality. Cooperative co-evolutionary algorithms (CCEAs) emerge as a promising paradigm for feature selection in Big Data. By decomposing a high-dimensional problem into low-dimensional subproblems, they allow subpopulations to evolve independently and collaborate to identify high-quality feature subsets. As the first stage of a CCEA, decomposition significantly impacts optimization, as poorly structured subproblems hinder search efficiency and cause premature convergence. Determining the number of subproblems and their feature allocation is a crucial part of this process − too many subproblems increase computational costs, while too few limit decomposition benefits. Motivated by this, we propose a decomposition strategy that leverages domain knowledge inherent in the data to generate robust subproblems through three stages: discriminative feature projection, feature space reduction, and feature clustering. Throughout these steps, we integrate low-cost parameter tuning mechanisms to optimize the number and size of subproblems, thereby eliminating the need for extensive offline experimentation through complete optimizations. We show that our approach not only relieves users from manual tuning, but also enhances model explainability by achieving more compact solutions, with an average of 32.85 % fewer features than baseline methods.},
  archive      = {J_KBS},
  author       = {Pedro Vinícius A.B. Venâncio and Lucas S. Batista},
  doi          = {10.1016/j.knosys.2025.113327},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113327},
  shortjournal = {Knowl. Based Syst.},
  title        = {A self-tuning decomposition strategy in cooperative co-evolutionary algorithms for high-dimensional feature selection},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dictionary attack on ECG authentication system using adversarial optimization and clustering. <em>KBS</em>, <em>316</em>, 113326. (<a href='https://doi.org/10.1016/j.knosys.2025.113326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram(ECG)-based biometric authentication has become a promising method to improve security in wearable devices due to its inherent uniqueness and difficulty to replicate. However, no studies currently demonstrate that ECG authentication can resist modern attack techniques employed against biometric authentication. In this paper, we present a novel dictionary attack against ECG authentication systems, which poses a significant threat. In contrast to conventional targeted attacks, this approach utilizes random pairing to breach a vast number of users, without requiring specific information about their biometric data. Our approach leverages adversarial optimization and clustering to generate synthetic ECG waveforms capable of bypassing authentication mechanisms of various systems, revealing critical vulnerabilities in the current implementation of ECG-based biometrics. We comprehensively evaluate the effectiveness of this attack across different ECG authentication models, demonstrating that despite the intrinsic uniqueness of ECG signals, a substantial number of users are vulnerable. Our attack method can bypass the authentication system of an average of 20% of users even at the most stringent false acceptance rate of 1%. With up to five attack attempts allowed, our method can bypass up to 62% of users’ ECG authentication models.},
  archive      = {J_KBS},
  author       = {Bonan Zhang and Lin Li and Chao Chen and Ickjai Lee and Kyungmi Lee and Tianqing Zhu and Kok-Leong Ong},
  doi          = {10.1016/j.knosys.2025.113326},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113326},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel dictionary attack on ECG authentication system using adversarial optimization and clustering},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the transferability of adversarial examples through semantic-mixup inputs. <em>KBS</em>, <em>316</em>, 113325. (<a href='https://doi.org/10.1016/j.knosys.2025.113325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are highly vulnerable to perturbations that are imperceptible to humans, especially transferable attacks, which can attack multiple models across different architectures without access to the target model, posing a significant security threat to real-world deployments. Various methods have been proposed to enhance the transferability of adversarial examples from different perspectives, among which input transformation-based attacks have shown particularly notable performance. However, existing methods either apply transformations to a single image or perform global transformations, resulting in insufficient enhancement of critical semantic content, which limit the transferability of adversarial samples. We have identified that the mid-low frequency components of an image embody the majority of the critical semantic information and play a dominant role in the model’s decision-making process. To this end, in this paper, we propose a novel input transformation-based attack called Semantic-Mixup Attack (SMA), which employs a primary–secondary relation, considering the input image as primary and a set of images randomly sampled from other categories as secondary. SMA utilizes the mid-low frequency components of the secondary image to represent corresponding semantic features and mixes them locally with the primary image, thereby increasing the diversity of semantic features in the input image and significantly reducing overfitting to the substitute model. By aggregating these semantic feature from other categories, SMA obtains a reasonable and stable gradient direction, which achieves a more global maximum and exhibits much better transferability. Extensive experiments on the ImageNet compatible dataset demonstrate the outstanding performance of our method compared to existing input transformation-based attacks, both on undefended and advanced defense models. Furthermore, our method can be combined with other attacks to further improve the adversarial transferability.},
  archive      = {J_KBS},
  author       = {Fuquan Gan and Yan Wo},
  doi          = {10.1016/j.knosys.2025.113325},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113325},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving the transferability of adversarial examples through semantic-mixup inputs},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring gene regulatory networks via directed graph contrastive representation learning. <em>KBS</em>, <em>316</em>, 113324. (<a href='https://doi.org/10.1016/j.knosys.2025.113324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring Gene Regulatory Networks (GRNs) has been a key focus in computational biology. Many methods have emerged that utilize existing graph structures and node vectors to infer potential edges, among which contrastive learning methods have received widespread attention. However, current graph contrastive learning methods are not specifically designed for directed graphs, which limits their effectiveness in inferring directed GRNs. In this paper, we propose to infer GRNs based on Directed Graph Contrastive Representation Learning (DGCRL). Considering the topological properties of directed graphs, we elaborately design an augmentation function, reversing edges, for transforming GRNs into source and target views. The augmentation function provides different node contexts for message passing in different views. Based on the two views, two attention-based encoders are deployed to learn the source and target vectors for each node, respectively. The dual vectors can capture richer semantic information and asymmetric node relationships in the directed graph. As the model parameters are continuously optimized, the source and target node of the regulatory edge are indirectly pulled closer. This enables the identification of such a specific pattern using a decoder, thereby inferring GRNs via a link prediction approach. Experiments on the DREAM5 and seven single-cell RNA sequencing (scRNA-seq) datasets with four types of ground-truth networks show that DGCRL can achieve better performance, demonstrating its great potential for large-scale GRN inference. The code is available at https://github.com/longkf/DGCRL .},
  archive      = {J_KBS},
  author       = {Kaifu Long and Luxuan Qu and Weiyiqi Wang and Zhiqiong Wang and Mingcan Wang and Junchang Xin},
  doi          = {10.1016/j.knosys.2025.113324},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113324},
  shortjournal = {Knowl. Based Syst.},
  title        = {Inferring gene regulatory networks via directed graph contrastive representation learning},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malicious encrypted traffic detection method based on multi-granularity representation under data imbalance conditions. <em>KBS</em>, <em>316</em>, 113320. (<a href='https://doi.org/10.1016/j.knosys.2025.113320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic encryption technology safeguards the secure transmission of user data but also enables attackers to conceal malicious activities. With the widespread adoption of encrypted communication protocols and the growing volume of encrypted traffic, accurately identifying malicious encrypted traffic has become a critical challenge in network security. Traditional methods for encrypted traffic classification rely on manual feature extraction and are hindered by imbalanced data distribution, leading to low classification accuracy. In this paper, we propose a maliciously encrypted traffic detection method based on multi-granularity representation under data imbalance conditions. Firstly, we propose a feature extraction method for encrypted traffic based on multi-granularity representation to fully extract the behavioral and temporal characteristics of the traffic in depth and improve the feature extraction effect. Secondly, to address the problem of imbalanced data distribution in malicious encrypted traffic, we introduce the prompt learning algorithm, which solves the issue of imbalanced malicious encrypted traffic datasets. This method improves detection effectiveness by constructing prompt samples, comprehensively learning the feature space of data samples, and transforming the multi-classification problem into multiple dichotomous classification problems. Lastly, we conduct experiments using real network traffic datasets to validate our proposed method. The results demonstrate that our approach outperforms the MLM model by 30% in both binary and multi-class classification tasks. Furthermore, when compared to other deep learning models, our method improves performance by 20% to 50%. Overall, our proposed method exhibits strong generalization and usability, along with effective capabilities for detecting and classifying malicious encrypted traffic.},
  archive      = {J_KBS},
  author       = {Tao Li and Zhiwei Yang and Wenshan Li and Linfeng Du and Xiaolong Lan and Junjiang He},
  doi          = {10.1016/j.knosys.2025.113320},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113320},
  shortjournal = {Knowl. Based Syst.},
  title        = {Malicious encrypted traffic detection method based on multi-granularity representation under data imbalance conditions},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating covariance overfitting in out-of-distribution detection through intrinsic parameter learning. <em>KBS</em>, <em>316</em>, 113318. (<a href='https://doi.org/10.1016/j.knosys.2025.113318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting out-of-distribution (OOD) samples is essential for ensuring model robustness, as it helps identify novel class instances and minimizes errors caused by unfamiliar inputs. However, current OOD detection methods often overfit to the covariance information of in-distribution (ID) training data, neglecting the intrinsic semantic relationships. When ID test samples undergo covariance shifts, OOD detectors may incorrectly classify them as OOD, resulting in degraded detection performance. In this paper, inspired by the lottery ticket hypothesis – which suggests that only a subset of parameters is crucial for generalization – we identify that only a portion of the model’s parameters is necessary for capturing intrinsic semantic correlations and achieving effective OOD detection under covariance shifts. We refer to these as intrinsic parameters, while the remaining extrinsic parameters tend to overfit to covariance information. Building on this observation, we propose Intrinsic Parameter Learning (IPL), a method that mitigates the negative effects of covariance overfitting during training, thereby preserving intrinsic semantic information. Specifically, in each training iteration, we separate the parameters into intrinsic and extrinsic groups, applying distinct update strategies to each. Additionally, we decouple the influence of logits’ norms through constrained optimization to strengthen the intrinsic parameters. Extensive experiments demonstrate that IPL significantly enhances OOD detection performance in both near-OOD and far-OOD scenarios. Furthermore, IPL can be seamlessly integrated with state-of-the-art OOD detection methods.},
  archive      = {J_KBS},
  author       = {Yusi Chen and Yi Wu and Tianyou Wang and Shuo Zhang and Daxin Zhu and Chao Liu},
  doi          = {10.1016/j.knosys.2025.113318},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113318},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mitigating covariance overfitting in out-of-distribution detection through intrinsic parameter learning},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-granularity multi-instance multi-label learning with variational autoencoder. <em>KBS</em>, <em>316</em>, 113317. (<a href='https://doi.org/10.1016/j.knosys.2025.113317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-instance multi-label learning (MIML) is a weakly supervised approach that models relationships between complex objects and multiple labels, where each object is represented as a bag of instances. A key advantage of MIML is its ability to perform both bag-level and instance-level multi-label predictions, relying solely on bag-level labels. However, a significant performance gap persists between instance-level MIML algorithms and fully supervised learning approaches due to the lack of instance-level labels. Existing MIML algorithms address this challenge by treating bag labels as ambiguous and attempting to reduce supervision imprecision. Moreover, they often assume that instances are independent and identically distributed (i.i.d.) and rely on prior knowledge to learn label correlations, which is impractical in real-world scenarios. To address these challenges, we propose MIMLVAE, a novel dual-granularity MIML algorithm based on a variational autoencoder. MIMLVAE employs a graph attention network to dynamically capture label correlations and instance dependencies, eliminating the i.i.d. assumption and prior knowledge. By treating all instances within a bag equally, it infers effective bag-level and instance-level representations for dual-granularity prediction. At the same time, the label encoder captures label-specific prototype representations, facilitating prototype-based classification at both the bag and instance levels without requiring label disambiguation. Furthermore, MIMLVAE integrates a Gaussian mixture model into the shared latent space of features and labels, mitigating posterior collapse and over-regularization. Experiments on six standard MIML datasets demonstrate that MIMLVAE significantly outperforms state-of-the-art methods in both bag-level and instance-level multi-label classification tasks.},
  archive      = {J_KBS},
  author       = {Meixia Wang and Yuhai Zhao and Yejiang Wang and Miaomiao Huang and Xuze Liu and Xingwei Wang},
  doi          = {10.1016/j.knosys.2025.113317},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113317},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-granularity multi-instance multi-label learning with variational autoencoder},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM4Jobs: Unsupervised occupation extraction and standardization leveraging large language models. <em>KBS</em>, <em>316</em>, 113302. (<a href='https://doi.org/10.1016/j.knosys.2025.113302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated occupation extraction and standardization from free-text job postings and resumes are crucial for applications like job recommendation and labor market policy formation. This paper introduces LLM4Jobs, a novel unsupervised methodology that taps into the capabilities of large language models (LLMs) for occupation coding. LLM4Jobs uniquely harnesses both the natural language understanding and generation capacities of LLMs. Evaluated on rigorous experimentation on synthetic and real-world datasets, we demonstrate that LLM4Jobs consistently surpasses unsupervised state-of-the-art benchmarks, demonstrating its versatility across diverse datasets and granularities. As a side result of our work, we present both synthetic and real-world datasets, which may be instrumental for subsequent research in this domain. Overall, this investigation highlights the promise of contemporary LLMs for the intricate task of occupation extraction and standardization, laying the foundation for a robust and adaptable framework relevant to both research and industrial contexts.},
  archive      = {J_KBS},
  author       = {Nan Li and Bo Kang and Tijl De Bie},
  doi          = {10.1016/j.knosys.2025.113302},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113302},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM4Jobs: Unsupervised occupation extraction and standardization leveraging large language models},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-graph regularized sparse robust adaptive concept factorization. <em>KBS</em>, <em>316</em>, 113299. (<a href='https://doi.org/10.1016/j.knosys.2025.113299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inability of traditional concept factorization methods to fully capture the intricate local and global manifold structures within the raw data space, they are unable to obtain detailed structural information effectively. To address this limitation, we put forward a concept factorization approach named sparse dual-graph regularized concept factorization with stable adaptive spectral clustering (SDCFSAS). Primarily, SDCFSAS leverages Dot-Product Weighting and stable adaptive spectral clustering to construct a similarity matrix that learns intrinsic features of the data, especially nonlinear or non-convex structures. Besides, by utilizing a robust estimator to filter the side effects of outlier points, it ensures that normal samples play a pivotal function in the construction of the model, enhancing the robustness and reliability of the model. Furthermore, the introduction of L 2 , r -norm ( 1 ≤ r ≤ 2 ) taking for a measure on the deviation term further strengthens the robustness. Additionally, the computable sparse L 2 , p -norm ( 0 < p ≤ 1 ) regularization terms are employed to establish a sparse model, improving the model’s generalization capability, computational efficiency, and noise reduction. Finally, The performance of algorithm used to solve SDCFSAS is studied in detail, especially its convergence and computational complexity. To demonstrate the clustering performance and recognition ability of our SDCFSAS, we proceed comparative experiments on eight real-world datasets against other similar state-of-the-art algorithms. Moreover, statistical analysis is employed to validate the results, which showcase the significant advantages of our approach.},
  archive      = {J_KBS},
  author       = {Weizhi Xiong and Yanrong Ma and Jun Ma},
  doi          = {10.1016/j.knosys.2025.113299},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113299},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-graph regularized sparse robust adaptive concept factorization},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-based natural answer generation via effective graph learning. <em>KBS</em>, <em>316</em>, 113288. (<a href='https://doi.org/10.1016/j.knosys.2025.113288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: Natural Answer Generation (NAG) aims to generate natural and fluent answers to user questions. Existing NAG methods typically employ fixed-hop retrieval to construct knowledge graphs and utilize attention-based networks for answer generation. However, these approaches lack interpretability, struggle to filter out redundant information in the graph, and are computationally intensive. Methods: To address these issues, this paper introduces an innovative approach AdaptQA model. Initially, AdaptQA constructs a knowledge graph from the knowledge base (KB) using an adaptive multi-hop retrieval algorithm. Subsequently, it generates answers through the Graph-based Mamba module (GBM), effectively filtering out redundant information. Finally, the answers are optimized using a pre-trained large language model to enhance their fluency and accuracy. Novelty: The proposed AdaptQA model introduces a new approach to NAG by improving the completeness of the knowledge graph and optimizing question answers. This method overcomes the limitations of existing NAG techniques by reducing the complexity of model inference. Findings: Through extensive experiments on two benchmark datasets, HotpotQA and WikiHop, AdaptQA demonstrates superior performance, significantly outperforming existing NAG methods. Specifically, AdaptQA achieves an accuracy of 94.47% on the HotpotQA dataset and 91.38% on the WikiHop dataset.},
  archive      = {J_KBS},
  author       = {Zedong Liu and Jianxin Li and Yongle Huang and Ningning Cui and Lili Pei},
  doi          = {10.1016/j.knosys.2025.113288},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113288},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-based natural answer generation via effective graph learning},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSAM: A simple and general stereo alignment module for multi-view document clustering. <em>KBS</em>, <em>316</em>, 113282. (<a href='https://doi.org/10.1016/j.knosys.2025.113282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view document clustering leverages diverse information from multiple perspectives to enhance clustering performance. In practice, multi-view datasets exist in a stereo space comprising features, views, and document samples. Although view alignment has become essential for maintaining representation consistency across views, current approaches face two critical limitations: (1) if semantically related features in different views are not properly associated, it may lead to a fragmented understanding of the data, and (2) if existing methods ignore sample alignment during the representation learning process, they may fail to preserve cluster structures. To address these limitations, we proposed and investigated a General Stereo Alignment Module (GSAM) with three key aspects: (1) a feature-level alignment mechanism to capture cross-view feature correlations by establishing connections between feature representations from different views; (2) view-level alignment to maintain semantic consistency across different views of identical samples, ensuring that the learned representations preserve view-specific characteristics; and (3) sample-level alignment to optimize the similarity relationships between samples during representation learning, enhancing the discriminative power for multi-view clustering. For effective feature extraction, GSAM employs specialized backbone networks (pre-trained language models for contextual views and statistical approaches for non-contextual views), followed by learnable view-specific autoencoders to enhance feature representations. Through this hierarchical alignment strategy, GSAM effectively captures the intrinsic relationships within multi-view document datasets that inherently exist in a sophisticated stereo space. Notably, GSAM is designed as a lightweight plug-and-play module that can seamlessly be integrated into various multi-view learning frameworks. The experimental results on five different types of multi-view document datasets demonstrate GSAM’s superior performance, notably with NMI gains of approximately 5% or higher compared to the second-best methods on the three datasets. Our code is publicly available at https://github.com/m22453/GSAM .},
  archive      = {J_KBS},
  author       = {Ruina Bai and Ruizhang Huang and Yanping Chen and Yongbin Qin},
  doi          = {10.1016/j.knosys.2025.113282},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113282},
  shortjournal = {Knowl. Based Syst.},
  title        = {GSAM: A simple and general stereo alignment module for multi-view document clustering},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSTG: An interpretable spatio-temporal selective state-space model for multi-sensor data fusion in intelligent diagnosis. <em>KBS</em>, <em>316</em>, 113278. (<a href='https://doi.org/10.1016/j.knosys.2025.113278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning algorithms have gained significant attention in fault diagnosis because of their ability to model complex data patterns. Traditional neural networks, such as convolutional and recurrent networks, typically handle Euclidean data, which may not capture relationships inherent in multi-sensor systems. In contrast, graph neural networks (GNNs) process graph-structured data, leveraging topology to better capture inter-sensor relationships. Recent GNN-based methods succeed in fault diagnosis by focusing on interactions between individual nodes. However, they often overlook the system’s temporal evolution, crucial for diagnosing faults that develop over time. To address this, we explore Selective State Space Models (SSSMs), which model graph networks as dynamic systems. By integrating SSSMs into spatio-temporal graph networks, we propose the Selective Spatio-temporal Graph Neural Network (SSTG). This model harnesses SSSMs to treat spatio-temporal graphs as unified systems, enabling accurate extraction of key fault features over time. We also design a dual-path Bayesian fusion GNN that incorporates uncertainty-weighted contributions, enhancing the model’s ability to handle varying data reliability. Empirical studies on three benchmark datasets show that the SSTG model significantly outperforms existing methods in performance and interpretability. Our work underscores the significance of incorporating SSSMs into graph-based frameworks, introducing new possibilities for advanced fault diagnosis.},
  archive      = {J_KBS},
  author       = {Chengming Wang and Yanxue Wang and Feng Zheng and Meng Li and Ruichen Xia},
  doi          = {10.1016/j.knosys.2025.113278},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113278},
  shortjournal = {Knowl. Based Syst.},
  title        = {SSTG: An interpretable spatio-temporal selective state-space model for multi-sensor data fusion in intelligent diagnosis},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A classification method based on dominance neighborhood granularity. <em>KBS</em>, <em>316</em>, 113276. (<a href='https://doi.org/10.1016/j.knosys.2025.113276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification algorithms, widely utilized in various practical settings, are increasingly demanded in critical domains to not only display high accuracy but also provide interpretable results. Granular Computing (GrC) theory, recognized for its capability to clarify complex data and issues through its concept of granularity, has become an intuitive and straightforward approach in problem-solving. Nevertheless, contemporary granular computing-based classification techniques are largely confined to the processing of Euclidean features of data, thereby neglecting relationships and structures between data within the data set. In response, we introduce a classification method based on dominance neighborhood granularity (CDNG). CDNG, while accommodating Euclidean features, also incorporates non-Euclidean features to obtain diverse information, thereby augmenting predictive accuracy. Specifically, CDNG establishes a dominance neighborhood granularity drawn from neighborhood granularity and dominance granularity. Subsequently, we appraise CDNG using real datasets and performance metrics, including accuracy (ACC), Recall Score (RS), and F1 score (F1), contrasting our findings with other classification methodologies. We conclude with an analysis of parameter experiments and multi-angle noise experiments specific to CDNG. The experimental results affirm that CDNG outperforms other methods in terms of accuracy while maintaining robustness concomitant with high accuracy.},
  archive      = {J_KBS},
  author       = {Bin Yu and Xu He and Weiping Ding},
  doi          = {10.1016/j.knosys.2025.113276},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113276},
  shortjournal = {Knowl. Based Syst.},
  title        = {A classification method based on dominance neighborhood granularity},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKE-former: A clinical knowledge-enhanced transformer for disease classification in telemedicine. <em>KBS</em>, <em>316</em>, 113259. (<a href='https://doi.org/10.1016/j.knosys.2025.113259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, disease classification in telemedicine scenario has become an important research topic, as it enables consultations without the need for face-to-face interactions between doctors and patients, which is especially beneficial for individuals in remote regions. Existing disease classification methods rely on specialized medical data to diagnose diseases, such as clinical records, radiology images, biological signals, etc. However, in telemedicine scenarios, only the patient’s self-description and image taken with a mobile phone are available. To deal with it, we first construct a corresponding dataset from the online consultation system of a large public hospital, which consists of patient self-description texts, images, and doctor’s diagnosis results. We propose a clinical knowledge-enhanced transformer (CKE-Former). Specifically, we first construct a multi-modal medical knowledge base (MMedKB), then we propose a medical concept normalization module and a multi-modal retrieval mechanism into our model, accessing specialized medical information to achieve disease classification. Experimental results show that our model is competitive compared with existing methods, which provides a solid benchmark for future research.},
  archive      = {J_KBS},
  author       = {Qi Peng and Yi Cai and Jiankun Liu and Xing Chen and Zefeng Wang and Jiayuan Xie and Qing Li},
  doi          = {10.1016/j.knosys.2025.113259},
  journal      = {Knowledge-Based Systems},
  month        = {5},
  pages        = {113259},
  shortjournal = {Knowl. Based Syst.},
  title        = {CKE-former: A clinical knowledge-enhanced transformer for disease classification in telemedicine},
  volume       = {316},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal multiobjective evolutionary algorithm based on neighborhood and enhanced special crowding distance. <em>KBS</em>, <em>315</em>, 113340. (<a href='https://doi.org/10.1016/j.knosys.2025.113340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective problems (MMOPs) may involve multiple Pareto optimal solutions corresponding to the same objective function value. Although several multimodal multiobjective evolutionary algorithms (MMOEAs) exist to address such problems, finding Pareto sets (PSs) that balance diversity and convergence and achieve a well-distributed Pareto front (PF) remains a challenging task. This paper proposes an MMOEA called the multimodal multiobjective evolutionary algorithm based on neighborhood and enhanced special crowding distance (MMO_NESCD) to address the abovementioned challenges. This MMOEA incorporates the enhanced special crowding distance (ESCD) and adaptive neighborhood strategy (ANS) in environmental selection. In MMO_NESCD, the population is clustered in the decision space to increase diversity. A nondominated sorting process that uses ESCD is subsequently employed to select individuals with high diversity for the next generation. This approach balances diversity and convergence in decision and objective spaces. Furthermore, during the update of the optimal archive, ANS is combined with ESCD to further increase population diversity. This algorithm achieves balanced PSs with diversity and convergence and a well-distributed PF in MMOPs. The results show that the new approach achieves better results than competitive methods do on CEC 2019 test problems.},
  archive      = {J_KBS},
  author       = {Caitong Yue and Jiankang Song and Jing Liang and Mengnan Liu and Kunjie Yu and Hongyu Lin and Ying Bi},
  doi          = {10.1016/j.knosys.2025.113340},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113340},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multimodal multiobjective evolutionary algorithm based on neighborhood and enhanced special crowding distance},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-city transfer learning for traffic forecasting via incremental distribution rectification. <em>KBS</em>, <em>315</em>, 113336. (<a href='https://doi.org/10.1016/j.knosys.2025.113336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality traffic forecasting is critical to facilitating urban intelligent transformation. In deep learning enabled urban intelligence era, accurate traffic forecasting requires large-scale data, obtaining which is not always feasible because of limitations posed by scarce equipment resources in cross-city scenarios. To address this problem, existing methods propose to learn transferable meta-knowledge from rich source city data so as to guide the forecasting on the target city. However, they mainly focus on obtaining a source distribution-centric or source and target shared knowledge, rather than target distribution-centric transferable knowledge, which results in unavoidable disturbances due to migration noise. In this case, we propose a cross-city transfer learning method based on Incremental Distribution Rectification from the perspectives of distribution discrepancy quantification and calibration, called Cross-IDR. Specifically, we leverage the Koopman enabled Optimal Transport method to measure the transfer process between distributions, thus modifying the source distribution-centric meta-knowledge to be target distribution-centric. In addition, a Spatio-Temporal Interaction alignment method is proposed to enhance the mining of cross-city interactions between spatial and temporal information. We verify the effectiveness of Cross-IDR on real-world traffic datasets, and the results demonstrate that it outperforms state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Banglie Yang and Runze Li and Yijing Wang and Sha Xiang and Shuo Zhu and Cheng Dai and Shengxin Dai and Bing Guo},
  doi          = {10.1016/j.knosys.2025.113336},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113336},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-city transfer learning for traffic forecasting via incremental distribution rectification},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New generation thermal traffic sensor: A novel dataset and monocular 3D thermal vision framework. <em>KBS</em>, <em>315</em>, 113334. (<a href='https://doi.org/10.1016/j.knosys.2025.113334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications like traffic safety analysis require highly accurate trajectory data in world coordinates of traffic participants. While systems like LiDAR or stereo cameras can provide such data, they are costly, sensitive to weather and lighting conditions, and may raise privacy concerns. Thermal roadside cameras offer a robust, privacy-compliant alternative. However, monocular thermal cameras face challenges due to the ambiguous relationship between pixel coordinates and world coordinates. Existing methods for monocular 3D detection from RGB roadside cameras often rely on simplifications or the complex task of depth estimation, which limits their effectiveness. Additionally, no dataset currently exists for monocular 3D detection using thermal roadside imagery. This work introduces a dataset of 9,591 thermal images annotated in 3D world coordinates, including detailed camera calibration and surface models. It proposes a lightweight neural network architecture leveraging a projection-based method to incorporate road surface information. By detecting bottom-center contact points in image space and projecting them into 3D, the presented framework efficiently estimates object's position, dimensions, and orientations in 3D. The presented approach outperforms homography-based methods by 25 percentage points in mean average precision (mAP). It achieves real-time performance with 54 FPS on a GPU server and 17 FPS on an NVIDIA Jetson Xavier NX, making it suitable for edge deployment. Unlike RGB-based systems, our method ensures data privacy and remains effective in diverse weather and lighting conditions, enabling reliable trajectory analysis and near-miss detection for traffic safety applications. Readers can find the dataset here: https://doi.org/10.17632/tw6ghtv624.1 . The code used in this work is available here: https://github.com/4rnd25/new_generation_thermal_traffic_sensor .},
  archive      = {J_KBS},
  author       = {Arnd Pettirsch and Alvaro Garcia-Hernandez},
  doi          = {10.1016/j.knosys.2025.113334},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113334},
  shortjournal = {Knowl. Based Syst.},
  title        = {New generation thermal traffic sensor: A novel dataset and monocular 3D thermal vision framework},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User disambiguation learning for precise shared-account marketing: A hierarchical self-attentive sequential recommendation method. <em>KBS</em>, <em>315</em>, 113328. (<a href='https://doi.org/10.1016/j.knosys.2025.113328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision marketing recommendations face significant challenges due to entanglement of sharing behavior in shared-account marketing. To disentangle shared user behaviors within strict privacy policies, this study proposes the Hierarchical Self-Attentive Sequential Recommendation (HierSASRec) model. HierSASRec employs user disambiguation learning to dynamically identify individual users within shared accounts, utilizing two-level representations for account-item and user-item interactions. By integrating the time intervals of item interactions into the density-based spatial clustering of applications with noise (DBSCAN) method, namely, the time-aware DBSCAN method, HierSASRec automatically extracts user-level sequences beyond fixed user counts, enhancing the identification of similar preferences and close interactions. Through a self-attention mechanism, HierSASRec combines hierarchical interaction information to optimize marketing precision. Additionally, a random user switch mechanism is devised to mitigate noise from long-term sequences, and focuses on immediate marketing decisions for the current user. Experimental validation within real-world datasets underscores the superiority of HierSASRec over state-of-the-art baselines, affirming its practical efficacy in enhancing marketing precision. The code is available at: https://github.com/muyunping123/HierSASRec .},
  archive      = {J_KBS},
  author       = {Weiyi Duan and Decui Liang},
  doi          = {10.1016/j.knosys.2025.113328},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113328},
  shortjournal = {Knowl. Based Syst.},
  title        = {User disambiguation learning for precise shared-account marketing: A hierarchical self-attentive sequential recommendation method},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin Q-learning-driven forest ecosystem optimization for feature selection. <em>KBS</em>, <em>315</em>, 113323. (<a href='https://doi.org/10.1016/j.knosys.2025.113323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) enhances the performance of the classification model by selecting relevant features and discarding unnecessary ones. Due to the efficiency of metaheuristic algorithms in solving FS problems, they have drawn much attention. However, the previous metaheuristic-based FS methods have drawbacks, such as easily falling into local optima and limited utilization of FS characteristics. To address these problems, we propose a novel twin Q-learning-driven forest ecosystem optimization named TQFEO for FS problems. Initially, an ordinal number initialization strategy is developed to guarantee the quality of initial individuals at the initial stage. Specifically, a twin Q-learning-driven forest ecosystem is constructed to ensure the algorithm's adaptive capability. Furthermore, a fitness-variance-evaluation-based status detection strategy is proposed to perceive optimization status. If an abnormality is detected, low-quality individuals are to be processed. Finally, a Manhattan distance guides position update and elite random walk strategy is designed to maintain population diversity and accelerate the convergence rate. Experimental results on 20 benchmark datasets across various domains demonstrate that TQFEO outperforms conventional and recent metaheuristic algorithms.},
  archive      = {J_KBS},
  author       = {Hongbo Zhang and Jinlong Li and Xiaofeng Yue and Xueliang Gao and Haohuan Nan},
  doi          = {10.1016/j.knosys.2025.113323},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113323},
  shortjournal = {Knowl. Based Syst.},
  title        = {Twin Q-learning-driven forest ecosystem optimization for feature selection},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TCrossE: Cross-space interaction of bicomplex and quaternion embeddings for temporal knowledge graph completion. <em>KBS</em>, <em>315</em>, 113321. (<a href='https://doi.org/10.1016/j.knosys.2025.113321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Completing temporal knowledge graphs is essential to ensuring their readiness for real-world applications. Temporal knowledge graph completion addresses this challenge by predicting missing temporal facts and enriching the knowledge base over time. However, existing models face key challenges: translation-based models offer interpretability but underperform, while neural network-based models achieve high accuracy but lack transparency in how they capture structural and temporal dependencies. To address these challenges, we propose TCrossE (Temporal Cross-Space Embedding), a novel model that fuses bicomplex and quaternion spaces to enhance the representation of temporal structures. By leveraging rotations in hypercomplex spaces, TCrossE creates hybrid embeddings that effectively model both structural relationships and temporal dependencies. The fusion of bicomplex and quaternion spaces is mathematically motivated and validated through empirical studies. Unlike prior models, TCrossE balances expressiveness and interpretability, ensuring strong performance without sacrificing model transparency. Additionally, our approach optimizes training efficiency, making it more practical for large-scale TKG applications. We evaluate TCrossE on five benchmark datasets: ICEWS14, ICEWS05–15, GDELT, WIKIDATA12k, and YAGO11k, covering a diverse range of temporal knowledge graph structures. Experimental results show that TCrossE outperforms state-of-the-art models, achieving up to 18 % improvement on GDELT and YAGO11k while maintaining competitive performance on other datasets. Furthermore, TCrossE exhibits lower training times, making it suitable for real-world deployment.},
  archive      = {J_KBS},
  author       = {Thanh Vu and Thanh Le},
  doi          = {10.1016/j.knosys.2025.113321},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113321},
  shortjournal = {Knowl. Based Syst.},
  title        = {TCrossE: Cross-space interaction of bicomplex and quaternion embeddings for temporal knowledge graph completion},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting semi-supervised regressor via confidence-weighted consistency regularization. <em>KBS</em>, <em>315</em>, 113319. (<a href='https://doi.org/10.1016/j.knosys.2025.113319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised regression aims to train a learner by utilizing both labeled and unlabeled data. Boosting is a popular approach in enhancing the performance of the base learner, which is often quite simple. One question is: can we boost different sophisticated semi-supervised regressors (SSRs) to provide better performance? In this paper, we propose a confidence-weighted consistency regularization (BS2C) algorithm to answer this question. First, we construct a neural network that works in parallel with an off-the-shelf SSR to provide pseudo-labels. In this way, the prediction ability of the regressor gradually shifts to the network. Second, we integrate supervised and consistency losses using a dynamic weighting strategy. Consequently, the impact of unlabeled data increases during training iterations. Third, we compute confidence and weights for pseudo-labels to guide the training. Therefore, the negative effect from network errors is reduced. Experiments were performed on fifteen real-world datasets using five popular SSRs, also in comparison with an existing boosting method. The results indicate that BS2C can boost SSRs in most cases, and superior than the counterpart. The source code is available at https://github.com/F1uency/BS2C .},
  archive      = {J_KBS},
  author       = {Liyan Liu and Luxuan Feng and Fan Min},
  doi          = {10.1016/j.knosys.2025.113319},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113319},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boosting semi-supervised regressor via confidence-weighted consistency regularization},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph out-of-distribution generalization through contrastive learning paradigm. <em>KBS</em>, <em>315</em>, 113316. (<a href='https://doi.org/10.1016/j.knosys.2025.113316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem we want to address is graph generalization in the out-of-distribution (OOD) scenario. Mainstream approaches to OOD generalization tasks specific to graph data primarily emphasize domain adaptation and invariant learning and do not consider contrastive learning paradigms that facilitate generalization capabilities. In this study, we enhance the conventional paradigm of graph contrastive learning by introducing a strategy that utilizes environment labeling information for positive and negative sample pair selection, redesign the learning goals of the model for OOD tasks, and propose the model Graph Contrastive Learning for Out-Of-Distribution (GCLOOD). A comprehensive series of experiments and analyses reveals that GCLOOD achieves superior performance over existing methodologies across datasets reflecting various types of data shift phenomena, thereby substantiating the efficacy of GCLOOD.},
  archive      = {J_KBS},
  author       = {Hongyi Du and Xuewei Li and Minglai Shao},
  doi          = {10.1016/j.knosys.2025.113316},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113316},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph out-of-distribution generalization through contrastive learning paradigm},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatial–spectral and temporal dual prototype network for motor imagery brain–computer interface. <em>KBS</em>, <em>315</em>, 113315. (<a href='https://doi.org/10.1016/j.knosys.2025.113315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery electroencephalogram (MI-EEG) decoding plays a crucial role in developing motor imagery brain–computer interfaces (MI-BCIs). However, decoding intentions from MI remains challenging due to the inherent complexity of EEG signals relative to the small-sample size. To address this issue, we propose a spatial–spectral and temporal dual prototype network (SST-DPN). First, we design a lightweight attention mechanism to uniformly model the spatial–spectral relationships across multiple EEG electrodes, enabling the extraction of powerful spatial–spectral features. Then, we develop a multi-scale variance pooling module tailored for EEG signals to capture long-term temporal features. This module is parameter-free and computationally efficient, offering clear advantages over the widely used transformer models. Furthermore, we introduce dual prototype learning to optimize the feature space distribution and training process, thereby improving the model’s generalization ability on small-sample MI datasets. Our experimental results show that the SST-DPN outperforms state-of-the-art models with superior classification accuracy (84.11% for dataset BCI4-2A, 86.65% for dataset BCI4-2B). Additionally, we use the BCI3-4A dataset with fewer training data to further validate the generalization ability of the proposed SST-DPN, achieving superior performance with 82.03% classification accuracy. Benefiting from the lightweight parameters and superior decoding performance, our SST-DPN shows great potential for practical MI-BCI applications. The code is publicly available at https://github.com/hancan16/SST-DPN .},
  archive      = {J_KBS},
  author       = {Can Han and Chen Liu and Jun Wang and Yaqi Wang and Crystal Cai and Dahong Qian},
  doi          = {10.1016/j.knosys.2025.113315},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113315},
  shortjournal = {Knowl. Based Syst.},
  title        = {A spatial–spectral and temporal dual prototype network for motor imagery brain–computer interface},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-view fuzzy clustering with exponential transformation and automatic view weighting. <em>KBS</em>, <em>315</em>, 113314. (<a href='https://doi.org/10.1016/j.knosys.2025.113314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view fuzzy clustering has gained widespread attention due to its unique capability to handle uncertainty through flexible membership assignment, allowing samples to belong to multiple clusters with varying supports, thereby providing a comprehensive understanding of multi-view data. This capability is particularly relevant to knowledge-driven systems that require interpretable integration of multi-view data. However, existing multi-view fuzzy clustering algorithms often struggle with handling noise and incorporating flexible weighting strategies for different views effectively. To address these challenges, this paper proposes four robust multi-view fuzzy clustering algorithms (RMFC-ET-VS, RMFC-ET-VP, RMFC-ET-MS, RMFC-ET-MP), which leverage an exponential transformation of Euclidean distance to effectively mitigate the impact of noise and outliers in the data, thereby enhancing clustering stability. Moreover, we introduce vector-based and matrix-based view weighting strategies, employing sum-to-1 and product-to-1 constraints to ensure that the most informative views contribute more effectively during clustering. The proposed algorithms offer a dual emphasis on robust distance metrics and adaptable view weighting, resulting in more accurate and resilient clustering outcomes. Extensive experiments on multiple real-world datasets demonstrate that the proposed algorithms significantly outperform existing multi-view clustering algorithms, both in terms of clustering performance and robustness.},
  archive      = {J_KBS},
  author       = {Zhe Liu and Haoye Qiu and Muhammet Deveci and Sukumar Letchmunan and Luis Martínez},
  doi          = {10.1016/j.knosys.2025.113314},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113314},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust multi-view fuzzy clustering with exponential transformation and automatic view weighting},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VQ-STE: Scene text erasing with mask refinement and vector-quantized texture dictionary. <em>KBS</em>, <em>315</em>, 113306. (<a href='https://doi.org/10.1016/j.knosys.2025.113306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text erasing (STE), which aims to remove text from natural images and restore a plausible background, has been extensively researched in recent years. Most existing STE methods employ segment-then-erase pipelines, either explicitly or implicitly. However, these methods still face challenges, such as inaccurate text segmentation, difficulty in large text removal, and the shortage of training data. To address the first two issues, we present a scene-text-erasing network, VQ-STE, and to mitigate the third issue, we introduce a high-quality synthetic dataset, MixSyn. VQ-STE comprises a lightweight text Mask Refinement Network (MRN) and a Texture Dictionary-based Inpainting Network (TDIN). The MRN refines the bounding box-level text region mask, producing a high-recall stroke-level text mask by incorporating data augmentation and multiple loss functions. The TDIN erases large text regions by replacing distorted features with those from a pre-learned Texture Dictionary. Moreover, our generated MixSyn dataset offers greater diversity in background, text appearance, layout, and annotation compared to existing synthetic datasets. VQ-STE performs effectively in one or two-step settings, i.e., with or without additional text bounding box information. Experimental results demonstrate that VQ-STE outperforms existing one-step and two-step methods in quantitative and qualitative evaluations on the SCUT-EnsText dataset.},
  archive      = {J_KBS},
  author       = {Zhengmi Tang and Tomo Miyazaki and Zhijie Wang and Yongsong Huang and Jonathan Pradana Mailoa and Shinichiro Omachi},
  doi          = {10.1016/j.knosys.2025.113306},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113306},
  shortjournal = {Knowl. Based Syst.},
  title        = {VQ-STE: Scene text erasing with mask refinement and vector-quantized texture dictionary},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active layered topology mapping driven by road intersection. <em>KBS</em>, <em>315</em>, 113305. (<a href='https://doi.org/10.1016/j.knosys.2025.113305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art autonomous driving systems heavily depend on prior dense maps. However, creating, storing, and transmitting such dense maps beyond complex environments is challenging due to the vast spatial scales involved. This limitation significantly hinders the widespread adoption of autonomous driving technology despite its potential to bring substantial societal benefits. In this paper, we propose a layered hybrid map construction method, which aims to improve the robustness and efficiency of autonomous mapping by using intersections as reference landmark nodes. Each node is organized across metric, semantic, and topology layers, offering crucial references for autonomous navigation without needing prior maps. To capture the road structure at intersection nodes, we propose an intelligent perception model that extracts three types of road semantic information: intersection type, curb characteristics, and road width. This perception model comprehensively and effectively extracts spatial structural representations around nodes, thereby aiding in accumulating semantic layers for map construction. Additionally, we have developed an enhanced Iterative Closest Point algorithm within a hierarchical architecture to improve node re-identification during the mapping process, ensuring stable and rapid localization in large-scale hybrid maps. This method incorporates artificial intelligence and offers a new paradigm for the re-identification of topology nodes. Experiments on six datasets demonstrate that the proposed hybrid mapping method can consistently and effectively construct semantic maps, achieving up to 97.58% similarity of road network topology structure with actual maps. The proposed method holds significant engineering application value in fields such as autonomous driving, robotics, geographic information systems, and urban planning.},
  archive      = {J_KBS},
  author       = {Di Hu and Xia Yuan and Chunxia Zhao},
  doi          = {10.1016/j.knosys.2025.113305},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113305},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active layered topology mapping driven by road intersection},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity confidence learning for unsupervised text-to-image person re-identification with incomplete modality. <em>KBS</em>, <em>315</em>, 113304. (<a href='https://doi.org/10.1016/j.knosys.2025.113304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing text-to-image person re-identification (TIReID) methods assume fully labeled and complete data for both person images and text descriptions. However, this assumption is unrealistic in real-world scenarios due to high labeling costs and privacy concerns. This work addresses a rarely explored task, i.e., unsupervised TIReID with incomplete modality learning. Prior approaches primarily focus on completing missing modalities and learning cross-modal consistency using global features. However, relying solely on these features limits the ability of model to comprehensively represent identities. Local features, which capture fine-grained details of data patches, are essential for effective cross-modal learning but are often overlooked. To address these limitations, we introduce WIN, a framework comprising three key components: (1) The Reliable Feature Completion (RFC) mechanism uses reciprocal neighbor mining to reconstruct both global and local features, ensuring the extraction of the most valuable information from multiple perspectives. (2) The Dual-Modal Clustering (DMC) mechanism addresses intra-class variability caused by missing labels by jointly clustering pedestrian identities from both modalities and generating pseudo-identity labels for supervised training. (3) To mitigate the inevitable noise introduced by imperfect feature completion and pseudo-label generation, we propose a Multi-Granularity Confidence Learning (MCL) mechanism. MCL leverages both global and local feature representations to estimate confidence scores for each sample and adaptively adjusts the optimization strength based on these scores, robustly bringing semantically similar visual and textual features closer in the common embedding space. Extensive experiments demonstrate the superiority of our method across diverse settings with missing modalities and in open-world environments.},
  archive      = {J_KBS},
  author       = {Yongxiang Li and Dezhong Peng and Haixiao Huang and Yizhi Liu and Huiming Zheng and Zheng Liu},
  doi          = {10.1016/j.knosys.2025.113304},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113304},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granularity confidence learning for unsupervised text-to-image person re-identification with incomplete modality},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning framework for ECG arrhythmia classification using 1D-CNN with attention mechanism. <em>KBS</em>, <em>315</em>, 113301. (<a href='https://doi.org/10.1016/j.knosys.2025.113301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases, particularly cardiac arrhythmias, remain a leading cause of global mortality, necessitating efficient and accurate diagnostic tools. Despite advances in deep learning for ECG analysis, current models face challenges in cross-population performance, signal noise robustness, limited training data efficiency, and clinical result interpretability. Additionally, most current approaches struggle to generalize across different ECG databases and require extensive computational resources for real-time analysis. This paper presents a novel hybrid deep learning framework for automated ECG analysis, combining one-dimensional convolutional neural networks (1D-CNN) with a specialized attention mechanism. The proposed architecture implements a four-stage CNN backbone enhanced with a squeeze-and-excitation attention block, enabling adaptive feature selection across multiple scales. The model incorporates advanced regularization techniques, including focal loss, L2 regularization, and an ensemble approach with mixed precision training. We conducted extensive experiments across multiple datasets to evaluate generalization capabilities. This study utilizes two standard databases: the MIT-BIH Arrhythmia Database (48 half-hour recordings sampled at 360 Hz) and the PTB Diagnostic ECG Database (549 records from 290 subjects sampled at 1000 Hz). Through rigorous validation including five-fold cross-validation and statistical significance testing, our model attained remarkable performance, achieving 99.48% accuracy on MIT-BIH, 99.83% accuracy on PTB, and 99.64% accuracy on the combined dataset, with corresponding F1-scores of 0.99, 1.00, and 1.00 respectively. The findings demonstrate robust generalization across varied ECG morphologies and recording conditions, with particular effectiveness in handling class imbalance without data augmentation. The model’s reliable performance across multiple datasets indicates significant potential for clinical applications in automated cardiac diagnostics.},
  archive      = {J_KBS},
  author       = {Mohammed Guhdar and Abdulhakeem O. Mohammed and Ramadhan J. Mstafa},
  doi          = {10.1016/j.knosys.2025.113301},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113301},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced deep learning framework for ECG arrhythmia classification using 1D-CNN with attention mechanism},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling vision-language pre-training models with modality-specific meta-learning. <em>KBS</em>, <em>315</em>, 113300. (<a href='https://doi.org/10.1016/j.knosys.2025.113300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language pre-training (VLP) models have exhibited excellent performance on diverse vision-language tasks, while the ensuing large-scale model parameters greatly limit their application. Knowledge distillation (KD) makes it possible to apply a VLP model to scenarios with limited resources and real-time responses by transferring the knowledge from it ( i.e. , teacher) into a lightweight one ( i.e. , student). However, existing KD methods are primarily designed for unimodal models and thus fail to realize their full potential when migrating them to distill VLP models considering the presence of multiple modalities. Moreover, these KD strategies only unilaterally force the student model to approach the output feature maps generated by the teacher model while ignoring the deeper correlations between them, which may hinder effective knowledge transfer. To tackle these issues, we propose MMKD, a multimodal K nowledge D istillation method with M odality-specific M eta-learning, in which the training objective of the teacher model is converted to optimize the teaching ability for knowledge transfer through feedback from the student model. Meanwhile, to disentangle mutual interference between different modalities when applying KD, the modality-specific distillation objective is designed to encourage the student model to learn the teacher’s knowledge from different modalities. By progressively optimizing the teacher model towards the direction of maximizing the student’s performance, more appropriate soft labels are generated to help the student model learn across different modalities, leading to improved performance. Experiments on three types of VLP models across different downstream tasks demonstrate that the superiority of the proposed method in compressing VLP models.},
  archive      = {J_KBS},
  author       = {Xinge Ma and Jin Wang and Xuejie Zhang},
  doi          = {10.1016/j.knosys.2025.113300},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113300},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distilling vision-language pre-training models with modality-specific meta-learning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BEFM: A balanced and efficient fine-tuning model in class-incremental learning. <em>KBS</em>, <em>315</em>, 113298. (<a href='https://doi.org/10.1016/j.knosys.2025.113298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate objective of class-incremental learning (CIL) is to solve the stability–plasticity dilemma by continuously learning new courses without losing what has been learnt from the previous ones. Typical CIL methods tend to favor sample replay and parameter regularization, but recent studies have shown that exploiting and adapting historical models can effectively improve model performance. We present A Balanced and Efficient Fine-tuning Model (BEFM) to improve memory consumption efficiency and prevent catastrophic forgetting in CIL by utilizing historical models. In order to fully utilize various normalization techniques and preserve the model’s high plasticity and stability throughout training, we first create a multi-normalization module to replace the original single batch normalization procedure. On the other hand, we construct a model expansion method with knowledge distillation and offer a logit fine-tuning strategy to increase memory and computational efficiency. The model expansion strategy effectively solves the memory problem caused by feature aggregation by expanding only the deeper models with greater influence when learning a new task, while the knowledge distillation strategy encourages the model to retain the memory of the old task and improves the stability of the model. As a way to address the issue of class imbalance, the logit fine-tuning technique optimizes the standard softmax cross entropy, improving classifier design without adding computational burden. We test our method on the CIFAR10, CIFAR100, and miniImageNet100 datasets under various conditions. According to experimental results, our strategy outperforms current approaches with notable gains in performance. The code is available at https://github.com/Lize-Liu/BEFM-main .},
  archive      = {J_KBS},
  author       = {Lize Liu and Jian Ji and Lei Zhao},
  doi          = {10.1016/j.knosys.2025.113298},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113298},
  shortjournal = {Knowl. Based Syst.},
  title        = {BEFM: A balanced and efficient fine-tuning model in class-incremental learning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferable and discriminative broad network for unsupervised domain adaptation. <em>KBS</em>, <em>315</em>, 113297. (<a href='https://doi.org/10.1016/j.knosys.2025.113297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation uses labeled data from a source domain to train a robust classifier for an unlabeled target domain with a distinct distribution. The Broad Learning System (BLS), known for its efficiency and effectiveness, is widely applied in classification and regression problems. This paper introduces a novel method named TD-BLS for unsupervised domain adaptation. TD-BLS combines UDA-BLSAE and discriminative BLS into an iterative network. UDA-BLSAE performs domain adaptation and data reconstruction simultaneously, balancing the preservation of intrinsic structure with the reduction of distribution discrepancy. Additionally, the discriminative BLS used in TD-BLS employs pseudo-labeling and manifold learning in the classifier stage to leverage high-confidence predictions and data geometric information. Finally, experiments on multiple public domain adaptation datasets demonstrate that our approach achieves rapid domain adaptation with higher accuracy compared to existing methods.},
  archive      = {J_KBS},
  author       = {Liujian Zhang and Zhiwen Yu and Kaixiang Yang and Bin Wang and C.L. Philip Chen},
  doi          = {10.1016/j.knosys.2025.113297},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113297},
  shortjournal = {Knowl. Based Syst.},
  title        = {Transferable and discriminative broad network for unsupervised domain adaptation},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q-value-based experience replay in reinforcement learning. <em>KBS</em>, <em>315</em>, 113296. (<a href='https://doi.org/10.1016/j.knosys.2025.113296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experience replay has long been used in reinforcement learning to store and reuse past experiences. However, most existing experience replay methods sample experiences with non-uniform probabilities that are proportional to their values, such as temporal-difference errors, which often lead to biased learning. To address this issue, we propose a new experience replay method that hierarchically samples experiences based on Q-values. Specifically, the proposed method divides a set of uniformly sampled experiences into three groups of the same size according to the Q-values and then uniformly samples the same number of experiences from the three groups as a mini-batch. In this manner, the sampled experiences can effectively maintain diversity. Moreover, to estimate the Q-value accurately, we develop a new critic network based on the self-attention mechanism. We integrate the new experience replay method and critic network into the twin delayed deep deterministic policy gradient algorithm to form a new reinforcement learning algorithm. An extensive set of experiments using several standard benchmarks demonstrates the effectiveness of the proposed algorithm.},
  archive      = {J_KBS},
  author       = {Zihong Zhang and Ruijia Li},
  doi          = {10.1016/j.knosys.2025.113296},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113296},
  shortjournal = {Knowl. Based Syst.},
  title        = {Q-value-based experience replay in reinforcement learning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled and reassociated deep representation for dynamic survival analysis with competing risks. <em>KBS</em>, <em>315</em>, 113295. (<a href='https://doi.org/10.1016/j.knosys.2025.113295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Survival analysis has been extensively utilized to analyze when the event of interest occurs. However, most of present studies merely focus on single risk and static data, while incapable of handling the scenario where competing risks and longitudinal observations are involved, which is prevalent in clinical practice, especially in the ICU. Although some impressive progress has been made in recent years, they generally utilize a single encoder to learn patient representations and input identical representations into each cause-specific subnetwork to learn the survival distribution of competing risks, thereby neglecting the specificity and association of each risk factor. In this study, we propose a novel model, namely competing risks disentangled and reassociated deep representation for dynamic survival analysis. On one hand, we propose risks-disentangled autoencoders to learn specific representations for each risk factor with contrastive learning. On the other hand, a risks-reassociated representation fusion module is proposed to explicitly learn the association relationships among competing risk representations with attention mechanism. Through extensive experiments on two popular clinical datasets, i.e., MIMIC-III and eICU, we demonstrate that our proposed model achieves advanced survival prediction performance. Visualization and interpretability analysis experiments are also provided to indicate the superior performance of our model.},
  archive      = {J_KBS},
  author       = {Chang Cui and Yongqiang Tang and Wensheng Zhang},
  doi          = {10.1016/j.knosys.2025.113295},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113295},
  shortjournal = {Knowl. Based Syst.},
  title        = {Disentangled and reassociated deep representation for dynamic survival analysis with competing risks},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of frequency-dependent test length on prediction performance in monthly/quarterly time series analysis. <em>KBS</em>, <em>315</em>, 113294. (<a href='https://doi.org/10.1016/j.knosys.2025.113294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While time series analysis is of great importance in predicting the future based on past and present data, it also has a great importance in improving the performance of models used in the same process. In this study, the effect of the test data length selected depending on the frequency length on the performance was investigated by using seven monthly and four quarterly datasets accessed as open-source. The research question investigated in this article is that whether and how the selection frequency-based test length for forecasting time series data, such as monthly or quarterly, are superior to the traditional selection. While statistical-based models such as autoregressive integrated moving average (AUTO.ARIMA), HOLT-WINTERS, Seasonal and trend decomposing time losess (STLF), theta method forecast (THETAF), and exponential smoothing state-space model with Box-Cox (TBATS) were used for time series forecasting analysis, on the other hand, deep learning models such as neural network autoregression (NNTAR), multiplayer perceptrons (MLP) and extreme learning machine (ELM) were used. In addition, the evaluation of forecasting performance relies on widely recognized metrics such as mean absolute percentage error (MAPE) and root mean square error (RMSE). The empirical studies conducted and reported in this article show that test data length selected as frequency multiples for monthly and quarterly time series has a positive effect on performance in forecasting analysis.},
  archive      = {J_KBS},
  author       = {Zeydin Pala and İhsan Tuğal},
  doi          = {10.1016/j.knosys.2025.113294},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113294},
  shortjournal = {Knowl. Based Syst.},
  title        = {Effect of frequency-dependent test length on prediction performance in monthly/quarterly time series analysis},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention guided filter and refinement feature network for image semantic segmentation. <em>KBS</em>, <em>315</em>, 113293. (<a href='https://doi.org/10.1016/j.knosys.2025.113293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global information and spatial texture are fundamental for optimizing the performance of segmentation networks. Although atrous convolution effectively enlarges receptive fields to accommodate multi-scale features, it cannot capture directional pixel correlations adequately. Moreover, fusing features from different levels via summation or concatenation can introduce substantial noise, compromising segmentation quality. To address these issues, we developed the Attention-Guided Filtering and Refinement Feature Network (FRFN), which enhances global information representation in deeper layers while minimizing noise in shallow features. The Dense Pyramid Attention Module (DPAM) embedded within FRFN captures multi-scale, long-range contextual dependencies. Additionally, the Strip Compression Spatial Block (SCSB) integrated into DPAM extends the long-range pixel interactions through strip convolution. The Enhancement Fusion Module (EFM) also filters noise in shallow features, enhancing the capacity to capture global information. Extensive experiments on the PASCAL VOC 2012 and Cityscapes test datasets, as well as the COCO-Stuff-164K validation set, validate the efficacy of our proposed methods, with FRFN achieving 83.5% and 80.1% m IoU on the respective test datasets, and 40.18% m IoU on the COCO-Stuff-164K validation set.},
  archive      = {J_KBS},
  author       = {Shusheng Li and Wenjun Tan and Liang Wan and Shufen Zhang and Changshuai Zhang and Yanliang Guo and Jiale Li},
  doi          = {10.1016/j.knosys.2025.113293},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113293},
  shortjournal = {Knowl. Based Syst.},
  title        = {Attention guided filter and refinement feature network for image semantic segmentation},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards regression testing and regression-free update for deep learning systems. <em>KBS</em>, <em>315</em>, 113292. (<a href='https://doi.org/10.1016/j.knosys.2025.113292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep neural networks have become prevalent in various systems, such as autonomous driving, privacy leakage detection, and sensitive data protection, and naturally raise wide concerns about their reliability. Current evaluation of the behaviors of DNN models is focused on their overall performance in a statistical way, e.g., measured by accuracy. However, the regression problem on model performance is also an important issue, especially in real-world applications. If a “new and improved” model exhibits errors absent in the old one, frustrated users may abandon the product. Moreover, the reliability of the model could be hard to maintain in the long term. Given its severity and importance, we aimed to detect and fix the regressions on DNN models without affecting the overall performance, and we made a preliminary study on two common situations where regressions occur, i.e., randomness and data evolution. Specifically, we formulated it into a constraint optimization problem by taking the regression-free conditions as constraints and approximating with the combination of two proxies. First, we suppressed the regressions by making the new model mimic the original model and design a quadratic penalty during model training. Second, given the trade-off between similarity to the old model and eligible performance of the new model, we designed a novel biased neuron response variability technique to suppress regression without performance degradation. To evaluate the effectiveness of our technique, we experimented on MINIST, CIFAR-10,and Fashion-MNIST datasets. The results show that our method can reduce the regression rate from 1.53% to 0.69% on average for the random seed change situation, and it was also effective for the data evolution situation.},
  archive      = {J_KBS},
  author       = {Shuyue Li and Ming Fan and Ting Liu},
  doi          = {10.1016/j.knosys.2025.113292},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113292},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards regression testing and regression-free update for deep learning systems},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A similarity learning network for unsupervised deformable brain MRI registration. <em>KBS</em>, <em>315</em>, 113291. (<a href='https://doi.org/10.1016/j.knosys.2025.113291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable image registration is a fundamental task in medical image analysis, aiming to accurately align medical images from different time points or patients. In recent years, learning-based unsupervised deformable registration has received significant attention due to its fast end-to-end registration capability. With the development of deep learning, deformable registration networks that use various advanced network architectures also shown increasingly better registration performance. However, most recent methods have mainly focused on replacing specific layers in networks with advanced network architectures such as Transformers, without specifically addressing the key issues of feature extraction and matching in the registration task itself. In this paper, we explore the key reasons for improving registration performance using Transformers and propose a novel similarity learning network (SLNet) for unsupervised deformable brain MRI registration. In SLNet, we propose: (i) a dual-stream encoder with saliency feature enhancement (SFE) that independently extracts hierarchical features from each image using a dual-stream structure and identifies salient features by computing similarity matrices within features, and (ii) a progressive decoder with similarity feature matching (SFM) that achieves explicit feature matching by computing similarity matrices between features and progressively estimates the final deformation field in a coarse-to-fine manner. Comprehensive experiments are conducted on four publicly available 3D brain MRI datasets (OASIS, IXI, Mindboggle, and LPBA). The results demonstrate that our SLNet achieves state-of-the-art performance, with a DSC improvement of at least 4.7% and an ASD reduction of at least 0.2 mm compared to the representative VoxelMorph.},
  archive      = {J_KBS},
  author       = {Yuan Chang and Zheng Li and Zhenyu Xu},
  doi          = {10.1016/j.knosys.2025.113291},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113291},
  shortjournal = {Knowl. Based Syst.},
  title        = {A similarity learning network for unsupervised deformable brain MRI registration},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional alignment text-embeddings with decoupled contrastive for sequential recommendation. <em>KBS</em>, <em>315</em>, 113290. (<a href='https://doi.org/10.1016/j.knosys.2025.113290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge in sequential recommendation is to accurately predict the next item based on historical interaction sequences by learning effective sequence representations. Existing models typically optimize sequence representations using the next ground-truth item as the supervised signal. However, this approach often results in biased interest representations and neglects the benefits of bidirectional supervision, leading to incomplete sequence representations and semantic mismatches. To address these limitations, we propose ADRec for bidirectional sequence–item A lignment text-embeddings with D ecoupled contrastive learning for sequential Rec ommendation based only on text data. ADRec combines self-supervised and supervised signals derived from intrinsic correlations in recommendation data, to enhance semantic consistency between sequence and ground-truth item representations, improving recommendation performance. Specifically, we introduce a hybrid learning mechanism that integrates an unsupervised contrastive learning paradigm to decouple sequence and item representations and supervised contrastive learning to achieve bidirectional semantic alignment. Additionally, a dual-momentum queue mechanism is devised to expand the diversity of negative samples with limited resources, optimizing the quality of user interest representations in the text modality. Extensive experiments on six public datasets show that ADRec consistently outperforms state-of-the-art methods by learning superior sequence representations. The code is publicly available at https://github.com/pppiao/ADRec .},
  archive      = {J_KBS},
  author       = {Piao Tong and Qiao Liu and Zhipeng Zhang and Yuke Wang and Tian Lan},
  doi          = {10.1016/j.knosys.2025.113290},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113290},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bidirectional alignment text-embeddings with decoupled contrastive for sequential recommendation},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesizing global and local perspectives in contrastive learning for graph anomaly detection. <em>KBS</em>, <em>315</em>, 113289. (<a href='https://doi.org/10.1016/j.knosys.2025.113289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data has shown explosive growth, with application scenarios covering social networks, e-commerce networks, financial transaction networks, etc. In this context, graph anomaly detection is particularly important, aiming to prevent various malicious activities. Existing approaches, however, are still limited in that they either ignore global information and focus only on aggregating neighbor information of the target node, or they utilize global context as a supervisory signal while ignoring local information. In certain scenarios, anomalies can only be detected in a single view (global or local). Furthermore, the issue of class imbalance in graph-based anomaly detection is exacerbated by the significant disparity between the number of benign user samples and anomalous samples in real-world scenarios. As a solution to the above challenges, we present a framework for synthesizing Global and Local perspectives in Contrastive Learning (GALCL). GALCL leverages multi-view contrast to integrate both global and local information. By using node-graph and node-subgraph cross-scale contrasts, the framework enhances the prominence of local and global information, thereby capturing anomaly information that might be missed by focusing solely on the global or local level. In addition, a class-wise loss function is adopted to alleviate class imbalances on the graph. Comprehensive experiments conducted on eight real-world datasets demonstrate that our method outperforms the current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qiqi Yang and Hang Yu and Zhengyang Liu and Pengbo Li and Xue Chen and Xiangfeng Luo},
  doi          = {10.1016/j.knosys.2025.113289},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113289},
  shortjournal = {Knowl. Based Syst.},
  title        = {Synthesizing global and local perspectives in contrastive learning for graph anomaly detection},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low correlation portfolio formation with preselection using rich relational data. <em>KBS</em>, <em>315</em>, 113287. (<a href='https://doi.org/10.1016/j.knosys.2025.113287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of return prediction and portfolio optimization has been widely proven effective. Traditional portfolio optimization approaches, however, rely solely on financial time series data, neglecting the inherent correlations among assets. This study introduces a novel low-correlation portfolio construction methodology utilizing rich relational data integrated via meta-paths. The proposed framework enhances return prediction while minimizing portfolio risk. In the first stage, Long Short-Term Memory (LSTM) networks are implemented to capture sequential patterns in the data. A Graph Neural Network (GNN) with a dual attention mechanism is employed in our framework. This network structure effectively summarizes information from relevant assets while selectively updating features. In the second stage, we develop an asset correlation scoring metric derived from the comprehensive relational data. Based on the predicted returns and correlation scores, we introduce two portfolio construction strategies: (1) a low-correlation strategy and (2) a hybrid strategy with high returns and low correlation. We use sample data from the S&P 500 Index between January 2017 and December 2021 to justify our proposed method. Results demonstrate that incorporating rich relational data significantly improves prediction accuracy. Under Markowitz’s framework, the correlation of high-quality assets is negatively related to their optimal weights. The correlation scoring metric is demonstrated to facilitate portfolio optimization. Assets exhibiting low correlations contribute to portfolio variance reduction and enhanced risk-adjusted performance. Our Prediction-based Low Correlation Portfolio (P-LCP) enhances returns at lower levels of risk. The Prediction-based Hybrid Portfolio (P-HP) demonstrates exceptional performance in terms of cumulative returns and Sharpe ratios. This work implements a data-driven portfolio construction method that utilizes historical and relational data, highlighting the effectiveness of combining predictive theory with low-correlation portfolio strategies.},
  archive      = {J_KBS},
  author       = {Kui Fu and Jing Wang},
  doi          = {10.1016/j.knosys.2025.113287},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113287},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low correlation portfolio formation with preselection using rich relational data},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadruple strategy-driven hiking optimization algorithm for low and high-dimensional feature selection and real-world skin cancer classification. <em>KBS</em>, <em>315</em>, 113286. (<a href='https://doi.org/10.1016/j.knosys.2025.113286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is critical in classification, aiming to identify the smallest subset of features that maximizes accuracy. Given the NP-hard nature of FS, metaheuristic algorithms (MAs) are commonly applied as effective wrapper-based FS methods. However, high-dimensional datasets with many features and limited samples pose challenges, often resulting in reduced effectiveness and increased computational costs. This study presents the Adaptive Enhanced Diversified Hiking Optimization Algorithm (AEDHOA), an improved variant of the Hiking Optimization Algorithm (HOA), crafted to address these issues efficiently. AEDHOA incorporates four key strategies: the Stratified Random Initialization Strategy (SRIS) for enhanced population diversity, the Enhanced Leader Coordination Strategy (ELCS) for multiple leader guidance to prevent premature convergence, the Adaptive Perturbation Strategy (APS) to introduce controlled randomness for escaping local optima, and the Dynamic Exploration Strategy (DES) to balance global exploration and local exploitation dynamically. AEDHOA's performance is validated using benchmark functions from CEC2017 and CEC2022, where it is compared with sets of classical, recent, and advanced algorithms to ensure comprehensive benchmarking. Additionally, AEDHOA is evaluated as a feature selection method on datasets from the UCI repository and a real-world skin cancer dataset, showcasing its capacity to overcome local minima and accelerate convergence. Comparative results reveal that AEDHOA achieves substantial improvements, with classification accuracy ranging from 0.76 to 1.00 across diverse datasets, demonstrating its robustness and effectiveness in high-dimensional FS tasks.},
  archive      = {J_KBS},
  author       = {Mahmoud Abdel-salam and Saleh Ali Alomari and Mohammad H. Almomani and Gang Hu and Sangkeum Lee and Kashif Saleem and Aseel Smerat and Laith Abualigah},
  doi          = {10.1016/j.knosys.2025.113286},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113286},
  shortjournal = {Knowl. Based Syst.},
  title        = {Quadruple strategy-driven hiking optimization algorithm for low and high-dimensional feature selection and real-world skin cancer classification},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy treed gaussian process for nonstationary regression with large-scale datasets. <em>KBS</em>, <em>315</em>, 113285. (<a href='https://doi.org/10.1016/j.knosys.2025.113285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard Gaussian process (GP) surrogate suffers from limitations of strong stationary assumption and large computational cost when applied in nonstationary and large-scale regression problems. To improve the performance of GP model in such applications, researchers have combined various partitioning strategies of the input space with standard GP model. However, the functional continuity of the partition-based GPs is not well solved, which limits the development of this direction. This paper proposes a fuzzy-partition-based GP surrogate for nonstationary regression with large-scale datasets named fuzzy treed Gaussian process (FTGP). Different from existing binary-partition-based GPs, FTGP first employs the fuzzy clustering technique to partition the whole input space into fuzzy regions and then constructs an independent GP in each fuzzy region only using training samples belonging to the subregion. For prediction, FTGP averages predictions from local models in a weighted average manner where the weights are membership values of the fuzzy regions. Through using the fuzzy partitioning technique, the proposed FTGP not only retains the advantages of the partition-based GPs, i.e., realizing nonstationary regression with reduced computational cost of the training procedure, but also guarantees the functional continuity over the whole input space. The effectiveness of the proposed FTGP is verified by an algebraic function and 28 real-world regression datasets.},
  archive      = {J_KBS},
  author       = {Wen Yao and Ning Wang and Xingchen Li},
  doi          = {10.1016/j.knosys.2025.113285},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113285},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fuzzy treed gaussian process for nonstationary regression with large-scale datasets},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering early predictions: A paradigm shift in diabetes risk assessment with deep active learning. <em>KBS</em>, <em>315</em>, 113284. (<a href='https://doi.org/10.1016/j.knosys.2025.113284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is one of the most widespread chronic diseases worldwide, affecting millions and posing significant health risks. Effective management depends on early detection and risk assessment, enabling medical professionals to take timely action and mitigate long-term healthcare consequences. However, there is a critical need for a reliable and accurate detection system to support medical professionals in clinical and computational assessments. Existing detection systems, particularly those based on traditional deep learning models, often fail to address challenges such as class imbalance, the inability to model non-linear patterns, high annotation costs, and the lack of explainability inherent in black-box models. To address these challenges in diabetes prediction, this study applies the proximity weighted synthetic oversampling technique to resolve class imbalance issues in the Behavioral Risk Factor Surveillance System (BRFSS) dataset, ensuring a balanced representation of healthy and diabetic individuals. Subsequently, we propose a novel Diabetic Class-based Sampling Pointer Network (DCSPNetwork) for early diabetes prediction by assessing high-risk factors. The DCSPNetwork effectively captures non-linear patterns in the BRFSS dataset, reduces overfitting risks, and minimizes labeling costs. Experimental results demonstrate the superior performance of DCSPNetwork, achieving an improvement score of 5.88% in accuracy, 8.14% in precision, 9.76% in recall, 8.33% in F1-score, and 4.3% in area under the receiver operating characteristics curve score, and a remarkable decrease of 30.3% in log loss, 72.90% in training time, and 30.30% in inference time compared to its benchmark pointer network model. Using a 10-fold cross-validation approach, we verified the performance and generalizability of our DCSPNetwork, ensuring consistent results across various data splits and demonstrating its robustness. To further support the DCSPNetwork’s efficacy and dependability, statistical validation is carried out utilizing a t-test and a 95% confidence interval. We incorporated explainable artificial intelligence techniques, local interpretable model-agnostic explanations, and Shapley additive explanations to enhance interpretability and transparency in predictions. These techniques improved the reliability of our model and offered insightful information about feature contributions in DCSPNetwork’s predictions. The results indicate that DCSPNetwork is a reliable and effective model for early diabetes risk assessment, combining high performance with interpretability.},
  archive      = {J_KBS},
  author       = {Ifra Shaheen and Nadeem Javaid and Azizur Rahim and Nabil Alrajeh and Neeraj Kumar},
  doi          = {10.1016/j.knosys.2025.113284},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113284},
  shortjournal = {Knowl. Based Syst.},
  title        = {Empowering early predictions: A paradigm shift in diabetes risk assessment with deep active learning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of alignment methods to support the assessment of similarity between e-commerce knowledge graphs. <em>KBS</em>, <em>315</em>, 113283. (<a href='https://doi.org/10.1016/j.knosys.2025.113283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise knowledge graphs combine data from multiple sources, and the structure and granularity of the resulting graphs can vary widely. The data in knowledge graphs is typically structured by schemas, mainly ontologies. Finding the alignments between content from different graphs allows to reduce redundancy, detect inconsistencies, and improve the use of the data. Recently, many graph alignment methods have been proposed, usually tested on general knowledge bases, so there is very little knowledge about the effectiveness of the methods in specific domains. Moreover, we are also interested in studying how these methods capture the semantic similarity between the schemas of the knowledge graphs. In this article, we study both aspects using 25 graph alignment methods on datasets related to e-commerce activities of organizations, such as product sales or customer satisfaction. We have developed a pipeline for generating and evaluating the results. The results show that the alignment methods can be used as a semantic similarity system between the ontology-dataset pairs that generate the knowledge graphs, that AttrE and BootEA are the most effective and robust methods across the different datasets, that the complexity of the structure of the ontology has a clear impact on the effectiveness of the methods, and that the results of the alignment experiments generate information about the similarity of the ontologies and reveal which parts of them should be better modeled to increase the performance of the methods.},
  archive      = {J_KBS},
  author       = {Ginés Almagro-Hernández and Juan Mulero-Hernández and Prashant Deshmukh and José Antonio Bernabé-Díaz and José Luis Sánchez-Fernández and Paola Espinoza-Arias and Juergen Mueller and Jesualdo Tomás Fernández-Breis},
  doi          = {10.1016/j.knosys.2025.113283},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113283},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evaluation of alignment methods to support the assessment of similarity between e-commerce knowledge graphs},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph knowledge tracing in cognitive situation: Validation of classic assertions in cognitive psychology. <em>KBS</em>, <em>315</em>, 113281. (<a href='https://doi.org/10.1016/j.knosys.2025.113281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a fundamental and challenging task in intelligent education, aiming to trace learners’ knowledge states and learning processes, providing better support and guidance for teaching and addressing mental factors. Previous KT tasks have focused on considering learners’ exposure to extrinsic environmental factors while ignoring the influence of intrinsic psychological factors. Moreover, previous methods have adopted a single perspective in modeling learners’ knowledge states, ignoring the diversity of states in the learning process. To address these issues, we define the concept of cognitive situation through the guidance of cognitive psychology theory to help to explain the extrinsic influence and intrinsic cognition of learners within complex learning environments. Moreover, we design a Cognitive Situation-based Graph KT (CSGKT) model to quantify learners’ influences in the cognitive process by modeling schemas capturing intrinsic characteristics and extrinsic factors through Hyper-Graph Neural Networks (HGNN). Second, we utilize a Directed Graph Convolutional Neural Network (DGCNN) to capture the correlation information between knowledge concepts and structure the learner’s cognitive activities and knowledge states, adding a detailed representation of multiple states of the learning process. In addition, we use the Erase-add Gate to filter out the knowledge states that do not match the learner’s current cognitive activities to stabilize the learner’s due cognition. In our experiments, we selected nine baseline models from three mainstream approaches, including sequence-based approaches, Transformer -based approaches, and complex structure-based approaches. The experimental results show that our models outperform these baseline models. At the same time, we also verify two classic assertions in cognitive psychology, namely, the “short-term memory forgetting of knowledge concepts is mainly caused by interference rather than memory trace fading” and the “cognitive imagery and perceptual function play an equivalent role in the cognitive process”, which further support the feasibility of the model.},
  archive      = {J_KBS},
  author       = {Qianxi Wu and Weidong Ji and Guohui Zhou and Yingchun Yang},
  doi          = {10.1016/j.knosys.2025.113281},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113281},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph knowledge tracing in cognitive situation: Validation of classic assertions in cognitive psychology},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research hypothesis generation over scientific knowledge graphs. <em>KBS</em>, <em>315</em>, 113280. (<a href='https://doi.org/10.1016/j.knosys.2025.113280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating research hypotheses is a crucial step in scientific investigation that involves the creation of precise, verifiable, and logically valid statements that can be empirically examined. Therefore, many efforts have been made to automate or assist this process through the use of various Artificial Intelligence solutions. However, most existing methods are tailored to very specific domains, particularly within the biomedical field. There have been recent attempts to formalize hypothesis generation as a link prediction task over knowledge graphs. This solution is potentially domain-independent and applicable across diverse disciplines. Nevertheless, current approaches for link prediction, which typically rely on embedding models or path-based methods, have shown limited success in accurately predicting new hypotheses. To address these limitations, this paper introduces ResearchLink, an innovative and domain-independent methodology for hypothesis generation over knowledge graphs. ResearchLink combines path-based features and knowledge graph embeddings with text embeddings, capturing the semantic context of entities within a given corpus, and integrates additional information from bibliometric databases to improve research collaboration predictions. To conduct a rigorous evaluation of ResearchLink, we constructed CSKG-600, a new dataset for hypothesis generation, consisting of 600 statements that were manually labeled by domain experts. ResearchLink achieved outstanding performance (78.7% P@20), significantly outperforming alternative approaches such as TransH (71.8%), TransD (71.7%), and RotatE (70.7%).},
  archive      = {J_KBS},
  author       = {Agustín Borrego and Danilo Dessì and Daniel Ayala and Inma Hernández and Francesco Osborne and Diego Reforgiato Recupero and Davide Buscaldi and David Ruiz and Enrico Motta},
  doi          = {10.1016/j.knosys.2025.113280},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113280},
  shortjournal = {Knowl. Based Syst.},
  title        = {Research hypothesis generation over scientific knowledge graphs},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syntax-based residual graph attention network for aspect-level sentiment classification. <em>KBS</em>, <em>315</em>, 113279. (<a href='https://doi.org/10.1016/j.knosys.2025.113279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification (ALSC) aims to predict the sentiment polarity of specific aspects in the input text. In recent years, given the advantages of graph neural networks (GNNs) in capturing structural information, an increasing number of studies have integrated them with dependency trees for ALSC, achieving state-of-the-art results. However, existing methods do not fully exploit the information within dependency trees. In this paper, we propose a syntax-based residual graph attention network (SRGAT) that simultaneously uses three types of syntactic information: dependency relation, dependency distance, and part-of-speech, to capture aspect-related sentiment features. Results from comparative experiments on four benchmark datasets show that our proposed model outperforms a range of state-of-the-art models. Additionally, ablation studies demonstrate the effectiveness of these three types of syntactic information for ALSC.},
  archive      = {J_KBS},
  author       = {Guangtao Xu and Zhihao Yang and Jinzhong Ning and Hongfei Lin and Jian Wang},
  doi          = {10.1016/j.knosys.2025.113279},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113279},
  shortjournal = {Knowl. Based Syst.},
  title        = {Syntax-based residual graph attention network for aspect-level sentiment classification},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-MWFP: Lightweight federated learning with interpretable multiple wavelet fusion network for fault diagnosis under variable operating conditions. <em>KBS</em>, <em>315</em>, 113277. (<a href='https://doi.org/10.1016/j.knosys.2025.113277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning, an advanced distributed machine learning paradigm, has shown significant potential in fault diagnosis. However, practical challenges, such as feature distribution differences across clients due to variable operating conditions and high communication resource demands, hinder its application in this field. To address these challenges, this paper proposes Fed-MWFP, an innovative framework that enhances federated learning with fault diagnosis capabilities under variable operating conditions through network modeling and pruning-integrated training. In this framework, an interpretable Multiple Wavelet Fusion Convolutional Network (MWFCN) is proposed as the global model. This model leverages the refined time-frequency analysis capabilities of multi-wavelet transforms and the feature fusion capability of multi-scale wavelet convolutional networks, enabling the extraction of time-frequency features that reflect the physical characteristics of the original vibration signals, thereby mitigating the negative transfer problem caused by feature distribution differences between clients. Furthermore, the pruning-integrated training scheme utilized in Fed-MWFP optimizes local client models and concurrently lightweights them, thereby facilitating a lightweight federated learning process. Experimental results on DDS fault simulation dataset and the real-world dataset from a wind turbine generator (WTG) validate the effectiveness of the proposed method.},
  archive      = {J_KBS},
  author       = {Yan Zhang and Haitao Kong and Yan Han and Qingqing Huang},
  doi          = {10.1016/j.knosys.2025.113277},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113277},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fed-MWFP: Lightweight federated learning with interpretable multiple wavelet fusion network for fault diagnosis under variable operating conditions},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph optimization algorithm enhanced by dual-scale spectral features with contrastive learning for robust bearing fault diagnosis. <em>KBS</em>, <em>315</em>, 113275. (<a href='https://doi.org/10.1016/j.knosys.2025.113275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing fault diagnosis is critical for ensuring the safe operation of mechanical equipment and a key research focus in industrial intelligence. While graph neural network (GNN)-based methods using time-series data have shown promise in fault diagnosis, their performance is often hindered under noisy conditions and in low-label scenarios, making it challenging to extract robust and discriminative features. To address these challenges, this paper proposes a novel graph optimization algorithm based on dual-scale spectral features and contrastive learning (DSSF-CL) for intelligent bearing fault diagnosis. The proposed method leverages Fourier operators within a dual-branch network to extract spectral features, where feature perturbation drives the network to learn high-order features from coarse-grained and fine-grained perspectives, providing first-order network parameters. These spectral features are then used to refine the initial K-Nearest Neighbors (KNN) graph through similarity optimization, enhancing the graph structure's robustness against noise and its ability to represent feature relationships effectively. The optimized graph structure, combined with coarse-grained, fine-grained, and cross-fused features extracted by the dual-branch network, is subsequently used in a supervised fine-tuning process with labeled data. Finally, a joint optimization strategy is employed, where supervised loss dominates the training while contrastive learning loss acts as a regularization term, improving the model's generalization under low-label and high-noise conditions. Experimental results on two public bearing datasets demonstrate that DSSF-CL achieves superior diagnostic accuracy compared to existing methods under noisy and low-label scenarios. These results highlight the effectiveness of DSSF-CL as a robust and accurate solution for bearing fault diagnosis.},
  archive      = {J_KBS},
  author       = {Ying Li and Xiaoping Liu and Junhui Hu and Pengfei Liang and Bin Wang and Xiaoming Yuan and Lijie Zhang},
  doi          = {10.1016/j.knosys.2025.113275},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113275},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph optimization algorithm enhanced by dual-scale spectral features with contrastive learning for robust bearing fault diagnosis},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesize then align: Modality alignment augmentation for zero-shot image captioning with synthetic data. <em>KBS</em>, <em>315</em>, 113274. (<a href='https://doi.org/10.1016/j.knosys.2025.113274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning aims to generate descriptive texts for given images. The underlying alignment between images and texts depends on the training with massive image–text pairs, but annotating substantial and high-quality data is costly. To alleviate this burden, zero-shot captioning methods forge noisy image–text correspondences without paired data, often resulting in poor alignment in real-world scenarios. Among them, synthesizing images based on text data improves cost efficiency in data collection and shows performance superiority, though generative models may produce mismatched content. This paper proposes a synthesize-then-align framework based on synthetic data for zero-shot captioning, which first generates images corresponding to the collected texts and then refines the image–text alignment during data preparation and caption decoding. For the content matching within synthetic image–text data, we maintain an image support set after image generation and construct a re-pairing mechanism to search for the synthetic images that match well with the target text, thus enhancing the semantic consistency between texts and images in synthetic pairs. In addition, considering that the modality gap hinders image–text alignment in decoding, we gather text semantics to represent the global and local views of the synthetic images, which aims at improving cross-modal alignment at both coarse and fine grains, respectively. With no access to real pairs, experimental results show that our method achieves state-of-the-art performance in several benchmark datasets.},
  archive      = {J_KBS},
  author       = {Zhiyue Liu and Jinyuan Liu and Xin Ling and Qingbao Huang and Jiahai Wang},
  doi          = {10.1016/j.knosys.2025.113274},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113274},
  shortjournal = {Knowl. Based Syst.},
  title        = {Synthesize then align: Modality alignment augmentation for zero-shot image captioning with synthetic data},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient mining top-k high utility itemsets in incremental databases based on threshold raising strategies and pre-large concept. <em>KBS</em>, <em>315</em>, 113273. (<a href='https://doi.org/10.1016/j.knosys.2025.113273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High utility itemset mining (HUIM) is a sub-problems of frequent itemset mining (FIM) that has received a lot of interest from researchers. It is used to analyze user behavior and improve business efficiency. The top-k high utility itemsets mining (top-k HUIM) issue aims to explore the k-itemsets with the highest utility from the database to handle the difficulty of threshold selection. Top-k HUIM algorithms ignore the transactions continuously added to the database in a dynamic environment, resulting in inaccurate top-k HUI results. However, the current top-k HUIM algorithms in the incremental database require users to request mining manually, or else, have it automatically processed every time the incremental batch is scanned, which is very small compared to the original database. Re -mining when the data is not updated enough affects the results and consumes a lot of resources without obtain new valuable insights. This research presents a raising threshold strategy to take advantage of the original database's mining results combining the updated database strategies. Furthermore, the paper proposes definitions of top-k mining using pre-large concept, thresholds, conditions for re-mining and method to solve the problem of always mining. Combining the proposed techniques and strategies, a complete “PreTK” algorithm is proposed to solve the proposed issues. The experiments are deployed to compare the algorithm's performance on diverse databases with baseline algorithms. The results demonstrate that the proposed method outperforms the state-of-the-art algorithms and may provide results faster, even when re-mining is necessary.},
  archive      = {J_KBS},
  author       = {N.T. Tung and Loan T.T. Nguyen and Trinh D.D. Nguyen and Bao Huynh},
  doi          = {10.1016/j.knosys.2025.113273},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113273},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient mining top-k high utility itemsets in incremental databases based on threshold raising strategies and pre-large concept},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Occluded human pose estimation based on part-aware discrete diffusion priors. <em>KBS</em>, <em>315</em>, 113272. (<a href='https://doi.org/10.1016/j.knosys.2025.113272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we focus on reconstructing human poses from RGB images, with particular attention given to the ambiguity issues caused by complex scenes such as occlusions. The main challenges we face are twofold: how to reconstruct a complete pose based on limited visible cues and how to handle the uncertainty of occluded parts. To address these issues, our primary approach is to leverage human prior knowledge to ensure the physical plausibility of the reconstructed pose and simulate occluded scenarios through the forward process of the diffusion model, followed by recovering the occluded parts through the reverse process. Specifically, we first train hierarchical encoders, codebooks, and decoders to learn rich pose prior knowledge and then incorporate these priors into a discrete diffusion model with multimodal guidance. We train the network to gradually predict clean discrete pose tokens that are consistent with prior knowledge and ultimately decode them into complete body poses. Extensive experimental results on the COCO and 3DMPB datasets demonstrate that our method achieves state-of-the-art performance compared with previous approaches. The code will be publicly available.},
  archive      = {J_KBS},
  author       = {Hongyu Xiao and Hui He and Yifan Xie and Yi Zheng},
  doi          = {10.1016/j.knosys.2025.113272},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113272},
  shortjournal = {Knowl. Based Syst.},
  title        = {Occluded human pose estimation based on part-aware discrete diffusion priors},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The single-valued neutrosophic extension of the PIPRECIA method. <em>KBS</em>, <em>315</em>, 113271. (<a href='https://doi.org/10.1016/j.knosys.2025.113271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making an intuitive decision in any business field without using adequate methodologies could lead to the selection of wrong solutions and eventually could cause a loss. The Multiple-Criteria Decision-Making (MCDM) methods could be beneficial in avoiding such an occurrence. The main target of this paper is to introduce such an MCDM technique that sublimates relatively simple procedures, acknowledging the decision environment's vagueness and intelligibility. With that aim, the Single-Valued Neutrosophic extension of the PIvot Pairwise RElative Criteria Importance Assessment (SVN PIPRECIA) is proposed. The main reason for using the SVN numbers is because they better incorporate the philosophical aspect of the decision process. The applicability of the proposed approach is observed in the actual case study involving selecting the appropriate bottle for Crna Tamjanika (Red Tamjanika) wine.},
  archive      = {J_KBS},
  author       = {Gabrijela Popovic and Dragisa Stanujkic and Marko Mihic and Florentin Smarandache and Darjan Karabasevic and Vuk Mircetic},
  doi          = {10.1016/j.knosys.2025.113271},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113271},
  shortjournal = {Knowl. Based Syst.},
  title        = {The single-valued neutrosophic extension of the PIPRECIA method},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical neighbor-enhanced graph contrastive learning for recommendation. <em>KBS</em>, <em>315</em>, 113263. (<a href='https://doi.org/10.1016/j.knosys.2025.113263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning has been widely incorporated into recommender systems, and leveraging potential neighbor relationships among users (or items) from graph structure or semantic space to design contrastive views has emerged as an effective paradigm. However, regardless of the structural or semantic neighbors, existing methods typically model them at a single level, neglecting either local-level structural relationships or the multiple levels of semantic information underlying the recommendation data, thereby limiting the ability to provide sufficient contrastive signals for model learning. In this paper, we propose a Dual-perspective H ierarchical N eighbor- E nhanced Graph C ontrastive L earning ( HNECL ) method for recommendation, aiming to fully exploit hierarchical neighbor relationships to construct more effective contrastive views from structural and semantic perspectives. Specifically, for structural perspective, we propose to model both local and global neighbors of a node by utilizing the layer-wise fused output of graph neural networks on multiple graphs as corresponding neighbor representations and treat them as positive pairs for structure-contrastive learning. As for semantic perspective, a hierarchical clustering strategy is proposed to represent the hierarchical semantic neighbors of a user (or an item) with hierarchical prototypes. Then, we incorporate the prototypes of different hierarchies into the corresponding semantics-contrastive learning objectives. Extensive experiments conducted on three public datasets demonstrate the effectiveness of the proposed HNECL.},
  archive      = {J_KBS},
  author       = {Hongjie Wei and Junli Wang and Yu Ji and Mingjian Guang and Chungang Yan},
  doi          = {10.1016/j.knosys.2025.113263},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113263},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical neighbor-enhanced graph contrastive learning for recommendation},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCDFuse: A semantic complementary distillation framework for joint infrared and visible image fusion and denoising. <em>KBS</em>, <em>315</em>, 113262. (<a href='https://doi.org/10.1016/j.knosys.2025.113262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible fusion has gained unprecedented attention due to its extensive applications in the field of computer vision. However, existing algorithms unilaterally focus on the fusion of clean scene images and are vulnerable to noise interference. Although this issue can be mitigated by deploying independent pre-denoising modules, the cascading of additional modules with diverse functionalities introduces supplementary complexity, computational overhead, and even inter-module interference. To overcome this limitation and achieve multitask unification, we propose a knowledge distillation framework for end-to-end simultaneous feature denoising and aggregation. In this framework, we leverage the advantages of the distillation architecture to generate soft labels, mitigating unstable fusion performance caused by lacking of label guidance. To achieve an accurate guidance for the function learning during the training process, an asymmetric noise-aware training strategy is devised for the facilitate of aggregation robustness and denoising capability. Moreover, to ensure the feature excavation and semantic complementary competence, a hybrid series–parallel CNN-transformer dual-branch En-Decoder is constructed. The proposed encoder incorporate the self-designed Textural-aware ConvNextV2, strip pooling attention and progressive residual transformer to compose the dual-branch architecture. In addition, the semantic complementary feature aggregation (SCFA) module are developed to realize a coarse-to-fine feature enhancement. Extensive experiments on both regular and noisy fusion materials are implemented to testify the integration and denoising performance of the proposed method. Notably, on the TNO dataset, the proposed method achieves improvements of 4% and 4.2% in the MSSIM and UQI metrics, respectively, compared to the second-best algorithm. Furthermore, we also investigate its facilitation for advanced visual tasks through object detection experiments.},
  archive      = {J_KBS},
  author       = {Shidong Xie and Haiyan Li and Yongsheng Zang and Jinde Cao and Dongming Zhou and Mingchuan Tan and Zhaisheng Ding and Guanbo Wang},
  doi          = {10.1016/j.knosys.2025.113262},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113262},
  shortjournal = {Knowl. Based Syst.},
  title        = {SCDFuse: A semantic complementary distillation framework for joint infrared and visible image fusion and denoising},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RRT*-enhanced long-horizon path planning for AUV adaptive sampling using a cost valley. <em>KBS</em>, <em>315</em>, 113261. (<a href='https://doi.org/10.1016/j.knosys.2025.113261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite advances in adaptive sampling, existing methods predominantly rely on myopic (greedy) strategies and single-objective criteria, which inadequately balance long-term exploration and exploitation. Moreover, obtaining real-time computations with complex, time-varying models remains challenging. With the goal of effective sampling of oceanographic variables by autonomous underwater vehicles, we propose a long-horizon adaptive sampling system that integrates a flexible cost valley concept with a non-myopic path planner. Our method addresses autonomous navigation within a fixed time frame while adaptively sampling ocean variables and avoiding obstacles, aiming to reduce the expected variability or classification error at river plume fronts. The novelty of our approach lies in combining variance and classification metrics as sampling objectives into a weighted cost surface that guides the vehicle along its minimal-cost path. We implement this concept using a rapidly exploring random trees (RRT*) strategy for non-myopic path planning. Simulation results based on 100 replicates demonstrate differences in traffic flow, root mean square error, variance reduction (VR), and integrated Bernoulli variance (IBV) under various cost weightings for RRT* versus a myopic approach. The equal weight cost valley appears robust, yielding prediction metrics closer to those in extreme IBV or VR-dominant cases. Statistical results further show that RRT*-based planning achieves only slightly better numerical scores than the myopic method—for example, an IBV of 75.76 (SD 7.26) compared to 75.93 (SD 6.4). A 2.5-hour field trial in a Norwegian fjord confirms that the AUV successfully runs the long-horizon adaptive sampling algorithm in real time on its onboard computing units.},
  archive      = {J_KBS},
  author       = {Yaolin Ge and Jo Eidsvik and André Julius Hovd Olaisen},
  doi          = {10.1016/j.knosys.2025.113261},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113261},
  shortjournal = {Knowl. Based Syst.},
  title        = {RRT*-enhanced long-horizon path planning for AUV adaptive sampling using a cost valley},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank joint distribution adaptation for cross-corpus speech emotion recognition. <em>KBS</em>, <em>315</em>, 113260. (<a href='https://doi.org/10.1016/j.knosys.2025.113260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in speech emotion recognition (SER) have made it a key research area in intelligent systems for understanding speakers’ emotional states. Despite this progress, conventional SER algorithms often struggle with cross-corpus SER (CCSER) owing to feature discrepancies between different corpora. To address this issue, various methods have been developed to identify common feature spaces and corpus-invariant features. However, these methods are prone to bias due to outlier samples in the source data. An effective alternative is to construct common subspaces by using representative samples from each class. Herein, we introduce a novel approach called low-rank joint distribution adaptation (LRJDA), which leverages low-rank decomposition for subspace transfer learning. LRJDA employs dimensional sparse constraints for fine-grained feature alignment to bridge the feature gaps between corpora. It focuses on learning common subspaces for marginal and conditional distributions by incorporating terms that constrain the deviations within and across corpora and emotion classes. The nuclear norm in the loss function enhances the robustness of the sample and feature selection. We evaluated LRJDA on the CCSER task using six different training and testing data combinations. The average results demonstrate that LRJDA achieves a weighted average recall of 41.81 % and an unweighted average recall of 40.25 % , representing a notable improvement over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Sunan Li and Cheng Lu and Yan Zhao and Hailun Lian and Tianhua Qi and Yuan Zong},
  doi          = {10.1016/j.knosys.2025.113260},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113260},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-rank joint distribution adaptation for cross-corpus speech emotion recognition},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IF-NS: A new negative sampling framework for knowledge graph embedding using influence function. <em>KBS</em>, <em>315</em>, 113258. (<a href='https://doi.org/10.1016/j.knosys.2025.113258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are widely used in tasks such as recommendation and question answering, with the aid of knowledge graph embedding (KGE) models. These models incorporate negative sampling during training but face challenges, including vanishing gradients and false negatives, primarily due to the lack of incorrect facts in KGs. While score functions in KGE models help mitigate vanishing gradient issues, they often fail to address false-negative samples. Drawing inspiration from influence functions, we propose a new framework for translational distance KGE models called IF-NS, which leverages influence to select high-quality negative samples. The core idea is to assess how each sample contributes to the KGE model during training, effectively retaining high-quality negative samples. To reduce computational complexity, we also develop a simplified influence estimation algorithm tailored to the L2-norm distance in the KGE loss function. Furthermore, we introduce a repository for storing and tracking high-quality negative samples, employing repository-based sampling and dynamic updating strategies to balance exploration and exploitation. Experimental results show that IF-NS effectively mitigates the issues of vanishing gradients and false negatives, significantly improving KGE model performance.},
  archive      = {J_KBS},
  author       = {Ming Cai and Zhuolin Deng and Chen Xiong},
  doi          = {10.1016/j.knosys.2025.113258},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113258},
  shortjournal = {Knowl. Based Syst.},
  title        = {IF-NS: A new negative sampling framework for knowledge graph embedding using influence function},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight object detection method based on fine-grained information extraction and exchange in UAV aerial images. <em>KBS</em>, <em>315</em>, 113253. (<a href='https://doi.org/10.1016/j.knosys.2025.113253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objects in unmanned aerial vehicle (UAV) images are easily disturbed by complex backgrounds, and objects at different positions in these images often have notable differences in size because of different shooting angles. To effectively detect objects, current mainstream methods improve the detection accuracy through complex iterative convolution operations and attention mechanisms. However, these methods not only improve the accuracy but also result in a high memory overhead and feature redundancy, which brings unbearable load pressure to the UAV platform. Therefore, to refine the multi-granularity object information of UAV aerial images via a lightweight manner and improve the precision of multi-scale object detection, we design an portable lightweight multi-scale UAV image object detection network (UAVDNet) based on MConvBottleNet. First, to overcome the challenge that the conventional convolution receptive field is unitary and easily loses the fine-grained information described above, we design a multifunctional convolution (MConv) module to achieve multi-receptive field information aggregation and feature weighting through hierarchical mechanism. Second, we propose MConvBottleNet to simultaneously aggregate local and global information using residual connections and channel shuffling operations on the basis of the diverse information provided by MConv. Third, to effectively exploit the context information in high-level semantic feature maps and preserve the original fine-grained details to the maximum possible extent, we design an inter-layer cascaded information aggregation pooling (ICIAP) module, which, together with MConvBottleNet, constitutes the feature extraction network. Finally, we propose a fusion network based on the feature recombination and enhancement (FRE) module, denoted as FRENet, which can take advantage of the information-complementary characteristic of different channel layers to obtain overall channel enhancement results and effectively improve the ability to detect multi-scale objects. Experiments on the VisDrone dataset show that UAVDNet achieves an average detection accuracy of 48.1% with only 4.4M parameters.},
  archive      = {J_KBS},
  author       = {Liming Zhou and Shuai Zhao and Shilong Li and Yadi Wang and Yang Liu and Xianyu Zuo},
  doi          = {10.1016/j.knosys.2025.113253},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113253},
  shortjournal = {Knowl. Based Syst.},
  title        = {A lightweight object detection method based on fine-grained information extraction and exchange in UAV aerial images},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary banyan tree growth optimization: A practical approach to high-dimensional feature selection. <em>KBS</em>, <em>315</em>, 113252. (<a href='https://doi.org/10.1016/j.knosys.2025.113252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional feature spaces in Scientific and Technical Service Resources (STSR) classification present significant challenges, including increased computational costs and diminished accuracy. Identifying an optimal subset of features from raw text vectors is thus critical for effective data classification. This paper introduces a novel metaheuristic algorithm called Binary Banyan Tree Growth Optimization (BBTGO), specifically designed for high-dimensional feature selection (FS). Inspired by the unique growth patterns of the banyan tree, BBTGO leverages a combination of innovative Boolean vectors, including rooting, multi-trunk, and adjustment operator, along with a perturbation phase to enhance the search efficiency and reduce feature dimensionality. These operators enhance the search for promising regions and reduce features by utilizing the optimal solutions clustered within subgroups. Furthermore, BBTGO incorporates a dynamic adjustment mechanism that periodically activates different growth operators to meet the search demands of high-dimensional space. We rigorously evaluate the exploration and exploitation capabilities of BBTGO through comprehensive statistical analyses of various performance metrics. The proposed method demonstrates superior results on 12 high-dimensional benchmark datasets and is successfully applied to feature selection in STSR text classification tasks. Experimental results show that BBTGO significantly outperforms existing methods in terms of classification accuracy, selected features, convergence speed, and processing time. These results underscore the potential of BBTGO as a robust and versatile solution for high-dimensional FS, with broad applicability to real-world classification challenges.},
  archive      = {J_KBS},
  author       = {Xian Wu and Minrui Fei and Wenju Zhou and Songlin Du and Zixiang Fei and Huiyu Zhou},
  doi          = {10.1016/j.knosys.2025.113252},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113252},
  shortjournal = {Knowl. Based Syst.},
  title        = {Binary banyan tree growth optimization: A practical approach to high-dimensional feature selection},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-level feature bias calibration learning for text-to-image person re-identification. <em>KBS</em>, <em>315</em>, 113251. (<a href='https://doi.org/10.1016/j.knosys.2025.113251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image Person Re-identification (TIReID) aims to retrieve the queried person using a textual description, which is facing significant challenges due to the huge modality gap. Existing approaches to address this challenge have primarily focused on designing cross-modality alignment strategies based on instance-level contrastive learning, but largely ignoring the limitation of this paradigm. Specifically, instance-level learning overly focuses on salient patterns of individual instances and inevitably leads to feature bias in instance-level feature distribution. Inspired by biological research, which suggests that population-level patterns can mitigate individual-level errors, we introduce a Structure-level Distribution Guiding ( SDG ) strategy based on the Expectation-Maximization (EM) algorithm. SDG can efficiently compute a confident structure-level feature distribution for guidance and employs inter- and intra-class guiding losses to achieve comprehensive representation learning and instance-level feature bias mitigating respectively. Our SDG achieves competitive Rank-1 accuracy of 74.68%, 66.56%, and 63.20% on CUHK-PEDES, ICFG-PEDES, and RSTPReid respectively.},
  archive      = {J_KBS},
  author       = {Yifeng Gou and Ziqiang Li and Junyin Zhang and Yunnan Wang and Yongxin Ge},
  doi          = {10.1016/j.knosys.2025.113251},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113251},
  shortjournal = {Knowl. Based Syst.},
  title        = {Instance-level feature bias calibration learning for text-to-image person re-identification},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-guided deep correlation mining and self-learning feature fusion framework for multimodal sentiment analysis. <em>KBS</em>, <em>315</em>, 113249. (<a href='https://doi.org/10.1016/j.knosys.2025.113249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis has garnered widespread attention due to its applications in fields such as human–robot interaction, offering a 10% to 20% accuracy(binary) improvement over unimodal sentiment analysis. However, existing methods still face significant challenges: (1) insufficient utilization of textual information, which impacts the effectiveness of modality fusion and correlation mining; (2) Excessive focus on modality fusion, with a lack of in-depth exploration of the correlations between individual modalities; and (3) the absence of unimodal labels in most multimodal sentiment analysis datasets, leading to challenges in co-learning scenarios. To address these issues, we propose a text-guided deep correlation mining and self-learning feature fusion framework using a multi-task learning strategy. This framework divides sentiment analysis into a multimodal task and three unimodal tasks (linguistic, acoustic, and visual). For unimodal tasks, we designed the Text-Guided Deep Information Correlation Mining Module (TUDCM), which fully explores the correlations between modalities under the guidance of textual information. For the multimodal task, we introduce a Self-Learning Text-Guided Multimodal Fusion Attention (SLTG-Attention) mechanism to enhance the role of textual information and adaptively learn relationships between modalities for efficient fusion. Additionally, we design a Multi-Distance Label Generation Module (MDLGM) to generate more accurate unimodal labels for co-learning scenarios. Extensive experiments on the MOSI, MOSEI, and SIMS datasets demonstrate that our framework significantly outperforms existing methods, achieving an approximate 1% improvement in accuracy. On the MOSI dataset, our method achieves 0.672 MAE, 0.816 correlation, 86.46% accuracy(binary), and 86.52% F1, with similar outstanding results observed on other datasets.},
  archive      = {J_KBS},
  author       = {Minghui Zhu and Xiaojiang He and Baojie Qiao and Yiming Luo and Zuhe Li and Yushan Pan},
  doi          = {10.1016/j.knosys.2025.113249},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113249},
  shortjournal = {Knowl. Based Syst.},
  title        = {Text-guided deep correlation mining and self-learning feature fusion framework for multimodal sentiment analysis},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing word distinction for bilingual lexicon induction with generalized antonym knowledge. <em>KBS</em>, <em>315</em>, 113247. (<a href='https://doi.org/10.1016/j.knosys.2025.113247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Bilingual Lexicon Induction (BLI) methods map monolingual word embeddings (WEs) into a shared semantic space and treat nearest cross-lingual neighbors as translation pairs. A common challenge with these techniques is the propensity for dissimilar semantic words to cluster together in the WE space, posing difficulties in accurately identifying translations. To address this problem, we propose a novel method that leverages antonym knowledge to enhance the separation between words with different semantics in the WE space. The knowledge of generalized antonyms is mined from commonly used data in BLI. Specifically, we jointly use seed lexicons and monolingual word embeddings (WEs) to identify semantically different words, which we refer to as “ generalized antonyms .” These generalized antonyms share high cosine similarity within the monolingual WE space and raise semantic confusion. The identified ”generalized antonyms” then serve as “ fixed anchor points ” to guide the training of the BLI model. The method requires no additional data and can be applied to any language pair. Comprehensive experiments demonstrate that our proposed method outperforms existing state-of-the-art (SOTA) BLI methods across nearly all diverse language pairs. The analysis study also proves that our method effectively enhances the distinction between words.},
  archive      = {J_KBS},
  author       = {Qiuyu Ding and Hailong Cao and Zihao Feng and Tiejun Zhao},
  doi          = {10.1016/j.knosys.2025.113247},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113247},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing word distinction for bilingual lexicon induction with generalized antonym knowledge},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetric content-aided transformer for efficient image super-resolution. <em>KBS</em>, <em>315</em>, 113246. (<a href='https://doi.org/10.1016/j.knosys.2025.113246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, efficient image super-resolution (SR) techniques have taken more and more attention, aiming to allow advanced SR algorithms to be deployed on edge devices. The self-attention mechanism allows Transformer networks to attend over a larger receptive field, thus boosting the performance and inevitably increasing model complexity. In the visual Transformer, the multi-head self-attention (MSA) mechanism is designed to consider the diversity of information between different attention heads. However, the MSA repeats its computations separately and learns various aspects of information spontaneously and unpredictably, thus suffering from redundant computing and high-frequency information loss issues. In this paper, we extend the conventional MSA mechanism into an asymmetric architecture to learn self-attention incrementally. In computing self-attention, content-aided positional encoding (CaPE) is proposed to improve the model to adjust the relative positional relationship for different image content. Extensive experiments indicate that the proposed method outperforms recent lightweight image SR methods with fewer parameters and lower computational costs. The code and trained models are publicly available at https://github.com/bbbolt/ACT .},
  archive      = {J_KBS},
  author       = {Qian Wang and Yanyu Mao and Ruilong Guo and Yao Tang and Jing Wei and Bo Quan},
  doi          = {10.1016/j.knosys.2025.113246},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113246},
  shortjournal = {Knowl. Based Syst.},
  title        = {Asymmetric content-aided transformer for efficient image super-resolution},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recursive counterfactual deconfounding for image recognition. <em>KBS</em>, <em>315</em>, 113245. (<a href='https://doi.org/10.1016/j.knosys.2025.113245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition is a classic and common task that has been widely applied in computer vision in the past decade. Most existing methods in literature aim to learn discriminative features for classification from labeled images; however, they generally neglect confounders that infiltrate the learned features, resulting in low discrimination performances on test images. To address this problem, we propose a Recursive Counterfactual Deconfounding model for image recognition in both closed- and open-set scenarios based on counterfactual analysis, called RCD. The proposed model consists of a factual graph and a counterfactual graph, where the relationships among image features, model predictions, and confounders are built and updated recursively to learn more discriminative features. It performs recursively so that subtler counterfactual features can be learned and progressively eliminated. Both the discriminability and generalizability of the proposed model can be improved accordingly. In addition, a negative correlation constraint is designed to alleviate the negative effects of counterfactual features during model training. Extensive experimental results in both the closed-set and open-set image recognition tasks demonstrate the effectiveness of the proposed method. Particularly under the hard testing mode of the three public datasets (Aircraft, CUB and ImageNet), the proposed method obtains a higher AUROC (Area Under the Receiver Operating Characteristic curves) by 0.7%–3.5% and a higher OSCR (Open-Set Classification Rate) by 0.2%–4.0%.},
  archive      = {J_KBS},
  author       = {Jiayin Sun and Mengyu Gao and Hong Wang and Qiulei Dong},
  doi          = {10.1016/j.knosys.2025.113245},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113245},
  shortjournal = {Knowl. Based Syst.},
  title        = {Recursive counterfactual deconfounding for image recognition},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffOSR: Latitude-aware conditional diffusion probabilistic model for omnidirectional image super-resolution. <em>KBS</em>, <em>315</em>, 113244. (<a href='https://doi.org/10.1016/j.knosys.2025.113244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Omnidirectional images (ODIs) have garnered considerable attention for their immersive experience. However, many ODIs suffer from low-resolution owing to constraints in storage and transmission. Unlike two-dimensional images, ODIs exhibit non-uniform pixel stretching across latitudes when converted to the equirectangular projection (ERP) format, resulting in latitude-dependent geometric distortions. While existing ODI super-resolution (ODISR) methods leverage the geometric properties of ERP images, they often struggle with a lack of high-frequency details. To generate ODIs with realistic and complex textures, we propose a latitude-aware conditional diffusion probabilistic model (DiffOSR) for ODISR. This method employs denoising diffusion probabilistic models to establish a stable mapping from noise in latent space to high-quality ODIs. To address the variation in pixel densities across latitudes, we incorporate a latitude distortion map as a prior condition to guide the denoising process. Additionally, we use the high-frequency sub-band obtained from discrete wavelet transform as another prior condition, deploying a high-frequency attention block to fine tune the attention weights of texture regions in the skip connections. Recognising that Gaussian noise can distort the geometric representation of ERP images during denoising, we introduce the latitude distortion-aware residual block to adaptively learn geometric distortions at various noise levels. Extensive experiments on the ODISR and SUN360 datasets demonstrate that DiffOSR outperforms existing ODISR methods in visual quality and objective perception metrics, such as LPIPS. Compared to the state-of-the-art diffusion-based super-resolution methods, DiffOSR achieves an improvement of over 1 dB in WS-PSNR. The source code will be available at https://github.com/liuleimi/DiffOSR .},
  archive      = {J_KBS},
  author       = {Leiming Liu and Ting Luo and Gangyi Jiang and Yeyao Chen and Haiyong Xu and Renzhi Hu and Zhouyan He},
  doi          = {10.1016/j.knosys.2025.113244},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113244},
  shortjournal = {Knowl. Based Syst.},
  title        = {DiffOSR: Latitude-aware conditional diffusion probabilistic model for omnidirectional image super-resolution},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-precision privacy-protected image retrieval based on multi-feature fusion. <em>KBS</em>, <em>315</em>, 113243. (<a href='https://doi.org/10.1016/j.knosys.2025.113243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the production of large amounts of image data in industrial applications, people outsource image computation and storage to the cloud to reduce the storage burden. To prevent privacy disclosure, it is necessary to encrypt images before storage and transmission. However, this encryption operation will greatly limit the utilization of the image, such as image retrieval. Some image retrieval schemes based on single local feature cannot fully reflect an image, and has low retrieval precision. In addition, image retrieval schemes that extract global features need to train a model. If the queried image dataset is different from the training set, the retrieval precision will be low. To improve the retrieval precision, a high-precision privacy-protected image retrieval scheme is proposed. In this scheme, we apply the SM4 algorithm and secure kNN algorithm to encrypt images and features, guaranteeing the security of the data. The construct of the Bkd index tree and the query trapdoor improve the retrieval efficiency. In addition, the feature extraction and the feature fusion technique are adopted to realize the high-precision encrypted image retrieval. Finally, experimental results confirm that our scheme outperforms existing methods in terms of retrieval precision, as well as the speed of image retrieval, trapdoor generation, and index generation.},
  archive      = {J_KBS},
  author       = {Miao Tian and Moting Su and Xiangli Xiao and Shuang Yi and Zhongyun Hua and Yushu Zhang},
  doi          = {10.1016/j.knosys.2025.113243},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113243},
  shortjournal = {Knowl. Based Syst.},
  title        = {High-precision privacy-protected image retrieval based on multi-feature fusion},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DS-net: A model driven network framework for lesion segmentation on fundus image. <em>KBS</em>, <em>315</em>, 113242. (<a href='https://doi.org/10.1016/j.knosys.2025.113242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a leading cause of vision loss in working-age adults, and analyzing retinal fundus plays a crucial role in early DR screening. However, multi-lesion segmentation of fundus images remains a challenging task due to the highly diverse shape, size, position, and brightness of lesions. In this paper, we propose an interpretable network framework for multi-lesion segmentation by integrating the prior knowledge of retinal fundus images into it. Specifically, we propose a probabilistic model for retinal fundus images, which is in a foreground–background decomposition manner, and both the characteristics of the foreground (lesions) and background (non-lesion fundus images) are taken into consideration. Then, we exploit the Expectation–Maximization (EM) algorithm to solve the proposed model and design a novel network architecture under the guidance of the calculation flow of the algorithm, called Decomposition-Segmentation Network (DS-Net). The components of the network consist of two subnetworks: S-Net and D-Net, corresponding to the E step and M step of the EM algorithm, respectively. D-Net aims to decompose the background and foreground compositions of the fundus image and S-Net takes the foreground as input and executes segmentation task. Similar to the EM algorithm, the two subnetworks separate the original segmentation task into two much easier but interpretable sub-tasks. This not only helps enhance the performance, but also greatly facilitates a deeper analysis of the network. Moreover, the proposed DS-Net framework can be easily integrated with current lesion segmentation networks in a plug-and-play manner, by setting current segmentation networks as S-Net in the framework, and lead to general performance improvements. Experiments on benchmark datasets substantiate the superiority of DS-Net quantitatively and visually. The code of our method is available at https://github.com/tanfy929/DS-Net .},
  archive      = {J_KBS},
  author       = {Feiyu Tan and Yuhan Wang and Qi Xie and Jiahong Fu and Renzhen Wang and Deyu Meng},
  doi          = {10.1016/j.knosys.2025.113242},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113242},
  shortjournal = {Knowl. Based Syst.},
  title        = {DS-net: A model driven network framework for lesion segmentation on fundus image},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge fusion diffusion for single image super-resolution. <em>KBS</em>, <em>315</em>, 113241. (<a href='https://doi.org/10.1016/j.knosys.2025.113241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single Image Super Resolution (SISR) is a critical facet of image processing dedicated to reconstructing high-resolution (HR) images from low-resolution (LR) counterparts. Recently, the two major issues persist in deep learning-based SISR methods: significant loss of high-frequency information in content loss based explicit methods and pattern collapse along with limited diversity in GAN based implicit methods. To overcome these obstacles, we present Edge Fusion Diffusion (EFD), a novel diffusion-based SISR model. EFD’s innovative approach integrates image edge fusion to effectively capture and utilize local image details, thereby enhancing the reconstruction of high-frequency information. By incorporating our Edge Conditional block (EC block), EFD improves image generation while ensuring a stable training process. Our EC block replaces some residual blocks with SENet network structure blocks and adds additional SENet blocks to all upsampling and downsampling modules, enhancing the network architecture’s depth and effectiveness in edge synthesis. Unlike other generative models, EFD significantly enhances image quality, specifically excelling in detailed edge synthesis. Compared to existing diffusion models, EFD stands out in extracting local details, improving edge effects, and substantially boosting the overall quality of synthesized images. Our comprehensive evaluation on the DIV2K dataset and six other benchmark datasets demonstrates that EFD achieves state-of-the-art performance in SISR tasks, delivering diverse and high-quality results.},
  archive      = {J_KBS},
  author       = {Zhikui Chen and Longxiang Zhang and Xu Zhang},
  doi          = {10.1016/j.knosys.2025.113241},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113241},
  shortjournal = {Knowl. Based Syst.},
  title        = {Edge fusion diffusion for single image super-resolution},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical spatial–angular integration for lightweight light field image super-resolution. <em>KBS</em>, <em>315</em>, 113240. (<a href='https://doi.org/10.1016/j.knosys.2025.113240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in light field super-resolution (LFSR) using Transformer-based methods have shown promising improvements. However, existing methods often restrict the modeling of spatial and angular information to individual sub-aperture images (SAIs) and macro-pixel images (MacPIs), limiting the potential for comprehensive information extraction. This results in a common trade-off between model complexity and performance. Additionally, the absence of lightweight models hinders the practical application of LFSR. To address these challenges, we propose a lightweight Transformer-based network that efficiently integrates spatial and angular representations while extending the modeling scope across both SAIs and MacPIs at a low complexity cost. Our approach introduces two key innovations: hierarchical spatial integration (HSI) and hierarchical angular integration (HAI), which capture intra- and inter-spatial and angular dependencies within SAIs and MacPIs, respectively. We then design a third-order loop structure that combines these two integrations, facilitating the progressive merging of spatial and angular information without introducing extra parameters. To further enhance model performance, we incorporate a dedicated epipolar plane image (EPI) module to capture the geometry of the spatial–angular correlation. Extensive experimental results demonstrate that our proposed model significantly outperforms state-of-the-art LFSR algorithms, achieving superior visual quality while maintaining lower computational complexity.},
  archive      = {J_KBS},
  author       = {Meng Li and Bo Ma and Shunzhou Wang},
  doi          = {10.1016/j.knosys.2025.113240},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113240},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical spatial–angular integration for lightweight light field image super-resolution},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective E-voting enhancement system through multi secret image sharing security system. <em>KBS</em>, <em>315</em>, 113239. (<a href='https://doi.org/10.1016/j.knosys.2025.113239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of Electronic Voting (E-voting) systems, ensuring the security and integrity of the voting process has become a critical concern. In this paper, we propose a novel Convolutional Neural Elliptical Curve blockchain (CbECB) enhancement to decentralized e-voting systems through the implementation of a multi-secret image-sharing security system. Also, Convoluting Neural Network (CNN) is an effective image processing strategy for processing as well as analyzing the data based on the e-voting process. Then, Elliptical Curve Cryptography (ECC) is used to provide higher security with a minimum number of key sizes. The multi-secret image-sharing security system is based on the concept of dividing an image into multiple shares, each of which individually does not reveal any meaningful information. Here, the secret keys are generated using the ECC algorithm then it splits into multiple share performances. After that, each voter receives one share of the secret key using the developed algorithm. Consequently, the neural framework is integrated with the Cryptography strategy for identifying the biometric data through the encryption and decryption performance. These shares are distributed among different authorities, ensuring that no single authority can gain complete access to the image. The combination of shares is required to reconstruct the original image. The proposed enhancement also offers advantages in terms of scalability and fault tolerance. The decentralized nature of the system allows for a distributed network of authorities, reducing the risk of a single point of failure and enabling fault tolerance in case of authority failures. The proposed enhancement holds promise for improving the security and integrity of decentralized e-voting, addressing critical concerns, and paving the way for more secure and trustworthy electronic voting systems. The developed model is validated in terms of performance metrics like time consumption, response time, designing cost, and memory usage. While comparing the traditional strategies the developed model attained suitable results. 122.5 MB decrement in memory usage, then nearly 52$ cost is reduced and a 10s decrement occurs in both time consumption and response time.},
  archive      = {J_KBS},
  author       = {Venkata Chinnaiah Gupta Samayamanthula and Satya Prasad Kodati},
  doi          = {10.1016/j.knosys.2025.113239},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113239},
  shortjournal = {Knowl. Based Syst.},
  title        = {An effective E-voting enhancement system through multi secret image sharing security system},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal supervised domain adaptation with a multi-level alignment strategy and consistent decision boundaries for cross-subject emotion recognition from EEG and eye movement signals. <em>KBS</em>, <em>315</em>, 113238. (<a href='https://doi.org/10.1016/j.knosys.2025.113238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal emotion recognition systems from Electroencephalogram (EEG) and eye tracking signals have overcome the limitation of incomplete information expressed by a single modality, leveraging the complementarity of multiple modal information. However, the applicability of these systems is still restricted to new users since signal patterns vary across subjects, decreasing the recognition performance. In this sense, supervised domain adaptation has emerged as an effective method to solve such problem by reducing distribution differences between multi-modal signals from known subjects and a new one. Nevertheless, existing works exhibit a sub-optimal feature distribution alignment, avoiding a correct knowledge transfer. Likewise, although multi-modal approaches present robustness by learning a shared latent space, EEG data are still exposed to noise and perturbations, producing misclassifications in sensitive decision boundaries. To solve these issues, we introduced a multi-modal supervised domain adaptation method, named Multi-level Alignment and Consistent Decision Boundaries (MACDB), which introduces a three-fold strategy for multi-level feature alignment comprising modality-specific normalization, angular cosine distance, and Joint Maximum Mean Discrepancy to achieve (1) an alignment per modality, (2) an alignment between modalities, and (3) an alignment across domains. Also, robust decision boundaries are encouraged over the EEG feature space by ensuring consistent predictions with respect to adversarial perturbations on EEG data. We evaluated our proposal on three public datasets, SEED, SEED-IV and SEED-V, employing leave-one-subject-out cross-validation. Experiments showed that the effectiveness of our proposal achieves an average accuracy of 86.68%, 85.03%, and 86.48% on SEED, SEED-IV, and SEED-V across the three available sessions, outperforming the state-of-the-art results.},
  archive      = {J_KBS},
  author       = {Magdiel Jiménez-Guarneros and Gibran Fuentes-Pineda},
  doi          = {10.1016/j.knosys.2025.113238},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113238},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modal supervised domain adaptation with a multi-level alignment strategy and consistent decision boundaries for cross-subject emotion recognition from EEG and eye movement signals},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedVOD: A two-stage video object detector training framework based on federated unsupervised learning and feature post-processing. <em>KBS</em>, <em>315</em>, 113237. (<a href='https://doi.org/10.1016/j.knosys.2025.113237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing video object detection (VOD) methods are developed based on centrally stored and densely labeled video data, which is not always practical. In many real-world scenarios (e.g., video surveillance and autonomous driving), video data is decentralized and lacks annotation. Centralizing this data not only increases communication and storage costs but also poses risks of privacy breaches. To address the above issues, this paper proposes a novel two-stage video object detector training framework called FedVOD. In this framework, we first introduce federated unsupervised learning to train feature extractors with multi-client unannotated data while preserving privacy. To overcome the heterogeneity and imbalance challenges of decentralized data, we develop a probability-guided communication protocol and DE-Avg model aggregation algorithm for federated system. Subsequently, an adaptive keyframe scheduler is devised to flexibly adjust the keyframe interval, thereby enhancing the rationality of keyframe selection. On this basis, to effectively strike the balance between the speed and accuracy of VOD, we perform different levels of feature extraction for keyframes and non-keyframes, and design two distinct feature post-processing workflows for the extracted features. For different data distributions, experimental results on the ImageNet VID dataset demonstrate the effectiveness and superiority of FedVOD. In addition, the detection performance in a security surveillance system reflects the potential of the framework to be applied to complex real-world scenarios.},
  archive      = {J_KBS},
  author       = {Han Hu and Wenli Du and Bing Wang and Feng Qian},
  doi          = {10.1016/j.knosys.2025.113237},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113237},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedVOD: A two-stage video object detector training framework based on federated unsupervised learning and feature post-processing},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OptNet: Optimization-inspired network beyond deep unfolding for structural artifact reduction. <em>KBS</em>, <em>315</em>, 113235. (<a href='https://doi.org/10.1016/j.knosys.2025.113235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural artifact reduction (SAR), such as metal artifact reduction (MAR) in computed tomography (CT) images and single image deraining (SID), aims to remove the artifacts with repeated structural patterns from the corrupted images. Recently, deep unfolding networks, also known as model-driven networks, have achieved remarkable performance, but they typically require multiple proximity sub-networks to replace the corresponding proximal operators for multivariable updates, increasing the number of learnable parameters. Moreover, existing SAR methods ignore advanced priors, such as textual priors, leaving room for further recovery performance improvement. To address these limitations, we rethink the deep unfolding framework and propose a universal optimization-inspired network architecture, termed OptNet, which introduces a novel multi-channel network design to reduce learnable parameter count while enhancing performance via incorporating textual priors. Concretely, we design the so-called OptNet with contrastive loss to perform multivariable updates, replacing multiple proximity sub-networks typically in iterative optimization algorithms with a multi-channel sub-network, thus reducing the learnable parameter count. OptNet is flexible and can incorporate any advanced priors. Specially, we integrate a pre-trained contrastive language-image pretraining (CLIP) model into an elaborated information fusion module (IFM) to incorporate textual priors, enabling multimodal information interaction that guides more accurate structural artifact reduction, enhancing generalizability across various degradation levels. Extensive experiments demonstrate that OptNet outperforms existing methods, achieving improvements of up to 0.25 dB on MAR and 0.6 dB on SID tasks, while surpassing its deep unfolding variant with a 1.33 dB gain on MAR and reducing parameters by approximately 50%.},
  archive      = {J_KBS},
  author       = {Ke Jiang and Yingshuai Zhao and Baoshun Shi},
  doi          = {10.1016/j.knosys.2025.113235},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113235},
  shortjournal = {Knowl. Based Syst.},
  title        = {OptNet: Optimization-inspired network beyond deep unfolding for structural artifact reduction},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeletal joint image-based multi-channel fusion network for human activity recognition. <em>KBS</em>, <em>315</em>, 113232. (<a href='https://doi.org/10.1016/j.knosys.2025.113232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a hot research area in computer vision. However, existing methods require complete human skeleton sequences and struggle to effectively utilize multi-dimensional information from body nodes. Therefore, we propose an approach that combines image expression and a three-channel fusion network algorithm to enhance the accuracy of human activity recognition. First, we established a platform to capture videos of human activities and collected a dataset comprising 9 different actions. Next, we selected 15 human body nodes and encoded the data from these nodes in a specific manner, resulting in the image expression of activity features. Subsequently, we designed a three-channel fusion network based on ResNet34, which assigns weights to each channel using Coordinate Attention (CA) and employs the Gaussian Error Linear Unit (GELU) to improve recognition accuracy. In this paper, a series of experiments were conducted to validate the superior performance of our proposed data encoding method and multi-channel fusion network algorithm, our improved fusion network achieved a recognition accuracy of 98.06% on the dataset, surpassing the original fusion network by 1.52%. In addition, we further demonstrated the superiority of our method by conducting experiments on two public datasets. This study contributes a high-precision solution to the field of HAR, making a significant contribution to the field by integrating multidimensional information. The code is available at https://github.com/Stalntis/Fusion-network .},
  archive      = {J_KBS},
  author       = {Tianang Sun and Chao Lian and Fanghecong Dong and Jinliang Shao and Xinyue Zhang and Qijun Xiao and Zhongjie Ju and Yuliang Zhao},
  doi          = {10.1016/j.knosys.2025.113232},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113232},
  shortjournal = {Knowl. Based Syst.},
  title        = {Skeletal joint image-based multi-channel fusion network for human activity recognition},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target–background interaction modeling transformer for object tracking. <em>KBS</em>, <em>315</em>, 113230. (<a href='https://doi.org/10.1016/j.knosys.2025.113230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-stream transformer trackers have received widespread attention for their excellent discriminatory ability. However, most of the existing trackers try to mine more information on the target while ignoring the exploitation of the background around it. In this study, we present a one-stream target–background interaction modeling transformer for object tracking. On the one hand, to mitigate the effect of interclass scenarios, a transformer-based target–background interaction model is proposed. This model performs multiview spatiotemporal attention modeling from 2D to 3D, fully exploring the relational dependencies between the target context and the search region. The model maximizes the acquisition of high-quality tokens for target representation by minimizing the influence of pure background tokens. On the other hand, by considering the intraclass strong similarity distractors, a progressive state-aware module is designed to optimize the feature structure used for representing the target. This module aggregates the historical state of the target into the self-attention mechanism, which learns the positional relationship between the target and the distractors in the current frame, to adaptively highlight the weight of the target. By jointly learning interclass variability and intraclass similarity, our method can more accurately reveal the composition and structure of target features, improving its visual perception in complex scenes. Extensive experiments on seven benchmarks compared to existing state-of-the-art trackers demonstrate the effectiveness of our proposed method.},
  archive      = {J_KBS},
  author       = {Huanlong Zhang and Weiqiang Fu and Rui Qi and Bineng Zhong and Xin Wang and Yanfeng Wang},
  doi          = {10.1016/j.knosys.2025.113230},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113230},
  shortjournal = {Knowl. Based Syst.},
  title        = {Target–background interaction modeling transformer for object tracking},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized mixed-order relation-aware recurrent neural networks based CAD model for skin cancer detection and classification. <em>KBS</em>, <em>315</em>, 113222. (<a href='https://doi.org/10.1016/j.knosys.2025.113222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer affects people of all ages, and early detection is essential to reduce mortality rates. The existing deep learning-based Computer-Aided Diagnosis (CAD) models face challenges in accurately differentiating between visually similar skin lesions. The suboptimal model interpretability, lack of robust feature extraction, and inefficient optimization techniques hinder the performance of these models. To address these challenges, an Optimized Mixed-Order Relation-Aware Recurrent Neural Network-based Computer-Aided Diagnosis Model for Skin Cancer Detection and Classification (MORARNN CADM-SKDC) is proposed in this paper. The proposed approach is trained using ISIC dataset and pre-processes the images with Environmentally Adaptive Event-Driven Robust Cubature Kalman Filter (EAEDRCKF) to enhance image quality. Then the affected lesions are segmented using Localized Sparse Incomplete Multi-View Clustering (LSIMVC), and discriminative features, like texture, size, color, position are extracted through the Generalized Transient-Squeezing Transform (GTST). The core of the model is Mixed-Order Relation-Aware Recurrent Neural Networks (MORARNN) classifies various skin cancer types, Actinic Keratosis, Nevus, Lentigo NOS, Melanoma, Seborrheic Keratosis, Solar Lentigo, Basal Cell Carcinoma. MORARNN captures mixed-order relationships between features, improving interpretability and classification precision. The Black-Winged Kite Algorithm (BWKA) optimizes MORARNN's weight parameters effectively, reducing computational complexity and enhancing model convergence. This combination boosts the model's adaptability across diverse skin lesion types. The proposed method distinguishes itself from existing techniques by combining MORARNN with BWKA for superior optimization, achieving higher accuracy of 99.89 %, F1-score of 99.85 %, and computational time of 98 ss. Unlike the existing techniques, it offers enhanced interpretability, robust feature extraction, and improved performance.},
  archive      = {J_KBS},
  author       = {G.S. Uthayakumar and Mallikarjun Yaramadhi and T. Marimuthu and T R Vijaya Lakshmi},
  doi          = {10.1016/j.knosys.2025.113222},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113222},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized mixed-order relation-aware recurrent neural networks based CAD model for skin cancer detection and classification},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous subgraph network with prompt learning for interpretable depression detection on social media. <em>KBS</em>, <em>315</em>, 113215. (<a href='https://doi.org/10.1016/j.knosys.2025.113215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive social media data reflects people’s authentic thoughts, emotions, and communication, allowing early detection of mental health issues such as depression by analyzing these data. Existing works about early depression detection on social media lacked interpretability and neglected the heterogeneity of social media data. Furthermore, they overlooked the global interaction among users. To address these issues, we develop a novel method that leverages a Heterogeneous Subgraph Network with Prompt Learning (HSNPL) and contrastive learning mechanisms. Specifically, we utilize prompt learning to interpretably map users’ implicit psychological symbols and incorporate deep semantic and diverse behavioral features by a heterogeneous information network. Then, we construct a heterogeneous graph network with a dual attention mechanism to model the relationships among heterogeneous social information at the feature level. Furthermore, we develop a heterogeneous subgraph network integrating subgraph attention and self-supervised contrastive learning to explore complicated interactions among users and groups at the user level. Extensive experimental results demonstrate that our proposed method significantly outperforms state-of-the-art methods for depression detection on social media.},
  archive      = {J_KBS},
  author       = {Chen Chen and Fenghuan Li and Haopeng Chen and Yuankun Lin},
  doi          = {10.1016/j.knosys.2025.113215},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113215},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous subgraph network with prompt learning for interpretable depression detection on social media},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal-based graph reasoning for visual commonsense reasoning. <em>KBS</em>, <em>315</em>, 113214. (<a href='https://doi.org/10.1016/j.knosys.2025.113214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Commonsense Reasoning (VCR) is to answer a question about the given image while providing a rationale that explains why the answer is true. Most studies have achieved remarkable performance by semantic alignment between the still image and answers. However, it is not trivial to answer temporal questions asking about some future moment, beyond the static content of the image. In this paper, we propose an Action-aware Temporal Graph Attention Network (ATGAN), in which temporal-oriented action reasoning is presented to infer the future action aligned with the answer. Since it is built on multiple actions, a verb-centric action segmentation module is designed to learn the importance distribution of key arguments associated with the verb and words surrounding the verb by discrete argument attention and continuous span attention, respectively. Additionally, we propose a question-guided visual extraction module to highlight visual objects relevant to the question via question commands and capture their relations in the image. Experimental results show that ATGAN outperforms strong baselines, especially for temporal questions. It improves performance by 2.88% and 2.50% on two subtasks, question answering and answer justification, respectively.},
  archive      = {J_KBS},
  author       = {Shaojuan Wu and Kexin Liu and Jitong Li and Peng Chen and Xiaowang Zhang and Zhiyong Feng},
  doi          = {10.1016/j.knosys.2025.113214},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113214},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal-based graph reasoning for visual commonsense reasoning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diversity-aware incentive mechanism for cross-silo federated learning with budget constraint. <em>KBS</em>, <em>315</em>, 113212. (<a href='https://doi.org/10.1016/j.knosys.2025.113212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) relies on a sufficient number of clients to utilize their local data for model training, making the incentive mechanism a crucial component for its success. Given the significant impact of the training dataset on FL performance, we introduce two key metrics: the scale and diversity of the training data. These factors are vital for improving model accuracy. However, designing an incentive mechanism that accounts for both the scale and diversity of data in FL is a challenge task. To address this, we propose an auction-based method for multi-dimensional objectives, called the diversity-aware incentive mechanism (DAIM). We prove that the DAIM satisfies three important properties: truthfulness, individual rationality and budget feasibility. Under this mechanism, clients are incentivized to truthfully report the size, distribution and cost of their local datasets, with selected clients contributing all or part of their data to federated model training. Experimental results show that, especially when the budget is limited, DAIM outperforms existing methods that ignore data diversity, particularly when there is significant variation in dataset distributions across clients.},
  archive      = {J_KBS},
  author       = {Xiaohong Wu and Yujun Lin and Haotian Zhong and Jie Tao and Yonggen Gu and Shigen Shen and Shui Yu},
  doi          = {10.1016/j.knosys.2025.113212},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113212},
  shortjournal = {Knowl. Based Syst.},
  title        = {A diversity-aware incentive mechanism for cross-silo federated learning with budget constraint},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive weighted multi-teacher distillation for efficient medical imaging segmentation with limited data. <em>KBS</em>, <em>315</em>, 113196. (<a href='https://doi.org/10.1016/j.knosys.2025.113196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep learning models have significantly improved performance in medical tasks, but their complex structures and high computational requirements pose challenges for clinical implementation. Additionally, data privacy concerns limit the availability of comprehensive datasets needed to train accurate models. To address these issues, we propose a novel adaptive knowledge distillation (KD) framework for medical imaging segmentation that integrates intermediate and high-level feature pairwise relationships between teacher and student models. Our framework features adaptive multi-teacher distillation, where multiple teacher models, each trained on limited data from different sites and hospitals with various scanning protocols, distill their knowledge to a student model using adaptive weighting. This method allows each teacher to convey deep feature representations to the student’s intermediate layers, enhancing performance without increasing complexity. To validate the efficacy of our framework, we conducted extensive experiments on two publicly available medical datasets, focusing on prostate and spleen tumor segmentation tasks. Our adaptive KD approach significantly improved dice scores by up to 9%, surpassing all tested baseline models. These results highlight the potential of our KD framework to enhance medical imaging segmentation while ensuring data privacy and security.},
  archive      = {J_KBS},
  author       = {Eddardaa Ben Loussaief and Hatem A. Rashwan and Mohammed Ayad and Adnan Khalid and Domemec Puig},
  doi          = {10.1016/j.knosys.2025.113196},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113196},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive weighted multi-teacher distillation for efficient medical imaging segmentation with limited data},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Make you said that: A motion robust multi-knowledge fusion framework for speaker-agnostic visual dubbing. <em>KBS</em>, <em>315</em>, 113193. (<a href='https://doi.org/10.1016/j.knosys.2025.113193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker-agnostic visual dubbing technology seeks to synchronize lip movements in facial videos with an audio signal, requiring high precision and exceptional audio-visual fidelity. While many existing methods focus on audio-visual synchronization, they often rely on generative adversarial networks (GANs) to inpaint cropped facial areas based on audio cues. However, these methods can result in unrealistic facial textures or noticeable artifacts, especially when videos contain natural head movements. To overcome these challenges, we propose a novel framework that utilizes the 3D Morphable Model (3DMM) as an intermediate representation, decomposing the visual dubbing task into two independent sub-tasks: audio-driven 3D expression prediction and 3D face-guided neural rendering. Our framework introduces an innovative audio-visual synchronization network guided by knowledge priors, significantly improving synchronization quality. We also propose a Multi-facial Prior Fusion Texture Enhanced Render Network, which ensures texture consistency across facial regions and enhances robustness to head movements. By employing a multi-task learning framework, our method maximizes the use of reference image textures, significantly improving the realism of generated talking face videos. Extensive experiments demonstrate that our framework outperforms state-of-the-art techniques and sets a new benchmark for speaker-agnostic visual dubbing.},
  archive      = {J_KBS},
  author       = {Yilei Chen and Shengwu Xiong},
  doi          = {10.1016/j.knosys.2025.113193},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113193},
  shortjournal = {Knowl. Based Syst.},
  title        = {Make you said that: A motion robust multi-knowledge fusion framework for speaker-agnostic visual dubbing},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation based transfer learning for patent transfer prediction. <em>KBS</em>, <em>315</em>, 113192. (<a href='https://doi.org/10.1016/j.knosys.2025.113192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As intellectual property competition intensifies, significant differences in patent data distribution arise across countries. Addressing cross-national prediction disparities through transfer learning, specifically from patent-developed to patent-developing countries, to enhance patent transfer prediction accuracy, remains challenging. This study addresses two fundamental challenges: (1) how to choose the transfer learning direction, and (2) how to improve the accuracy of patent transfer prediction. We herein propose a domain adaptation transfer learning-based patent transfer prediction model. For the choice of transfer learning direction, we identify key indicators for directional selection by evaluating the influence of patent data indicators and establish criteria for determining the transfer learning direction. For domain adaptation learning, we use the BERT pretrained model, incorporating a lambda layer to extract patent features. A gradient reversal layer is added to narrow the disparity in patent feature distribution between the source and target domains, allowing us to learn domain-shared features. The experiments show that patent quantity and patent transfer speed are important indicators for choosing the transfer learning direction. Additionally, the model significantly improves precision, recall, and F1-score, with improvement rates of 6.85%, 6.83%, and 7.11%, respectively, compared with baseline models.},
  archive      = {J_KBS},
  author       = {Weidong Liu and Yiming Wang and Keqin Gan and Xiangfeng Luo and Yu Zhang and Cuicui Jiang},
  doi          = {10.1016/j.knosys.2025.113192},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113192},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain adaptation based transfer learning for patent transfer prediction},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving graph structure learning for multivariate time series forecasting. <em>KBS</em>, <em>315</em>, 113190. (<a href='https://doi.org/10.1016/j.knosys.2025.113190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of graph neural networks (GNN) in multivariate time series forecasting has yielded remarkable achievements. The adjacency matrix which describes the interactions among variables is dense and static in most previous efforts no matter hand-crafted or self-learned. However, we argue that: (1) In the real-world scenario, the interactions could be dynamic and evolving; (2) A sparse and compact graph structure could better reflect such interactions. Along this line, this paper proposes a deep neural network based on GNN to address multivariate time series forecasting problem. Firstly, we construct a sparse and principal structure from the original dense graph structure differentiably by Gumbel-Softmax. Secondly, a new series of graphs are constructed by the recurrent neural network to model the evolving correlations among variables during each individual time point. Thirdly, a novel temporal constraint which is aimed at enhancing the training process is proposed to help evolving graphs capture the temporal smoothness of time series. Lastly, a unified neural network is constructed that integrates all of the above modules to make the final prediction, effectively addressing both temporal dependency and pairwise correlations in a comprehensive manner. Experiments are performed on six datasets comprising various domains, evaluating the performance of our model in single-step and multi-step forecasting tasks. The results showcase the exceptional performance of our model compared to the existing approaches in the field.},
  archive      = {J_KBS},
  author       = {Junchen Ye and Qian Liu and Zihan Liu and Weimiao Li and Tongyu Zhu and Leilei Sun and Bowen Du},
  doi          = {10.1016/j.knosys.2025.113190},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113190},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evolving graph structure learning for multivariate time series forecasting},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The evolution of cooperation in continuous dilemmas via multi-agent reinforcement learning. <em>KBS</em>, <em>315</em>, 113153. (<a href='https://doi.org/10.1016/j.knosys.2025.113153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of cooperation aims to investigate how to increase the proportion of cooperating participants in a system. It has been studied in a broad range of domains from biology and social science to multi-agent systems and control systems. However, the current research shares a common limitation in that each participant can only opt for cooperation or defection. In the real-world, however, whether to cooperate or defect may not be a strict option; rather, it might be measured in multiple levels. To address this issue, we first propose a novel continuous dilemma in the federated learning setting called the malicious client’s dilemma, where malicious clients can quantify the poisonous updates that will be sent to the server. A multi-agent reinforcement learning-based method that involves a deep prediction network and a deep generation network is then developed to deal with the continuous dilemma. Taking each participant in turn, the deep prediction network predicts the behavior of the other participants in the current round based on their previous behavior. Then, based on the prediction, the deep generation network generates an action for the participant. We theoretically prove that, by combining the two networks, both the learning stationarity and convergence can be guaranteed. A comprehensive set of experiments comparing our method with two other state-of-the-art methods also based on reinforcement learning demonstrates the superior performance of our method in both the proposed dilemma and two other prevalent dilemmas. Our method achieves better results in promoting cooperation and obtaining higher rewards through its unique ability to predict other agents’ behavior and generate optimal strategies based on these predictions, while existing methods rely solely on historical behaviors or reputation mechanisms.},
  archive      = {J_KBS},
  author       = {Congcong Zhu and Dayong Ye and Tianqing Zhu and Wanlei Zhou},
  doi          = {10.1016/j.knosys.2025.113153},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113153},
  shortjournal = {Knowl. Based Syst.},
  title        = {The evolution of cooperation in continuous dilemmas via multi-agent reinforcement learning},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated experimental design using a human–AI teaming framework. <em>KBS</em>, <em>315</em>, 113138. (<a href='https://doi.org/10.1016/j.knosys.2025.113138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a human–AI teaming framework for the optimization of expensive black-box functions. Inspired by the intrinsic difficulty of extracting expert knowledge and distilling it back into AI models and by observations of human behavior in real-world experimental design, our proposed algorithm lets the human expert take the lead in the experimental process. The human expert can use their domain expertise to its full potential, while the AI plays the role of a muse, injecting novelty and searching for areas of weakness to break the human out of over-exploitation induced by cognitive entrenchment. We validate our proposed algorithm using synthetic data and with human experts performing real-world experiments.},
  archive      = {J_KBS},
  author       = {Arun Kumar A.V. and Alistair Shilton and Sunil Gupta and Shannon Ryan and Majid Abdolshah and Hung Le and Santu Rana and Julian Berk and Mahad Rashid and Svetha Venkatesh},
  doi          = {10.1016/j.knosys.2025.113138},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113138},
  shortjournal = {Knowl. Based Syst.},
  title        = {Accelerated experimental design using a human–AI teaming framework},
  volume       = {315},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering generalized clusters with adaptive mixture density-based clustering. <em>KBS</em>, <em>314</em>, 113250. (<a href='https://doi.org/10.1016/j.knosys.2025.113250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based clustering algorithms are widely used for their ability to handle complex datasets; however, their performance often depends on the definition of density and is sensitive to data shapes, density variations, and noise. To address these challenges, we propose a novel parameter-free clustering algorithm named "Bombing", which can automatically determine the number of clusters. The algorithm enhances adaptability to complex data structures by combining global and local density estimations and utilizing dynamically adjusted density measures. By introducing the concept of generalized clusters and employing a "bombing" process that propagates clustering outward from core points, the method effectively mitigates the impact of cluster shapes, overlaps, and noise. Additionally, through the analysis of adjacency degrees, the algorithm can automatically detect the optimal number of clusters without prior knowledge. Experimental results on various synthetic and real datasets show that our proposed algorithm outperforms existing methods in clustering accuracy and robustness. It effectively handles noise and cluster overlap, and excels in identifying the optimal value of K .},
  archive      = {J_KBS},
  author       = {Zexuan Fei and Haoyu Zhai and Jie Yang and Bin Wang and Yan Ma},
  doi          = {10.1016/j.knosys.2025.113250},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113250},
  shortjournal = {Knowl. Based Syst.},
  title        = {Discovering generalized clusters with adaptive mixture density-based clustering},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel parallel framework for scatter search. <em>KBS</em>, <em>314</em>, 113248. (<a href='https://doi.org/10.1016/j.knosys.2025.113248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scatter search (SS) is a well-established metaheuristic for hard combinatorial optimization problems. SS is characterized by its versatility and ease of context adaptation and implementation. Although the literature includes SS parallelization schemes for specific problems, a general parallel framework for scatter search has not been developed and tested. We introduce three SS parallel designs, each focusing on a different task, namely, reducing computational time, increasing search exploration, and balancing search intensification and diversification. The proposed designs are tested on problems where the state of the art is a traditional (sequential) SS approach. This testing platform helps us assess the contributions of the parallel computing strategies to solution speed and quality. Our publicly available code is designed to be adapted to optimization problems that are not considered here. The results show promising avenues for establishing a general framework of SS parallelization.},
  archive      = {J_KBS},
  author       = {A. Casado and S. Pérez-Peló and J. Sánchez-Oro and A. Duarte and M. Laguna},
  doi          = {10.1016/j.knosys.2025.113248},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113248},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel parallel framework for scatter search},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMS: A hyperspectral image classification method based on SVM and multi-modal attention network. <em>KBS</em>, <em>314</em>, 113236. (<a href='https://doi.org/10.1016/j.knosys.2025.113236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral (HS) image classification technology is increasingly used for identifying land cover categories. However, spectral aliasing restricts its ability to accurately and completely capture land cover features. To overcome this issue, herein, we introduce a classification method that integrates three modules, namely, a convolutional neural network with an attention mechanism (AMCNN), multi-modal cross-layer adaptive fusion encoder (MCAFE) and support vector machine (SVM), which is referred to as attention-based multi-modal cross-layer fusion network with SVM (AMS). In particular, AMCNN integrates convolution and attention mechanisms to overcome the limitations of a single CNN structure in dynamically allocating attention. MCAFE is proposed to overcome the issues of ineffective inter-layer information interaction and gradient vanishing commonly observed in stacked encoder layers structures. Furthermore, SVM is used to obtain the decision boundaries because of its better performance on linearly separable data than on traditional fully connected (FC) layers. Experimental results demonstrate that AMS considerably enhances the overall accuracy (OA), average accuracy (AA) and Kappa metrics on the Houston and MUUFL datasets, outperforming other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yingxia Chen and Zhaoheng Liu and Zeqiang Chen},
  doi          = {10.1016/j.knosys.2025.113236},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113236},
  shortjournal = {Knowl. Based Syst.},
  title        = {AMS: A hyperspectral image classification method based on SVM and multi-modal attention network},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDGE: Edge distillation and gap elimination for heterogeneous networks in 3D medical image segmentation. <em>KBS</em>, <em>314</em>, 113234. (<a href='https://doi.org/10.1016/j.knosys.2025.113234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressing the cumbersome Vision Transformers (ViTs) or ConvNets into compact students can effectively facilitate the deployment of 3D medical image segmentation models on embedded devices. However, teacher-student heterogeneity coupled with huge capacity discrepancies poses tremendous challenges in facilitating effective knowledge transfer. This paper introduces the Edge Distillation and Gap Elimination (EDGE) framework for 3D medical image segmentation while effectively mitigating the knowledge gap across heterogeneous networks. We observe that the degradation of knowledge transfer between heterogeneous networks in 3D medical image segmentation may be attributed to a lack of edge-sensitive knowledge transfer. Initially, Edge Constraint Knowledge Distillation (ECKD) is introduced to facilitate knowledge transfer of edge-sensitive logits and enhance the student's edge perception ability. Subsequently, we propose quantifying the knowledge gap as Hausdorff Distance (HD) in 3D abdominal CT images. Accordingly, Segmentation Refinement Knowledge Distillation (SRKD) is further introduced after the ECKD module to address knowledge transfer degradation in heterogeneous networks by minimizing the HD. Lastly, Scale Adaptation Knowledge Distillation (SAKD) is presented to enhance the student's performance in segmenting multi-organs with varying scales after projecting multiple stages of features into logits space. Extensive experiments are conducted on two 3D segmentation datasets, WORD and BTCV. Our proposed EDGE method consistently exhibits excellent performance across various teacher-student combinations. These results suggest that our method holds promise in bridging the knowledge gap with a significant margin compared to other competitive methods. The effectiveness of the individual modules is further confirmed via ablation experiments and visualization results.},
  archive      = {J_KBS},
  author       = {Xiangchun Yu and Tianqi Wu and Dingwen Zhang and Jian Zheng and Jianqing Wu},
  doi          = {10.1016/j.knosys.2025.113234},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113234},
  shortjournal = {Knowl. Based Syst.},
  title        = {EDGE: Edge distillation and gap elimination for heterogeneous networks in 3D medical image segmentation},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCSSGA-UNet: Biomedical image segmentation with DenseNet channel spatial and semantic guidance attention. <em>KBS</em>, <em>314</em>, 113233. (<a href='https://doi.org/10.1016/j.knosys.2025.113233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have progressed significantly in the field of biomedical image segmentation, although precision remains a challenge. The inconsistent sizes and shapes of the lesion regions make it difficult for the existing deep learning methods to extract their discriminatory features. Additionally, spatial and semantic information is not effectively merged during decoding, resulting in redundant information and semantic gaps. To address these challenges, we propose the Dense Channel Spatial Semantic Guidance Attention UNet (DCSSGA-UNet) architecture, which integrates DenseNet201 as the base encoder and attention mechanisms to enhance segmentation performance. The decoder follows the standard U-Net pipeline, with the encoder capturing global multi-scale features through dense convolutional and transition blocks, which enhance the model’s ability to distinguish between intricate details. The introduction of the channel spatial attention (CSA) and semantic guidance attention (SGA) modules selectively focuses on important features and reduces redundancy, effectively bridging semantic gaps. Tests conducted on three medical image datasets (CVC-ClinicDB, CVC-ColonDB, and Kvasir-SEG) showed that our proposed DCSSGA-UNet model could detect object variabilities with improved results and outperformed other comparable methods. It achieved the mean intersection-over-union (mIoU) scores of 95.67%, 92.39%, and 93.97%, as well as mean dice coefficient (mDice) of 98.85%, 95.71%, and 96.10%, respectively. These results highlight the model’s superior precision and exceptional versatility, making it a valuable tool for clinical applications, particularly for accurate lesion segmentation and assisting in the diagnosis and treatment of diseases like colorectal cancer.},
  archive      = {J_KBS},
  author       = {Tahir Hussain and Hayaru Shouno and Mazin Abed Mohammed and Haydar Abdulameer Marhoon and Taukir Alam},
  doi          = {10.1016/j.knosys.2025.113233},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113233},
  shortjournal = {Knowl. Based Syst.},
  title        = {DCSSGA-UNet: Biomedical image segmentation with DenseNet channel spatial and semantic guidance attention},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A geometry-aware generative model for face morphing attacks. <em>KBS</em>, <em>314</em>, 113231. (<a href='https://doi.org/10.1016/j.knosys.2025.113231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated face recognition systems are vulnerable against various attacks, such as adversarial attacks, digital manipulation and physical spoofs. As a special case of digital manipulation attacks, face morphing draws increasing concerns due to such attacks generalizing well across diverse face recognition systems. However, the threat of face morphing attacks is underestimated due to the following characteristics of state-of-the-art morphing methods. (i) Their generated face images have low visual quality with artifacts, (ii) they fail to guarantee high similarity with contributing subjects, and (iii) they do not explicitly consider countering face morphing detection methods when constructing morphing attacks. Based on the observation that facial geometry information is vital in face recognition, we present in this paper a geometry-aware generative model (GAGM), which can realize more threatening attacks against human experts, face recognition and morphing attack detection. GAGM synthesizes morphs with the drive of both facial geometry and texture based on dual invertible networks, resulting in visually realistic and highly deceptive morphed face images. To circumvent morphing-attack detection, GAGM implements a fine-grained adversarial attack strategy to mislead the detection methods. Visualization results demonstrate that GAGM, compared to existing techniques, is capable of generating visually faultless facial morphs. Meanwhile, extensive quantitative experiments show that GAGM can significantly increase the attack success rate against face recognition and deceive various morphing attack detection models.},
  archive      = {J_KBS},
  author       = {Zongyong Deng and Qijun Zhao and Libin Ye and Qiaoyun He and Zuyuan He and Jie Huang},
  doi          = {10.1016/j.knosys.2025.113231},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113231},
  shortjournal = {Knowl. Based Syst.},
  title        = {A geometry-aware generative model for face morphing attacks},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster search optimisation of deep neural networks for audio emotion classification. <em>KBS</em>, <em>314</em>, 113223. (<a href='https://doi.org/10.1016/j.knosys.2025.113223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated patient monitoring solutions greatly benefit from audio emotion classification, although the considerable variance in individual expression and interpretation of emotions poses a challenge. Current approaches often employ standard Audio Spectrogram Transformer (AST) and deep learning models such as Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN)-based networks. However, their performance can be enhanced by integrating neural architecture search techniques using swarm optimisation algorithms. In this research, we explore AST with hyperparameter optimisation for speech emotion recognition. Three deep learning architectures with optimisable τ b -block structures and variable filter numbers, i.e. 1DCNN, bidirectional LSTM (BiLSTM) and CNN-BiLSTM, are also proposed, enabling the optimisation of network depth and width. A novel Cluster Search Optimisation (CSO) algorithm is introduced. It incorporates Cluster Centroid Search, a Cluster Distance Improvement metric and reinforcement learning to dispatch different search actions based on clustering convergence and Q -learning strategies, respectively. A novel Noise Tempered K-means (NTKM) clustering model is also proposed with the integration of Gaussian-based noise insertion and cluster compactness-separation measurement, to further fine-tune the cluster centriods obtained using OPTICS clustering. CSO is used for hyperparameter and architecture search for AST and aforementioned deep networks. Attention mechanisms are also integrated with CSO-optimised networks to further enhance feature learning. We evaluate the resulting models against those devised by other optimisation algorithms across the EMO-DB, SAVEE, and TESS datasets. The empirical results demonstrate that CSO-optimised AST and CNN-BiLSTM with attention mechanisms outperform other architectures and yield favourable comparison results against those from existing state-of-the-art audio emotion classification methods.},
  archive      = {J_KBS},
  author       = {Sam Slade and Li Zhang and Houshyar Asadi and Chee Peng Lim and Yonghong Yu and Dezong Zhao and Arjun Panesar and Philip Fei Wu and Rong Gao},
  doi          = {10.1016/j.knosys.2025.113223},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113223},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cluster search optimisation of deep neural networks for audio emotion classification},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking the robustness of graph neural networks: An information theory perspective. <em>KBS</em>, <em>314</em>, 113221. (<a href='https://doi.org/10.1016/j.knosys.2025.113221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been widely used in multiple fields, but they exhibit vulnerable performance when faced with adversarial attacks. Therefore, researching more robust GNN defenses has garnered widespread attention. However, existing GNN defenses ignore the inherent contradiction between increasing the knowledge domain of GNNs and enhancing the uniqueness of embeddings, which leads to the suboptimal robustness of GNNs. To address these limitations, we propose a multi-graph and dual-view adversarial defense for GNNs, called G raph O ptimization of L atent D istance (GOLD). Initially, from the mutual information perspective, GOLD utilizes a multi-graph generator to produce multiple graphs with different semantics, namely modified graph, damaged graph (with corrupt-semantic) and refined graph (with unique-semantic). Next, using local-view information bottleneck and global-view link reconstruction, GOLD forms a dual-view contrastive loss, and then optimizes the latent embeddings. Through iterative execution of the above process, GOLD extends the knowledge domain of GNNs and enhances the uniqueness of embeddings, thus improving the robustness of GNNs. Ultimately, we validate the effectiveness of GOLD through extensive experiments, demonstrating its superior performance across three benchmark datasets and four large-scale attack scenarios.},
  archive      = {J_KBS},
  author       = {Ding Li and Hui Xia and Xin Li and Rui Zhang and Mingda Ma},
  doi          = {10.1016/j.knosys.2025.113221},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113221},
  shortjournal = {Knowl. Based Syst.},
  title        = {Rethinking the robustness of graph neural networks: An information theory perspective},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling syphilis progression and disability risk with neural networks. <em>KBS</em>, <em>314</em>, 113220. (<a href='https://doi.org/10.1016/j.knosys.2025.113220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the progression and disability outcomes of syphilis using an Artificial Neural Network (ANN)-based approach, focusing on chronic infection stages among high-risk populations. Syphilis progression models traditionally face challenges in capturing complex dynamics and associated disability due to computational inefficiencies in solving nonlinear differential equations. To address these limitations, we extend the deterministic SEIARS framework to incorporate disability parameters, capturing syphilis impacts across primary, secondary, and tertiary stages, including neurosyphilis and cardiovascular complications. The ANN model leverages the Levenberg–Marquardt Backpropagation (LMB) algorithm, with training data generated via the Runge–Kutta method, to accurately simulate infection transmission and recovery dynamics. Our model stratifies populations by risk levels and accounts for reinfection due to loss of immunity, integrating high- and low-risk group behaviors. The ANN-based approach overcomes limitations of traditional finite difference methods, such as Euler and Runge–Kutta, which are often hindered by memory demands and approximation errors. By dividing the dataset into 5% testing, 10% validation, and 85% training, the model achieves an average Mean Squared Error (MSE) of 1 . 8673 × 1 0 − 10 and regression coefficients (R-values) close to 1, validating its accuracy and consistency. This work highlights the utility of ANN-based approaches in enhancing the precision of epidemic models, offering valuable insights into targeted interventions and treatment strategies for syphilis and similar infections.},
  archive      = {J_KBS},
  author       = {Kamel Guedri and Rahat Zarin and Mowffaq Oreijah and Samaher Khalaf Alharbi and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.knosys.2025.113220},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113220},
  shortjournal = {Knowl. Based Syst.},
  title        = {Modeling syphilis progression and disability risk with neural networks},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topic modeling through rank-based aggregation and LLMs: An approach for AI and human-generated scientific texts. <em>KBS</em>, <em>314</em>, 113219. (<a href='https://doi.org/10.1016/j.knosys.2025.113219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing presence of AI-generated and human-paraphrased content in scientific literature presents new challenges for topic modeling, particularly in maintaining semantic coherence and interpretability across diverse text sources. Traditional topic modeling methods, such as Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF), often suffer from inconsistencies and diminished coherence when applied to heterogeneous sources. Recently, large language models (LLMs) have demonstrated potential for enhanced topic extraction, yet they frequently lack the stability and interpretability required for reliable deployment. In response to these limitations, we propose a novel, robust ensemble framework that integrates rank-based aggregation and LLM-powered topic extraction to achieve consistent, high-quality topic modeling across AI-generated, AI-paraphrased, and human-generated scientific abstracts. Our framework employs a rank-based aggregation scheme to reduce inconsistencies in LLM outputs and incorporates neural topic models to enhance coherence and semantic depth. By combining the strengths of traditional models and LLMs, our framework consistently outperforms baseline methods in terms of topic coherence, diversity, and stability. Experimental results on a diverse dataset of scientific abstracts demonstrate a substantial improvement in coherence scores and topic interpretability, with our ensemble approach outperforming conventional models and leading neural topic models by significant margins. This framework not only addresses the challenges of cross-source topic modeling but also establishes a benchmark for robust, scalable analysis of scientific literature spanning AI and human narratives.},
  archive      = {J_KBS},
  author       = {Tuğba Çelikten and Aytuğ Onan},
  doi          = {10.1016/j.knosys.2025.113219},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113219},
  shortjournal = {Knowl. Based Syst.},
  title        = {Topic modeling through rank-based aggregation and LLMs: An approach for AI and human-generated scientific texts},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning prototypes from background and latent objects for few-shot semantic segmentation. <em>KBS</em>, <em>314</em>, 113218. (<a href='https://doi.org/10.1016/j.knosys.2025.113218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation (FSS) aims to segment target object within a given image supported by few samples with pixel-level annotations. Existing FSS framework primarily focuses on target area for learning a target-object prototype while directly neglecting non-target clues. As such, the target-object prototype has not only to segment the target object but also to filter out non-target area simultaneously, resulting in numerous false positives. In this paper, we propose a background and latent-object prototype learning network (BLPLNet), which learns prototypes from not only the target area but also the non-target counterpart. From our perspective, the non-target area is delineated into background full of repeated textures and salient objects, refer to as latent objects in this paper. Specifically, a background mining module (BMM) is developed to specially learn a background prototype by episodic learning. The learned background prototype replaces the target-object one for background filtering, reducing the false positives. Moreover, a latent object mining module (LOMM), based on self-attention mechanism, works together with the BMM for learning multiple soft-orthogonal prototypes from latent objects. Then, the learned latent-object prototypes, which condense the general knowledge of objects, are used in a target object enhancement module (TOEM) to enhance the target-object prototype with the guidance of affinity-based scores. Extensive experiments on PASCAL-5 i and COCO-20 i datasets demonstrate the superiority of the BLPLNet, which outperforms state-of-the-art methods by an average of 0.60% on PASCAL-5 i . Ablation studies validate the effectiveness of each component, and visualization results indicate that the learned latent-object prototypes indeed convey the general knowledge of objects.},
  archive      = {J_KBS},
  author       = {Yicong Wang and Rong Huang and Shubo Zhou and Xueqin Jiang and Zhijun Fang},
  doi          = {10.1016/j.knosys.2025.113218},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113218},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning prototypes from background and latent objects for few-shot semantic segmentation},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic relation-aware graph attention network with noise augmented layer-wise contrastive learning for recommendation. <em>KBS</em>, <em>314</em>, 113217. (<a href='https://doi.org/10.1016/j.knosys.2025.113217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems based on knowledge graphs enhance the explainability of recommendations by incorporating external knowledge. Nevertheless, the accuracy of recommendations heavily depends on dense interaction data and high-quality knowledge graphs, both of which commonly suffer from data sparsity. Introducing graph contrastive learning to enhance representation quality can effectively improve recommendation performance. Existing graph contrastive learning methods that use graph augmentation can alleviate the data sparsity problem. However, they often neglect the semantic modeling of relation embeddings and lack sufficient contrastive information, leading to insufficient utilization of the embedding space for relations and nodes. To address this, we propose a semantic relation-aware graph attention network with a noise augmented layer-wise contrastive learning model for recommendation, named SRGAN . Specifically, we design a semantic relation-aware graph attention network that updates the semantics of relations during multi-layer iterations to better capture user preferences. Additionally, we construct a noise-augmented layer-wise contrastive learning model, employing simple yet effective noise perturbations to generate contrastive views for entities and relations. By maximizing the consistency of the representations in each layer, the model achieves alignment with the lower-level features of the intermediate layers. Extensive experiments on three public benchmark datasets demonstrate that our proposed method significantly outperforms current approaches. To ensure reproducibility, we make the code and data from our experiments publicly available on https://github.com/liujianfang2021/SRGAN .},
  archive      = {J_KBS},
  author       = {Jianfang Liu and Wei Wang and Baolin Yi and Huanyu Zhang and Xiaoxuan Shen},
  doi          = {10.1016/j.knosys.2025.113217},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113217},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semantic relation-aware graph attention network with noise augmented layer-wise contrastive learning for recommendation},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using machine learning in combinatorial optimization: Extraction of graph features for travelling salesman problem. <em>KBS</em>, <em>314</em>, 113216. (<a href='https://doi.org/10.1016/j.knosys.2025.113216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has emerged as a paradigmatic approach for addressing complex problems across various scientific disciplines, including combinatorial optimization. This article specifically explores the application of machine learning to the Travelling Salesman Problem (TSP) as a technique for evaluating and classifying graph edges. The methodology involves extracting a set of graph features and statistical measures for each edge in the graph. Subsequently, a machine learning model is constructed using the training data, and this model is employed to classify edges in a TSP instance, determining whether they are part of the optimal solution or not. This article contributes to existing knowledge in these key aspects: (a) enhancement of statistical measures, (b) introduction of a novel graph feature, and (c) preparation of training data to simulate real-world problem scenarios. Rigorous experimentation on benchmark instances from the well-established TSP library demonstrates a noteworthy increase in classification accuracy compared to the original approach without the improvements; various popular machine learning techniques are employed and evaluated. Furthermore, the characteristics and effects of the novel approaches are assessed and discussed, including their application to a basic heuristic algorithm. This research finds practical applications in problem reduction, involving the elimination of decision variables, or as a support for heuristic or metaheuristic algorithms in finding solutions.},
  archive      = {J_KBS},
  author       = {Petr Stodola and Radomír Ščurek},
  doi          = {10.1016/j.knosys.2025.113216},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113216},
  shortjournal = {Knowl. Based Syst.},
  title        = {Using machine learning in combinatorial optimization: Extraction of graph features for travelling salesman problem},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced discrete SAC-based speed and lane change decision-making method for autonomous vehicle in highway scenario. <em>KBS</em>, <em>314</em>, 113213. (<a href='https://doi.org/10.1016/j.knosys.2025.113213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A discrete decision-making strategy based on advanced discrete soft actor–critic (ADSAC) is designed in this paper to enhance driving safety, comfort, and efficiency in highway scenarios. By modifying the policy network to output a probability distribution for each discrete action through the softmax function, a novel autonomous driving method is developed to integrate behavior decision-making based on reinforcement learning with rule-based planning and tracking control methods, thereby combining the advantages of data-driven approaches with the stability of rule-based methods. This strategy builds upon the traditional prioritized experience replay (PER) by introducing the manhattan distance to evaluate the similarity of sampled experiences to ensure the diversity of experiences used for training. The gradual decay of experience priority over time are adopted and an updating technique of hybrid on-policy and off-policy experiences is also implemented, which is achieved by mixing latest experiences with previous random experiences. This proposed method can enhance the utilization rate of effective experiences to further improving the sample efficiency and stability of the algorithm’s training process. Finally, the algorithm validation is conducted on the highway-simulator and comparative experiment analysis with common discrete reinforcement learning algorithms is carried out.},
  archive      = {J_KBS},
  author       = {Kang Sun and Haiyan Zhao and Hongbin Xie and Bingzhao Gao},
  doi          = {10.1016/j.knosys.2025.113213},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113213},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced discrete SAC-based speed and lane change decision-making method for autonomous vehicle in highway scenario},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cross-encoders using knowledge graph hierarchy for medical entity linking in zero- and few-shot scenarios. <em>KBS</em>, <em>314</em>, 113211. (<a href='https://doi.org/10.1016/j.knosys.2025.113211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Entity Linking (MEL) is a common task in natural language processing, focusing on the normalization of recognized entities from clinical texts using large knowledge bases (KBs). This task presents significant challenges, especially when working with electronic health records that often lack annotated clinical notes, even in languages like English. The difficulty increases in few-shot or zero-shot scenarios, where models must operate with minimal or no training data, a common issue when dealing with less-documented languages such as Spanish. Existing solutions that combine contrastive learning with external sources, like the Unified Medical Language System (UMLS), have shown competitive results. However, most of these methods focus on individual concepts from the KBs, ignoring relationships such as synonymy or hierarchical links between concepts. In this paper, we propose leveraging these relationships to enrich the training triplets used for contrastive learning, improving performance in MEL tasks. Specifically, we fine-tune several BERT-based cross-encoders using enriched triplets on three clinical corpora in Spanish : DisTEMIST, MedProcNER, and SympTEMIST. Our approach addresses the complexity of real-world data, where unseen mentions and concepts are frequent. The results show a notable improvement in lower top- k accuracies, surpassing the state-of-the-art by up to 5.5 percentage points for unseen mentions and by up to 5.9 points for unseen concepts. This improvement reduces the number of candidate concepts required for cross-encoders, enabling more efficient semi-automatic annotation and decreasing human effort. Additionally, our findings underscore the importance of leveraging not only the concept-level information in KBs but also the relationships between those concepts.},
  archive      = {J_KBS},
  author       = {Fernando Gallego and Pedro Ruas and Francisco M. Couto and Francisco J. Veredas},
  doi          = {10.1016/j.knosys.2025.113211},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113211},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing cross-encoders using knowledge graph hierarchy for medical entity linking in zero- and few-shot scenarios},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained local label correlation for multi-label classification. <em>KBS</em>, <em>314</em>, 113210. (<a href='https://doi.org/10.1016/j.knosys.2025.113210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comprehensive learning label correlation is conducive to boosting the accuracy of multi-label classification. While existing methods focus on exploring the correlation-aware original features or latent subspaces, they often overlook the role of correlation in deducing local structures. The oversight can result in suboptimal topic-based label correlation estimation and thus incur information loss. In contrast to the conventional single-granularity-based learning for local label correlation, we propose a multi-granularity correlation-based feature augmentation (MGOFA) model. MGOFA consists of three components that progressively refine the granularity of label correlation: granular-based feature augmentation for relative neighborhood-based class tendency estimation, granular-based latent topic mining for tendency-aware topic modeling, and fine-grained label correlation mining for augmented local label correlation learning. The information on neighborhood-based similarity between instances is explicitly leveraged and contributes to the model two-fold. Firstly, it induces the prototypes of latent topics, which share more knowledge with the label association. Secondly, it refines the discriminative granularity of the model by integrating it with the original features. Such a formulation simulates the viewpoint of human decision-making by automatically determining optimal solutions on both data and knowledge from coarse and refined granularity, respectively. Extensive comparisons completed of ten benchmarks demonstrate that MGOFA outperforms the state-of-the-art methods with satisfying convergence and sensitivity.},
  archive      = {J_KBS},
  author       = {Tianna Zhao and Yuanjian Zhang and Duoqian Miao and Witold Pedrycz},
  doi          = {10.1016/j.knosys.2025.113210},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113210},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained local label correlation for multi-label classification},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic domain adaptive ensemble for intelligent fault diagnosis of machinery. <em>KBS</em>, <em>314</em>, 113209. (<a href='https://doi.org/10.1016/j.knosys.2025.113209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-domain intelligent fault diagnosis (IFD) using unlabeled data has attracted more and more attention. However, most researchers focus on the improvement of single domain adaptive method (DAM). How to make full use of existing DAMs to improve the accuracy and generalization of the IFD model is a challenging problem. As a potential solution, a general dynamic domain adaptive ensemble (DDAE) framework is proposed. By introducing the optimal adaptation factor and combining with the proposed dynamic adaptive evaluating strategy, the DDAE can quantitatively evaluate the importance of different DAMs, and dynamically adjust the weight of DAMs during the training process. By this way, the ensemble strategy can be constructed adaptively within the model. We also design a feasible DDAE-based neural network model by integrating three different DAMs. Extensive experimental analysis indicates that the diagnostic performance of the model is superior to existing deep learning and transfer learning methods.},
  archive      = {J_KBS},
  author       = {Kui Hu and Qingbo He and Hao Xu and Changming Cheng and Zhike Peng},
  doi          = {10.1016/j.knosys.2025.113209},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113209},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic domain adaptive ensemble for intelligent fault diagnosis of machinery},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature reuse framework with texture-adaptive aggregation for reference-based super-resolution. <em>KBS</em>, <em>314</em>, 113201. (<a href='https://doi.org/10.1016/j.knosys.2025.113201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference-based super-resolution (RefSR), significant success has been achieved in the field of super-resolution. It reconstructs low-resolution (LR) inputs using high-resolution reference images, obtaining more high-frequency details and alleviating the ill-posed problem of single-image super-resolution (SISR). Previous research in the RefSR has mainly focused on finding correlations, transferring, and aggregating similar texture information from LR reference (Ref) the LR. However, an essential detail of perceptual loss and adversarial loss has been underestimated, impacting texture transfer and reconstruction negatively. In this paper, we propose a feature reuse framework, FRFSR, which divides the model training into two steps. Firstly, the first model is trained using reconstruction loss to enhance its texture transfer and aggregation abilities. Secondly, using all losses for training, the feature output of the first model is reintroduced into the training process to supplement texture, generating visually appealing images. The feature reuse framework is applicable to any RefSR model, and experiments show that several RefSR methods exhibit improved performance when retrained with our reuse framework. Considering that the textures in the reference are not entirely consistent with those in the LR, this naturally leads to the problem of texture misuse. Therefore, we design a Dynamic Residual Block (DRB). The DRB utilizes the feature perception capability of decoupled dynamic filters to dynamically aggregate texture information between LR input and Ref images, reducing instances of texture misuse. The source code can be obtained from https://github.com/Yi-Yang355/FRFSR .},
  archive      = {J_KBS},
  author       = {Xiaoyong Mei and Yi Yang and Ming Li and Changqin Huang and Kai Zhang and Fudan Zheng},
  doi          = {10.1016/j.knosys.2025.113201},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113201},
  shortjournal = {Knowl. Based Syst.},
  title        = {A feature reuse framework with texture-adaptive aggregation for reference-based super-resolution},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised spatial–temporal video grounding via spatial–temporal annotation on a single frame. <em>KBS</em>, <em>314</em>, 113200. (<a href='https://doi.org/10.1016/j.knosys.2025.113200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of weakly-supervised spatial–temporal video grounding, where model training only relies on video-sentence pairs, has garnered considerable attention. Its objective is to identify and localize spatial–temporal regions within a video that correspond to objects or events described in a query sentence. Existing approaches frame this task as a multiple instance learning (MIL) problem, where a bag is constructed for each frame and the same sentence is assigned to all frame bags. However, this approach can lead to false-positive frames as not all frames necessarily correspond to the query sentence. Additionally, region proposals in each frame are typically generated by pre-trained object detection models, which primarily focus on core regions and may result in inaccurate object or event localization. To address these issues, we propose annotating a spatial–temporal region in a single frame, which provides a simple yet effective means to enhance grounding performance without incurring significant additional cost. Specifically, we innovatively contribute a spatial–temporal MIL framework. In the temporal-level MIL, by applying Gaussian weighting to the frames of a video, we assign higher weights to the frames that are close to the annotated frame, while lower weights are assigned to frames that are further away. In the spatial-level MIL, we propose regions in the each frame and compute their similarity with the annotated bounding box, selecting regions with higher similarity scores for training. Ultimately, temporal-level and spatial-level MILs are integrated to jointly optimize the accuracy of both types of grounding. Through experimental evaluations on two re-annotated datasets, our proposed framework has been demonstrated to exhibit superiority in terms of both overall performance comparison and detailed micro-level analyses. Compared to the latest weakly-supervised methods on the VidSTG dataset, our method improves the temporal localization performance by at least 10.35% and the spatial localization performance by at least 11.89%.},
  archive      = {J_KBS},
  author       = {Shu Luo and Shijie Jiang and Da Cao and Huangxiao Deng and Jiawei Wang and Zheng Qin},
  doi          = {10.1016/j.knosys.2025.113200},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113200},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly-supervised spatial–temporal video grounding via spatial–temporal annotation on a single frame},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global–local prototype-based few-shot learning for cross-domain hyperspectral image classification. <em>KBS</em>, <em>314</em>, 113199. (<a href='https://doi.org/10.1016/j.knosys.2025.113199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because cross-domain information can help in tackling the small-sample-size challenge, cross-domain hyperspectral image (HSI) classification has become a hot issue in recent years. Few-shot learning (FSL) has been recognized as an effective solution for cross-domain HSI classification. In particular, the prototype-based FSL method, which aims to train a generalized feature metric space by performing feature matching between prototypes and query samples, is the most commonly used FSL method for cross-domain HSI classification. However, existing prototype-based FSL methods mainly use the global semantic information of the HSI pixel neighborhood to establish the prototype-based feature metric space. This ignores the local semantic information and fails to exploit the global–local semantic relationship of the HSI pixel neighborhood. To address this problem, a novel global–local prototype-based FSL (GLP-FSL) is proposed for cross-domain HSI classification in this study. First, we propose a multiview spatial–spectral feature extraction module to capture both global-view and local-view spatial–spectral features across domains. Second, we present a global–local spatial–spectral feature-matching module to better achieve prototype-based spatial–spectral feature matching by exploiting the global–local semantic relationship. Moreover, a spatial–spectral domain-adaptation strategy based on global–local knowledge distillation is designed for boosting the universal applicability of the feature metric space. Finally, the proposed GLP-FSL is evaluated on five public HSI datasets, and the extensive experimental results indicate that the proposed GLP-FSL considerably outperforms other state-of-the-art FSL methods.},
  archive      = {J_KBS},
  author       = {Haojin Tang and Yuelin Wu and Hongyi Li and Dong Tang and Xiaofei Yang and Weixin Xie},
  doi          = {10.1016/j.knosys.2025.113199},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113199},
  shortjournal = {Knowl. Based Syst.},
  title        = {Global–local prototype-based few-shot learning for cross-domain hyperspectral image classification},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting restaurant survival using nationwide google maps data. <em>KBS</em>, <em>314</em>, 113198. (<a href='https://doi.org/10.1016/j.knosys.2025.113198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restaurant sector is pivotal to firm exit research, which influences economic policy and managerial strategy recommendations. Recent studies using online data are based on geographically limited datasets and have largely omitted temporal dynamics in user interactions. Additionally, these studies rely on manual labeling for text analysis, a resource-intensive approach. Built upon the case of Poland, our study introduces the first comprehensive, nationwide analysis of restaurant survival using Google Maps data. We enhance predictive model performance by incorporating time-sensitive user interactions. Our model controls for established determinants of business exit and proves robust regarding data quality issues associated with user-provided business directories. We apply an efficient, label-free method for extracting semantic content from reviews, thereby creating useful features for firm exit prediction. Furthermore, we present an efficient feature selection strategy using hierarchical agglomerative clustering that retains predictive power while reducing the model complexity. Our model has broad applications ranging from credit scoring to early-warning systems for business closures, while our data collection method opens doors to large-scale firm exit studies in regions where official records are lacking and online sources used in previous studies are less prevalent.},
  archive      = {J_KBS},
  author       = {Tomasz Starakiewicz and Piotr Wójcik},
  doi          = {10.1016/j.knosys.2025.113198},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113198},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting restaurant survival using nationwide google maps data},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge assimilation: Implementing knowledge-guided agricultural large language model. <em>KBS</em>, <em>314</em>, 113197. (<a href='https://doi.org/10.1016/j.knosys.2025.113197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although supervised fine-tuning (SFT) and retrieval-augmented generation (RAG) can help large language models (LLMs) incorporate domain knowledge, they have the following limitations: (1) Data scarcity. There is a severe lack of high-quality data and knowledge bases on dialogue in agriculture. (2) Token-level oversight. Current SFT primarily focuses on fitting general tokens, neglecting agricultural-specific tokens. It leads to omissions of critical information in responses. (3) Sentence-level hurdle. Agricultural queries necessitate sentence-level evidence support from domain knowledge bases, which poses a challenge to precision evidence retrievers. This paper introduces a novel Knowledge-guided Agriculture LLM (KALLM) designed to facilitate multi-task decision-making in agricultural settings. We begin by addressing the data quality issue by establishing an annotation standard and constructing a comprehensive dataset consisting of 220,000 Q&A pairs derived from authoritative agricultural documents. At the token level, we propose a knowledge-coordinated SFT approach that enhances the representation of agriculture-specific tokens by amplifying their significance during the decoding process. At the sentence level, we introduce a self-reflective RAG mechanism based on topic matching to improve the accuracy of evidence retrieval. Experimental results compared with seven competitive open-domain LLMs and the current SFT-RAG pipeline show that our KALLM achieves state-of-the-art performance and is significantly superior to existing generation frameworks in terms of response fluency, accuracy, and domain fidelity.},
  archive      = {J_KBS},
  author       = {Jingchi Jiang and Lian Yan and Haifeng Liu and Zhenbo Xia and Haotian Wang and Yang Yang and Yi Guan},
  doi          = {10.1016/j.knosys.2025.113197},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113197},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge assimilation: Implementing knowledge-guided agricultural large language model},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera-aware embedding refinement for unsupervised person re-identification. <em>KBS</em>, <em>314</em>, 113195. (<a href='https://doi.org/10.1016/j.knosys.2025.113195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a data-centric approach, Camera-aware Embedding Refinement (CER), to enhance the discriminability of unsupervised person re-identification. CER consists of two components: camera proxy memory and Camera-aware Embedding Generation (CEG). Camera proxy memory is initialized with original embeddings and updated during training using auxiliary embeddings generated by CEG to ensure consistency within the memory. The auxiliary embeddings are created by CEG based on the intrinsic relationships within the original dataset, accounting for image variations caused by different camera perspectives. Specifically, CEG handles scenarios such as images of the same person captured by different cameras, images of different individuals captured by the same camera, and images of different individuals from different cameras. Training the downstream unsupervised Re-ID model with only the auxiliary embeddings significantly improves feature discriminability. Our method focuses on generating auxiliary embeddings and can be adapted for various unsupervised Re-ID models. Extensive experiments show that our approach consistently outperforms state-of-the-art techniques.},
  archive      = {J_KBS},
  author       = {Yimin Liu and Meibin Qi and Yongle Zhang and Wenbo Xu and Qiang Wu},
  doi          = {10.1016/j.knosys.2025.113195},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113195},
  shortjournal = {Knowl. Based Syst.},
  title        = {Camera-aware embedding refinement for unsupervised person re-identification},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiking neural network classification of X-ray chest images. <em>KBS</em>, <em>314</em>, 113194. (<a href='https://doi.org/10.1016/j.knosys.2025.113194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are powerful and biologically plausible models of neural processing and represent a transition to a new generation of neural networks, as they address the problem of high resource requirements by significantly reducing energy consumption. In this paper we investigate the use of SNNs for the diagnosis of COVID-19 cases from chest x-rays, by proposing a simple Spiking Neural Network (SNN) that proves to be effective despite the low resources requested with respect to other solutions proposed in the literature. The paper explains the architecture of the SNN and evaluates the performance of the model in terms of both result accuracy and energy consumption. Experimental results show competitive performance in terms of accuracy and a significant reduction in energy consumption.},
  archive      = {J_KBS},
  author       = {Marco Gatti and Jessica Amianto Barbato and Claudio Zandron},
  doi          = {10.1016/j.knosys.2025.113194},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113194},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spiking neural network classification of X-ray chest images},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-perspective empathy modeling for empathetic dialogue generation. <em>KBS</em>, <em>314</em>, 113191. (<a href='https://doi.org/10.1016/j.knosys.2025.113191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empathy is a complex psychological phenomenon involving three aspects: cognition, affection, and behavior. It is essential for personalized intelligent dialogue agents. Most existing methods do not comprehensively consider these three aspects when generating empathetic responses, affecting dialogue quality. To address this issue, we previously proposed an empathetic dialogue generation model named CAB, producing responses by considering the three aspects holistically. Now, we propose an improved version of CAB, named CAB ¯ , which enhances the cognition and behavior modules to further improve response quality. In terms of cognition, the model retrieves information from an external knowledge base, constructs a multi-hop reasoning graph, and encodes it using a graph convolutional network (GCN). Then, a relational network is used to generate path representations for each dialogue, establishing logical relationships between keywords to better capture the subtleties of context and enhance the understanding of semantics. To enhance the expression at the affection, the model uses dual latent variables to capture the emotional dependencies between the two interlocutors. Regarding behavior, the model extracts the embedding and high-dimensional feature representation of the dialogue act from the latent space and integrates these comprehensive features into the encoder, so that dialogue generation is guided by dialogue behavior. In the decoding phase, we introduce a knowledge-aware pointer network that probabilistically selects words from the dialogue history and knowledge entities to enhance the relevance and diversity of the response. Experiment results demonstrate that CAB ¯ achieves superior performance under both automatic and manual evaluations, generating more diverse and empathetic responses.},
  archive      = {J_KBS},
  author       = {Baiyou Qiao and Yuekai Zhang and Pan Gao and Xinchi Li and Shuo Wang and Donghong Han},
  doi          = {10.1016/j.knosys.2025.113191},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113191},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-perspective empathy modeling for empathetic dialogue generation},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced differential evolution through chaotic and euclidean models for solving flexible process planning. <em>KBS</em>, <em>314</em>, 113189. (<a href='https://doi.org/10.1016/j.knosys.2025.113189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Differential Evolution (DE) algorithm is a well-founded technique proposed in 1995. Its simple but effective structure has attracted attention over the years. Moreover, its design has allowed the publication of several variants that are positioned as competitive approaches. Nonetheless, most of these modifications focus on the mutation and crossover stages, while the initialization and selection phases have received less attention. However, in recent years, different studies have demonstrated the advantage of improving these two stages for certain optimization problems. Therefore, in this work, a new DE variant is proposed to solve the Flexible Process Planning (FPP) problem, one of the most relevant tasks in manufacturing optimization. In this work, the DE initialization is enhanced by a chaotic Opposition-Based-Learning (OBL) method. At the same time, the selection is improved by a dynamic model based on Euclidean distances. This work’s novelty lies in optimizing a real-world task with a DE variant focused exclusively on the initialization and selection operators. The efficiency of the method was also tested on the CEC-2017 functions. The outcomes probe its robustness and competitiveness for general optimization and manufacturing systems.},
  archive      = {J_KBS},
  author       = {Eduardo H. Haro and Diego Oliva and Luis A. Beltrán and Angel Casas-Ordaz},
  doi          = {10.1016/j.knosys.2025.113189},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113189},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced differential evolution through chaotic and euclidean models for solving flexible process planning},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-domain information guidance: Diffusion models for the inpainting of dunhuang murals. <em>KBS</em>, <em>314</em>, 113188. (<a href='https://doi.org/10.1016/j.knosys.2025.113188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital conservation of Dunhuang murals, inpainting plays a pivotal role in the reconstructing of complete murals. Focusing on the semantic difference between masked and unmasked regions and the irrationality of the semantics of masked regions in the digitization of Dunhuang frescoes for inpainting, we applied the diffusion probability model based on image denoising to the inpainting of Dunhuang murals through official collaboration. We proposed a new frequency-domain guided diffusion model for Dunhuang mural painting to reconstruct the traditional structure-guided image painting process. First, we designed a module that generates frequency-domain information to decompose the frescoes into high- and low-frequency components. Then, we restored them to obtain the corresponding high- and low-frequency images. These images can guide the diffusion inpainting process of damaged murals, effectively resolving the semantic differences between masked and unmasked regions and yielding semantically consistent and reasonable inpainting results. In addition, we proposed a bilateral contrastive learning strategy to ensure that the inpainted images are closer to the positive samples and farther away from the negative samples in the representation space, thereby optimizing the inpainting performance. The effectiveness of the proposed method was verified by conducting large-scale inpainting experiments on real Dunhuang murals and the Place2 standard dataset. The proposed method outperformed other methods in terms of the subjective and objective evaluation metrics. The proposed method effectively recovered the details and content information of the damaged murals and provided more advanced technical support for the digitization and conservation of Dunhuang murals.},
  archive      = {J_KBS},
  author       = {Yuan Ding and Kaijun Wu and Bin Tian},
  doi          = {10.1016/j.knosys.2025.113188},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113188},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-domain information guidance: Diffusion models for the inpainting of dunhuang murals},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully bayesian differential gaussian processes through stochastic differential equations. <em>KBS</em>, <em>314</em>, 113187. (<a href='https://doi.org/10.1016/j.knosys.2025.113187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Gaussian process models typically employ discrete hierarchies, but recent advancements in differential Gaussian processes (DiffGPs) have extended these models to infinite depths. However, existing DiffGP approaches often overlook the uncertainty in kernel hyperparameters by treating them as fixed and time-invariant, which degrades the model’s predictive performance and neglects the posterior distribution. In this work, we introduce a fully Bayesian framework that models kernel hyperparameters as random variables and utilizes coupled stochastic differential equations (SDEs) to jointly learn their posterior distributions alongside those of inducing points. By incorporating the estimation uncertainty of hyperparameters, our method significantly enhances model flexibility and adaptability to complex dynamic systems. Furthermore, we employ a black-box adaptive SDE solver with a neural network to achieve realistic, time-varying posterior approximations, thereby improving the expressiveness of the variational posterior. Comprehensive experimental evaluations demonstrate that our approach outperforms traditional methods in terms of flexibility, accuracy, and other key performance metrics. This work not only provides a robust Bayesian extension to DiffGP models but also validates its effectiveness in handling intricate dynamic behaviors, thereby advancing the applicability of Gaussian process models in diverse real-world scenarios.},
  archive      = {J_KBS},
  author       = {Jian Xu and Zhiqi Lin and Min Chen and Junmei Yang and Delu Zeng and John Paisley},
  doi          = {10.1016/j.knosys.2025.113187},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113187},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fully bayesian differential gaussian processes through stochastic differential equations},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User group-enhanced user feature distribution transfer framework for non-overlapping cross-domain recommendations. <em>KBS</em>, <em>314</em>, 113186. (<a href='https://doi.org/10.1016/j.knosys.2025.113186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation (CDR) aims to alleviate data sparsity in the target domain by leveraging rich information from source domains. Most existing approaches rely on overlapping information to transfer knowledge, but in real scenarios, these correspondences are often unknown. This makes it critical to develop CDR systems without overlapping information. However, such CDR systems still face user feature bias between domains and ignore the importance of sparse interaction information from the target domain, resulting in sub-optimal recommendations performance. To address challenges, we propose a U ser G roup-enhanced U ser F eature D istribution T ransfer framework (UGUFDT) for CDR. Specifically, it first utilizes a User Feature Separation Network bridges domains by constructing a cross-domain user–cluster graph to capture transferable user features, while User Feature Reconstructor refines unbiased user representations through reconstruction factors to build an inverse user–cluster graph, filter out source domain-specific noises. Then, we introduce three types of loss function – Difference Loss , Similarity Loss , Reconstruction Loss – to reduce feature distribution discrepancies between domains. Furthermore, to fully exploit interactions in target domain, we propose a User–Group Graph with a Soft Allocation Mechanism, which aggregates group-level preferences to enhance user representations. Finally, a Prediction Layer with a Fusion Mechanism integrates both cross-domain transferable knowledge and target-domain preferences to generate more accurate recommendations. Experiments on three publicly available datasets – ML, AB, and AM – demonstrate that the proposed model significantly outperforms state-of-the-art models on the HR and NDCG evaluation metrics, validating the effectiveness of our model.},
  archive      = {J_KBS},
  author       = {Xiaoying Gao and Ling Ding and Jianting Chen and Yunxiao Yang and Yang Xiang},
  doi          = {10.1016/j.knosys.2025.113186},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113186},
  shortjournal = {Knowl. Based Syst.},
  title        = {User group-enhanced user feature distribution transfer framework for non-overlapping cross-domain recommendations},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal discovery using dynamically requested knowledge. <em>KBS</em>, <em>314</em>, 113185. (<a href='https://doi.org/10.1016/j.knosys.2025.113185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal Bayesian Networks (CBNs) are an important tool for reasoning under uncertainty in complex real-world systems. Determining the graphical structure of a CBN remains a key challenge and is undertaken either by eliciting it from humans, using machine learning to learn it from data, or using a combination of these two approaches. In the latter case, human knowledge is generally provided to the algorithm before it starts, but here we investigate a novel approach where the structure learning algorithm itself dynamically identifies and requests knowledge for relationships that the algorithm identifies as “uncertain” during structure learning. We integrate this approach into the Tabu structure learning algorithm and show that it offers considerable gains in structural accuracy, which are generally larger than those offered by existing approaches for integrating knowledge. We suggest that a variant which requests only arc orientation information may be particularly useful where the practitioner has little preexisting knowledge of the causal relationships. As well as offering improved accuracy, the approach can use human expertise more effectively and contributes to making the structure learning process more transparent.},
  archive      = {J_KBS},
  author       = {Neville K. Kitson and Anthony C. Constantinou},
  doi          = {10.1016/j.knosys.2025.113185},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113185},
  shortjournal = {Knowl. Based Syst.},
  title        = {Causal discovery using dynamically requested knowledge},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DHR-BLS: A huber-type robust broad learning system with its distributed version. <em>KBS</em>, <em>314</em>, 113184. (<a href='https://doi.org/10.1016/j.knosys.2025.113184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The broad learning system (BLS) is a recently developed neural network framework recognized for its efficiency and effectiveness in handling high-dimensional data with a flat network architecture. However, traditional BLS models are highly sensitive to outliers and noisy data, which can significantly degrade performance. While incorporating the ℓ 1 -norm loss function enhances robustness against outliers, it often compromises performance on clean datasets. To address this limitation, we propose the Huber-type robust broad learning system (HR-BLS), which integrates the Huber loss function into BLS, effectively combining the strengths of both ℓ 1 -norm and ℓ 2 -norm loss functions to achieve balanced robustness against data anomalies. Moreover, the elastic-net regularization is included to simultaneously enhance model stability and promote sparsity. To effectively manage large-scale and distributed data, we extend HR-BLS by introducing the distributed Huber-type robust broad learning system (DHR-BLS). Given the non-differentiability of the ℓ 1 -norm, traditional gradient-based optimization methods are insufficient. Therefore, we adopt the alternating direction method of multipliers (ADMM) to train, ensuring convergence through the use of appropriate constraints. Experimental results on both synthetic and benchmark datasets show that HR-BLS outperforms traditional BLS and other state-of-the-art robust learning methods in terms of accuracy and robustness. Furthermore, DHR-BLS demonstrates exceptional scalability and effectiveness, making it suitable for distributed learning environments.},
  archive      = {J_KBS},
  author       = {Yuao Zhang and Shuya Ke and Jing Li and Weihua Liu and Jueliang Hu and Kaixiang Yang},
  doi          = {10.1016/j.knosys.2025.113184},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113184},
  shortjournal = {Knowl. Based Syst.},
  title        = {DHR-BLS: A huber-type robust broad learning system with its distributed version},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial classification and uncertainty estimation under subjective logic. <em>KBS</em>, <em>314</em>, 113183. (<a href='https://doi.org/10.1016/j.knosys.2025.113183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise classification algorithms suffer from misclassification when they encounter confusing samples, i.e., out-of-domain (OOD) and imprecise (IM) samples. Consequently, the ability to detect different kinds of confusing samples is a guarantee of models’ robustness. To the best of our knowledge, there are two main approaches. Some authors attempt to identify OOD samples through uncertainty estimation. Others assign IM samples to class subsets by performing partial classification. The existing methods focus on one of the approaches and overlook the improvement brought by integrating these two strategies into one method. In addition, in terms of partial classification, some existing methods try to enumerate all the prediction subsets, however, it is impossible when the dataset contains hundreds of classes. In an attempt to alleviate these challenges, based on subjective logic a novelty classification method called PCSL, which can perform partial classification and uncertainty estimation simultaneously is proposed. For uncertainty estimation, a scalar value is quantified to represent the predictive uncertainty. With regard to partial classification, beliefs (i.e., confidence scores) are assigned to potential prediction subsets to aid further decision-making. Experiments demonstrate the excellent performance of the PCSL method as compared to the existing methods. It can be concluded that the PCSL method makes it possible to improve models’ robustness by either rejecting confusing samples or assigning confusing samples to prediction subsets.},
  archive      = {J_KBS},
  author       = {Jiarui Xie and Violaine Antoine and Thierry Chateau},
  doi          = {10.1016/j.knosys.2025.113183},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113183},
  shortjournal = {Knowl. Based Syst.},
  title        = {Partial classification and uncertainty estimation under subjective logic},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building robust deep recommender systems: Utilizing a weighted adversarial noise propagation framework with robust fine-tuning modules. <em>KBS</em>, <em>314</em>, 113181. (<a href='https://doi.org/10.1016/j.knosys.2025.113181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of deep recommendation algorithms decreases significantly under adversarial attacks. While some approaches improve the recommender system robustness via adversarial training, they primarily target shallow models or rely on coarse-grained noise, so that deep models remain vulnerable. This study proposes a new adversarial training framework, the Random Adversarial Weight Perturbation Framework Equipped with Robust Fine-Tuning (RAWP-FT). Specifically, RAWP-FT first performs adversarial training of deep models by introducing more fine-grained adversarial noise into the hidden layer weight parameters. Subsequently, RAWP-FT identifies and targets the modules or layers with the lowest robustness after adversarial training and performs specialized adversarial training and fine-tuning to improve the model robustness further. Experiments demonstrate that RAWP-FT significantly enhances the robustness of deep recommendation models. We apply RAWP-FT to MLP and other deep models, highlighting its ability to strengthen vulnerable components through robust critical fine-tuning. Experiments on four publicly available datasets confirm that RAWP-FT-trained models can withstand adversarial noise while maintaining performance.},
  archive      = {J_KBS},
  author       = {Fulan Qian and Wenbin Chen and Hai Chen and Jinggang Liu and Shu Zhao and Yanping Zhang},
  doi          = {10.1016/j.knosys.2025.113181},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113181},
  shortjournal = {Knowl. Based Syst.},
  title        = {Building robust deep recommender systems: Utilizing a weighted adversarial noise propagation framework with robust fine-tuning modules},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCN-RLR-CAN: A novel human-computer negotiation model based on round-level recurrence and causal attention networks. <em>KBS</em>, <em>314</em>, 113180. (<a href='https://doi.org/10.1016/j.knosys.2025.113180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Human-Computer Negotiation (HCN) systems have shown promising progress in simulating complex negotiation dialogues. However, these systems still need to grapple with critical challenges such as limited adaptability to proper negotiation tones, ineffective capture of long-term dependencies, and constraints in generating diverse, natural, and strategically sound responses. To address these limitations, we propose the HCN-RLR-CAN, a novel HCN model based on Round-Level Recurrence (RLR) and Causal Attention Network (CAN). Our approach, which uniquely processes dialogues as role-based parallel texts and employs a hierarchical encoder to comprehend user dialogue history, offers a fresh perspective on addressing these challenges. The model employs causal attention learning modules to separately model linguistic strategies and dialogue acts. Additionally, it employs a round-level recursive decoding mechanism that generates responses by synthesising historical dialogue information, dialogue act and strategy encodings, and previous decoding states. With its significant performance advantages over baseline models, the HCN-RLR-CAN model has the potential to inspire a new wave of research and development in the field of HCN systems.},
  archive      = {J_KBS},
  author       = {Jianting Zhang and Xudong Luo and Xiaojun Xie},
  doi          = {10.1016/j.knosys.2025.113180},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113180},
  shortjournal = {Knowl. Based Syst.},
  title        = {HCN-RLR-CAN: A novel human-computer negotiation model based on round-level recurrence and causal attention networks},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate triple table: A general architecture for virtual knowledge graphs. <em>KBS</em>, <em>314</em>, 113179. (<a href='https://doi.org/10.1016/j.knosys.2025.113179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual knowledge graphs (VKGs) have been widely applied to access relational data with a semantic layer by using an ontology in use cases that are dynamic in nature. However, current VKG techniques focus mainly on accessing a single relational database and remain largely unstudied for data integration with several heterogeneous data sources. To overcome this limitation, we propose intermediate triple table ( ITT ), a general VKG architecture to access multiple and diverse data sources. Our proposal is based on data shipping and addresses heterogeneity by adopting a schema-oblivious graph representation that intervenes between the sources and the queries. We minimize data computation by just materializing a relevant subgraph for a specific query. We employ star-shaped query processing and extend this technique to mapping candidate selection. For rapid materialization of the ITT , we apply a mapping partitioning technique to parallelize mapping execution, which also guarantees duplicate-free subgraphs and reduces memory consumption. We use SPARQL-to-SQL query translation to homogeneously evaluate queries over the ITT and execute them with an in-process analytical store. We implemented ITT on top of a knowledge graph materialization engine and evaluated it with two VKG benchmarks. The experimental results show that our proposal outperforms state-of-the-art techniques for complex graph queries in terms of execution time. It also decreases the number of timeouts although it uses more memory as a trade-off. The experiments also demonstrate the source independence of the architecture on a mixed distribution of data with SQL and document stores together with various file formats.},
  archive      = {J_KBS},
  author       = {Julián Arenas-Guerrero and Oscar Corcho and María S. Pérez},
  doi          = {10.1016/j.knosys.2025.113179},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113179},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intermediate triple table: A general architecture for virtual knowledge graphs},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced BiGAN architecture for network intrusion detection. <em>KBS</em>, <em>314</em>, 113178. (<a href='https://doi.org/10.1016/j.knosys.2025.113178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems face significant challenges in handling high-dimensional, large-scale, and imbalanced network traffic data. This paper proposes a new architecture combining a denoising autoencoder (AE) and a Wasserstein Generative Adversarial Network (WGAN) to address these challenges. The AE-WGAN model extracts high-representative features and generates realistic synthetic attacks, effectively resolving data imbalance and enhancing anomaly-based intrusion detection. Our extensive experiments on NSL-KDD and CICIDS-2017 datasets demonstrate superior performance, achieving 98% accuracy and 99% F1-score in binary classification, surpassing recent approaches by 7%–15%. In multiclass cases, the model achieves 89% precision for DoS attacks and 84% for Probe attacks, while maintaining 79% precision for rare U2R attacks. Time complexity analysis reveals 23% reduced training time while maintaining high-quality synthetic attack generation, contributing a robust framework capable of handling modern network traffic complexities and evolving cyber threats.},
  archive      = {J_KBS},
  author       = {Mohammad Arafah and Iain Phillips and Asma Adnane and Mohammad Alauthman and Nauman Aslam},
  doi          = {10.1016/j.knosys.2025.113178},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113178},
  shortjournal = {Knowl. Based Syst.},
  title        = {An enhanced BiGAN architecture for network intrusion detection},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAM-LAD: Segment anything model meets zero-shot logic anomaly detection. <em>KBS</em>, <em>314</em>, 113176. (<a href='https://doi.org/10.1016/j.knosys.2025.113176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual anomaly detection is vital in real-world applications, such as industrial defect detection and medical diagnosis. However, most existing methods focus on local structural anomalies and fail to detect higher-level functional anomalies under logical conditions. Although recent studies have explored logical anomaly detection, they can only address simple anomalies like missing or addition and show poor generalizability due to being heavily data-driven. To fill this gap, we propose SAM-LAD, a zero-shot, plug-and-play framework for anomaly detection in any scene. First, we obtain a query image’s feature map using a pre-trained backbone. Simultaneously, we retrieve the reference images and their corresponding feature maps via the nearest neighbor search. Then, we introduce the Segment Anything Model (SAM) to obtain object masks of the query and reference images. Each object mask is multiplied by the entire image’s feature map to obtain object feature maps. Next, an Object Matching Model (OMM) is proposed to match objects in the query and reference images. To facilitate object matching, we propose a Dynamic Channel Graph Attention (DCGA) module, treating each object as a keypoint and converting its feature maps into feature vectors. Finally, based on the object matching relations, an Anomaly Measurement Model (AMM) is proposed to detect objects with logical anomalies. Structural anomalies in the objects can also be detected. We validate our proposed SAM-LAD using various benchmarks, including industrial datasets (MVTec Loco AD, MVTec AD), and the logical dataset (DigitAnatomy). Extensive experimental results demonstrate that SAM-LAD outperforms existing SoTA methods, particularly in detecting logical anomalies.},
  archive      = {J_KBS},
  author       = {Yun Peng and Xiao Lin and Nachuan Ma and Jiayuan Du and Chuangwei Liu and Chengju Liu and Qijun Chen},
  doi          = {10.1016/j.knosys.2025.113176},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113176},
  shortjournal = {Knowl. Based Syst.},
  title        = {SAM-LAD: Segment anything model meets zero-shot logic anomaly detection},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale spectral augmentation for graph contrastive learning for fMRI analysis to diagnose psychiatric disease. <em>KBS</em>, <em>314</em>, 113175. (<a href='https://doi.org/10.1016/j.knosys.2025.113175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and incompleteness of cognitive tests, as well as subjective biases in humans, using functional magnetic resonance imaging (fMRI) data for accurate diagnosis of psychiatric disease is a challenging task. In addition, existing contrastive methods are also limited by graph augmentation and negative sampling methods in population-based classification. In order to improve the representation learning and classification of fMRI under limited labeled data, we propose a new contrastive self-supervised learning method based on spectral augmentation, namely Multiscale Spectral Augmentation for Graph Contrastive Learning (MSA-GCL) for fMRI Analysis. Concretely, we adopt a two-stage spectral augmentation method by initialization and fine-tuning to mine features of multimodal data. This approach effectively addresses the limitations faced by models that solely rely on coarse-grained spectral augmentation, which leads to weak robustness and limited generalization on medical datasets. Besides, we add a semantic module to fully utilize non-imaging data. Our method is tested on ABIDE I and ADHD-200 datasets, demonstrating superior performance in diagnosis of autism spectrum disorders(ASD) and attention deficit and hyperactivity disorder(ADHD).},
  archive      = {J_KBS},
  author       = {Chang Hu and Yihong Dong and Shoubo Peng},
  doi          = {10.1016/j.knosys.2025.113175},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113175},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiscale spectral augmentation for graph contrastive learning for fMRI analysis to diagnose psychiatric disease},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised multi-label cardiovascular diseases detection via contrastive learning and label inference. <em>KBS</em>, <em>314</em>, 113173. (<a href='https://doi.org/10.1016/j.knosys.2025.113173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse amount of labeled Electrocardiogram (ECG) data can reduce the performance of deep neural networks (DNNs) in detecting cardiovascular diseases (CVDs). Existing semi-supervised learning methods have reduced the dependence of DNN on labeled data. However, CVDs are often concurrent, and ECG features have individual differences. It is crucial to obtain the CVDs relationships and learn invariant CVDs representations. This paper proposes a semi-supervised learning framework based on contrastive learning and label inference (SemiCLLI) for multi-label CVDs classification with sparse labeled ECG data. To make pseudo labels reflect the CVDs relationships, based on global correlation and local similarity of CVDs distribution, the pseudo labels are generated by pseudo label inference module using asymmetric co-occurrence probabilities and neighbor weight controlled predictions. Meanwhile, this paper builds an adaptive dual threshold module by prediction-based dual threshold update strategy, which provides positive and negative confidence thresholds for each category to filters out unlabeled data with reliable pseudo labels. To learn the invariant representations of CVDs, we propose a pseudo-labeling based multi-label contrastive learning task to maximize the consistency of the representations between samples with the common category based on pseudo labels similarity and entropy-based representations similarity. We conduct various groups experiments on four ECG benchmark datasets to validate the performance of SemiCLLI. The experimental results show that SemiCLLI performs better than the state-of-the-art methods in multi-label CVDs classification with sparse labeled ECG data.},
  archive      = {J_KBS},
  author       = {Ning Wang and Haiyan Wang and Panpan Feng and Shihua Li and Jian Tan and Zongmin Wang and Bing Zhou},
  doi          = {10.1016/j.knosys.2025.113173},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113173},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised multi-label cardiovascular diseases detection via contrastive learning and label inference},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent collaborative operation planning via cross-domain transfer learning. <em>KBS</em>, <em>314</em>, 113172. (<a href='https://doi.org/10.1016/j.knosys.2025.113172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has shown promising potentials in assisting multi-agent systems (MAS) to deal with complex collaborative tasks. In this work, we investigate MAS collaboration in 3D underwater environment. In response to the problem of high sampling cost in underwater operation when multi-agent without any prior knowledge, the multi-agent collaborative operation planning via cross-domain transfer learning (CDTL) is proposed. In CDTL, the training process of MAS is accelerated through learning the domain invariant knowledge from the samples of 2D ground collaborative tasks that easily obtained. First, the samples in ground tasks are divided into six state phases based on the semantic order of task execution, and a state transition graph is constructed accordingly. Then, a domain adaptation method with inter-class relationship (ICDA) is proposed, which focuses on the invariant semantic structure of the ground (source) and the underwater (target) task to capture prior knowledge. During the knowledge transferring, ICDA is used to correct decision of the agents’ policies that based on MAX-Q controller. Finally, the extensive experiments show that CDTL reduces the cost of physical time by 37.3% when the MAS completes the new task for the first time.},
  archive      = {J_KBS},
  author       = {Cheng Ding and Zhi Zheng},
  doi          = {10.1016/j.knosys.2025.113172},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113172},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-agent collaborative operation planning via cross-domain transfer learning},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AUDAN: An adversarial unsupervised domain adaptation network informed decision-making in audit risk assessment. <em>KBS</em>, <em>314</em>, 113171. (<a href='https://doi.org/10.1016/j.knosys.2025.113171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops an adversarial unsupervised domain adaptation network (AUDAN) for audit risk assessment from a data-driven perspective, which can offer a novel solution for the audit issue data distribution shift problem in audits. The proposed AUDAN consists of three neural network–based modules: the feature extractor, the domain classifier, and the risk-level classifier. A joint adversarial learning scheme based on these three modules is developed to enable learning discriminative and domain-invariant feature representations from audit issue data. In developing the AUDAN, the data is reorganized into source and target domains. A simple yet effective model selection technique, called latest held-out source risk validation , is proposed for the time-variant domain shift , where the data distribution of one period is closer to the data distribution of the adjacent period. The superiority of the latest held-out source risk validation technique has been theoretically justified. Computational experiments based on a real-world dataset were performed to verify the advantages and effectiveness of the AUDAN. The results showed that the AUDAN achieves superior testing performance in most cases. Additionally, the AUDAN yields robust classification results and outperforms the benchmarking models, including the train-on-target model, which is trained with the label information of target domain data revealed and can be regarded as a strong competitor. Ablation studies further showed the superiority of the developed latest held-out source risk validation method.},
  archive      = {J_KBS},
  author       = {Ziquan OU and Zijun ZHANG},
  doi          = {10.1016/j.knosys.2025.113171},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113171},
  shortjournal = {Knowl. Based Syst.},
  title        = {AUDAN: An adversarial unsupervised domain adaptation network informed decision-making in audit risk assessment},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated opposition learning based chaotic single candidate optimization algorithm: A new alternative to population-based heuristics. <em>KBS</em>, <em>314</em>, 113169. (<a href='https://doi.org/10.1016/j.knosys.2025.113169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the Single Candidate Optimizer (SCO) as an alternative to population-based heuristics, that is faster than them. Although the SCO algorithm is a fast single-candidate-based heuristic, it has certain limitations. To overcome these limitations and enhance the search performance of SCO, several solutions were proposed in this study. First, owing to the single-candidate nature of the SCO, the initial solution position can play a critical role. To compensate for this, an accelerated opposition-learning mechanism was integrated into the SCO. In addition, instead of the equation that is active when the number of unsuccessful improvement attempts is reached in the SCO structure, a mutation operator including chaotic functions (Levy, Gauss, and Cauchy) has been incorporated into the algorithm. Again, equations based on new approaches were added to the SCO algorithm to update the position of the candidate solution during the exploration and exploitation phases. Finally, the standard boundary value control mechanism is replaced with a more effective one. The algorithm developed in this study is named Accelerated Opposition Learning based Chaotic Single Candidate Optimizer (AccOppCSCO), inspired by the accelerated opposition learning mechanism and the mutation operator involving chaotic behaviors. The search capability of the proposed AccOppCSCO algorithm was first analyzed using four different methods: convergence, search history, trajectory, and computational complexity. The effectiveness of the mechanisms used in the AccOppCSCO algorithm for four different two-dimensional benchmark problems from the IEEE Congress on Evolutionary Computation 2014 (CEC2014) package was demonstrated. Subsequently, the performance of the proposed AccOppCSCO algorithm was evaluated on the CEC2014 and IEEE Congress on Evolutionary Computation 2020 (CEC2020) benchmark problems with different dimensions. The results show that the AccOppCSCO algorithm works effectively in the CEC2014 and CEC2020 test sets and offers better optimization results than SCO. The AccOppCSCO algorithm ranked first in the overall evaluation of the 30-dimensional CEC2014 comparison results with State of the Art (SOTA) heuristics from the literature. Finally, for ten different engineering design problems, the AccOppCSCO algorithm was analyzed and compared with the original SCO and other SOTA heuristics. The results show that AccOppCSCO is effective for engineering design problems. This emphasizes that the algorithm can work effectively on a wide range of problems and can be used in various applications. The source code of the AccOppCSCO algorithm for the CEC2014 benchmark suite is publicly available at https://github.com/uguryuzgec/AccOppCSCO .},
  archive      = {J_KBS},
  author       = {Ugur Yuzgec},
  doi          = {10.1016/j.knosys.2025.113169},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113169},
  shortjournal = {Knowl. Based Syst.},
  title        = {Accelerated opposition learning based chaotic single candidate optimization algorithm: A new alternative to population-based heuristics},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating backdoor attacks in federated learning based intrusion detection systems through neuron synaptic weight adjustment. <em>KBS</em>, <em>314</em>, 113167. (<a href='https://doi.org/10.1016/j.knosys.2025.113167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning has emerged as a transformative paradigm that enables collaborative model training across distributed clients while preserving data privacy. However, Federated Learning systems are vulnerable to backdoor attacks, where malicious clients introduce harmful triggers into the global model, undermining its security and reliability. Traditional defenses often struggle to balance robust protection with maintaining high model accuracy, leaving Federated Learning systems exposed to significant risks. In this article, we present SHIELD-FL (Synaptic Harmonization for Intelligent and Enhanced Learning Defense), a novel framework designed to provide comprehensive backdoor defense in federated learning environments. At the core of SHIELD-FL is SYNAPSE (Synaptic Neuron Adjustment for Protective System Enhancement), an innovative metric that leverages L2 norm analysis to detect and identify neurons influenced by backdoor triggers. This targeted approach enables precise adjustment and pruning of compromised neurons, effectively neutralizing backdoor threats while preserving overall model performance. SHIELD-FL further enhances protection through a coordinated, system-wide strategy implemented across all clients, ensuring robust defense against backdoor attacks throughout the federated learning network. We rigorously evaluated SHIELD-FL on multiple datasets, demonstrating its effectiveness. The results consistently show that proposed model outperforms state-of-the-art defenses, achieving superior accuracy and resilience against backdoor attacks. Our approach provides a unified and effective solution for securing the federated learning based intrusion detection systems against emerging threats, marking a significant advancement in the field of security.},
  archive      = {J_KBS},
  author       = {Umer Zukaib and Xiaohui Cui},
  doi          = {10.1016/j.knosys.2025.113167},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113167},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mitigating backdoor attacks in federated learning based intrusion detection systems through neuron synaptic weight adjustment},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised adverse weather-degraded image restoration via contrastive learning. <em>KBS</em>, <em>314</em>, 113162. (<a href='https://doi.org/10.1016/j.knosys.2025.113162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating the impact of adverse weather on images, such as rain, haze, snow and raindrops, poses a critical challenge in numerous computer vision tasks, particularly in outdoor scenarios like port security and traffic surveillance. Recent successful methods for restoring images affected by severe weather have predominantly embraced supervised learning, which heavily depend on the quality of collected image pairs. However, capturing ideal image pairs for adverse weather image restoration in real-world scenarios is nearly impossible. In practice, unpaired images are more commonly available. The absence of proper supervision among unpaired images can result in low-quality image restoration outcomes. Therefore, utilizing unpaired image data for adverse weather image restoration remains a significant challenge. In this paper, we propose an effective method for Unsupervised Adverse weather-degraded Image Restoration (UAIR). Our approach leverages contrastive learning to explore both the similarities and differences in deep feature space among images. We not only utilize the intrinsic similarities between restored image and original degraded image to guide the content of the restored image, but also take advantage of the categoricaly differences within unpaired image data, thereby strengthening the connections between the restored image and the clean image at category level. Extensive experiments conducted on benchmark datasets for various tasks, including image snow removal, combined image rain and haze removal and image raindrop removal demonstrate that our proposed method achieves state-of-the-art performance on both weather-specific and all-in-one weather image restoration.},
  archive      = {J_KBS},
  author       = {Xinxi Xie and Quan Liu and Jun Yang and Hao Zhang and Zijun Zhou and Chuanjie Zhang and Junwei Yan},
  doi          = {10.1016/j.knosys.2025.113162},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113162},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unsupervised adverse weather-degraded image restoration via contrastive learning},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distortion information and edge features guided network for real-world image restoration. <em>KBS</em>, <em>314</em>, 113159. (<a href='https://doi.org/10.1016/j.knosys.2025.113159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration methods for specific single distortion have exhibited impressive performance. In real scenarios, distortions are hybrid and variable, and these methods are no longer effective. Recently, some methods for hybrid distortion have been explored. However, their performance drops sharply when the distortion type changes. In addition, the images restored by these methods lack edge details. To solve these issues, we try to learn the distortion information and edge features of the image and use them to guide the reconstruction of the image. Based on this, we propose a Distortion Information and Edge Features Guided Network (DIEFGN). We define a distortion vector to represent the distortion information of the image and use neural networks to estimate it. Since the edges of the image are anisotropic and the 3 × 3 convolution is isotropic, we propose multi-direction linear depthwise convolution (MLDC) to better extract edge features. During image reconstruction, we propose a multi-level progressive fusion strategy to fuse edge features into original image features to enhance the edge details of the restored image. Additionally, distortion vectors are used to modulate the fused image features at all levels, enabling the network to adapt to the variable hybrid distortion. Experiments indicate that the proposed DIEFGN achieves state-of-the-art performance when dealing with real-world images with different distortion types and distortion levels.},
  archive      = {J_KBS},
  author       = {Yuhang Wang and Hai Li and Shujuan Hou and Zhetao Dong and Ruixue Gao},
  doi          = {10.1016/j.knosys.2025.113159},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113159},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distortion information and edge features guided network for real-world image restoration},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilateral decoupling complementarity learning network for camouflaged object detection. <em>KBS</em>, <em>314</em>, 113158. (<a href='https://doi.org/10.1016/j.knosys.2025.113158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing camouflaged object detection methods have made impressive achievements, however, the interference from highly similar backgrounds, as well as the indistinguishable object boundary, still hider the detection accuracy. In this paper, we propose a three-stage bilateral decoupling complementarity learning network (BDCL-Net) to explore how to utilize the specific advantages of multi-level encoded features for achieving high-quality inference. Specifically, all side-output features are decoupled into two branches to generate three complementary features. Different from previous methods that focus on obtaining the camouflaged object and body boundary, our body modeling stage, which includes a global positioning flow (GPF) module and a multi-scale body warping (MBW) module, is deployed to obtain a global contextual feature that provides coarse localization of potential camouflaged objects and a body feature that emphasizes learning the central areas of camouflaged objects. The detail preservation stage is designed to generate a detail feature that pays attention to the regions around the boundary. Consequently, the body prediction can avoid disturbances from the highly similar backgrounds, while the detail prediction can reduce errors caused by imbalanced boundary pixels. The complementary feature integration (CFI) module in the feature aggregation stage is designed to fuse these complementary features in an interactive learning manner. We conduct extensive experiments on four public datasets to demonstrate the effectiveness and superiority of our proposed network. The code is available at http://github.com/iuueong/BDCLNet .},
  archive      = {J_KBS},
  author       = {Rui Zhao and Yuetong Li and Qing Zhang and Xinyi Zhao},
  doi          = {10.1016/j.knosys.2025.113158},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113158},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bilateral decoupling complementarity learning network for camouflaged object detection},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FreeNet: An efficient frequency-domain early exiting network for dynamic inference. <em>KBS</em>, <em>314</em>, 113155. (<a href='https://doi.org/10.1016/j.knosys.2025.113155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early exiting has become an effective method for improving inference efficiency. Most early exiting models place early classifiers in shallow layers, forcing reliance on low-level features and limiting performance. Moreover, these models typically use the spatial representation of the image (RGB image) as input, reducing spatial redundancy only by lowering the resolution. Compared to spatial representation, frequency domain representation provides richer multilevel information, enabling more efficient early exiting mechanisms. To this end, this paper proposes a dynamic fr equency-domain e arly e xiting net work (FreeNet). Our model employs wavelet transform to decompose images into multiple levels of frequency information, with distinct frequency sub-models dedicated to feature extraction at each level. Each classifier is positioned at the end of its frequency sub-model, ensuring it can leverage high-level features with semantic information. Our model performs inference sequentially from low frequency to high frequency. For easy samples, it uses only a small amount of low-frequency information, while for hard samples, it dynamically supplements high-frequency information to ensure reliable results. Extensive experiments applying our method to various baseline models show that our model achieves a better balance between performance and computational cost. For instance, on the ImageNet-1k dataset, our method can reduce 58% FLOPs of ResNet50 by only a 0.3% accuracy loss.},
  archive      = {J_KBS},
  author       = {Yicheng Yan and Xianfeng Li and Kai Cui and Haoran Sun and Zifeng Yu},
  doi          = {10.1016/j.knosys.2025.113155},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113155},
  shortjournal = {Knowl. Based Syst.},
  title        = {FreeNet: An efficient frequency-domain early exiting network for dynamic inference},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing slogan classification in ubiquitous learning environment: A hierarchical multilabel approach with fuzzy neural networks. <em>KBS</em>, <em>314</em>, 113148. (<a href='https://doi.org/10.1016/j.knosys.2025.113148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent social-media analytics research has explored the complex domain of slogans and product or service endorsements, which present classification challenges in marketing, owing to their adaptability across different contexts. Existing research emphasizes flat-text classification, neglecting the nuanced hierarchical structure of English at the document and sentence levels. To overcome this gap, this study introduces a robust slogan identification and classification (RoICS) model within a ubiquitous-learning framework. It uses a new dataset that includes 6,909 ProText and 1,645 propaganda-text corpora (PTC) samples, encompassing both slogan and non-slogan labels. This model investigates the complex hierarchical multilabel structure of slogans using a granular computing–based deep-learning model and fine-grained structures. The proposed RoICS model achieved an accuracy of 84%, outperforming state-of-the-art models. We validated the utility of our contributions through a series of quantitative and qualitative experiments across various openness scenarios (25%, 50%, and 75%) using the ProText and PTC datasets. These findings not only refine our understanding of slogan detection, but also hold significant implications for information-systems researchers and practitioners, offering a potent tool for sentence-level ubiquitous-learning data analysis.},
  archive      = {J_KBS},
  author       = {Pir Noman Ahmad and Adnan Muhammad Shah and KangYoon Lee and Rizwan Ali Naqvi and Wazir Muhammad},
  doi          = {10.1016/j.knosys.2025.113148},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113148},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing slogan classification in ubiquitous learning environment: A hierarchical multilabel approach with fuzzy neural networks},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TVC former: A transformer-based long-term multivariate time series forecasting method using time-variable coupling correlation graph. <em>KBS</em>, <em>314</em>, 113147. (<a href='https://doi.org/10.1016/j.knosys.2025.113147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term multivariate time series forecasting is crucial in various domains that require the effective modeling of intervariable dependencies in series data. However, existing methods tend to capture these dependencies directly across the entire series, thus neglecting the local dynamic characteristics of the intervariable correlation patterns caused by locality differences and the dynamic variability of the series. To address this, we propose TVC Former, a forecasting model that uses a time-variable coupling correlation graph (TVC graph). The TVC graph treats local window-level subsequences as nodes and explicitly models local intervariable dependence. Its structure is dynamically and adaptively generated to effectively represent task-specific valuable intervariable local correlation patterns while eliminating irrelevant ones. Specifically, a sparsified graph structure is initialized based on the correlation between the input historical series and statistical similarity between the subsequences. It is then optimized using a pattern capture-fusion sparsification unit with learnable parameters. In addition, we propose a time-variable joint-encoding framework with a transformer encoder as the backbone. By introducing local head markers and a graph neural network, the framework effectively captures the intervariable dependencies using the TVC graph. Experiments on seven real-world datasets demonstrate the superiority of TVC Former in long-term forecasting tasks.},
  archive      = {J_KBS},
  author       = {Zhenyu Liu and Yuan Feng and Hui Liu and Ruining Tang and Bo Yang and Donghao Zhang and Weiqiang Jia and Jianrong Tan},
  doi          = {10.1016/j.knosys.2025.113147},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113147},
  shortjournal = {Knowl. Based Syst.},
  title        = {TVC former: A transformer-based long-term multivariate time series forecasting method using time-variable coupling correlation graph},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliding window-aided recursive efficient kernel decomposition for KPI-oriented fault detection of complex industrial processes. <em>KBS</em>, <em>314</em>, 113140. (<a href='https://doi.org/10.1016/j.knosys.2025.113140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sliding window techniques are widely used for precise real-time fault detection. However, their adoption increases the computational load, prompting integration with recursive methods to improve efficiency. Currently, sliding window fault detection predominantly targets key performance indicator (KPI)-oriented faults in linear systems, with limited exploration of nonlinear systems. Moreover, the nonlinear KPI-oriented fault detection method using kernel direct decomposition (KDD) requires substantial computation. It lacks a seamless framework for recursive calculations when integrating the sliding window technology. Motivated by the above background, this study investigates an efficient nonlinear KPI-oriented fault detection method that integrates sliding window technology for online monitoring. To this end, an efficient kernel decomposition (EKD) method is studied, which has a higher computational efficiency than the KDD method and provides an ideal framework to establish the recursion form. Based on this, the sliding window technology and the modified rank-one factorization method are utilized to optimize the proposed EKD method, and a recursive EKD is presented to solve the computational complexity problem due to the sliding window. Detailed scrutiny is devoted to analyzing the selection process for unknown parameters within the introduced methodologies. Finally, three case studies are presented to demonstrate the fault detection performance of the proposed methods.},
  archive      = {J_KBS},
  author       = {Hao Ma and Yan Wang and Xiang Liu and Jie Yuan and Yihong Zhou},
  doi          = {10.1016/j.knosys.2025.113140},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113140},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sliding window-aided recursive efficient kernel decomposition for KPI-oriented fault detection of complex industrial processes},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPCA: Dynamic multi-prototype cross-attention for change detection unsupervised domain adaptation of remote sensing images. <em>KBS</em>, <em>314</em>, 113135. (<a href='https://doi.org/10.1016/j.knosys.2025.113135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) is a key technique for enhancing the generalization and reusability of remote sensing image change detection (CD) models. However, the effectiveness of UDA is often hindered by discrepancies in feature distributions and sample imbalances across disparate CD datasets. To address these issues, we propose the Dynamic Multi-Prototype Cross-Attention model for UDA in CD. This approach enhances the representation of complex land cover features by incorporating multi-prototype features into a cross-attention mechanism, while addressing sample imbalance through a novel pseudo-sample generation strategy. The Multi-prototypes and Difference Feature Cross-Attention Module iteratively updates the multi-prototype features and integrates them with a classical two-stream CD model. This allows the model to achieve domain alignment by minimizing the neighborhood distance between the global multi-prototype features and high-confidence target domain prototype features. In addition, we propose the Sample Fusion and Pasting module, that generates new target domain-style samples of changed regions to facilitate CD-UDA training. Experimental evaluations on the LEVIR, GZ, WH, and GD datasets confirm that DPCA model effectively bridges the feature distribution gap between the source and target domains, significantly improving the detection performance on the unlabeled target domain. The source code is available at https://github.com/Fanrongbo/DPCA-CD-UDA .},
  archive      = {J_KBS},
  author       = {Rongbo Fan and Jialin Xie and Junmin Liu and Yan Zhang and Hong Hou and Jianhua Yang},
  doi          = {10.1016/j.knosys.2025.113135},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113135},
  shortjournal = {Knowl. Based Syst.},
  title        = {DPCA: Dynamic multi-prototype cross-attention for change detection unsupervised domain adaptation of remote sensing images},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFTFormer: A spatial-frequency noise aware CNN-transformer for low light image enhancement. <em>KBS</em>, <em>314</em>, 113055. (<a href='https://doi.org/10.1016/j.knosys.2025.113055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions are often accompanied by reduced visibility, noise, and color distortion. However, when using the CNN-Transformer hybrid model for low-light image enhancement, input noise randomly infiltrates the global features, disrupting the representation of critical features in the original input. To tackle this, we propose FFTFormer, a f ast f ourier t ransform embedded noise-aware CNN-Trans former , which removes noise in both the spatial and frequency domains. Specifically, FFTFormer adopts a U-shaped network architecture, comprising a transformer-based encoder with an integrated self-attention mechanism (CA_Swin), a FFT-embedded fusion module (FFTF), and a CNN-based decoder. FFTFormer first uses CA_Swin to differentiate feature importance, initially filtering out coarse-grained noise in the spatial domain. Then, it employs FFTF to refine the image features into multi-scale frequency domains, further distinguishing persistent noise mixed within the features. Finally, a locally spatial-sensitive CNN decoder progressively reconstructs the image’s details and brightness. Extensive experiments are conducted to validate the proposed method. Particularly, FFTFormer achieves improvements of 0.0216 in SSIM and 2.1219 in PSNR on the MIT-Adobe FiveK dataset. Compared with the baseline method LLFormer, FFTFormer improves SSIM and PSNR by 0.0255 and 0.6960 on the LOL dataset, and 0.0216 and 3.2897 on the MIT-Adobe FiveK dataset.},
  archive      = {J_KBS},
  author       = {Xiao Pei and Yongdong Huang and Weijian Su and Fengjuan Zhu and Qiang Liu},
  doi          = {10.1016/j.knosys.2025.113055},
  journal      = {Knowledge-Based Systems},
  month        = {4},
  pages        = {113055},
  shortjournal = {Knowl. Based Syst.},
  title        = {FFTFormer: A spatial-frequency noise aware CNN-transformer for low light image enhancement},
  volume       = {314},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic branch layer fusion: A new continual learning method for rotating machinery fault diagnosis. <em>KBS</em>, <em>313</em>, 113177. (<a href='https://doi.org/10.1016/j.knosys.2025.113177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world environments, the critical components of rotating machinery often encounter various new fault types because of complex operating conditions. The replay-based continual learning method in fault diagnosis mitigates catastrophic forgetting associated with the introduction of previous fault samples. However, the retention of previous samples during the training of new tasks creates an imbalance in the distribution of dataset and limits the mitigation of catastrophic forgetting. A new continual learning method based on dynamic branch layer fusion is proposed and applied to the diagnosis scenarios with imbalanced dataset. In particular, the proposed method builds a branch layer for each old task to retain the old knowledge upon the arrival of a new task, then the branch layers fusion structure is designed to solve the problem of model growth. Additionally, a two-stage training process encompassing model adaptation and fusion is proposed. On this basis, integration loss is used to optimize the learning of models for all types across tasks. Finally, the assembly of the old and new models is achieved through distillation loss, enhancing the reliability of models on all tasks. Experimental results indicate that the catastrophic forgetting problem prevalent in imbalanced dataset can be effectively alleviated by the proposed method.},
  archive      = {J_KBS},
  author       = {Changqing Shen and Zhenzhong He and Bojian Chen and Weiguo Huang and Lin Li and Dong Wang},
  doi          = {10.1016/j.knosys.2025.113177},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113177},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic branch layer fusion: A new continual learning method for rotating machinery fault diagnosis},
  volume       = {313},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient algorithm for fast discovery of high-efficiency patterns. <em>KBS</em>, <em>313</em>, 113157. (<a href='https://doi.org/10.1016/j.knosys.2025.113157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-efficiency pattern mining (HEPM) problem has recently emerged as a variant of the high-utility pattern mining problem, aiming to identify patterns with the highest profit-to-investment ratio by considering both their utilities and investments. However, due to its vast search space, the HEPM problem is inherently difficult and complex to solve. Existing HEPM algorithms suffer from inefficiencies in runtime and memory usage due to inadequate search space pruning. This study introduces a new algorithm named EHEPM to address this issue more effectively. EHEPM introduces four new upper-bound models to enhance search space pruning and presents two data structures for the accurate and efficient calculation of pattern efficiency and upper-bound values. Experimental results conducted on various datasets demonstrate that EHEPM outperforms existing algorithms in terms of runtime, memory consumption, number of join operations, and scalability.},
  archive      = {J_KBS},
  author       = {Irfan Yildirim},
  doi          = {10.1016/j.knosys.2025.113157},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113157},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient algorithm for fast discovery of high-efficiency patterns},
  volume       = {313},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatically resolving conflicts between expert systems: An experimental approach using large language models and fuzzy cognitive maps from participatory modeling studies. <em>KBS</em>, <em>313</em>, 113151. (<a href='https://doi.org/10.1016/j.knosys.2025.113151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mental model is an individual’s internal representation of knowledge that enables reasoning in a given domain. Cognitive dissonance arises in a mental model when there is internal conflict, causing discomfort, which individuals seek to minimize by resolving the dissonance. Modelers frequently use fuzzy cognitive maps (FCMs) to represent mental models and perspectives on a system and facilitate reasoning. Dissonance may arise in FCMs when two individuals with conflicting mental models interact (e.g., in a hybrid agent-based model with FCMs representing individuals’ mental models). We define cognitive dissonance for FCMs and develop an algorithm to automatically resolve it by leveraging large language models (LLMs). We apply our algorithm to our real-world case studies and find our approach can successfully resolve the dissonance, suggesting LLMs can broadly resolve conflict within expert systems. Additionally, our method may identify opportunities for knowledge editing of LLMs when the dissonance cannot be satisfactorily resolved through our algorithm.},
  archive      = {J_KBS},
  author       = {Ryan Schuerkamp and Hannah Ahlstrom and Philippe J. Giabbanelli},
  doi          = {10.1016/j.knosys.2025.113151},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113151},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automatically resolving conflicts between expert systems: An experimental approach using large language models and fuzzy cognitive maps from participatory modeling studies},
  volume       = {313},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHRN: A multi-perspective hierarchical relation network for knowledge graph embedding. <em>KBS</em>, <em>313</em>, 113040. (<a href='https://doi.org/10.1016/j.knosys.2025.113040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) aims to improve entity and relation representations, enhancing the accuracy of link prediction tasks. Recently, deep neural networks have been widely adopted for KGE. However, existing methods mainly focus on improving feature interactions through permutation and reshaping embeddings from a translational perspective, often overlooking the rotational interactions between entities and relations. Furthermore, these models tend to treat all relations in the knowledge graph uniformly, neglecting their heterogeneous characteristics. A novel KGE model with a multi-perspective hierarchical relation network (MHRN) is proposed to mitigate the two problems. Specifically, it generates multi-perspective rotation embeddings by leveraging a group equivariant convolutional layer that incorporates both translation and rotation transformations. This approach captures rotational interactions and significantly enhances the expressiveness of the neural network, all without adding extra parameters. Additionally, the hierarchical relation component employs relation-oriented convolutional filters to preserve the diverse characteristics of different relations. The hierarchical mechanism further extends the receptive field, integrating global information while retaining detailed local features during the aggregation process. Experimental results demonstrate that MHRN excels in capturing rotational interactions and preserving relational characteristics. It delivers outstanding performance on seven benchmark datasets, surpassing baseline methods in 2 out of 4 indicators on FB15k-237, and in all 4 indicators on both FB15k and YAGO3–10 datasets.},
  archive      = {J_KBS},
  author       = {Zengcan Xue and Zhaoli Zhang and Hai Liu and Zhifei Li and Shuyun Han and Erqi Zhang},
  doi          = {10.1016/j.knosys.2025.113040},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113040},
  shortjournal = {Knowl. Based Syst.},
  title        = {MHRN: A multi-perspective hierarchical relation network for knowledge graph embedding},
  volume       = {313},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KMDSAN: A novel method for cross-domain and unsupervised bearing fault diagnosis. <em>KBS</em>, <em>312</em>, 113170. (<a href='https://doi.org/10.1016/j.knosys.2025.113170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain bearing fault diagnosis is a serious challenge due to the unlabeled dataset. Deep subdomain adaptation network assisted by K-means clustering algorithm (KMDSAN), a diagnosis method based on non-adversarial network and alignment of subdomain, is proposed in this paper. Taking deep subdomain adaptation network (DSAN) as basic framework is the main difference between KMDSAN and most existing methods, because DSAN emphasizes the subdomain alignment rather than global alignment. Additionally, the K-means clustering algorithm is utilized to optimize the local maximum mean discrepancy to improve the performance of DSAN. Finally, a deep network with an improved attention mechanism is designed for the feature extraction of original bearing vibration signal. In comparison to other methods, KMDSAN is concise yet highly effective, and results from two datasets related to bearing demonstrate that the proposed method achieves excellent diagnosis accuracy.},
  archive      = {J_KBS},
  author       = {Shuping Wu and Peiming Shi and Xuefang Xu and Xu Yang and Ruixiong Li and Zijian Qiao},
  doi          = {10.1016/j.knosys.2025.113170},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113170},
  shortjournal = {Knowl. Based Syst.},
  title        = {KMDSAN: A novel method for cross-domain and unsupervised bearing fault diagnosis},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection using binary horse herd optimization algorithm with lightGBA ensemble classification in microarray data. <em>KBS</em>, <em>312</em>, 113168. (<a href='https://doi.org/10.1016/j.knosys.2025.113168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis presents significant challenges due to its high dimensionality, imbalanced distribution, and complexity. Traditional feature selection methods often fall short of addressing these challenges effectively. In response, this research proposes a novel hybrid methodology that integrates multi-filtering techniques with the Multi-Objective Binary Horse Herd Optimization (MOBHHO) algorithm to tackle gene selection and ensemble classification in microarray data. The study begins by identifying the limitations of existing methods, emphasizing the need for a comprehensive approach that combines the strengths of multi-filtering and metaheuristic optimization. Leveraging various filtering methods, including Information Gain, entropy, Pearson correlation, mutual information, mean absolute deviation, and weighted entropy variance, the proposed methodology aims to mitigate biases and enhance the robustness of feature selection. Subsequently, the MOBHHO wrapper method facilitates multi-objective optimization, optimizing objectives by minimizing selected features and maximizing prediction criteria. Finally, the ensemble prediction model LightGBA capitalizes on the diverse solutions obtained from MOBHHO, striking an optimal balance between feature count and prediction accuracy. The proposed method was evaluated on multiple high-dimensional microarray datasets such as Small Round Blue Cell Tumors (SRBCT), Prostate tumors, Lung cancer, Leukemia, Colon tumor and diffuse large B-cell lymphoma (DLBCL), Lymphoma, ALL-AML-4C, ALL-AML-3C, and MLL datasets are used to assess its effectiveness in feature selection and classification accuracy. The experimental outcomes demonstrate the efficacy of the proposed methodology, showcasing improved prediction accuracy and feature subset selection across diverse datasets.},
  archive      = {J_KBS},
  author       = {R.S. Preyanka Lakshme and S. Ganesh Kumar},
  doi          = {10.1016/j.knosys.2025.113168},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113168},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature selection using binary horse herd optimization algorithm with lightGBA ensemble classification in microarray data},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchically trusted evidential fusion method with consistency learning for multimodal language understanding. <em>KBS</em>, <em>312</em>, 113164. (<a href='https://doi.org/10.1016/j.knosys.2025.113164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans generally prefer to express certain emotions or intentions through verbal and nonverbal language depending on different contexts. The correlations among different language modalities dynamically vary for different humans. However, previous studies usually assume that the importance of different modalities is equal for each person when expressing their intents or emotions. This study presents a hierarchically-trusted evidential fusion (HTEF) method for multimodal language understanding, leveraging the uncertainty estimation of multimodal learning models to improve language comprehension. Specifically, a generalized feature-wise multimodal alignment module (GFMA) is developed to measure the coherence among multiple modalities and generate hierarchical views for multimodal input. By uncertainty estimation, the generated multiple views are transformed into opinions with different reliabilities, which are then aggregated by a trusted evidential fusion strategy to reduce the overall uncertainty of multimodal learning models. A consistency learning strategy is designed to address the conflict among different opinions. Experiments were conducted on the dataset MIntRec and MELD datasets collected from real-world environments. Results validate the effectiveness of the proposed method in terms of classification performance and robustness.},
  archive      = {J_KBS},
  author       = {Ying Yang and Yan-Qiu Yang and Gang Ren and Ben-Gong Yu},
  doi          = {10.1016/j.knosys.2025.113164},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113164},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchically trusted evidential fusion method with consistency learning for multimodal language understanding},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SHKD: A framework for traffic prediction based on sub-hypergraph and knowledge distillation. <em>KBS</em>, <em>312</em>, 113163. (<a href='https://doi.org/10.1016/j.knosys.2025.113163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a critical function of Intelligent Transportation Systems. Inspired by Graph/HyperGraph Neural Networks theory, researchers have proposed a series of effective methods for traffic prediction that have been proved as significant successes. Most methods construct an unchanging graph or hypergraph based on a fixed traffic network topology during prediction. These methods treat all traffic data (flow, speed, occupancy) equally, ignoring the different inherent attributes of traffic data. Other methods construct dynamic graph or hypergraph based on traffic data but ignore the topological structure of the road network itself. These methods will decrease the accuracy of prediction results. In this paper, we propose an innovative framework for traffic data prediction based on Sub-Hypergraph and Knowledge Distillation (SHKD), which effectively extracts traffic data features and combines them with road network topology. Specifically, we first cluster traffic data based on the inherent attributes and construct hypergraphs for data with similar attributes to represent their relationships, referred to as sub-hypergraphs. Then a teacher network is built from these sub-hypergraphs to extract the data features in traffic, while a student network is constructed based on the geographical connectivity among roads to extract global topological features. To integrate the two types of features, we apply a knowledge distillation method to transfer the data features learned by the teacher network into the training process of the student network, yielding the final prediction results. The proposed method has been assessed with several real-world datasets in predicting traffic status. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_KBS},
  author       = {Xiangyu Yao and Xinglin Piao and Qitan Shao and Yongli Hu and Baocai Yin and Yong Zhang},
  doi          = {10.1016/j.knosys.2025.113163},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113163},
  shortjournal = {Knowl. Based Syst.},
  title        = {SHKD: A framework for traffic prediction based on sub-hypergraph and knowledge distillation},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate erasable pattern discovery and analytics on stream data. <em>KBS</em>, <em>312</em>, 113161. (<a href='https://doi.org/10.1016/j.knosys.2025.113161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Erasable pattern mining, which finds patterns that can be removed by having a low gain value, minimizes losses by finding products that have less profit to overcome financial crises occurring in industrial fields such as manufacturing factories. When using data in the real world, there are errors of various sizes in the data, such as measurement errors, communication errors, or noise. The results from these environments are not accurate and the defects in the pattern extracted in this way may cause long-lasting effects and significant losses in the industrial field. Accordingly, we propose a mining strategy that extracts reliable and robust erasable patterns in any environment. Our proposed algorithm applies the concept of approximate factor to consider an error range of data and the number of transactions. It also extracts erasable patterns quickly and efficiently by considering characteristics of data streams generated and accumulated in real time. In this paper, approximate erasable pattern mining is performed from the data stream to extract reliable erasable patterns even in an environment where errors may occur. The performance evaluations are conducted using four real datasets that have various characteristics and two synthetic dataset groups. The results of the evaluations demonstrate our approach is faster the maximum four times over regarding runtime and generally efficient regarding memory usage.},
  archive      = {J_KBS},
  author       = {Seungwan Park and Hyunsoo Kim and Hanju Kim and Myungha Cho and Doyoung Kim and Doyoon Kim and Unil Yun},
  doi          = {10.1016/j.knosys.2025.113161},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113161},
  shortjournal = {Knowl. Based Syst.},
  title        = {Approximate erasable pattern discovery and analytics on stream data},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EBAO: An intrusion detection framework for wireless sensor networks using an enhanced binary aquila optimizer. <em>KBS</em>, <em>312</em>, 113156. (<a href='https://doi.org/10.1016/j.knosys.2025.113156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, Wireless Sensor Networks (WSNs) lack built-in algorithms to identify and react to intrusions and threats, necessitating the establishment of Intrusion Detection Systems (IDSs). In practice, it is difficult to design an IDS in WSNs due to the large scale, mobility, and limited memory of the sensors in WSNs. Feature Selection (FS) responds to these challenges by reducing data dimensionality and improving IDS accuracy, thereby enhancing intrusion detection classification by selecting the most expressive features in intrusion detection datasets. This paper presents a new intrusion detection framework called the Enhanced Binary Aquila Optimizer (EBAO) model. EBAO aims to efficiently improve the feature space to enhance detection accuracy while minimizing computational complexity in IDSs. EBAO integrates four improvements in the original Aquila Optimizer (AO) to address the FS problem. First, it uses a hybrid initialization approach that combines the Lévy flight generation function and the random uniform generation function to generate suitable solutions for the FS problem. Second, it employs the β-hill climbing algorithm as a local search method to enable the AO method to search efficiently in the FS solution space. Third, it employs the mutation equations of the Harris Hawks optimization method in the optimization process of AO based on a probabilistic function to explore the FS solution space. Lastly, it models the FS solution space in AO using two categories of binarization techniques (S-shaped and V-shaped). The performance of EBOA was evaluated using ten WSN datasets and eight transfer functions and then compared with eight metaheuristic-based IDSs and six machine learning algorithms. The Wilcoxon pair signed rank and Friedman tests were used to determine the statistical differences and rankings of the evaluated algorithms based on classification accuracy and fitness value. The experimental and statistical analysis strongly indicated that EBAO demonstrates superior effectiveness compared to the eight popular optimization wrapper algorithms for all ten datasets, which highlights its robustness and reliability. EBAO is https://github.com/drnooraldeen/EBOA.git},
  archive      = {J_KBS},
  author       = {Noor Aldeen Alawad and Bilal H. Abed-alguni and Ala Mohammad Shakhatreh},
  doi          = {10.1016/j.knosys.2025.113156},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113156},
  shortjournal = {Knowl. Based Syst.},
  title        = {EBAO: An intrusion detection framework for wireless sensor networks using an enhanced binary aquila optimizer},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoreNet: Leveraging context-aware representations via MLP networks for CTR prediction. <em>KBS</em>, <em>312</em>, 113154. (<a href='https://doi.org/10.1016/j.knosys.2025.113154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction is pivotal for industrial recommendation systems and has been driving intensive research. Recent studies emphasized the effectiveness of adaptive methods that use context-aware representations to enhance predictions by dynamically adjusting feature representations across instances and overcoming fixed embedding limitations. The typical architecture for learning context-aware representations involves a network block built on Multi-Head Self-Attention (MHA) or Multi-Layer Perceptron (MLP). Despite promising results, three main challenges arise from these methods. First, relying on a single network block limits the learning potential of the model by providing only one perspective on the interactions. Second, implementing the MHA mechanism requires multiple attention layers for its effectiveness, thereby increasing the complexity of the model. Third, using only a vanilla MLP makes it difficult to combine implicit and explicit feature interactions, which is crucial for successful CTR solutions. To address these issues, we propose a novel model called Co ntext-Awa re Net ( CoreNet ). CoreNet incorporates an advanced module, Context-Aware Module ( CAM ), which employs a combination of MLP and Hadamard products to generate comprehensive context-aware representations. The CAM component integrates a two-stream network with first-order and second-order aware streams, extracting insights from different perspectives to complement each other and enhance overall performance. Extensive experiments on four public datasets consistently demonstrate that CoreNet outperforms other state-of-the-art models. Notably, our CAM component is lightweight and model-agnostic, facilitating seamless integration into streaming CTR models to enhance performance in a plug-and-play manner 1 .},
  archive      = {J_KBS},
  author       = {Khoi N.P. Dang and Thu Thuy Tran and Ta Cong Son and Tran Tien Anh and Duc Anh Nguyen and Nguyen Van Son},
  doi          = {10.1016/j.knosys.2025.113154},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113154},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoreNet: Leveraging context-aware representations via MLP networks for CTR prediction},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task dual-level adversarial transfer learning boosted RUL estimation of CNC milling tools. <em>KBS</em>, <em>312</em>, 113152. (<a href='https://doi.org/10.1016/j.knosys.2025.113152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively estimating the remaining useful life (RUL) of milling tools is crucial for intelligent preventive maintenance of CNC milling systems. In this paper, a novel generalized RUL estimation model based on multi-task dual-level adversarial transfer learning with multi-level attention (MTDTL-MA) is proposed for tool RUL prediction with variable working conditions. A multi-task learning structure with multi-level attention is used to predict the wear of each tool face in parallel and capture the max wear of entire tools as a health index for more accurate RUL estimation. Multi-channel encoder-decoder self-attention, multi-gate attention and global-local adversarial transferable attention are integrated to emphasize useful wear-related features, tool face-specific features and transferable features between source and target domains, respectively. A new auxiliary subdomain adversarial domain adaptation and global-local adversarial transferable attention is proposed to form a dual-level adversarial domain adaptation to synergistically improve transfer learning. Both the PHM2010 and Ideahouse dataset (2021) are employed to verify the effectiveness of MTDTL-MA, and the results indicate that the proposed method provides higher RUL prediction accuracy compared to several state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Pei Wang and Jinrui Liu and Jingshuai Qi and Kesong Zhou and Hongbo Zhai},
  doi          = {10.1016/j.knosys.2025.113152},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113152},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-task dual-level adversarial transfer learning boosted RUL estimation of CNC milling tools},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale representation learning for heterogeneous networks via hawkes point processes. <em>KBS</em>, <em>312</em>, 113150. (<a href='https://doi.org/10.1016/j.knosys.2025.113150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of dynamic heterogeneous network representation learning, current research methods have certain limitations. These limitations are mainly observed in the manual design of meta-paths, the handling of node attribute sparsity, and the fusion of dynamic heterogeneous information. To overcome these challenges, this paper presents a multi-scale representation learning method for heterogeneous networks via Hawkes point processes called MSRL. MSRL models the self-excitation effect among historical events by integrating the Hawkes process and captures the facilitating effect of external structures on event occurrence through a ternary closure process. This study employs the integration of time series analysis with neighbourhood interaction information to automate the extraction of the node pair representation. The MSRL model treats edges as time-stamped events, which not only captures the temporal dependencies between events, but also addresses the imbalance between different node types and the challenge of information fusion from a multi-granularity perspective. In particular, the model enhances the accurate estimation of the probability of node pairs forming edges by analysing the interactions between node pairs and their neighbours, which significantly improves the accuracy of tasks such as prediction. To validate the effectiveness of the MSRL model, an extensive experimental evaluation is conducted in this paper. The experimental results show that the MSRL model outperforms existing baseline models on several benchmark datasets, demonstrating its significant advantages and potential applications in the field of dynamic heterogeneous network representation learning.},
  archive      = {J_KBS},
  author       = {Qi Li and Fan Wang},
  doi          = {10.1016/j.knosys.2025.113150},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113150},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-scale representation learning for heterogeneous networks via hawkes point processes},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM knowledge-driven target prototype learning for few-shot segmentation. <em>KBS</em>, <em>312</em>, 113149. (<a href='https://doi.org/10.1016/j.knosys.2025.113149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Segmentation (FSS) aims to segment new class objects in a query image with few support images. The prototype-based FSS methods first model a target prototype and then match it with the query feature for segmentation. Recent research has focused on mining visual features to model the prototype. However, modeling the target prototype using visual features alone is not sufficient to represent target objects due to appearance differences between targets in support and query images. To address this limitation, based on the generalizable knowledge implied in the Large Language Model (LLM), we propose an LLM Knowledge-Driven Target Prototype Learning method (KD-TPL) to learn a robust prototype for the target object in the query image. Specifically, a knowledge-driven semantic prior generator is constructed to mine semantic priors in the query image applied to LLM knowledge. Based on the modeled semantic priors, a knowledge-driven hybrid prototype learner is designed to learn a representative target prototype. A knowledge-driven query feature enhancer is developed to enhance the semantics of the query feature. Finally, competitive comparison and ablation experimental results on COCO- 2 0 i and PASCAL- 5 i demonstrate the effectiveness of our method.},
  archive      = {J_KBS},
  author       = {Pengfang Li and Fang Liu and Licheng Jiao and Shuo Li and Xu Liu and Puhua Chen and Lingling Li and Zehua Hao},
  doi          = {10.1016/j.knosys.2025.113149},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113149},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM knowledge-driven target prototype learning for few-shot segmentation},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified single-objective genetic algorithm for solving the rural postman problem with load-dependent costs. <em>KBS</em>, <em>312</em>, 113146. (<a href='https://doi.org/10.1016/j.knosys.2025.113146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the rural postman problem with load-dependent costs, a variant of the arc routing problem where the traversal cost of an edge depends on its length and the vehicle’s load. The objective is to find a minimum-cost tour that services all required edges, a problem of particular importance when the demand weight is significant compared to the vehicle’s curb weight. We present an integer linear programming model for the problem and propose a heuristic algorithm based on bio-inspired methodologies to efficiently obtain near-optimal solutions within short computing times. The effectiveness of the approach is demonstrated through computational experiments on benchmark instances, and the results highlight the practicality of the proposed methods.},
  archive      = {J_KBS},
  author       = {David De Santis and Mercedes Landete and Xavier Cabezas and José María Sanchis and Juanjo Peiró},
  doi          = {10.1016/j.knosys.2025.113146},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113146},
  shortjournal = {Knowl. Based Syst.},
  title        = {A modified single-objective genetic algorithm for solving the rural postman problem with load-dependent costs},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based approach with two-step minority classes prediction for intrusion detection in internet of things networks. <em>KBS</em>, <em>312</em>, 113143. (<a href='https://doi.org/10.1016/j.knosys.2025.113143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of Internet of Things (IoT) technology has significantly enhanced several aspects of our modern life, from smart homes and cities to healthcare and industry. However, the distributed nature of IoT devices and the highly dynamic functioning of their environments introduce additional security challenges compared to conventional networks. Moreover, the datasets used to construct intrusion detection systems (IDS) are intrinsically imbalanced. Existing balancing techniques can address this issue with partially imbalanced datasets. However, their efficiency is limited when dealing with highly imbalanced datasets. As a result, the IDS delivers a humble performance that dissatisfies the IoT-based systems requirements. Therefore, novel approaches must be investigated to address this issue. In this paper, we propose a deep learning-based approach with two-step minority classes prediction to enhance intrusion detection in IoT networks. As our main model, we employ a one-dimensional convolutional neural network (1-D CNN), which predicts network traffic with a single output for the minority classes. Additionally, another 1-D CNN is trained on these minorities, but it only performs a second prediction if the first model classifies the output as the minority group. Furthermore, we utilize the class weight technique to achieve more balance in the models’ learning. We evaluated the proposed approach on the UNSW-NB15 and BoT-IoT datasets, two well-known benchmarks in building IDS for IoT networks. Compared to state-of-the-art methods, our approach revealed superior performance, achieving 80.65% and 99.99% accuracy in the multi-classification, respectively.},
  archive      = {J_KBS},
  author       = {Salah Eddine Maoudj and Aissam Belghiat},
  doi          = {10.1016/j.knosys.2025.113143},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113143},
  shortjournal = {Knowl. Based Syst.},
  title        = {A deep learning-based approach with two-step minority classes prediction for intrusion detection in internet of things networks},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OCPNet: A deep learning model for online cloud load prediction. <em>KBS</em>, <em>312</em>, 113142. (<a href='https://doi.org/10.1016/j.knosys.2025.113142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of cloud platform load contributes to the optimal allocation of cloud platform resources, and is an important means to solve resource scheduling problems and effectively manage cloud resources. However, most previous studies on cloud load prediction are based on offline settings, lacking scalability in realistic scenarios where data streams constantly arrive. Online real-time prediction of cloud loads can improve prediction efficiency, realizing fast response and dynamic adjustment to sudden loads, effectively minimizing resource wastage and enhancing system robustness. Therefore, we propose a deep learning—based online cloud load prediction network, OCPNet. It employs a forward architecture of learning module stacking, which progressively expands the receptive field of the convolutional kernel inside the learning module by exponentially growing the dilation factor to acquire short- and long-term features. Additionally, an online learning mechanism incorporating memory capabilities is proposed, which utilizes a fast learner to complete the learning of data streams, and a Pearson trigger to initiate the dynamic interaction between the memorizer and fast learner, thereby reducing the concept drift’s impact. Moreover, we propose a feature extractor that enriches the data features of variables by accomplishing the extraction of variable relationships using the flip and multi-attention mechanisms. In experiments on Huawei Cloud and Microsoft Cloud workload datasets, OCPNet is compared with current mainstream deep learning models for cloud workload prediction. Results indicate that OCPNet’s online multivariate and univariate prediction mean square error decreases by 25.5% and 35.5%, respectively, compared with the best deep learning baseline models.},
  archive      = {J_KBS},
  author       = {Zhengkai Wang and Hui Liu and Ertong Shang and Quan Wang and Junzhao Du},
  doi          = {10.1016/j.knosys.2025.113142},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113142},
  shortjournal = {Knowl. Based Syst.},
  title        = {OCPNet: A deep learning model for online cloud load prediction},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demystifying deep credit models in e-commerce lending: An explainable approach to consumer creditworthiness. <em>KBS</em>, <em>312</em>, 113141. (<a href='https://doi.org/10.1016/j.knosys.2025.113141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ‘Buy Now, Pay Later’ service has revolutionized consumer credit, particularly in e-commerce, by offering flexible options and competitive rates. However, assessing credit risk remains challenging due to limited personal information. Given the availability of consumer online activities, including shopping and credit behaviors, and the necessity for model explanation in high-stakes applications such as credit risk management, we propose an intrinsic explainable model, GLEN (GRU-based Linear Explainable Network), to predict consumers’ credit risk. GLEN leverages the sequential behavior processing capabilities of GRU, along with the transparency of linear regression, to predict credit risk and provide explanations simultaneously. Empirically validated on a real-world e-commerce dataset and a public dataset, GLEN demonstrates a good balance between competitive predictive performance and interpretability, highlighting critical factors for credit risk forecasting. Our findings suggest that past credit status is crucial for credit risk forecasting, and the number of borrowings and repayments is more influential than the amount borrowed or repaid. Additionally, browsing frequency and purchase frequency are also important factors. These insights can provide valuable guidance for platforms to predict credit risk more accurately.},
  archive      = {J_KBS},
  author       = {Chaoqun Wang and Yijun Li and Siyi Wang and Qi Wu},
  doi          = {10.1016/j.knosys.2025.113141},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113141},
  shortjournal = {Knowl. Based Syst.},
  title        = {Demystifying deep credit models in e-commerce lending: An explainable approach to consumer creditworthiness},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overlapping community-based malicious user detection scheme in social networks. <em>KBS</em>, <em>312</em>, 113139. (<a href='https://doi.org/10.1016/j.knosys.2025.113139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently social networks have become an important platform for social interaction and information dissemination. However, the existence of malicious social users poses a huge security threat to social networks and their information, especially it is very difficult to detect these malicious social users in overlapping communities. In this paper, we propose a malicious user detection scheme for overlapping communities-based social networks. In our scheme, we first construct a new overlapping community detection method, which is used to determine the community core and node label update order based on node influence and node relationship strength. Then we propose a malicious user detection method for overlapping communities, which is based on the changes of node attribute and node trust. In our detection method, the change trends of community attribute and message propagation influence of a node in different overlapping communities are used to determine whether the node is malicious with its specific community. Further, related experimental results show our malicious user detection scheme is effective to detect malicious users in overlapping communities.},
  archive      = {J_KBS},
  author       = {Ke Gu and Deng Yang and Wenwu Zhao and Xiong Li},
  doi          = {10.1016/j.knosys.2025.113139},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113139},
  shortjournal = {Knowl. Based Syst.},
  title        = {Overlapping community-based malicious user detection scheme in social networks},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-tolerant universal representation learning for multivariate time series from global-to-local perspective. <em>KBS</em>, <em>312</em>, 113137. (<a href='https://doi.org/10.1016/j.knosys.2025.113137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning for multivariate time series (MTS) has shown great potential in various analysis tasks. However, most existing representation models are designed for a certain task, such as forecasting and classification, which may cause poor generality and incomplete feature extraction. Moreover, these models are often sensitive to noise, which also affects the performance. To address these issues, an unsupervised, noise-tolerant universal representation learning model, namely TSG2L, is proposed for multivariate time series from a global-to-local perspective. Inspired by the idea of “drawing the outline before filling in the details”, TSG2L adopts a global-to-local learning way instead of the traditional local-to-global way. Technically, TSG2L divides the representation learning process into two sequential stages: global feature learning (drawing outline) and local feature learning (filling detail). In the first stage , a noise-tolerant multi-scale global reconstruction network is designed to perform variable-independent global feature learning. In the second stage , a noise-tolerant “1+M” prediction network is developed to integrate global features and perform variable-related local feature learning. To the best of our knowledge, this is the first work to explore MTS representation learning from a global-to-local perspective. Extensive experiments on three analysis tasks and eighteen real-world datasets demonstrate that TSG2L outperforms several state-of-the-art models. The source code of TSG2L is available at https://github.com/infogroup502/TSG2L .},
  archive      = {J_KBS},
  author       = {Lei Chen and Yepeng Xu and Chaoqun Fan and Yuan Li and Ming Li and Zexin Lu and Xinquan Xie},
  doi          = {10.1016/j.knosys.2025.113137},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113137},
  shortjournal = {Knowl. Based Syst.},
  title        = {Noise-tolerant universal representation learning for multivariate time series from global-to-local perspective},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When fractional calculus meets robust learning: Adaptive robust loss functions. <em>KBS</em>, <em>312</em>, 113136. (<a href='https://doi.org/10.1016/j.knosys.2025.113136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, robust loss functions are crucial for addressing challenges like outliers and noise. This paper introduces a novel family of adaptive robust loss functions, Fractional Loss Functions (FLFs), generated by deploying the fractional derivative operator into conventional ones. We demonstrate that adjusting the fractional derivative order α allows generating a diverse spectrum of FLFs while preserving the essential properties necessary for gradient-based learning. We show that tuning α gives the unique property to morph the loss landscape to reduce the influence of large residuals. Thus, α serves as an interpretable hyperparameter defining the robustness level of FLFs. However, determining α prior to training requires a manual exploration to pinpoint an FLF that aligns with the learning tasks. To overcome this issue, we reveal that FLFs can balance robustness against outliers while increasing penalization of inliers by tuning α . This inherent feature allows transforming α to an adaptive parameter as a trade-off that ensures balanced learning of α is feasible. Thus, FLFs can dynamically adapt their loss landscape, facilitating error minimization while providing robustness during training. We performed experiments across diverse tasks and showed that FLFs significantly enhanced performance. Our source code is available at https://github.com/mertcankurucu/Fractional-Loss-Functions .},
  archive      = {J_KBS},
  author       = {Mert Can Kurucu and Müjde Güzelkaya and Ibrahim Eksin and Tufan Kumbasar},
  doi          = {10.1016/j.knosys.2025.113136},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113136},
  shortjournal = {Knowl. Based Syst.},
  title        = {When fractional calculus meets robust learning: Adaptive robust loss functions},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient continuous control perspective for reinforcement-learning-based sequential recommendation. <em>KBS</em>, <em>312</em>, 113133. (<a href='https://doi.org/10.1016/j.knosys.2025.113133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation, where user preference is dynamically inferred from sequential historical behaviors, is a critical task in recommender systems (RSs). To further optimize long-term user engagement, offline reinforcement-learning-based RSs have become a mainstream technique as they provide an additional advantage in avoiding global explorations that may harm online users’ experiences. However, previous studies mainly focus on discrete action and policy spaces, which might have difficulties in handling dramatically growing items efficiently. To mitigate this issue, in this paper, we aim to design an algorithmic framework applicable to continuous policies. To facilitate the control in the low-dimensional but dense user preference space, we propose an E fficient Co ntinuous C ontrol framework (ECoC). Based on a statistically tested assumption, we first propose the novel unified action representation abstracted from normalized user and item spaces. Then, we develop the corresponding policy evaluation and policy improvement procedures. During this process, strategic exploration and directional control in terms of unified actions are carefully designed and crucial to final recommendation decisions. Moreover, beneficial from unified actions, the conservatism regularization for policies and value functions are combined and perfectly compatible with the continuous framework. The resulting dual regularization ensures the successful offline training of RL-based recommendation policies. Finally, we conduct extensive experiments to validate the effectiveness of our framework. The results show that compared to the discrete baselines, our ECoC is trained far more efficiently. Meanwhile, the final policies outperform baselines in both capturing the offline data and gaining long-term rewards.},
  archive      = {J_KBS},
  author       = {Jun Wang and Likang Wu and Qi Liu and Yu Yang},
  doi          = {10.1016/j.knosys.2025.113133},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113133},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient continuous control perspective for reinforcement-learning-based sequential recommendation},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metacognitive symbolic distillation framework for multi-choice machine reading comprehension. <em>KBS</em>, <em>312</em>, 113130. (<a href='https://doi.org/10.1016/j.knosys.2025.113130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic knowledge distillation can transfer the reasoning abilities of large language models (LLMs) effectively to smaller models. However, in the context of multi-choice machine reading comprehension (MMRC), traditional distillation methods focus primarily on learning from the rationales of the correct options generated by the large teacher model, overlooking the educational significance of reasoning behind incorrect options. In human education, metacognition emphasizes the importance of actively identifying errors, enhancing the overall understanding. Inspired by this approach, we propose an innovative framework that incorporates metacognition into symbolic distillation. Initially, we prompt the teacher LLM to generate rationales for all options in the MMRC dataset. Subsequently, the small student model is fine-tuned using these rationales, including those for incorrect options. Our experiments on two MMRC datasets demonstrate that this framework improves the performance of the small student model significantly compared to standard fine-tuned and distilled models. We further find that when the student model is sufficiently large, upgrading the teacher model could yield further improvements. However, the effectiveness of our framework is constrained by the performance of the teacher model on more complex MMRC tasks.},
  archive      = {J_KBS},
  author       = {Jiacheng Yao and Xin Xu and Guoxiu He},
  doi          = {10.1016/j.knosys.2025.113130},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113130},
  shortjournal = {Knowl. Based Syst.},
  title        = {Metacognitive symbolic distillation framework for multi-choice machine reading comprehension},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verifiable federated learning with group chaining in edge computing. <em>KBS</em>, <em>312</em>, 113129. (<a href='https://doi.org/10.1016/j.knosys.2025.113129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, each client retains its data locally on the device, sharing only model update gradients rather than the raw dataset. While a centralized cloud server can access larger datasets, it incurs high communication overhead and latency and remains susceptible to privacy risks, as it can analyze or manipulate uploaded gradients to infer client information. To address these challenges, we propose a Verifiable Federated Learning Scheme with Group Chaining in Edge Computing (VFLGC), which accelerates model training, optimizes communication and computation overhead, and mitigates gradient leakage risks. Our approach groups clients, linking them in chain structures within each group to enhance privacy protection of individual dataset information. Edge servers handle partial aggregations, while the main aggregation server performs global aggregation. Additionally, a secure verification mechanism based on Lagrange interpolation ensures the correctness of the aggregated gradients. The experimental results demonstrate a model accuracy of 96.38% on the MNIST dataset, 70.1% on the CHFAR-10 dataset, and 90.86% on the AGNews dataset at a learning rate of 0.01. The experimental evaluation confirms the practical effectiveness of the proposed scheme, with VFLGC outperforms the existing schemes, achieving all targeted objectives.},
  archive      = {J_KBS},
  author       = {Shufen Niu and Lin Hu and Xingxing Nan and Yan Zhang and Weifang Wang},
  doi          = {10.1016/j.knosys.2025.113129},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113129},
  shortjournal = {Knowl. Based Syst.},
  title        = {Verifiable federated learning with group chaining in edge computing},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGAN-LD: A sparse label propagation-based anomaly detection approach using multi-generative adversarial networks. <em>KBS</em>, <em>312</em>, 113124. (<a href='https://doi.org/10.1016/j.knosys.2025.113124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with synthetic data for anomaly detection has attracted a lot of attention. Recent works attempted to utilize generative adversarial networks (GANs) to generate pseudo-labeled synthetic samples for the model’s learning process. However, in real applications, the sparsity of originally labeled training samples leads to a model collapsing problem, such that most of the pseudo-labeled samples synthesized by GANs are crowded in a small area, resulting in the difficulty for GANs in learning the spatial distribution of samples. In this paper, we proposed a sparse label propagation-based anomaly detection approach using the multi-generators dual-discriminator framework (MGAN-LD). Firstly, DBSCAN clustering is utilized to assign samples to different clusters. Then, to expand the labeled training set, label propagation processes are carried out in each cluster to generate highly-credible pseudo-labels for unlabeled samples. Furthermore, a novel GAN with multiple generators is trained to simultaneously learn the local data distribution of different areas in the feature space based on the expanded training set to avoid the model collapsing. Finally, the training set is further augmented by synthetic samples from multiple generators of MGAN-LD, and the set is employed to train an overall discriminator. Benefiting from the data augmentation, MGAN-LD can build reliable classification boundaries between normal and abnormal samples. MGAN-LD is evaluated against nine classical anomaly detection methods on 11 public datasets. The results show that MGAN-LD improves the AUC metrics by an average of 10%, the AP metrics by an average of 17%, and the F1 metrics by an average of 15% compared with other classical methods.},
  archive      = {J_KBS},
  author       = {Shuyu Li and Wen Chen and Kaiyan Xing and Hongchao Wang and Yilin Zhang and Ming Kang},
  doi          = {10.1016/j.knosys.2025.113124},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113124},
  shortjournal = {Knowl. Based Syst.},
  title        = {MGAN-LD: A sparse label propagation-based anomaly detection approach using multi-generative adversarial networks},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoPolCNN: A neural architecture search method of convolutional neural network for PolSAR image classification. <em>KBS</em>, <em>312</em>, 113122. (<a href='https://doi.org/10.1016/j.knosys.2025.113122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs), as a kind of typical classification model known for good performance, have been utilized to cope with polarimetric synthetic aperture radar (PolSAR) image classification. Nevertheless, the performances of CNNs highly rely on well-designed network architectures and there is no theoretical guarantee on how to design them. As a result, the architectures of CNNs can be only designed by human experts or by trial and error, which makes the architecture design is annoying and time-consuming. So, a neural architecture search (NAS) method of CNN called AutoPolCNN, which can determine the architecture automatically, is proposed in this paper. Specifically, we firstly design the search space which covers the main components of CNNs like convolution and pooling operators. Secondly, considering the fact that the number of layers can also influence the performance of CNN, we propose a super normal module (SNM), which can dynamically adjust the number of network layers according to different datasets in the search stage. Finally, we develop the loss function and the search method for the designed search space. Via AutoPolCNN, preparing the data and waiting for the classification results are enough. Experiments carried out on three PolSAR datasets prove that the architecture can be automatically determined by AutoPolCNN within an hour ( at least 10 times faster than existing NAS methods ) and has higher overall accuracy (OA) than state-of-the-art (SOTA) PolSAR image classification CNN models.},
  archive      = {J_KBS},
  author       = {Guangyuan Liu and Yangyang Li and Yanqiao Chen and Ronghua Shang and Licheng Jiao},
  doi          = {10.1016/j.knosys.2025.113122},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113122},
  shortjournal = {Knowl. Based Syst.},
  title        = {AutoPolCNN: A neural architecture search method of convolutional neural network for PolSAR image classification},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel information compression and textual information enhancement for multimodal sentiment analysis. <em>KBS</em>, <em>312</em>, 113121. (<a href='https://doi.org/10.1016/j.knosys.2025.113121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) aims to extract sentiment information from textual, visual, and auditory modalities. While previous works have largely focused on representation learning and feature fusion strategies, challenges unique to video-based multimodal data remain underexplored. Compared to image–text tasks, video sequences are longer, leading to increased redundancy and noise in both visual and auditory modalities. Additionally, there are inherent discrepancies in semantic richness across different modalities, a factor often overlooked in prior studies. To address these challenges, we propose the Multi-level Information Compression and Textual Information Enhancement Network (MCEN), which leverages the inherent advantages of textual data in MSA tasks. Our approach features a Hierarchical Information Compression (HIC) module designed to reduce noise and redundancy in the visual and auditory modalities while extracting unimodal semantic information at varying scales. Furthermore, we introduce a Textual Information Enhancement (TIE) module to facilitate cross-modal information fusion at different semantic levels. The model is further enhanced by a Contrastive Predictive Coding (CPC) loss, which regulates the contribution of different layers and improves the inter-modal information used. Extensive experiments conducted on three widely used benchmark datasets — MOSI, MOSEI, and CH-SIMS — demonstrate that our method achieves state-of-the-art performance while maintaining a parameter count under 1M.},
  archive      = {J_KBS},
  author       = {Yuchen Zhang and Hong Zhong and Naji Alhusaini and Guilin Chen and Cheng Wu},
  doi          = {10.1016/j.knosys.2025.113121},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113121},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multilevel information compression and textual information enhancement for multimodal sentiment analysis},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable tri-factorization guided multi-view subspace clustering. <em>KBS</em>, <em>312</em>, 113119. (<a href='https://doi.org/10.1016/j.knosys.2025.113119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based Multi-view Subspace Clustering (AMSC) has exhibited its outstanding capability in large-scale multi-view clustering. Despite significant progress, previous AMSC approaches still suffer from two limitations. First, they mostly neglect the high-order correlation, which undermines their ability in discovering complex cluster structures. Second, they frequently overlook the potential connection between multi-view dimension reduction and anchor subspace clustering, which affects their robustness to low-quality views. In view of these issues, we present a Scalable Tri-factorization Guided Multi-view Subspace Clustering (ST-MSC) approach. Specifically, the proposed approach seeks to recover the latent sample-anchor relationships in multiple embedded spaces, where the multi-view anchor representations are stacked into a low-rank tensor to enhance their high-order correlations with tri-factorization guidance. Theoretical analysis indicates that the tri-factorization paradigm has inherent relevance with two mutually beneficial tasks, namely, the multi-view dimensionality reduction and the anchor-based multi-view subspace clustering. Furthermore, a simple yet fast algorithm is devised to minimize the objective model, where the latent embedding spaces and the anchor subspace structure can be iteratively updated in a unified manner. Experiments have been conducted to verify the effectiveness and efficiency of our ST-MSC approach in comparison with the advanced approaches.},
  archive      = {J_KBS},
  author       = {Guang-Yu Zhang and Chang-Bin Guan and Dong Huang and Zihao Wen and Chang-Dong Wang and Lei Xiao},
  doi          = {10.1016/j.knosys.2025.113119},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113119},
  shortjournal = {Knowl. Based Syst.},
  title        = {Scalable tri-factorization guided multi-view subspace clustering},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TF-attack: Transferable and fast adversarial attacks on large language models. <em>KBS</em>, <em>312</em>, 113117. (<a href='https://doi.org/10.1016/j.knosys.2025.113117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the great advancements in large language models (LLMs), adversarial attacks against LLMs have recently attracted increasing attention. We found that pre-existing adversarial attack methodologies exhibit limited transferability and are notably inefficient, particularly when applied to LLMs. In this paper, we analyze the core mechanisms of previous predominant adversarial attack methods, revealing that (1) the distributions of importance score differ markedly among victim models, restricting the transferability; (2) the sequential attack processes induces substantial time overheads. Based on the above two insights, we introduce a new scheme, named TF-Attack , for T ransferable and F ast adversarial attacks on LLMs. TF-Attack employs an external LLM as a third-party overseer rather than the victim model to identify critical units within sentences. Moreover, TF-Attack introduces the concept of Importance Level , which allows for parallel substitutions of attacks. We conduct extensive experiments on 6 widely adopted benchmarks, evaluating the proposed method through both automatic and human metrics. Results show that our method consistently surpasses previous methods in transferability and delivers significant speed improvements, up to 10 × faster than earlier attack strategies.},
  archive      = {J_KBS},
  author       = {Zelin Li and Kehai Chen and Lemao Liu and Xuefeng Bai and Mingming Yang and Yang Xiang and Min Zhang},
  doi          = {10.1016/j.knosys.2025.113117},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113117},
  shortjournal = {Knowl. Based Syst.},
  title        = {TF-attack: Transferable and fast adversarial attacks on large language models},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models can better understand knowledge graphs than we thought. <em>KBS</em>, <em>312</em>, 113060. (<a href='https://doi.org/10.1016/j.knosys.2025.113060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When we integrate factual knowledge from knowledge graphs (KGs) into large language models (LLMs) to enhance their performance, the cost of injection through training increases with the scale of the models. Consequently, there is significant interest in developing prompt strategies that effectively incorporate KG information into LLMs. However, the community has not yet comprehensively understood how LLMs process and interpret KG information in different input formats and organizations within prompts, and researchers often rely on trial and error. To address this gap, we design extensive experiments to empirically study LLMs’ comprehension of different KG prompts. At the literal level, we reveal LLMs’ preferences for various input formats (from linearized triples to fluent natural language text). At the attention distribution level, we discuss the underlying mechanisms driving these preferences. We then investigate how the organization of structured knowledge impacts LLMs and evaluate LLMs’ robustness in processing and utilizing KG information in practical scenarios. Our experiments show that (1) linearized triples are more effective than fluent NL text in helping LLMs understand KG information and answer fact-intensive questions; (2) Different LLMs exhibit varying preferences for different organizational formats of triples; (3) LLMs with larger scales are more susceptible to noisy, incomplete subgraphs.},
  archive      = {J_KBS},
  author       = {Xinbang Dai and Yuncheng Hua and Tongtong Wu and Yang Sheng and Qiu Ji and Guilin Qi},
  doi          = {10.1016/j.knosys.2025.113060},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113060},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language models can better understand knowledge graphs than we thought},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From local to global: Leveraging document graph for named entity recognition. <em>KBS</em>, <em>312</em>, 113017. (<a href='https://doi.org/10.1016/j.knosys.2025.113017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that aims to identify the span and category of entities within text. Recent advancements have demonstrated significant improvements in NER performance by incorporating document-level context. However, due to input length limitations, these models only consider the context of nearby sentences, failing to capture global long-range dependencies within the entire document. To address this issue, we propose a novel span-based two-stage method that formulates the document as a span graph, enabling the capture of global long-range dependencies at both token and span levels. Specifically, (1) we first train a binary classifier without considering entity types to extract candidate spans from each sentence. (2) Then, we leverage the robust contextual understanding and structural reasoning capabilities of Large Language Models (LLMs) like GPT to incrementally integrate these spans into the document-level span graph. By utilizing this span graph as a guide, we retrieve relevant contextual sentences for each target sentence and jointly encode them using BERT to capture token-level dependencies. Furthermore, by employing a Graph Transformer with well-designed position encoding to incorporate graph structure, our model effectively exploits span-level dependencies throughout the document. Extensive experiments on resource-rich nested and flat NER datasets, as well as low-resource distantly supervised NER datasets, demonstrate that our proposed model outperforms previous state-of-the-art models, showcasing its effectiveness in capturing long-range dependencies and enhancing NER accuracy.},
  archive      = {J_KBS},
  author       = {Yu-Ming Shang and Hongli Mao and Tian Tian and Heyan Huang and Xian-Ling Mao},
  doi          = {10.1016/j.knosys.2025.113017},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113017},
  shortjournal = {Knowl. Based Syst.},
  title        = {From local to global: Leveraging document graph for named entity recognition},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval type-2 fuzzy neural networks for multi-label classification. <em>KBS</em>, <em>312</em>, 113014. (<a href='https://doi.org/10.1016/j.knosys.2025.113014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of multi-dimensional labels plays an important role in machine learning problems. We discovered that traditional binary labels could not capture the contents and relationships in an instance. Hence, we propose a multi-label classification model based on interval type-2 fuzzy logic. In the proposed model, we use a deep neural network to predict an instance’s type-1 fuzzy membership and another to predict the membership’s fuzzifiers, resulting in interval type-2 fuzzy memberships. We also propose a loss function for determining the similarities between binary labels in datasets and interval type-2 fuzzy memberships generated by our model. The experiments validate that our approach outperforms baselines in multi-label classification benchmarks.},
  archive      = {J_KBS},
  author       = {Dayong Tian and Feifei Li and Yiwen Wei},
  doi          = {10.1016/j.knosys.2025.113014},
  journal      = {Knowledge-Based Systems},
  month        = {3},
  pages        = {113014},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interval type-2 fuzzy neural networks for multi-label classification},
  volume       = {312},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCA-InceptionUNeXt: A lightweight spatial-channel-attention-based network for efficient medical image segmentation. <em>KBS</em>, <em>311</em>, 113166. (<a href='https://doi.org/10.1016/j.knosys.2025.113166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is essential for both diagnostic and therapeutic applications, requiring the precise delineation of complex anatomical structures. In this paper, we introduce a lightweight Spatial-Channel-Attention-based network for efficient medical image segmentation, named SCA-InceptionUNeXt. Our model is built on a U-shaped architecture and incorporates two key innovations: a modified InceptionNeXt block and a novel Spatial-aware Channel Attention (SCA) module. The customized InceptionNeXt block enhances feature extraction by leveraging depthwise and pointwise separable convolutions, significantly reducing the model's parameter count. Meanwhile, the SCA mechanism unifies spatial and channel attention into a cohesive module, allowing the network to capture cross-dimensional interactions that improve feature fusion. Comprehensive evaluations across four medical imaging datasets demonstrate that SCA-InceptionUNeXt outperforms state-of-the-art (SOTA) methods in segmenting a variety of lesions and organs across different imaging modalities: breast tumors in ultrasound images, polyp regions in colonoscopy sequences, skin lesions in dermoscopy images, and multiple organs in abdominal CT scans. Notably, our approach achieved a Dice coefficient of 81.66% on the BUSI dataset for breast lesion segmentation while using 26.11 million fewer parameters than U-Net, offering an effective balance between complexity and performance that meets the stringent requirements of medical imaging applications.},
  archive      = {J_KBS},
  author       = {Jaouad Tagnamas and Hiba Ramadan and Ali Yahyaouy and Hamid Tairi},
  doi          = {10.1016/j.knosys.2025.113166},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113166},
  shortjournal = {Knowl. Based Syst.},
  title        = {SCA-InceptionUNeXt: A lightweight spatial-channel-attention-based network for efficient medical image segmentation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-informed prototype contrastive learning for cross-scene hyperspectral image classification. <em>KBS</em>, <em>311</em>, 113165. (<a href='https://doi.org/10.1016/j.knosys.2025.113165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-scene hyperspectral image classification (HSIC) has gained significant attention for its ability to enhance classification performance on unlabeled data across diverse domains. However, many existing methods fail to fully recognize the uncertainties induced by spectral shifts, hindering effective domain alignment and classification accuracy. While prototype-guided domain alignment has proven effective in knowledge transfer due to the representative nature of prototypes derived through average aggregation, these prototypes primarily capture the expectations of feature distributions with minimal uncertainty. This overlooks the critical role of high-uncertainty samples in defining feature distribution boundaries, thereby complicating optimal domain alignment. To address this issue, we propose Uncertainty-Informed Prototype Contrastive Learning (UIPCL), a novel framework that integrates uncertainty-informed self-training (UIT) and decision-boundary-aware prototype alignment (DPA). Specifically, UIT leverages contrastive learning with adaptive thresholds derived from uncertainty assessments to select pseudo-labels with low uncertainty for more robust prototype estimation. Additionally, DPA introduces a novel metric for quantifying feature distribution distances between domains, aligning both representative prototypes and discriminative decision boundaries to enhance domain alignment robustness. Finally, tailored for HSIC, we design a dual-branch CNN-Transformer that incorporates multi-level spatial-spectral feature fusion, enabling richer feature representations. Extensive experiments on two benchmark datasets for cross-scene HSIC and two self-made UAV HSIs datasets demonstrate that the proposed UIPCL consistently outperforms the state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Kai Xu and Zhou Zhu and Bocai Wu and Chengcheng Fan},
  doi          = {10.1016/j.knosys.2025.113165},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113165},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncertainty-informed prototype contrastive learning for cross-scene hyperspectral image classification},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cluster chaotic optimization for solving power loss and voltage profiles problems on electrical distribution networks. <em>KBS</em>, <em>311</em>, 113145. (<a href='https://doi.org/10.1016/j.knosys.2025.113145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for electricity poses significant challenges in maintaining a reliable and efficient power supply. Optimal Capacitor Placement (OCP) in electrical engineering addresses this issue by strategically positioning capacitor banks within constrained Radial Distribution Networks (RDNs). Traditional optimization methods often struggle with this problem; alternative approaches, such as metaheuristic algorithms, present promising solutions. Despite advances in optimization techniques, challenges in achieving optimal solutions continue. To address these challenges, recent hybrid computational methods, such as the cluster chaotic optimization (CCO) algorithm, have emerged to enhance stability and robustness in finding optimal solutions. The effectiveness of the CCO algorithm lies in its combination of Evolutionary Computation (EC) and Machine Learning (ML) approaches. These approaches improve the search strategy by leveraging information extracted from the solution landscape, resulting in high performance in discovering optimal solutions. In this context, this work aims to utilize the strengths of the CCO algorithm to solve real-world challenges and evaluate its potential in addressing the OCP. The CCO algorithm was tested on three benchmark RDNs to assess its efficacy. Results were compared with those obtained from classical and recently developed methods and analyzed using non-parametric tests. The findings indicate that the CCO algorithm is competitive and robust in solving the OCP, outperforming similar strategies, and demonstrates its effectiveness in optimizing complex real-world problems in electrical engineering.},
  archive      = {J_KBS},
  author       = {Primitivo Diaz and Eduardo H. Haro and Omar Avalos and Nayeli Perez},
  doi          = {10.1016/j.knosys.2025.113145},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113145},
  shortjournal = {Knowl. Based Syst.},
  title        = {A cluster chaotic optimization for solving power loss and voltage profiles problems on electrical distribution networks},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ANOGAT-sparse-TL: A hybrid framework combining sparsification and graph attention for anomaly detection in attributed networks using the optimized loss function incorporating the twersky loss for improved robustness. <em>KBS</em>, <em>311</em>, 113144. (<a href='https://doi.org/10.1016/j.knosys.2025.113144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the identification of abnormalities in attributed networks has become essential for applications including social media analysis, cybersecurity, and financial fraud detection. Unsupervised graph anomaly detection techniques seek to recognize infrequent and anomalous patterns in graph-structured data without the necessity of labelled instances. Conventional methods employing Graph Neural Networks (GNNs) frequently encounter difficulties, especially due to the transmission of noisy edges and the intrinsic intricacy of node interrelations. To overcome these restrictions, we introduce ANOGAT-Sparse-TL, an innovative hybrid framework that integrates graph sparsification and Graph Attention Networks (GAT) with autoencoder-based reconstruction for anomaly detection in attributed networks. The sparsification procedure removes extraneous edges and highlights significant node connections, thereby enhancing computational efficiency and improving anomaly detection efficacy. By including GAT, our model carefully allocates significance to pertinent neighboring nodes, yielding enhanced node embeddings. The autoencoder subsequently reconstructs these embeddings to detect abnormalities via reconstruction errors. Incorporating Tversky Loss in the reconstruction process further improves the robustness of the model by effectively addressing the imbalance between normal and anomalous data, prioritizing the detection of rare anomalies. This optimized loss function allows ANOGAT-Sparse-TL to focus on hard-to-reconstruct instances, which are typically indicative of anomalies, and reduces the impact of noisy data on the model's performance. ANOGAT-Sparse-TL effectively integrates attribute-based and structural anomalies, yielding comprehensive anomaly ratings. Comprehensive studies on the four real-world datasets indicate that our strategy surpasses current state-of-the-art methodologies, with enhanced performance. Moreover, the scalability of our methodology guarantees its relevance to extensive real-world networks, rendering it an adaptable option for diverse graph anomaly detection activities. ANOGAT-Sparse-TL, despite its complexity, maintains computational efficiency and provides substantial improvements in anomaly detection inside attributed networks. Future research may concentrate on enhancing interpretability and broadening generalizability to various network architectures.},
  archive      = {J_KBS},
  author       = {Wasim Khan and Nadhem Ebrahim},
  doi          = {10.1016/j.knosys.2025.113144},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113144},
  shortjournal = {Knowl. Based Syst.},
  title        = {ANOGAT-sparse-TL: A hybrid framework combining sparsification and graph attention for anomaly detection in attributed networks using the optimized loss function incorporating the twersky loss for improved robustness},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep feature clustering for multi-class industrial image anomaly detection. <em>KBS</em>, <em>311</em>, 113134. (<a href='https://doi.org/10.1016/j.knosys.2025.113134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing unsupervised multi-class anomaly detection algorithms usually train unified reconstruction networks to capture the distribution of all classes simultaneously. However, under such a challenging setting, popular reconstruction networks need to be elaborately designed to avoid the “identical shortcut”. In addition, the distribution of each category is different, which may mean different requests for expression ability. To solve these problems, built on the intuitive “classification-then-detection” idea, we utilize clustering algorithm to expose the category information hidden in the pre-trained deep features, then propose a simple and application-friendly approach for multi-class anomaly detection. The proposed approach consists of Category Anchor Construction (CAC), Category Information Mining (CIM) and Local Feature Routing (LFR). Firstly, CAC is proposed to extract the corresponding pre-trained features from a small subset of training images to construct category anchors, preserving the valuable category information provided by the training set. Then, CIM is introduced to mine category information embedded in pre-trained features by category anchors voting and acquires the category labels. Finally, to achieve multi-class anomaly detection, we propose LFR, splitting multi-class distribution into multiple single-class distributions according to category labels so that separate single-class anomaly detection heads can be trained to express them. In spite of simplicity, the proposed method outperforms state-of-the-art algorithms in terms of accuracy and stability on the widely used MVTec-AD, VisA, MVTec-LOCO, MPDD and BTAD datasets.},
  archive      = {J_KBS},
  author       = {Rongxiang Wang and Zhi Li and Long Zheng and Weidong Wang and Shuyun Li},
  doi          = {10.1016/j.knosys.2025.113134},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113134},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep feature clustering for multi-class industrial image anomaly detection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio–temporal graph hierarchical learning framework for metro passenger flow prediction across stations and lines. <em>KBS</em>, <em>311</em>, 113132. (<a href='https://doi.org/10.1016/j.knosys.2025.113132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of metro passenger flow is crucial for the public and metro managers as it can provide decision support. Previous research has predominantly focused on predicting passenger flow at individual stations and lines, often encountering challenges in simultaneously predicting both aspects. Furthermore, some studies that mine spatio–temporal data from metro networks have tended to remain at a global level and have not deeply explored individual stations. In this study, we propose a hybrid prediction framework using spatio-temporal graph neural networks to accurately predict inter-station and inter-line passenger flows while also considering the overall network dynamics. This approach not only captures global information but also emphasizes the importance of precise predictions for individual stations. By utilizing spatio-temporal graph convolutional networks, we derive the global spatio–temporal information to construct a feature flow. Then, by employing the proposed Local Feature Extraction Module, we perform an initial prediction to obtain the prediction value of each individual station, thereby completing the first stage of feature extraction and model training. Furthermore, we establish a new hierarchical prediction module to generate line-level passenger flow predictions while correcting station-level prediction errors in the first stage. Four experiments based on real data from the Hangzhou and Shanghai metro systems demonstrate that our framework outperforms all baseline models, highlighting its outstanding performance and versatility.},
  archive      = {J_KBS},
  author       = {Hongtao Li and Wenjie Fu and Haina Zhang and Wenzheng Liu and Shaolong Sun and Tao Zhang},
  doi          = {10.1016/j.knosys.2025.113132},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113132},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatio–temporal graph hierarchical learning framework for metro passenger flow prediction across stations and lines},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaMGT: Molecular representation learning via adaptive mixture of GCN-transformer. <em>KBS</em>, <em>311</em>, 113131. (<a href='https://doi.org/10.1016/j.knosys.2025.113131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of molecular properties is a fundamental and indispensable task for drug and material industries. Effective molecular representation learning is critical to facilitating this task. To date, methods based on graph neural networks have achieved considerable success in molecular property prediction. Existing methods for molecular representation learning directly employ the message-passing mechanism for atomic-level properties of molecules, i.e., atoms and bonds. However, these approaches fail to simultaneously model both local and global structural features of molecules. Given that local and global structural features are important in the determination of molecular properties, this study introduces a novel method for molecular representation learning that aims to simultaneously model local and global structural features, referred to as Ada ptive M ixture G CN- T ransformer ( AdaMGT ). In particular, we incorporate local structural features into the graph transformer by combining its global attention mechanism with a local convolutional filter. Simultaneously, we introduce a diffusion process with energy constraints to address the computational overhead of the quadratic global attention. Finally, an adaptive unit is employed to adaptively ascertain the mixed importance of features on the basis of personalization. Results of extensive experiments on the dataset MoleculeNet demonstrate that AdaMGT consistently outperforms state-of-the-art baseline models in both classification and regression tasks related to molecular property prediction.},
  archive      = {J_KBS},
  author       = {Cangfeng Ding and Zhaoyao Yan and Lerong Ma and Bohao Cao and Lu Cao},
  doi          = {10.1016/j.knosys.2025.113131},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113131},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdaMGT: Molecular representation learning via adaptive mixture of GCN-transformer},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained recognition of citrus varieties via wavelet channel attention network. <em>KBS</em>, <em>311</em>, 113128. (<a href='https://doi.org/10.1016/j.knosys.2025.113128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification (FGVC) has numerous applications in various sectors, including industrial, service, and agricultural sectors. However, the existing FGVC methods do not allow simultaneous capturing of local and global image features, leading to unsatisfactory results. To solve FGVC problems, this study proposes a wavelet channel attention network (WCANet). A WCANet improves multiscale feature extraction within channel attention modules by combining global average pooling (GAP) which captures global features—with wavelet transform (WT), which captures local features. Intelligent identification of citrus varieties is urgently required for the differentiated management of different varieties of citrus trees planted in a smart citrus orchard. However, no public dataset is currently available for use in the fine-grained recognition of citrus varieties for intelligent management of citrus orchards. Therefore, we developed a dataset, named citrus variety dataset (CVD), based on the canopy images of eight common citrus varieties. Experimental results show that when a WCANet is added to a 50-layer residual network (ResNet-50) and a 101-layer residual network (ResNet-101), the citrus variety identification accuracies of these two models are 96.67 % and 96.83 %, respectively, which are better than the corresponding accuracies of other channel attention modules with the same settings. Finally, by adding a WCANet to ResNet-50 and pretraining on ImageNet, a citrus variety identification accuracy of 99.10 % was achieved. In this study, we provide a performance enhancement solution for the expert systems used in the identification of citrus varieties and agricultural products.},
  archive      = {J_KBS},
  author       = {Fukai Zhang and Xiaobo Jin and Jie Jiang and Gang Lin and Mingzhi Wang and Shan An and Qiang Lyu},
  doi          = {10.1016/j.knosys.2025.113128},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113128},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained recognition of citrus varieties via wavelet channel attention network},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From multi-scale grids to dynamic regions: Dual-relation enhanced transformer for image captioning. <em>KBS</em>, <em>311</em>, 113127. (<a href='https://doi.org/10.1016/j.knosys.2025.113127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of image captioning is to describe the visual content of an image in an accurate and natural sentence. Some previous methods adopt convolutional networks to encode grid-level features, whereas others use an object detector to extract region-level features. However, the spatial resolution of high-level grid features is typically low, thus capturing small-scale objects is challenging for such models. In addition, most region-based methods directly set the same number of regions to represent all images, failing to account for varying scene complexities across different images. They introduce noise in region relationship modeling and disrupt sentence reasoning. To address these issues, we propose a novel D ual- R elation E nhanced T ransformer ( DRET ) model that complements the advantages of multi-scale grid and dynamic region features. In the encoding phase, we first apply multiple sampling strategies to generate multi-scale grid features, then design a novel multi-scale grid attention (MGA) encoder that learns the relationships between features at different scales. Meanwhile, a new dynamic region selection (DRS) encoder is devised to dynamically select an appropriate number of regions based on the scene complexity of each input image, effectively pruning redundant regions and enhancing correlations between selected regions. In the decoding stage, we combine the advantages of grid and region features, using a cross-modal adaptive gating (CAG) decoder that automatically determines the gate weights of the two visual features at each time step. Extensive experiments on MS-COCO and Flickr30K show that our model achieves better performance compared to current methods.},
  archive      = {J_KBS},
  author       = {Wei Zhou and Chuanle Song and Dihu Chen and Tao Su and Haifeng Hu and Chun Shan},
  doi          = {10.1016/j.knosys.2025.113127},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113127},
  shortjournal = {Knowl. Based Syst.},
  title        = {From multi-scale grids to dynamic regions: Dual-relation enhanced transformer for image captioning},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fine-grained scene retrieval model for narrative images based on multi-view feature fusion and SC-fused re-ranking. <em>KBS</em>, <em>311</em>, 113126. (<a href='https://doi.org/10.1016/j.knosys.2025.113126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene retrieval is imperative to resource acquisition and scene perception of narrative images. Most studies have mainly extracted semantic and visual features to capture scene information while ignoring implicit features, i.e., structure relations. Moreover, similarity-based ranking is widely used to match similar items, but they are irrelevant at the scene level. To this end, we construct a fine-grained scene retrieval model for narrative images based on m ulti-view f eature f usion and s cene c ategory (SC)-fused r e-ranking ( M2FSCR ). Specifically, to represent the scene information of narrative images, the visual and semantic features are extracted through ViT_BS_RN ( Vi sion T ransformers, B OW_ S IFT, and R es N et) and LERT ( L inguistically-motivated bidirectional E ncoder R epresentation from T ransformer), respectively. Then, on the basis of constructing semantic relation graphs, the structure relations of narrative images, text, and image-text pairs are extracted by multi-channel graph attention networks (MGAT). Additionally, cross-fusion is designed to capture the complementary information between images and text at the intertwined decision and feature levels to improve the effect of fine-grained scene recognition. Finally, the visual, semantic, and structure relation features are fused through the multi-view feature fusion strategy to match narrative images, and the SC-fused re-ranking strategy is devised to optimize the search results. The experimental results show that the mAP of the proposed model is 0.8648 in fine-grained scene retrieval, improved by 4.9 % to the optimal image-text retrieval method.},
  archive      = {J_KBS},
  author       = {Shouqiang Sun and Ziming Zeng and Qingqing Li and Tingting Li},
  doi          = {10.1016/j.knosys.2025.113126},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113126},
  shortjournal = {Knowl. Based Syst.},
  title        = {A fine-grained scene retrieval model for narrative images based on multi-view feature fusion and SC-fused re-ranking},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning discriminative topological structure information representation for 2D shape and social network classification via persistent homology. <em>KBS</em>, <em>311</em>, 113125. (<a href='https://doi.org/10.1016/j.knosys.2025.113125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting topological structure information from data sources such as images and social networks remains a significant challenge. Drawing inspiration from the theory of topological structure in visual perception (topological perception theory), this study employs topological data analysis (TDA) to extract topological information, which is typically represented using persistence diagrams. To facilitate end-to-end learning, we introduce a topological set network (TSNet) that transforms topological information into vector representations through mixed entropy and self-attention mechanisms. Our approach first applies persistent homology to extract topological structure information from the data, followed by a 45-degree clockwise rotation of this information. We then design a topological set layer (TS-Layer) that creates vectorized representations by encoding persistence diagrams into topological set blocks (TS-Blocks) with diverse distributions. We provide theoretical proof that the TS-Layer maintains stability under input perturbations. To further enhance the discriminative power of the encoded topological features, we incorporate a residual attention layer (RA-Layer). Experimental results demonstrate that our proposed approach achieves superior performance compared to recent state-of-the-art methods. Specifically, our method achieves accuracy improvements of 1.2% (75.8% vs. 74.6%) and 1.7% (94.4% vs. 92.7%) on the Animal and MPEG-7 datasets respectively compared to the best existing methods. For social network classification tasks, our approach demonstrates improvements of 1.0% (55.9% vs. 54.9%) and 2.1% (48.5% vs. 46.4%) on the reddit-5k and reddit-12k datasets respectively, validating the effectiveness of our topological feature extraction and vectorization approach.},
  archive      = {J_KBS},
  author       = {Changshuo Wang and Rongsheng Cao and Ruiping Wang},
  doi          = {10.1016/j.knosys.2025.113125},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113125},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning discriminative topological structure information representation for 2D shape and social network classification via persistent homology},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical feature selection via joint local label enhancement and neighborhood label distribution correlation. <em>KBS</em>, <em>311</em>, 113123. (<a href='https://doi.org/10.1016/j.knosys.2025.113123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification learning is an efficient approach for classification tasks with hierarchical structure. For large-scale hierarchical classification, feature selection is effectively addressed the high-dimensional feature space problem caused by complex semantic structures. However, the performance of algorithms is often constrained by the class imbalance distribution in the dataset. In particular, different subtasks within the hierarchical structure each faces different degrees of class imbalance challenges. In this paper, we propose a new Hierarchical Feature Selection method joint local label enhancement and Neighborhood Label Distribution correlation (HFS-NLD). Firstly, the class imbalance characteristics specific to each subtask in the hierarchy are exploited to transform hierarchical logical label into label distribution. Secondly, the label distribution prediction of each sample is driven by the unique neighborhood label distribution correlation of that sample. Subsequently, recursive selection process is employed to identify a discriminative common feature subset. Finally, the experimental results demonstrate the efficacy of our proposed algorithm across seven datasets with varying ratios of class imbalance.},
  archive      = {J_KBS},
  author       = {Chenxi Wang and Weihang Liu and Lei Guo and Yaojin Lin},
  doi          = {10.1016/j.knosys.2025.113123},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113123},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical feature selection via joint local label enhancement and neighborhood label distribution correlation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature enhancement network based on image partitioning in a multi-branch encoder-decoder architecture. <em>KBS</em>, <em>311</em>, 113120. (<a href='https://doi.org/10.1016/j.knosys.2025.113120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is of great significance in the medical field, as it can help doctors intelligently, quickly, and accurately locate key lesion areas, providing crucial support for the diagnosis, treatment, and recovery of patients. The primary reason existing segmentation networks encounter accuracy bottlenecks is that the size of lesion images limits the network's attention to information, while also causing a lack of image information transmission between encoding and decoding. This study proposes a Multi-branch Partition Feature Enhancement Network (MPFE Net), which is essentially based on our proposed network system, the Multi-Branch Partition-Guided Decoding Network (MPD Net), using an image partition strategy. This approach divides the image at the encoding end and passes it to the decoding end, enabling parallel decoding with branches based on partitions to alleviate the problem of insufficient image information transmission. In terms of module design and optimization, under the processing idea of image partitioning, we have constructed the Bottleneck module Multi-semantic Progressive Interaction Guider (MPIG) for semantic progressive fusion. Furthermore, we have enhanced the ability to extract local information in the Vision Transformer, constructing the Multi-branched Feature Enhancement with Shared ViT (MFES ViT) to enhance control over image details. In the experiments, MPFE Net was compared with 20 models on 8 medical datasets for metric exploration, image comparison, process verification, and statistical analysis. We also discussed in detail 4 key issues. The results show that MPFE Net has better lesion universality and segmentation superiority.},
  archive      = {J_KBS},
  author       = {Yuefei Wang and Yutong Zhang and Li Zhang and Yuxuan Wan and Zhixuan Chen and Yuquan Xu and Ruixin Cao and Liangyan Zhao and Yixi Yang and Xi Yu},
  doi          = {10.1016/j.knosys.2025.113120},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113120},
  shortjournal = {Knowl. Based Syst.},
  title        = {A feature enhancement network based on image partitioning in a multi-branch encoder-decoder architecture},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KG-prompt: Interpretable knowledge graph prompt for pre-trained language models. <em>KBS</em>, <em>311</em>, 113118. (<a href='https://doi.org/10.1016/j.knosys.2025.113118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) can provide rich factual knowledge for language models, enhancing reasoning ability and interpretability. However, existing knowledge injection methods usually ignore the structured information in KGs. Using structured knowledge to enhance pre-trained language models (PLMs) still has a set of challenging issues, including resource consumption of knowledge retraining, heterogeneous information, and knowledge noise. To address these issues, we explore how to flexibly inject structured knowledge into frozen PLMs. Inspired by prompt learning, we propose a novel method K nowledge G raph Prompt (KG-Prompt), which for the first time encodes the KG as structured prompts to enhance the knowledge expression ability of PLMs. KG-Prompt consists of a compressed subgraph construction module and a KG prompt generation module. In the compressed subgraph construction module, we construct compressed subgraphs based on a path-weighting strategy to reduce knowledge noise. In the KG prompt generation module, we propose a multi-hop consistency optimization strategy to learn the representation of compressed subgraphs, and then generate KG prompts based on a knowledge mapper to solve the heterogeneous information problem. The KG prompts can be inserted into the input of PLMs expediently, which decouples from PLMs and the downstream model without knowledge retraining and reduces computational resources. Extensive experiments on three knowledge-driven natural language understanding tasks demonstrate that our approach effectively improves the knowledge reasoning ability of PLMs. Furthermore, we provide a detailed analysis of different KG prompts and discuss the interpretability and generalizability of the proposed method.},
  archive      = {J_KBS},
  author       = {Liyi Chen and Jie Liu and Yutai Duan and Runze Wang},
  doi          = {10.1016/j.knosys.2025.113118},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113118},
  shortjournal = {Knowl. Based Syst.},
  title        = {KG-prompt: Interpretable knowledge graph prompt for pre-trained language models},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Escape velocity-based adaptive outlier detection algorithm. <em>KBS</em>, <em>311</em>, 113116. (<a href='https://doi.org/10.1016/j.knosys.2025.113116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is a pivotal technique within the realm of data mining, serving to pinpoint aberrant values nestled within datasets. It has been widely employed across diverse domains, including detection of credit card frauds, identification of seismic activities, and identification of anomalies within image datasets. However, existing approaches still face three shortcomings: (1) they often struggle with the intricacies of parameter selection and the vexing top-n dilemma, (2) they lack in their capacity to discern local outliers, and (3) their algorithmic efficacies markedly wane as datasets burgeon in sample point size and outlier prevalence. In addressing these formidable hurdles, we propose a novel, E scape V elocity-based adaptive O utlier D etection algorithm, noted as EVOD. The EVOD algorithm calculates the escape velocity of each data sample point and automatically detects the number of outliers by monitoring peak fluctuations in the growth rate of escape velocities of sample points, thereby solving the top-n problem suffered by existing outlier detection algorithms. Experimental results demonstrate that our algorithm, without requiring manual adjustment of parameters, can simultaneously detect global outliers, local outliers, and outlier clusters. In addition, it maintains a good performance even as the number of sample points and outliers in the dataset increases, particularly for complex manifold datasets.},
  archive      = {J_KBS},
  author       = {Juntao Yang and Lijun Yang and Dongming Tang and Tao Liu},
  doi          = {10.1016/j.knosys.2025.113116},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113116},
  shortjournal = {Knowl. Based Syst.},
  title        = {Escape velocity-based adaptive outlier detection algorithm},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal interactive learning dynamic adaptive graph convolutional network for traffic forecasting. <em>KBS</em>, <em>311</em>, 113115. (<a href='https://doi.org/10.1016/j.knosys.2025.113115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting plays a critical role in tasks such as route planning and traffic management. Recent advancements in graph neural networks have enabled the effective modeling of spatiotemporal correlations, significantly enhancing traffic prediction accuracy. However, most existing research primarily focuses on general spatiotemporal characteristics shared across all nodes, often neglecting the unique attributes of individual nodes. Additionally, these studies tend to overlook the diverse temporal features inherent in the data, limiting their ability to fully capture complex spatiotemporal dependencies. To tackle these challenges, this study introduces the Spatiotemporal Interactive Learning Dynamic Adaptive Graph Convolutional Network (SILDAGCN) for traffic forecasting. Specifically, SILDAGCN incorporates a data embedding module to integrate temporal features into the raw data and extract critical information effectively. Moreover, it employs a dynamic adaptive graph convolutional network designed to capture real-time spatiotemporal dynamics and uncover both shared and node-specific spatiotemporal correlations. This paper also introduces a spatiotemporal feature interaction learning mechanism designed to capture and learn the diverse, evolving characteristics of spatiotemporal dependencies, enabling mutual enhancement through effective feedback. Finally, the output block leverages convolutional operations to enhance the model’s information extraction capabilities, producing the final traffic network forecasts. Experimental evaluations on four real-world datasets demonstrate that SILDAGCN achieves accurate traffic flow and demand predictions with relatively low computational cost.},
  archive      = {J_KBS},
  author       = {Feng Jiang and Xingyu Han and Shiping Wen and Tianhai Tian},
  doi          = {10.1016/j.knosys.2025.113115},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113115},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatiotemporal interactive learning dynamic adaptive graph convolutional network for traffic forecasting},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimension rotations based on quaternion system for modeling various patterns in temporal knowledge graphs. <em>KBS</em>, <em>311</em>, 113114. (<a href='https://doi.org/10.1016/j.knosys.2025.113114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing information is a prevalent occurrence in temporal knowledge graphs (TKGs), and thus, TKG completion holds considerable importance. Modeling the diverse relational patterns inherent in TKGs is crucial for this process. However, existing methods mainly focus on pre-existing patterns within knowledge graphs while neglecting the influence of temporal information. It is common for multiple relationships to exist between two entities at the same moment, as well as for the same event to transpire at different timestamps. Existing models primarily rely on single or sequential transformations, rendering them inadequate for modeling these intricate patterns. To tackle these challenges, we propose a novel model, multi-dimension rotations based on quaternion system (MDRQS), that integrates the attention mechanism to fuse rotations of different dimensions for modeling interactions between entities. This complex combination of transformations, utilizing parallelization, enables the modeling of the aforementioned patterns through multi-dimensional rotations. The attention mechanism determines the most appropriate dimensional rotation for different facts at various timestamps. We demonstrate that MDRQS effectively models pre-existing and new patterns. Through experiments conducted on four benchmark datasets, the effectiveness of our model is shown in the link prediction task.},
  archive      = {J_KBS},
  author       = {Jun Zhu and Jiahui Hu and Di Bai and Yan Fu and Junlin Zhou and Duanbing Chen},
  doi          = {10.1016/j.knosys.2025.113114},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113114},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-dimension rotations based on quaternion system for modeling various patterns in temporal knowledge graphs},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IReGNN: Implicit review-enhanced graph neural network for explainable recommendation. <em>KBS</em>, <em>311</em>, 113113. (<a href='https://doi.org/10.1016/j.knosys.2025.113113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable recommendations can not only recommend items to users but also provide corresponding explanations, which is crucial for enhancing the transparency, credibility, and security of the system. Reviews, as an important information source for explainable recommendations, have received considerable attention. However, existing review-based explainable recommendations focus primarily on exploring user preferences and item features, as well as generating explanations from reviews, overlooking the limitations imposed by review sparsity on model performance. To address this issue, we propose an Implicit Review-enhanced Graph Neural Network (IReGNN) for explainable recommendations. Specifically, we construct a review network and a rating network, respectively. For the review network, we adopt an unsupervised approach to mine different topics of users and items, thereby enhancing node attribute representations. On the other hand, for the rating network, we extract implicit relationships between individuals and generate virtual reviews under the constraint of topics, which can effectively alleviate the data sparsity issue. Finally, we leverage a spatial graph neural network to learn node representations, generating accurate recommendations and high-quality explanations. Through a series of experiments on three publicly available datasets, results demonstrate that IReGNN outperforms eight baseline models in terms of rating prediction and explanation quality. Moreover, our model also has certain advantages in sparse data scenarios. The model and datasets are released at: https://github.com/SamuelZack/IReGNN.git .},
  archive      = {J_KBS},
  author       = {Qingbo Hao and Chundong Wang and Yingyuan Xiao and Wenguang Zheng},
  doi          = {10.1016/j.knosys.2025.113113},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113113},
  shortjournal = {Knowl. Based Syst.},
  title        = {IReGNN: Implicit review-enhanced graph neural network for explainable recommendation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain recommendation via knowledge distillation. <em>KBS</em>, <em>311</em>, 113112. (<a href='https://doi.org/10.1016/j.knosys.2025.113112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems frequently suffer from data sparsity, resulting in less-than-ideal recommendations. A prominent solution to this problem is Cross-Domain Recommendation (CDR), which employs data from various domains to mitigate data sparsity and cold-start issues. Nevertheless, current mainstream methods, like feature mapping and co-training exploring domain relationships, overlook latent user–user and user–item similarities in the shared user–item interaction graph. Spurred by these deficiencies, this paper introduces KDCDR, a novel cross-domain recommendation framework that relies on knowledge distillation to utilize the data from the graph. KDCDR aims to improve the recommendation performance in both domains by efficiently utilizing information from the shared interaction graph. Furthermore, we enhance the effectiveness of user and item representations by exploring the relationships between user–user similarity and item–item similarity, as well as user–item interactions. The developed scheme utilizes the inner-domain graph as a teacher and the cross-domain graph as a student, where the student learns by distilling knowledge from the two teachers after undergoing a high-temperature distillation process. Furthermore, we introduce dynamic weight that regulates the learning process to prevent the student network from overly favoring learning from one domain and focusing on learning knowledge that the teachers have taught incorrectly. Through extensive experiments on four real-world datasets, KDCDR demonstrates significant improvements over state-of-the-art methods, proving the effectiveness of KDCDR in addressing data sparsity issues and enhancing cross-domain recommendation performance. Our code and data are available at https://github.com/pandas-bondage/KDCDR .},
  archive      = {J_KBS},
  author       = {Xiuze Li and Zhenhua Huang and Zhengyang Wu and Changdong Wang and Yunwen Chen},
  doi          = {10.1016/j.knosys.2025.113112},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113112},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain recommendation via knowledge distillation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IFM: Integrating and fine-tuning adversarial examples of recommendation system under multiple models to enhance their transferability. <em>KBS</em>, <em>311</em>, 113111. (<a href='https://doi.org/10.1016/j.knosys.2025.113111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In black-box attack scenarios on recommendation systems, attackers typically rely on surrogate models to approximate the target model and use them to generate adversarial examples due to a lack of knowledge about the internal mechanisms of the target recommendation model. However, reliance on a single surrogate model often leads to adversarial examples that are prone to overfitting, making them vulnerable to local extremes and limiting their transferability across different models. Moreover, methods generating adversarial examples in flat minimum regions fail to consistently perform across diverse models. To address these limitations, this paper proposes a feature integration and fine-tuning framework, IFM, which aims to reduce the overfitting of adversarial examples and enhance their transferability. IFM captures a wider range of attack features by integrating the knowledge of multiple recommendation models and performs fine-tuning to further improve the transferability of the adversarial examples. Experimental results affirm that our approach markedly enhances the transferability of adversarial examples in recommendation systems over existing state-of-the-art techniques, enabling efficient attacks on recommendation models.},
  archive      = {J_KBS},
  author       = {Fulan Qian and Yan Cui and Mengyao Xu and Hai Chen and Wenbin Chen and Qian Xu and Caihong Wu and Yuanting Yan and Shu Zhao},
  doi          = {10.1016/j.knosys.2025.113111},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113111},
  shortjournal = {Knowl. Based Syst.},
  title        = {IFM: Integrating and fine-tuning adversarial examples of recommendation system under multiple models to enhance their transferability},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized recommendation by integrating a neural topic model and bayesian personalized ranking. <em>KBS</em>, <em>311</em>, 113110. (<a href='https://doi.org/10.1016/j.knosys.2025.113110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation systems typically sort items and provide users with top items by analyzing user–item interactions. Interactions vary from person to person because they are determined by personal intents and other environmental factors. However, these intents are implicit and difficult to capture because experimental data often contain plain user–item interactions. In this study, we proposed an attentive neural topic model ( ANTM ) to determine user latent intents and distinguish individual preferences. We first used the neural topic model in the natural language processing domain to discover user latent intents by encoding user–item interactions and jointly learned the model and variational parameters during inference. In addition, because of differences in user latent intents, we applied an attention mechanism to intents to obtain individual preferences. The representation of user features enriched by individual latent intents was then used to replace plain user profiles to provide personalized recommendations. Experimental results demonstrated that the proposed ANTM outperformed the best baseline algorithm by 1.09%–17.25% and 0.66%–10.38% in terms of the hit rate for recommending the top-5 and top-10 items, respectively. Moreover, its improvements over the best baseline algorithm were 0.69%–35.48% and 0.54%–15.48% in terms of normalized discounted cumulative gain in recommending the top-5 and top-10 items, respectively.},
  archive      = {J_KBS},
  author       = {Yixin Zhang and Sichen Lin and Zhili Zhao and Xuran Zhu and Chenbo He},
  doi          = {10.1016/j.knosys.2025.113110},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113110},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized recommendation by integrating a neural topic model and bayesian personalized ranking},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised category-enhanced graph neural networks for recommendation. <em>KBS</em>, <em>311</em>, 113109. (<a href='https://doi.org/10.1016/j.knosys.2025.113109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Graph Neural Networks (GNNs) has substantially advanced recommendation systems based on collaborative filtering. Despite their effectiveness, these networks are often susceptible to noise and sparsity problems from datasets. Thus, contrastive learning and knowledge graphs have been introduced as solutions to recommendation systems. However, both of these techniques have been incorporated into recommendation models as auxiliary tasks, neglecting the enhancement of node representations for the overall task. Therefore, we propose a novel contrastive learning method called C ategory- E nriched C ontrastive L earning ( CECL ) to obtain high-quality user–item interactions. Unlike previous studies, CECL does not introduce categories into the recommendation system as auxiliary supervised signals but uses them as direct supervised signals during model training. This directly supervised signal can enable the model to learn and emphasise category-specific patterns and relationships more efficiently, resulting in more accurate and stable user and item embeddings. By showing optimised category alignment, CECL improves representation quality. Specifically, we first construct initial embeddings for users and items based on the categories of user interactions and those to which items belong. Then, these embeddings are input into the recommendation model. The primary recommendation task is conducted in the supervised model. In the self-supervised model, contrastive pairs are constructed using edge dropout, and the consistency between different views of the same node is maximised to explore stable category preferences. Finally, multi-task training is applied to jointly optimise the recommendation and contrastive learning tasks. Comprehensive experiments conducted on eight real-world datasets validate the effectiveness of the proposed CECL. Compared with existing graph-enhanced methods, CECL achieves an average improvement of 15.17% in Recall@20 and 9.64% in NDCG@20 metrics. Our implementations are available at https://github.com/shark-art/Code .},
  archive      = {J_KBS},
  author       = {Funing Yang and Haihui Du and Xingliang Zhang and Yongjian Yang and Ying Wang},
  doi          = {10.1016/j.knosys.2025.113109},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113109},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised category-enhanced graph neural networks for recommendation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering matrix regularization guided hierarchical graph pooling. <em>KBS</em>, <em>311</em>, 113108. (<a href='https://doi.org/10.1016/j.knosys.2025.113108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical graph pooling effectively captures hierarchical structural information by iteratively simplifying the input graph into smaller graphs using a pooling function, which has demonstrated superior performance in graph-level tasks. However, existing methods often lack a detailed analysis of the pooling function, leading to issues such as noise, loss of essential information, and difficulties in balancing the retention and removal of graph details. In this paper, we address these challenges from an information theory perspective by analyzing information transmission through the clustering matrix within the pooling function. We introduce a novel approach, CMRGP, which is guided by clustering matrix regularization. This method enhances graph representations by selectively filtering task-relevant information from the input graph to create a compressed yet predictive clustering matrix. Specifically, we incorporate high-frequency information via the graph Laplacian matrix and introduce a dynamic gating mechanism to combine both high- and low-frequency information from graph nodes, improving the predictability of the clustering matrix. Additionally, we employ a noise injection technique, adding multivariate independent Gaussian noise to the clustering matrix to compress information and accurately define node category affiliations. Theoretical validation confirms the effectiveness of our approach. We conduct extensive experiments on datasets spanning social networks, biological proteins, and molecular chemistry, totaling 17,372 sample graphs. CMRGP achieves superior performance in graph-level classification, with an average accuracy improvement of 4.36–8.16% across six public datasets, including increases of 4.36% on DD and 8.16% on NCI1.},
  archive      = {J_KBS},
  author       = {Zidong Wang and Liu Yang and Tingxuan Chen and Jun Long},
  doi          = {10.1016/j.knosys.2025.113108},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113108},
  shortjournal = {Knowl. Based Syst.},
  title        = {Clustering matrix regularization guided hierarchical graph pooling},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALGGNet: An adaptive local-global-graph representation network for brain-computer interfaces. <em>KBS</em>, <em>311</em>, 113096. (<a href='https://doi.org/10.1016/j.knosys.2025.113096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain is a complex system comprising neurons, local circuits, and functional regions. Neural pathways link various regions and collaborate to accomplish intricate cognitive and behavioral functions. To investigate brain activity within and between functional regions, we propose an adaptive local-global graph representation network (ALGGNet). This network suits brain-computer interface (BCI) applications, including the decoding of motor imagery electroencephalogram (EEG) signals and emotion recognition. ALGGNet consists of three essential components: the adaptive local region partitioning block, the temporal learning block, and the graph learning block. First, we adopt the concept of brain functional regions in neuroscience and employ the double clustering algorithm to generate brain-like functional regions for specific data sets adaptively. The EEG channels are then reordered according to the clustering results. Subsequently, the EEG signal passes through the time information processing stage and the graph learning stage. The time information processing stage mainly includes a multi-scale temporal convolution block and a feature mapping block with a coordinate attention (CA) mechanism. The graph learning stage includes graph filters that aggregate information about local regions and global graph convolutional networks (GCNs) that learn complex relationships between local regions. We conduct experiments on the motor imagery dataset and the emotion recognition dataset, respectively, and the results show that the proposed network obtains state-of-the-art performance. Additionally, we perform many ablation experiments, parameter tuning experiments, and visualization experiments to demonstrate the proposed ALGGNet better.},
  archive      = {J_KBS},
  author       = {Wenlong Wang and Baojiang Li and Xiuyun Liu and Xingbin Shi and Yuxin Qin and Haiyan Wang and Xichao Wang},
  doi          = {10.1016/j.knosys.2025.113096},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113096},
  shortjournal = {Knowl. Based Syst.},
  title        = {ALGGNet: An adaptive local-global-graph representation network for brain-computer interfaces},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining multimodal CNN-DNN model predictions for quality monitoring of porosity in laser metal deposition. <em>KBS</em>, <em>311</em>, 113095. (<a href='https://doi.org/10.1016/j.knosys.2025.113095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart manufacturing integrates advanced technologies to create efficient and adaptable production processes. A key component of this paradigm is additive manufacturing (AM), specifically Laser Metal Deposition (a metal-based AM process), which enables the production of complex, high-precision parts. However, ensuring the quality of parts, especially in preventing porosity defects, remains a significant challenge. Novel physics-informed multimodal deep learning models were developed to leverage the complementary strengths of physics and data-driven models. The method combines in-process sensor data with physical principles to improve porosity prediction accuracy. Key hyperparameter impacts on model performance were determined using ablation analysis with functional analysis of variance (fANOVA). Despite their effectiveness, these models lack interpretability, hindering their practical application. This study introduces explainable deep learning models that not only enhance prediction accuracy but also provide transparency in their decision-making process through SHapley Additive exPlanations (SHAP)-inspired explanations. Quantitative metrics (Relevancy, Discernability, and Stability) are developed to evaluate the usefulness of the explanations provided by the explainable model, enabling a comparison between the printing process characteristics and the patterns identified by the deep learning model. This approach ensures predictions align with physical principles, building trust and encouraging wider use of deep learning in quality monitoring and prediction for smart manufacturing. © Elsevier Science. All rights reserved},
  archive      = {J_KBS},
  author       = {Vidita Gawade and Mengfei Chen},
  doi          = {10.1016/j.knosys.2025.113095},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113095},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explaining multimodal CNN-DNN model predictions for quality monitoring of porosity in laser metal deposition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HebCGNN: Hebbian-enabled causal classification integrating dynamic impact valuing. <em>KBS</em>, <em>311</em>, 113094. (<a href='https://doi.org/10.1016/j.knosys.2025.113094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying graph-structured data presents significant challenges due to the diverse features of nodes and edges and their complex relationships. While Graph Neural Networks (GNNs) are widely used for graph prediction tasks, their performance is often hindered by these intricate dependencies. Leveraging causality holds potential in overcoming these challenges by identifying causal links among features, thus enhancing GNN classification performance. However, depending solely on adjacency matrices or attention mechanisms, as commonly studied in causal prediction research, is insufficient for capturing the complex interactions among features. To address these challenges, we present HebCGNN , a Hebbian-enabled Causal GNN classification model that incorporates dynamic impact valuing . Our method creates a robust framework that prioritizes causal elements in prediction tasks. Extensive experiments on seven publicly available datasets across diverse domains demonstrate that HebCGNN outperforms state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Simi Job and Xiaohui Tao and Taotao Cai and Lin Li and Haoran Xie and Cai Xu and Jianming Yong},
  doi          = {10.1016/j.knosys.2025.113094},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113094},
  shortjournal = {Knowl. Based Syst.},
  title        = {HebCGNN: Hebbian-enabled causal classification integrating dynamic impact valuing},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph anomaly detection via diffusion enhanced multi-view contrastive learning. <em>KBS</em>, <em>311</em>, 113093. (<a href='https://doi.org/10.1016/j.knosys.2025.113093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Anomaly Detection (GAD) is of critical importance in areas such as cybersecurity, finance, and healthcare. Detecting anomalous nodes in graph data is a challenging task due to intricate interactions and attribute inconsistencies. Existing methods often distinguish anomalous nodes by using contrasting strategies at various scales. However, they overlook the enhancement methods of positive and negative sample pairs in the contrastive learning process, which can have a significant impact on the robustness and accuracy of the model. To address these limitations, we propose an innovative contrastive self-supervised approach called Diffusion Enhanced Multi-View Contrastive Learning (DE-GAD), which jointly optimizes a diffusion-based enhancement module and a multi-view contrastive learning-based module to better identify anomalous information. Specifically, in the diffusion-based enhancement module, we use the noise addition and stepwise denoising outputs of the diffusion model to enhance the original graphs, and use the loss of reconstruction to the original graphs as one of the criteria for anomaly detection. Second, in the multi-view contrastive module, we establish three contrastive views, namely node–node contrast, node–subgraph contrast, and subgraph–subgraph contrast, to enable the model to better capture the underlying relationships of graph nodes and thereby identify anomalies in the structural space. Finally, two complementary modules and their corresponding losses are integrated to detect anomalous nodes more accurately. Empirical experiments conducted on six benchmark datasets demonstrate the superiority of our proposed approach over existing methods.},
  archive      = {J_KBS},
  author       = {Xiangjie Kong and Jin Liu and Huan Li and Chenwei Zhang and Jiaxin Du and Dongyan Guo and Guojiang Shen},
  doi          = {10.1016/j.knosys.2025.113093},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113093},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph anomaly detection via diffusion enhanced multi-view contrastive learning},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards consistency of rule-based explainer and black box model — Fusion of rule induction and XAI-based feature importance. <em>KBS</em>, <em>311</em>, 113092. (<a href='https://doi.org/10.1016/j.knosys.2025.113092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based models offer a human-understandable representation, i.e. they are interpretable. For this reason, they are used to explain the decisions of non-interpretable complex models, referred to as black box models. The generation of such explanations involves the approximation of a black box model by a rule-based model. To date, however, it has not been investigated whether the rule-based model makes decisions in the same way as the black box model it approximates. Decision making in the same way is understood in this work as the consistency of decisions and the consistency of the most important attributes used for decision making. This study proposes a novel approach ensuring that the rule-based surrogate model mimics the performance of the black box model. The proposed solution performs an explanation fusion involving rule generation and taking into account the feature importance determined by the selected XAI methods for the black box model being explained. The result of the method can be both global and local rule-based explanations. The quality of the proposed solution was verified by extensive analysis on 30 tabular benchmark datasets representing classification problems. Evaluation included comparison with the reference method and an illustrative case study. In addition, the paper discusses the possible pathways for the application of the rule-based approach in XAI and how rule-based explanations, including the proposed method, meet the user perspective and requirements for both content and presentation. The software created and a detailed report containing the full experimental results are available on the GitHub repository ( https://github.com/ruleminer/FI-rules4XAI ).},
  archive      = {J_KBS},
  author       = {Michał Kozielski and Marek Sikora and Łukasz Wawrowski},
  doi          = {10.1016/j.knosys.2025.113092},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113092},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards consistency of rule-based explainer and black box model — Fusion of rule induction and XAI-based feature importance},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structured reasoning and answer verification: Enhancing question answering system accuracy and explainability. <em>KBS</em>, <em>311</em>, 113091. (<a href='https://doi.org/10.1016/j.knosys.2025.113091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of question-answering (QA) models has significantly advanced, yet challenges remain in verifying the accuracy of generated answers and providing clear explanations of the reasoning behind them. In response, this study introduces a novel answer verification model that detects inaccuracies in QA system outputs and offers structured, multi-step explanations to enhance both understanding and reliability. We built an answer verification system consisting of a stepwise prover and two types of verifiers and tested the proposed system on the EntailmentBank dataset as well as the ARC, AQUA-RAT, and AR-LSAT datasets from the STREET benchmark. By correcting the answers generated by the T5-large and GPT-3.5 QA models and comparing the results before and after correction, we observed notable improvements in answer accuracy and explanation clarity. Specifically, the proposed model increased the exact match score of the T5-large model by 1.76% and that of GPT-3.5 by 3.53% on the EntailmentBank dataset. Additionally, to address potential data scarcity, the study proposes a data augmentation technique that employs large language models and multi-hop datasets to generate reasoning chains, thereby enriching the training data. Although the augmented data did not match the quality of the gold data, which is manually curated and verified by humans, our experiments demonstrated that combining gold data with augmented data resulted in better performance than using only a subset of the gold data.},
  archive      = {J_KBS},
  author       = {Jihyung Lee and Gary Geunbae Lee},
  doi          = {10.1016/j.knosys.2025.113091},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113091},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structured reasoning and answer verification: Enhancing question answering system accuracy and explainability},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JAMC: A jigsaw-based autoencoder with masked contrastive learning for cardiovascular disease diagnosis. <em>KBS</em>, <em>311</em>, 113090. (<a href='https://doi.org/10.1016/j.knosys.2025.113090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) is a prevalent approach in the diagnosis of cardiovascular diseases. It leverages unlabeled ECG data for pre-training and thus alleviates the reliance on manual annotations. However, existing self-supervised methods tend to focus on either global or local features, hindering the integrated consideration of the global spatial relationships indicated by leads and the local cardiac activity information. To address this problem, a jigsaw-based autoencoder with masked contrastive learning (JAMC) is proposed. The model merges instance discrimination-based contrastive learning with jigsaw-based reconstruction task. This merge allows for simultaneous attention to the global invariant features and local detail features of the signals. In addition, lead, temporal, and mixed jigsaw transformations are applied, which rely on the contrast between different views to enable the model to synthesize the spatial position of each lead and the temporal features of ECG segments. The comparison of the three techniques highlights the impact of spatial lead structure and temporal dependencies on feature learning. To further emphasize local lead correlations, another lead mask transformation is introduced. It infers missing lead information from the remaining leads, promoting a focus on local features to certain regions of the heart. JAMC learns morphological, temporal, and spatial physiological features of ECG signals from both global and local perspectives. In contrast to existing methods, it demonstrates increases in F1-macro by 7.26% and 17.29% on the Chapman and the CPSC2018 dataset, respectively. The method explores a universal SSL framework that combines generative and contrastive tasks, demonstrating exceptional performance. This framework holds potential application value in the field of ECG signal classification and diagnosis.},
  archive      = {J_KBS},
  author       = {Yue Ge and Huaicheng Zhang and Jiguang Shi and Deyu Luo and Sheng Chang and Jin He and Qijun Huang and Hao Wang},
  doi          = {10.1016/j.knosys.2025.113090},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113090},
  shortjournal = {Knowl. Based Syst.},
  title        = {JAMC: A jigsaw-based autoencoder with masked contrastive learning for cardiovascular disease diagnosis},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WFFS—An ensemble feature selection algorithm for heterogeneous traffic accident data analysis. <em>KBS</em>, <em>311</em>, 113089. (<a href='https://doi.org/10.1016/j.knosys.2025.113089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents are unexpected incidents where one or multiple vehicles collide and damage properties, dying or injuring many individuals. It causes significant social burdens, including loss of life, serious injuries, and economic suppression from medical costs, property damages, and productivity losses. This kind of incident brings a miserable situation for the affected people. Many factors, including infrastructure, weather, vehicles, or driver-related issues, contribute to happening traffic accidents. This work explores an innovative approach by investigating contributing factors to ensure road safety. In this study, an ensemble machine learning model, namely Weighted Fusion-Based Feature Selection (WFFS), was proposed to identify different significant features to reduce the effects of traffic accidents. A large amount of traffic accident records from the United Kingdom (UK) were gathered and split into several folds, which were cleaned and balanced using different techniques such as removing percentages, Synthetic Minority Oversampling Technique (SMOTE), and random oversampling. Then, WFFS were employed in each fold and identified the most significant features to predict traffic accident severity more accurately. Different classifiers, such as tree-based, bagging, boosting, and voting classifiers, were implemented into WFFS-generated feature subsets and performed better than primary data and other feature subsets. In this case, the random tree-based bagging method provided the highest accuracy of 97.28% to predict accident severity for the WFFS subset, where its number of features is 18. However, different classifiers achieved better accuracies for 6 out of 11 times using WFFS. This method is highly recommended for policymakers and transportation engineers to identify potentially hazardous locations and take appropriate measures to diminish the effects of traffic accidents.},
  archive      = {J_KBS},
  author       = {Alimul Rajee and Md. Shahriare Satu and Mohammad Zoynul Abedin and K.M. Akkas Ali and Saad Aloteibi and Mohammad Ali Moni},
  doi          = {10.1016/j.knosys.2025.113089},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113089},
  shortjournal = {Knowl. Based Syst.},
  title        = {WFFS—An ensemble feature selection algorithm for heterogeneous traffic accident data analysis},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based imputation framework for bridge health monitoring using generative adversarial networks. <em>KBS</em>, <em>311</em>, 113088. (<a href='https://doi.org/10.1016/j.knosys.2025.113088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Structural Health Monitoring (SHM) systems, accurate sensor measurements are essential for assessing structural conditions and performance. However, data loss due to transmission failures or sensor malfunctions can significantly undermine these assessments. To encounter this issue, researchers have explored various strategies, from discarding incomplete data to leveraging artificial intelligence for imputing missing data. Among these, deep learning-based methods have shown potential but are frequently hindered by the requirement for extensive, complete datasets, intricate architectures, and limited adaptability within the structural mechanics domain, resulting in computational inefficiencies for SHM applications. To address these limitations, this study presents the Modified Generative Adversarial Imputation Network (MGAIN), an advanced framework for full-field sensor data recovery across both time and frequency domains, assuming all sensors contribute to data missingness. By adjusting the generator-discriminator architecture and optimizing both the loss and activation functions, MGAIN achieves greater robustness while reducing computational demands. Efficiency and performance of the proposed framework are evaluated using six various sensor datasets obtained during full-scale monitoring of the steel railway bridge KW51 in Belgium. Comparative studies across different batch sizes, iteration numbers, and missing rates, including high missing rates up to 90%, demonstrate that MGAIN outperforms two state-of-the-art generative adversarial network (GAN)-based imputation frameworks, GAIN, and SGAIN, in terms of computational efficiency and imputation accuracy. These results underscore MGAIN's potential to significantly enhance the robustness of missing data imputation in SHM systems, thereby supporting more accurate structural condition assessments.},
  archive      = {J_KBS},
  author       = {Sumit Saha and Krishn Katyal and Surendra Nadh Somala},
  doi          = {10.1016/j.knosys.2025.113088},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113088},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning-based imputation framework for bridge health monitoring using generative adversarial networks},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge guided deep deterministic policy gradient. <em>KBS</em>, <em>311</em>, 113087. (<a href='https://doi.org/10.1016/j.knosys.2025.113087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep deterministic policy gradient (DDPG) exhibits excellent handling capabilities for complex regulation and control problems with continuous state and action spaces. However, its trial-and-error interaction and learning from scratch require extensive exploration by the agent, leading to low learning efficiency and even non-convergence in sparse reward environments. To fully utilize knowledge during the learning process to improve efficiency and performance, this paper draws inspiration from human learning methods and proposes a semantic knowledge-guided DDPG (KGDDPG) approach. In terms of knowledge representation, considering the fuzziness and precision of semantic knowledge, a knowledge system based on a rule framework combining precise propositions and fuzzy propositions is constructed. In terms of knowledge integration, to reduce the randomness of exploration, a knowledge-guided action strategy based on stacked generalization is proposed. Furthermore, a supervised-then-reinforced learning method is employed: the ”supervised” phase quickly incorporates prior knowledge to accelerate learning, while the ”reinforced” phase refines the policy network to overcome the limitations of relying solely on prior knowledge. Finally, experiments were conducted using a mapless navigation task for mobile robots to verify the effectiveness and practical feasibility of the method.},
  archive      = {J_KBS},
  author       = {Peng Qin and Tao Zhao},
  doi          = {10.1016/j.knosys.2025.113087},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113087},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge guided deep deterministic policy gradient},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TML-DA: Transfer metric learning based distribution alignment framework for domain class imbalanced classification. <em>KBS</em>, <em>311</em>, 113086. (<a href='https://doi.org/10.1016/j.knosys.2025.113086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonrandom and biased sampling can lead to class imbalance and distribution mismatch issues between domains. Most existing methods sequentially address these issues by combining resampling strategies with transfer learning. However, these approaches typically focus only on the class imbalance within a single domain and overlook the imbalance across domains. To tackle both domain class imbalance and distribution mismatch problems, this paper proposes a transfer metric learning-based distribution alignment (TML-DA) framework, designed for homogeneous and transductive transfer learning. First, the importance-based transfer metric learning module constructs a transfer metric network with an importance parameter, which learns domain-invariant feature representations of source and target data under the domain class imbalance by increasing its within-class coherence and between-class difference. Then, the target domain label prediction module predicts more accurate labels for the unlabeled target data by leveraging inter-domain distance similarity, offering an improvement over traditional probabilistic prediction methods. Finally, the domain distribution alignment module minimizes both marginal and conditional distribution discrepancies while maximizing within-class coherence and between-class difference. This ensures that the learned transfer metric network generalizes more effectively from the source to the target domain. The proposed TML-DA has been evaluated on the long-tailed USPS+MNIST and Office+Caltech public datasets, delivering superior performance and generalization ability in addressing the domain class imbalance classification of the unlabeled target domain data.},
  archive      = {J_KBS},
  author       = {Mi Yan and Na Jiang and Ning Li},
  doi          = {10.1016/j.knosys.2025.113086},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113086},
  shortjournal = {Knowl. Based Syst.},
  title        = {TML-DA: Transfer metric learning based distribution alignment framework for domain class imbalanced classification},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting active learning via re-aligned feature space. <em>KBS</em>, <em>311</em>, 113085. (<a href='https://doi.org/10.1016/j.knosys.2025.113085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) aims to reduce the annotation labor required for data annotation in deep learning by selecting the most informative samples from unlabeled data. Traditional AL methods typically evaluate sample informativeness based on either uncertainty or diversity, with some hybrid approaches combining both to enhance performance. However, these hybrid methods often overlook the fundamental differences between uncertainty-based and diversity-based strategies, which can lead to suboptimal results. To address this limitation, we propose a central metric for uncertainty measurement based on feature positions, aligning it more closely with diversity-based approaches. We provide a theoretical analysis for using feature distance as an uncertainty metric, allowing for a smooth integration with diversity-driven methods. Additionally, we introduce a novel loss function, built on class centroids, that re-aligns the feature space by incorporating two margins to support the proposed uncertainty evaluation framework. In this re-aligned feature space, we merge our uncertainty evaluation technique with the diversity-based core-set selection approach, resulting in a hybrid model called “center-aware active learning”. We demonstrate the effectiveness of our method through extensive experiments on CIFAR-10, CIFAR-100, Caltech101, Caltech256, and TinyImageNet datasets for the classification task, and the results demonstrate the superiority of our proposed method.},
  archive      = {J_KBS},
  author       = {Tianxiang Yin and Ningzhong Liu and Han Sun and Shifeng Xia},
  doi          = {10.1016/j.knosys.2025.113085},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113085},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boosting active learning via re-aligned feature space},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Object tracking using optimized dual interactive wasserstein generative adversarial network from surveillance video. <em>KBS</em>, <em>311</em>, 113084. (<a href='https://doi.org/10.1016/j.knosys.2025.113084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking in videos is crucial for applications such as video analytics, video surveillance, and intelligent transportation systems. Despite important advancements, challenges like occlusions, background noise, variable object counts, and object appearance similarity still hinder effective tracking. To overcome these complications, Object Tracking using Optimized Dual Interactive Wasserstein Generative Adversarial Network from Surveillance Video (OTSV-DWGAN-GPCOA) is proposed . The input data is collected from the Moving Objects Video Clips Dataset. During the Pre-Processing Phase , noise removal and background subtraction are performed using Anisotropic Diffusion Kuwahara Filtering (ADKF) , transforming the surveillance video clips into unique frames for analysis. In the Moving Object Detection Phase , Residual Exemplars Local Binary Pattern (RELBP) is utilized to extract morphological features such as size, texture, color, intensity, shape, and contrast. Additionally, Adaptive Density-Based Spatial Clustering (ADSC) is employed to detect moving objects. In the Moving Object Tracking Phase , the Giza Pyramids Construction Optimization Algorithm (GPCOA) optimizes the parameters of the DWGAN to improve tracking accuracy. Once objects are successfully tracked, the output represents the tracking steps. In the final phase, Moving Object Prediction utilizes the Minkowski Distance Metric to predict the position of tracked objects in each frame. The OTSV-DWGAN-GPCOA method is implemented in Python and assessed using performance metrics. The method achieves 20.11 %, 24.16 % and 22.23 % higher accuracy, 22.45 %, 19.34 % and 24.22 % higher Tracking rate analyzed with existing techniques such asMOD-YOLOv2-SV,ODL-CNN-MRCED, and AR-SSN-VSSC respectively .},
  archive      = {J_KBS},
  author       = {Karthik Srinivasan},
  doi          = {10.1016/j.knosys.2025.113084},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113084},
  shortjournal = {Knowl. Based Syst.},
  title        = {Object tracking using optimized dual interactive wasserstein generative adversarial network from surveillance video},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understand and detect: Multi-step zero-shot detection with image-level specific prompt. <em>KBS</em>, <em>311</em>, 113083. (<a href='https://doi.org/10.1016/j.knosys.2025.113083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large-scale pre-trained vision-language models (VLMs) has led to new deep learning paradigms. Techniques such as Vision-Language Model Pre-training and Zero-shot Prediction are now widely applied to visual recognition tasks. These include applications like zero-shot object detection. Despite their potential, existing VLM-based methods typically treat object detection as a phrase grounding task, relying on a single prompt that encompasses all object labels to be localized. This approach often leads to significant hallucinations and errors. To address these challenges, it is crucial to improve how VLMs interpret and extract knowledge from each image. By achieving a more precise alignment between textual and visual modalities, VLMs can enhance inference accuracy. In this paper, we introduce an “Understand and Detect” pipeline that decomposes traditional detection precesses into multiple steps, generating image-specific prompts tailored to each scenario. Extensive experiments conducted on five public natural image datasets across diverse scenarios highlight the superior detection accuracy of our approach.},
  archive      = {J_KBS},
  author       = {Miaotian Guo and Kewei Wu and Zhuqing Jiang and Haiying Wang and Aidong Men},
  doi          = {10.1016/j.knosys.2025.113083},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113083},
  shortjournal = {Knowl. Based Syst.},
  title        = {Understand and detect: Multi-step zero-shot detection with image-level specific prompt},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled sparse graph attention networks with multi-intent fusion for session-based recommendation. <em>KBS</em>, <em>311</em>, 113082. (<a href='https://doi.org/10.1016/j.knosys.2025.113082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based Recommendation has garnered considerable interests recently due to providing personalized recommendations based on anonymous behavior sequences. Most of existing models learn user preferences from a holistic perspective without delving into the key factors that drive user–item interactions. This results in an insufficient capture of user intent, as they rely solely on session data for predictions. Additionally, these models are more susceptible to the negative impact of noise on account of the limited short-term interactions. To tackle these problems, we propose a novel model called D isentangled S parse G raph Attention Networks with M ulti- I ntent F usion for Session-based Recommendation to learn item embeddings from factor level and model user intent for better inferring the user preferences. Specifically, we map item embeddings into multiple factors using disentanglement techniques and utilize gated graph neural network to learn the embeddings based on the item adjacent similarity matrix calculated for each factor. An innovative position information generation module is designed to encode the order of items. Subsequently, we model user intent from three perspectives and apply intent-aware fusion module to integrate them into a unified intent representation for incorporating intent information into the current session. Sparse attention networks are employed to denoise and extract the intent pattern of the current session. Furthermore, sessions exhibiting similar intent pattern are identified to augment the representation of the current session. Extensive experiments on five datasets indicate that our model outperforms state-of-the-art methods consistently.},
  archive      = {J_KBS},
  author       = {Yifeng Wang and Jihua Zhu and Liang Duan and Ansong Li and Jiarun Sun and Chaoyu Wang and Zhaolong Li},
  doi          = {10.1016/j.knosys.2025.113082},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113082},
  shortjournal = {Knowl. Based Syst.},
  title        = {Disentangled sparse graph attention networks with multi-intent fusion for session-based recommendation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCMnet: A cluster-level contrastive cross-domain framework for GIS insulation defects diagnosis. <em>KBS</em>, <em>311</em>, 113081. (<a href='https://doi.org/10.1016/j.knosys.2025.113081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven intelligent diagnosis of insulation defects, based on partial discharge signal, is an efficient strategy for evaluating the safety of gas-insulated switchgear (GIS). However, the robustness of the intelligent model is menaced by the discrepancy between the training dataset and unlabeled datasets in unpredictable scenarios. Herein, we propose a novel learning framework, i.e., Contrastive Cluster-prototypical Matching Networks (CCMnet), which significantly enhances model robustness. This framework enables the model to extract finer-grained class-discriminative features by integrating cluster contrastive learning (CCL) and cluster subdomain feature alignment. In CCL, class-specific features and the mutual information between cluster prototype and classes are enhanced by reducing intra-cluster variance and increasing inter-cluster separation. Subsequently, cluster-subdomain feature alignment, based on statistical moment, is adopted to transfer class-discriminative information across domains. Consequently, CCMnet outperforms six classical methods in terms of accuracy, stability, and robustness across six cross-domain tasks. Notably, the model demonstrates an average accuracy improvement of 8.29 %–19.3 %. This work introduces new strategies for improving the robustness of GIS insulation defects model in unpredictable scenarios.},
  archive      = {J_KBS},
  author       = {Song Yu and Rui Wang and Bin Gou and Jigang Wang and Yujie Zhu and An Zhong and Baisen Lin and Weiwen Chen and Congzhen Xie},
  doi          = {10.1016/j.knosys.2025.113081},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113081},
  shortjournal = {Knowl. Based Syst.},
  title        = {CCMnet: A cluster-level contrastive cross-domain framework for GIS insulation defects diagnosis},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COSDA: Covariance regularized semantic data augmentation for self-supervised visual representation learning. <em>KBS</em>, <em>311</em>, 113080. (<a href='https://doi.org/10.1016/j.knosys.2025.113080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent contrastive learning-based self-supervised learning has seen significant improvements through employing an extensive data augmentation strategy, particularly focusing on the generation of positive pairs. However, the current techniques primarily operate at the pixel level, confined to basic spatial and color transformations, thus lacking the capability to incorporate more complex semantic alterations such as object repositioning, rotation, or color modification within the image. Consequently, the resultant positive pairs are less informative for learning features that are invariant to such semantic variations. In this work, we introduce a new methodology termed COvariance Regularized Semantic Data Augmentation (COSDA), designed to generate a diverse collection of feature embeddings that serve as positives relative to an anchor point. These generated features are intended to possess distinct semantic characteristics from the anchor point while maintaining consistent category identities, accomplished through Gaussian sampling in the deep feature space. By theoretically analyzing the scenario where the number of generated positive features approaches infinity, we establish an upper bound for the InfoNCE loss and optimize this bound without explicit feature generation. Rigorous experimental assessments, conducted on datasets of varying scales, alongside downstream tasks encompassing detection and segmentation, corroborate the efficacy of COSDA.},
  archive      = {J_KBS},
  author       = {Hui Chen and Yongqiang Ma and Jingjing Jiang and Nanning Zheng},
  doi          = {10.1016/j.knosys.2025.113080},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113080},
  shortjournal = {Knowl. Based Syst.},
  title        = {COSDA: Covariance regularized semantic data augmentation for self-supervised visual representation learning},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-lingual distillation for domain knowledge transfer with sentence transformers. <em>KBS</em>, <em>311</em>, 113079. (<a href='https://doi.org/10.1016/j.knosys.2025.113079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Natural Language Processing (NLP) have substantially enhanced language understanding. However, non-English languages, especially in specialized and low-resource domains like biomedicine, remain largely underrepresented. Bridging this gap is essential for promoting inclusivity and expanding the global applicability of NLP technologies. This study presents a cross-lingual knowledge distillation framework that utilizes sentence transformers to improve domain-specific NLP capabilities in non-English languages. Specifically, the framework focuses on biomedical text classification tasks. By aligning sentence embeddings between a teacher model trained on English biomedical corpora and a multilingual student model, the proposed method effectively transfers both domain-specific and task-specific knowledge. This alignment allows the student model to efficiently process and adapt to biomedical texts in Spanish, French, and German, particularly in low-resource settings with limited tuning data. Extensive experiments with domain-adapted models like BioBERT and multilingual BERT with machine-translated text pairs demonstrate substantial performance improvements in downstream biomedical NLP tasks. The proposed framework proves highly effective in scenarios characterized by limited training data availability. The results highlight the scalability and effectiveness of this approach, facilitating the development of robust multilingual models tailored to the biomedical domain, thus advancing global accessibility and impact in biomedical NLP applications.},
  archive      = {J_KBS},
  author       = {Ruben Piperno and Luca Bacco and Felice Dell’Orletta and Mario Merone and Leandro Pecchia},
  doi          = {10.1016/j.knosys.2025.113079},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113079},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-lingual distillation for domain knowledge transfer with sentence transformers},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised hybrid contrastive learning for PolSAR image classification. <em>KBS</em>, <em>311</em>, 113078. (<a href='https://doi.org/10.1016/j.knosys.2025.113078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been widely applied in polarimetric synthetic aperture radar (PolSAR) image classification. However, these methods require abundant labeled data to achieve satisfactory performance, and it requires considerable effort to obtain a good deal of labeled data in practice, which requires huge human and resources. To tackle these issues, a new semi-supervised hybrid contrastive learning (SSHCL) is proposed for PolSAR image classification of finite labeled data. First, a hybrid contrastive learning model is constructed to extract feature information using only a handful of labeled data and unlabeled data. Second, combined with the idea of semi-supervised learning, a semi-supervised samples selection method is proposed. The pseudo-labeled samples are selected from unlabeled samples by combining superpixel and contrastive similarity, and are included in the label dataset. Then, the extended labeled samples are used to train the network for a new round. Finally, the optimized SSHCL network is used to classify the pixels of the whole image. The experimental outcomes conducted on three real PolSAR datasets demonstrate that the superior performance of the proposed compared to other existing methods under finite labeled data.},
  archive      = {J_KBS},
  author       = {Wenqiang Hua and Nan Sun and Lin Liu and Chen Ding and YiZhuo Dong and Wei Sun},
  doi          = {10.1016/j.knosys.2025.113078},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113078},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semi-supervised hybrid contrastive learning for PolSAR image classification},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image classification based on enhanced learning of global and local features with structural priors. <em>KBS</em>, <em>311</em>, 113077. (<a href='https://doi.org/10.1016/j.knosys.2025.113077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have become a popular paradigm in image classification and defect diagnosis. The texture is considered one of the key factors affecting the performance of the convolutional neural networks and Transformers in classification tasks. In some application scenarios, the shape plays a greater role and affects the generalization ability of the deep models. Therefore, this work proposes a structure-aware feature enhancement module to improve the perceptual ability of inherent structure priors. Meanwhile, to better motivate the network to understand the structural information, a novel feature fusion module is introduced, whose ability to operate based on the frequency domain information can sense the structural priors from a macroscopic point of view and fuse it into the backbone network more effectively. Numerical experiments on a smaller Imagenet and a hand-collected glass insulator defect dataset validate the effectiveness and generalization capabilities of the proposed solution.},
  archive      = {J_KBS},
  author       = {Yuan Cao and Di Jiang and Qiang Yang},
  doi          = {10.1016/j.knosys.2025.113077},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113077},
  shortjournal = {Knowl. Based Syst.},
  title        = {Image classification based on enhanced learning of global and local features with structural priors},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating image representation and texture feature for sensor-based gymnastics activity recognition. <em>KBS</em>, <em>311</em>, 113076. (<a href='https://doi.org/10.1016/j.knosys.2025.113076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based gymnastics activity recognition has been a hot topic in recent years. Accurate gymnastics activity recognition plays a crucial role in monitoring athlete performance and preventing sports injuries. However, current gymnastics recognition methods lack sufficient interpretability and cannot fully utilize the information of time series data from sensors. Therefore, we propose a gymnastics activity recognition scheme based on image representation and visual texture feature extraction methods. The framework is mainly divided into four parts: image generation, image concentration, texture feature and reduction, and classification. Firstly, we established a gymnastics activity recognition system based on wearable sensors, which can collect acceleration information and transmit it to a host computer. Secondly, a maximum scale distance-based criterion (MSD) and four concentration strategies are proposed to obtain the final optimal wavelet scalogram of four concentration strategies. Thirdly, we propose for the first time that texture can be used to represent the feature information of wavelet scalogram, and we introduce a new texture feature extraction algorithm to obtain features from different directions along the time and scale axis. We also discuss the impact of different sampling intervals on recognition accuracy. Experimental results show that the proposed method achieves a recognition accuracy of 99.11%, with a Precision of 99.13%, Recall of 99.11%, and F1-score of 99.11%. These metrics represent a significant improvement, with accuracy at least 4.53% higher than machine learning methods with feature extraction, and 1.79% higher than end-to-end deep learning methods. This study provides an effective paradigm for activity recognition and has the potential for extension to other sports and real-time motion analysis applications.},
  archive      = {J_KBS},
  author       = {Chao Lian and Yuliang Zhao and Tianang Sun and Jinliang Shao and Yinghao Liu and Changzeng Fu and Xiaoyong Lyu and Zhikun Zhan},
  doi          = {10.1016/j.knosys.2025.113076},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113076},
  shortjournal = {Knowl. Based Syst.},
  title        = {Incorporating image representation and texture feature for sensor-based gymnastics activity recognition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-sensor contrastive learning-based pre-training for machinery fault diagnosis under sample-limited conditions. <em>KBS</em>, <em>311</em>, 113075. (<a href='https://doi.org/10.1016/j.knosys.2025.113075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, data-driven approaches have been extensively used in fault diagnosis. However, most existing methods are based on single-sensor fault data, which is hard to suit for complex industrial systems. Extracting complementary fault features from multi-sensor monitoring data is imperative, especially under limited labeled samples. Inspired by the success of self-supervised learning in handling unlabeled data, we propose a cross-sensor contrastive learning-based pre-training method for machinery fault diagnosis under sample-limited conditions. In the initial pre-training phase, we introduce an innovative cross-sensor contrastive framework to capture complementary features among different sensors for enhancing the acquisition of discriminative fault features. Then, in the fine-tuning phase, a novel cross-sensor interactive attention is designed for effective feature fusion to provide a more robust feature representation. The proposed method is validated on three benchmark datasets, demonstrating superior diagnostic performance under limited labeled samples and well-adapted to different working conditions.},
  archive      = {J_KBS},
  author       = {Hao Hu and Yue Ma and Ruoxue Li and Zhixi Feng and Shuyuan Yang and Shaoyi Du and Yue Gao},
  doi          = {10.1016/j.knosys.2025.113075},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113075},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-sensor contrastive learning-based pre-training for machinery fault diagnosis under sample-limited conditions},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time–frequency transform based EEG data augmentation for brain–computer interfaces. <em>KBS</em>, <em>311</em>, 113074. (<a href='https://doi.org/10.1016/j.knosys.2025.113074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate decoding of electroencephalography (EEG) signals is crucial for brain–computer interfaces (BCIs); however, individual differences, non-stationarity of EEG signals, and limited training data make the decoding very challenging. Existing EEG data augmentation approaches usually operate in the temporal, frequency, or spatial domain only, which may not adequately capture the non-stationarity of EEGs. Moreover, these methods typically generate within-subject augmented trials, restricting their effectiveness in accommodating inter-subject variability. This paper proposes two time–frequency transform based EEG data augmentation approaches: Discrete Wavelet Transform Augmentation (DWTaug) and Hilbert–Huang Transform Augmentation (HHTaug). Both follow three steps: time–frequency domain decomposition, cross-subject sub-signal reassembling, and time domain reconstruction. Augmenting data expands the pool of labeled training samples, alleviating the data scarcity problem; time–frequency decomposition captures the non-stationary properties of EEG signals more effectively; finally, cross-subject reassembling of sub-signals handles individual differences. Experiments on 17 datasets from three different BCI paradigms demonstrated the superiority of DWTaug and HHTaug over nine existing EEG data augmentation approaches, improving 4% over baseline on average. By leveraging essential time–frequency information, DWTaug and HHTaug introduce new utility to traditional signal processing techniques, enhancing EEG data augmentation, thus effectively addressing key EEG decoding challenges. To our knowledge, this is the first work to simultaneously address individual variability, non-stationarity, and data scarcity in EEG decoding, significantly enhancing the real-world applicability of BCIs. Our code is publicized at https://github.com/wzwvv/CSDA .},
  archive      = {J_KBS},
  author       = {Ziwei Wang and Siyang Li and Xiaoqing Chen and Dongrui Wu},
  doi          = {10.1016/j.knosys.2025.113074},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113074},
  shortjournal = {Knowl. Based Syst.},
  title        = {Time–frequency transform based EEG data augmentation for brain–computer interfaces},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning with multiple classifier aggregation. <em>KBS</em>, <em>311</em>, 113073. (<a href='https://doi.org/10.1016/j.knosys.2025.113073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) has garnered attention due to its capability to address statistical heterogeneity among clients. Typically, prevailing PFL methods aggregate a single global model for personalization, which may be inadequate for clients with diverse data distributions. Furthermore, in the local update, each private dataset is used to optimize the model independently, which increases the risk of overfitting the current data distribution and losing previously acquired knowledge, resulting in knowledge forgetting. In this study, a personalized federated learning with multiple classifier aggregation (FedMCA) method is proposed. FedMCA splits the client model into its head and base, optimizing them respectively using an alternating strategy that sequentially targets the head and base. Initially, to address the suboptimal model problem, the proposed method aggregates multiple classifiers using data distribution and employs knowledge distillation to impart positive and negative classifier knowledge for learning the most suitable personalized model head. Additionally, to mitigate knowledge forgetting, a learnable personalization layer is introduced, and hidden loss is utilized to learn the knowledge of the global base and prevent overfitting of the model base. The experimental results demonstrate that the proposed method achieves competitive performance across various benchmarks, outperforming most state-of-the-art PFL algorithms. The source code is publicly available at https://github.com/xiaye-maker/FedMCA .},
  archive      = {J_KBS},
  author       = {Shaifeng Zheng and Qingling Zhu and Qiuzhen Lin and Songbai Liu and Ka-Chun Wong and Jianqiang Li},
  doi          = {10.1016/j.knosys.2025.113073},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113073},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized federated learning with multiple classifier aggregation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring human perception in interactive digital advertising: A genetic-kansei engineering approach with human-AI collaboration. <em>KBS</em>, <em>311</em>, 113072. (<a href='https://doi.org/10.1016/j.knosys.2025.113072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence technologies have significantly enhanced the capability to generate interactive digital advertising content, aligning with the user-centric principles of Industry 5.0. Broad user engagement is crucial for interactive marketing, but the human perception of interactive digital advertising styles has not been widely explored. This study proposes a Genetic-Kansei Engineering approach with human-AI collaboration to address research gaps, focusing on human perception in digital advertising. This method involves (1) Advertising Content Analysis (ACA): extracting structural and animation effects attributes of digital advertising content through case analysis, (2) Human Perception Identification (HPI): capturing the style semantics of digital advertisements using Kansei Engineering methods and establishing their correlation with animation effects through the Back Propagation Neural Networks (BPNN), and (3) Stylized Parameter Generation (SPG): identifying the optimal solution for stylized animation effects parameter generation using Genetic Algorithms. Based on this methodology, we have developed an interactive design tool for e-commerce product digital advertisements, which has been validated for good usability. In comparative experiments, we evaluated the memorability, quality of generation, and diversity of e-commerce advertisements produced by the proposed approach against those generated by existing design tools. The results indicate that the proposed AI-Supported and Genetic-Kansei Engineering-driven approach and its derivative design tool are highly effective and usable, demonstrating the possibility of broad implementation.},
  archive      = {J_KBS},
  author       = {Danni Chang and Luyao Wang and Yan Xiang and Xinyu Zhu and Ching-Hung Lee},
  doi          = {10.1016/j.knosys.2025.113072},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113072},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploring human perception in interactive digital advertising: A genetic-kansei engineering approach with human-AI collaboration},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational global clue inference for weakly supervised video moment retrieval. <em>KBS</em>, <em>311</em>, 113071. (<a href='https://doi.org/10.1016/j.knosys.2025.113071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised video moment retrieval is a challenging video understanding task aimed at modeling fine-grained cross-modality alignment using only video-query pair annotation. Recent mask reconstruction-based works have achieved promising performance, which interact with masked query and video segments to reconstruct the query, and then measure the segment-query alignment based on the reconstruction accuracy. However, they overlook an important issue: queries are selective summaries of the rich semantics in videos; therefore, reconstructing based only on two incomplete modalities may cause confusion about the reference content for reconstruction, thereby affecting the effectiveness of the reconstruction results as a matching degree measure. To address this issue, we uncover and model the guiding role of the global clue based on the query set composed of all queries corresponding to the video. Specifically, to prevent the query set from causing potential information leakage in the reconstruction and to reduce the impact of noisy annotations, we model the global clue as a Gaussian latent variable conditioned on the query set. Moreover, since the query set is unavailable during inference, we propose a variational inference reconstruction model conditioned on the global clue and derive the corresponding Evidence Lower Bound (ELBO). By jointly optimizing the ELBO and query set predictor during training, we encourage the model to minimize reconstruction error while generating a more accurate query set to serve as the basis for modeling global clues during inference. Extensive experiments validate the effectiveness of our method.},
  archive      = {J_KBS},
  author       = {Zezhong Lv and Bing Su},
  doi          = {10.1016/j.knosys.2025.113071},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113071},
  shortjournal = {Knowl. Based Syst.},
  title        = {Variational global clue inference for weakly supervised video moment retrieval},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level cross-knowledge fusion with edge guidance for camouflaged object detection. <em>KBS</em>, <em>311</em>, 113070. (<a href='https://doi.org/10.1016/j.knosys.2025.113070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection aims to identify objects that are “perfectly” assimilated into their surroundings, which has a wide range of valuable applications. The key challenge is that there exists high intrinsic similarities between the candidate objects and noise background. Despite the numerous learning frameworks developed in recent years to address this issue, they still struggle when confronted with highly deceptive camouflaged objects. In response, we propose a coarse-to-fine framework that leverages rough target positioning guided by edge semantics and refined identification assisted by cross-knowledge. Specifically, we dynamically mine additional object-related edge cues to guide representation learning in camouflaged object detection. This process focuses on exploring the initial object structure and facilitating the search for coarse regions of objects across multiple observation dimensions, mirroring biological mechanisms. Subsequently, multi-level cross-knowledge, refined through aggregation, aids in decoding the representation of precise regions. Employing a deep supervision strategy from top to bottom, our framework achieves accurate camouflaged object detection. Experiments conducted on various widely-used benchmark datasets demonstrate that our proposed network outperforms previous methods both qualitatively and quantitatively.},
  archive      = {J_KBS},
  author       = {Wei Sun and Qianzhou Wang and Yulong Tian and Xiaobao Yang and Xianguang Kong and Yizhuo Dong and Yanning Zhang},
  doi          = {10.1016/j.knosys.2025.113070},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113070},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-level cross-knowledge fusion with edge guidance for camouflaged object detection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPGB: Learning discriminative embeddings with multi-prototype and gradient balancing strategy for multi-modal 3D open world object detection. <em>KBS</em>, <em>311</em>, 113069. (<a href='https://doi.org/10.1016/j.knosys.2025.113069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extensive research has been conducted on the closed world 3D object detection. However, the closed-set scenario is not practical for the complex and dynamic real-world environment, especially for autonomous driving systems which require the ability to perceive and respond to various road traffic emergencies. This paper thoroughly investigates multi-modal 3D open world object detection. The primary challenges are unstructured nature (e.g. irregularity and sparsity) and data imbalance. To better capture the intra-class diversity and inter-class difference, we introduce the multi-prototype contrastive learning and a weighted cross-entropy loss. To handle long-tail data distribution problem, we utilize the multi-head structure for region proposal network (RPN) with rate and magnitude gradient balancing strategy. In addition, we incorporate prototypes as feature replay during incremental tasks to alleviate the catastrophic forgetting problem. Extensive experiments on the KITTI and Waymo datasets evidence that the proposed MPGB demonstrates superiority in recognizing both novel and known categories, compared to baselines. The code is available at https://github.com/zhanghaozhe23/MPGB .},
  archive      = {J_KBS},
  author       = {Haozhe Zhang and Liyan Ma and Zhi Li and Tieyong Zeng},
  doi          = {10.1016/j.knosys.2025.113069},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113069},
  shortjournal = {Knowl. Based Syst.},
  title        = {MPGB: Learning discriminative embeddings with multi-prototype and gradient balancing strategy for multi-modal 3D open world object detection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairUDT: Fairness-aware uplift decision trees. <em>KBS</em>, <em>311</em>, 113068. (<a href='https://doi.org/10.1016/j.knosys.2025.113068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training data used for developing machine learning classifiers can exhibit biases against specific protected attributes. Such biases typically originate from historical discrimination or certain underlying patterns that disproportionately under-represent minority groups, such as those identified by their gender, religion, or race. In this paper, we propose a novel approach, FairUDT, a fairness-aware Uplift-based Decision Tree for discrimination identification. FairUDT demonstrates how the integration of uplift modeling with decision trees can be adapted to include fair splitting criteria. Additionally, we introduce a modified leaf relabeling approach for removing discrimination. We divide our dataset into favored and deprived groups based on a binary sensitive attribute, with the favored dataset serving as the treatment group and the deprived dataset as the control group. By applying FairUDT and our leaf relabeling approach to preprocess three benchmark datasets, we achieve an acceptable accuracy–discrimination tradeoff. We also show that FairUDT is inherently interpretable and can be utilized in discrimination detection tasks.},
  archive      = {J_KBS},
  author       = {Anam Zahid and Abdur Rehman Ali and Shaina Raza and Rai Shahnawaz and Faisal Kamiran and Asim Karim},
  doi          = {10.1016/j.knosys.2025.113068},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113068},
  shortjournal = {Knowl. Based Syst.},
  title        = {FairUDT: Fairness-aware uplift decision trees},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preserving high-order ego-centric topological patterns in node representation in heterogeneous graph. <em>KBS</em>, <em>311</em>, 113067. (<a href='https://doi.org/10.1016/j.knosys.2025.113067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks often represent a node by recursively aggregating neighbors within its ego-graph, but this approach struggles to capture high-order ego-centric topological patterns. In homogeneous graphs, a common solution is to predefine specific high-order ego-centric topological patterns (e.g., triangle) and search for them within the ego-graph to enhance node representation. Yet, this is intractable for heterogeneous graphs due to two challenges: (1) the diversity in node and relation types leads to an excessive number of possible patterns, and (2) the varying schemas across heterogeneous graphs make it impractical to predefine universal patterns. To address these challenges, we propose Task-oriented Anchor Ego-Graph learning for Heterogeneous Graphs (TAEG-HG), a method that automatically learns to generate informative high-order ego-centric topological patterns tailored to the heterogeneous graph and task. These learned patterns serve as anchors, i.e., each node is represented by the similarity between its ego-graph and the learned patterns. Therefore, TAEG-HG explicitly preserves high-order ego-centric semantics in node representations and offers built-in interpretability through the learned patterns. We evaluate TAEG-HG on two real-world, million-scale datasets and four open benchmark datasets. TAEG-HG outperforms existing state-of-the-art methods, with notable improvements in tasks closely related to ego-centric topology, such as predicting future citations of scholars, where it surpasses the strongest baseline by over 5%.},
  archive      = {J_KBS},
  author       = {Tianqianjin Lin and Yangyang Kang and Zhuoren Jiang and Kaisong Song and Xurui Li and Hongsong Li and Jiawei Liu and Changlong Sun and Cui Huang and Xiaozhong Liu},
  doi          = {10.1016/j.knosys.2025.113067},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113067},
  shortjournal = {Knowl. Based Syst.},
  title        = {Preserving high-order ego-centric topological patterns in node representation in heterogeneous graph},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new adaptive multi-scale attention adversarial network for cross-domain fault diagnosis. <em>KBS</em>, <em>311</em>, 113066. (<a href='https://doi.org/10.1016/j.knosys.2025.113066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault diagnosis of rotating components such as bearings and gearboxes is crucial for ensuring the safe operation of machinery. However, traditional deep learning diagnostic models often exhibit poor performance when facing changes in operating conditions. To address this issue, this paper proposes an adaptive multi-scale attention adversarial network (AMSAAN). First, a combination of one-dimensional (1-D) wide convolution and two-dimensional (2-D) multi-scale convolution is employed to extract long-term temporal features and short-term multi-scale features from the samples. Second, to reduce the impact of noise, a multi-layer attention feature refinement mechanism is utilized to progressively refine the extracted features layer by layer. Cross-domain adaptation is carried out in two parts: domain shift reduction and feature alignment. The first part uses a dual-domain distance approach combining correlation alignment (CORAL) distance and Wasserstein distance to reduce domain distribution differences. The second part integrates contrastive loss and domain adversarial mechanisms to achieve domain feature alignment. This method comprehensively considers both supervised domain adaptation (SDA) and unsupervised domain adaptation (UDA). The proposed AMSAAN effectively extracts domain-invariant features, reduces noise impact, and achieves domain adaptation. The effectiveness of AMSAAN is demonstrated through experimental results based on two datasets of bearings and planetary gearboxes. AMSAAN achieves a diagnostic accuracy of over 97 % across multiple transfer tasks under varying operating conditions, and the noise resistance of the model has been demonstrated to be superior to that of other methods.},
  archive      = {J_KBS},
  author       = {Lingtan Kong and Jinrui Wang and Dawei Wang and Huaiqian Bao and Zongzhen Zhang and Baokun Han and Xuhao Man and Ranran Qin and Xiaoli Yang},
  doi          = {10.1016/j.knosys.2025.113066},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113066},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new adaptive multi-scale attention adversarial network for cross-domain fault diagnosis},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel smart street intervention mechanism using clustering-based path optimization for street networks. <em>KBS</em>, <em>311</em>, 113065. (<a href='https://doi.org/10.1016/j.knosys.2025.113065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is quite challenging to discover the imminent infection producing areas to determine the spreading pattern of the epidemic and adopt a counter strategy to combat the outbreak in a timely manner. Therefore, this paper explores the executive perspective to examine the infrastructure systems, such as street networks, to support the continuity of administrative operations essential to controlling the spread of an epidemic. We achieve this by application of optimization-oriented and unsupervised machine learning methods that assemble analysis and decision-making practices into a data-driven model. First, the proposed model analyzes the infection triggering areas at the street-segment level to implement the smart lockdown (street intervention mechanism). The model then suggests to deliberately closing the streets in such a way that only a minimal number of additional streets should be selected to ensure the safety margins against the epidemic. We achieve this by identifying the critical pathways between the affected streets through shortest path analysis. This enables an instinctive assessment of the path of movement between the immediate vicinity of the affected streets. The proposed model thus increases the ability of the managing authorities to implement the resilience plans in a shorter time, so that the unplanned infrastructure can withstand the catastrophic event that it could suffer. We use the efficiency measure to substantiate the proposed model. The evaluations show that the suggestions produced by the proposed model are far more robust and efficient.},
  archive      = {J_KBS},
  author       = {Tahira Sadaf and Usman Qamar and Shoab Ahmed Khan and Saad Almutairi},
  doi          = {10.1016/j.knosys.2025.113065},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113065},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel smart street intervention mechanism using clustering-based path optimization for street networks},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust adaptive denoising of color images with mixed gaussian and impulsive noise. <em>KBS</em>, <em>311</em>, 113064. (<a href='https://doi.org/10.1016/j.knosys.2025.113064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising remains one of the most crucial research areas within image processing given its effect on later analysis. During the different steps of image acquisition, transmission, and storage, noise considerably deteriorates image quality. Very poor image quality may prevent a vision system in some limiting situations from performing properly. In natural images, Gaussian and impulsive noise is probably the most frequent kind of noise and will be tackled in this paper. Various solutions to this problem are given in the contemporary literature, but all these techniques can be further improved for even better results, hence bringing better outcomes in further stages of image processing. In this paper, we will present a Robust Adaptive Denoising technique (RAD) that makes use of elements of the Non-Local Means mechanism in combination with a new measure of the similarity of image patches, taking into account the impulsiveness component of image noise. The proposed methodology introduces an adaptive selection technique that relieves potential users from the complex process of parameter tuning to get the best results. We have also analyzed problems connected with the size of the patch and processing block, and also with some local weighting aspects. Extensive experimentation demonstrates that the proposed approach outperforms the performance of existing filters and yields results superior to those obtained by recent neural network-based techniques. The proposed solution can be utilized without the cumbersome network training process, is independent of any a priori knowledge of the mixed noise level and image characteristics.},
  archive      = {J_KBS},
  author       = {Damian Kusnik and Bogdan Smolka},
  doi          = {10.1016/j.knosys.2025.113064},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113064},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust adaptive denoising of color images with mixed gaussian and impulsive noise},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge reasoning based on graph neural networks with multi-layer top-p message passing and sparse negative sampling. <em>KBS</em>, <em>311</em>, 113063. (<a href='https://doi.org/10.1016/j.knosys.2025.113063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have received increasing interest in knowledge reasoning since they can learn the structure and semantic information of graphs. However, as the number of hops increases, the number of entities grows exponentially, resulting in a sharp rise in resource costs. Furthermore, the presence of irrelevant entities during message passing can accumulate noise, thereby diminishing the model’s accuracy. To solve these problems, a knowledge reasoning model based on graph neural networks with multi-layer top-p message passing and sparse negative sampling is proposed. To be specific, we designed a dynamic top-p message-passing strategy that dynamically samples key entities related to the query based on their probability distribution, thereby reducing high resource costs. Then the similarity-based negative sampling is applied to dense entities in the knowledge graph, while random sampling is used for sparse entities, which enhances the model’s ability to identify irrelevant entities. Extensive experiments conducted on three datasets (WN18RR, FB15k-237, and NELL-995) demonstrate our model outperforms other SOTA methods in knowledge reasoning, achieving an average improvement of 5.16%, 6.16% and 6.71% in MRR, Hits@1 and Hits@10 respectively, and it also has a great advantage in training efficiency than SOTA GNN-based methods, with the average improvement of 11.99% in training time. Our model not only offers a novel method for knowledge reasoning, but also contributes valuable insights for the advancement of knowledge graph technologies.},
  archive      = {J_KBS},
  author       = {Wenjie Liu and Zhijie Ren and Liang Chen},
  doi          = {10.1016/j.knosys.2025.113063},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113063},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge reasoning based on graph neural networks with multi-layer top-p message passing and sparse negative sampling},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A halton enhanced solution-based human evolutionary algorithm for complex optimization and advanced feature selection problems. <em>KBS</em>, <em>311</em>, 113062. (<a href='https://doi.org/10.1016/j.knosys.2025.113062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification problem is a significant area in the field of Artificial intelligence. Feature selection (FS) enhances the classification process by eliminating irrelevant and redundant features. The Human Evolutionary Algorithm (HEO) is an innovative optimization approach inspired by how humans gather information. It proved its simplicity, flexibility, and the limited number of parameters. Nevertheless, the HEO exhibits downsides such as a low convergence competence and a bias to trap in local extremes in various optimization problems, including the feature selection process. Consequently, this might result in an ineffective elimination of irrelevant and redundant features. Therefore, this study incorporates three enhancements into HEO to present a Halton-based Enhanced Solution Human Evolutionary Algorithm with t-distribution disturbance (HEST-HEO). The HEST-HEO employs the Halton sequence to initially locate individual solutions, thereby enhancing population diversity. Furthermore, the Enhanced Solution Quality (ESQ) operator is incorporated into the HEO algorithm to amend its search capability. Finally, the t-distribution disturbance is devoted to augmenting the optimal solution, thereby preventing the algorithm from getting trapped in local optima. To assess the efficacy of the HEST-HEO algorithm, we employ a set of 12 intricate functions from the global CEC'22 test suite. In addition, 14 standard datasets are utilized to assess the feature selection of the proposed method and compare it with a set of popular and recent peers. Thus, the HEST-HEO algorithm exhibits excellent convergence and search accuracy, significantly improves classification accuracy, reduces the number of selected features, and is both effective and resilient in feature selection.},
  archive      = {J_KBS},
  author       = {Mahmoud Abdel-Salam and Amit Chhabra and Malik Braik and Farhad Soleimanian Gharehchopogh and Nebojsa Bacanin},
  doi          = {10.1016/j.knosys.2025.113062},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113062},
  shortjournal = {Knowl. Based Syst.},
  title        = {A halton enhanced solution-based human evolutionary algorithm for complex optimization and advanced feature selection problems},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPA-EI: Long-tailed classification by dual progressive augmentation from explicit and implicit perspectives. <em>KBS</em>, <em>311</em>, 113061. (<a href='https://doi.org/10.1016/j.knosys.2025.113061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks have significantly advanced visual recognition tasks; however, handling long-tailed distribution data remains a substantial challenge for machine learning. Data augmentation is widely recognized as an effective technique for long-tailed image classification. However, most explicit and implicit data augmentation methods fail to balance sample-level generalization with feature-level semantic richness. In this paper, we present a dual progressive augmentation framework designed to mitigate category imbalance in long-tailed classification scenarios. Our framework progressively enhances data diversity and representation by combining explicit and implicit augmentation stages. In the explicit augmentation stage, we employ Mixup training to improve sample-level generalization, thereby increasing the diversity of tail-category data representations. Subsequently, the implicit augmentation stage incorporates category-level covariance learning and meta-learning methodologies, enriching feature-level semantic diversity. Extensive experimental results validate the effectiveness of our method, particularly for tail categories. The proposed framework improves the performance of tail categories by 1% ∼ 2% over the second-best method while maintaining the performance of head categories across different long-tailed datasets. Code is available at https://github.com/fhqxa/DPA-EI .},
  archive      = {J_KBS},
  author       = {Yan Zhao and Wenwei He and Hong Zhao},
  doi          = {10.1016/j.knosys.2025.113061},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113061},
  shortjournal = {Knowl. Based Syst.},
  title        = {DPA-EI: Long-tailed classification by dual progressive augmentation from explicit and implicit perspectives},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal deep learning for improved face presentation attack detection. <em>KBS</em>, <em>311</em>, 113059. (<a href='https://doi.org/10.1016/j.knosys.2025.113059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face presentation attack detection (FacePAD) is critical for securing face recognition systems against attacks such as printed photos, videos, and 3D masks. Existing methods often struggle with generalizability, computational efficiency, and handling sophisticated attacks, particularly in resource-constrained environments. To address these challenges, this study proposes a lightweight CNN-based architecture, MobileNetV3, integrated with spatio-temporal feature extraction. The proposed method effectively captures both dynamic and static characteristics and achieves state-of-the-art performance, including an Equal Error Rate (EER) of 0.0% on the Replay-Attack and Replay-Mobile datasets, and 0.83% on the challenging ROSE-Youtu dataset. With real-time efficiency, processing 256 samples in 11 ms, the model is suitable for deployment on mobile and embedded platforms. This work demonstrates that lightweight architectures with spatio-temporal features can balance computational efficiency and accuracy, setting a benchmark for practical FacePAD systems in applications like mobile authentication, surveillance, and access control, enhancing biometric security.},
  archive      = {J_KBS},
  author       = {Shujaat Khan and Taha Hasan Masood Siddique and Muhammad Sohail Ibrahim and Abdul Jabbar Siddiqui and Kejie Huang},
  doi          = {10.1016/j.knosys.2025.113059},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113059},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatio-temporal deep learning for improved face presentation attack detection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HireGC: Hierarchical inductive network representation learning via graph coarsening. <em>KBS</em>, <em>311</em>, 113058. (<a href='https://doi.org/10.1016/j.knosys.2025.113058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive network representation learning utilizes node feature information to efficiently generate embeddings for unseen data, achieving significant success in learning vector representations for new nodes within a network. However, most existing methods focus primarily on modeling the information from neighboring nodes of new nodes, limiting the model’s ability to capture the broader network context. In this paper, we propose a H ierarchical i nductive network re presentation learning model based on G raph C oarsening (HireGC), which effectively captures richer hierarchical network information and employs a multi-level decomposition approach for structured network analysis. Specifically, HireGC uses an iterative coarsening algorithm to generate network structural information across multiple layers, then merges this multilayer network information through node-level mapping and group-level inheritance mechanisms to produce high-quality vector representations for new nodes. Unlike existing methods that only consider neighboring nodes, our approach captures the multi level structural information of the entire network, enabling the learning of more effective inductive embeddings from a broader perspective. Extensive experiments on six benchmark graph datasets demonstrate the superiority of HireGC over other state-of-the-art methods, highlighting the crucial role of hierarchical network information in inductive network representation learning.},
  archive      = {J_KBS},
  author       = {Shu Zhao and Ci Xu and Ziwei Du and Yanping Zhang and Zhen Duan and Jie Chen},
  doi          = {10.1016/j.knosys.2025.113058},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113058},
  shortjournal = {Knowl. Based Syst.},
  title        = {HireGC: Hierarchical inductive network representation learning via graph coarsening},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoT-driven framework for short text classification: Enhancing and transferring capabilities from large to smaller model. <em>KBS</em>, <em>311</em>, 113057. (<a href='https://doi.org/10.1016/j.knosys.2025.113057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short Text Classification (STC) is crucial for processing and understanding the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping the semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study first employs CoT to investigate and enhance the capabilities of LLMs in STC tasks. We propose the Syntactic and Semantic Enrichment CoT (SSE-CoT) method, effectively decomposing the STC tasks into four distinct steps: (i) essential concept identification, (ii) common-sense knowledge retrieval, (iii) text rewriting, and (iv) classification. Furthermore, recognizing resource constraints in sectors like finance and healthcare, we then introduce the CoT-Driven Multi-Task Learning (CDMT) framework to extend these capabilities to smaller models. This framework begins by extracting rationales from LLMs and subsequently fine-tunes smaller models to optimize their performance. Extensive experimentation across six short-text benchmarks validated the efficacy of the proposed methods. In particular, SSE-CoT achieved state-of-the-art performance with substantial improvements on all datasets, particularly on the Ohsumed and TagMyNews datasets.},
  archive      = {J_KBS},
  author       = {Hui Wu and Yuanben Zhang and Zhonghe Han and Yingyan Hou and Lei Wang and Siye Liu and Qihang Gong and Yunping Ge},
  doi          = {10.1016/j.knosys.2025.113057},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113057},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoT-driven framework for short text classification: Enhancing and transferring capabilities from large to smaller model},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESNet: An efficient skeleton-guided network for camouflaged object detection. <em>KBS</em>, <em>311</em>, 113056. (<a href='https://doi.org/10.1016/j.knosys.2025.113056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although most of the existing camouflaged object detection methods achieve significant progress, they still have limitations in the following aspects. Firstly, they usually ignore the internal topological structure of objects. Secondly, they are unable to simultaneously balance performance and efficiency. To address the above issues, we propose an Efficient Skeleton-guided Network (ESNet), which utilizes skeleton information to focus on the geometric structure and extension properties of objects. Specifically, to improve the ability of the network to represent the skeleton information, we design a lightweight skeleton encoder and make skeleton labels to supervise the skeleton features generated by the skeleton encoder. To enhance the ability of the network to perceive the internal structure of objects, we design a Skeleton Guidance Fusion Module (SGFM), which introduces skeleton information into semantic features. Furthermore, we introduce a Part-Object Relational Mapping (PORM) component to further improve the micro integrity of camouflaged objects. Extensive experimental results show that ESNet achieves excellent performance, and it has only 10.8M parameters and real-time inference speed (140.3 FPS).},
  archive      = {J_KBS},
  author       = {Peng Ren and Tian Bai and Fuming Sun},
  doi          = {10.1016/j.knosys.2025.113056},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113056},
  shortjournal = {Knowl. Based Syst.},
  title        = {ESNet: An efficient skeleton-guided network for camouflaged object detection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel strongly-typed genetic programming algorithm for combining sentiment and technical analysis for algorithmic trading. <em>KBS</em>, <em>311</em>, 113054. (<a href='https://doi.org/10.1016/j.knosys.2025.113054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of algorithms in finance and trading has become an increasingly thriving research area, with researchers creating automated and pre programmed trading instructions utilising indicators from technical and sentiment analysis. The indicators of the two analyses have been used mostly individually, despite evidence that their combination can be profitable and financially advantageous. In this paper, we examine the advantages of combining indicators from both technical and sentiment analysis through a novel genetic programming algorithm, named STGP-SATA. Our algorithm introduces technical and sentiment analysis types, through a strongly-typed architecture, whereby the associated tree contains one branch with only technical indicators and another branch with only sentiment analysis indicators. This approach allows for better exploration and exploitation of the search space of the indicators. To evaluate the performance of STGP-SATA we compare it with three other GP variants on three financial metrics, namely Sharpe ratio, rate of return and risk. We furthermore compare STGP-SATA against two financial and four algorithmic benchmarks, namely, multilayer perceptron, support vector machine, extreme gradient boosting, and long short term memory network. Our study shows that the combination of technical and sentiment analysis indicators through STGP-SATA improves the financial performance of the trading strategies and statistically and significantly outperforms the other benchmarks across the three financial metrics.},
  archive      = {J_KBS},
  author       = {Eva Christodoulaki and Michael Kampouridis and Maria Kyropoulou},
  doi          = {10.1016/j.knosys.2025.113054},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113054},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel strongly-typed genetic programming algorithm for combining sentiment and technical analysis for algorithmic trading},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking eigenpairs: Community detection with orthogonality. <em>KBS</em>, <em>311</em>, 113053. (<a href='https://doi.org/10.1016/j.knosys.2025.113053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering and matrix factorization are two widely utilized algorithms for community detection. On the one hand, most existing spectral clustering algorithms focus on learning node representations from a well-designed similarity matrix that thoroughly incorporates data attribute information. However, they often overlook the intrinsic attribute information embedded within the algorithm itself. On the other hand, the node representations generated by most existing matrix factorization algorithms often exhibit a lack of linear independence, leading to the presence of redundant information. Motivated by them, we propose an algorithm, SOCD ( S elective O rthogonalization for C ommunity D etection), which leverages the orthogonality loss of the Lanczos algorithm to monitor whether eigenvalues converge or not, and saves the already converged eigenpairs, then the corresponding converged eigenvectors are employed for community structure detection. Meanwhile, the already converged eigenvectors continue to be orthogonalized against the Lanczos vector to preserve the orthogonality of the Lanczos algorithm. A large number of experiments conducted on real datasets with community labels demonstrate the superiority of our algorithm over its competitors. The experimental code is available for download at https://github.com/AnonSimRank/SOCD/ .},
  archive      = {J_KBS},
  author       = {Liping Yan and Jie Cao and Weiren Yu and Yuyao Wang and Darko B. Vuković},
  doi          = {10.1016/j.knosys.2025.113053},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113053},
  shortjournal = {Knowl. Based Syst.},
  title        = {Rethinking eigenpairs: Community detection with orthogonality},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoLE: A collaborative legal expert prompting framework for large language models in law. <em>KBS</em>, <em>311</em>, 113052. (<a href='https://doi.org/10.1016/j.knosys.2025.113052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have achieved remarkable outcomes in various natural language processing tasks. However, their application to the highly specialized field of law presents unique challenges. Legal language, characterized by complex syntax, domain-specific terminology, and nuanced logical relationships, poses significant hurdles for existing NLP models in accurately understanding and processing legal queries. Furthermore, the sheer volume of legal documents complicates information retrieval and knowledge extraction, making it difficult for models to pinpoint relevant legal articles and cases. Moreover, existing legal LLMs often struggle to effectively handle colloquial user queries and lack efficient mechanisms for selecting the most relevant demonstrations in In-Context Learning (ICL), hindering their ability to provide accurate and comprehensive legal advice. In order to address these issues, we propose a novel prompting framework named “Collaborative Legal Experts” ( CoLE ). This framework draws inspiration from teamwork paradigms in real-world legal case processing. First, we design an intent identification module to analyze user queries for identifying potential intents and law domains. Then, through two subsequent processes, potential background information and the best demonstration are generated. Finally, we design a prompt generator to assemble prompts generated from the previous steps. It combines with the LLMs to generate the final answer. Notably, we find that the self-generated information by LLMs has a smaller gap when fused with LLMs. We evaluate performance by integrating it with 7 general-purpose Chinese LLMs and comparing its performance against 8 specialized legal LLMs across 10 datasets, including Single-Choice, Multiple-Choice, and Question&Answer. The results indicate that integrating with CoLE’s LLMs has the potential to significantly enhance performance in the law field, particularly without the need for annotated datasets or model parameter updates. Moreover, our proposed model outperforms all state-of-the-art LLMs in law. The code is available at https://github.com/liboaccn/cole .},
  archive      = {J_KBS},
  author       = {Bo Li and Shuang Fan and Shaolin Zhu and Lijie Wen},
  doi          = {10.1016/j.knosys.2025.113052},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113052},
  shortjournal = {Knowl. Based Syst.},
  title        = {CoLE: A collaborative legal expert prompting framework for large language models in law},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-guided feature refinement for point cloud semantic segmentation with weakly supervision. <em>KBS</em>, <em>311</em>, 113050. (<a href='https://doi.org/10.1016/j.knosys.2025.113050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud segmentation is a widely concerned task for 3D part/scene parsing and many learning-based methods are proposed to improve the performance significantly. However, the performance is limited by the quality and quantity of labeled data. Therefore, we propose a multi-guided feature refinement (MGFR) to capture more effective representation with fewer annotations. Specifically, MGFR is a point-wise method based on a hybrid neighbor system and consists of feature aggregation and weight refinement. Feature aggregation is implemented in an attention-based manner guided by explicit information (structure geometry prior and RGB prior), neighbor information and prototype information. Weight refinement is a probabilistic method which is guided by the effective components of prototype extracted from neighbor members. The refined point feature of MGFR is provided with more local smoothness and global consistency, which can improve the performance on different instances of the same class and reduce the counterintuitive error around classification boundary or isolated outliers. Furthermore, we also use a neighbor-based contrastive loss, a prototype-based loss with regularization and a neighbor-based multiple instance loss to achieve local optimization and regularize the distribution of point embedding. Experimentally, we evaluate MGFR on ShapeNet Part dataset, Stanford 2D-3D (S3DIS) dataset and ScanNet, which shows the effectiveness in weakly-supervised task.},
  archive      = {J_KBS},
  author       = {Yufan Wang and Qunfei Zhao and Zeyang Xia},
  doi          = {10.1016/j.knosys.2025.113050},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113050},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-guided feature refinement for point cloud semantic segmentation with weakly supervision},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term evolutionary patterns matter: Self-supervised anomaly detection on dynamic graphs. <em>KBS</em>, <em>311</em>, 113049. (<a href='https://doi.org/10.1016/j.knosys.2025.113049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) plays a crucial role in identifying anomalous individuals (e.g., nodes or edges) whose behaviors or patterns deviate significantly from the normal majority within a graph. Recent years have witnessed breakthrough advancements in research on static graphs. However, the GAD problem becomes more challenging when switching from static graphs to dynamic graphs due to the temporal evolution of graph structures and the scarcity of anomaly labels. Although various approaches have been proposed to address these challenges, they often struggle to capture the evolving dynamics and neglect the potential of capturing nodes’ smooth long-term evolutionary patterns for self-supervised anomaly detection in dynamic graph. In this work, we empirically demonstrate that normal nodes exhibit smooth long-term evolutionary patterns, while anomalous nodes deviate significantly from their long-term histories. Motivated by this observation, we propose a multi-step histories-based contrastive learning framework, MHisCL, to detect anomalies in dynamic graphs in a self-supervised manner. Specifically, we treat a node’s current state and its multi-step historical states as a positive contrastive pair, encouraging alignment between them to capture the smooth long-term evolutionary patterns of normal nodes. Consequently, MHisCL is capable of efficiently detecting anomalies by measuring the disagreement of nodes’ positive pairs through a simple similarity computation. Furthermore, to better capture complex evolving dynamics, MHisCL incorporates a novel state space time encoding (SSTE), which explicitly models the temporal evolution of node representations through a linear dynamical system. We evaluate MHisCL on several dynamic graph benchmarks, and it outperforms state-of-the-art baseline by large margins.},
  archive      = {J_KBS},
  author       = {Yun Fu and Che Zhou and Jintang Li and Liang Chen},
  doi          = {10.1016/j.knosys.2025.113049},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113049},
  shortjournal = {Knowl. Based Syst.},
  title        = {Long-term evolutionary patterns matter: Self-supervised anomaly detection on dynamic graphs},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A good teacher learns while teaching: Heterogeneous architectural knowledge distillation for fast MRI reconstruction. <em>KBS</em>, <em>311</em>, 113048. (<a href='https://doi.org/10.1016/j.knosys.2025.113048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing high-quality images from under-sampled k-space data is a core problem in fast Magnetic Resonance Imaging. To address this issue, in this study, a super-resolution reconstruction technique based on knowledge distillation across heterogeneous networks. Employing a corrective strategy to refine the erroneous knowledge within the teacher network, the proposed method enhances the accuracy of the knowledge imparted to the student network by incorporating accurate edge information. By reconstructing the mathematical model, the proposed method ensures that the convolutional neural network-based student network can effectively learn the remote feature information from the visual transformer-based teacher network, and achieve high-quality image reconstruction using heterogeneous network knowledge transfer. Experiments on multiple publicly available datasets, in both k-space and image domain, demonstrate that the proposed method achieves performance close to state-of-the-art methods while maintaining a low level of complexity, and can efficiently recover the original information from k-space under-sampled data.},
  archive      = {J_KBS},
  author       = {Cheng-Hao Qiu and Xian-Shi Zhang and Yong-Jie Li},
  doi          = {10.1016/j.knosys.2025.113048},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113048},
  shortjournal = {Knowl. Based Syst.},
  title        = {A good teacher learns while teaching: Heterogeneous architectural knowledge distillation for fast MRI reconstruction},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing knowledge retrieval with in-context learning and semantic search through generative AI. <em>KBS</em>, <em>311</em>, 113047. (<a href='https://doi.org/10.1016/j.knosys.2025.113047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving and extracting knowledge from sets of many complex research documents and large databases presents significant challenges in today’s information-rich era. Existing retrieval systems, which rely on general-purpose Large Language Models (LLMs), often fail to provide accurate responses to domain-specific inquiries. Additionally, the high cost of pretraining or finetuning LLMs for specific domains limits their adoption. To address those limitations, a novel methodology is proposed that combines the generative capabilities of LLMs with the fast and accurate retrieval capabilities of vector databases. This retrieval system can handle tabular and non-tabular data, understand natural language queries, and retrieve relevant information without finetuning. The developed model, Generative Text Retrieval (GTR), is adaptable to unstructured and structured data with minor refinement. GTR was evaluated on manually annotated and public datasets, achieving more than 90% accuracy and delivering truthful outputs in 87% of cases. The proposed model achieved state-of-the-art performance with a Rouge-L F1 score of 0.98 on the MSMARCO dataset. A refined model, Generative Tabular Text Retrieval (GTR-T), demonstrated its efficiency in large database querying, achieving an Execution Accuracy (EX) of 0.82 and an Exact-Set-Match (EM) accuracy of 0.60 on the Spider dataset, using open-source LLM. Those efforts leverage generative AI and in-context learning to enhance human-text interaction.},
  archive      = {J_KBS},
  author       = {Mohammed-Khalil Ghali and Abdelrahman Farrag and Daehan Won and Yu Jin},
  doi          = {10.1016/j.knosys.2025.113047},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113047},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing knowledge retrieval with in-context learning and semantic search through generative AI},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint resource allocation and congestion-aware routing based on hybrid optimization in IoT. <em>KBS</em>, <em>311</em>, 113046. (<a href='https://doi.org/10.1016/j.knosys.2025.113046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, the Internet of Things (IoT) is linked through various forms of communication medium. In IoT, numerous devices are interconnected; hence, network congestion is created. The network congestion and overflow may create data privacy issues. Furthermore, resource allocation (RA) is the major function in IoT systems, in which the system's performance is based on the precise and effectual allocation of resources. As a result, this research proposes a novel optimization named Lyrebird Jaya Hunger Search Optimization (LJHSO) for RA and Lyrebird Fractional Walruses Optimization Algorithm (LFWBO) for congestion-aware routing in IoT. The IoT nodes simulation is the initial process and the cross-layer optimization approach for joint RA and routing is performed. The IoT layer is composed of sensing, network, data processing, and application layers. The RA is carried out in the physical or sensing layer using the LJHSO. Moreover, the congestion-aware routing is done in the network layer by the LFWBO with fitness parameters like queue length, energy, distance, and link quality. Furthermore, metrics like energy, makespan, throughput, and execution time are considered to validate the performance of the proposed LJHSO+LFWBO-based joint RA and congestion-aware routing, with the finest outcome of 0 . 747 bits/Joule, 0.332, 0.853 Mbps, and 1.913 s are attained.},
  archive      = {J_KBS},
  author       = {Yannam Bharath Bhushan and S. Aparna},
  doi          = {10.1016/j.knosys.2025.113046},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113046},
  shortjournal = {Knowl. Based Syst.},
  title        = {Joint resource allocation and congestion-aware routing based on hybrid optimization in IoT},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGMS-GCN: Attention-guided multi-scale graph convolutional networks for skeleton-based action recognition. <em>KBS</em>, <em>311</em>, 113045. (<a href='https://doi.org/10.1016/j.knosys.2025.113045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks have the capability to model non-Euclidean data with high effectiveness. Due to this capability, they perform well on standard benchmarks for skeleton-based action recognition (SBAR). Specifically, spatial–temporal graph convolutional networks (ST-GCNs) function effectively in learning spatial–temporal relationships on skeletal graph patterns. In ST-GCN models, a fixed skeletal graph pattern is used across all layers. ST-GCN models obtain spatial–temporal features by performing standard convolution on this fixed graph topology within a local neighborhood limited by the size of the convolution kernel. This convolution kernel dimension can only model dependencies between joints at short distances and short-range temporal dependencies. However, it fails to model long-range temporal information and long-distance joint dependencies. Effectively capturing these dependencies is key to improving the performance of ST-GCN models. In this study, we propose AGMS-GCN, an attention-guided multi-scale graph convolutional network structure that dynamically determines the weights of the dependencies between joints. In the proposed AGMS-GCN architecture, new adjacency matrices that represent action-specific joint relationships are generated by obtaining spatial–temporal dependencies with the attention mechanism on the feature maps extracted using spatial–temporal graph convolutions. This enables the extraction of features that take into account both the short- and long-range spatial–temporal relationship between action-specific joints. This data-driven graph construction method provides a more robust graph representation for capturing subtle differences between different actions. In addition, actions occur through the coordinated movement of multiple body joints. However, most existing SBAR approaches overlook this coordination, considering the skeletal graph from a single-scale perspective. Consequently, these methods miss high-level contextual features necessary for distinguishing actions. The AGMS-GCN architecture addresses this shortcoming with its multi-scale structure. Comprehensive experiments demonstrate that our proposed method attains state-of-the-art (SOTA) performance on the NTU RGB+D 60 and Northwestern-UCLA datasets. It also achieves SOTA competitive performance on the NTU RGB+D 120 dataset. The source code of the proposed AGMS-GCN model is available at: https://github.com/ugrkilc/AGMS-GCN .},
  archive      = {J_KBS},
  author       = {Ugur Kilic and Ozge Oztimur Karadag and Gulsah Tumuklu Ozyer},
  doi          = {10.1016/j.knosys.2025.113045},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113045},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGMS-GCN: Attention-guided multi-scale graph convolutional networks for skeleton-based action recognition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-driven method for real-time acoustic holographic field reconstruction using physical modeling and semi-supervised neural networks. <em>KBS</em>, <em>311</em>, 113044. (<a href='https://doi.org/10.1016/j.knosys.2025.113044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic holography is an emerging technology that can dynamically generate any desired holographic acoustic field in three-dimensional space. The holographic acoustic field can be recorded as an acoustic hologram for modeling acoustic radiation force, which is promising for a wide range of applications. Currently, the state-of-the-art equipment to support the generation of complex dynamic holographic acoustic fields is the phased transducer array (PTA), which generates holographic acoustic fields by controlling the phase of acoustic waves emitted by discrete transducers. However, accurate reconstruction of holographic acoustic fields from PTA is a difficult nonlinear problem to solve. The reconstruction schemes of traditional iterative algorithms are not only complex but also have poor real-time performance, and although supervised deep learning methods can overcome these problems, they require a large amount of labeled training data. Therefore, in this work, we propose the PhysNet-DUAH method, which seamlessly integrates physical propagation models with deep learning techniques. Using both unlabeled and labeled data, the network is optimized with a semi-supervised training strategy to predict the optimal phase distribution and achieve real-time accurate acoustic hologram reconstruction. The PhysNet-DUAH method not only learns the potential mapping relationship between the target hologram and the PTA phase distribution, but also learns how to reconstruct the optimal target acoustic hologram, which avoids the problem of mismatched training data. The experimental results show that the PhysNet-DUAH method can reconstruct the holographic acoustic field from the PTA quickly and efficiently with excellent accuracy and real-time performance by only one forward propagation, which provides new possibilities for accurate and flexible acoustic holography applications.},
  archive      = {J_KBS},
  author       = {Shuai Wang and Fucheng You and Xuewei Wang and Han Xiao},
  doi          = {10.1016/j.knosys.2025.113044},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113044},
  shortjournal = {Knowl. Based Syst.},
  title        = {A knowledge-driven method for real-time acoustic holographic field reconstruction using physical modeling and semi-supervised neural networks},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph–Regularized consensus learning and diversity representation for unsupervised multi-view feature selection. <em>KBS</em>, <em>311</em>, 113043. (<a href='https://doi.org/10.1016/j.knosys.2025.113043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing data dimensionality reduction methods, unsupervised multi-view feature selection has been widely adopted for its effectiveness. However, most of the current methods lack sufficient integration of consensus and complementarity principles. On the one hand, some methods focus solely on the consensus representation of multiple views and neglect the inter-view complementarity and the uniqueness of each view. On the other hand, some methods obtain intrinsic representation matrices for each view and combine them crudely to form the final result, which fails to exploit complementary information among views. Inspired by these two aspects, this paper proposes the Graph-Regularized Consensus Learning and Diversity Representation (GCDUFS) for unsupervised multi-view feature selection. The algorithm leverages graph regularization to constrain the consensus matrix, better capturing common manifold information. It also utilizes kernel functions to measure the dependency of the data in the Hilbert space, effectively capturing the diverse information across all views. Additionally, symmetric non-negative matrix factorization (SNMF) is employed for clustering analysis. The above-mentioned methods are smoothly integrated into a unified model framework, and the GCDUFS algorithm is optimized using the alternating direction method of multipliers (ADMM) minimization strategy. Through the analysis of nine multi-view datasets, we conducted comprehensive clustering experiments and verified that our proposed method outperforms several state-of-the-art competitors in terms of performance.},
  archive      = {J_KBS},
  author       = {Shengke Xu and Xijiong Xie and Zhiwen Cao},
  doi          = {10.1016/j.knosys.2025.113043},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113043},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph–Regularized consensus learning and diversity representation for unsupervised multi-view feature selection},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSLTA-CDFSAR: Global sequences and local tuples alignment for cross-domain few-shot action recognition. <em>KBS</em>, <em>311</em>, 113041. (<a href='https://doi.org/10.1016/j.knosys.2025.113041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition (FSAR) has made substantial progress, however it primarily addresses problems within a single domain. Its effectiveness is often questioned when applied across different domains. This is mainly due to inductive biases in data distribution during the meta-training, including spatial and temporal distribution biases. These combined biases further complicate the adaptation issue in videos, making it challenging for models trained in one domain to adapt to another. In order to deal with this problem, we first enhance the source domain videos with frames from unlabeled target domain videos. Then, we employ a dual-branch structure to process the videos. The first branch, named the Domain Temporal branch, simultaneously handles global sequences of videos from both the source and target domains, while the second branch, named the Local-Global Adapter branch, compares local tuples of videos with global sequences from the source domain. We align the meta-learning results of the source domain from the first branch with that from the second branch, enabling us to obtain domain-invariant information solely from the source domain. Concurrently, in the first branch, we perform a reconstruction operation for the target domain videos, allowing the model to extract features that approach the target domain. Our code is available on: https://github.com/cofly2014/GSLTA.git .},
  archive      = {J_KBS},
  author       = {Fei Guo and Han Qi and Xuetao Zhang and Li Zhu and Jing Sun},
  doi          = {10.1016/j.knosys.2025.113041},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113041},
  shortjournal = {Knowl. Based Syst.},
  title        = {GSLTA-CDFSAR: Global sequences and local tuples alignment for cross-domain few-shot action recognition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust prior-biased acquisition function for human-in-the-loop bayesian optimization. <em>KBS</em>, <em>311</em>, 113039. (<a href='https://doi.org/10.1016/j.knosys.2025.113039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In diverse fields of application, Bayesian Optimization (BO) has been proposed to find the optimum of black-box functions, surpassing human-driven searches. BO’s appeal lies in its data efficiency, making it suitable for optimizing costly-to-evaluate functions without requiring extensive training data. While BO can perform well in closed-loop, domain experts frequently have hypotheses about which parameter combinations are more likely to yield optimal results. Hence, for BO to be truly relevant and adopted by practitioners, such prior knowledge needs to be efficiently and seamlessly integrated into the optimization framework. Some methods were recently developed to address this challenge, but they suffer from robustness issues when provided erroneous insight. Building on the idea of element-wise prior-weighted acquisition function, we propose to use a fixed-weight effective prior that distills expert user knowledge with minimal computational cost. Comprehensive investigation across diverse task conditions and prior quality levels revealed that our method, α - π BO, surpasses Vanilla BO when provided with insights of good quality while maintaining robustness against misleading information. Moreover, unlike other methods, α - π BO typically requires no hyperparameter tuning, largely simplifying its implementation in diverse tasks.},
  archive      = {J_KBS},
  author       = {Rose Guay-Hottin and Lison Kardassevitch and Hugo Pham and Guillaume Lajoie and Marco Bonizzato},
  doi          = {10.1016/j.knosys.2025.113039},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113039},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust prior-biased acquisition function for human-in-the-loop bayesian optimization},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time fall detection on roads using transfer learning-based granulated bi-LSTM. <em>KBS</em>, <em>311</em>, 113038. (<a href='https://doi.org/10.1016/j.knosys.2025.113038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new deep learning-based model, namely, transfer learning-based granulated Bi-LSTM (TLG-LSTM) is developed for fall detection on roads. The TLG-LSTM can handle the uncertainty issue arising between various ‘Fall’ and ‘No Fall’ events in complex scenarios concerning both indoor (i.e., home) and outdoor (i.e., road) areas. The TLG-LSTM consists of four phases: (i) object detection and tracking, (ii) MoveNet-Lightening and object-level feature(s) computation for all the detected objects, (iii) granule formation using these features, and (iv) temporal self attention mechanism-based Bi-LSTM for granule classification as ‘Fall’ or ‘No Fall’. Unlike state-of-the-art models, TLG-LSTM uses both MoveNet-Lightning and object-level features, enabling better modeling of both indoor and outdoor falls. For each detected object, two MoveNet-Lightning features, namely head-hip distance and hip-ankle distance are defined and used for obtaining a granule, namely pose granule. Whereas, three object-level features, namely change in aspect ratio, speed variation, and change in area are used for obtaining another granule, namely object granule. The commonality between these two granules represents the approximate regions concerning fall scenarios. Instead of the entire frame, these common granules are fed to the Bi-LSTM network for fall classification, thereby increasing speed as well as accuracy. Moreover, temporal self attention mechanism-based transfer learning is used to re-train the Bi-LSTM network, enhances the training speed and accuracy. Characteristics of TLG-LSTM are demonstrated over several real-time traffic videos acquired from ‘YouTube8M’. The superiority of the developed TLG-LSTM is also claimed over several state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Anima Pramanik and Soumick Sarker and Sobhan Sarkar and Sankar K. Pal},
  doi          = {10.1016/j.knosys.2025.113038},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113038},
  shortjournal = {Knowl. Based Syst.},
  title        = {Real-time fall detection on roads using transfer learning-based granulated bi-LSTM},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized double transformer residual super-resolution network-based X-ray images for classification of pneumonia identification. <em>KBS</em>, <em>311</em>, 113037. (<a href='https://doi.org/10.1016/j.knosys.2025.113037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia is an infectious disease characterized by inflammation of the lungs' air sacs, which results in the accumulation of fluid or pus. Medical images is important for the timely identification and precise diagnosis of illnesses; chest X-rays are a commonly utilized modality for respiratory disorders including pneumonia. In this research, optimized double transformer residual super-resolution network-related chest x-ray imageries for the classification of pneumonia identification (DTRSN-XRI-CPI). The procedure involves pre-processing the input image using region-aware neural graph collaborative filtering (RNGCF) to reduce noise, enhance contrast, and eliminate high and low frequencies from the collected dataset. Next, the Synchro-squeezed fractional wavelet transform (SFWT) is utilized for the feature extraction to extract color features such as color, shape, spatial, texture, and relation from the image. Hence, the weight parameters for DTRSN are optimized using the Hunter Prey Optimization Algorithms (HPOA). Then the DTRSN-XRI-CPI is implemented in Python and the performance metrics like precision, accuracy, recall, specificity, F1-score, and ROC are analysed. The performance of the DTRSN-XRI-CPI approach attains 20.7 %, 22.6 % and 30.5 % higher accuracy; 21.8 %, 29.3 % and 30.5 %higher precision and 21.8 %, 29.5 % and 32.6 % higher recall when analysed through existing an intelligent computational framework based on deep learning for the identification and classification of pneumonia illness (ICPD-DL-ICF), an adaptive and altruistic deep feature selection approach based on PSO for pneumonia detection from chest X-rays (APSO-DFSM-PDCX) and a deep learning system that uses explainable AI (DLAIB-PI-EAI) techniques respectively.},
  archive      = {J_KBS},
  author       = {Jerald Prasath G and Prabu S and V. Valli Mayil and Sumit Saini},
  doi          = {10.1016/j.knosys.2025.113037},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113037},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized double transformer residual super-resolution network-based X-ray images for classification of pneumonia identification},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention contrastive learning with missing modality for multimodal recommendation. <em>KBS</em>, <em>311</em>, 113035. (<a href='https://doi.org/10.1016/j.knosys.2025.113035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation plays an important role in many online content-sharing platforms. Most existing reported approaches of multimodal recommendation employ user-interaction graphs or auxiliary graphs (e.g., user–user or item–item relation graphs) to augment user and/or item representations. However, real-world data suffer the problem of missing modality which affects recommendation performance. In this paper, we propose the Graph Attention Contrastive Learning with Missing Modality (MMGACL) model utilizing modality complementation and modality fusion of modality-aware user–item graphs to enhance recommendations. In particular, we construct user–item bipartite graphs for each modality and extract item subgraphs, leveraging contextual information to enhance item representations. Thereafter, we employ a bimodal attention mechanism to provide complementary information across modalities and fuse different modalities. The fused item representations are combined with user–item interactions to complement user information. Finally, we perform graph contrastive learning on the completed global graph to maximize mutual information between users and items and learn more accurate embedding representations. Extensive experiments on four benchmark datasets demonstrate the effective performance of our proposed model versus several state-of-the-art methods in scenarios with missing modality.},
  archive      = {J_KBS},
  author       = {Wenqian Zhao and Kai Yang and Peijin Ding and Ce Na and Wen Li},
  doi          = {10.1016/j.knosys.2025.113035},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113035},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph attention contrastive learning with missing modality for multimodal recommendation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A construction of hyperbolic tree-based graph convolutional networks utilizing the padé approximation. <em>KBS</em>, <em>311</em>, 113034. (<a href='https://doi.org/10.1016/j.knosys.2025.113034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) (Zhang et al., 2018) are known for their exceptional graph learning performance. However, they have difficulties with complex topological structures, which can lead to over-smoothing and computational inefficiency. Existing hyperbolic GCN models are unable to efficiently capture the intricate features of such graphs, resulting in reduced accuracy. A hyperbolic tree-based graph convolutional neural network (HTGCN) is proposed that preserves the complexity of graph structures and mitigates the problem of over-smoothing by transforming graphs into tree structures and using hyperbolic models to aggregate key features. HTGCN improves the topological and spatial mapping of datasets. It also uses a parallel strategy for logarithmic and exponential approximation. Experimental results on six real-world datasets demonstrate that HTGCN improves accuracy in node classification and link prediction tasks compared to existing hyperbolic GCNs and topological structure models. This highlights its unique advantage in handling complex network structures. This paper extends the application of HGCNs and provides a new perspective and tools for deep learning models to handle complex networks.},
  archive      = {J_KBS},
  author       = {Bo Peng and Huan Xu and Yupeng Sun and Quanle Liu and Xiangjiu Che},
  doi          = {10.1016/j.knosys.2025.113034},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113034},
  shortjournal = {Knowl. Based Syst.},
  title        = {A construction of hyperbolic tree-based graph convolutional networks utilizing the padé approximation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDC: Dynamic distribution calibration for few-shot learning under multi-scale representation. <em>KBS</em>, <em>311</em>, 113030. (<a href='https://doi.org/10.1016/j.knosys.2025.113030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in few-shot learning (FSL) have attracted significant attention. However, many existing methods focus primarily on optimizing training processes and sample generation, often overlooking the crucial task of accurately modeling the true feature distribution of few-shot classes. In this paper, we propose a novel dynamic distribution calibration method for few-shot learning under multi-scale representation. This method captures multi-dimensional and directional information in the feature space and dynamically learns a similarity matrix between samples, enabling the few-shot class distributions to better approximate the true distribution. The method involves two key steps. First, a multi-scale representation strategy optimizes feature representation across multiple dimensions and directions using a feature description matrix and composite metric, leading to more accurate similarity calculations between base and novel class samples. Second, a dynamic calibration strategy constructs a dynamic weight matrix based on sample similarity, automatically selecting the appropriate number and weight of base class samples for distribution calibration. This ensures that the calibrated distribution closely aligns with the true unbiased distribution. On benchmarks miniImageNet, CUB and CIFAR-FS, our method outperformed state-of-the-art methods in both the 5-way-1-shot and 5-way-5-shot settings, demonstrating its effectiveness in few-shot distribution calibration.},
  archive      = {J_KBS},
  author       = {Lingxing Chen and Yang Gu and Yi Guo and Fan Dong and Dongmei Jiang and Yiqiang Chen},
  doi          = {10.1016/j.knosys.2025.113030},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113030},
  shortjournal = {Knowl. Based Syst.},
  title        = {DDC: Dynamic distribution calibration for few-shot learning under multi-scale representation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corporate relation extraction for the construction of knowledge-bases against tax fraud. <em>KBS</em>, <em>311</em>, 113026. (<a href='https://doi.org/10.1016/j.knosys.2025.113026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tax fraud is a criminal activity that entails significant losses for governments. Due to its clandestine nature, it is difficult to reliably estimate the amount of taxes evaded. To fight tax fraud, this investigation details the construction and evaluation of a corporate relation extraction system designed to access an unstructured knowledge-base and extract corporate relations for further validation. The system was developed in response to a need raised by the Treasury and Finance Department of the Provincial Council of Gipuzkoa (Spain). It follows a waterfall architecture that integrates Natural Language Processing (NLP) and Computer Vision (CV) components, including web scraping, optical character recognition, syntactic parsing, and information extraction. The proposed system produces a relational knowledge-base with structured data representing 23 types of corporate operations published in the Official Gazette of the Commercial Registry (e.g., incorporation of companies, terminations, capital increases and reductions, mergers and takeovers, etc.), allowing for comparison with the fiscal information available in the tax agency. Facilitating such comparison across distinct sources is key to identifying discrepancies that might be indicators of tax fraud.},
  archive      = {J_KBS},
  author       = {Inigo Lopez-Gazpio and Laura Baselga-Pascual and Aitor Garmendia-Lazcano},
  doi          = {10.1016/j.knosys.2025.113026},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113026},
  shortjournal = {Knowl. Based Syst.},
  title        = {Corporate relation extraction for the construction of knowledge-bases against tax fraud},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social bot detection using variational generative adversarial networks with hidden markov models in twitter network. <em>KBS</em>, <em>311</em>, 113019. (<a href='https://doi.org/10.1016/j.knosys.2025.113019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online social networks (OSNs), bots are creative software programs which attempt to manipulate and influence benign accounts by disseminating fake information. Recent approaches to bot identification suffer from imbalanced data, as well as overfitting and scalability related issues. To address these challenges, this paper proposes a novel two-stage approach, called hidden Markov model based variational generative adversarial network (HMM-VGAN). The first stage trains the variational autoencoder (VAE) using a set of features, such as profile, URL, word embedding over linguistic, user behavioral pattern, and social relationship with a goal to remove noisy data. The second stage integrates VAE with generative adversarial networks (VGAN) which is used for generating an augmented data to overcome imbalanced distribution of data. The second stage proposes an ensemble based HMM with a pre-trained recurrent neural network of VGAN algorithm for bot identification. Experimental results using three Twitter datasets demonstrate the efficacy of the proposed HMM-VGAN algorithm in terms if performance metrics such as precision, recall and accuracy. Precisely, the proposed HMM-VGAN algorithm achieves around 95% precision and up to 4%–10% improvement on precision over other existing approaches.},
  archive      = {J_KBS},
  author       = {Greeshma Lingam and Sajal K. Das},
  doi          = {10.1016/j.knosys.2025.113019},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113019},
  shortjournal = {Knowl. Based Syst.},
  title        = {Social bot detection using variational generative adversarial networks with hidden markov models in twitter network},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VAE-CapsNet: A common emotion information extractor for cross-subject emotion recognition. <em>KBS</em>, <em>311</em>, 113018. (<a href='https://doi.org/10.1016/j.knosys.2025.113018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the uniqueness of brain structure, function, and emotional experiences, neural activity patterns differ among subjects. As a result, affective brain–computer interfaces (aBCIs) must account for individual differences in neural activity, electroencephalogram data, and particularly emotion pattern (EP). These differences in emotion information types and distribution patterns, such as session EP differences (SEPD) and individual EP differences (IEPD), pose notable challenges for cross-subject and cross-session emotion classification. To address these challenges, we propose a novel common emotion information extraction framework VAE-CapsNet that combines a variational autoencoder (VAE) and capsule network (CapsNet). A VAE-based unsupervised EP transformation module is used to mitigate SEPD, while five segmental activation functions are introduced to match EPs across different subjects. The CapsNet-based information extractor efficiently handles various emotion information, producing universal emotional features from different sessions. We validated the performance of the VAE-CapsNet framework through cross-session, cross-subject, and cross-dataset experiments on the SEED, SEED-IV, SEED-V, and FACED datasets.},
  archive      = {J_KBS},
  author       = {Huayu Chen and Junxiang Li and Huanhuan He and Shuting Sun and Jing Zhu and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.knosys.2025.113018},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113018},
  shortjournal = {Knowl. Based Syst.},
  title        = {VAE-CapsNet: A common emotion information extractor for cross-subject emotion recognition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relevant emotion ranking with topic-enhanced emotion transition. <em>KBS</em>, <em>311</em>, 113015. (<a href='https://doi.org/10.1016/j.knosys.2025.113015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion detection aims to predict multiple emotions associated with a given text. Relevant Emotion Ranking (RER) goes one step further to rank relevant emotions by their intensities while irrelevant emotions are excluded. However, previous relevant emotion ranking methods predict emotions directly from the document, ignoring the transition of emotions over sentences. We argue that such a transition can be vital for the RER method. Because based on humans’ reading or writing habits, sentences at tail can be more influential for document-level emotions. Therefore, a novel relevant emotion ranking model with emotion transition motivated by the time series method is proposed, where the current document-level emotions are estimated by the historical global emotions and the present local emotions. Furthermore, we argue that the topic transition between sentences evokes the emotional transition between sentences. A hybrid information encoder with a topic generation module is proposed, where the sentence-level topic information is extracted to enhance the emotion transition. Experimental results demonstrate the effectiveness of the proposed model compared to other state-of-the-art relevant emotion ranking methods and large language models on two real-world datasets.},
  archive      = {J_KBS},
  author       = {Linhai Zhang and Xin Zhang and Deyu Zhou},
  doi          = {10.1016/j.knosys.2025.113015},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113015},
  shortjournal = {Knowl. Based Syst.},
  title        = {Relevant emotion ranking with topic-enhanced emotion transition},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-label enhancement for weakly supervised object detection using self-supervised vision transformer. <em>KBS</em>, <em>311</em>, 113012. (<a href='https://doi.org/10.1016/j.knosys.2025.113012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised object detection (WSOD) using image-level labels has gained attention in the computer vision community. Most advanced WSOD approaches generate instance-level labels based on class activation maps (CAMs), which are limited by incomplete box labels and sparse information regarding class labels. These inaccurate pseudo-labels mislead the training of the subsequent detection module, thus hampering detection performance. To address these issues, we propose a novel pseudo-label enhancement (PLE) framework for a one-stage WSOD method that consists of a CAM reassembly (CAMR) and a composite scoring module (CSM). The CAMR explores the collaboration between class priors from CAMs and the semantic-aware grouping ability of self-supervised vision transformers (ViTs). Specifically, CAMR initially propagates object localization cues from CAMs to feature maps obtained using a self-supervised ViT. Subsequently, CAMR utilizes the patch affinity of these feature maps to extract more integral object information and improve the instance localization accuracy and completeness. Subsequently, the reassembled CAMs are refined using a multi-threshold strategy to generate bounding-box pseudo-labels. The CSM replaces one-hot labels with soft-class labels that leverage localization precision and classification confidence to counter information sparseness limitations. The proposed PLE is evaluated using the PASCAL VOC and MS-COCO datasets. The experimental results demonstrate that the performance of PLE surpasses that of the advanced methods. On average, PLE improves by 7.1% mAP on the VOC 2007 test set and 6.0% mAP on the MS-COCO 2017 validation set compared with the one-stage WSOD method.},
  archive      = {J_KBS},
  author       = {Kequan Yang and Yuanchen Wu and Jide Li and Chao Yin and Xiaoqiang Li},
  doi          = {10.1016/j.knosys.2025.113012},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113012},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pseudo-label enhancement for weakly supervised object detection using self-supervised vision transformer},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional domain transfer knowledge distillation for catastrophic forgetting in federated learning with heterogeneous data. <em>KBS</em>, <em>311</em>, 113008. (<a href='https://doi.org/10.1016/j.knosys.2025.113008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning approach that has gained significant attention owing to its advantages in privacy protection and data security. However, the heterogeneous data distribution among clients makes these models susceptible to catastrophic forgetting during continuous learning, resulting in the loss of knowledge from previous tasks. To address this issue, this paper presents a bidirectional domain transfer knowledge distillation framework that incorporates knowledge transfer and knowledge retrospection modules. The proposed framework enhances knowledge preservation and sharing capabilities in FL scenarios. The knowledge transfer module mitigates knowledge forgetting due to data heterogeneity by distilling key knowledge between global and local models. Meanwhile, the knowledge retrospection module allows the model to review historical information when updating the current task, improving stability and adaptability. The experimental results demonstrate that the proposed framework significantly reduces catastrophic forgetting in non-independent and identically distributed (non-IID) data environments and improves the model’s generalization performance. Compared to traditional FL methods, the proposed method achieves better knowledge preservation across various datasets.},
  archive      = {J_KBS},
  author       = {Qi Min and Fei Luo and Wenbo Dong and Chunhua Gu and Weichao Ding},
  doi          = {10.1016/j.knosys.2025.113008},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113008},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bidirectional domain transfer knowledge distillation for catastrophic forgetting in federated learning with heterogeneous data},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneity-aware pruning framework for personalized federated learning in remote sensing scene classification. <em>KBS</em>, <em>311</em>, 113007. (<a href='https://doi.org/10.1016/j.knosys.2025.113007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is widely applied in remote sensing image classification due to its capability to protect data privacy and effectively utilize distributed data sources. However, limited computational resources on edge devices at client-side lead to poor communication performance among scene classification models in federated learning. Therefore, we propose a heterogeneity-aware pruning framework (HAPF) to personalize the pruning of clients. Specifically, we design a data-personalized pruning method (DPPM) that customizes each local model structure based on the amount of data input from edge devices to enhance the understanding capability of scene classification. In particular, we design a personalized pruning strategy, which is based on the eigenvalue distribution mechanism (EDM). It utilizes the eigenvalue distribution of the convolutional layers to measure the redundancy of the filters, thus minimizing the model complexity while preserving key information. Given the difficulty of aggregating models at a central server caused by the heterogeneity of pruned models from different clients, we adopt an adaptive heterogeneous aggregation mechanism (AHAM). AHAM selects the appropriate pruned model structure as the aggregation baseline, ensuring seamless integration and parameter aggregation across different clients. Surprisingly, the experimental results of VGG-16 and ResNet-50 on AID, NWPU-RESISC45, PatternNet and WHU-RS19 datasets show that HAPF reduces floating point operations per second (FLOPs) and parameters effectively, as well as improves the model accuracy. That means HAPF can not only save the training computation resource for local training but also improve the generalization of the global model in federated learning.},
  archive      = {J_KBS},
  author       = {Zhuping Hu and Maoguo Gong and Zhuowei Dong and Yiheng Lu and Jianzhao Li and Yue Zhao},
  doi          = {10.1016/j.knosys.2025.113007},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113007},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneity-aware pruning framework for personalized federated learning in remote sensing scene classification},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expression prompt collaboration transformer for universal referring video object segmentation. <em>KBS</em>, <em>311</em>, 113006. (<a href='https://doi.org/10.1016/j.knosys.2025.113006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly related tasks aiming to segment specific objects from video sequences according to expression prompts. However, due to the challenges of modeling representations for different modalities, existing methods struggle to balance between interaction flexibility and localization precision. In this paper, we address this problem from two perspectives: the alignment of audio and text and the deep interaction among audio, text, and visual modalities. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text. The proposed EPCFormer exploits the fact that audio and text prompts referring to the same objects are semantically equivalent by using contrastive learning for both expressions. Then, to facilitate deep interactions among audio, text, and visual modalities, we introduce an Expression-Visual Attention (EVA) module. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our EPCFormer attains state-of-the-art results on both tasks.},
  archive      = {J_KBS},
  author       = {Jiajun Chen and Jiacheng Lin and Guojin Zhong and Haolong Fu and Ke Nai and Kailun Yang and Zhiyong Li},
  doi          = {10.1016/j.knosys.2025.113006},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113006},
  shortjournal = {Knowl. Based Syst.},
  title        = {Expression prompt collaboration transformer for universal referring video object segmentation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aggregated mutual learning between CNN and transformer for semi-supervised medical image segmentation. <em>KBS</em>, <em>311</em>, 113005. (<a href='https://doi.org/10.1016/j.knosys.2025.113005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent Advances show that both Convolutional layers and Transformer blocks have their own advantages in the feature learning tasks of medical image analysis. However, the existing models combining both CNN and Transformers cannot effectively integrate the features extracted by both networks. In this work, we propose a new semi-supervised medical image segmentation method which can effectively aggregate mutual learning between CNN and Transformer, denoted AML-CT, which consists of an auxiliary module and a main network. Specifically, the auxiliary module consists of two segmentation subnetworks based on CNN and Transformer, aiming at extracting features from different perspectives, where, to enhance integration of image features from distinct segmentation networks, a Cross-Branch Feature Fusion module is proposed to effectively fuses local and global information via internal cross-fusion of feature maps between networks. Then, to aggregate the extracted image features from the auxiliary module, a three-branch network (TB-net) structure is further proposed to learn the extracted joint features and facilitate aggregation of multi-source information. Experimental results on two public datasets demonstrate that: (i) AML-CT successfully accomplishes medical image segmentation tasks with limited labeled data, outperforming recent mainstream semi-supervised segmentation methods; (ii) Ablation studies confirm the effectiveness of each module in the AML-CT model for performance improvement.},
  archive      = {J_KBS},
  author       = {Zhenghua Xu and Hening Wang and Runhe Yang and Yuchen Yang and Weipeng Liu and Thomas Lukasiewicz},
  doi          = {10.1016/j.knosys.2025.113005},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113005},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aggregated mutual learning between CNN and transformer for semi-supervised medical image segmentation},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized multi-anchor space-aware temporal convolutional neural network for automobile sales prediction. <em>KBS</em>, <em>311</em>, 113000. (<a href='https://doi.org/10.1016/j.knosys.2025.113000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sales forecasting is essential for effective operations, resource management, and well-informed strategic decision-making in the competitive and fast-paced automobile industry. The traditional methods that merely consider historical performance and market trends may overlook crucial information. Therefore, an Optimized Multi-anchor Space-aware Temporal Convolutional Neural Network for Automobile Sales Prediction (MSTCNN-AM-SP) is proposed in this manuscript. Initially, the input data is gathered from Historical Automobile Sales dataset. The collected data is given to pre-processing using Sigma-Mixed Unscented Kalman Filter (SMUKF) technique to handle the missing values. After processing the data, Clouded Leopard Optimization Algorithm (CLOA) is used to select the relevant features for car sales. Then the selected features are fed to Multi-anchor Space-aware Temporal Convolutional Neural Network (MSTCNN) for effectively predicting the automobile sales. In general, MSTCNN does not adapt any optimization strategies to determine the optimum parameters to ensure accurate prediction of sales. Hence, Red Billed Blue Magpie Optimizer (RBMO) is proposed to enhance the weight parameter of MSTCNN classifier, which precisely predicts the automobile sales. The proposed MSTCNN-AM-SP method attains 23.56 %, 21.83 % and 23.71 % lower RMSE, 21.19 %, 20.28 % and 21.62 % lower MSE are analyzed with existing techniques, like Sales Demand Forecasting in Car Industry Utilizing Seagull Optimization Depend Holt Winter and Quintile Regression Neural Network (SDF-CI-QRNN), Predictive Modeling Framework for Forecasting Cumulative Sales of Euro-compliant, Battery-electric, Autonomous vehicles (PMF-FCS-BAV) and DL Method for Sales Prediction in Retail Stores: E2E Analysis and Implementation (RNN-SPR-EAI) respectively.},
  archive      = {J_KBS},
  author       = {Sivabalan S and Minu RI},
  doi          = {10.1016/j.knosys.2025.113000},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113000},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized multi-anchor space-aware temporal convolutional neural network for automobile sales prediction},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context gating in spiking neural networks: Achieving lifelong learning through integration of local and global plasticity. <em>KBS</em>, <em>311</em>, 112999. (<a href='https://doi.org/10.1016/j.knosys.2025.112999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans learn multiple tasks in succession with minimal mutual interference, through the context gating mechanism in the prefrontal cortex (PFC). The brain-inspired models of spiking neural networks (SNN) have drawn massive attention for their energy efficiency and biological plausibility. To overcome catastrophic forgetting when learning multiple tasks in sequence, current SNN models for lifelong learning focus on memory reserving or regularization-based modification, while lacking SNN to replicate human experimental behavior. Inspired by biological context-dependent gating mechanisms found in PFC, we propose SNN with context gating trained by the local plasticity rule (CG-SNN) for lifelong learning. The iterative training between global and local plasticity for task units is designed to strengthen the connections between task neurons and hidden neurons and preserve the multi-task relevant information. The experiments show that the proposed model is effective in maintaining the past learning experience and has better task-selectivity than other methods during lifelong learning. Our results provide new insights that the CG-SNN model can extend context gating with good scalability on different SNN architectures with different spike-firing mechanisms. Thus, our models have good potential for parallel implementation on neuromorphic hardware and model human’s behavior.},
  archive      = {J_KBS},
  author       = {Jiangrong Shen and Wenyao Ni and Qi Xu and Gang Pan and Huajin Tang},
  doi          = {10.1016/j.knosys.2025.112999},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112999},
  shortjournal = {Knowl. Based Syst.},
  title        = {Context gating in spiking neural networks: Achieving lifelong learning through integration of local and global plasticity},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reffusion: Enhancement conditional diffusion framework with dual domain interaction transformer for image restoration. <em>KBS</em>, <em>311</em>, 112998. (<a href='https://doi.org/10.1016/j.knosys.2025.112998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is an ill-posed problem that relies on the fidelity of detail recovery and conformity to the original data distribution. Due to their powerful generative abilities, diffusion models have shown potential in image restoration. However, the uncertainty in their noise estimation and detail generation limits their performance. Additionally, existing diffusion models focus on processing in pixel space, without considering the advantages of frequency information. To address these issues, we propose the Enhancement Conditional Diffusion Framework with Dual Domain Interaction Transformer for image restoration, called Reffusion. We employ the conditional diffusion model for stable restoration and propose an enhancement training strategy to enhance the fidelity of detail restoration. The discrete wavelet transform (DWT) is utilized to capture multi-scale frequency information, facilitating the fusion of local representation through interaction with spatial features. Moreover, we employ the fast Fourier transform (FFT) for feature conversion in self-attention, enabling Reffusion to capture dual domain long-range dependencies. By integrating frequency and spatial features, our method achieves accurate noise estimation and high fidelity detail recovery. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art (SOTA) methods in low-light image enhancement, image deraining, and image desnowing, and validate the effectiveness of our method in high-level vision.},
  archive      = {J_KBS},
  author       = {Dirui Xie and Xiaofang Hu and He Xiao and Yue Zhou and Shukai Duan},
  doi          = {10.1016/j.knosys.2025.112998},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112998},
  shortjournal = {Knowl. Based Syst.},
  title        = {Reffusion: Enhancement conditional diffusion framework with dual domain interaction transformer for image restoration},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robustness of object detection: Hubel–Wiesel model connected with deep learning. <em>KBS</em>, <em>311</em>, 112984. (<a href='https://doi.org/10.1016/j.knosys.2025.112984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of deep learning, object detection has become an increasingly important aspect of this field. As research on neural networks continues to advance, many effective models have emerged, improving both the accuracy and the training speed of these tasks. However, enhancing the robustness of models remains a challenging task in deep learning. Most of the suggested methods have been tailored to enhance robustness for specific models and tasks, leaving few options applicable to universal models and datasets. We propose an artificial visual system derived from the Hubel–Wiesel model. This model is a widely recognized neurobiological theory that explains how cortical neurons achieve selective responses to visual stimuli in terms of their orientation. However, it primarily elucidates the organization and facilitation of visual information processing within the visual cortex. To simulate simple and complex cells found in the visual cortex, we have employed the McCulloch–Pitts (MP) neuron model. By doing so, we have constructed an artificial visual system (AVS) focused on object detection and noise reduction. Our study significantly improves the robustness of the model on a universal model and dataset through a series of experiments. Through these experiments, we demonstrate that our scheme exhibits substantial advantages in noise resistance compared to a single neural network. These results not only validate the effectiveness of our scheme but also indirectly support the rationale behind the Hubel–Wiesel model and highlight its biological resemblance to the natural vision system.},
  archive      = {J_KBS},
  author       = {Yu Wang and Bin Li and Yuki Todo},
  doi          = {10.1016/j.knosys.2025.112984},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112984},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing robustness of object detection: Hubel–Wiesel model connected with deep learning},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ContReviews: A content-based recommendation system for updating living evidences in health care. <em>KBS</em>, <em>311</em>, 112981. (<a href='https://doi.org/10.1016/j.knosys.2025.112981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systematic reviews (SRs) summarise the knowledge available in the literature related to a specific research topic. Keeping SRs up-to-date with new publications as soon as they become available is fundamental to avoid their early obsolescence. Recently, automated methods have been proposed to update one or more SRs. However, particularly in the health care domain, it is necessary to scale these methods to maintain Living Evidences , which comprise thousands of SRs. In this context, the main issue of using the current methods is that they are SR-specific, that is, they require manually designing and optimising search queries and eligibility assessment models for each SR. To address this challenge, the ContReviews system is proposed. ContReviews first leverages an academic knowledge graph to gather new publications, and then uses a content-based recommendation model to match these new publications to all the SRs in a Living Evidence . To faithfully represent new publications and SRs, multiple publication properties are used (i.e., title, abstract, citation network, and authors) and, for each of them, likelihoods of relevance are calculated and used to learn a relevance assessment function for an entire Living Evidence . ContReviews has been evaluated on a dataset of 6000+ Cochrane Reviews in the health care domain, reporting high efficiency and high effectiveness in recommending new publications to the Cochrane Reviews. Specifically, ContReviews has achieved an average precision of 98.1% with a recall of 100% on the considered Cochrane Reviews.},
  archive      = {J_KBS},
  author       = {Paolo Tenti and James Thomas and Rafael Peñaloza and Gabriella Pasi},
  doi          = {10.1016/j.knosys.2025.112981},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112981},
  shortjournal = {Knowl. Based Syst.},
  title        = {ContReviews: A content-based recommendation system for updating living evidences in health care},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end controller with image-based visual servoing of industrial manipulators with soft-actor-critic algorithm. <em>KBS</em>, <em>311</em>, 112980. (<a href='https://doi.org/10.1016/j.knosys.2025.112980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an end-to-end vision servoing controller based on a soft-actor-critic deep reinforcement learning algorithm was designed to address the key challenges in image-based vision servoing systems. These challenges include: First, significant nonlinearities and coupling effects between the velocities of image features and camera movements, and second, the singularities associated with robot poses. To enhance the training efficiency and control accuracy of the visual servoing localization tasks, a novel reward function is proposed. The advantages of the approach were evaluated by comparing the control performance of agents trained with two reward functions and conducting simulation experiments with five mainstream controllers. The experimental results demonstrated that, compared with the traditional reward functions, the proposed reward function significantly improves the guidance of agent behavior and enhances the efficiency and effectiveness of task completion. Furthermore, the proposed control method achieved an order-of-magnitude improvement in control accuracy compared with those of traditional controllers and exhibited superior global convergence. Finally, a real-time control system based on ROS2 and IGH protocol master was developed to facilitate practical deployment. Experimental results indicate that, in real-world scenarios, the proposed approach achieves a control accuracy comparable to that observed in simulations. In addition, a valuable example of the application of deep reinforcement learning algorithms in the field of high-precision visual servoing control is also provided.},
  archive      = {J_KBS},
  author       = {Zhongcan Li and Yufei Zhou and Lining Wang and Xianke Zhang and Ang Li and Mingchao Zhu and Qingwen Wu},
  doi          = {10.1016/j.knosys.2025.112980},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112980},
  shortjournal = {Knowl. Based Syst.},
  title        = {An end-to-end controller with image-based visual servoing of industrial manipulators with soft-actor-critic algorithm},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VSI: An interpretable bayesian feature selection method based on vendi score. <em>KBS</em>, <em>311</em>, 112973. (<a href='https://doi.org/10.1016/j.knosys.2025.112973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practitioners use various feature importance metrics to rank features based on their importance to discard weak predictors, simplifying predictive models and improving generalizability. Model-dependent feature ranking methods often rely on training a machine learning model. However, a common issue is the confusion between feature importance and feature impact on the trained model, leading to potential misinterpretations in fields such as medicine and business. This problem primarily stems from the widespread use of model-based methods that leads to misinterpreting feature importance with its impact on the trained model. To address this, we introduce Vendi Score Importance (VSI), an interpretable model-independent feature ranking metric. VSI quantifies each feature’s impact on the overall Vendi score instead of a machine learning model, beginning with only the target/label and sequentially adding features. As a model-independent metric, VSI relies solely on feature and target values, making it applicable to both classification and regression tasks. We demonstrate VSI’s effectiveness through applications to four benchmark problems (two classification and two regression), comparing it to LIME, Permutation, and SHAP (model-agnostic methods), as well as Mutual Information Regression (MIR), a univariate, model-independent approach. Results show that VSI not only provides interpretable importance scores for each feature but also outperforms others in computational efficiency. To confirm VSI’s robustness against random noise, we repeated the feature ranking procedure 100 times, introducing different random features each time. The results highlight VSI’s superior performance, particularly in maintaining agnosticism to random noise.},
  archive      = {J_KBS},
  author       = {Mohsen Mousavi and Nasser Khalili},
  doi          = {10.1016/j.knosys.2025.112973},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112973},
  shortjournal = {Knowl. Based Syst.},
  title        = {VSI: An interpretable bayesian feature selection method based on vendi score},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ATSumm: Auxiliary information enhanced approach for abstractive disaster tweet summarization with sparse training data. <em>KBS</em>, <em>311</em>, 112969. (<a href='https://doi.org/10.1016/j.knosys.2025.112969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of situational information on Twitter poses a challenge for users to manually discern vital and relevant information during disasters. A concise and human-interpretable overview of this information can aid decision makers implement efficient and quick disaster responses. Existing abstractive summarization approaches can be categorized as sentence- or key-phrase-based. This study focused on a sentence-based approach, which is typically implemented as a dual-phase procedure. The initial phase, known as the extractive phase, involves the identification of the most relevant tweets. The subsequent phase, which is referred to as the abstractive phase, generates a more human-interpretable summary. In this study, we adopted a methodology from prior research for the extractive phase. Most existing approaches employ deep learning-based frameworks for the abstractive phase of summarization. Such frameworks can either be pre-trained or require training from scratch. However, to achieve an appropriate level of performance, it is imperative to have substantial training data for both methods, which are not readily available. This study proposed an abstractive tweet summarizer (ATSumm) that effectively addresses the issue of data sparsity using auxiliary information. We introduced the auxiliary pointer generator network (AuxPGN) model, which utilizes a unique attention mechanism called key-phrase attention . This attention mechanism incorporates auxiliary information in the form of key-phrases and their corresponding importance scores from the input tweets. We evaluated the proposed approach through comparisons with 10 state-of-the-art approaches across 13 disaster datasets. The evaluation results indicated that ATSumm achieved superior performance compared with state-of-the-art approaches, with an improvement of 4 − 80 % in the ROUGE-N F1-score.},
  archive      = {J_KBS},
  author       = {Piyush Kumar Garg and Roshni Chakraborty and Sourav Kumar Dandapat},
  doi          = {10.1016/j.knosys.2025.112969},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112969},
  shortjournal = {Knowl. Based Syst.},
  title        = {ATSumm: Auxiliary information enhanced approach for abstractive disaster tweet summarization with sparse training data},
  volume       = {311},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked region disparity-based unsafe behavior detection via campus monitoring device images. <em>KBS</em>, <em>310</em>, 113051. (<a href='https://doi.org/10.1016/j.knosys.2025.113051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsafe behaviour on campuses is identifiable through monitoring device inputs analyzed using computer vision-aided techniques. Disparities in features, such as pixels and edges, of the input objects are correlated to detect unsafe behavior. The existing masked region disparity-based approach struggles to detect unsafe actions in busy campus contexts due to partial occlusions. Environmental factors, such as illumination and perspective, also affect detection accuracy. Therefore, this study proposes a masked region-centric disparity detection method with a Convolutional Neural Network (CNN) to detect unsafe behavior. This method is designed to identify group feature disparities in multiple regions represented in the input image. Object masks are generated to identify mismatched masks based on the areas and their feature differences. CNN is trained to identify regional feature disparities to prevent mask misdetection. In this approach, disparity masks are used to classify the unsafe behavior of the objects in the scene. Additionally, the convolution layer estimates disparity through previous and continuous region masks to enhance detection precision. The proposed method achieves 96.15 % high identification precision, 98.469 % high classification rate, and a 0.045 % reduction in false detection rates for the highest possible maximum regions used.},
  archive      = {J_KBS},
  author       = {Yuhua Wu and Shujuan Feng and Yangkai Wu and Jinming Wang and Shitong Zhou and Mengjia Yuan and Ziwei Hu and Cancan Wu},
  doi          = {10.1016/j.knosys.2025.113051},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113051},
  shortjournal = {Knowl. Based Syst.},
  title        = {Masked region disparity-based unsafe behavior detection via campus monitoring device images},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the effectiveness of XAI techniques for encoder-based language models. <em>KBS</em>, <em>310</em>, 113042. (<a href='https://doi.org/10.1016/j.knosys.2025.113042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The black-box nature of large language models (LLMs) necessitates the development of eXplainable AI (XAI) techniques for transparency and trustworthiness. However, evaluating these techniques remains a challenge. This study presents a general evaluation framework using four key metrics: Human-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. We assess the effectiveness of six explainability techniques from five different XAI categories—model simplification (LIME), perturbation-based methods (SHAP), gradient-based approaches (InputXGradient, Grad-CAM), Layer-wise Relevance Propagation (LRP), and attention mechanisms-based explainability methods (Attention Mechanism Visualization, AMV)—across five encoder-based language models: TinyBERT, BERTbase, BERTlarge, XLM-R large, and DeBERTa-xlarge, using the IMDB Movie Reviews and Tweet Sentiment Extraction (TSE) datasets. Our findings show that the model simplification-based XAI method (LIME) consistently outperforms across multiple metrics and models, significantly excelling in HA with a score of 0.9685 on DeBERTa-xlarge, robustness, and consistency as the complexity of large language models increases. AMV demonstrates the best Robustness, with scores as low as 0.0020. It also excels in Consistency, achieving near-perfect scores of 0.9999 across all models. Regarding Contrastivity, LRP performs the best, particularly on more complex models, with scores up to 0.9371.},
  archive      = {J_KBS},
  author       = {Melkamu Abay Mersha and Mesay Gemeda Yigezu and Jugal Kalita},
  doi          = {10.1016/j.knosys.2025.113042},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113042},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evaluating the effectiveness of XAI techniques for encoder-based language models},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decoupling enhancement and mamba depth extraction-based feature fusion in transformer hashing image retrieval. <em>KBS</em>, <em>310</em>, 113036. (<a href='https://doi.org/10.1016/j.knosys.2025.113036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing for image retrieval has garnered significant attention for enabling rapid image retrieval by mapping high-dimensional image features to low-dimensional binary hash codes. However, maximizing the preservation of the original high-dimensional space’s similarity structure within limited-length hash codes remains a key research focus. Contemporary methods often leverage attention mechanisms and Transformers to improve hash code quality, yet they tend to overemphasize high-level semantic features while neglecting crucial connections between lower-level features and hash codes. To address this, we propose FMTH: a framework for Frequency Decoupling Enhancement and Mamba Depth Extraction-Based Feature Fusion in Transformer Hashing Image Retrieval. Our framework introduces three key components: (1) an adaptive frequency-domain decoupling enhancement module using discrete cosine transform to target missing information in hierarchical features, (2) a Hybrid Selection State Space module based on Mamba concept for effective global-local feature extraction, and (3) a global similarity proxy loss for optimizing data correlations. Extensive experiments on CIFAR-10, MS_COCO, and ImageNet datasets demonstrate that FMTH achieves state-of-the-art performance, with improvements of 1.95%, 7.29%, and 1.93% in mean average precision over the best existing methods. These results validate our approach’s effectiveness in preserving similarity structure and enhancing retrieval performance through comprehensive feature utilization and efficient semantic capture. The source code of our FMTH framework is publicly available at https://github.com/cslxju/FMTH .},
  archive      = {J_KBS},
  author       = {Jiayi Chen and Shuli Cheng and Liejun Wang and Yongming Li and Qiang Zou},
  doi          = {10.1016/j.knosys.2025.113036},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113036},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency decoupling enhancement and mamba depth extraction-based feature fusion in transformer hashing image retrieval},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised cross-contrastive learning network for image manipulation detection and localization. <em>KBS</em>, <em>310</em>, 113033. (<a href='https://doi.org/10.1016/j.knosys.2025.113033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant reduction in the cost of image manipulation due to advancements in image editing tools, it is crucial to investigate methods for detecting image manipulation. Currently, mainstream methods are based on various types of deep learning models, which have achieved some success. However, these models largely rely on pixel-level ground truth annotations for supervision, leading to an increase in image-level false positives due to limited real images. Obtaining GT annotations is time-consuming and labor-intensive, and the supervised model has a high demand for tampering mask. To address these limitations, we propose a Weakly-Supervised Cross-Contrastive Learning (WSCCL) network that can detect and locate image manipulation based solely on image-level labels (‘real’/‘tampered’). Specifically, we first leverage a dual-stream encoder–decoder architecture to extract visual and noise features separately and generate corresponding prediction distribution maps. We then adopt an adaptive approach to fuse prediction distribution maps, obtaining weakly-supervised pseudo-label. We design the Cross-Contrastive Learning Module(CCLM) using different aggregation methods for different layer features in the encoder, and apply cross-contrastive learning for the fusion features and the predicted features maps generated by the decoder. Finally, WSCCL compares the similarity between the reconstructed image obtained from the decoder and the predicted distribution map to make the pseudo-label closer to the real GT. Furthermore, extensive experiments confirm that our approach based on weakly supervised learning is comparable to supervised learning, both at the image-level and pixel-level. WSCCL exhibits strong adaptability to various types of manipulation and high resistance to attacks. This study demonstrates that our weakly supervised learning method can compete fully with supervised learning, regardless of the level of manipulation or annotation.},
  archive      = {J_KBS},
  author       = {Ruyi Bai},
  doi          = {10.1016/j.knosys.2025.113033},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113033},
  shortjournal = {Knowl. Based Syst.},
  title        = {Weakly-supervised cross-contrastive learning network for image manipulation detection and localization},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CompoCraft: An expert system for process selection in sustainable composites. <em>KBS</em>, <em>310</em>, 113032. (<a href='https://doi.org/10.1016/j.knosys.2025.113032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the manufacturing landscape continues to evolve, the integration of intelligent decision support systems plays a pivotal role in offering sustainable, efficient, and informed decision making. The current study presents CompoCraft , a rule-based knowledge expert system designed to optimize manufacturing process selection for sustainable polymer composites during the conceptual design stage. The knowledge base for the expert system was developed using inputs from the domain experts across academia and industry. The process-criteria compatibility mapping was conducted using fuzzy ratings; where the criteria included material, part characteristics, and production requirements. The expert system performed selection in two phases: screening and ranking. The ranks of the screened processes were based on the process compatibility score (PCS). Additionally, a comparison based on cost ratings was conducted, empowering the designer to make an informed decision and select the most cost-effective process from the pool of highly compatible options. The validation of the system was performed by showcasing two case studies (Case I: coir polypropylene composite panel knob and Case II: jute epoxy composite chair back support and seat boards) for the natural fiber reinforced polymer composites. Thereon, sensitivity analysis was conducted to justify the system stability. Finally, the robust expert system; CompoCraft can be effectively used by domain practitioners, designers, or researchers.},
  archive      = {J_KBS},
  author       = {Aditi Mahajan and Inderdeep Singh and Navneet Arora},
  doi          = {10.1016/j.knosys.2025.113032},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113032},
  shortjournal = {Knowl. Based Syst.},
  title        = {CompoCraft: An expert system for process selection in sustainable composites},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale common-private feature adversarial decoupling network for hyperspectral pansharpening. <em>KBS</em>, <em>310</em>, 113031. (<a href='https://doi.org/10.1016/j.knosys.2025.113031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral pansharpening involves the fusion of a high-resolution panchromatic (PAN) image with a lower-resolution hyperspectral (LRHS) image, yielding a remarkable high-resolution hyperspectral (HRHS) image. Most of the existing pansharpening methods design specific feature extraction modules to dig deep spatial–spectral features. However, these methods ignore the commonalities and characteristics between PAN image and HS image, which may cause common information redundancy and private information loss. Here, we propose a multiscale common-private feature decoupling network based on adversarial learning (called HP-MFDN) for HS pansharpening, which refines and integrates the common-private features extracted from PAN and LRHS images of different scales losslessly, enhancing the pansharpening performance by fully utilizing the complementary information of PAN and HS images. Specifically, in each scale of PAN and HS images, the co-learning common-private feature decoupling module (CL-CPFDM) consisting of adversarial learning network and the specific decoupling losses is presented to decouple PAN and HS features into mutually orthogonal and independent common-private features. In addition, we specially design an information lossless refinement-based fusion module (ILRFM) for private information integration based on invertible neural network (INN), ensuring an effective spatial–spectral information flow for HRHS image reconstruction. Experimental results demonstrate that the proposed HP-MFADN outperforms other widely accepted state-of-the-art methods in both objective metrics and visual appearance. The code link is: https://github.com/Jiahuiqu/HP-MFDN .},
  archive      = {J_KBS},
  author       = {Shaoxiong Hou and Song Xiao and Jiahui Qu and Wenqian Dong},
  doi          = {10.1016/j.knosys.2025.113031},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113031},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiscale common-private feature adversarial decoupling network for hyperspectral pansharpening},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DyCR-net: A dynamic context-aware routing network for multi-modal sarcasm detection in conversation. <em>KBS</em>, <em>310</em>, 113029. (<a href='https://doi.org/10.1016/j.knosys.2025.113029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is frequently used as a rhetorical device in daily life, where speakers express criticism, mockery, or irony by saying the opposite of what they mean or making statements that contrast with reality. In everyday conversations, humans typically rely on context to detect sarcastic intent, interpreting the background of the dialogue, perceiving emotions conveyed through tone of voice, and decoding non-verbal cues from body language and facial expressions. Most existing studies focus on constructing multimodal representations and identifying inconsistencies between modalities as indicators of sarcasm. However, the dynamic shifts in modality focus are critical for understanding complex real-world sarcastic scenarios. To address this, we propose a Dynamic Context-Aware Routing Network (DyCR-Net), which leverages multi-granularity cues from various modalities and constructs cross-modal routing networks (Text–Video, Text–Audio, and Video–Audio) that prioritize different networks depending on the sarcastic scenario. The weights of the routing networks are dynamically adjusted to better capture the required sarcastic information. Notably, our framework outperforms current state-of-the-art methods across multiple benchmark datasets.},
  archive      = {J_KBS},
  author       = {Xingjie Zhuang and Zhixin Li and Fengling Zhou and Jingliang Gu and Canlong Zhang and Huifang Ma},
  doi          = {10.1016/j.knosys.2025.113029},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113029},
  shortjournal = {Knowl. Based Syst.},
  title        = {DyCR-net: A dynamic context-aware routing network for multi-modal sarcasm detection in conversation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated waste classification system using deep learning techniques: Toward efficient waste recycling and environmental sustainability. <em>KBS</em>, <em>310</em>, 113028. (<a href='https://doi.org/10.1016/j.knosys.2025.113028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing negative effects caused by inadequate waste processing have led to the widespread implementation of waste classification systems. One effective approach is to develop an automated classification system that uses advanced waste recognition technology. This method can decrease the amount of manual labor required for waste separation and recycling activities. In the present study, a novel three-stage waste classification system was proposed. It incorporates the parallel lightweight depth-wise separable convolutional neural network (DP-CNN) in conjunction with the ensemble extreme learning machine (En-ELM) classifier. Waste items are first classified into two main categories: biodegradable and non-biodegradable. The dataset is then split into nine distinct categories in the second stage based on the overall waste characteristics. The final stage of the classification process involves a more detailed granularity, as all images are assigned to one of thirty-six specific classes. With an average accuracy, precision, recall, f1, and ROC-AUC values of 96 %, 95.0 ± 0.02 %, 95.0 ± 0.02 %, 95.0 ± 0.02 %, and 98.77 %, respectively, the proposed model demonstrates promising results in the first stage of two-class classification. Advancing to the second stage, the framework showed excellent results in nine-class classification, with performance rates of 91.00 %, 90.0 ± 0.04 %, 89.44 ± 0.06 %, 89.66 ± 0.05 %, and 98.57 %, respectively. Similar to the previous stages, the model continued to perform effectively in the third stage, achieving 85.25 % accuracy, 85.02 % precision, 85.25 % recall, 84.54 % f1-score, and 98.68 % AUC in the thirty-six-class classification. The En-ELM classifier, a fusion of pseudoinverse ELM (PI-ELM) and L1 regularized ELM (L1-RELM), achieved impressive results with an average testing time of 0.00001 s. A novel comprehensive dataset titled TriCascade WasteImage, which combines four smaller preexisting datasets, was used to measure the performance of the DP-CNN-En-ELM model. With only nine layers and 1.09 million parameters, the proposed approach precisely extracts pertinent information from images to classify diverse waste materials. The effectiveness of the model is confirmed by comparing it to advanced transfer learning methods. Various explainable AI (XAI) methods are used to explore the interpretability and decision-making capability of the proposed model. Additionally, this study presents a comprehensive prototype hardware architecture for rapid waste categorization in an augmented environment, enabling autonomous waste sorting in industrial applications.},
  archive      = {J_KBS},
  author       = {Md. Nahiduzzaman and Md. Faysal Ahamed and Mansura Naznine and Md. Jawadul Karim and Hafsa Binte Kibria and Mohamed Arselene Ayari and Amith Khandakar and Azad Ashraf and Mominul Ahsan and Julfikar Haider},
  doi          = {10.1016/j.knosys.2025.113028},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113028},
  shortjournal = {Knowl. Based Syst.},
  title        = {An automated waste classification system using deep learning techniques: Toward efficient waste recycling and environmental sustainability},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFCQA: Multi-range feature cross-attention mechanism for no-reference image quality assessment. <em>KBS</em>, <em>310</em>, 113027. (<a href='https://doi.org/10.1016/j.knosys.2025.113027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning techniques have made significant progress in the field of No-Reference Image Quality Assessment (NR-IQA). However, existing methods often rely on a single backbone network, and different backbone networks have different preferences, which limits the ability to capture both global and local information, thereby restricting the comprehensive extraction of diverse image features. In this context, we propose a novel approach called Multi-Range Feature Cross-Attention Mechanism for No-Reference Image Quality Assessment (MFCQA) to address the limitations of a single backbone network and the processing of global and local information. Our method utilizes multiple backbone networks to better capture features from different ranges of the image. Additionally, we introduce the Cross-Attention Module (CAM) to extract potential features from different backbone features and facilitate better information interaction and fusion. This enables more effective handling of global and local information, which improves the accuracy of image quality assessment. Experiments demonstrate the excellent performance of our method in the NR-IQA task. Compared to existing methods, our method demonstrates outstanding performance in image quality assessment, surpassing even some of the best SOTA methods. These results validate the effectiveness and feasibility of our proposed method.},
  archive      = {J_KBS},
  author       = {Nu Sun and Jian Jin and Lili Meng and Weisi Lin and Hao Wang and Li Liu and Huaxiang Zhang},
  doi          = {10.1016/j.knosys.2025.113027},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113027},
  shortjournal = {Knowl. Based Syst.},
  title        = {MFCQA: Multi-range feature cross-attention mechanism for no-reference image quality assessment},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent genetic algorithm for bayesian networks structural learning. <em>KBS</em>, <em>310</em>, 113025. (<a href='https://doi.org/10.1016/j.knosys.2025.113025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks (BNs) are a powerful probabilistic graphical tool for modeling relationships between random variables in an interpretable way. The relationships among variables are represented by the BN structure, a directed acyclic graph, which can be learned from a data set. However, the structural learning process is NP-hard. One popular strategy for learning a BN’s structure is the Search and Score approach, where a quality score is defined as the objective function to be optimized. This approach has led to various algorithms, ranging from linear integer programming to heuristics and metaheuristics. In this paper, we present a novel algorithm for BN structure learning, an adaptation of the Multi-Agent Genetic Algorithm designed to tackle the structural learning problem efficiently. Our algorithm was compared to three others across benchmark problems of varying variable sizes, using a randomized factorial design with different sample sizes. Results show our method outperformed others, especially in detecting edge presence and direction, and proved effective for both small and large-scale BN learning, as confirmed by statistical tests.},
  archive      = {J_KBS},
  author       = {João P.A.F. Campos and Itallo G. Machado and Michel Bessani},
  doi          = {10.1016/j.knosys.2025.113025},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113025},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-agent genetic algorithm for bayesian networks structural learning},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOCS: Object detection based on dense channel compression for feature spatial solidification. <em>KBS</em>, <em>310</em>, 113024. (<a href='https://doi.org/10.1016/j.knosys.2025.113024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we examine the associations between channel features and convolutional kernels during the processes of feature purification and gradient backpropagation, with a focus on the forward and backward propagation within the network. Consequently, we propose a method called Dense Channel Compression for Feature Spatial Solidification. Drawing upon the central concept of this method, we introduce two innovative modules for backbone and head networks: the Dense Channel Compression for Feature Spatial Solidification Structure (DF) and the Asymmetric Multi-Level Compression Decoupled Head (ADH). When integrated into the YOLOv5 model, these two modules demonstrate exceptional performance, resulting in a modified model referred to as YOLOCS. Evaluated on the MSCOCO dataset, the large, medium, and small YOLOCS models yield AP of 50.1%, 47.6%, and 42.5%, respectively. Maintaining inference speeds remarkably similar to those of the YOLOv5 model, the large, medium, and small YOLOCS models surpass the YOLOv5 model’s AP by 1.1%, 2.3%, and 5.2%, respectively.},
  archive      = {J_KBS},
  author       = {Lin Huang and Weisheng Li and Yujuan Tan and Linlin Shen and Jing Yu and Haojie Fu},
  doi          = {10.1016/j.knosys.2025.113024},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113024},
  shortjournal = {Knowl. Based Syst.},
  title        = {YOLOCS: Object detection based on dense channel compression for feature spatial solidification},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoMTNAS: Automated meta-reinforcement learning on graph tokenization for graph neural architecture search. <em>KBS</em>, <em>310</em>, 113023. (<a href='https://doi.org/10.1016/j.knosys.2025.113023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks have achieved breakthroughs in various fields due to their powerful automated representation capabilities for graph. Designing effective graph neural architectures is critical for feature representation and property prediction in non-Euclidean graph-structured data. However, this design process heavily relies on the strong prior knowledge and experience of researchers. The inherent complexity and irregularity in graph-structured data make it challenging for existing methods to develop strategies for capturing expressive representations beyond traditional paradigms, resulting in unaffordable computational cost and precision loss across diverse graphs. To this end, we propose a novel automated meta-reinforcement learning on graph tokenization for graph neural architecture search, named AutoMTNAS, to learn a more general and reliable architecture search policy. In particular, our graph tokenization method identifies critical nodes and structural patterns within the graph and captures label-aware global information to summarize potential valuable insights. We define a meta-reinforcement learning searcher that utilizes parameter sharing and policy gradients to discover optimal architectures for new tasks, even with limited available observations. Extensive experiments on benchmark datasets, ranging from small to large, demonstrate that AutoMTNAS outperforms human-invented architectures and existing graph neural architecture search methods.},
  archive      = {J_KBS},
  author       = {Mingshuo Nie and Dongming Chen and Huilin Chen and Dongqi Wang},
  doi          = {10.1016/j.knosys.2025.113023},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113023},
  shortjournal = {Knowl. Based Syst.},
  title        = {AutoMTNAS: Automated meta-reinforcement learning on graph tokenization for graph neural architecture search},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustness enhancement of deep reinforcement learning-based traffic signal control model via structure compression. <em>KBS</em>, <em>310</em>, 113022. (<a href='https://doi.org/10.1016/j.knosys.2025.113022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep reinforcement learning (DRL) has found extensive applications in the field of traffic signal control (TSC). However, many studies have demonstrated the vulnerabilities of DRL-based models when exposed to abnormal data, which can lead to wrong knowledge representation. In this paper, an Integrated Structure and Robustness Enhancement framework is proposed, consisting of a Robust Distillation module and a Structure Compression module. Firstly, abnormal traffic flow data are utilized as training inputs to generate a Poisoned Model, serving as a means to analyze potential data security threats. Secondly, the Robust Distillation module, which adopts a macro-level perspective, uses the latent knowledge in the hidden layers of the Poisoned Model as the distillation target. Small-gradient distillation is then performed by constructing a robust distillation loss function with temperature, through which wrong knowledge in the Poisoned Model is suppressed. Furthermore, the Structure Compression module, taking a micro-level perspective, conducts layer-wise quantification of redundant neurons in the robust student model and eliminates the abnormal parameters associated with abnormal data through iterative pruning of these redundant structures. Finally, a streamlined and high-performance Enhancement Model is generated, containing only the minimum number of neurons required. Experimental results demonstrate that the Integrated Structure and Robustness Enhancement framework effectively compresses the structure of the Poisoned Model, achieving minimal performance degradation and efficiently enhancing robustness compared to the Poisoned Model when exposed to abnormal data.},
  archive      = {J_KBS},
  author       = {Dongwei Xu and Xiangwang Liao and Zefeng Yu and Tongcheng Gu and Haifeng Guo},
  doi          = {10.1016/j.knosys.2025.113022},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113022},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robustness enhancement of deep reinforcement learning-based traffic signal control model via structure compression},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-guided and cross-modality attention network for liver tumor segmentation and quantification via integrating dynamic MRI. <em>KBS</em>, <em>310</em>, 113021. (<a href='https://doi.org/10.1016/j.knosys.2025.113021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation and quantitative measurement of liver tumors, including hemangiomas and hepatocellular carcinoma (HCC), using dynamic Magnetic Resonance Imaging (MRI) sequences are crucial for effective treatment and prognosis. However, these tasks remain challenging due to two key issues: (1) the severe class imbalance between tumors and background, particularly for small HCC lesions, which complicates precise feature extraction; and (2) the diverse imaging features across dynamic MRI phases, making effective fusion of multi-phase information difficult. To address these challenges, this study proposes the Uncertainty-guided and Cross-modality Attention Network (UgCmA-Net). UgCmA-Net incorporates three innovative components: (1) a cross-modality attention pyramid module within a parallel attention-based encoder, enhancing tumor-specific feature extraction across dynamic phases; (2) a fusion Transformer (F-Trans), where the non-local Transformer captures long-range dependencies, and the phase-aware Transformer fuses multi-phase dynamic MRI features; and (3) an uncertainty-guided auxiliary-primary segmentor, which improves edge confidence and segmentation accuracy through uncertainty estimation. The UgCmA-Net was validated using dynamic MRI sequences (T1 pre-contrast MRI, arterial-phase, portal venous phase, and delay-phase contrast-enhanced MRI) from 265 clinical subjects. Experimental results show that the proposed UgCmA-Net achieves state-of-the-art performance, with a dice similarity coefficient of 85.44%, Hausdorff Distance of 2.28 mm, and mean absolute error values of 1.85 mm, 1.90 mm, 6.52 mm, and 97.27 mm 2 for multi-index quantification of center point, max-diameter, circumference, and area, respectively. Statistical analysis confirms that the improvements are statistically significant (p < 0.05), demonstrating the robustness of the proposed method. These findings demonstrate that UgCmA-Net is highly effective for liver tumor segmentation and quantification, indicating its potential clinical value in liver tumor analysis and treatment planning.},
  archive      = {J_KBS},
  author       = {Jianfeng Zhao and Shuo Li},
  doi          = {10.1016/j.knosys.2025.113021},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113021},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncertainty-guided and cross-modality attention network for liver tumor segmentation and quantification via integrating dynamic MRI},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crested ibis algorithm and its application in human-powered aircraft design. <em>KBS</em>, <em>310</em>, 113020. (<a href='https://doi.org/10.1016/j.knosys.2025.113020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the observation of crested ibis foraging behavior, we propose a novel bio-inspired optimization algorithm called Crested Ibis Algorithm (CIA). We designed different exploration strategies by simulating the success or failure of ibis foraging and the escape behavior of fish from ibis foraging. Moreover, the dynamic balance between exploration and exploitation was realized through the information interaction mechanism of the two populations. To validate the performance of the proposed CIA algorithm, we conducted comparative experiments with 14 competitive algorithms on different dimensions of the CEC2017 and CEC2022 benchmark suites and showed excellent performance. In addition, we extend the CIA algorithm to the problem of Human-Powered Aircraft Design optimization (HPA). Experiments and statistical tests demonstrate the proposed CIA’s superb performance and outstanding robustness. The source code is available at https://github.com/RuiZhong961230/CIA .},
  archive      = {J_KBS},
  author       = {Yuefeng Xu and Rui Zhong and Chao Zhang and Jun Yu},
  doi          = {10.1016/j.knosys.2025.113020},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113020},
  shortjournal = {Knowl. Based Syst.},
  title        = {Crested ibis algorithm and its application in human-powered aircraft design},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASMWP: Adaptive spatial masking for weakly-supervised point cloud semantic segmentation. <em>KBS</em>, <em>310</em>, 113016. (<a href='https://doi.org/10.1016/j.knosys.2025.113016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully supervised is highly dependent on labels, while obtaining high-quality annotations is costly and consumes a lot of human, material, and financial resources. To address this problem, we study weakly-supervised point cloud semantic segmentation with sparse annotations, aiming to achieve competitive performance with a small amount of labeled data. We propose a new weakly-supervised adaptive masking method for point cloud semantic segmentation. Most existing masking strategies use random selection, which may mask labels in critical regions. To avoid this, we design an adaptive spatial masking strategy, which adaptively masks part of the point cloud labels to improve the understanding of local contextual semantics. And the performance of the masking network is enhanced by modulating the importance of features through a feature enhancement module. We further add a reliable pseudo-labels guidance loss to the consistency framework to strengthen the consistency constraints. Extensive experiments on ScanNet V2 and S3DIS show that our method outperforms the state-of-the-art.},
  archive      = {J_KBS},
  author       = {Xindan Zhang and Ying Li and Xinnian Zhang},
  doi          = {10.1016/j.knosys.2025.113016},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113016},
  shortjournal = {Knowl. Based Syst.},
  title        = {ASMWP: Adaptive spatial masking for weakly-supervised point cloud semantic segmentation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating overconfidence in unknown sample predictions: A confidence-enhanced one-versus-all network for open-set transfer fault diagnosis. <em>KBS</em>, <em>310</em>, 113013. (<a href='https://doi.org/10.1016/j.knosys.2025.113013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has significantly advanced the generalization performance of fault diagnosis models. In particular, open-set transfer fault diagnosis has garnered increasing attention because it can identify unknown fault types that are unseen in the source domain. However, the existing methods frequently suffer from overconfident predictions of unknown samples, thereby leading to difficulties in differentiating them from known samples. In this study, we address this limitation by introducing a confidence-enhanced one-versus-all network (CEOVA) for open-transfer fault diagnosis. Unlike traditional approaches that rely on presupposed thresholds or modeling of known–unknown boundaries, CEOVA identifies unknown samples through one-versus-all network learning of the “none of the above” concept. To ensure lower confidence scores for unknown samples, we develop two techniques: a data augmentation strategy and a single-label probability transformation. The former generates open data to help the model learn unknown concepts effectively, whereas the latter addresses the issue of high-probability outputs for unknown samples by converting multilabel probabilities from the one-versus-all network into single-label probabilities. Simultaneously, open-entropy minimization is used to align known samples in the target domain with their corresponding classes in the source domain while ensuring that unknown samples remain unaligned. Comprehensive open-set fault diagnosis experiments conducted on two datasets demonstrate the efficacy and excellence of the developed model.},
  archive      = {J_KBS},
  author       = {Yang Liu and Aidong Deng and Minqiang Deng and Xue Ding and Dongying Liu},
  doi          = {10.1016/j.knosys.2025.113013},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113013},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mitigating overconfidence in unknown sample predictions: A confidence-enhanced one-versus-all network for open-set transfer fault diagnosis},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A slim prompt-averaged consistency prompt learning for vision–language model. <em>KBS</em>, <em>310</em>, 113011. (<a href='https://doi.org/10.1016/j.knosys.2025.113011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in prompt tuning have enhanced the adaptation of large pre-trained models to target tasks. However, existing methods struggle to establish an effective balance between task-specific knowledge and generalizable knowledge during tuning, skewing too heavily towards one at the expense of the other. To address this issue, we propose a Slim Prompt-Averaged Consistency (SPAC) prompt learning approach. Specifically, SPAC introduces a temporal ensembling-based averaged-prompt module and leverages a multifaceted consistency mechanism to ensure knowledge consistency under the guidance of averaged-prompt. Additionally, SPAC employs the contrastive learning strategy to further enhance the learning of target task representations based on positive and negative sample pairs. Furthermore, considering the notable resource consumption of existing prompt formats, we refine the prompt format, significantly reducing resource consumption during training and inference. Extensive experiments on 11 benchmark datasets demonstrate that our approach outperforms others in few-shot prompt learning transfer tasks, including base-to-novel generalization and cross-dataset transfer, while consuming fewer resources.},
  archive      = {J_KBS},
  author       = {Siyu He and Shengsheng Wang and Sifan Long},
  doi          = {10.1016/j.knosys.2025.113011},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113011},
  shortjournal = {Knowl. Based Syst.},
  title        = {A slim prompt-averaged consistency prompt learning for vision–language model},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view multi-scale cognitive representation for deep knowledge tracing. <em>KBS</em>, <em>310</em>, 113010. (<a href='https://doi.org/10.1016/j.knosys.2025.113010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing is one of the key technologies for achieving personalized learning, aiming to predict students’ future performance by analyzing their historical responses during the learning process. In recent years, the development of deep learning has led to the emergence of deep knowledge tracing, which employs neural network models to better capture the complex dynamic patterns in students’ learning processes. However, most existing deep learning-based knowledge tracing models primarily learn a student’s cognitive state through sequential modeling of single-scale exercise-answer interactions, neglecting the multi-scale characteristics of both short-term and long-term learning processes. This approach often struggles to fit the complex cognitive states of students. Moreover, these methods typically model students’ mastery of exercises but overlook their problem-solving abilities, a critical factor in determining whether students can correctly answer the exercises to be predicted. To address the shortcomings of existing knowledge tracing models, we propose a D ual-view M ulti-scale Cognitive Representation-based K nowledge T racing model (DMKT). From the exercise mastery view, the model designs a multi-scale representation method that simultaneously considers students’ long-term static cognitive states and short-term dynamic cognitive states to better fit their complex cognitive conditions. From the problem solving view, the model adopts a Transformer architecture to explicitly learn joint representations of exercises answered by students at each time step and the most similar historical exercises, integrating response information to model their performance on both new and old exercises. Furthermore, to effectively learn the similarity relationships between exercises, we extend multiple exercise-centered heterogeneous relations and propose a dual-channel heterogeneous graph-based online feature distillation method to fully model exercise representations. Extensive experimental results demonstrate that our model exhibits significant superiority, while also providing a certain level of interpretability for the model’s predictions from both the exercise mastery and problem solving view.},
  archive      = {J_KBS},
  author       = {Qing Li and Xin Yuan and Jieyu Yue and Xiaoxuan Shen and Ruxia Liang and Sannyuya Liu and Zhonghua Yan},
  doi          = {10.1016/j.knosys.2025.113010},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113010},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-view multi-scale cognitive representation for deep knowledge tracing},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided prompt-based continual learning: Aligning task-prompts through contrastive hard negatives. <em>KBS</em>, <em>310</em>, 113009. (<a href='https://doi.org/10.1016/j.knosys.2025.113009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning aims to empower a single model to continually adapt to novel environments and perform new tasks while retaining previous knowledge without catastrophic forgetting. Compared with rehearsal-based methods, which need expensive buffers, prompt-based methods become popular paradigms recently. However, we observe that sometimes the learned task prompts are difficult to distinguish, which results in the wrong task prompt selection during inference. Therefore, we design a Knowledge-Enhanced Module to learn better task prompts with inter-task and intra-task class semantic information. We also propose to select hard negative samples to learn more distinguishable task prompts by Contrastive Learning. Experiments on two popular benchmark datasets achieve state-of-the-art performance with remarkable advantages. The accuracy reached 88.20% and 71.64% on CIFAR-100 and ImageNet-R, which outperforms the SOTA model 1.12% and 1.14% respectively. At the same time, through top-N hard negative samples optimization, the standard deviation of the experiment is reduced to 0.13% and 0.02%, making the model performance more stable.},
  archive      = {J_KBS},
  author       = {Heng-yang Lu and Long-kang Lin and Chenyou Fan and Chongjun Wang and Wei Fang and Xiao-jun Wu},
  doi          = {10.1016/j.knosys.2025.113009},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113009},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-guided prompt-based continual learning: Aligning task-prompts through contrastive hard negatives},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale semantically enriched feature pyramid network with enhanced focal loss for small-object detection. <em>KBS</em>, <em>310</em>, 113003. (<a href='https://doi.org/10.1016/j.knosys.2025.113003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep-learning methods have achieved higher accuracy in the detection of large objects. However, the performances of these methods are relatively poor for small objects. Studies have revealed several reasons for this weakness. First, small objects have limited spatial dimensions, causing them to have less semantic information. Second, the imbalance between foreground and background features complicates the process of distinguishing small objects from the background. This study presents a multi-scale semantic information enhancement module that captures sensitive details from the higher prediction layers of a feature pyramid network. This module infuses the captured details into its lowest prediction layer, which is responsible for detecting small objects. We approached the class imbalance issue using a novel enhanced focal loss method that embeds a special weighting factor to enhance the contribution of easy examples in the object detection training process. The empirical results show that, compared with baseline methods, our method achieves better performance in detecting small objects.},
  archive      = {J_KBS},
  author       = {Twahir Kiobya and Junfeng Zhou and Baraka Maiseli},
  doi          = {10.1016/j.knosys.2025.113003},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113003},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-scale semantically enriched feature pyramid network with enhanced focal loss for small-object detection},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic channel pruning by neural network based on improved poplar optimisation algorithm. <em>KBS</em>, <em>310</em>, 113002. (<a href='https://doi.org/10.1016/j.knosys.2025.113002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are used in diverse domains, such as computer vision and natural language processing. However, the increasing number of parameters and memory requirements pose challenges for their deployment on edge devices. Studies have demonstrated that CNNs have redundant parameters, the criteria for importance-based pruning methods are cumbersome and existing automatic pruning algorithms struggle to effectively capture global features. To address the drawbacks of such methods, an automatic channel pruning method using improved the poplar optimisation algorithm (ACPPO) is proposed herein. This study aimed to search for the optimal network structure using clustering and optimisation algorithms. First, hierarchical density–based clustering is employed to group the channels of each convolutional layer based on similarity, thereby forming a preliminary compression structure. Subsequently, the improved poplar optimisation algorithm (POA) is used to determine the optimal compact network structure with an iterative optimisation search. During the asexual propagation of the POA, the local optimum is used instead of the original random historical information to guide the search direction of individuals, thereby enhancing the diversity of the population and improving search efficiency and global search capability. Herein, the effectiveness of ACPPO is verified on two commonly used image classification datasets: CIFAR-10 and ILSVRC-2012. On CIFAR-10, ACPPO reduces the GoogLeNet network by 69.37% of the parameters and 75.33% of the FLOPs, with an accuracy improvement of 0.13% over the benchmark.},
  archive      = {J_KBS},
  author       = {Yuanxu Hu and Debao Chen and Feng Zou and Yajun Liu},
  doi          = {10.1016/j.knosys.2025.113002},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113002},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automatic channel pruning by neural network based on improved poplar optimisation algorithm},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stable neural network for inverse scattering problems with contaminated data. <em>KBS</em>, <em>310</em>, 113001. (<a href='https://doi.org/10.1016/j.knosys.2025.113001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the application of stable neural networks to solve inverse scattering problems in the presence of data contamination. Such contamination arises when part of the data during the data acquisition is affected by noise, data loss, part of the data is completely replaced by noise. Given the inherent complexity and information loss, accurately reconstructing the location and shape of non-penetrable obstacles from contaminated data is both crucial and challenging in practical settings. Ensuring the stability of the algorithm is key to effectively handling these diverse contamination scenarios. We model the feedforward process of the neural network as a continuous dynamical system and introduce a stabilized neural network unit, termed RKU, based on the Runge–Kutta method. Building upon this, we propose a convolutional neural network model called RKUN. The stability of the proposed approach is demonstrated through theoretical analysis, and its effectiveness is validated through numerical experiments.},
  archive      = {J_KBS},
  author       = {Jiabao Zhuang and Pinchao Meng and Weishi Yin},
  doi          = {10.1016/j.knosys.2025.113001},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {113001},
  shortjournal = {Knowl. Based Syst.},
  title        = {A stable neural network for inverse scattering problems with contaminated data},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian regularization neural network procedure to solve the language learning system. <em>KBS</em>, <em>310</em>, 112997. (<a href='https://doi.org/10.1016/j.knosys.2025.112997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research is to provide the numerical performances of the language learning system (LLS) by applying the process of Bayesian regularization neural network (BRNN). The division of the mathematical LLS is provided in three categories, familiar, unknown, and mastered. A design of dataset based on the Runge-Kutta is applied to lessen the mean square error (MSE). The division of the data is performed into training as 70 %, while the data for validation uses 20 % and 10 % for testing. The proposed BRNN is provided by taking the activation sigmoid function, fifteen neurons, and optimization through Bayesian regularization to solve the LLS. The correctness of the BRNN solver is observed by the comparison of literature results and the negligible absolute error. Moreover, the consistency of the BRNN is observed through the statistical performances based on state transition, regression, MSE, and error histogram.},
  archive      = {J_KBS},
  author       = {Zulqurnain Sabir and Samir Khansa and Ghida Baltaji and Tareq Saeed},
  doi          = {10.1016/j.knosys.2025.112997},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112997},
  shortjournal = {Knowl. Based Syst.},
  title        = {A bayesian regularization neural network procedure to solve the language learning system},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature enhancement network guided by multi-dimensional collaborative edge information for remote sensing image compression. <em>KBS</em>, <em>310</em>, 112996. (<a href='https://doi.org/10.1016/j.knosys.2025.112996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, there are some common problems in lossy compression methods for remote sensing images, such as block effect and blur effect, which are particularly evident at high compression ratios. Although some models have been developed that apply prior knowledge of local smoothing to probabilistic models to address these issues, it can result in significant loss of structural features. In this paper, a dynamic feature enhancement network guided by multi-dimensional collaborative edge information for remote sensing image compression (DMENet) is proposed, which can achieve high fidelity remote sensing image compression while preserving more structural features. Firstly, a multi-dimensional feature extraction module guided by edge information (MDEI) is carefully designed to extract structural features and edge features from images. These features are aligned structurally through loss to achieve high-quality restoration of structural features Secondly, a slice dynamic pyramid module (SDPM) is constructed to achieve dynamic extraction of irregular shaped features and multi-scale features. Furthermore, a latent representation space enhancement module (LSM) is proposed to address the issue of deep level feature loss in probabilistic models due to low information capacity. Finally, a high-quality remote sensing image compression is performed through the entire network under the guidance of a novel rate distortion optimization strategy (a constraint that focuses more on structural features). The experimental results show that compared with some advanced compression models, DMENet can compress remote sensing images more effectively.},
  archive      = {J_KBS},
  author       = {Cuiping Shi and Kaijie Shi and Zexin Zeng and Fei Zhu},
  doi          = {10.1016/j.knosys.2025.112996},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112996},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic feature enhancement network guided by multi-dimensional collaborative edge information for remote sensing image compression},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and efficient detector for concealed object in active millimeter wave images. <em>KBS</em>, <em>310</em>, 112995. (<a href='https://doi.org/10.1016/j.knosys.2025.112995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concealed object detection based on active millimeter wave (AMMW) images offers non-contact, real-time detection, making it ideal for high-throughput security applications like large venues, railway stations, and airports. The model design is also developing in the direction of lightweight. However, challenges arise due to AMMW images’ low resolution, lack of color, and difficulty in detecting small objects obscured by body clutter. Firstly, to overcome the lack of color and detailed information in AMMW images, as well as the problem caused by the small size of most concealed objects and their tendency to be obscured by body clutter, a new backbone is designed to improve the model’s feature extraction capabilities for concealed objects in AMMW images. Due to the severe noise interference in AMMW images, this paper introduces an attention mechanism to direct the model to prioritize the targets, thereby achieving noise suppression. Finally, to meet the needs of practical applications, several lightweight modifications of the model are introduced based on the characteristics of concealed objects, such as introducing depth-wise convolutions (DWConv) and removing redundant branches. Using YOLOv8n as the baseline and incorporating the abovementioned improvements, a lightweight and efficient detector designed specifically for concealed object detection is proposed. This detector has only 0.6M parameters and 3.8 GFLOPs, significantly lower than other mainstream state-of-the-art (SOTA) detectors. Extensive experimental results on the constructed dataset and a public AMMW dataset demonstrate that the proposed model’s detection accuracy is on par with other models while its detection speed is the fastest.},
  archive      = {J_KBS},
  author       = {Chunyu Li and Hang Lyu and Kai Duan},
  doi          = {10.1016/j.knosys.2025.112995},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112995},
  shortjournal = {Knowl. Based Syst.},
  title        = {A lightweight and efficient detector for concealed object in active millimeter wave images},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage unidirectional fusion network for RGBT tracking. <em>KBS</em>, <em>310</em>, 112983. (<a href='https://doi.org/10.1016/j.knosys.2025.112983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB and Thermal (RGBT) tracking has recently attracted significant attention for its ability to accurately localize targets in complex scenarios. However, the creation of large-scale RGBT tracking datasets is both resource-intensive and laborious, motivating researchers to develop prompt tuning methods to adapt upstream RGB trackers to multimodal data with minimal additional parameters. Nevertheless, these methods do not fully exploit the supplementary modality information and tend to overlook the dynamic advantages between the two modalities in challenging scenarios. To address these issues, we propose a Two-stage Unidirectional Fusion (TUF) algorithm for RGBT tracking. This approach maximizes knowledge retention from upstream models while effectively leveraging the complementarity between the two modalities. It allows the powerful RGB feature extraction backbone from the upstream model to guide TIR image feature extraction through a two-stage unidirectional fusion strategy. Additionally, we have introduced an autoregressive decoder into RGBT tracking as a replacement for traditional bounding box prediction heads. This streamlines the framework of our RGBT tracker and improves tracking accuracy. Extensive experiments conducted on four widely used RGBT tracking benchmarks validate that our method surpasses existing state-of-the-art prompt tuning approaches, achieving a superior balance between performance and efficiency.},
  archive      = {J_KBS},
  author       = {Yisong Liu and Zhao Gao and Yang Cao and Dongming Zhou},
  doi          = {10.1016/j.knosys.2025.112983},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112983},
  shortjournal = {Knowl. Based Syst.},
  title        = {Two-stage unidirectional fusion network for RGBT tracking},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FEV-swin: Multi-source heterogeneous information fusion under a variant swin transformer framework for intelligent cross-domain fault diagnosis. <em>KBS</em>, <em>310</em>, 112982. (<a href='https://doi.org/10.1016/j.knosys.2025.112982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data-driven intelligent fault diagnosis, due to the diversity of actual data distribution, more researches focus on cross-domain fault diagnosis. Current research mainly focuses on single sensor data. However, in complex industrial systems, it is necessary to make comprehensive use of multi-source heterogeneous data to monitor the operation status of the system from multiple perspectives. To address the limitation of existing cross-domain fault diagnosis methods in effectively utilizing the complementary information from multi-source heterogeneous data, this paper proposes a novel multi-source heterogeneous information fusion model, called feature enhancement variant-swin transformer (FEV-Swin), based on the swin-transformer framework for intelligent cross-domain fault diagnosis. The proposed model incorporates a series of components designed to enhance cross-domain fault diagnosis performance. It includes a data augmentation module to increase the diversity of source domain data, a shifted windows mechanism to strengthen horizontal and vertical feature extraction capabilities, and a combination of a pyramid feature fusion module with a domain adaptation module to achieve efficient multi-source heterogeneous data fusion and distribution alignment. Experimental results demonstrate that the application of the FEV-Swin model in rotor systems significantly improves fault diagnosis accuracy and applicability, highlighting its broad potential for deployment in complex industrial scenarios.},
  archive      = {J_KBS},
  author       = {Keyi Zhou and Ningyun Lu and Bin Jiang and Zhisheng Ye},
  doi          = {10.1016/j.knosys.2025.112982},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112982},
  shortjournal = {Knowl. Based Syst.},
  title        = {FEV-swin: Multi-source heterogeneous information fusion under a variant swin transformer framework for intelligent cross-domain fault diagnosis},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain knowledge-guided intelligent recognition of multi-type potential landslides. <em>KBS</em>, <em>310</em>, 112979. (<a href='https://doi.org/10.1016/j.knosys.2025.112979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of potential landslides is essential for early warning and prevention. While effective, traditional detection methods suffer from high workload, subjectivity, and inaccuracies due to inaccessible landslide distributions. This paper addresses these limitations by introducing a novel data-driven approach that leverages domain knowledge systematically. The approach is based on a three-stage embedding framework, integrating domain knowledge related to potential landslide characteristics, to enhance the recognition of various potential landslide types. Firstly, domain knowledge for potential landslide identification is constructed from the perspective of hazard characteristics. Then, the corresponding knowledge rules are embedded in the preparation, modeling, and prediction stages respectively. Tested in Zhenyuan County, Yunnan Province, China, the domain knowledge-guided random forest (DKRF) model demonstrates significantly improved interpretability and accuracy in classification. It increased accuracy and recall rates by 3 % and 15 %, respectively, and reduced missed and false classifications by 15 % and 3 %. This study not only advances the field of landslide research by offering a cost-effective investigative tool but also contributes to the development of interpretable machine-learning applications.},
  archive      = {J_KBS},
  author       = {Qinghao Liu and Huimin Liu and Qing Lan and Kui Li and Cheng Huang and Xuexi Yang},
  doi          = {10.1016/j.knosys.2025.112979},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112979},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain knowledge-guided intelligent recognition of multi-type potential landslides},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRNet: Parallel reinforcement network for two-view correspondence learning. <em>KBS</em>, <em>310</em>, 112978. (<a href='https://doi.org/10.1016/j.knosys.2025.112978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-view correspondence learning is a fundamental task in computer vision for locating the same object across two different images, and its essence lies in capturing the context from the images. Recent studies employ the standard Convolutional Neural Network (CNN) as the core architecture to capture the context. However, the inherent nature of the CNN’s local receptive field and pooling operations can result in the loss of certain semantic context. This can result in the CNN-based correspondence learning methods having an insufficient understanding of the global context, especially on image pairs including challenges like significant viewpoint changes, repetitive structures and weak textures. To address this issue and these challenges, we propose a novel correspondence learning method called Parallel Reinforcement Network (PRNet). Firstly, we design a reinforcement injection block, not only to dynamically refine feature weights by using channel attention mechanism, but also to preserve important details for alleviating over-smoothing issue by strengthening the network’s capacity. Secondly, to alleviate the potential issue of overlooking the weak local context by CNN, we propose a parallel fusion block to integrate both shallow and deep features, preserving local details and enhancing global context. We evaluate the performance of the proposed PRNet on an outlier rejection task and a relative pose estimation task. The experimental results demonstrate the proposed PRNet exceeds several existing state-of-the-art methods in various challenging scenarios.},
  archive      = {J_KBS},
  author       = {Zheng Kang and Taotao Lai and Zuoyong Li and Lifang Wei and Riqing Chen},
  doi          = {10.1016/j.knosys.2025.112978},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112978},
  shortjournal = {Knowl. Based Syst.},
  title        = {PRNet: Parallel reinforcement network for two-view correspondence learning},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGHINT: Attribute-guided representation learning on heterogeneous information networks with transformer. <em>KBS</em>, <em>310</em>, 112977. (<a href='https://doi.org/10.1016/j.knosys.2025.112977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, heterogeneous graph neural networks (HGNNs) have achieved impressive success in representation learning by capturing long-range dependencies and heterogeneity at the node level. However, few existing studies have delved into the utilization of node attributes in heterogeneous information networks (HINs). In this paper, we investigate the impact of inter-node attribute disparities on HGNNs performance within the benchmark task, i.e. , node classification, and empirically find that typical models exhibit significant performance decline when classifying nodes whose attributes markedly differ from their neighbors. To alleviate this issue, we propose a novel Attribute-Guided heterogeneous Information Networks representation learning model with Transformer (AGHINT), which allows a more effective aggregation of neighbor node information under the guidance of attributes. Specifically, AGHINT transcends the constraints of the original graph structure by directly integrating higher-order similar neighbor features into the learning process and modifies the message-passing mechanism between nodes based on their attribute disparities. Extensive experimental results on three real-world heterogeneous graph benchmarks with target node attributes demonstrate that AGHINT outperforms the state-of-the-art.},
  archive      = {J_KBS},
  author       = {Jinhui Yuan and Shan Lu and Peibo Duan and Jieyue He},
  doi          = {10.1016/j.knosys.2025.112977},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112977},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGHINT: Attribute-guided representation learning on heterogeneous information networks with transformer},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled hyperbolic representation learning for heterogeneous graphs. <em>KBS</em>, <em>310</em>, 112976. (<a href='https://doi.org/10.1016/j.knosys.2025.112976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs have attracted considerable research interests in the past few years owing to their remarkable ability to represent complex real-world systems. However, the existing methods have two pain points in embedding heterogeneous graphs into low-dimensional spaces. (1) Heterogeneous graphs contain both structural and semantic information, yet these aspects are often mixed in original data, hence hindering effective representation learning. (2) Most real-world heterogeneous graphs exhibit power-law distributions over both the entire graphs and single edge types, and they suffer mismatch with Euclidean spaces, in which most existing methods are built. These two challenges require that representation methods should unmix the information while considering the distributions of entire graphs and single edge types. Herein, we propose Dis-H 2 GCN , a Disentangled Hyperbolic Heterogeneous Graph Convolutional Network. On the one hand, we leverage the mutual information minimization and discrimination maximization constraints to disentangle the semantic features from comprehensively learned representations by independent message propagation for each edge type, away from the pure structural features. On the other hand, the entire model is constructed upon hyperbolic geometry to narrow the gap between data distributions and representing spaces. We evaluate the performance of proposed Dis-H 2 GCN on five real-world heterogeneous graph datasets across two downstream tasks, node classification and link prediction, with the results demonstrating its superiority over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qijie Bai and Changli Nie and Haiwei Zhang and Zhicheng Dou and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.112976},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112976},
  shortjournal = {Knowl. Based Syst.},
  title        = {Disentangled hyperbolic representation learning for heterogeneous graphs},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Textual out-of-distribution (OOD) detection for LLM quality assurance. <em>KBS</em>, <em>310</em>, 112975. (<a href='https://doi.org/10.1016/j.knosys.2025.112975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) detection is critical for ensuring AI quality and reliability, particularly with the rise of large models characterized by immense parameters and complex architectures. This paper addresses the challenge of detecting textual OOD data in sentiment analysis using large language models (LLMs). To enhance robustness in sentiment classification and improve OOD rejection, we incorporate prototype learning into LLM-based sentiment analysis. Experimental evaluations on two benchmark datasets, leveraging traditional scoring methods, demonstrate the effectiveness of the proposed GPT model with prototype loss. The model outperforms baseline approaches, achieving superior OOD detection across three datasets beyond the training domain.},
  archive      = {J_KBS},
  author       = {Tinghui Ouyang and Yoshiki Seo and Isao Echizen},
  doi          = {10.1016/j.knosys.2025.112975},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112975},
  shortjournal = {Knowl. Based Syst.},
  title        = {Textual out-of-distribution (OOD) detection for LLM quality assurance},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent prompt learning for vision-language models. <em>KBS</em>, <em>310</em>, 112974. (<a href='https://doi.org/10.1016/j.knosys.2025.112974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained vision-language models, such as CLIP, have shown remarkable capabilities across various downstream tasks by learning prompts that consist of context concatenated with a class name; for example, ‘a photo of a [dog]’ with [dog] as a class prior. Advanced prompt-learning methods typically initialize and optimize the context; for example, ‘ a photo of a ’ for downstream task adaptation. However, context optimization typically leads to poor generalization performance over novel classes or datasets sampled from different distributions. This may be attributed to prompt inconsistency; namely, prompts optimized using one image distribution may differ from those optimized using a different image distribution. To improve the generalization performance of optimized prompts, we propose the novel consistent prompt learning (CPL) approach that identifies and addresses the image distribution that causes prompt inconsistency by performing distributional exploration. CPL identifies and mitigates prompt inconsistency in an adversarial training scheme, in which prompt inconsistency is measured as the similarity discrepancy between images and two different prompts. Specifically, CPL calculates two similarities between a query image and two prompts, and determines the prompt inconsistency through the discrepancy between these two similarities. Subsequently, CPL performs distributional exploration to enlarge the discrepancy and uses an adversarial-training approach to mitigate the discrepancy. Consequently, the model predictions are insensitive to prompt changes. The optimized prompt performs well under various image distributions. Comprehensive experiments show that the proposed CPL method performs favorably on four types of representative tasks across 11 datasets, which improves on existing prompt-learning methods, achieving state-of-the-art performance.},
  archive      = {J_KBS},
  author       = {Yonggang Zhang and Xinmei Tian},
  doi          = {10.1016/j.knosys.2025.112974},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112974},
  shortjournal = {Knowl. Based Syst.},
  title        = {Consistent prompt learning for vision-language models},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent marketing platform with influencer classification in social networking services. <em>KBS</em>, <em>310</em>, 112972. (<a href='https://doi.org/10.1016/j.knosys.2025.112972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborations with influencers in social networking services (SNS) for online commercial advertisement has gained significant momentum in recent years. However, the existing approaches suffer from a lack of precision in matching advertisements to specific target user groups (e.g., influencers). To address the issue, in this paper we present an intelligent marketing platform that classifies influencers based on a newly built SNS post text dataset and the comprehensive performance factors. The proposed platform fine-tunes a pretrained language model with the SNS post text dataset of influencers, which can achieve a better classification accuracy. To further improve the matching accuracy for marketing partners, we integrate multiple performance features of influencers into the proposed platform. Our results show that the proposed model can provide more than 90% classification accuracy for business partners in their product advertisements. Furthermore, we used a real-world business requirement to implement and evaluate the proposed platform with a web-based system, which provides an easy way for online commercial advertisement.},
  archive      = {J_KBS},
  author       = {Xiaohong Yu and Jinyong Kim and Yoseop Ahn and Mose Gu and Jaehoon (Paul) Jeong and JinYeong Bak and Jaemin Jo},
  doi          = {10.1016/j.knosys.2025.112972},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112972},
  shortjournal = {Knowl. Based Syst.},
  title        = {An intelligent marketing platform with influencer classification in social networking services},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel three-stage matheuristic for the capacitated minimum spanning tree problem with time windows. <em>KBS</em>, <em>310</em>, 112971. (<a href='https://doi.org/10.1016/j.knosys.2025.112971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the capacitated minimum spanning tree problem with time windows (CMSTPTW), which considers capacity constraints for the subtrees and time windows. CMSTPTW belongs to the NP-hard family, making it a computational challenge to find high-quality solutions efficiently. Therefore, this work proposes a novel three-stage matheuristic (3SM) approach that combines modified Prim’s algorithm, an iterated local search (ILS), and a mixed-integer linear programming (MILP) model solved with a general-purpose solver. The first stage involves generating an initial solution using Prim’s algorithm adapted to the CMSTPTW. Once the initial solution is generated, the second stage consists of solving the MILP by a general-purpose solver considering a given time limit and using the best solution found by 3SM as a warm start. In the last stage, the 3SM approach employs an ILS with various perturbation and local search operators to further refine and optimize the solution. Moreover, the ILS uses two additional strategies: a set of elite solutions to preserve the best solutions throughout the algorithm’s execution and a penalization procedure to navigate the infeasible solutions space. These strategies, along with effective parameter tuning, complement each other to increase the algorithm’s exploration and enhance the quality of the final solution. The proposed algorithm’s performance is evaluated on an existing set of instances and in two new additional sets of larger instances that are proposed. The computational results show that the 3SM approach outperforms the state-of-the-art algorithms and the general-purpose solver in terms of solution quality within a given time limit.},
  archive      = {J_KBS},
  author       = {Pablo Reyes-Polanco and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.112971},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112971},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel three-stage matheuristic for the capacitated minimum spanning tree problem with time windows},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Control-flow anomaly detection by process mining-based feature extraction and dimensionality reduction. <em>KBS</em>, <em>310</em>, 112970. (<a href='https://doi.org/10.1016/j.knosys.2025.112970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The business processes of organizations may deviate from normal control flow due to disruptive anomalies, including unknown, skipped, and wrongly-ordered activities. To identify these control-flow anomalies, process mining can check control-flow correctness against a reference process model through conformance checking, an explainable set of algorithms that allows linking any deviations with model elements. However, the effectiveness of conformance checking-based techniques is negatively affected by noisy event data and low-quality process models. To address these shortcomings and support the development of competitive and explainable conformance checking-based techniques for control-flow anomaly detection, we propose a novel process mining-based feature extraction approach with alignment-based conformance checking. This variant aligns the deviating control flow with a reference process model; the resulting alignment can be inspected to extract additional statistics such as the number of times a given activity caused mismatches. We integrate this approach into a flexible and explainable framework for developing techniques for control-flow anomaly detection. The framework combines process mining-based feature extraction and dimensionality reduction to handle high-dimensional feature sets, achieve detection effectiveness, and support explainability. The results show that the framework techniques implementing our approach outperform the baseline conformance checking-based techniques while maintaining the explainable nature of conformance checking. We also provide an explanation of why existing conformance checking-based techniques may be ineffective. Finally, the results indicate that detection effectiveness is not solely dependent on the specific framework technique used, as no one-size-fits-all process mining-based feature extraction approach is suitable for all the synthetic and real-world datasets.},
  archive      = {J_KBS},
  author       = {Francesco Vitale and Marco Pegoraro and Wil M.P. van der Aalst and Nicola Mazzocca},
  doi          = {10.1016/j.knosys.2025.112970},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112970},
  shortjournal = {Knowl. Based Syst.},
  title        = {Control-flow anomaly detection by process mining-based feature extraction and dimensionality reduction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel s-box generation method based on metastable inducing over FPGA for block ciphers. <em>KBS</em>, <em>310</em>, 112968. (<a href='https://doi.org/10.1016/j.knosys.2025.112968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substitution boxes (s-boxes) providing the nonlinearity property are fundamental components of modern encryption systems. The security of these systems directly depends on the quality of the s-boxes ensuring a high level of resistance to advanced attacks. Although there is no perfect method in the literature, improving the cryptographic properties of s-boxes, such as nonlinearity and differential independence remains an important area of interest for many researchers. In this paper, we propose a new s-box generation method based on the reinforcement of the randomness obtained from the metastable states of the R-S latch. In the proposed method, a Field Programmable Gate Array (FPGA) chip is used to obtain design inputs based on physical reality obtained from the hardware level. Design inputs with poor statistical adequacy are transformed into s-boxes by passing them through four different hash functions (Blake2b, Blake2 s, SHA3 and Shake). A total of 333,328 s-boxes are generated with the proposed method for four different scenarios and widely used evaluation metrics such as bijectivity, nonlinearity (NL), strict avalanche criteria (SAC), bit independence criteria (BIC), differential probability (DP) and linear probability (LP) are considered for the analysis. Taking into account these metric values, the study also presents a detailed performance comparison of the proposed s-boxes with recent studies from the last 5 years in the literature. The fact that the nonlinearity degree of 75 % of the produced s-boxes is higher than 103, which is the average limit value in the literature, also confirms the method's efficiency, proven reliable by the analysis results. When all these results are evaluated together, they confirm that the proposed method is highly effective in generating robust s-boxes and that these s-boxes can be reliably used in modern cryptographic systems.},
  archive      = {J_KBS},
  author       = {Ali Murat Garipcan and Yılmaz Aydın and Fatih Özkaynak},
  doi          = {10.1016/j.knosys.2025.112968},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112968},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel s-box generation method based on metastable inducing over FPGA for block ciphers},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised dual graph learning for recommendation. <em>KBS</em>, <em>310</em>, 112967. (<a href='https://doi.org/10.1016/j.knosys.2025.112967'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) is one of the common approaches for recommendation. Recently, graph-based methods, which use the holistic bipartite graph structure to learn user preferences for items, have emerged as effective techniques for CF. Nevertheless, existing graph-based recommenders primarily consider entity connections (i.e., user–user, item–item, and user–item relations) but ignore semantic associations among interaction behaviors (e.g., relationships between different interactions of the same user or item). Because the modelings of entities and interaction behaviors are crucial components in CF, we believe that jointly learning discriminative relationships of these two parts achieves performance gain. In this work, we develop dual graph learning modules, which model both entity-level and behavior-level relations for better learning of the entities and interactions. One entity-centric module adopts graph convolutions on the user–item bipartite graph to capture connections between entities. The other behavior-centric module introduces the user–item line graph (where nodes represent interaction behaviors) and then creates a line graph neural network on this graph to distill semantic associations of interaction behaviors. In addition, self-supervised learning is utilized to model cooperative signals between the two graph learning modules, complementing the representation learning capabilities of each module. We name our method self-supervised dual graph learning (SDGL). Experiment results on the seven real-world datasets indicate the superiority of our SDGL over the state-of-the-art baselines. Specifically, SDGL achieves a performance improvement of 1.30% ∼ 7.99% in the Precision@10 metric compared to the best baseline models.},
  archive      = {J_KBS},
  author       = {Anchen Li and Bo Yang and Huan Huo and Farookh Khadeer Hussain and Guandong Xu},
  doi          = {10.1016/j.knosys.2025.112967},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112967},
  shortjournal = {Knowl. Based Syst.},
  title        = {Self-supervised dual graph learning for recommendation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based probabilistic forecasting of daily hotel demand using web search behavior. <em>KBS</em>, <em>310</em>, 112966. (<a href='https://doi.org/10.1016/j.knosys.2025.112966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate demand forecasting is crucial for the hotel industry, influencing revenue management, staffing, and resource allocation. This paper presents an innovative approach to probabilistic forecasting of daily hotel demand by integrating the Temporal Fusion Transformer (TFT) model with Google Trends data. Our key contributions include: (1) leveraging web search behavior to enhance demand forecasting accuracy, (2) applying TFT for interpretable probabilistic forecasts, evaluated using the Winkler Score, and (3) conducting a comprehensive comparative analysis with state-of-the-art time series and probabilistic forecasting models. Our approach is validated using data from multiple hotels, showing significant accuracy improvements. The proposed method achieves an average Mean Absolute Error (MAE) of, 4.25 surpassing traditional models like ARIMA, TiDE and LSTM. The findings underscore the value of web search data in forecasting and offer a powerful tool for hotel managers and other stakeholders in the hospitality industry.},
  archive      = {J_KBS},
  author       = {Cristof Rojas and Adam Jatowt},
  doi          = {10.1016/j.knosys.2025.112966},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112966},
  shortjournal = {Knowl. Based Syst.},
  title        = {Transformer-based probabilistic forecasting of daily hotel demand using web search behavior},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on deep learning in Edge–Cloud collaboration: Model partitioning, privacy preservation, and prospects. <em>KBS</em>, <em>310</em>, 112965. (<a href='https://doi.org/10.1016/j.knosys.2025.112965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the rapid advancements of AI technologies and mobile computing have led to the growing prevalence of smart devices and rising demands for on-device Deep Learning applications. Given this context, the Edge–Cloud Collaboration System has attracted considerable attention. This survey article focuses on a typical architecture in such a system, called Partitioned Deep Neural Network . Concretely, a complex Deep Learning model is partitioned into two segments. The shallow part, which serves as the feature extractor, is deployed on the edge device, while the remaining layers are processed on the cloud server for result inferences. We provide a comprehensive overview of Partitioning Deep Neural Networks for the Edge–Cloud Collaboration System , including model split, experimental settings, threat models, and assessment metrics. Then, we conduct a systematic summary of state-of-the-art privacy-preserving technologies, providing detailed comparisons of their advantages and limitations in practice. Finally, we highlight the main open challenges and propose intriguing research problems as future directions from various aspects, including attacking settings, novel application scenarios, evaluation measurements, and the applications and potential influences of Large Language Models in related domains.},
  archive      = {J_KBS},
  author       = {Xichen Zhang and Roozbeh Razavi-Far and Haruna Isah and Amir David and Griffin Higgins and Michael Zhang},
  doi          = {10.1016/j.knosys.2025.112965},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112965},
  shortjournal = {Knowl. Based Syst.},
  title        = {A survey on deep learning in Edge–Cloud collaboration: Model partitioning, privacy preservation, and prospects},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). POMM: A public opinion management model integrating network game and opinion dynamics for social networks. <em>KBS</em>, <em>310</em>, 112964. (<a href='https://doi.org/10.1016/j.knosys.2025.112964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In public opinion research, quantifying and modelling the evolution trends of public opinion and assessing the effectiveness of management strategies are critical topics of research. Conventional network game models in public management typically focus on behavioural changes, whereas opinion dynamics models focus on the evolution of opinion. However, both these approaches do not consider the interaction between behaviours and opinions. These behaviours and opinions encompass aspects such as individuals disseminating their opinions or remaining silent, their trust or distrust in external opinions, and whether their attitude is positive or negative. To integrate individual factors in the dissemination of public opinion, this study proposed an innovative public opinion management model (POMM), which combines the public opinion evolution model (POEM) with customised management strategies. The POEM integrates network game theory and opinion dynamics to comprehend the complex interaction between individual psychological processes and opinion dissemination behaviours. This approach enables precise modelling of the complex relationship between behaviour and opinion tendency. Authority-targeted and network structure-targeted management strategies were proposed. These strategies are compatible with the POEM framework and can be used to evaluate the effectiveness of public opinion management strategies. Through numerical simulations and comparative experiments, we systematically analysed the key factors influencing the evolution of public opinion, highlighting the advantages of POEM over conventional opinion dynamics models and evaluating the effectiveness of various management strategies. The results demonstrate that POMM exhibits considerable potential for optimising public opinion management.},
  archive      = {J_KBS},
  author       = {Yitai Xu and Xiaofeng Liu and Jianbo Yuan and Jiayi Luo and Wen Zhou and Miao Yu and Yongming He},
  doi          = {10.1016/j.knosys.2025.112964},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112964},
  shortjournal = {Knowl. Based Syst.},
  title        = {POMM: A public opinion management model integrating network game and opinion dynamics for social networks},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A contrast-invariant feature extraction framework for single-domain generalization in infrared small target detection. <em>KBS</em>, <em>310</em>, 112963. (<a href='https://doi.org/10.1016/j.knosys.2025.112963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection has important applications in many fields, but the domain gap between synthesized training samples and the real test images leads to significant performance degradation in real-life applications. This paper proposes a single-domain generalized infrared small target detection framework (SGIRNet) that integrates feature modulation and invariant feature extraction to effectively improve the generalization ability of the existing model. Firstly, considering the huge variability between the foreground targets and backgrounds in different data domains contributes to performance degradation, we devise a new contrast modulation model (CM) to remedy the feature domain gap by interleaving enhancement and suppression operations. Furthermore, a position and channel invariant feature extraction module (PCIFM) is proposed to extract target features that are not affected by contrast changes, thereby mitigating the problem of insufficient local difference modulation and greatly reducing false alarms caused by structural background interference. We integrate the proposed framework with several existing models to evaluate the performance. Extensive results show that our proposed framework can significantly improve the detection performance of existing models in the unseen domain, demonstrating the superior generalization ability of the proposed method.},
  archive      = {J_KBS},
  author       = {Weijian Chi and Jiahang Liu and Xiankai Lu and Yue Ni and Xiaozhen Wang},
  doi          = {10.1016/j.knosys.2025.112963},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112963},
  shortjournal = {Knowl. Based Syst.},
  title        = {A contrast-invariant feature extraction framework for single-domain generalization in infrared small target detection},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-center federated learning mechanism based on consortium blockchain for data secure sharing. <em>KBS</em>, <em>310</em>, 112962. (<a href='https://doi.org/10.1016/j.knosys.2025.112962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, federated learning enables hospitals to collaborate on model training without disclosing patient privacy data. However, it still faces challenges such as single point of failure and communication inefficiency. For this reason, this study innovatively combines consortium blockchain and federated learning. A multi-center federated learning mechanism based on consortium blockchain (MCFLM-CB) is proposed to optimize the security and efficiency of data collaboration and sharing. Firstly, the MCFLM-CB model uses the multi-party co-management feature of the consortium blockchain to replace the central server of federated learning, so that the system performs the training of the federated learning model in multiple centers. It also achieves the elimination of the disadvantages that a single centralized server controls the data model. Secondly, we propose a Dynamic Grouping-based Practical Byzantine Fault Tolerant (DG-PBFT) consensus algorithm. The algorithm performs regrouping and center node selection based on node state changes. It improves the consensus algorithm in blockchain system adaptive ability. Finally, we propose a reputation value-based weighted federal average algorithm. By synthesizing multiple reputation attributes to evaluate the reputation of participants, it comprehensively reflects the node performance. The accuracy and reliability of reputation values are improved. To prove the effectiveness of the method, we validated it on 12 large-scale standardized biomedical image sets MedMNIST. The results show that the model achieves 93.2% accuracy and significantly improves the efficiency of the blockchain.},
  archive      = {J_KBS},
  author       = {Bin Wang and Zhao Tian and Xinrui Liu and Yujie Xia and Wei She and Wei Liu},
  doi          = {10.1016/j.knosys.2025.112962},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112962},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-center federated learning mechanism based on consortium blockchain for data secure sharing},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive sampling framework for data-efficient modelling of marine antibiotic-resistance genes (ARGs). <em>KBS</em>, <em>310</em>, 112961. (<a href='https://doi.org/10.1016/j.knosys.2025.112961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying antibiotic-resistance genes (ARGs) in marine systems traditionally relies on extensive laboratory-based analysis. Data-driven modelling of ARGs is an emerging and promising approach that could enable real-time water quality monitoring, reducing both field and lab work, and associated costs. This work demonstrates a combination of Squared Prediction Error (SPE), Kernel Principal Component Analysis (KPCA) and Gaussian Processes (GP) for marine monitoring. The work advances real-time decision-making for both when to sample and data-efficient modelling by identifying when environmental conditions are likely to be novel. This was quantified by the SPE-KPCA model as a difference between current water conditions and those previously sampled. By identifying already-sampled environmental conditions, the number of water samples that were collected was reduced. The modelling of the level of ARGs is based on the GP predictive model. The method adaptively updated SPE-KPCA and GP models as new data were collected. The proposed framework was validated on both synthetic and real-life data. The validation demonstrated that the GP model, using a subset of the data sequentially selected by the SPE-KPCA model, led to similar prediction accuracy to the case of using all data, showing the potential for reducing the costs of data acquisition in this problem.},
  archive      = {J_KBS},
  author       = {Tian Cong and Pascal Craw and Adrien Ickowicz and Neil Francis},
  doi          = {10.1016/j.knosys.2025.112961},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112961},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive sampling framework for data-efficient modelling of marine antibiotic-resistance genes (ARGs)},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InfraFFN: A feature fusion network leveraging dual-path convolution and self-attention for infrared image super-resolution. <em>KBS</em>, <em>310</em>, 112960. (<a href='https://doi.org/10.1016/j.knosys.2025.112960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) is a classic visual problem that aims to generate high-quality, high-resolution images from low-resolution inputs. However, most deep learning methods are designed for visible images and often overlook infrared images, which play a crucial role in numerous research fields such as aerospace and remote sensing. Due to hardware limitations, infrared images possess a lower resolution and exhibit characteristics distinct from visible images, including low contrast and indistinct gradients. These unique patterns are challenging to extract and represent. To address this issue, we propose a Infrared Feature Fusion Network (InfraFFN) for infrared image SR in this paper. Specifically, we design a Residual Feature Fusion Block (RFFB) for deep feature extraction. Each Feature Fusion Block (FFB) within RFFB effectively combines the advantages of convolution and self-attention, and utilizes bi-directional information interactions across branches to better model in both channel and spatial dimensions. Furthermore, considering the low contrast in infrared images, we designed a dual-path convolution structure to extract features under different sizes of receptive fields and fuse features at various scales. Extensive experiments demonstrate that our InfraFFN achieves superior visual improvement on multiple infrared image datasets compared to state-of-the-art methods. The source codes are available at https://github.com/szw811/InfraFFN .},
  archive      = {J_KBS},
  author       = {Feiwei Qin and Zhengwei Shen and Ruiquan Ge and Kai Zhang and Fei Lin and Yeru Wang and Juan M. Gorriz and Ahmed Elazab and Changmiao Wang},
  doi          = {10.1016/j.knosys.2025.112960},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112960},
  shortjournal = {Knowl. Based Syst.},
  title        = {InfraFFN: A feature fusion network leveraging dual-path convolution and self-attention for infrared image super-resolution},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DyArtbank: Diverse artistic style transfer via pre-trained stable diffusion and dynamic style prompt artbank. <em>KBS</em>, <em>310</em>, 112959. (<a href='https://doi.org/10.1016/j.knosys.2025.112959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artistic style transfer aims to transfer the learned style onto an arbitrary content image. However, most existing style transfer methods can only render consistent artistic stylized images, making it difficult for users to get enough stylized images to enjoy. To solve this issue, we propose a novel artistic style transfer framework called DyArtbank, which can generate diverse and highly realistic artistic stylized images. Specifically, we introduce a Dynamic Style Prompt ArtBank (DSPA), a set of learnable parameters. It can learn and store the style information from the collection of artworks, dynamically guiding pre-trained stable diffusion to generate diverse and highly realistic artistic stylized images. DSPA can also generate random artistic image samples with the learned style information, providing a new idea for data augmentation. Besides, a Key Content Feature Prompt (KCFP) module is proposed to provide sufficient content prompts for pre-trained stable diffusion to preserve the detailed structure of the input content image. Extensive qualitative and quantitative experiments verify the effectiveness of our proposed method.},
  archive      = {J_KBS},
  author       = {Zhanjie Zhang and Quanwei Zhang and Guangyuan Li and Junsheng Luan and Mengyuan Yang and Yun Wang and Lei Zhao},
  doi          = {10.1016/j.knosys.2025.112959},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112959},
  shortjournal = {Knowl. Based Syst.},
  title        = {DyArtbank: Diverse artistic style transfer via pre-trained stable diffusion and dynamic style prompt artbank},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAHKT: Knowledge tracing with multi-association heterogeneous graph embedding based on knowledge transfer. <em>KBS</em>, <em>310</em>, 112958. (<a href='https://doi.org/10.1016/j.knosys.2025.112958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is crucial in online education for tracing learners knowledge states and improving learning outcomes. However, existing graph-based KT models often focus solely on prerequisite associations among concepts or correlations between concepts and questions, neglecting the complex multi-association relationships among entities. This oversight causes biased question representations, which in turn affects the knowledge transfer propagation process, ultimately leading to inconsistencies between the represented and actual knowledge states. To address this, we propose multi-association heterogeneous knowledge transfer (MAHKT), a novel KT model that leverages multi-association heterogeneous graph embeddings based on knowledge-transfer principles, to better capture the evolution of knowledge states. Five types of associations were defined between questions and concepts to construct a multi-association heterogeneous graph, thereby proposing a knowledge triplet embedding method to extract the potential value of these associations. Grounded in near- and far-transfer theories, MAHKT employs a perception-attention mechanism to calculate similarity weights, propagates embeddings from first-order neighbors to capture near-transfer effects, and stacks propagation layers to aggregate far-transfer information, thereby comprehensively integrating richer knowledge from similar knowledge transfers across various association contexts. Finally, two LSTM modules were utilized to track the evolution of learner’s knowledge states across questions and concepts, to predict their future performance. The experimental results show that MAHKT significantly outperformed existing KT methods, enhancing prediction accuracy and improving model interpretability in the knowledge transfer process.},
  archive      = {J_KBS},
  author       = {Huali Yang and Junjie Hu and Jinjin Chen and Shengze Hu and Jing Geng and Qiang Zhu and Tao Huang},
  doi          = {10.1016/j.knosys.2025.112958},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112958},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAHKT: Knowledge tracing with multi-association heterogeneous graph embedding based on knowledge transfer},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention holistic processing multi-channel graph transformer with graph residual connections for predicting lncRNA–Protein interactions. <em>KBS</em>, <em>310</em>, 112957. (<a href='https://doi.org/10.1016/j.knosys.2025.112957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the interactions between long non-coding RNAs (lncRNAs) and proteins is crucial for elucidating complex regulatory mechanisms within cells. Recent advances in graph-neural-network prediction methods have been significant. However, they still insufficiently address the sparsity of data in predicting associations between lncRNAs and proteins, and often overlook the importance of weighting multilevel representations during the encoding process of lncRNAs and proteins. Moreover, the high complexity of encoding networks can lead to model instability. We introduce a novel approach called the G raph residual connection attention H olistic processing multiple C hannels graph T ransformer (GHCT) for predicting interactions between lncRNAs and proteins. This model leverages identity feature matrices for adaptive encoding and employs deep graph residual modules to resolve issues of model instability. The GHCT captures complex feature representations and long-distance dependencies through holistic attentional processing. It also utilises this graph multichannel attention mechanism to capture cross-channel graph aggregation information and effectively capture and integrate information from different data channels. Finally, matrix multiplication is used for decoding and prediction. We conducted extensive experiments on three widely used datasets, including sparse datasets, in which our GHCT model achieved area under the curve (AUC) scores of 0.9775, 0.9746, and 0.9808, significantly outperforming other state-of-the-art models. Moreover, we conducted ten repeated experiments on imbalanced and noisy datasets, the results of which demonstrated the excellent generalisation and noise resistance capabilities of our model. Our case studies have also shown that our method can discover new lncRNA–protein interactions, providing valuable insights for predicting the interactions between lncRNAs and proteins.},
  archive      = {J_KBS},
  author       = {Qi Wu and Yinbo Liu and Shuxia Chen and Wenwen Xu and Yunzhi Wu and Xiaolei Zhu and Yi Yue},
  doi          = {10.1016/j.knosys.2025.112957},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112957},
  shortjournal = {Knowl. Based Syst.},
  title        = {Attention holistic processing multi-channel graph transformer with graph residual connections for predicting lncRNA–Protein interactions},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view representation learning with decoupled private and shared propagation. <em>KBS</em>, <em>310</em>, 112956. (<a href='https://doi.org/10.1016/j.knosys.2025.112956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning has demonstrated strong potential in processing data from different sources or viewpoints. Despite the significant progress made by Multi-view Graph Neural Networks (MvGNNs) in exploiting graph structures, features, and representations, existing research generally lacks architectures specifically designed for the intrinsic properties of multi-view data. This leads to models that still have deficiencies in fully utilizing consistent and complementary information in multi-view data. Most of current research tends to simply extend the single-view GNN framework to multi-view data, lacking in-depth strategies to handle and leverage the unique properties of these data. To address this issue, we propose a simple yet effective MvGNN framework called Multi-view Representation Learning with Decoupled private and shared Propagation (MvRL-DP). This framework enables multi-view data to be effectively processed as a whole by alternating private and shared operations to integrate cross-view information. In addition, to address possible inconsistencies between views, we present a discriminative loss that promotes class separability and prevents the model from being misled by noise hidden in multi-view data. Experiments demonstrate that the proposed framework is superior to current state-of-the-art methods in the multi-view semi-supervised classification task.},
  archive      = {J_KBS},
  author       = {Xuzheng Wang and Shiyang Lan and Zhihao Wu and Wenzhong Guo and Shiping Wang},
  doi          = {10.1016/j.knosys.2025.112956},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112956},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view representation learning with decoupled private and shared propagation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level knowledge distillation for fine-grained fashion image retrieval. <em>KBS</em>, <em>310</em>, 112955. (<a href='https://doi.org/10.1016/j.knosys.2025.112955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained fashion image retrieval (FIR) is crucial for enhancing customer experience, providing personalized recommendations, increasing conversion rates, and reducing returns. Our investigation into fine-grained FIR revealed that discerning subtle and intra-attribute variations is crucial. Though Knowledge Distillation (KD) has been verified to be effective in extracting more discriminative visual representations in several tasks, most KD methods transfer knowledge on an item level, which may not always achieve optimal performance in this task which cares about the relational and ranking information as well. To address these challenges, we propose an online KD framework for leveraging KD’s advantages in feature extraction to improve existing fine-grained FIR methods. We also introduce a novel multi-level knowledge distillation (MKD) strategy that transfers multi-level features between two backbones including the item-level, doublet sample-level, and triplet sample-level. The MKD enhances the learning of individual feature representations, similarity information between two samples, and rank information among triplet samples, which can significantly improve fine-grained FIR. We experimentally verified that our MKD outperforms the item-level KD strategy and existing typical relation-aware KD strategies. The proposed KD framework and MKD strategy lead to a significant and consistent improvement in retrieval accuracy when adopted in existing fine-grained FIR methods (e.g., a +8.60% increase in mAP on the FashionAI dataset for the ASENet_V2 model).},
  archive      = {J_KBS},
  author       = {Ling Xiao and Toshihiko Yamasaki},
  doi          = {10.1016/j.knosys.2025.112955},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112955},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-level knowledge distillation for fine-grained fashion image retrieval},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discriminator to grade classification results of neural networks via prediction error tracking method. <em>KBS</em>, <em>310</em>, 112954. (<a href='https://doi.org/10.1016/j.knosys.2025.112954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current artificial intelligence (AI) classifiers provide only the prediction accuracy to represent the classifier as a whole. Therefore, users have to risk incurring the same rate of prediction errors for all prediction results, which can be unacceptable in security areas requiring high reliability. Herein, we devise a new method for tracking prediction errors and use it to create a novel discriminator to grade classification results of neural networks. Through experiments and objective evaluation metrics, we demonstrate its efficacy in identifying highly reliable predictions made by a classifier leading us into believing that users can verify whether the classifier’s predictions are correct even for field data without ground truth labels. We expect that the proposed method and discriminator will notably transform the landscape of AI classifiers when introduced to AI industries.},
  archive      = {J_KBS},
  author       = {Gyuyoung Lee and Changjo Yun and Sungjin Kim and Brent Byunghoon Kang},
  doi          = {10.1016/j.knosys.2025.112954},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112954},
  shortjournal = {Knowl. Based Syst.},
  title        = {Discriminator to grade classification results of neural networks via prediction error tracking method},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label completion based concept factorization for incomplete multi-view clustering. <em>KBS</em>, <em>310</em>, 112953. (<a href='https://doi.org/10.1016/j.knosys.2025.112953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering (IMVC) has attracted much attention due to its superior performance in handling incomplete multi-view data. However, existing IMVC methods pay little attention to the semantic associations between incomplete data and concepts. On the other hand, the acquisition of cluster labels also needs to be achieved by clustering algorithms, which splits concept factorization and label learning into two steps. To address these limitations, we design a new IMVC model called label completion based concept factorization (LCCF). Specifically, we first integrate the concept factorization and label learning into the IMVC framework, which can explore the semantic associations between incomplete data and concepts and simultaneously reduce the cost of the completion process. Meanwhile, the weighted spectral rotation is employed to adaptively perform view indicator matrix fusion, which can seamlessly obtain the categories of all samples. Furthermore, we introduce the weighted tensor Schatten p -norm (WTSN) regularization, which can better approximate the rank and exploit the salient structural information in the matrix based on the differences between the singular values. To evaluate the effectiveness of our method, we conduct comprehensive experiments by comparing it with eight baseline methods utilizing five evaluation metrics. The results demonstrate that the proposed LCCF model exhibits superior performance compared to existing state-of-the-art methods. In particular, on the NGs dataset with a missing rate of 50%, the LCCF model exhibits much better performance in terms of ACC and MNI metrics, with an improvement of 8.4% and 22.7%, respectively, in comparison to the second-best algorithm.},
  archive      = {J_KBS},
  author       = {Beihua Yang and Peng Song and Yuanbo Cheng and Zhaowei Liu and Yanwei Yu},
  doi          = {10.1016/j.knosys.2025.112953},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112953},
  shortjournal = {Knowl. Based Syst.},
  title        = {Label completion based concept factorization for incomplete multi-view clustering},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-based sample generation method for few-shot bearing condition monitoring. <em>KBS</em>, <em>310</em>, 112952. (<a href='https://doi.org/10.1016/j.knosys.2024.112952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing intelligent fault diagnosis methods rely on abundant fault samples to complete the sample space. However, in real-world conditions, fault samples are scarce and easily overlooked because equipment typically operates normally, presenting a few-shot fault diagnosis challenge. To address this, a hybrid data-driven scheme combined with physics-based sample generation (PSG) is proposed for few-shot bearing fault diagnosis. The core approach involves using simple equipment parameters and health signals to generate realistic fault samples. Specifically, a nonlinear dynamic model of the bearing-rotor system (RBS) is developed to generate interpretable mechanistic signals for various faults, thereby constructing a complete sample space. The PSG scheme, enhanced by a cosine similarity update strategy, minimizes distribution shifts and increases sample diversity. Finally, the hybrid dataset was used to train AI models on both laboratory and public data, achieving top average accuracies of 97.3%, 99.3%, and 99.1% with CNN, VGG-19, and ResNet, respectively. The results demonstrate that the proposed method outperforms other popular sample generation methods.},
  archive      = {J_KBS},
  author       = {Zepeng Ma and Lei Fu and Fang Xu and Libin Zhang},
  doi          = {10.1016/j.knosys.2024.112952},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112952},
  shortjournal = {Knowl. Based Syst.},
  title        = {A physics-based sample generation method for few-shot bearing condition monitoring},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High–low frequency dynamic interactive fusion network for multivariate time series forecasting. <em>KBS</em>, <em>310</em>, 112951. (<a href='https://doi.org/10.1016/j.knosys.2024.112951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate multivariate time series prediction has numerous real-world applications, such as traffic flow analysis and marine phenomenon forecasting. Time series data often involves both smooth cyclical changes and sudden events, and the interplay between these factors poses significant challenges for prediction. Existing methods either model time series data directly, neglecting the intertwined influences, or utilize decomposition learning without fully capturing the patterns of the decomposed sequences. To address these issues, we propose HiLIN, a novel high–low frequency dynamic interactive fusion model for time series data. HiLIN decouples the time series into high-frequency (reflecting short-term fluctuations) and low-frequency (reflecting long-term seasonal changes) sequences, modeling each according to its distinct characteristics. Specifically, to capture sharp fluctuations in event sequences, we employ a dynamic spatiotemporal graph convolution method. The MLP module is used to model the long-term trend patterns effectively. Additionally, we design an adaptive fusion module to integrate sequence information based on the input sequence’s characteristics. This integration is achieved through a high- and low-frequency interactive fusion framework that synchronously captures spatiotemporal features. Extensive experiments on five real datasets from traffic and ocean domains demonstrate that HiLIN outperforms existing methods, validating its effectiveness in capturing complex spatiotemporal patterns.},
  archive      = {J_KBS},
  author       = {Chengci Wang and Zhuolin Li and Jie Yu and Lingyu Xu},
  doi          = {10.1016/j.knosys.2024.112951},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112951},
  shortjournal = {Knowl. Based Syst.},
  title        = {High–low frequency dynamic interactive fusion network for multivariate time series forecasting},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bio-inspired optimization of feature selection and SVM tuning for voice disorders detection. <em>KBS</em>, <em>310</em>, 112950. (<a href='https://doi.org/10.1016/j.knosys.2024.112950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verbal communication is essential to human life, forming the foundation for self-expression and interaction. However, voice disorders pose a significant challenge, severely impeding communication ability. These disorders, which affect critical aspects of voice such as loudness, pitch, and resonance, disrupt speech and social and professional functioning. Often rooted in structural abnormalities of the vocal tract, voice disorders demand urgent attention, as early detection is paramount to ensuring timely and effective treatment. Addressing these issues is vital to restoring the fundamental human ability to connect and communicate. This study employs a bio-inspired machine learning approach to detect voice disorders, aiming to evaluate the effectiveness of simpler methods, excluding deep learning. The research applies three bio-inspired optimization algorithms — Genetic Algorithm (GA), Particle Swarm Optimizer (PSO), and Whale Optimization Algorithm (WOA) — as wrapper-based feature selection methods, with Support Vector Machine (SVM) serving as the base learner. The approach focuses on optimizing SVM parameters (cost and gamma) while identifying the most critical features for voice disorder detection. Experiments were conducted on three datasets, with performance evaluated using recall, precision, and F1-score. The GA achieved the highest F1-score (96.3%) on the first dataset, while WOA demonstrated superior performance on the second and third datasets, with F1-scores of 71.8% and 42.3%, respectively. Feature importance analysis using the SHAP algorithm highlighted Mel spectrogram, temporal correlation, and fast Fourier transform features as key contributors to improving prediction accuracy.},
  archive      = {J_KBS},
  author       = {Maria Habib and Victor Vicente-Palacios and Pablo García-Sánchez},
  doi          = {10.1016/j.knosys.2024.112950},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112950},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bio-inspired optimization of feature selection and SVM tuning for voice disorders detection},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the exploitation in the estimation of distribution algorithm through simulated annealing strategies for solar energy problems. <em>KBS</em>, <em>310</em>, 112949. (<a href='https://doi.org/10.1016/j.knosys.2024.112949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of Distribution Algorithms (EDAs) have gained substantial attention in optimization due to their ability to efficiently explore complex search spaces by modeling promising regions through probability distributions. However, their effectiveness can be further enhanced by integrating complementary optimization techniques. This paper proposes a hybrid approach that combines the strengths of an EDA with the powerful optimization capabilities of Simulated Annealing (SA) in synergy with a mutation operator and the initialization using the Latin Hypercube. It is called directed EDA (R-EDA). The hybrid algorithm permits a better exploration since the early optimization stages. It weighs the diversity-preserving mechanisms of EDAs while incorporating the robust exploitation abilities of SA in combination with a mutation operator. The synergy of the elements introduced in the R-EDA permits an algorithm that can provide accurate solutions to complex and high-dimensional problems. The R-EDA is tested over a series of experiments on 36 benchmark optimization problems in 30, 50, and 100 dimensions with unimodal, multimodal, composite, and shifted optimization landscapes. Additionally, a comparison of the application of modeling solar cells using three different approaches is presented. The experimental results demonstrate the efficacy of R-EDA in achieving superior optimization performance compared with well-known state-of-the-art algorithms over the benchmark function and solar cells modeling application. Furthermore, the impact of key algorithmic parameters is analyzed, providing insights into the synergistic effects of the hybridization process.},
  archive      = {J_KBS},
  author       = {Jorge Ramos-Frutos and Diego Oliva and Israel Miguel-Andrés and Mario A. Navarro and Arturo Valdivia and Saúl Zapotecas-Martínez and Diego Campos-Peña},
  doi          = {10.1016/j.knosys.2024.112949},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112949},
  shortjournal = {Knowl. Based Syst.},
  title        = {Improving the exploitation in the estimation of distribution algorithm through simulated annealing strategies for solar energy problems},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial distance evidential clustering for missing data with multiple imputation. <em>KBS</em>, <em>310</em>, 112948. (<a href='https://doi.org/10.1016/j.knosys.2024.112948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of clustering missing data is a hot topic that remains challenging. This is because imputation-based clustering methods that provide inaccurate estimations may cause uncertainty and imprecision, leading to a negative impact on clustering accuracy. Moreover, missing values may result in incomplete objects that are indistinguishable between clusters, especially when critical attribute values are lost. To address these issues, a partial distance evidential clustering (PEC) method is introduced in this study. Specifically, the (complete or incomplete) object is preliminarily partitioned as certain or uncertain according to evidential clustering based on the partial distance without any imputation strategy. In this manner, we can fully model the data structure and avoid the negative effects of inaccurate estimations on the clustering process. In addition, an uncertain object with missing values is input multiple times to obtain different complete versions, modeling the uncertainty of the estimations. The clustering results of the versions are combined to make a decision under the Dempster–Shafer theory framework. In this process, the objects in the overlapping zones of clusters are usually indistinguishable between clusters, and they are assigned to meta-clusters to characterize imprecision and reduce the risk of errors. Experiments on a synthetic toy and several real-world datasets demonstrate the effectiveness of the proposed PEC method compared with related methods.},
  archive      = {J_KBS},
  author       = {Hong-Peng Tian and Zhen Zhang},
  doi          = {10.1016/j.knosys.2024.112948},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112948},
  shortjournal = {Knowl. Based Syst.},
  title        = {Partial distance evidential clustering for missing data with multiple imputation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic ensemble learning based data mining framework for medical imbalanced big data. <em>KBS</em>, <em>310</em>, 112947. (<a href='https://doi.org/10.1016/j.knosys.2024.112947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, technologies like the Internet of Things, smart cities, healthcare, and social media rely heavily on advanced data analytics. In medical data, certain critical diseases are significantly underrepresented compared to more prevalent conditions, creating a class imbalance that can lead to biased models favoring majority class predictions. This imbalance reduces the accuracy and reliability of predictions for the minority class, which is often essential for early diagnosis and intervention in rare but severe diseases. This is particularly challenging in medical data, where cancer classification faces problems such as high dimensionality, redundancy, and severe class imbalance. To address these challenges, this paper proposes a novel framework which integrates a Relevance Vector Machine classifier with an Incremental Ensemble framework to effectively manage data imbalance. It employs a Gaussian Mixture Models-based combined resampling algorithm to balance the dataset by resampling. Mutual Information Gain Maximization enhances the effectiveness of feature selection. To further enhance performance, an Adaptive Weighted Broad Learning System is incorporated a density-based weight generation mechanism using prior distribution information. Additionally, an Incremental Dynamic Learning Policy-based Relevance Vector Machine classifier is incorporated to adapt to new data, and maintain high accuracy. The proposed model achieves superior performance with an Accuracy of 99 %, a Kappa value of 98 %, an F1-Score of 99 %, and an MCC of 96.9 %. These results underscore the model's effectiveness in addressing class imbalance, enhancing predictive accuracy for minority classes, and offering a robust solution for complex medical datasets essential for improved healthcare outcomes.},
  archive      = {J_KBS},
  author       = {M. Rithani and R. Prasanna Kumar and Altalbe Ali},
  doi          = {10.1016/j.knosys.2024.112947},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112947},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dynamic ensemble learning based data mining framework for medical imbalanced big data},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGT: Unbiased sequential recommendation via disentangled graph transformer. <em>KBS</em>, <em>310</em>, 112946. (<a href='https://doi.org/10.1016/j.knosys.2024.112946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inevitable biases in the observed data often result in biased user representations and recommendation outcomes. Currently, most debiasing techniques are designed for traditional recommendation systems and typically rely on an unbiased dataset to estimate Propensity Scores (PS), which are crucial for developing robust recommendation models. However, in sequential recommendation scenarios, obtaining such an unbiased auxiliary dataset is extremely challenging, which significantly complicates the accurate estimation of inverse propensity scores and the extraction of unbiased user representations from biased user–item interactions. To address this challenge, we propose a Disentangled Graph Transformer (DGT) model enhanced by Propensity Scores for unbiased sequential recommendations. Specifically, we construct a temporal heterogeneous network and extract disentangled representations of users and items, effectively reducing the impact of self-selection bias in historical interaction data. Additionally, we decompose the propensity score into three distinct components: user-rating propensity, item-rating propensity, and user–item correlation propensity. By incorporating the distributions of user and item ratings as prior knowledge, we improve the precision of our propensity score estimation. Ultimately, these refined propensity scores are strategically employed as weighting factors within the loss functions and during the aggregation phase of the DGT layer, thereby strengthening the sequential recommendation system’s resistance to biases. We have conducted extensive experiments on five benchmark datasets to assess the efficacy and robustness of our model. In comparison with the state-of-the-art approaches, our DGT model has exhibited superior ability to provide unbiased recommendations. Our codes and datasets are available at GitHub: https://github.com/ycy89/DGT.git .},
  archive      = {J_KBS},
  author       = {Chenglin Li and Tao Xie and Chenyun Yu and Bo Hu and Zang Li and Lei Cheng and Beibei Kong and Di Niu},
  doi          = {10.1016/j.knosys.2024.112946},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112946},
  shortjournal = {Knowl. Based Syst.},
  title        = {DGT: Unbiased sequential recommendation via disentangled graph transformer},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing text anonymization via re-identification risk-based explainability. <em>KBS</em>, <em>310</em>, 112945. (<a href='https://doi.org/10.1016/j.knosys.2024.112945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text anonymization is a challenging task usually carried out by human annotators, thereby incurring significant economic and temporal costs. Even though automated approaches have been proposed to mitigate those costs, practical mechanisms for text anonymization mostly rely on named entity recognition (NER), which is acknowledged to offer insufficient privacy protection. To tackle this issue, we propose a methodology to enhance the privacy protection attained by any text anonymization mechanism –with a focus on NER-based ones–, while providing empirical guarantees against re-identification rooted on the k -anonymity privacy model. Our method relies on a neural language model trained on the aggregated background knowledge that can be leveraged to conduct re-identification attacks. Then, it employs explainability techniques to detect and iteratively mask the unprotected terms that caused the greatest re-identification risk until a user-defined k -anonymity level is reached. On the contrary to most existing methods in the text anonymization literature, our approach allows to intuitively configure the desired level of protection, and to tune the trade-off between privacy and data utility preservation. Experiments show that our method is able to significantly and consistently lower the re-identification risk of NER-based anonymizations, and to compete against more sophisticated state-of-the-art text anonymization methods while being free of their costs and external dependencies.},
  archive      = {J_KBS},
  author       = {Benet Manzanares-Salor and David Sánchez},
  doi          = {10.1016/j.knosys.2024.112945},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112945},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing text anonymization via re-identification risk-based explainability},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PNasFH-net: Pyramid neural architecture search forward network for facial emotion recognition in uncontrolled and pose variant environment. <em>KBS</em>, <em>310</em>, 112944. (<a href='https://doi.org/10.1016/j.knosys.2024.112944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face emotion recognition has attracted more attention in recent years because of its wide range of applications. This framework represents a novel facial emotion recognition technique known as a Pyramid Neural Architecture Search Forward Network (PNasFH-Net) developed for face emotion recognition. At first, the input image is subjected to image denoising and contrast enhancement using the Type II Fuzzy System and Cuckoo Search Optimization Algorithm (T2FCS) filter. Then, face detection is performed using the Viola-Jones algorithm based on the resultant denoised contrast-enhanced image. Subsequently, different features, like Spider Local Image Features (SLIF) with entropy, and Local Directional Number Pattern (LDNP) are extracted from the detected face in the feature extraction phase. Finally, facial emotions at different poses are recognized from the extracted features using PNasFH-Net. Here, PNasFH-Net is developed by the integration of the Deep Pyramidal Residual Network (PyramidNet) and NASNet. The recognized classes are surprise, sad, neutral, happy, fear, disgust, contempt and anger. The benchmark dataset for facial expression recognition, AffectNet is employed to assess the performance of the proposed model using performance measures, such as accuracy, TPR, and TNR. In addition, the developed PNasFH-Net obtained a higher accuracy of 90.315 %, True Negative Rate (TNR) of 90.157 % and True Positive Rate (TPR) of 91.047 %.},
  archive      = {J_KBS},
  author       = {Saranya Ravindran and Sasikumar Rajagopalan},
  doi          = {10.1016/j.knosys.2024.112944},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112944},
  shortjournal = {Knowl. Based Syst.},
  title        = {PNasFH-net: Pyramid neural architecture search forward network for facial emotion recognition in uncontrolled and pose variant environment},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-directional gated recurrent unit enhanced twin support vector regression with seasonal mechanism for electric load forecasting. <em>KBS</em>, <em>310</em>, 112943. (<a href='https://doi.org/10.1016/j.knosys.2024.112943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate electric load forecasting has numerous benefits, including cost reduction in power generation and valuable guidance for decision-makers in the power industry. Support Vector Regression (SVR) has gained attention for its strong mathematical foundation and high performance in electric load forecasting. However, SVR encounters challenges in computational cost, fitting large-scale datasets and seasonal pattern capturing. To overcome these limitations, this paper proposes SCBTIA, an intelligent load forecasting model that integrates data pre-processing, deep learning model, an improved meta-heuristic optimization algorithm and rolling seasonal mechanism into twin support vector regression (TWSVR). TWSVR improves upon SVR by delivering superior performance and reduced computational time, alleviating its limitations. Further, TWSVR is integrated with bi-directional gated recurrent unit (BiGRU) deep learning model using complementary ensemble empirical mode decomposition (CEEMD). This work also introduces an improved arithmetic optimization algorithm (IAOA) for dynamically selecting optimal hyper-parameter combinations in TWSVR. A seasonal mechanism that applying rolling-window method is also applied in the proposed model. Experiments encompass ablation studies, comparisons with SVR and TWSVR models, as well as single basic models and state-of-the-art models. These experiments utilize two real-world electric load datasets, highlighting SCBTIA's superior performance. Experiments illustrate that the proposed SCBTIA model has ability to address the challenges faced in electric load forecasting and provide an advanced solution that outperforms existing approaches.},
  archive      = {J_KBS},
  author       = {Zichen Zhang and Chenglong Zhang and Yongquan Dong and Wei-Chiang Hong},
  doi          = {10.1016/j.knosys.2024.112943},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112943},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bi-directional gated recurrent unit enhanced twin support vector regression with seasonal mechanism for electric load forecasting},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient gaussian mixture model and its application to neural networks. <em>KBS</em>, <em>310</em>, 112942. (<a href='https://doi.org/10.1016/j.knosys.2024.112942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian mixture models (GMMs) are powerful tools specifically suited for problems where data distributions are multi-modal. Inspired by Fourier expansion, we propose a concept called GMM expansion to approximate arbitrary densities. A simple learning method is introduced under this framework. Theoretical and numerical analyses are provided to show that densities under GMM expansion are able to approximate arbitrary densities with certain accuracy. The proposed learning algorithm demonstrates better accuracy and time efficiency compared to classic density approximation methods such as the Expectation Maximization (EM) algorithm and Bayesian variational inference (BVI) for Gaussian mixture models. The proposed framework also shows better accommodation of neural networks. Three neural network applications are built to demonstrate its usability. The accuracy of density estimation in neural networks is reported to be significantly improved in one of the applications. Another application shows that latent variables can be easily turned into random variables. This user-friendly method opens up more possibilities in terms of latent manipulation, embedding techniques, and many other potential uses.},
  archive      = {J_KBS},
  author       = {Weiguo Lu and Deng Ding and Fengyan Wu and Gangnan Yuan},
  doi          = {10.1016/j.knosys.2024.112942},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112942},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient gaussian mixture model and its application to neural networks},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision–language representation learning with breadth and depth attention pre-training. <em>KBS</em>, <em>310</em>, 112941. (<a href='https://doi.org/10.1016/j.knosys.2024.112941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advances in computer vision and natural language processing have led to increased attention toward the challenge of understanding vision and language together across multiple domains. Representation learning has become a major focus of research on cross-modal information understanding. However, current methods often fall short of providing comprehensive interaction and meaningful supervised guidance that would allow for effective learning of visual-linguistic joint representation. In this paper, we introduce the Breadth and Depth Attention Pre-training (BDAP) model for vision–language representation learning. Our model includes a breadth attention network designed to model feature associations between text sentences and image regions across different image levels. It uses fine-grained image features to promote more effective cross-modal feature interactions. Additionally, a depth attention network, which repeatedly calculates attention scores, is designed to deeply capture the complementarity between the image and text by gradually refining important image regions related to the text. Furthermore, we propose an attention pre-training network that leverages attention annotated distribution maps as prior knowledge to supervise the learning process of the breadth and depth attention networks, thereby enabling weight initialization of both types of attention networks. Extensive experiments on datasets of visual question answering and multi-modal sentiment analysis demonstrate the promising superiority of our BDAP model for vision–language representation learning.},
  archive      = {J_KBS},
  author       = {Yun Liu and Bo Zhang and ChenCheng Wang and Genglong Yan and Ke Zhou and Zhoujun Li and LeiLei Zhang},
  doi          = {10.1016/j.knosys.2024.112941},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112941},
  shortjournal = {Knowl. Based Syst.},
  title        = {Vision–language representation learning with breadth and depth attention pre-training},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models as oracles for instantiating ontologies with domain-specific knowledge. <em>KBS</em>, <em>310</em>, 112940. (<a href='https://doi.org/10.1016/j.knosys.2024.112940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective: To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Methods: Starting from (i) an initial schema composed by inter-related classes and properties and (ii) a set of query templates, our method queries the LLM multiple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution: We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Experimentally, our approach achieves a quality metric that is up to five times higher than the state-of-the-art, while reducing erroneous entities and relations by up to ten times. Finally, we provide a SWOT analysis of the proposed method.},
  archive      = {J_KBS},
  author       = {Giovanni Ciatto and Andrea Agiollo and Matteo Magnini and Andrea Omicini},
  doi          = {10.1016/j.knosys.2024.112940},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112940},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language models as oracles for instantiating ontologies with domain-specific knowledge},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spam email classification based on cybersecurity potential risk using natural language processing. <em>KBS</em>, <em>310</em>, 112939. (<a href='https://doi.org/10.1016/j.knosys.2024.112939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spam emails go beyond being merely annoying messages, they have become one of the most used vectors for cyberattacks such as stealing personal information or spreading malware. These breaches in cybersecurity lead to financial and data loss for individuals and organisations. Thus, the ability to differentiate potentially risky emails is crucial to launch earlier warnings and gain relevant information for cybersecurity experts. Recent works have proposed models to detect phishing, fraudulent or critical spam emails. However, their focus is often restricted to a particular email type or only evaluated on spam emails received by organisations. In this work, we propose a new set of 56 features extracted using Natural Language Processing (NLP) techniques and grouped into five categories: Headers , Text , Attachments , URLs , and Protocols . We build a dataset, Spam Email Risk Classification (SERC), divided into two sub-datasets: one collected from a private source and another from Bruce Guenter’s public corpus. To assess the potential risk of spam emails for users, we follow two strategies: a binary classification using low and high risk and a regression approach to predict the level of risk from 1 to 10. We evaluated three Machine Learning classifiers and three regression models. Random Forest obtains the highest classification performance with 0.914 of F1-Score on SERC and Random Forest Regressor achieves the lowest Mean Square Error (MSE) of 0.781 for regression. We also conduct an analysis of the feature importance in terms of each feature and group where those from the Headers and Text groups become more relevant.},
  archive      = {J_KBS},
  author       = {Francisco Jáñez-Martino and Rocío Alaiz-Rodríguez and Víctor González-Castro and Eduardo Fidalgo and Enrique Alegre},
  doi          = {10.1016/j.knosys.2024.112939},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112939},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spam email classification based on cybersecurity potential risk using natural language processing},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep maximum a posterior estimator for accelerated MRI reconstruction. <em>KBS</em>, <em>310</em>, 112938. (<a href='https://doi.org/10.1016/j.knosys.2024.112938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methodologies have demonstrated their efficacy in addressing MRI reconstruction from a collection of under-sampled measurements captured by multiple coils and yield reconstructions of exceptional quality. Since an acquired MRI volume is composed of many MRI slices, leveraging the correlation information between adjacent slices to assist in the reconstruction of the current slice is an intuitive idea. In this study, based on the maximum a posterior (MAP) estimation framework, we propose a novel MAP-based MRI reconstruction method called MAP-MRINet with adaptive spatial fusion and deep image prior. Specifically, we develop a novel observation model that considers the correlations among adjacent under-sampled slices, enabling integration of slice alignment and image reconstruction. Additionally, we split the image prior into high-frequency (HF) and low-frequency (LF) components based on the Framelet transform to provide more dedicated constraints. We unroll the proposed iterative MAP-based MRI reconstruction algorithm into a deep convolutional network. We conduct experiments on two publicly available real-world MRI datasets at various acceleration rates, and both qualitative and quantitative comparisons outperform current state-of-the-art single-slice and multi-slice reconstruction techniques. The experimental results validate the effectiveness and practicality of the proposed model.},
  archive      = {J_KBS},
  author       = {Tingting Wang and Shengcheng Ye and Faming Fang and Guixu Zhang and Yuanyi Zheng},
  doi          = {10.1016/j.knosys.2024.112938},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112938},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep maximum a posterior estimator for accelerated MRI reconstruction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with complete service commitment of data heterogeneity. <em>KBS</em>, <em>310</em>, 112937. (<a href='https://doi.org/10.1016/j.knosys.2024.112937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) systems grapple with data statistical heterogeneity, primarily manifested as non-iid label distribution skew and quantity skew. Label skew refers to the uneven distribution of labels across clients, while quantity skew pertains to disparities in the amount of data held by each client. Despite significant advancements, existing FL frameworks, many of which are open-source, have predominantly addressed label skew with limited success in managing quantity skew. This paper demonstrates through empirical evidence the incomplete commitment of data heterogeneity, leading to under performance due to unaddressed quantity skew. In response, we propose a novel taxonomy that distinguishes between “heterogeneity w ithout q uantity s kew” (WQS) and “heterogeneity a mplified by q uantity s kew” (AQS), the latter of which characterizes our complete service commitment. Our findings indicate how quantity skew can lead to a notable decline in model performance, particularly affecting clients with lesser data, and contribute to the redundancy effects in clients with abundant data, where the marginal utility of additional data diminishes. Furthermore, we introduce FedED, a theoretical framework that calculates effective data counts in a model-independent and loss-agnostic manner, integrating these counts into the server’s weighted aggregation process. This methodology, enhanced by an effective-sample-based client sampling strategy, significantly improves model performance by addressing both label and quantity skews concurrently. Extensive experiments validate that our approach outperforms existing methods and integrates seamlessly with current frameworks to elevate FL robustness further, thereby offering a holistic solution to the challenges posed by data heterogeneity in FL systems.},
  archive      = {J_KBS},
  author       = {Yizhi Zhou and Junxiao Wang and Yuchen Qin and Xiangyu Kong and Xin Xie and Heng Qi and Deze Zeng},
  doi          = {10.1016/j.knosys.2024.112937},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112937},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning with complete service commitment of data heterogeneity},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Irrelevant patch-masked autoencoders for enhancing vision transformers under limited data. <em>KBS</em>, <em>310</em>, 112936. (<a href='https://doi.org/10.1016/j.knosys.2024.112936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked Autoencoders (MAE) offer an effective solution for improving Vision Transformer (ViT) performance on data-limited tasks. While two-stage masking methods improve MAE by employing well-designed strategies to identify irrelevant patches, their reliance on separate training stages complicates both implementation and model optimization during the pre-training stage. To address this, we propose Irrelevant Patch-Masked Autoencoder (IP-MAE), which integrates a lightweight patch selection module directly into the MAE pre-training process. This module employs a class-specific feature alignment approach to extract relevant features, identifying irrelevant patches by comparing image patches to the extracted features. To further enhance the capture of class-specific features, we introduce a variance-weighting method that reduces the impact of irrelevant features on module optimization, complemented by a multi-scale technique for more effective weight adjustment. Extensive experiments demonstrate the effectiveness of our method, with IP-MAE achieving an 8.57% Top-1 accuracy improvement over ViTs and 1.77% over MAE on Tiny-ImageNet, demonstrating competitive performance with two-stage methods while requiring 16.28% fewer parameters. Visualizations further confirm its ability to effectively mask irrelevant patches, demonstrating its potential for data-limited tasks. Our code is available at: https://github.com/rqfzpy/IP-MAE .},
  archive      = {J_KBS},
  author       = {Qiang Ren and Junli Wang},
  doi          = {10.1016/j.knosys.2024.112936},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112936},
  shortjournal = {Knowl. Based Syst.},
  title        = {Irrelevant patch-masked autoencoders for enhancing vision transformers under limited data},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trigonometric feature learning for RGBD and RGBT image salient object detection. <em>KBS</em>, <em>310</em>, 112935. (<a href='https://doi.org/10.1016/j.knosys.2024.112935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-depth (RGBD) and RGB-thermal infrared (RGBT) images are integral to multi-modal salient object detection (SOD). Despite the impressive results of existing RGBD and RGBT SOD networks, two key areas remain in need of improvement. First, current methods rely heavily on feature fusion techniques, leading to overly complex and inflexible network architectures. Second, these methods lack a unified, adaptive strategy for combining features across different modalities or layers. To address these limitations, we propose a novel Trigonometric Feature Learning (TFL) strategy for generalized feature fusion in multi-modal SOD. Drawing inspiration from the trigonometric principles underlying vector operations, where the dot product of two vectors is the product of their magnitudes and the cosine of the angle between them, our TFL strategy maps features into graph space to compute the “cosine” mapping value for feature fusion. This cosine value dynamically adjusts based on feature attributes, enabling adaptive and effective fusion. To validate the TFL strategy, we design two network structures that use the TFL as the sole feature fusion mechanism for multi-modal SOD. Comparative evaluations against state-of-the-art methods demonstrate the strong performance of our networks, highlighting the unified and adaptive capabilities of the TFL strategy. The source code is available at https://github.com/huanglm-me/TFL-Net.git .},
  archive      = {J_KBS},
  author       = {Liming Huang and Aojun Gong},
  doi          = {10.1016/j.knosys.2024.112935},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112935},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trigonometric feature learning for RGBD and RGBT image salient object detection},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-oriented multi-scale heterogeneous community detection using weighted positives and debiased negatives. <em>KBS</em>, <em>310</em>, 112934. (<a href='https://doi.org/10.1016/j.knosys.2024.112934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection aims to identify groups of closely connected nodes in complex networks. While community detection methods for homogeneous networks are well-developed, they struggle with higher-order semantics and scalability in heterogeneous networks. Moreover, existing heterogeneous community detection approaches typically focus on node representations followed by clustering, often neglecting important community structure semantics and higher-order mate-path interaction semantics. Contrastive learning is an effective measure for community detection but is prone to introducing noise such as False Positives (FPs) and False Negatives (FNs), with prior work failing to address both issues simultaneously. To tackle these challenges, we propose a Community-oriented Multi-scale heterogeneous Community detection using Weighted positives and Debiased negatives (CMCWD) approach. This method constructs Node-Wise Heterogeneous information Modeling (NWHM) and Community-Wise Heterogeneous information Modeling (CWHM) using contrastive learning and supplemented with generative learning to emphasize structural information between nodes and avoid neglecting important community structures. Specifically, NWHM captures multi-scale local and higher-order meta-path interaction information from both a local topological view and a meta-path distillation view, considering both the independence and interactivity of meta-paths. Meanwhile, CWHM captures community structure semantics using Non-negative matrix factorization-based generative learning. Additionally, CMCWD introduces two denoising strategies – Robust Cross-view Weighted contrastive Mechanism (RCWM) and Community-Oriented Debiased contrastive Mechanism (CODM) – to simultaneously mitigate FPs and FNs in community detection. We conduct extensive experiments on six public datasets to validate the effectiveness of CMCWD. The results demonstrate that CMCWD outperforms other mainstream methods, achieving a 9.98% higher NMI compared to the second-best unsupervised method on the AMINER, underscoring its effectiveness.},
  archive      = {J_KBS},
  author       = {Fangfang Liu and Chunjie Li and Bo Wu},
  doi          = {10.1016/j.knosys.2024.112934},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112934},
  shortjournal = {Knowl. Based Syst.},
  title        = {Community-oriented multi-scale heterogeneous community detection using weighted positives and debiased negatives},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context based spatial–temporal graph convolutional networks for traffic prediction. <em>KBS</em>, <em>310</em>, 112933. (<a href='https://doi.org/10.1016/j.knosys.2024.112933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting plays an important role in traffic management and travel planning. Inspired by natural language processing, this paper analogizes traffic sensors to words and traffic features of sensor data to word meanings. Traffic conditions upstream and downstream of a chokepoint affect its flow, similar to how context influences the meaning of utterances. Based on this analogy, this paper constructs a road semantic graph and proposes a context-based spatio-temporal graph convolutional network (CSTGCN) model for traffic prediction. Firstly, this paper introduces Dynamic Time Warping (DTW) to calculate the similarity of traffic features of nodes, constructs a road semantic graph, and mines and utilizes the implicit information in similar traffic patterns. Secondly, based on the road semantic graph, we build an adaptive spatio-temporal Graph Attention Network (GAT) component. The component designs an adaptive function to extract the changing spatial features, which realizes the dynamic capture of multi-order neighborhood spatial features in different periods. In addition, we designed a geo-semantic fusion module based on a convolutional neural network (GS-CNN). This module combines the real-time traffic of sensors and realizes the multi-dimensional dynamic fusion of spatio-temporal features by assigning weights to different features. Experiments show that CSTGCN can deeply mine the spatio-temporal correlation of sensors in the road network, and the model has a more obvious accuracy improvement in traffic prediction performance compared with the current baseline method.},
  archive      = {J_KBS},
  author       = {Chaolong Jia and Wenjing Zhang and Yumei He and Rong Wang and Jinchao Li and Yunpeng Xiao},
  doi          = {10.1016/j.knosys.2024.112933},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112933},
  shortjournal = {Knowl. Based Syst.},
  title        = {Context based spatial–temporal graph convolutional networks for traffic prediction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representations aligned counterfactual domain learning for open-set fault diagnosis under speed transient conditions. <em>KBS</em>, <em>310</em>, 112932. (<a href='https://doi.org/10.1016/j.knosys.2024.112932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity and high integration of industrial equipment pose new challenges to the reliable operation and maintenance of intelligent fault diagnosis technology. Open-ended real-world data suggests that health state identification of intelligent diagnosis is at high risk from unknown classes and domain shifts of continuous variation. Thus in addition to generalizing from known instances under variable conditions for classification, fault diagnosis has to be capable of acknowledging the novelty of the unseen. This paper develops a Transformer of Counterfactual Domain Learning (TCDL) for open set recognition of rotating machinery under speed transient conditions. The proposed model enforces the alignment of the learned representations for extracting domain invariant features. Meanwhile, feature augmentation is employed to learn more robust representations and thus can be applied with few samples. To achieve open set recognition, we construct counterfactual domains upon the factual domains of closed-set features. By maximizing the inter-class separation between factual and counterfactual, the TCDL is prompted to learn compact class reception regions whereas rejecting the novel. The superiority of the TCDL is verified in two cases of the laboratory fault simulation and industrial high-speed trains (HST) with the F1 Score over 94 % and 96 %.},
  archive      = {J_KBS},
  author       = {Shen Liu and Jinglong Chen and Zhen Shi and Liuyang Song and Shuilong He},
  doi          = {10.1016/j.knosys.2024.112932},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112932},
  shortjournal = {Knowl. Based Syst.},
  title        = {Representations aligned counterfactual domain learning for open-set fault diagnosis under speed transient conditions},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-aware reasoning network for document-level relation extraction with co-regularization loss. <em>KBS</em>, <em>310</em>, 112931. (<a href='https://doi.org/10.1016/j.knosys.2024.112931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to identify complicated relations among entity pairs in a document. It is challenging as a document usually has multiple entity pairs, and the two entities within a pair may also be scattered in a document with different entity-specific labels, even over a long distance. Existing works usually focus on extracting crucial evidence sentences as a concise clue for relation inference. However, they suffer from two limitations: (1) indiscriminately utilizing all words in the sentences for relation inference may inevitably introduce noise problems (e.g., unrelated chunks/clauses involved), thus incurring a decline in performance. (2) they do not consider the noisy labeling phenomenon, as there exists a considerable amount of unlabeled instances in the DocRE scenario. To address the above issues, we propose a novel approach, named P ath- A ware R easoning N etwork (PARN) for DocRE. Specifically, PARN explicitly models the shortest inferring paths for each given entity pair over a word-level constructed document graph, and then incorporates a path-aware constraint into the self-attention mechanism, thereby directing the model’s attention towards the crucial segments along these paths. Furthermore, a co-regularization loss is also proposed to alleviate the intrinsic noisy labeling problem, which increases the prediction consistency of the output. Extensive experiments on three DocRE datasets demonstrate the superiority of the proposed model, as compared to previous state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yuan Yin and Xuhua Ai and Yiting Yu and Xiaoye Qu and Wei Wei},
  doi          = {10.1016/j.knosys.2024.112931},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112931},
  shortjournal = {Knowl. Based Syst.},
  title        = {Path-aware reasoning network for document-level relation extraction with co-regularization loss},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing multi-object tracking through occlusion-awareness and trajectory optimization. <em>KBS</em>, <em>310</em>, 112930. (<a href='https://doi.org/10.1016/j.knosys.2024.112930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The essence of multiple-object tracking lies in assigning a unique identity to each target. In recent years, most methods have made some progress in the study of complex scenarios. However, frequent occlusions pose significant challenges to maintaining the continuity of target identities. We believe that treating mutually occluded targets separately is an effective solution to the occlusion problem. In this study, in order to distinguish mutually occluded targets, we first devised a method for obtaining the relative spatial relationship between targets from the detection results. Subsequently, utilizing this cue, we propose an association method for targets separated according to spatial relationships. When a target is not currently occluded, it is prioritized to enter data association and pick a trajectory. The occluded targets then wait for all the previous targets to be matched to enter the matching process. Finally, we develop a method for determining and recovering trajectories lost due to occlusion, which further enhances the stable tracking capability of our method in the face of occlusion. Our approach offers a perspective on disentangling occluded targets and association schemes. Experimental results demonstrate a substantial improvement in tracking accuracy. Our method achieves state-of-the-art performance across multiple datasets, including MOT16, MOT17, MOT20, and DanceTrack.},
  archive      = {J_KBS},
  author       = {Mengzhen Li and Yukuan Zhang and Yunhua Jia and Yang Yang},
  doi          = {10.1016/j.knosys.2024.112930},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112930},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing multi-object tracking through occlusion-awareness and trajectory optimization},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning based automated vein recognition using swin transformer and super graph glue model. <em>KBS</em>, <em>310</em>, 112929. (<a href='https://doi.org/10.1016/j.knosys.2024.112929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein recognition is a secure and emerging biometric modality, including applications from automated portals at immigration checkpoints to most contributive amenities like pay-by-finger and accessing PC. Its reliability makes it integral in embedded systems, including ATMs and access control systems. Despite recent breakthroughs in finger vein verification, current methods are completely reliant on domain expertise and lack the scalability required to identify finger vein features from raw photos. The swin transformer (SwinT) and the super graph glue model are used in this study to develop a deep learning-based automatic vein recognition solution. The finger vein images were initially gathered from three publicly available datasets: the finger vein dataset, Published_database_FV_USM, and HKPU dataset. Then, pre-processing is applied based on the determined quality of data from the dataset. The extended rolling guidance filter (ExRoLL) is used for filtering, and the contrast-limited adaptive histogram equalization (CLAHE) approach is used for contrast enhancement. The osprey depthwise separable swin transformer model (ODSwiT) was then utilized to extract features such as Mean, Contrast, Energy, Smoothness, and vein pattern. The osprey optimization algorithm (OspA) was utilized to optimize the network model's hyperparameters. Finally, using the super graph glue (SGG) model, match the retrieved features from both training and testing. By matching the traits, the suggested technique determines whether the user is a real individual or an imposter. The suggested model has a high accuracy of 0.98113 % for finger vein, 0.99085 % for Published_database_FV_USM, and 0.984 % for HKPU Dataset when compared to current models.},
  archive      = {J_KBS},
  author       = {Kavi Bhushan and Surendra Singh and Kamal Kumar and Parveen Kumar},
  doi          = {10.1016/j.knosys.2024.112929},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112929},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning based automated vein recognition using swin transformer and super graph glue model},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based graph clustering network with dual information interaction. <em>KBS</em>, <em>310</em>, 112928. (<a href='https://doi.org/10.1016/j.knosys.2024.112928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of attributed graph clustering has garnered increasing attention, particularly with the advent of graph convolutional network (GCN), which have deepened our understanding of learning both attribute and structural information in graphs. Existing graph deep embedding clustering methods typically learn attribute or structural information alone, or integrate attribute information into a learning network for structural information. However, these methods fail to fully integrate the available information. Therefore, we propose a novel deep attributed graph clustering method named A ttention-based Graph Clustering N etwork with D ual I nformation I nteraction (ADIIN). Specifically, an attention-based interaction fusion module is presented to adaptively incorporate two types of information and propagate the fused information to both networks interactively. Additionally, it can adjustively integrate information from each hidden layer at different scales based on attentional mechanisms. Furthermore, we design a more robust quadruple joint self-supervision strategy to align node attribute representation, linear fusion representation, and multi-scale feature fusion representation, thereby enhancing the clustering performance of the entire model. Extensive experiments conducted on several benchmark datasets demonstrate that our proposed method outperforms state-of-the-art deep clustering methods. Our code is publicly available at https://github.com/sliboo/ADIIN .},
  archive      = {J_KBS},
  author       = {Xiumin Lin and Yafang Li and Caiyan Jia and Baokai Zu and Wanting Zhu},
  doi          = {10.1016/j.knosys.2024.112928},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112928},
  shortjournal = {Knowl. Based Syst.},
  title        = {Attention-based graph clustering network with dual information interaction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangle representation learning with excluding confounding bias for causal effect estimation. <em>KBS</em>, <em>310</em>, 112926. (<a href='https://doi.org/10.1016/j.knosys.2024.112926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal effect estimation aims to discover the impact of treatments on effects from observational data. Existing approaches suffer from effectively overcoming confounding bias, in which the core challenge is to disentangle confounders from treatment and effect variables simultaneously. To this end, we propose a novel D isentangle R epresentation L earning approach with E xcluding C onfounding B ias mechanism ( DRL ECB ) for causal effect estimation with the three-fold ideas: (1) Disentangling treatment variables into instrumental, confounders and risk factors by maximizing and minimizing mutual information (MI); (2) Balancing confounding representations to eliminate confounding bias by reweighting on treatment and control groups; (3) Constructing outcome regression networks with confounding and risk representations to predict outcomes and summarizing the total loss to estimate causal effects. We conducted extensive experiments on benchmark and synthetic datasets. The results demonstrate that DRL ECB performs significantly better than its rivals. The code is open-source and publicly available at https://github.com/youdianlong/DRLECB .},
  archive      = {J_KBS},
  author       = {Dianlong You and Dongyan Wang and Bingxin Liu and Xiaoyi Ge and Di Wu and Xindong Wu},
  doi          = {10.1016/j.knosys.2024.112926},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112926},
  shortjournal = {Knowl. Based Syst.},
  title        = {Disentangle representation learning with excluding confounding bias for causal effect estimation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-relation learning network for audio-visual event localization. <em>KBS</em>, <em>310</em>, 112925. (<a href='https://doi.org/10.1016/j.knosys.2024.112925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In audio-visual event localization task, mining the rich relations within the video is essential for accurate event localization. However, the visual relations between visual entities (i.e. objects and regions) are ignored by existing methods. In addition, existing models usually create two modality-specific streams to process the intra- and cross-modal relations for audio and visual features. Unfortunately, such a dual-stream architecture may exist parameter redundancy. Furthermore, the inherent temporal continuity relation between successive event segments is not explored by existing methods. To address these issues and improve event localization accuracy, we propose a Multi-Relation Learning Network (MRLN) that effectively mines visual relations, intra- and cross-modal relations, and temporal continuity relations. Specifically, we propose an audio-conditioned graph attention to dynamically capture the audio-related visual relations for the visual-level relation learning. To reduce the parameter redundancy when learning the intra- and cross-modal relations, a coupled modalities and relations encoder (CMRE) with a lightweight single-stream structure is introduced, where the audio-visual modalities and the intra- and cross-modal relations are synchronously processed by performing parameter-shared attention. For arbitrary adjacent event segments, we propose a novel continuity loss to simulate their continuity relations, which improves the consistency of successive event segments. Moreover, MRLN is a robust framework that can be applied to dual-grained visual entities: the fine-grained object overlooked by existing works and the coarse-grained regions. Extensive experiments on benchmark datasets demonstrate the effectiveness of our method. Compared to recent state-of-the-art (SOTA) models, our method achieves the new SOTA performance while possessing significantly fewer trainable parameters.},
  archive      = {J_KBS},
  author       = {Pufen Zhang and Jiaxiang Wang and Meng Wan and Sijie Chang and Lianhong Ding and Peng Shi},
  doi          = {10.1016/j.knosys.2024.112925},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112925},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-relation learning network for audio-visual event localization},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retinopathy identification in optical coherence tomography images based on a novel class-aware contrastive learning approach. <em>KBS</em>, <em>310</em>, 112924. (<a href='https://doi.org/10.1016/j.knosys.2024.112924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision technology has played a significant role in the advancement of retinal disease detection based on optical coherence tomography (OCT) images; however, it typically relies on large, labeled datasets that may be scarce. Detecting retinal diseases presents specific challenges, such as the need for accurate differentiation between various subtle disease features, and the requirement for extensive labeled data, which is often difficult and expensive to obtain. Additionally, manual annotation of retinal images is labor-intensive and prone to human error. Semi-supervised learning, particularly via pseudo-labeling, is promising for utilizing unlabeled data; however, it is not always resistant to confirmation bias. To address this issue, we propose a novel semi-supervised learning (SSL) approach that combines class-aware contrastive learning with FixMatch, enhancing the robustness and precision of retinal disease recognition using minimal labeled data. Unlike traditional instance-level contrastive methods, we developed a class-aware contrast method to refine disease differentiation. To prioritize reliable data and reduce overfitting to incorrect pseudo-labels, we constructed a selection matrix from out-of-distribution data and reweighted the predictions based on prediction scores, effectively mitigating confirmation bias. Furthermore, we propose the use of supervised contrastive loss to understand subtle diseases. Our proposed method outperformed existing approaches, with classification accuracies of over 0.955 and AUC values of 0.996 on three widely used OCT datasets. Remarkably, the proposed method matched the expert performance with only 80 labeled images and surpassed most experts with 160 images. Our source code is available at: https://github.com/HappyCloud555/OCT .},
  archive      = {J_KBS},
  author       = {Yuan Li and Chenxi Huang and Bowen Zheng and Zhiyuan Zheng and Hongying Tang and Shenghong Ju and Jun Xu and Yuemei Luo},
  doi          = {10.1016/j.knosys.2024.112924},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112924},
  shortjournal = {Knowl. Based Syst.},
  title        = {Retinopathy identification in optical coherence tomography images based on a novel class-aware contrastive learning approach},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical selection of hidden parameters through expanded enhancement matrix stability for functional-link neural networks and broad learning systems. <em>KBS</em>, <em>310</em>, 112923. (<a href='https://doi.org/10.1016/j.knosys.2024.112923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional-link neural network(FLNN) and its recent advancement, i.e ., broad learning system(BLS), share the same mathematical essence in terms of the analytical solution to the parameters in their respective output layers. However, their performance often depends on an excessive number of enhancement nodes and the randomly assigned hidden parameters. This actually triggers a serious challenge: how to effectively select randomly assigned hidden parameters from the available candidates to simultaneously guarantee stronger generalization capability and fast training speed. In this study, we introduce the new concept of expanded enhancement matrix stability (EEMS) to address this challenge and identify the crucial factor for fast training in FLNN and BLS. We theoretically reveal the relationship between EEMS and the generalization capabilities of FLNN and BLS, in terms of the upper bounds of both the generalization error and the variance of cross-validation loss. Following this, we derive analytical (and hence fast) hidden parameter selection algorithms—EEMS-r and EEMS-cv—for both FLNN and BLS, based on EEMS with respect to the generalization error and the variance of cross-validation loss. Experimental results on 14 benchmarking datasets demonstrate the effectiveness of the proposed algorithms EEMS-r and EEMS-cv on most of the adopted datasets in enhancing generalization performance and reveal that a downsized structure of BLS may be empirically preset, in contrast to the standard BLS.},
  archive      = {J_KBS},
  author       = {Yuchen Li and Chi-Man Vong and C.L. Phillip Chen and Shitong Wang},
  doi          = {10.1016/j.knosys.2024.112923},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112923},
  shortjournal = {Knowl. Based Syst.},
  title        = {Analytical selection of hidden parameters through expanded enhancement matrix stability for functional-link neural networks and broad learning systems},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early-stage detection of cognitive impairment by hybrid quantum-classical algorithm using resting-state functional MRI time-series. <em>KBS</em>, <em>310</em>, 112922. (<a href='https://doi.org/10.1016/j.knosys.2024.112922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following recent developments in quantum machine learning techniques, several algorithms have been developed for disease detection. This study explored the application of a hybrid quantum-classical algorithm for classifying region-of-interest time-series data obtained from resting-state functional magnetic resonance imaging (fMRI) in patients with early-stage cognitive impairment. Classical one-dimensional convolutional layers were used in conjunction with quantum convolutional neural networks in our hybrid algorithm. In a classical simulation, the proposed hybrid algorithms in our study exhibited higher balanced accuracies than classical convolutional neural networks under similar training conditions. In addition, in our study, among the 116 brain regions, two brain regions (the right hippocampus and left parahippocampus) that showed relatively higher classification performance in the proposed algorithm were confirmed. The associations of the two selected regions with cognitive decline, as found in previous studies, were validated using seed-based functional connectivity analysis. Thus, we confirmed both improvement in model performance with the quantum convolutional neural network and neuroscientific validity of brain regions from our hybrid quantum-classical model.},
  archive      = {J_KBS},
  author       = {Junggu Choi and Tak Hur and Daniel K. Park and Na-Young Shin and Seung-Koo Lee and Hakbae Lee and Sanghoon Han},
  doi          = {10.1016/j.knosys.2024.112922},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112922},
  shortjournal = {Knowl. Based Syst.},
  title        = {Early-stage detection of cognitive impairment by hybrid quantum-classical algorithm using resting-state functional MRI time-series},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor self-representation network for subspace clustering via alternating direction method of multipliers. <em>KBS</em>, <em>310</em>, 112921. (<a href='https://doi.org/10.1016/j.knosys.2024.112921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep subspace clustering methods based on data self-representation have become highly popular owing to their ability to automatically discover more suitable feature spaces. However, many existing subspace clustering methods meet matrix-based self-expressiveness requirements by directly converting the feature tensor into a matrix. This approach results in a loss of spatial structure information inherent in the tensor. To overcome this problem, we propose the tensor self-representation network (TSRN). TSRN introduces the tensor mode-d product to apply matrix-based self-expressiveness to the tensor, thereby preserving the spatial information of the feature tensor. This method fully utilizes the channel, height and width information within the feature tensor, resulting in a self-expressive coefficient matrix that is more suitable for clustering. To capture the intrinsic representation in the low-dimensional space, we impose low-rank constraints in each mode. This results in a deeper network, thereby increasing the difficulty of training. To optimize TSRN effectively, we introduce auxiliary variables and leverage the alternating direction method of multipliers (ADMM) to decompose the problem into two more manageable subproblems. This enables us to obtain a deep low-rank representation by efficiently training a shallower network. TSRN outperforms other traditional and deep subspace clustering methods on several benchmark datasets. Notably, on the COIL20 dataset, TSRN achieves an accuracy of 100%, demonstrating its effectiveness. Ablation studies report that the application of the tensor mode-d product is effective to obtain a good representation of the data and that ADMM is well suited for optimizing the variable coupling problem brought by the tensor mode-d product.},
  archive      = {J_KBS},
  author       = {Ming Chen and Kailing Guo and Xiangmin Xu},
  doi          = {10.1016/j.knosys.2024.112921},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112921},
  shortjournal = {Knowl. Based Syst.},
  title        = {Tensor self-representation network for subspace clustering via alternating direction method of multipliers},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLIP-guided continual novel class discovery. <em>KBS</em>, <em>310</em>, 112920. (<a href='https://doi.org/10.1016/j.knosys.2024.112920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Novel Class Discovery (CNCD) aims to adapt a trained classification model to a new task while maintaining its performance on the old task. This presents two main challenges: (1) unsupervised learning of new tasks and (2) avoiding forgetting old classes when previous data is unavailable. Some prior works use task IDs to identify old and novel classes for parameter isolation, while others waive the requirement of task IDs by combining novel class discovery and old knowledge preservation into a single training process. However, this often leads to interference with feature space and presents difficulties in balancing old and new knowledge. This work proposes a method that does not require task IDs and argues that decoupling the training process is beneficial. We find that a simple semi-supervised learning strategy with prototype adaptation can unleash the strong generalization ability of the CLIP model to a small CNCD model for novel class discovery. However, this operation may deteriorate the performance of old classes. To address this issue, CutMix is utilized to improve the network’s representation and preserve old knowledge. Compared to the baseline method, our method not only surpasses it on the novel classes to a significant margin (33.1% on the TinyImageNet) but also exhibits more accurate prediction on old classes (2.9% on the TinyImageNet). These advantages are further boosted when multiple novel class discovery steps are required ( 31 . 2 % → 56 . 1 % on the TinyImageNet regarding the overall performance). Code will be made available.},
  archive      = {J_KBS},
  author       = {Qingsen Yan and Yiting Yang and Yutong Dai and Xing Zhang and Katarzyna Wiltos and Marcin Woźniak and Wei Dong and Yanning Zhang},
  doi          = {10.1016/j.knosys.2024.112920},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112920},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLIP-guided continual novel class discovery},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TJMN: Target-enhanced joint meta network with contrastive learning for cross-domain recommendation. <em>KBS</em>, <em>310</em>, 112919. (<a href='https://doi.org/10.1016/j.knosys.2024.112919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation (CDR) provides a promising solution to mitigate the sparsity issue in the target domain by exploiting auxiliary information from the source domain. Recently, meta learning based methods have been proposed and achieved the state-of-the-art performance. However, these methods learn the transfer bridge solely relying on the source domain while the rich information from the target domain are ignored. Moreover, they leverage either a common transfer bridge or a personalized transfer bridge to transform user representations, without considering the multi-grained characteristics of user preference. In this paper, we propose a target-enhanced joint meta network with contrastive learning (JTMN) for cross-domain recommendation. To be specific, we develop a target bridge to incorporate information from the target domain to guide the learning process of user preference transfer. In addition, we introduce multi-grained transfer bridges to model the complex transfer patterns of user preference across different domains. At last, a target-aware contrastive learning layer is designed to obtain better user representations. The experimental results on six CDR tasks demonstrate that our proposed TJMN model significantly outperforms all strong baselines, especially when the training data become more sparse.},
  archive      = {J_KBS},
  author       = {Xiaofei Zhu and Lele Duan and Stefan Dietze and Ran Yu},
  doi          = {10.1016/j.knosys.2024.112919},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112919},
  shortjournal = {Knowl. Based Syst.},
  title        = {TJMN: Target-enhanced joint meta network with contrastive learning for cross-domain recommendation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to discover anomalous spatiotemporal trajectory via open-world state space model. <em>KBS</em>, <em>310</em>, 112918. (<a href='https://doi.org/10.1016/j.knosys.2024.112918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying anomalous trajectories that deviate from usual driving patterns in an open-world context has recently become a critical and urgent task in location-aware systems. In contrast to the closed-world settings, its goal is to not only identify known but also detect the presence of unknown anomalous behaviors. Despite the achievements of recent self-motivated learning paradigms, existing solutions either do not have the ability to discover unknown anomalous behaviors or can only expose their presence. In this study, we first formally define our task as the Anomalous Trajectory Discovery problem in an Open-world scenario (ATDO), and introduce a novel fine-grained O pen-world S tate S pace L earning ( OSSL ) framework that has the ability to discover multiple unknown patterns in addition to classifying the existing known behavioral patterns of trajectories. Due to the inherent density behind massive trajectories, we are motivated by state space models and devise a Spatial–temporal State Space (S3) block to explore the long-term dependencies behind the lengthy trajectories. To enable open-world learning, we devise two adapters that operate interactively with three open-world objectives to discover multiple unknown patterns in addition to identifying existing behaviors. With the context setting of two progressive open-world tasks, the experimental results conducted on two large trajectory datasets demonstrate the superiority of OSSL for both known and unknown anomalous patterns.},
  archive      = {J_KBS},
  author       = {Qiang Gao and Chaoran Liu and Li Huang and Goce Trajcevski and Qing Guo and Fan Zhou},
  doi          = {10.1016/j.knosys.2024.112918},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112918},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to discover anomalous spatiotemporal trajectory via open-world state space model},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-enhanced time series data imputation with long-term dependency diffusion models. <em>KBS</em>, <em>310</em>, 112917. (<a href='https://doi.org/10.1016/j.knosys.2024.112917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imputation is crucial for addressing challenges posed by missing values in multivariate time series data across various fields, such as healthcare, traffic, and economics, and has garnered significant attention. Among various methods, diffusion model-based approaches show notable performance improvements. However, existing methods often cause disharmonious boundaries between missing and known regions and overlook long-range dependencies in missing data estimation, leading to suboptimal results. To address these issues, we propose a Diffusion-based time Series Data Imputation (DSDI) framework. We develop a weight-reducing injection strategy that incorporates the predicted values of missing points with reducing weights into the reverse diffusion process to mitigate boundary inconsistencies. Further, we introduce a multi-scale S4-based U-Net, which combines hierarchical information from different levels via multi-resolution integration to capture long-term dependencies. Experimental results demonstrate that our model outperforms existing imputation methods.},
  archive      = {J_KBS},
  author       = {Chunjing Xiao and Xue Jiang and Xianghe Du and Wei Yang and Wei Lu and Xiaomin Wang and Kevin Chetty},
  doi          = {10.1016/j.knosys.2024.112917},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112917},
  shortjournal = {Knowl. Based Syst.},
  title        = {Boundary-enhanced time series data imputation with long-term dependency diffusion models},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-precision malware detection in android apps using quantum explainable hierarchical interaction network. <em>KBS</em>, <em>310</em>, 112916. (<a href='https://doi.org/10.1016/j.knosys.2024.112916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of Android applications has increased the prevalence of fraudulent and malicious apps, posing significant risks to user security and privacy. Existing detection methodologies often struggle with poor interpretability, scalability, and computational complexity, limiting their effectiveness. To address these challenges, this study introduces the Quantum Explainable Hierarchical Interaction Network (QEHIN), a novel framework designed to detect real and fake Android applications with superior accuracy and interpretability. QEHIN incorporates quantum computing principles such as superposition and entanglement to model high-order feature interactions effectively. Its innovative architecture includes a Quantum Embedding Layer for transforming input features into quantum states, a Quantum Hierarchical Interaction Network (QHIN) for capturing complex dependencies, a Quantum Deep Neural Network (QDNN) for enhanced feature processing, and a Quantum Cross-Hierarchical Unit (QCHU) to ensure seamless integration across hierarchical levels. This design achieves precise, transparent, and scalable detection of malicious applications, addressing the shortcomings of traditional methods. Evaluation on the Google Play Store Reviews, MobileRec, and Android-App-Recommendation datasets demonstrates the novelty and effectiveness of QEHIN. It achieves an accuracy of 98.86 %, precision of 98.78 %, recall of 98.82 %, and a kappa score of 98.54 %, significantly outperforming existing approaches.},
  archive      = {J_KBS},
  author       = {Ramnath Muthusamy and Yesubai Rubavathi Charles},
  doi          = {10.1016/j.knosys.2024.112916},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112916},
  shortjournal = {Knowl. Based Syst.},
  title        = {High-precision malware detection in android apps using quantum explainable hierarchical interaction network},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized network with domain invariance and specificity representation for bearing remaining useful life prediction under unknown conditions. <em>KBS</em>, <em>310</em>, 112915. (<a href='https://doi.org/10.1016/j.knosys.2024.112915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The requirement to satisfy the assumption of identically and independently distributed data limits the practical application of traditional remaining useful life (RUL) prediction methods. In domain generalization methods, data augmentation and domain-invariant representations face the challenges of maintaining sequence consistency for long time-series data and prognosticating RUL under unknown operating conditions. A novel generalized network with invariance and specificity representation is proposed to address these issues. First, the run-to-failure bearing data were divided into healthy and degraded stages. Next, the time-vector quantized variational autoencoder network generates diverse data from the degradation stage. Subsequently, the domain invariant and domain-specific feature representation network (DIDSR) is proposed for cross-condition prediction of rolling bearing RUL. The DIDSR network is divided into two parts: the domain-invariant component and the domain-specific component. The former extracts shared features from multiple source domains, while the latter learns the characteristics of each source domain through a domain classifier and weights them to obtain the final prediction. Ultimately, the proposed method is extensively evaluated on two bearing run-to-failure datasets. Comparative and ablation experiments validate the effectiveness and superiority of the approach.},
  archive      = {J_KBS},
  author       = {Qing Zheng and Pengtao Teng and Kai Zhang and Guofu Ding and Xuwei Lai and Zhixuan Li and Zhaocheng Yuan},
  doi          = {10.1016/j.knosys.2024.112915},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112915},
  shortjournal = {Knowl. Based Syst.},
  title        = {A generalized network with domain invariance and specificity representation for bearing remaining useful life prediction under unknown conditions},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-based IR-system for bank supervisors. <em>KBS</em>, <em>310</em>, 112914. (<a href='https://doi.org/10.1016/j.knosys.2024.112914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bank supervisors face the complex task of ensuring that new measures are consistently aligned with historical precedents. To address this challenge, we introduce a novel Information Retrieval (IR) System tailored to assist supervisors in drafting both consistent and effective measures. This system ingests findings from on-site investigations. It then retrieves the most relevant historical findings and their associated measures from a comprehensive database, providing a solid basis for supervisors to write well-informed measures for new findings. Utilizing a blend of lexical, semantic, and Capital Requirements Regulation (CRR) fuzzy set matching techniques, the IR system ensures the retrieval of findings that closely align with current cases. The performance of this system, particularly in scenarios with partially labeled data, is validated through a Monte Carlo methodology, showcasing its robustness and accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for fine-tuning, the final model achieves a Mean Average Precision (MAP@100) of 0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those of both standalone lexical models such as BM25 and semantic BERT-like models.},
  archive      = {J_KBS},
  author       = {Ilias Aarab},
  doi          = {10.1016/j.knosys.2024.112914},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112914},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-based IR-system for bank supervisors},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-enhanced framework for medical image report generation using multimodal contexts. <em>KBS</em>, <em>310</em>, 112913. (<a href='https://doi.org/10.1016/j.knosys.2024.112913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep learning technology continues to advance, including large language models and multimodal models, its application in the medical field has become a widely recognized research topic. In this context, a series of automated systems based on deep learning have been developed, aiming to generate corresponding text reports from medical images. However, these current methods often generate text reports solely based on patients’ images, overlooking the multimodal medical context, which encompasses various factors such as clinical information, diagnostic results, and medical knowledge. This limitation restricts the clinical application of automatically generated reports. To address this issue, we propose a novel Context-Enhanced Framework for medical image report generation. Our approach integrates various multimodal contextual elements, including but not limited to clinical text, medical knowledge, diagnostic results, and image data, to enrich the report generation process. We evaluated this framework on two public chest X-ray datasets, IU-Xray and MIMIC-CXR, using standard natural language generation and clinical effectiveness metrics. The results showed state-of-the-art performance, indicating improved quality in language and clinical accuracy. Our source code is available here .},
  archive      = {J_KBS},
  author       = {Hongzhao Li and Hongyu Wang and Xia Sun and Hua He and Jun Feng},
  doi          = {10.1016/j.knosys.2024.112913},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112913},
  shortjournal = {Knowl. Based Syst.},
  title        = {Context-enhanced framework for medical image report generation using multimodal contexts},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProxyMatting: Transformer-based image matting via region proxy. <em>KBS</em>, <em>310</em>, 112911. (<a href='https://doi.org/10.1016/j.knosys.2024.112911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate image matting requires an in-depth exploration of both the contextual information and the fine-grained details within input images. To this end, recent advancements in transformer-based matting incorporate three context tokens (triple-token), which are the representations of the three trimap regions, into the transformer structure. However, the triple-token, constrained by its limited information capacity, might not adequately capture the global context within the image, particularly for high-resolution inputs. In this paper, we introduce a transformer-based image matting model named ProxyMatting, which efficiently addresses the aforementioned issues by integrating context into the transformer block through the Region Proxies. The region proxies are the representation of predefined-sized regions but differ from the triple-token in two aspects: (1) Region proxies offer enriched contextual information, as the number of generated proxies (context tokens) scales proportionally with the resolution of the feature map. (2) Each proxy is responsible for gathering the necessary contextual information for its designated region and delivering it exclusively to the spatial tokens within that region. ProxyMatting benefits from incorporating region proxies, enabling each spatial token to efficiently extract contextual information from its corresponding proxy token. By restricting each spatial token to query from only one proxy token, ProxyMatting maintains computational efficiency compared to triple-token approaches. Experiments show that ProxyMatting demonstrates outstanding performance across standard matting datasets.},
  archive      = {J_KBS},
  author       = {Jide Li and Kequan Yang and Yuanchen Wu and Xichen Ye and Hanqi Yang and Xiaoqiang Li},
  doi          = {10.1016/j.knosys.2024.112911},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112911},
  shortjournal = {Knowl. Based Syst.},
  title        = {ProxyMatting: Transformer-based image matting via region proxy},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scenario potentiality-constrain network for RGB-D salient object detection. <em>KBS</em>, <em>310</em>, 112910. (<a href='https://doi.org/10.1016/j.knosys.2024.112910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The salient object detection network transitions from 2D to 3D by incorporating depth information, aiming to identify the most attractive object in a pair of RGB-D images. Current detection methods rely heavily on the model’s ability to adapt non-linearly to multi-modal inputs, creating a bottleneck. This limitation could be optimized by establishing an objective mechanism for evaluating scenario representation and dynamically enhancing the contribution of high-quality modalities in the prediction process. To this end, we propose a novel network, SPCNet, which constructs depth-potential pseudo-labels through pixel sampling and array discretization judgments, train the model’s ability to evaluate depth quality based on objective criteria, and dynamically adjust the weight of high-quality information. These operations are executed within a cross-pixel depth-potential measurement unit and a scenario potentiality-constrain module. Additionally, to mitigate redundant information interference, a multi-modal feature refinement module is proposed to generate high-level global descriptors by calibrating single-modal information and fostering cross-modal information interaction, which refine the low-level single-modal features for subsequent fusion and inference. Qualitative and quantitative results demonstrate that our model outperforms 20 state-of-the-art models across six evaluation metrics on six publicly available datasets. The code and prediction results have been published in https://github.com/guanyuzong/SPC .},
  archive      = {J_KBS},
  author       = {Guanyu Zong and Xu Li and Qimin Xu},
  doi          = {10.1016/j.knosys.2024.112910},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112910},
  shortjournal = {Knowl. Based Syst.},
  title        = {Scenario potentiality-constrain network for RGB-D salient object detection},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trans-SAM: Transfer segment anything model to medical image segmentation with parameter-efficient fine-tuning. <em>KBS</em>, <em>310</em>, 112909. (<a href='https://doi.org/10.1016/j.knosys.2024.112909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Segment Anything Model (SAM) has gained substantial attention in image segmentation due to its remarkable performance. It has demonstrated impressive zero-shot capabilities through interactive segmentation. However, due to the predominance of natural images in the training data, it often exhibits unsatisfactory performance when directly applied to medical image segmentation tasks. Training SAM from scratch in the medical domain is computationally resource-intensive and data-demanding. Additionally, when fine-tuning pre-trained SAM, the limited quantity of medical data will potentially lead to catastrophic forgetting. To address these issues, we proposed Trans-SAM, which utilizes Parameter-Efficient Fine-Tuning (PEFT) to transfer SAM into the medical image segmentation. The key novelties include the Intuitive Perceptual Fine-tuning (IPF) adapter, which directly integrates input image features into each layer of the encoder, and the Multi-scale Domain Transfer (MDT) adapter, a convolution-based mechanism designed to infuse inductive biases into the SAM. With our method, the general features extracted by pre-trained SAM can be better transferred to the medical domain. Moreover, our method can achieve satisfactory performance with a minimal amount of data during the fine-tuning. We conducted extensive evaluations on six medical datasets including different organs and modalities. The experimental results demonstrate that Trans-SAM shows superior performance compared to state-of-the-art PEFT methods. It significantly improves the performance of SAM for medical image segmentation. The code will be available at https://github.com/wuyanlin-wyl/Trans-SAM .},
  archive      = {J_KBS},
  author       = {Yanlin Wu and Zhihong Wang and Xiongfeng Yang and Hong Kang and Along He and Tao Li},
  doi          = {10.1016/j.knosys.2024.112909},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112909},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trans-SAM: Transfer segment anything model to medical image segmentation with parameter-efficient fine-tuning},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMSMO: Learning to generate multimodal summary for scientific papers. <em>KBS</em>, <em>310</em>, 112908. (<a href='https://doi.org/10.1016/j.knosys.2024.112908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, publishers like Elsevier increasingly use graphical abstracts (i.e., a pictorial paper summary) along with textual abstracts to facilitate scientific paper readings. In such a case, automatically identifying a representative image and generating a suitable textual summary for individual papers can help editors and readers save time, facilitating them in reading and understanding papers. To tackle the case, we introduce the dataset for Scientific Multimodal Summarization with Multimodal Output (SMSMO). Unlike other multimodal tasks which performed on generic, medium-size contents (e.g., news), SMSMO needs to tackle longer multimodal contents in papers, with finer-grained multimodality interactions and semantic alignments between images and text. For this, we propose a cross-modality, multi-task learning summarizer (CMT-Sum). It captures the intra- and inter-modality interactions between images and text through a cross-fusion module; and models the finer-grained image–text semantic alignment by jointly generating the text summary, selecting the key image and matching the text and image. Extensive experiments conducted on two newly introduced datasets on the SMSMO task showcase our model’s effectiveness.},
  archive      = {J_KBS},
  author       = {Xinyi Zhong and Zusheng Tan and Shen Gao and Jing Li and Jiaxing Shen and Jingyu Ji and Jeff Tang and Billy Chiu},
  doi          = {10.1016/j.knosys.2024.112908},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112908},
  shortjournal = {Knowl. Based Syst.},
  title        = {SMSMO: Learning to generate multimodal summary for scientific papers},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cycling topic graph learning for neural topic modeling. <em>KBS</em>, <em>310</em>, 112905. (<a href='https://doi.org/10.1016/j.knosys.2024.112905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models aim to discover a set of latent topics in a textual corpus. Graph Neural Networks (GNNs) have been recently utilized in Neural Topic Models (NTMs) due to their strong capacity to model document representations with the text graph. Most of the previous works construct the text graph by considering documents and words as nodes and document embeddings are learned through the topology structure of the text graph. However, while conducting graph learning on topic modeling, sorely considering document-word propagation will lose the guidance of topic relevance and the graph propagation cannot reflect the true relationship at the topic level which will result in inaccurate topic extraction. To address the above-mentioned issue, we propose a novel neural topic model based on Cycling Topic Graph Learning (CyTGL). Specifically, we design a novel three-party topic graph for document-topic-word to incorporate topic propagation into graph-based topic models. In the three-party topic graph, the topic layer is latent and we recursively extract the topic layer through the learning process. Leveraging this topic graph, we employ topic attention message passing to propagate topical information to enhance the document representations. What is more, the topic layer in the three-party graph can be regarded as the prior knowledge that offers guidance for the process of topic extraction. Crucially, the hierarchical relationships in the three-party graph are maintained during the learning process. We conduct experiments on several widely used datasets and the results show our proposed approach outperforms state-of-the-art topic models.},
  archive      = {J_KBS},
  author       = {Yanyan Liu and Zhiguo Gong},
  doi          = {10.1016/j.knosys.2024.112905},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112905},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cycling topic graph learning for neural topic modeling},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning orientation detection system and its application to grayscale images. <em>KBS</em>, <em>310</em>, 112901. (<a href='https://doi.org/10.1016/j.knosys.2024.112901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In previous studies, researchers demonstrated the effectiveness of dendritic neuron-based models in learning and detecting object orientation within binary images. This innovative approach significantly reduced learning time and costs compared to conventional neural networks. This paper extends the existing model by integrating bio-inspired components into a novel Dendritic Neuron-based Artificial Visual System (DAVS), specifically applying the On-Off Responses Mechanism in horizontal and bipolar cells to the model. This enhancement enables the model to adeptly identify object orientation in grayscale images. Experimental results underscore the model’s exceptional robustness, emphasizing its potential for real-world applications. The incorporation of bio-inspired features not only improves performance but also paves the way for further exploration in the realm of neural network research.},
  archive      = {J_KBS},
  author       = {Tianqi Chen and Yuki Todo and Zeyu Zhang and Zhiyu Qiu and Yuxiao Hua and Zheng Tang},
  doi          = {10.1016/j.knosys.2024.112901},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112901},
  shortjournal = {Knowl. Based Syst.},
  title        = {A learning orientation detection system and its application to grayscale images},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta doubly robust: Debiasing CVR prediction via meta-learning with a small amount of unbiased data. <em>KBS</em>, <em>310</em>, 112898. (<a href='https://doi.org/10.1016/j.knosys.2024.112898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postclick conversion rate (CVR) prediction is an essential task for e-commerce domains, but it is affected by selection bias. Some existing research has attempted to reduce selection bias by directly combining unbiased data. However, these approaches simply combine unbiased and biased data, without fully realizing their potential to reduce selection bias. Moreover, these models exhibit poor learning capabilities when dealing with small datasets, further increasing the difficulty of extracting debiasing knowledge from a limited amount of unbiased data. To address these challenges, we propose a novel meta-learning debiasing method based on gradient optimization, called Meta Doubly Robust (Meta-DR). First, we reformulate CVR prediction as a meta-learning problem and transform it into a dual-stage meta-learning process involving local and global optimization, aiming to enhance the model’s ability to fully use a small amount of unbiased data. Specifically, Meta-DR continuously captures user preference features in the support set through local optimization to enhance the ability to learn new knowledge, and further extracts debiasing knowledge from a small amount of unbiased data through global optimization to reduce selection bias. Second, we realize a few-shot, multiround learning process by applying a meta-learning algorithm, which enhances the model’s learning ability in few-shot data scenarios. Therefore, Meta-DR can effectively extract debiasing knowledge even when the amount of unbiased data is small. Extensive experiments on two public datasets demonstrate that our method outperforms state-of-the-art debiasing techniques, achieving improvements 8.3% and 5.5% in normalized discounted cumulative gain @5 (NDCG@5) and Recall@5 metrics, respectively, compared to the strongest baseline.},
  archive      = {J_KBS},
  author       = {Pengkun Li and Xiangrong Tong and Yingjie Wang and Qiang Zhang},
  doi          = {10.1016/j.knosys.2024.112898},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112898},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta doubly robust: Debiasing CVR prediction via meta-learning with a small amount of unbiased data},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainability-based adversarial attack on graphs through edge perturbation. <em>KBS</em>, <em>310</em>, 112895. (<a href='https://doi.org/10.1016/j.knosys.2024.112895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of graph neural networks (GNNs) in various domains, they exhibit susceptibility to adversarial attacks. Understanding these vulnerabilities is crucial for developing robust and secure applications. In this paper, we investigate the impact of evasion adversarial attacks through edge perturbations which involve both edge insertions and deletions. A novel explainability-based method is proposed to identify important nodes in the graph and perform edge perturbation between these nodes. The task of node classification in GNNs has a substantial effect on tasks that involve network analysis in numerous domains. Considering the broad applicability of this method, understanding potential strategies for adversarial attacks can provide insight to defend against them. Explainability offers comprehensive reasoning behind the predictions made by GNNs and facilitates transparency about the inner operation of the model. We show that additional information and insights that can be gained through GNN-based explainability methods can be utilized to strengthen the adversarial attack. The proposed method is tested for node classification with three different architectures and datasets. The results suggest that introducing edges between nodes of different classes has a higher impact as compared to removing edges among nodes within the same class.},
  archive      = {J_KBS},
  author       = {Dibaloke Chanda and Saba Heidari Gheshlaghi and Nasim Yahya Soltani},
  doi          = {10.1016/j.knosys.2024.112895},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112895},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainability-based adversarial attack on graphs through edge perturbation},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intuitively interpreting GANs latent space using semantic distribution. <em>KBS</em>, <em>310</em>, 112894. (<a href='https://doi.org/10.1016/j.knosys.2024.112894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efforts have been made in understanding the latent representations constructed by generative adversarial networks (GANs), which facilitate the efficient learning and optimization of models. How to intuitively interpret and manipulate the multi-valued semantic features in latent space still needs exploration. In this work, we propose an interpretable framework for interpreting semantics in the latent space generated by the GANs models as a high-dimensional Gaussian distribution. For both binary-valued and multi-valued features, this framework can provide a semantic description intuitively. The analysis from different granularities in the latent space can also be intuitively revealed through constructing an undirected weighted graph based on the average Hellinger distance between different semantic distributions. Based on this interpretation, manipulating semantic information can be realized in high-dimensional uninterpretable latent spaces. Furthermore, according to the relationship between latent variables and semantic distributions, we build a semantic classifier for latent variables which benefits for introducing prior knowledge. The framework is evaluated by applying it to the state-of-the-art GANs methods. Experiments show that the proposed framework has advantages in intuitiveness with the ability to interpret complex multi-valued features, and make ordinary GANs model controllable by realizing semantic manipulation and classification without additional training. It provides a novel and practical approach to understand the representation mechanism of GANs.},
  archive      = {J_KBS},
  author       = {Ruqi Wang and Guoyin Wang and Lihua Gu and Qun Liu and Yue Liu and Yike Guo},
  doi          = {10.1016/j.knosys.2024.112894},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112894},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intuitively interpreting GANs latent space using semantic distribution},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SKD-SBSR: Structural knowledge distillation for sketch-based 3D shape retrieval. <em>KBS</em>, <em>310</em>, 112891. (<a href='https://doi.org/10.1016/j.knosys.2024.112891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-based 3D shape retrieval (SBSR) is a complex cross-modal matching problem, primarily due to the heterogeneous distribution of cross-modal data and the sparse, diverse nature of sketches. A crucial yet often overlooked characteristic of sketches is their consistent internal structural features, despite being human-drawn and varied. We argue that an effective SBSR model can explicitly consider this structural consistency, emphasizing the extraction of rich, multi-grained features from sketches. Moreover, a successful transfer of this structural information to conventional geometric features is essential. To address these challenges, we propose a novel method called Structural Knowledge Distillation for Sketch-Based 3D Shape Retrieval (SKD-SBSR), which explicitly considers the structural coherence of sketches. Key innovations include a Dual-branch sketch-3D shape feature extraction Network (DualNet) with a Progressive Loss (PLoss) that incrementally adapts the strength of loss constraints to ensure geometric feature consistency and flexibility. We also introduce a Structural Feature extraction Network (SFNet) equipped with a Multi-Grained Structural Feature (MGSF) encoder, which captures rich structural features through graph transformer and feature fusion operations. To fully utilize both structural and geometric features, we propose a Structural Feature Knowledge Distillation (SFKD) module that effectively transfers structural knowledge, thereby enhancing the feature representation of DualNet and achieving robust retrieval. Comprehensive experiments on the SHREC’13, SHREC’14, and Part-SHREC’14 datasets demonstrate that SKD-SBSR achieves state-of-the-art performance in SBSR tasks.},
  archive      = {J_KBS},
  author       = {Yawen Su and Wenjing Li and Jing Bai and Gan Lin},
  doi          = {10.1016/j.knosys.2024.112891},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112891},
  shortjournal = {Knowl. Based Syst.},
  title        = {SKD-SBSR: Structural knowledge distillation for sketch-based 3D shape retrieval},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segment-level event perception with semantic dictionary for weakly supervised audio-visual video parsing. <em>KBS</em>, <em>310</em>, 112884. (<a href='https://doi.org/10.1016/j.knosys.2024.112884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Videos capture auditory and visual signals, each conveying distinct events. Simultaneously analyzing these multimodal signals enhances human comprehension of the video content. We focus on the audio-visual video parsing task, in which we integrate auditory and visual cues to identify events in each modality and pinpoint their temporal boundaries. Since fine-grained segment-level annotation is labor-intensive and time-consuming, only video-level labels are provided during the training phase. Labels and timestamps for each modality are unknown. A prevalent strategy is to aggregate audio and visual features through cross-modal attention and further denoise video labels to parse events within video segments in a weakly supervised manner. However, these denoised labels have limitations: they are restricted to the video level, and segment-level annotations remain unknown. In this paper, we propose a semantic dictionary description method for audio-visual video parsing, termed SDDP ( S emantic D ictionary D escription for video P arsing), which uses a semantic dictionary to explicitly represent the content of video segments. In particular, we query the relevance of each segment with semantic words from the dictionary and determine the pertinent semantic words to redescribe each segment. These redescribed segments encode event-related information, facilitating cross-modal video parsing. Furthermore, a pseudo label generation strategy is introduced to convert the relevance of semantic dictionary queries into segment-level pseudo labels, which provide segment-level event information to supervise event prediction. Extensive experiments demonstrate the effectiveness of the proposed method, achieving superior performance compared with state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Zhuyang Xie and Yan Yang and Yankai Yu and Jie Wang and Yan Liu and Yongquan Jiang},
  doi          = {10.1016/j.knosys.2024.112884},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112884},
  shortjournal = {Knowl. Based Syst.},
  title        = {Segment-level event perception with semantic dictionary for weakly supervised audio-visual video parsing},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIIPSO-EFS: Learning system with self-optimized parameters for chaotic time series online prediction. <em>KBS</em>, <em>310</em>, 112878. (<a href='https://doi.org/10.1016/j.knosys.2024.112878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving fuzzy systems (EFSs) have been widely used for online prediction. However, most EFSs compute outputs using single-pass learning without ensuring the optimality of parameters. To address this issue, EFS based on multi-population information integrated particle swarm optimization (MIIPSO-EFS) is proposed. The model is designed with two learning stages. In the structural learning stage, the model constructs a rule base and updates model parameters. In the parameter learning stage, an improved particle swarm optimization is designed to search for optimal parameters. Simulation results from the financial and meteorological datasets show the competitiveness of MIIPSO-EFS compared with other benchmark models.},
  archive      = {J_KBS},
  author       = {Lei Hu and Xinghan Xu and Jianwei Liu and Xiaohui Yan and Min Han},
  doi          = {10.1016/j.knosys.2024.112878},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112878},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIIPSO-EFS: Learning system with self-optimized parameters for chaotic time series online prediction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A malicious feature detection and prevention mechanism with BRDH approach for improved security in homomorphic blockchain. <em>KBS</em>, <em>310</em>, 112872. (<a href='https://doi.org/10.1016/j.knosys.2024.112872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today's digital landscape, safeguarding sensitive data from external threats is a pressing concern. This paper introduces an innovative approach named Buffalo Recurrent Diffie Hellman (BRDH), designed to bolster data security by proactively identifying and mitigating potential risks. BRDH combines the power of African Buffalo optimization and Recurrent Neural Networks (RNN) to continuously monitor data in the cloud, swiftly detecting and responding to suspicious activities. Data encryption is employed to establish robust security measures using the Diffie-Hellman algorithm. Homomorphic encryption further enhances security by validating hash values and denying access in case of discrepancies. Authorized users receive a private key to decrypt cypher Text and access the original data securely. BRDH significantly enhances data confidentiality, achieves over 99 % accuracy in malicious feature detection, and reduces encryption/decryption times compared to conventional models, as demonstrated through applications in the stock market, healthcare, and network traffic data. BRDH sets a new standard in robust data protection amidst evolving security threats. Method Advantages},
  archive      = {J_KBS},
  author       = {K Swanthana and S.S. Aravinth},
  doi          = {10.1016/j.knosys.2024.112872},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112872},
  shortjournal = {Knowl. Based Syst.},
  title        = {A malicious feature detection and prevention mechanism with BRDH approach for improved security in homomorphic blockchain},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven approach for selection of on-chain vs off-chain carbon credits data storage methods. <em>KBS</em>, <em>310</em>, 112871. (<a href='https://doi.org/10.1016/j.knosys.2024.112871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As blockchain technology continues to revolutionize various industries, the efficient and secure storage of data has become a critical challenge. Inspired by blockchain’s distributed peer-to-peer networks, security and information storage solutions have found widespread application in high-information environments due to their efficiency, security, traceability, and decentralized nature. However, as blockchain applications expand and the volume of data grows exponentially, the interplay between on-chain and off-chain storage is rapidly becoming a crucial factor in blockchain data management. The motivation for this research stems from the pressing need to address the scalability and performance issues inherent in blockchain systems as they handle increasingly large datasets. Carbon credits data, specifically from a provenance perspective, is multimodal in nature. It can be captured using many different modes and devices and could include images, text, and unstructured data. Current literature lacks a comprehensive analysis of the trade-offs between on-chain and off-chain storage methods, particularly for multimedia data, in terms of their impact on system scalability, operational efficiency, and economic viability. This gap in knowledge hinders stakeholders from making informed decisions about optimal data disposition strategies for their blockchain implementations. This paper aims to bridge this gap by delivering a comprehensive explanation of the data storage methods adopted by blockchain systems, focusing on scalability, efficiency, and economic viability as key evaluation criteria. We analyze the unique connotations and implications of both on-chain and off-chain storage, considering their effects on data retrieval times and overall system performance. Through our analysis, we derive valuable insights to guide the decision-making process in designing and implementing blockchain solutions tailored to specific needs and application scenarios. By providing a thorough examination of these storage methods, this research enables stakeholders to make informed choices about blockchain data disposition, ensuring the long-term sustainability and efficiency of their blockchain implementations. Our findings will contribute to the optimization of blockchain systems, balancing performance, security, and cost-effectiveness in an era of rapidly expanding blockchain applications and data volumes.},
  archive      = {J_KBS},
  author       = {Nada Atetallah Alghanmi and Nouf Atiahallah Alghanmi and Samaher Atiatallah Alghanmi and Ming Zhao and Farookh Khadeer Hussain},
  doi          = {10.1016/j.knosys.2024.112871},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112871},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven approach for selection of on-chain vs off-chain carbon credits data storage methods},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Don’t overlook any detail: Data-efficient reinforcement learning with visual attention. <em>KBS</em>, <em>310</em>, 112869. (<a href='https://doi.org/10.1016/j.knosys.2024.112869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of visual reinforcement learning across various domains, the introduction of visual attention mechanisms aims to emulate human visual tasks, enabling deep models to focus on the crucial parts of images and enhancing model performance. However, in situations with limited data samples, solely introducing visual attention mechanisms can exacerbate overfitting in deep reinforcement learning (DRL), deteriorating performance. Herein, we propose a method called ‘Don’t overlook any detail (DOAD)’ to tackle this issue. A two-step training strategy is proposed to increase the training frequency of the visual attention module while avoiding the specification of explicit tasks and fully acknowledging the pivotal role of visual attention in the learning process, rendering the model more adaptable to environmental changes. Furthermore, a conditional network reset method is proposed to simulate the flexibility observed in human learning processes, encouraging the model to adapt more flexibly to new information through regular reset mechanisms without excessively adhering to early knowledge. Finally, extensive experiments were conducted on 26 game environments within the Atari 100K environment. Compared to the baseline with the introduction of visual attention on the interquartile mean (IQM) from 0.44 to 0.37, the introduction of DOAD visual attention methods can improve the IQM to 0.70. DOAD elucidates the internal mechanisms of DRL and offers novel insights for applying visual attention mechanisms in DRL models under limited sample data contexts.},
  archive      = {J_KBS},
  author       = {Jialin Ma and Ce Li and Zhiqiang Feng and Limei Xiao and Chengdan He and Yan Zhang},
  doi          = {10.1016/j.knosys.2024.112869},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112869},
  shortjournal = {Knowl. Based Syst.},
  title        = {Don’t overlook any detail: Data-efficient reinforcement learning with visual attention},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MKFTracker: An RGBT tracker via multimodal knowledge embedding and feature interaction. <em>KBS</em>, <em>310</em>, 112860. (<a href='https://doi.org/10.1016/j.knosys.2024.112860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current RGBT tracking algorithm can track targets under all weather conditions. However, there exists bounding box ambiguity and tracking drift. To solve these problems, we propose a tracker called MKFTracker; it leverages multimodal semantic information, including both textual and visual data, and improves accuracy by exploring potential interdependencies between modalities. MKFTracker comprises a Multilevel Modal Interaction (MMI) module and a Semantic Awareness Refinement (SAR) mechanism, which facilitate multimodal knowledge migration, adaptive mining, and multimodal feature fusion to achieve accurate target tracking. Specifically, the MMI enhances instance representation in images by emphasising on discriminative feature generation for images through a bidirectional approach. Unlike other tracking algorithms, MKFTracker considers the rich semantic information inherent in image–text pairs. Moreover, the SAR mechanism is designed based on Visual and Linguistic Pretraining (VLP) models to organically link heterogeneous multimodality. SAR combines high-level semantic information from image–text pairs with specific advantages of different images to enhance the target regression accuracy and refine scale estimations. Extensive experiments conducted on four public RGBT benchmarks demonstrated that MKFTracker addresses bounding box ambiguity and tracking drift, achieving a level of performance that is competitive with state-of-the-art algorithms.},
  archive      = {J_KBS},
  author       = {Fangfang Li and Weidai Xia and Dongming Zhou and Jinde Cao},
  doi          = {10.1016/j.knosys.2024.112860},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112860},
  shortjournal = {Knowl. Based Syst.},
  title        = {MKFTracker: An RGBT tracker via multimodal knowledge embedding and feature interaction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphCLIP: Image-graph contrastive learning for multimodal artwork classification. <em>KBS</em>, <em>310</em>, 112857. (<a href='https://doi.org/10.1016/j.knosys.2024.112857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present GraphCLIP, a novel contrastive learning framework for multimodal artwork classification that integrates visual and contextual information to improve predictive accuracy and interpretability. Traditional computer vision methods often fall short in visual arts, where context is crucial. GraphCLIP leverages image data and a Knowledge Graph to extract features from both perspectives. Evaluated on the A r t G r a p h dataset, with over 100,000 artworks in 32 styles and 18 genres, GraphCLIP outperforms existing models in single-task (up to + 8 % in F1-score) and multi-task settings (up to + 6 % ), demonstrating robustness even with unseen classes. Additionally, visual and contextual qualitative explanations enhance model transparency. The versatility of GraphCLIP extends beyond art classification: its methodology can be adapted to other domains where integrating diverse data types is essential. (The code is publicly available at: https://github.com/CILAB-ArtGraph/graphclip.git .)},
  archive      = {J_KBS},
  author       = {Raffaele Scaringi and Giuseppe Fiameni and Gennaro Vessio and Giovanna Castellano},
  doi          = {10.1016/j.knosys.2024.112857},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112857},
  shortjournal = {Knowl. Based Syst.},
  title        = {GraphCLIP: Image-graph contrastive learning for multimodal artwork classification},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive dual-channel multi-modal graph neural network for few-shot learning. <em>KBS</em>, <em>310</em>, 112845. (<a href='https://doi.org/10.1016/j.knosys.2024.112845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph neural network (GNN)-based approaches have achieved great success in the field of few-shot learning (FSL). These FSL methods usually employ a meta-learning episode training strategy aimed at learning a GNN model to solve FSL tasks. However, most of the existing methods do not consider that using a task-independent GNN model on tasks with a completely independent feature space will lead to poor performance. To address this problem, we propose an Adaptive Dual-channel Multi-modal GNN (AMGNN). First, we introduce a feature augmentation (FA) module based on a multi-head attention mechanism to improve the quality of the feature representations produced for the support samples. Then, we employ semantic knowledge to construct a dual-channel multi-modal GNN that learns feature representations and is guided by fused modal information, including both semantic and visual knowledge. The introduction of semantic knowledge provides correlations between tasks and consistent global embedding for previously separated task feature spaces, thus improving the generalization ability of meta-GNN models on different tasks. Finally, we present an adaptive dual-channel feature fusion module that flexibly fuses the outputs of the two channels and learns the complementary relationships between them to obtain more discriminative instance features. These features guide the query sample class inference process. We conduct extensive experiments on two few-shot classification datasets, and the results demonstrate that our proposed model significantly outperforms the current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jieyi Yang and Yihong Dong and Guoqing Li},
  doi          = {10.1016/j.knosys.2024.112845},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112845},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive dual-channel multi-modal graph neural network for few-shot learning},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational reasoning networks. <em>KBS</em>, <em>310</em>, 112822. (<a href='https://doi.org/10.1016/j.knosys.2024.112822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural-symbolic methods integrate neural architectures, knowledge representation and reasoning. However, they have struggled with both the intrinsic uncertainty of the observations and scaling to real-world applications. This paper presents Relational Reasoning Networks (R2N), a novel end-to-end model that performs relational reasoning in the latent space of a deep learner architecture, where the representations of constants, ground atoms and their manipulations are learned in an integrated fashion. Unlike flat architectures such as Knowledge Graph Embedders, which can only represent relations between entities, R2Ns define an additional computational structure, accounting for higher-level relations among the ground atoms. The considered relations can be explicitly known, like the ones defined by logic formulas, or defined as unconstrained correlations among groups of ground atoms. R2Ns can be applied to purely symbolic tasks or as a neural-symbolic platform to integrate learning and reasoning in heterogeneous problems with entities represented both symbolically and feature-based. The proposed model overtakes the limitations of previous neural-symbolic methods that have been either limited in terms of scalability or expressivity. The proposed methodology is shown to achieve state-of-the-art results in different experimental settings.},
  archive      = {J_KBS},
  author       = {Giuseppe Marra and Michelangelo Diligenti and Francesco Giannini},
  doi          = {10.1016/j.knosys.2024.112822},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112822},
  shortjournal = {Knowl. Based Syst.},
  title        = {Relational reasoning networks},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fault diagnosis via unsupervised domain adaptation: The role of intermediate domain construction. <em>KBS</em>, <em>310</em>, 112766. (<a href='https://doi.org/10.1016/j.knosys.2024.112766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent endeavors in unsupervised domain adaptation (UDA) for fault diagnosis often encounter large domain discrepancies due to direct adaptation. To address this issue, certain studies attempted to bridge the substantial domain gaps by generating intermediate domains between the source and target domains. In this paper, we introduce a novel UDA technique that integrates this concept with adversarial learning for enhanced diagnostic intelligence. Specifically, we propose an innovative method that effectively constructs the intermediate domain by implementing a learnable mixup on the input data. Subsequently, we use two semi-supervised mixup losses in the feature and label spaces to quantify the domain divergence between the source and target domains, while domain adversarial learning is employed to extract domain-invariant features. Additionally, Batch Spectral Penalization (BSP) is incorporated to learn feature representations that are both transferable and discriminative. The extensive experimental results validate the efficacy of our approach on three prominent public datasets: CWRU, PU, and PHM2009.},
  archive      = {J_KBS},
  author       = {Peng Cao and Jun Yang and Jinyin Jia and Junfan Chen and Anfei Fan},
  doi          = {10.1016/j.knosys.2024.112766},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112766},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intelligent fault diagnosis via unsupervised domain adaptation: The role of intermediate domain construction},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized high-dimensional memristive hopfield neural network for DoS attack detection in mobile adhoc network. <em>KBS</em>, <em>310</em>, 112698. (<a href='https://doi.org/10.1016/j.knosys.2024.112698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MANET (Mobile Adhoc Network) is a decentralized and dynamically adaptable network infrastructure, offering flexibility where fixed configurations are impractical or unnecessary. With various real-life applications, MANETs have received significant interest from the research community. Security is an important aspect of every computer network system, and MANETs are no exception. This research centers on addressing Denial of Service (DoS) attacks in MANETs, and highlighting the inadequacy of general classification models in distinguishing these attacks from network errors. In this paper, an Optimized High-Dimensional Memristive Hopfield Neural Network for DoS Attack Detection in Mobile Adhoc Network (HDMHNN-DoSAD-MANET) is proposed. The input data are taken from the Kitsune Network Attack Dataset. The collected input data is preprocessed using Regularized Bias-aware Ensemble Kalman Filtering (RBEKF) to remove the noise from the dataset. Then the pre-processed data are given to the High-Dimensional Memristive Hopfield Neural Network (HDMHNN) for detecting DoS attack in MANET as, Active Wiretap (AW), ARP MitM, Fuzzing (FG), OS Scan, SSDP Flood, SYN DoS, SSL renegotiation, Mirai (MI) and Video Injection (VI). The Portia Spider Optimization Algorithm (PSOA) is proposed to enhance the weight parameter of HDMHNN network. The HDMHNN-DoSAD-MANET method is implemented and its efficiency is analyzed under some metrics, such as, Precision, Accuracy, F1-score, Recall, Specificity, Error rate, Computation time, RoC. The HDMHNN-DoSAD-MANET method achieves 36.64%, 33.87% and 31.56% higher Precision; 32.44%, 31.88 and 33.59% higher Accuracy; 28.39%, 32.85 and 19.73% higher F1-score; 29.89%, 32.66 and 34.93% higher Recall, when compared with the existing methods.},
  archive      = {J_KBS},
  author       = {Gayathri Devi S and Chandia S and Savithri V and Saraswathi K},
  doi          = {10.1016/j.knosys.2024.112698},
  journal      = {Knowledge-Based Systems},
  month        = {2},
  pages        = {112698},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized high-dimensional memristive hopfield neural network for DoS attack detection in mobile adhoc network},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy assistants for prosumers to enable trading strategies on local electricity markets. <em>KBS</em>, <em>309</em>, 112927. (<a href='https://doi.org/10.1016/j.knosys.2024.112927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home assistants gained more attention as they provide guidance and can also be active in energy communities and assist prosumers by controlling appliances. Graphical interface and interaction with appliances via vocal commands have transformed home assistants into valuable tools. In this paper, we propose a methodology embedded within an Energy Assistant (EA) that incorporates algorithms for forecasting generation availability, recommending optimal time slots for load scheduling, optimally scheduling appliances, setting trading strategies in Local Electricity Markets (LEM), and controlling the operation of appliances. EA provides decision support for trading on LEM using reinforcement learning agents trained to optimize the price and quantities to maximize the trading probability and minimize the cost. The EA algorithms are embedded as a home assistant into an Alexa skill that has multiple intents corresponding to user requests. For simulations, 114 apartments, 7 houses with small Photovoltaic (PV) systems and a large PV system of 500 kW are considered. When 51 % of the households use EA, Self-Consumption Index increases from 0.72 to 0.85 and Grid Dependence Index reduces from 56 to 32. The average annual cost per apartment decreased from €96.62 to €76.60 after using EA for trading, indicating savings of 37.80 %.},
  archive      = {J_KBS},
  author       = {Adela Bâra and Simona-Vasilica Oprea},
  doi          = {10.1016/j.knosys.2024.112927},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112927},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy assistants for prosumers to enable trading strategies on local electricity markets},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical and complementary experts transformer with momentum invariance for image-text retrieval. <em>KBS</em>, <em>309</em>, 112912. (<a href='https://doi.org/10.1016/j.knosys.2024.112912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have highlighted a burgeoning interest in harnessing the pre-trained Bottom-Up and Top-Down (BUTD) based region-level features for image-text retrieval (ITR) by designing sophisticated networks or objectives with fixed alignment annotations. However, such approaches not only fail to adequately represent the entire image but also neglect the significance of the semantic invariance. In this study, we propose a Hierarchical and Complementary Experts Transformer with Momentum Invariance (HiCer) method for ITR. Specifically, we delicately design a Complementary Experts Transformer (COME) module for visual modality, which learns the complementary representation from both the grid field and the region field. Further, we extract the hierarchical features from each COME layer to enable progressive context learning, and aggregate them with a parameter-shared aggregator. Moreover, we refine the current momentum contrast training paradigm by eliminating false negatives that are enqueued in the dynamic queue and provide a detailed explanation of the dynamic queue based training paradigm from a Semantic-Invariant perspective. Extensive experiments on the benchmark MSCOCO, Flickr30K, and Crisscrossed Caption datasets are conducted to demonstrate the superiority on both retrieval accuracy and inference efficiency. Compared with the state-of-the-art method RCAR, our HiCer method exhibits favorable performance, achieving an absolute gain of 4.9% and 12.0% on the R@Sum metric, while enjoying over 950 and 500 times faster inference speed on the MSCOCO 5-Folds 1K and 5K Testing sets, respectively. Our source code will be released at https://github.com/zyy0822/HiCer .},
  archive      = {J_KBS},
  author       = {Yan Zhang and Zhong Ji and Yanwei Pang and Jungong Han},
  doi          = {10.1016/j.knosys.2024.112912},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112912},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical and complementary experts transformer with momentum invariance for image-text retrieval},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming decoder-only models into encoder-only models with improved understanding capabilities. <em>KBS</em>, <em>309</em>, 112907. (<a href='https://doi.org/10.1016/j.knosys.2024.112907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decoder-only architecture has become a key driver in the current wave of large language models. However, its reliance on causal (i.e., left-side) attention limits its text understanding capabilities compared to encoder-only models that utilize bidirectional attention. On the other hand, existing encoder-only models are constrained by the scale of training data and model size, resulting in restricted understanding, especially in non-English contexts. To obtain encoder-only models with powerful understanding capabilities and also multilingual knowledge, we propose Dec2Enc, which transforms decoder-only models into encoder-only models by recovering bidirectional attention, thereby improving their understanding potential. In particular, Dec2Enc uses a zero initialization strategy that begins fine-tuning with the original causal attention mechanism, gradually learning bidirectional attention during training, which mitigates significant training disruptions that arise from mismatches between the attention mechanisms used in pre-training and fine-tuning. In our experiments with various decoder-only models from 0.5B to 9B, Dec2Enc boosts understanding capabilities and utilizes multilingual knowledge, achieving an increase of 5.2% to 22.4% in percentage of exact match answers in seven languages compared to vanilla decoder-only models, and also outperforming existing encoder-only models in overall performance. Our code is available at https://github.com/nju-websoft/Dec2Enc .},
  archive      = {J_KBS},
  author       = {Zixian Huang and Xinwei Huang and Ao Wu and Xiaxia Wang and Gong Cheng},
  doi          = {10.1016/j.knosys.2024.112907},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112907},
  shortjournal = {Knowl. Based Syst.},
  title        = {Transforming decoder-only models into encoder-only models with improved understanding capabilities},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposing spatio-temporal heterogeneity: Matrix-informed ensemble learning for interpretable prediction. <em>KBS</em>, <em>309</em>, 112906. (<a href='https://doi.org/10.1016/j.knosys.2024.112906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction aims to forecast location or time-related changes in the physical world with disciplinary knowledge and historical data. Ensemble learning strategies that integrate multiple base learners can leverage the advantages of different models and thus gain wide attention in the field of spatio-temporal prediction. However, existing methods often ignore the unified expression of spatial and temporal heterogeneity in the ensemble process and fail to clarify the mechanisms of model integration under these constraints, limiting the predictive ability and the interpretability of ensemble models. Therefore, this study proposed a M atrix- I nformed E nsemble L earning Method (MI-EL) for interpretable spatio-temporal prediction. The core idea of this method is to decompose the spatio-temporal heterogeneous ensemble weight matrix into the multiplication of the spatial and temporal factor matrix. By constructing a spatio-temporal embedding learning module, it utilizes spatial associations and temporal attributes of the samples to solve the spatial and temporal factor matrices, thereby achieving a unified expression of spatial and temporal heterogeneity in the ensemble process. On this basis, interpretable spatial and temporal score vectors are constructed for explicitly expressing the influence intensities and response rules of different base learners under conditions of spatial and temporal heterogeneity. Experiments on traffic flow, traffic speed and air quality prediction tasks show that the proposed method outperforms eight existing ensemble methods in the prediction accuracies at different time steps. Additionally, it effectively identifies the performance patterns of base learners at different spatio-temporal units by assigning higher spatio-temporal scores to better-performing base learners, thereby achieving superior prediction results.},
  archive      = {J_KBS},
  author       = {Lizeng Wang and Shifen Cheng and Feng Lu},
  doi          = {10.1016/j.knosys.2024.112906},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112906},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decomposing spatio-temporal heterogeneity: Matrix-informed ensemble learning for interpretable prediction},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent grading system for mangosteen based on improved convolutional neural network. <em>KBS</em>, <em>309</em>, 112904. (<a href='https://doi.org/10.1016/j.knosys.2024.112904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses cognitive challenges in mangosteen production and processing by developing an efficient grading mechanism. A specialized hardware unit was constructed to evaluate mangosteen based on external characteristics, utilizing image preprocessing techniques for color attribute extraction using the RGB model, contour extraction through image segmentation, and diameter measurement via ellipse fitting. We propose a novel convolutional neural network (CNN) model, MobileSeNet, which outperforms MobileNetV2 in average Precision, Recall, and F1-score metrics, achieving a grading accuracy of 98.13 %. Furthermore, MobileSeNet processes images in an average of 76 ms, which is 48 ms faster than MobileNetV2, underscoring its efficiency. Additionally, we developed a user-friendly human-computer interaction interface to enhance usability and minimize cognitive challenges, optimizing user experience and contributing to improved task execution and reduced errors. This comprehensive approach establishes a robust foundation for future advancements in automated grading systems, thereby enhancing productivity in the agricultural sector.},
  archive      = {J_KBS},
  author       = {Yinping Zhang and Joon Huang Chuah},
  doi          = {10.1016/j.knosys.2024.112904},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112904},
  shortjournal = {Knowl. Based Syst.},
  title        = {An intelligent grading system for mangosteen based on improved convolutional neural network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-input interpretation of a deep classification neural network. <em>KBS</em>, <em>309</em>, 112903. (<a href='https://doi.org/10.1016/j.knosys.2024.112903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The justification for artificial intelligence-based predictions has become increasingly important due to their application in very delicate fields. In this work, we present MaxPIn as a linearization-based interpretation of deep classifiers that puts maximum emphasis on the input data values. The output conservation property of MaxPIn is achieved by including network and linearization bias contributions. Furthermore, we designed an interpretation technique specifically for the softmax layer, dubbed CCI, which is compatible with any output-conserving class score interpretation. The idea behind CCI is to consider input contributions to all the class scores simultaneously when calculating the final probability distribution interpretation for a single class. Our experiments show that MaxPIn achieves the most consistent quality regarding the assessment of input image area relevance compared to other popular interpretation methods. Including the network and linearization biases helped MaxPIn maintain the quality across different evaluation settings. We further show that zero-centered class score distributions with lower absolute values are more suitable for softmax extended interpretations. Finally, the comparison of interpretations at different network layers suggests that it is best to interpret the entire network.},
  archive      = {J_KBS},
  author       = {Suraja Poštić and Marko Subašić},
  doi          = {10.1016/j.knosys.2024.112903},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112903},
  shortjournal = {Knowl. Based Syst.},
  title        = {Single-input interpretation of a deep classification neural network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank tensor based smooth representation learning for multi-view unsupervised feature selection. <em>KBS</em>, <em>309</em>, 112902. (<a href='https://doi.org/10.1016/j.knosys.2024.112902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective dimension reduction method, multi-view unsupervised feature selection (MUFS) has attracted much attention in recent years. However, most existing MUFS methods fail to consider noise interference in the data fully and usually ignore higher-order information between different views. To address the above issues, this article proposes a novel MUFS method, named low-rank tensor based smooth representation learning (LTSRL). Specifically, LTSRL utilizes a low-pass filtering technique to remove the noise in the original data, thereby obtaining a smooth representation of each view. Meanwhile, it performs self-representation learning on the smooth representation matrix, which can get the underlying structure information of data. Then, LTSRL stacks a tensor on the self-representation matrix and imposes a weighted low-rank tensor constraint on the tensor, which can capture higher-order information and simultaneously consider the contributions of different views. Extensive experiments demonstrate the effectiveness of our proposed method in comparison with several state-of-the-art benchmark methods.},
  archive      = {J_KBS},
  author       = {Changjia Wang and Peng Song and Meng Duan and Shixuan Zhou and Yuanbo Cheng},
  doi          = {10.1016/j.knosys.2024.112902},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112902},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-rank tensor based smooth representation learning for multi-view unsupervised feature selection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LECM: A model leveraging emotion cause to improve real-time emotion recognition in conversations. <em>KBS</em>, <em>309</em>, 112900. (<a href='https://doi.org/10.1016/j.knosys.2024.112900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time emotion recognition in conversations (RTERC), which relies solely on dialogue history to identify the emotion of a target utterance, has become a prominent research area due to its extensive application value. For RTERC, the primary challenge lies in efficiently extracting contextual information from the dialogue history. Previous studies generally focus on modelling dependencies between utterances but neglect the role of emotional causes in the dialogue history, resulting in unsatisfactory recognition performance. In this paper, we propose a multi-task learning Model that can Leverage the Emotion Cause (LECM), which integrates the main task of RTERC with an auxiliary task of causal emotion entailment (CEE). Specifically, LECM employs a shared encoder to extract the semantic feature vectors of utterances, which are further enriched by a refinement-capable knowledge integration module in the main task. Both the enhanced semantic vectors and the emotion cause vectors derived from the CEE task are jointly input into a cause-oriented tendency network for RTERC. Experimental results on three different benchmark datasets demonstrate the superiority and effectiveness of the proposed model.},
  archive      = {J_KBS},
  author       = {Wenxuan Lu and Zhongtian Hu and Jiashi Lin and Lifang Wang},
  doi          = {10.1016/j.knosys.2024.112900},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112900},
  shortjournal = {Knowl. Based Syst.},
  title        = {LECM: A model leveraging emotion cause to improve real-time emotion recognition in conversations},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data for enhanced privacy: A VAE-GAN approach against membership inference attacks. <em>KBS</em>, <em>309</em>, 112899. (<a href='https://doi.org/10.1016/j.knosys.2024.112899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The raw data utilized in training machine learning models faces a potential threat from membership inference attacks. To mitigate this risk, employing synthetic data instead of real data is proved effective in desensitizing the information. We introduce a novel generative model, combining Variational Autoencoder and Generative Adversarial Network, to enhance privacy protection by generating synthetic data. In our approach, discrete variables are encoded by conditional generators, and sampling training is employed to ensure the distribution of synthetic data closely aligning with the real data. The modification of the model structure prompts a refinement of the loss function. We leverage Wasserstein distance with gradient penalty and SNorm to keep the stability of the model training process. Experimental results demonstrate that the efficacy of our model surpasses existing state-of-the-art models in terms of data utility metrics. Notably, in the face of membership inference attacks, the similarity from the results indicates the difficulty when distinguish the real data from synthetic data. It means our model have highlighting capabilities for the privacy protection.},
  archive      = {J_KBS},
  author       = {Jian’en Yan and Haihui Huang and Kairan Yang and Haiyan Xu and Yanling Li},
  doi          = {10.1016/j.knosys.2024.112899},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112899},
  shortjournal = {Knowl. Based Syst.},
  title        = {Synthetic data for enhanced privacy: A VAE-GAN approach against membership inference attacks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing associative classification on imbalanced data through ontology-based feature extraction and resampling. <em>KBS</em>, <em>309</em>, 112897. (<a href='https://doi.org/10.1016/j.knosys.2024.112897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Associative classification models are valuable for discovering relationships within heterogeneous data systems, making them particularly useful for data integration tasks. However, they struggle with imbalanced and sparse data. This paper addresses the problem of imbalanced classification in building maintenance data by providing several updates based both on algorithms and preprocessing. Experiments conducted on real maintenance datasets demonstrate significant improvements in accuracy and precision.},
  archive      = {J_KBS},
  author       = {Joel Mba Kouhoue and Jerry Lonlac and Alexis Lesage and Arnaud Doniec and Stéphane Lecoeuche},
  doi          = {10.1016/j.knosys.2024.112897},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112897},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing associative classification on imbalanced data through ontology-based feature extraction and resampling},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RVFL-LSTM: A lightweight model with long-short term memory for time series. <em>KBS</em>, <em>309</em>, 112896. (<a href='https://doi.org/10.1016/j.knosys.2024.112896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have been widely used for time series prediction due to their excellent ability to capture the sequential relationship between the past and the future in time series data. However, the existing neural networks, such as long-short term memory(LSTM) and recurrent ones, are often criticized for their complex structure and strict training mode, but some lightweight network models often cannot achieve satisfying prediction performance. In order to tackle this challenge, this paper proposes a lightweight model with long-short term memory for time series, named RVFL-LSTM, which is trained for moving auto-regression task. To highlight the long and short-term patterns in time series data, RVFL-LSTM adjusts the input weights to learn the short-term patterns and updates the output weights gradually to capture the long-term patterns. Experimental results show that the proposed method can capture the long-term and short-term patterns efficiently, and it is very competitive in time series prediction with respect to prediction accuracy and computational complexity.},
  archive      = {J_KBS},
  author       = {Qiang Liu and Qin Wang and Xizhao Wang},
  doi          = {10.1016/j.knosys.2024.112896},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112896},
  shortjournal = {Knowl. Based Syst.},
  title        = {RVFL-LSTM: A lightweight model with long-short term memory for time series},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing visual representation for text-based person searching. <em>KBS</em>, <em>309</em>, 112893. (<a href='https://doi.org/10.1016/j.knosys.2024.112893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based person search aims to retrieve the matched pedestrians from a large-scale image database according to the text description. The core difficulty of this task is how to extract effective details from pedestrian images and texts, and achieve cross-modal alignment in a common latent space. Prior works adopt image and text encoders pre-trained on unimodal data to extract global and local features from image and text respectively, and then global–local alignment is achieved explicitly. However, these approaches still lack the ability of understanding visual details, and the retrieval accuracy is still limited by identity confusion. In order to alleviate the above problems, we rethink the importance of visual features for text-based person search, and propose VFE-TPS , a V isual F eature E nhanced T ext-based P erson S earch model. It introduces a pre-trained multimodal backbone CLIP to learn basic multimodal features and constructs Text Guided Masked Image Modeling task to enhance the model’s ability of learning local visual details without explicit annotation. In addition, we design Identity Supervised Global Visual Feature Calibration task to guide the model learn identity-aware global visual features. The key finding of our study is that, with the help of our proposed auxiliary tasks, the knowledge embedded in the pre-trained CLIP model can be successfully adapted to text-based person search task, and the model’s visual understanding ability is significantly enhanced. Experimental results on three benchmarks demonstrate that our proposed model exceeds the existing approaches, and the Rank-1 accuracy is significantly improved with a notable margin of about 1 % ∼ 9 % . Our code can be found at https://github.com/zhangweifeng1218/VFE_TPS .},
  archive      = {J_KBS},
  author       = {Wei Shen and Ming Fang and Yuxia Wang and Jiafeng Xiao and Diping Li and Huangqun Chen and Ling Xu and Weifeng Zhang},
  doi          = {10.1016/j.knosys.2024.112893},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112893},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing visual representation for text-based person searching},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LDPMF: Local differential privacy enhanced matrix factorization for advanced recommendation. <em>KBS</em>, <em>309</em>, 112892. (<a href='https://doi.org/10.1016/j.knosys.2024.112892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Recommender Systems are widely applied in various industries, the primary objective of which is to utilize the user–item interaction records to enhance the recommendation accuracy and user experience. However, with information overload, the variety of items recommended by recommender systems has increased dramatically, leading to a surge in the number of user ratings. The ensuing problem is that privacy leakage may become particularly prominent when recommender systems acquire items and ratings, since that user’s behavior records may contain certain sensitive information, which can be accessible easily. To cope with these challenges, differential privacy preservation techniques have become powerful tools to solve the privacy leakage problem in recommender systems. However, these methods still face issues such as the balance between privacy protection and utility, attacks and inferential threats. In this article, we propose a novel local differential privacy based recommender system referred to as LDPMF, to enhance the performance of privacy preservation and robustness of recommendation interference. In practice, LDPMF aims to simultaneously protect ratings and the rated items. By employing a stochastic process with a dimensionality reduction technique, we successfully decrease the perturbation error, and reduce the error generated by updating iterations through stabilizing the noise radius. In addition, we introduce a factor for stabilizing the perturbation gradient for LDPMF. In practice, we conduct performance evaluation for LDPMF over two real-life datasets: MovieLens and LibimSeTi. The experimental results indicate that LDPMF significantly outperforms the compared approaches under strong privacy requirements.},
  archive      = {J_KBS},
  author       = {Xiang Li and Wang Zhou and Amin Ul Haq and Shakir Khan},
  doi          = {10.1016/j.knosys.2024.112892},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112892},
  shortjournal = {Knowl. Based Syst.},
  title        = {LDPMF: Local differential privacy enhanced matrix factorization for advanced recommendation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware consistency learning for semi-supervised medical image segmentation. <em>KBS</em>, <em>309</em>, 112890. (<a href='https://doi.org/10.1016/j.knosys.2024.112890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised medical image segmentation faces two challenging issues: (1) insufficient exploration of latent structures leading to difficulty in comprehensively capturing complex features and structures in medical images; (2) sensitivity to noise, where unlabeled data lacks accurate label information, making the model more prone to noise interference during the learning process. In this paper, a method, uncertainty-aware consistency learning (UAC), is proposed to improve the poor generalization and suboptimal performance in semi-supervised medical image segmentation caused by insufficient information exploration and sensitivity to noise. Firstly, by employing multiple perturbation strategies at both the input and output levels, specifically through data-level and scale-level perturbations, the model is better equipped to capture structural information within organs and essential features that impact segmentation performance. Secondly, the perturbation uncertainty leverages perturbation prediction differences to measure uncertainty helps the model generate reliable predictions and avoid excessive focus on unreliable areas in the predictions. Experimental results on three public medical image segmentation datasets demonstrate that our UAC, utilizing multiple perturbation strategies and uncertainty estimation, exhibits generality across various organ segmentation tasks and achieves accurate segmentation, with the DICE of 91.15%(LA), 77.52%(Pancreas-CT) and 78.71%(PARSE) under a 10% label ratio setting. Comparative and ablation studies indicate that our method outperforms state-of-the-art semi-supervised medical image segmentation methods.},
  archive      = {J_KBS},
  author       = {Min Dong and Ating Yang and Zhenhang Wang and Dezhen Li and Jing Yang and Rongchang Zhao},
  doi          = {10.1016/j.knosys.2024.112890},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112890},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncertainty-aware consistency learning for semi-supervised medical image segmentation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-hierarchical error-aware contrastive learning for event argument extraction. <em>KBS</em>, <em>309</em>, 112889. (<a href='https://doi.org/10.1016/j.knosys.2024.112889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event argument extraction (EAE) aims to identify the spans and roles of arguments for the given event type. Deep learning-based EAE methods, especially generation-based methods, have achieved strong performance. However, constrained by supervised training with correct labels, these approaches struggle to discriminate potential extraction errors, manifesting as prediction omissions, redundancy, deviation, and boundary shifts, which limit the downstream applications of EAE. In this paper, we explore strategies for improving the representation learning capability of generative models to circumvent these potential errors. We reformulate the EAE as a template-filling task and propose ERCL, a multi-hierarchical error-aware contrastive learning framework. Specifically, we first design knowledge-free data augmentation algorithms, which generate negative templates covering known potential errors without introducing any external knowledge. Based on these negative samples, the model learns to identify the distribution of potential extraction errors from both sentence and span hierarchies under the guidance of contrastive learning, thus populating templates with correct argument spans. Extensive experiments on ACE05, RAMS and WIKIEVENTS demonstrate that ERCL outperforms other state-of-the-art methods on both sentence and document-level datasets. Furthermore, ERCL also shows strong performance in low-resource scenarios.},
  archive      = {J_KBS},
  author       = {Song He and Wenli Du and Xin Peng and Zhangpeng Wei and Xin Li},
  doi          = {10.1016/j.knosys.2024.112889},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112889},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-hierarchical error-aware contrastive learning for event argument extraction},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic matching-prototypical learning for noisy few-shot relation classification. <em>KBS</em>, <em>309</em>, 112888. (<a href='https://doi.org/10.1016/j.knosys.2024.112888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification (FSRC) targets at tackling the long-tail relation problem by identifying relations between entity pairs with few labeled instances. Most of exiting approaches are difficult to deal with text noise in the real world and complex scenes owing to the few labeled sample instances available for learning and the diversity of text expressions. Moreover, they are constrained by limited capacity to extract text features, thus ignoring the proximity of similar relations and the distinctiveness of different relations in the semantic space. Herein, we propose an innovative D ynamic M atching- P rototypical N etwork (DMPN), which equips with three mechanisms for noisy FSRC. In particular, DMPN adopts an I nstance- G uided M atching (IGM) module and a D imension- G uided A ttention (DGA) module to eliminate the deviation of prototype calculation, and dynamically adjusts the contributions of different instances and dimensional features in the support set. Additionally, a two-stage R elation- A ware T raining (RAT) method is designed to focus on noisy relations and improve the discrimination of relation representations. Extensive experiments conduct on the FewRel dataset demonstrate that our model outperform other competitive baselines. Specifically, in the noiseless scenario and under three different noise rate settings, DMPN achieves an average accuracy of 84.71%/80.81%/74.43%/66.81% respectively, which improves from 2.26% to 6.38% on average compared to all baseline methods.},
  archive      = {J_KBS},
  author       = {Haijia Bi and Tao Peng and Jiayu Han and Hai Cui and Lu Liu},
  doi          = {10.1016/j.knosys.2024.112888},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112888},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic matching-prototypical learning for noisy few-shot relation classification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSPCL: Label-specific supervised prototype contrastive learning for multi-label text classification. <em>KBS</em>, <em>309</em>, 112887. (<a href='https://doi.org/10.1016/j.knosys.2024.112887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has led to further breakthroughs in feature representation. However, text datasets often suffer from class imbalance issues, resulting in suboptimal feature representation performance. Recent studies have introduced prototype networks for single-label scenarios. The prototype network replaces the contrastive samples with class prototypes to mitigate class imbalances. However, in multi-label scenarios, directly updating the prototype network using multi-label samples may introduce a large amount of noise, because a sample may belong to multiple classes. Therefore, the construction of high-quality prototype representations in multi-label scenarios becomes challenging. To address this issue, we propose a label-specific supervised prototype contrastive learning network (LSPCL). LSPCL dynamically learns the relationships between labels and constructs a label-specific prototype repository to enhance the quality of multi-label text feature representations. Specifically, we utilize external knowledge for data augmentation to capture label semantic information more effectively. Our proposal involves a dynamic graph convolutional network that is designed to learn the potential relationships between labels, thereby facilitating improved exploration of label distributions across datasets. Furthermore, we construct a label-specific prototype repository and initialize it using label information. Subsequently, through the attention interaction between labels and text, we obtain label-specific text representations and update the prototype repository using these representations. Finally, we optimize the contrastive learning process using the label-specific prototype repository. In addition, we design a new multi-label supervised prototype contrastive learning loss function to optimize the training process. LSPCL achieved performance improvements of up to 2.9%, 2.1%, and 8.42% on the AAPD, RCV1-v2, and EUR-Lex datasets, respectively, demonstrating its superiority over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Gang Wang and Yajun Du and Yurui Jiang},
  doi          = {10.1016/j.knosys.2024.112887},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112887},
  shortjournal = {Knowl. Based Syst.},
  title        = {LSPCL: Label-specific supervised prototype contrastive learning for multi-label text classification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMAdam: Dual averaging enhanced adaptive gradient method for deep neural networks. <em>KBS</em>, <em>309</em>, 112886. (<a href='https://doi.org/10.1016/j.knosys.2024.112886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved remarkable success in a wide range of fields, largely due to their stable and efficient optimizers. We propose a novel optimizer called Dual Momentum Adam (DMAdam), which combines the stability of dual averaging with the efficiency of adaptive gradient techniques. DMAdam adaptively tunes the learning rate and employs dual averaging updates, effectively balancing stability and convergence rate. This strategy enhances the control of DMAdam over gradient updates, resulting in superior performance in a variety of optimization tasks. Theoretically, we investigate the convergence properties of DMAdam for non-convex models and obtain the non-ergodic convergence of its gradient sequence. Numerically, we demonstrate the impressive performance of DMAdam on CIFAR-10 and CIFAR-100 datasets for image classification tasks. Additionally, DMAdam shows robust performance in natural language processing and object detection tasks. The PyTorch code of DMAdam is available at: https://github.com/Wenhan-Jiang/DMAdam.git .},
  archive      = {J_KBS},
  author       = {Wenhan Jiang and Jinlan Liu and Naimin Zhang and Dongpo Xu},
  doi          = {10.1016/j.knosys.2024.112886},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112886},
  shortjournal = {Knowl. Based Syst.},
  title        = {DMAdam: Dual averaging enhanced adaptive gradient method for deep neural networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROSIN: Robust semantic image hiding network. <em>KBS</em>, <em>309</em>, 112885. (<a href='https://doi.org/10.1016/j.knosys.2024.112885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography aims to imperceptibly conceal a secret image within a cover image, allowing for its recovery at the intended receiver without arousing suspicion. However, many current approaches prioritize high output quality and payload capacity, often neglecting robustness, especially when images are subjected to distortions during transmission. To address this limitation, we propose ROSIN (Robust Semantic Image Hiding Network), a novel framework that enhances the robustness of hidden images by leveraging the stability of semantic features in cover images. Specifically, our method semantically disentangles the cover image into identity and attribute features, and then embeds the secret image into the identity feature, which is more resilient to distortions due to identity feature’s value and geometric invariance properties. We evaluate ROSIN across multiple dimensions, including imperceptibility, fidelity, and robustness, using metrics such as PSNR and SSIM. Experimental results demonstrate that ROSIN achieves superior robustness, outperforming SOTA methods by approximately 15% in resisting distortions, such as JPEG compression and noise attacks, while maintaining comparable imperceptibility and fidelity with PSNR of 44.97 dB and an SSIM of 0.97 for 256x256 secret image. Our method strikes a balance between imperceptibility and robustness, making it suitable for real-world applications where image transmission is subject to various lossy distortions. This work also represents the first attempt to leverage the stability of semantic features to enhance the robustness of image steganography, opening a new research direction.},
  archive      = {J_KBS},
  author       = {Yuan Zhao and Bo Liu and Tianqing Zhu and Ming Ding and Wanlei Zhou},
  doi          = {10.1016/j.knosys.2024.112885},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112885},
  shortjournal = {Knowl. Based Syst.},
  title        = {ROSIN: Robust semantic image hiding network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining converging patterns over streaming trajectories of moving objects in road networks. <em>KBS</em>, <em>309</em>, 112883. (<a href='https://doi.org/10.1016/j.knosys.2024.112883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A converging pattern represents the process in which a collection of moving objects gradually converges toward a target area from various directions and eventually forms a dense group. Unlike most existing group patterns, it indicates the early formation of group events, which has a significant application for predicting and detecting emergency events. Existing studies of the converging pattern merely discover patterns from historical trajectories in an offline manner. However, online mining over streaming trajectories has a more practical impact in some real-world scenarios like real-time traffic monitoring. In this paper, we investigate online algorithms that enable converging pattern mining over network-constrained streaming trajectories of moving objects. To achieve synchronization with the speed of trajectory updates, we propose an incremental density-based clustering algorithm in the road network called I D C R N and a converging monitoring method to detect converging patterns in real-time. To efficiently retrieve the constantly evolving spatial relationship among objects in road networks with a large search space and an intractable computation complexity for network distance, we propose a dual index called M O R N to support continuous neighborhood query and cluster pruning in the road network. Extensive experiments with real and synthetic datasets validate the efficiency of our proposed index and methods.},
  archive      = {J_KBS},
  author       = {Jinping Jia and Ge Ji and Bin Zhao and Genlin Ji},
  doi          = {10.1016/j.knosys.2024.112883},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112883},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mining converging patterns over streaming trajectories of moving objects in road networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale neighbourhood feature interaction network for photovoltaic cell defect detection. <em>KBS</em>, <em>309</em>, 112882. (<a href='https://doi.org/10.1016/j.knosys.2024.112882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic power generation is a critical component in the industrial sector, with the efficiency of energy production being influenced by surface defects in photovoltaic cells. Recent advancements in defect detection have been largely driven by the widespread use of deep learning models. However, detecting defects at multiple scales especially small ones remains challenging due to the varying sizes of defects on photovoltaic cells. Additionally, the presence of significant noise in the images further complicates the extraction of distinguishable features. To address these challenges, this study proposes a novel, one-stage multi-scale neighbourhood feature interaction network (MNFI-Net) designed to detect defects of various sizes against complex backgrounds. The MNFI-Net architecture includes the following components: (1) Ghost cross-stage module, aimed at reducing redundant information; (2) neighbourhood feature interaction module, which enhances the model’s ability to detect defects of different sizes; (3) global attention mechanism that focuses on highlighting key features in the fused feature maps. Additionally, for multi-scale defect detection tasks, we introduced a new balanced efficient loss function. Extensive comparison experiments and ablation studies were conducted on the public photovoltaic electroluminescence image dataset. The experimental results demonstrate that MNFI-Net achieves 94.0% precision and 95.5% mean average precision, outperforming existing state-of-the-art methods in defect classification and detection. The code and proposed models in this study can be accessed at https://github.com/lyc686/MNFI-Net .},
  archive      = {J_KBS},
  author       = {Yu Chen Liu and Qiang Hua and Lin Lin Chen and Chun Ru Dong and Feng Zhang and Yong Zhang},
  doi          = {10.1016/j.knosys.2024.112882},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112882},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-scale neighbourhood feature interaction network for photovoltaic cell defect detection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISFORS-MIX: Multi-agent reinforcement learning with importance-sampling-free off-policy learning and regularized-softmax mixing network. <em>KBS</em>, <em>309</em>, 112881. (<a href='https://doi.org/10.1016/j.knosys.2024.112881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent reinforcement learning (MARL), the low quality of value function and the estimation bias and variance in value function decomposition (VFD) are critical challenges that can significantly impact the performance of cooperative and competitive tasks. These issues often lead to suboptimal policies and unstable learning, which hinders the practical application of MARL in complex environments. This paper proposes a novel method called Importance-Sampling-Free Off-policy learning and Regularized-Softmax Mixing network (ISFORS-MIX) to address these problems. Through enhancing the value function quality and modifying the loss function, ISFORS-MIX integrates Importance-Sampling-Free Off-policy (ISFO) learning and Regularized-Softmax (RS) techniques to improve the performance of QMIX. ISFORS-MIX is verified on the StarCraft Multi-Agent Challenge (SMAC) and WarGame Challenge (WGC) benchmarks. Results show that ISFORS-MIX outperforms five baseline algorithms, including QMIX and QTRAN, and can increase the quality of multi-agent cooperation and confrontation. Moreover, agents trained with ISFORS-MIX can make decisions faster and more stable to complete given tasks.},
  archive      = {J_KBS},
  author       = {Jinjun Rao and Cong Wang and Mei Liu and Jingtao Lei and Wojciech Giernacki},
  doi          = {10.1016/j.knosys.2024.112881},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112881},
  shortjournal = {Knowl. Based Syst.},
  title        = {ISFORS-MIX: Multi-agent reinforcement learning with importance-sampling-free off-policy learning and regularized-softmax mixing network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local tangent space transfer and alignment for incomplete data. <em>KBS</em>, <em>309</em>, 112880. (<a href='https://doi.org/10.1016/j.knosys.2024.112880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering the intrinsic structure of incomplete data is a significant challenge in machine learning. When data incompleteness results in high sparsity levels and samples exhibiting varying degrees of missing data, traditional data processing methods are often insufficient. We propose Local Tangent Space Transfer and Alignment, a method combining transfer learning and manifold learning. This method aims to discover local information that remains usable even under high levels of data sparsity to facilitate the learning of nonlinear characteristics in regions with high sparsity. The method initially employs a combined strategy of cosine similarity and expected squared Euclidean distance to measure and select neighbors for each sample point. Existing nuclear norm regularization (NNR) methods are utilized to establish the local coordinate system for sample neighborhoods with lower sparsity. By contrast, we introduce a novel NNR model for highly sparse neighborhoods. This model aids in learning nonlinear features through the local tangent space of transferred neighborhoods, thereby enhancing the accuracy of determining the local coordinate system of incomplete data. By aligning the local coordinates, the global coordinates of the incomplete data are ultimately obtained. We demonstrate the effectiveness of this method on simulated and real-world datasets.},
  archive      = {J_KBS},
  author       = {Yue Zheng and Jing Wang},
  doi          = {10.1016/j.knosys.2024.112880},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112880},
  shortjournal = {Knowl. Based Syst.},
  title        = {Local tangent space transfer and alignment for incomplete data},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prospective domain adaptation for longitudinal data. <em>KBS</em>, <em>309</em>, 112879. (<a href='https://doi.org/10.1016/j.knosys.2024.112879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longitudinal data includes the information of samples in various timepoints. When applying machine learning algorithms to this data, the use of up-to-date information will yield more accurate results. In this case, if the labels are derived from the up-to-date information, out-of-date samples for which data has not yet been collected are excluded from the prediction. To alleviate this problem, domain adaptation can be a method for the prediction of out-of-date samples in that the method transforms those features similar with the up-to-date samples and bridges to the use of labels. Especially, domain adversarial training methods with a gradient reversal layer derive feature representation where samples in different domains appear to be one set so as to make the origin of them indistinguishable. However, since existing methods focus on different data with heterogeneous features, by considering that homogeneous features are continuously collected in longitudinal data, those need to be improved for the out-of-date and up-to-date samples so that their features are exactly matched. Motivated by this, we propose a method of domain adaptation, namely prospective domain adaptation, where the transformation of the out-of-date features purposes to match the properties of the up-to-date features. Therefore, in the proposed method, the out-of-date features are adapted to the manifold and distribution of the up-to-date features so that two feature sets are implicitly and explicitly matched. The experimental results demonstrated that the proposed method derives well-matched feature representation and outperforms comparative methods.},
  archive      = {J_KBS},
  author       = {Sunghong Park and JeongHeun Yeon and Dong-gi Lee and Sang Joon Son and Hyun Goo Woo and Hyunjung Shin},
  doi          = {10.1016/j.knosys.2024.112879},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112879},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prospective domain adaptation for longitudinal data},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label smoothing regularization-based no hyperparameter domain generalization. <em>KBS</em>, <em>309</em>, 112877. (<a href='https://doi.org/10.1016/j.knosys.2024.112877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization learns from one or multiple source domains. It aims to extract a domain-invariant model that can be employed in an unknown target domain. During network training, the models may become overly reliant on the distribution of the training datasets, ultimately leading to an inability to capture the appropriate patterns present in the unseen data accurately. To alleviate these issues, we introduce weighted label smoothing regularization, which reduces the confidence of the model in the correct category and increases the confidence in other categories to mitigate overfitting. More importantly, the proposed weighted label smoothing regularization allows the model to focus more on the relative relationships between categories rather than on absolute differences, which helps the model learn general features and improves its ability to generalize to new data. After introducing label smoothing regularization, we observe that the gradient signals of the label loss and regularization loss are antagonistic to each other, which may suggest that they correspond to different optimal solutions. A reasonable explanation for this is that label smoothing regularization focuses on the generalization performance of the model, whereas the label loss is more concentrated on the accuracy under the current data distribution. To balance this relationship, we propose weight adaptation. Weight adaptation adjusts the weights adaptively based on the gradient performance and the importance of each loss without manually setting a hyperparameter. This allows the model to allocate more attention to the more crucial loss in the optimization process while reducing the influence of the less important loss. Additionally, by dynamically adjusting the weights during training, weight adaptation can enhance model robustness and prevent overfitting. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_KBS},
  author       = {Yanmei Wang and Xin Wu and XiYao Liu and Fupeng Chu and Huan Liu and Zhi Han},
  doi          = {10.1016/j.knosys.2024.112877},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112877},
  shortjournal = {Knowl. Based Syst.},
  title        = {Label smoothing regularization-based no hyperparameter domain generalization},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced multimodal interaction model for emotion recognition in conversation. <em>KBS</em>, <em>309</em>, 112876. (<a href='https://doi.org/10.1016/j.knosys.2024.112876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Emotion Recognition in Conversation (MERC) aims to identify the emotional state of a speaker who expresses their opinions through text, vision, and audio information during conversations. MERC enables intelligent machines to exhibit empathy, which can increase the effectiveness of human–computer interactions. However, the existing research lacks sufficient mining of the emotional and semantic information of multiple modalities, as well as the differences and associations between multiple modalities. Hence, the two core focuses of this study are the multimodal feature mining method and the emotion fusion method in the conversational context. We propose a Feature-Enhanced Multimodal Interactive (FEMI) model for MERC tasks. Specifically, the proposed FEMI model is designed considering the following three objectives: (1) designing a feature-enhanced module that contains different feature extractors to explore deep emotional and semantic information from emotional clues and semantic attributes; (2) building a dialogue incremental transformer module to reconstruct the context interaction between interlocutors; and (3) proposing a multimodal interactive module to eliminate multimodal differences and build multimodal and cross-modal emotional associations. Extensive experiments were performed on two public datasets, and the results demonstrated that the proposed FEMI model is superior to MERC tasks.},
  archive      = {J_KBS},
  author       = {Yanping Fu and XiaoYuan Yan and Wei Chen and Jun Zhang},
  doi          = {10.1016/j.knosys.2024.112876},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112876},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature-enhanced multimodal interaction model for emotion recognition in conversation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGCN: Mamba-integrated spatiotemporal graph convolutional network for long-term traffic forecasting. <em>KBS</em>, <em>309</em>, 112875. (<a href='https://doi.org/10.1016/j.knosys.2024.112875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting plays a vital role in effective traffic management. In recent years, numerous researchers have employed spatiotemporal graph neural networks to capture the spatiotemporal dependencies of traffic flow and have achieved better predictive performance. However, the accuracy of these models decreases rapidly with increasing number of prediction steps, which makes them less effective for long-sequence time forecasting. Recently, Mamba has attracted attention owing to its ability to handle complex dependencies in sequences while maintaining near-linear complexity. Therefore, to overcome these challenges, this study proposes a traffic forecasting model that integrates Mamba with a graph convolutional network. The proposed model extracts spatial relationships between road network nodes using a graph convolutional network and captures long-term temporal dependencies in historical traffic data using a bidirectional Mamba architecture. Specifically, spatial features are extracted using Chebyshev convolution, followed by feature encoding and embedding. These embeddings are processed by a bidirectional Mamba encoder to generate outputs that are combined with residual connections obtained via residual convolution. Finally, projection and dimensional transformation complete the feature extraction and fusion processes. The accuracy of the proposed model was better than that of the baseline models, as evidenced by the experimental results obtained on the four real-world datasets. The code is available at https://github.com/Vincent665/MGCN-for-Traffic-Prediction .},
  archive      = {J_KBS},
  author       = {Wenxie Lin and Zhe Zhang and Gang Ren and Yangzhen Zhao and Jingfeng Ma and Qi Cao},
  doi          = {10.1016/j.knosys.2024.112875},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112875},
  shortjournal = {Knowl. Based Syst.},
  title        = {MGCN: Mamba-integrated spatiotemporal graph convolutional network for long-term traffic forecasting},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced graph transformer: Multi-scale attention with heterophilous curriculum augmentation. <em>KBS</em>, <em>309</em>, 112874. (<a href='https://doi.org/10.1016/j.knosys.2024.112874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning is a crucial area in machine learning, with widespread applications in social networks, recommendation systems, and traffic flow prediction. Recently, Graph Transformers have emerged as powerful tools for this purpose, garnering significant attention. In this work, we observe a fundamental issue of previous Graph Transformers that they overlook the scale-related information gap and often employ an identical attention computation method for different-scale node interactions, leading to suboptimality of model performance. To address this, we propose a Multi-Scale Attention Graph Transformer (MSA-GT) that enables each node to conduct adaptive interactions conditioned on different scales from both local and global perspectives. Specifically, MSA-GT guides several attention mechanisms to focus on individual scales and then perform customized combinations via an attention-based fusion module, thereby obtaining much more semantically fine-grained node representations. Despite the potential of the above design, we still observe over-fitting to some extent, which is a typical challenge for training Graph Transformers. We propose two additional technical components to prevent over-fitting and improve the performance further. We first introduce a path-based pruning strategy to reduce ineffective attention interactions, facilitating more accurate relevant node selection. Additionally, we propose a Heterophilous Curriculum Augmentation (HCA) module, which gradually increases the training difficulty, forming a weak-to-strong regularization schema and therefore enhancing the model’s generalization ability step-by-step. Extensive experiments show that our method outperforms many state-of-the-art methods on eight public graph benchmarks, proving its effectiveness.},
  archive      = {J_KBS},
  author       = {Jianzhi Zhuang and Jin Li and Chenjunhao Shi and Xinyi Lin and Yang-Geng Fu},
  doi          = {10.1016/j.knosys.2024.112874},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112874},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced graph transformer: Multi-scale attention with heterophilous curriculum augmentation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controllable facial protection against malicious translation-based attribute editing. <em>KBS</em>, <em>309</em>, 112873. (<a href='https://doi.org/10.1016/j.knosys.2024.112873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the rapid development of AI-generated content, face attribute editing has achieved realism that is indistinguishable from reality while meeting users’ demands for social sharing and personalization. However, it also triggers users’ concerns about arbitrary modifications to their facial images. Existing schemes effectively prevent facial images from being tampered with, but they fail to simultaneously accommodate nonmalicious attribute editing outputs. Herein, we propose a controllable facial protection scheme to counter malicious translation-based facial attribute editing models. Our scheme supports the editing of target attributes but prevents protected attributes from being tampered with. It also employs iteratively optimized adversarial perturbations to divert attribute editing. Target attribute edits can be ensured to be correctly output by the model, while outputs of other protected attribute edits cannot achieve the desired results. Furthermore, our scheme utilizes low-frequency information to control image content characteristics, thereby constraining the output of denied access attribute editing while also maintaining consistency in attribute classification with the original image. Extensive experiments validate the effectiveness of our scheme in controlling access, maintaining image quality, and controlling attribute classification.},
  archive      = {J_KBS},
  author       = {Yiyi Xie and Yuqian Zhou and Tao Wang and Zhongyun Hua and Wenying Wen and Shuang Yi and Yushu Zhang},
  doi          = {10.1016/j.knosys.2024.112873},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112873},
  shortjournal = {Knowl. Based Syst.},
  title        = {Controllable facial protection against malicious translation-based attribute editing},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel automated interactive reinforcement learning framework with a constraint-based supervisor for procedural tasks. <em>KBS</em>, <em>309</em>, 112870. (<a href='https://doi.org/10.1016/j.knosys.2024.112870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to perform procedural motion or manipulation tasks in unstructured or uncertain environments poses significant challenges for intelligent agents. Although reinforcement learning algorithms have demonstrated positive results on simple tasks, the hard-to-engineer reward functions and the impractical amount of trial-and-error iterations these agents require in long-experience streams still present challenges for deployment in industrially relevant environments. In this regard, interactive reinforcement learning has emerged as a promising approach to mitigate these limitations, whereby a human supervisor provides evaluative or corrective feedback to the learning agent during training. However, the requirement of a human-in-the-loop approach throughout the learning process can be impractical for tasks that span several hours. This study aims to overcome this limitation by automating the learning process and substituting human feedback with an artificial supervisor grounded in constraint-based modeling techniques. In contrast to the logical constraints commonly used for conventional reinforcement learning, constraint-based modeling techniques offer enhanced adaptability in terms of conceptualizing and modeling the human knowledge of a task. This modeling capability allows an automated supervisor to acquire a closer approximation to human reasoning by dividing complex tasks into more manageable components and identifying the associated subtask and contextual cues in which the agent is involved. The supervisor then adjusts the evaluative and corrective feedback to suit the specific subtask under consideration. The framework was assessed using three actor-critic agents in a human–robot interaction environment, demonstrating a sample efficiency improvement of 50% and success rates of ≥ 95% in simulation and 90% in real-world implementation.},
  archive      = {J_KBS},
  author       = {Íñigo Elguea-Aguinaco and Aitor Aguirre-Ortuzar and Unai Izagirre-Aizpitarte and Ibai Inziarte-Hidalgo and Simon Bøgh and Nestor Arana-Arexolaleiba},
  doi          = {10.1016/j.knosys.2024.112870},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112870},
  shortjournal = {Knowl. Based Syst.},
  title        = {Novel automated interactive reinforcement learning framework with a constraint-based supervisor for procedural tasks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeleton-based action recognition through attention guided heterogeneous graph neural network. <em>KBS</em>, <em>309</em>, 112868. (<a href='https://doi.org/10.1016/j.knosys.2024.112868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous graph convolutional networks typically use homogeneous graphs to explore the hidden dependencies between joints in skeleton-based action recognition. Consequently, these networks treat both physical and nonphysical connections between joints as a single edge attribute and model them simultaneously, blurring the essential distinction between kinematic and interactive relationships. We propose an Attention Guided Heterogeneous Graph Neural Network (AG-HGNN), introducing a novel heterogeneous skeleton graph (HSG). In HSG, joints are represented as vertices; the physical and the nonphysical connections are represented as actual and virtual edges, respectively. Vertices and actual or virtual edges constitute actual and virtual metapaths, respectively. To comprehensively capture the relational patterns of each metapath, we design a rotary self-attention convolution module to understand the semantic associations between joints by introducing the rotary position embedding. Additionally, we propose an inter-frame adaptive temporal convolution module to adaptively adjust the weight of frames in the metapath, enabling spatial convolution to capture temporal dynamics. Among these metapaths, we develop a semantic aggregation module to determine the importance of each metapath in fusing the semantic associations revealed through metapaths. Experiments on three public datasets demonstrate that our proposed AG-HGNN achieves outstanding results .},
  archive      = {J_KBS},
  author       = {Tianchen Li and Pei Geng and Xuequan Lu and Wanqing Li and Lei Lyu},
  doi          = {10.1016/j.knosys.2024.112868},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112868},
  shortjournal = {Knowl. Based Syst.},
  title        = {Skeleton-based action recognition through attention guided heterogeneous graph neural network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying graph neural networks against adversarial attacks via ensemble learning. <em>KBS</em>, <em>309</em>, 112867. (<a href='https://doi.org/10.1016/j.knosys.2024.112867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research reveals that Graph Neural Networks (GNNs) are vulnerable to adversarial attacks. Existing defense methods attempt to purify perturbed graphs from topological or attribute perspectives. However, such input processing step may lead to a loss of generalization performance in GNNs. Additionally, defending from one perspective has limited effectiveness. This paper proposes a novel ensemble learning framework named “Fortifier” that fortifies GNNs against adversarial attacks. It employs a stacking strategy for defense by integrating two perspectives. Specifically, a low-rank approximation model based on Schur decomposition (Schur) and an edge-enhanced attention (EEA) model are introduced to extract global and local features of graphs, respectively. Following this, the graph fusion model (GFU) is introduced as a meta-learner, aimed at fusing the robust components extracted by the two base learners, thereby further fortifying the defense. Furthermore, a parameter-passing strategy is employed to transfer the robustness learned by GFU to other GNNs, which enhances their resilience while maintaining excellent generalization performance. Extensive experiments show that Fortifier effectively defends against both targeted and non-targeted attacks on homogeneous and heterogeneous graphs, and significantly improves the robustness of GNNs.},
  archive      = {J_KBS},
  author       = {Chenyu Zhou and Wei Huang and Xinyuan Miao and Yabin Peng and Xianglong Kong and Yi Cao and Xi Chen},
  doi          = {10.1016/j.knosys.2024.112867},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112867},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fortifying graph neural networks against adversarial attacks via ensemble learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary cross-client network aggregation for personalized federated learning. <em>KBS</em>, <em>309</em>, 112866. (<a href='https://doi.org/10.1016/j.knosys.2024.112866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) enables the training of machine-learning models on dispersed data while ensuring user privacy. Despite their advantages, existing PFL algorithms primarily focus on model architectures and communication issues and often neglect the crucial aspects of efficiency and adaptation in addressing problems trapped in local optima. In this study, we propose an innovative solution to overcome this limitation by introducing an evolutionary cross-client aggregation approach. Our approach aims to enhance personalized model performance in non-independent and identically distributed (non-IID) FL settings. By leveraging the diversity of the client models and employing mutation-based cross-client aggregation, we generate new architectures that are subsequently trained locally during the FL process. We evaluated the effectiveness of our proposed method through experiments on a benchmark dataset and compared its performance with that of other FL methods. The results demonstrate the superiority of our approach, which achieved an impressive accuracy of 85% and outperformed existing methods.},
  archive      = {J_KBS},
  author       = {Yuwei Fan and Wei Xi and Yuhao Shen and Jizhong Zhao},
  doi          = {10.1016/j.knosys.2024.112866},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112866},
  shortjournal = {Knowl. Based Syst.},
  title        = {Evolutionary cross-client network aggregation for personalized federated learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial event patch for spiking neural networks. <em>KBS</em>, <em>309</em>, 112865. (<a href='https://doi.org/10.1016/j.knosys.2024.112865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs), serving as a nexus between neuroscience and machine learning, strive to emulate the intricacies of biological neurons. Their remarkable energy efficiency has garnered significant interest, propelling their adoption in real-world scenarios demanding stringent resource utilization. Advanced SNNs primarily utilize the widely adopted Leaky Integrate-and-Fire (LIF) neurons and are extensively applied across diverse domains. While SNNs have showcased image classification performance comparable to convolutional neural networks, a thorough investigation into their robustness remains absent in current research. Our work introduces adversarial event patch attack, which avoid adding and suppressing events in input spaces with high temporal and spatial resolution. We also propose a novel strategy named extended rate gradient approximation (ERGA), which accelerates the optimization of adversarial event patch and promotes better convergence of adversarial event patch by combining it into the optimization process of adversarial event patch. Our adversarial event patch attack achieves an average attack success rate of up to 68.41%. The Code is available at: https://github.com/yszbb/AE-Patch .},
  archive      = {J_KBS},
  author       = {Song Yan and Jinlong Fei and Hui Wei and Bingbing Zhao and Zheng Wang and Guoliang Yang},
  doi          = {10.1016/j.knosys.2024.112865},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112865},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adversarial event patch for spiking neural networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visemble: A fast ensemble approach for time series classification with multiple visual representations. <em>KBS</em>, <em>309</em>, 112864. (<a href='https://doi.org/10.1016/j.knosys.2024.112864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series are prevalent data in finance, smart cities, sensor networks, engineering, bioinformatics, among other domains. These data differ from regular tabular data as they involve sequences of observations at successive, equally spaced points in time. The temporal ordering of observations in time series carries significant information, making pattern detection in subsequences crucial for supervised learning tasks such as forecasting and classification. Current classification methods often overlook the potential of transformations that represent time series as images. Visual representations such as Recurrence Plots and Markov Transition Fields capture intricate temporal dynamics and spatial patterns that traditional one-dimensional approaches might miss. We propose Visemble , an efficient and accurate ensemble method for time series classification that leverages multiple visual representations and weighted soft voting. Besides our proposal, we present a broader discussion regarding time series imaging representations. Visemble combines the original time domain representation, first-order differences, and various two-dimensional representations. Our ensemble integrates accurate and diverse classifiers to improve the classification performance of individual imaging based models efficiently using Random Forest. A comprehensive experimental evaluation with hundreds benchmark datasets from varying domains demonstrated that Visemble achieves comparable accuracy to state-of-the-art ensemble based methods, such as Elastic Ensemble, BOSS, and Temporal Dictionary Ensemble, but with significantly reduced computational time.},
  archive      = {J_KBS},
  author       = {Vinicius M.A. Souza and Patrickerson S. Veiga and André G.R. Ribeiro},
  doi          = {10.1016/j.knosys.2024.112864},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112864},
  shortjournal = {Knowl. Based Syst.},
  title        = {Visemble: A fast ensemble approach for time series classification with multiple visual representations},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Step-wise contrastive representation learning for diagnosing unknown defective categories in planetary gearboxes. <em>KBS</em>, <em>309</em>, 112863. (<a href='https://doi.org/10.1016/j.knosys.2024.112863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning methods have demonstrated remarkable efficacy in the diagnostic analysis of planetary gearboxes, their practical application in industrial settings is considerably restrained by several inherent limitations. Among these critical challenges are the pronounced dependency on the quality of initial labeling, the constraints associated with loss function strategies employed in contrastive learning, the complexities involved in elucidating intra-cluster and inter-cluster dynamics, as well as the ongoing difficulties in recognizing unknown faults. In response to these challenges, this study introduces a novel methodology termed Step-wise Contrastive Representation Learning, which is specifically designed to address the issue of unidentified fault classes through the utilization of a constrained set of known fault categories. Furthermore, this research develops a comprehensive analytical framework that scrutinizes the relationships between intra-cluster and inter-cluster dynamics in both over-clustered and standard-clustered contexts, thereby facilitating enhanced optimization of model performance. In addition, a multi-step loss function strategy is proposed, encompassing stages from pre-training to advanced training phases, which significantly improves the model’s adaptability to effectively capture the intricate characteristics of new or unrecognized instances. Ultimately, this framework aims to strengthen the development of a specialized classification network that enhances the accuracy and reliability of gear fault diagnosis, thereby yielding substantial improvements in generalization capabilities within dynamic industrial case studies.},
  archive      = {J_KBS},
  author       = {Peng Chen and Ruijin Zhang and Shuai Fan and Junyu Guo and Xingkai Yang},
  doi          = {10.1016/j.knosys.2024.112863},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112863},
  shortjournal = {Knowl. Based Syst.},
  title        = {Step-wise contrastive representation learning for diagnosing unknown defective categories in planetary gearboxes},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized interpretable generalized additive neural network-based human brain diagnosis using medical imaging. <em>KBS</em>, <em>309</em>, 112862. (<a href='https://doi.org/10.1016/j.knosys.2024.112862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Optimized Interpretable Generalized Additive Neural Network-based Human Brain Diagnosis using Medical Imaging (IGANN HBD-MI) to address challenges in MRI-based brain tumor classification. Current deep learning models suffer from high parameter dependency, computational complexity, and difficulties with MRI image noise, which can lead to inaccurate classifications. The IGANN HBD-MI framework begins by collecting MRI brain images from the BRaTS 2021 Task 1 Dataset, which are preprocessed using the Pseudolinear Maximum Correntropy Kalman Filter (PMCKF) to enhance image quality by resampling, normalizing intensity, and removing noise. Segmentation is performed using Sparse Reconstructive Multi-View Evidential Clustering (SRMVEC), which isolates Regions of Interest (RoI) crucial for diagnosis. Haralick texture features are extracted using the Synchro Transient Extracting Transform (SET) for significant texture information. Classification is carried out by the Interpretable Generalized Additive Neural Network (IGANN), which categorizes brain images into Native, Post-contrast T1-weighted, T2-weighted, and T2 FLAIR types. The Elite Opposite Sparrow Search Algorithm (EOSSA) optimizes IGANN's parameters to improve classification accuracy. The IGANN HBD-MI method achieves 99.61% accuracy, 98.5% precision, and 97.2% sensitivity, outperforming existing methods for reliable brain disease classification in MRI images.},
  archive      = {J_KBS},
  author       = {Kathirvel N and Sasidhar A and Rajasekaran M and Saravana Kumar K},
  doi          = {10.1016/j.knosys.2024.112862},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112862},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized interpretable generalized additive neural network-based human brain diagnosis using medical imaging},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft label enhanced graph neural network under heterophily. <em>KBS</em>, <em>309</em>, 112861. (<a href='https://doi.org/10.1016/j.knosys.2024.112861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks have shown great potential in these years, primarily owing to their remarkable capacity for neighborhood aggregation. However, compared with their great success on homophilic networks where the connected nodes have similar features or labels, traditional graph neural networks encounter significant performance degradation on heterophilic networks where dissimilar nodes tend to form connections. Although some heterophilic graph neural networks have been proposed to tackle this problem, most of them have not fully taken advantage of neighborhood label information. In particular, though nodes tend to connect with heterophilic neighbors in heterophilic networks, the neighborhood label distributions of nodes in the same class tend to be similar and vice versa, which helps in improving the distinguishability of node representations. In this work, by leveraging the soft label of nodes, we propose an end-to-end label-guided graph neural network to aggregate the neighborhood information from different classes individually. To further improve the generality, we incorporate an attention mechanism to determine the aggregation weights for each class adaptively. Comprehensive experiments demonstrate the superiority of the proposed model on both heterophilic and homophilic datasets.},
  archive      = {J_KBS},
  author       = {Han Yang and Junyuan Fang and Jiajing Wu and Dan Li and Yaonan Wang and Zibin Zheng},
  doi          = {10.1016/j.knosys.2024.112861},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112861},
  shortjournal = {Knowl. Based Syst.},
  title        = {Soft label enhanced graph neural network under heterophily},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic network security leveraging efficient CoviNet with granger causality-inspired graph neural networks for data compression in cloud IoT devices. <em>KBS</em>, <em>309</em>, 112859. (<a href='https://doi.org/10.1016/j.knosys.2024.112859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing adoption of Internet of Things (IoT) devices has led to the centralization of data on cloud servers, offering enhanced memory capacity and advanced administrative capabilities. However, this change introduces significant security risks. Therefore, a novel method is proposed to predict and secure dynamic networks in cloud-based IoT systems using a Granger Causality Inspired Graph Neural Network integrated with Efficient coviNet (GCIGNN-ENet). The proposed GCIGNN-ENet framework classifies network traffic into Benign, Bot, Brute Force, DDoS, DoS, Heartbleed, Infiltration, Port Scan, and Web Attack. EfficientcoviNet replaces the causality-inspired layer in GCIGNN, and incorporating dense layers from ENetV2 for improved performance. Despite its capabilities, GCIGNN-ENet struggles to dynamically optimize security thresholds for cloud IoT systems. To address this, the Local Neighbour Spider Monkey Optimization (LNSMO) algorithm is employed to enhance the accuracy of classifiers and adaptability in predicting network security threats. The proposed DNS-EGCN CIOTD framework is implemented in Python and evaluated using performance metrics, like Accuracy, Precision, Recall, F-score, and Computational Time. The simulation results demonstrate that the DNS-EGCN CIOTD achieves 23.12 %, 21.23 %, and 21.32 % higher accuracy, 23.12 %, 21.23 % and 21.32 % higher recall and 23.54 %, 22.18 % and 23.65 % higher F-score when compared to the existing methods, such as Transfer Learning Method for IDS on Cloud IoT Devices utilizing Optimized CNN (TIDS-CIOT-CNN), Ranking Security of IoT-dependent Smart Home Consumer Devices (RS-IOT-SHCD), Rotating Behind Security: An Enhanced Authentication Protocol for IoT-enabled Devices in Distributed Cloud Computing Architecture (RSAP-IOTD-DCA).},
  archive      = {J_KBS},
  author       = {M. Baritha Begum and Yogeshwaran A and N.R. Nagarajan and P. Rajalakshmi},
  doi          = {10.1016/j.knosys.2024.112859},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112859},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic network security leveraging efficient CoviNet with granger causality-inspired graph neural networks for data compression in cloud IoT devices},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MsAD-LEC: Estimating large-scale brain effective connectivity network based on multi-subgraph attention diffusion. <em>KBS</em>, <em>309</em>, 112858. (<a href='https://doi.org/10.1016/j.knosys.2024.112858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating brain effective connectivity network from functional magnetic resonance imaging (fMRI) data is a key research topic in the fields of neurology and brain science, as this data can play an important role in early diagnosis of brain diseases. However, estimating a large-scale brain effective connectivity network from fMRI data remains challenging due to the high computational complexity and complex data distributions. In the present study, we proposed a novel method for estimating large-scale brain effective connectivity network based on multi-subgraph attention diffusion (MsAD-LEC). This method comprises two modules: a multi-resolution cluster-based subgraph partition module and an attention diffusion-based brain effective connectivity estimation module. In the partition module, a partial correlation analysis is first conducted to determine the conditional independent relationships among brain regions, to accurately construct an undirected causal skeleton. The method then applied the multi-resolution Louvain algorithm to partition the undirected causal skeleton into multiple subgraphs and cross-subgraph edges. This partition can transform a large-scale estimation problem into multiple smaller-scale estimation problems, thus reducing the overall computational complexity. In the estimation module, the method first applies forward diffusion to normalize the data distributions to address the data distribution shifts potentially caused by the preceding subgraph partition. The method then involves inverse diffusion with multi-head self-attention to capture long-term brain region dependencies, to accurately estimate subgraph and cross-subgraph effective connectivity, to obtain a large-scale brain effective connectivity network. Experimental results demonstrated that the MsAD-LEC can accurately estimate large-scale brain effective connectivity networks and scales in hundreds of brain regions.},
  archive      = {J_KBS},
  author       = {Junzhong Ji and Jingdong Fan and Jinduo Liu},
  doi          = {10.1016/j.knosys.2024.112858},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112858},
  shortjournal = {Knowl. Based Syst.},
  title        = {MsAD-LEC: Estimating large-scale brain effective connectivity network based on multi-subgraph attention diffusion},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guiding fusion of dynamic functional and effective connectivity in spatio-temporal graph neural network for brain disorder classification. <em>KBS</em>, <em>309</em>, 112856. (<a href='https://doi.org/10.1016/j.knosys.2024.112856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain connectivity pattern describes complex information in the brain network, which is widely applied for understanding brain connectome and diagnosing neurological diseases. Researchers have investigated brain network analysis using functional MRI (fMRI) from broadly two different perspectives: functional connectivity (FC), which relies on statistical independence and is typically evaluated using correlations, and effective connectivity (EC), which is based on directional causal influences among brain regions. Thus, the fusion of FC and EC can further extract more comprehensive information for characterizing brain abnormalities. However, most current brain network analysis methods focus on either FC or EC. To address this problem, we propose a novel Spatio-Temporal Graph Neural Network named as DCSTN to fuse dynamic functional and effective connectivity networks in the feature space, and construct brain network embeddings in a comprehensive manner. First, we introduce dynamic FCs and ECs to simultaneously model the brain network from different perspectives. Then, we employ message passing-based spatial graph convolution to analyze spatial characteristics of the brain network in discrete time segments. Finally, we introduce a novel fusion module based on a cross-attention mechanism, which incorporates continuous temporal information to extract brain embeddings for the purpose of identifying brain disorders. The whole framework utilizes the causal linkage of dynamic ECs during time evolution to guide the fusion of discrete FC networks. Qualitative and quantitative experimental results from public datasets validate the effectiveness of fusing FC and EC, and the proposed DCSTN outperforms state-of-the-art methods in different types of brain disorder classification.},
  archive      = {J_KBS},
  author       = {Dongdong Chen and Mengjun Liu and Sheng Wang and Zheren Li and Lu Bai and Qian Wang and Dinggang Shen and Lichi Zhang},
  doi          = {10.1016/j.knosys.2024.112856},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112856},
  shortjournal = {Knowl. Based Syst.},
  title        = {Guiding fusion of dynamic functional and effective connectivity in spatio-temporal graph neural network for brain disorder classification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of cognitive syndromes in a southeast asian population: Interpretable graph convolutional neural networks. <em>KBS</em>, <em>309</em>, 112855. (<a href='https://doi.org/10.1016/j.knosys.2024.112855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is a debilitating disease that afflicts a large population worldwide. Early diagnosis of cognitive impairment can allow for preventative measures to be taken to slow down or prevent the progression to dementia. In this study, we devise an interpretable graph convolutional neural network approach, GCNEnsemble, using both non-clinical variables such as MRI preprocessed features including cortical thickness and gray matter volumes, and clinical features from a community-dwelling Southeast Asian population in Singapore aged between 30 and 95 years from the Biomarker and Cognition study (BIOCIS), to classify participants into cognitively normal, subjective cognitive decline, and mild cognitive impairment. We further conducted ablation studies and varied the quantities of labeled data to understand the contribution of the non-clinical features and the applicability of GCNEnsemble in low to high labeled data availability scenarios. GCNEnsemble was able to attain the highest accuracy and Matthew's correlation coefficient compared to existing state-of-the-art methods. Feature interpretability via Integrated Gradients identified features such as visual cognitive assessment test (VCAT), systolic and diastolic blood pressure, and cerebrospinal fluid volume as key features for the classification, with VCAT having the highest feature importance. There was higher median cerebrospinal fluid volume, right frontal pole thickness, left pallidum volume, and right hippocampal fissure volume but lower VCAT for the mild cognitive impairment group than the two other groups. In conclusion, GCNEnsemble can be used as a semi-supervised interpretable classification tool for cognitive syndrome in a Southeast Asian population.},
  archive      = {J_KBS},
  author       = {Charlene Zhi Lin Ong and Ashwati Vipin and Yi Jin Leow and Pricilia Tanoto and Faith Phemie Hui En Lee and Smriti Ghildiyal and Shan Yao Liew and Yanteng Zhang and Asad Abu Bakar Ali and Jagath C Rajapakse and Nagaendran Kandiah},
  doi          = {10.1016/j.knosys.2024.112855},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112855},
  shortjournal = {Knowl. Based Syst.},
  title        = {Classification of cognitive syndromes in a southeast asian population: Interpretable graph convolutional neural networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-UNet: An effective multi-U convolutional networks for semantic segmentation. <em>KBS</em>, <em>309</em>, 112854. (<a href='https://doi.org/10.1016/j.knosys.2024.112854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {U-Net is a classic architecture for semantic segmentation. However, it has several limitations, such as difficulty in capturing complex images detail due to its simple U structure, long convergence time arising from fixed network parameters, and suboptimal efficacy in decoding and restoring multi-scale information. To deal with the above issues, we propose a Multiple U-shaped network (Multi-UNet) assuming that constructing appropriate U-shaped structure can achieve better segmentation performance. Firstly, inspired by the concept of connecting multiple similar blocks, our Multi-UNet consists of multiple U-block modules, with each succeeding module directly connected to the previous one to facilitate data transmission between different U structures. We refer to the original bridge connections of U-Net as Intra-U connections and introduce a new type of connection called Inter-U connections. These Inter-U connections aim to retain as much detailed information as possible, enabling effective detection of complex images. Secondly, while maintaining Mean Intersection over Union (Mean-IoU), the up-sampling of each U applies uniformly small channel values to reduce the number of model parameters. Thirdly, a Spatial-Channel Parallel Attention Fusion (SCPAF) module is designed at the initial layer of every subsampling module of U-block architecture. It enhances feature extraction and alleviate computational overhead associated with data transmission. Finally, we replace the final up-sampling module with Atrous Spatial Pyramid Pooling Head (ASPPHead) to accomplish seamless multi-scale feature extraction. Our experiments are compared and analyzed with advanced models on three public datasets, and it can be concluded that the universality and accuracy of Multi-UNet network are superior.},
  archive      = {J_KBS},
  author       = {Qiangwei Zhao and Jingjing Cao and Junjie Ge and Qi Zhu and Xiaoming Chen and Wenxi Liu},
  doi          = {10.1016/j.knosys.2024.112854},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112854},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-UNet: An effective multi-U convolutional networks for semantic segmentation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity hierarchical contrastive learning between foreground and background for semi-supervised video action detection. <em>KBS</em>, <em>309</em>, 112853. (<a href='https://doi.org/10.1016/j.knosys.2024.112853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised video action detection has received increasing attention due to its lower data annotation cost and performance comparable to fully supervised methods. However, due to the presence of dynamic background regions in the video, existing methods may encounter biases when interpreting the foreground and background of the video. This bias causes the model to mistakenly identify dynamic background areas as action foregrounds or to overlook background information, leading to misjudgment of the foreground. In response to this issue, this paper proposes a multi-granularity hierarchical contrastive learning between foreground and background for semi-supervised video action detection method termed as Multi-FB. Specifically, this paper proposes a multi-granularity encoding network based on foreground and background. This network uses a unified encoder to represent and learn foreground and background regions in videos at different granularities, thereby improving the model's understanding of action foreground and related background. Secondly, this paper proposes an Intra-model multi-granularity hierarchical contrastive strategy, which aims to minimize the representation discrepancies of foreground-to-foreground and background-to-background at different granularities within the same video, while maximizing the representation differences between the foreground and background at various granularities within the video. Furthermore, this paper proposes a Cross-model multi-granularity hierarchical contrastive strategy, which aims to enhance the consistency of the model's representations of foregrounds and backgrounds between the original data and the augmented data. A large number of experimental results on JHMDB-21 and UCF101–24 show that the proposed method can significantly distinguish feature representations between different categories, achieving performance comparable to state-of-the-art methods under semi-supervised conditions.},
  archive      = {J_KBS},
  author       = {Qiming Zhang and Zhengping Hu and Yulu Wang and Hehao Zhang and Jirui Di},
  doi          = {10.1016/j.knosys.2024.112853},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112853},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granularity hierarchical contrastive learning between foreground and background for semi-supervised video action detection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGCNet: Multiple group-wise correlation network with hierarchical contrastive learning for co-salient object detection. <em>KBS</em>, <em>309</em>, 112852. (<a href='https://doi.org/10.1016/j.knosys.2024.112852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-salient object detection (CoSOD) aims to discover common salient objects from a group of relevant images. Existing methods typically extract inter-image correspondences in one or two image groups, which could limit the ability of model to learn high-quality representations. To overcome this limitation, we propose a novel multiple group-wise correlation network (MGCNet), which thoroughly learns inter-image relations by simultaneously processing positive and negative samples among four image groups. Initially, to enhance the discriminative capability of model, we introduce the multi-level contrastive learning module (MCLM), which pulls positive sample pairs closer and pushes negative sample pairs farther at both the global and local levels by applying contrastive learning. Subsequently, to enhance consensus features more comprehensively, we propose the dual enhancement module (DEM), which sufficiently explores both the channel and spatial dimensions in a two-stage manner. Finally, to retain the integrity of the consensus features, we design the consensus retaining module (CRM), which effectively fuses neighboring level features to complement the location information within the consensus features. Extensive experiments on three challenging benchmark datasets demonstrate that our MGCNet achieves excellent performance compared to 17 state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Xian Fang and Xin Wang and Jinchao Zhu and Qiaohong Chen and Zuofan Chen},
  doi          = {10.1016/j.knosys.2024.112852},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112852},
  shortjournal = {Knowl. Based Syst.},
  title        = {MGCNet: Multiple group-wise correlation network with hierarchical contrastive learning for co-salient object detection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MICD: More intra-class diversity in few-shot text classification with many classes. <em>KBS</em>, <em>309</em>, 112851. (<a href='https://doi.org/10.1016/j.knosys.2024.112851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has gained much interest and achieved remarkable performance in handling limited data scenarios. However, existing few-shot text classification methods typically aim at classifying a limited number of classes, usually ranging from 5 to 10, posing a challenge for many real-world tasks that require few-shot text classification for many classes. Few-shot text classification for many classes has rarely been studied and it is a challenging problem. Distinguishing differences among many classes is more challenging than distinguishing differences among small classes. To address this issue, we propose a new few-shot text classification model for many classes called MICD (More Intra-Class Diversity in few-shot text classification with many classes). Our model comprises two crucial components: Intra-Class Diversity Contrastive Learning (ICDCL) and Intra-Class Augmentation (ICA). ICDCL trains an encoder to enhance feature discriminability by maintaining both intra-class diversity and inter-class specificity, effectively improving generalization performance, even when data is limited. ICA addresses data scarcity by selecting diverse support samples and applying intra-class mix-up, enabling robust generalization to out-of-distribution data—an essential consideration in many-class few-shot learning scenarios. Experimental results on four real datasets show that MICD provides significant performance improvement over the other state-of-the-art approaches.},
  archive      = {J_KBS},
  author       = {Gwangseon Jang and Hyeon Ji Jeong and Mun Yong Yi},
  doi          = {10.1016/j.knosys.2024.112851},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112851},
  shortjournal = {Knowl. Based Syst.},
  title        = {MICD: More intra-class diversity in few-shot text classification with many classes},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedFM: A federated few-shot learning method by comparison network and model calibration. <em>KBS</em>, <em>309</em>, 112848. (<a href='https://doi.org/10.1016/j.knosys.2024.112848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a flexible and efficient approach for leveraging distributed data through parameter upload and aggregation. However, the practical applicability of current FL methodologies is constrained by issues such as label scarcity and client heterogeneity. (1) Label scarcity arises from users lacking the capability or willingness to annotate local data. This constraint results in inadequately trained models and obstructs the inference phase in FL. (2) Client heterogeneity stems from the asynchronous update mechanism of shared models. The server calculates a weighted average of the parameters uploaded by participating clients, overlooking the training variations and model-calibration differences among them. Herein, we present a novel federated few-shot learning framework called federated few-shot and model-calibration to address the above challenges. Initially, we use strong data augmentation to improve feature extraction efficiency and train the comparison network that maps unlabeled data into labels of a labeled support set, eliminating the necessity for fine-tuning to accommodate new class types. In addition, the inherent heterogeneity of data across multiple clients poses a challenge that frequently results in performance deterioration. To address this issue, we propose a model-calibration update method that aggregates model parameters weighted by the expected calibration errors obtained using local models. Compared with existing FL approaches, our method achieves improved one-shot classification accuracy from 85.42% to 92.61% and from 42.85% to 47.92% on the Omniglot and Mini-ImageNet datasets, respectively. In addition to providing improved performance on few-shot learning and privacy preservation, our method can be easily extended to zero-shot learning.},
  archive      = {J_KBS},
  author       = {Chen Zhao and Shudi Bao and Meng Chen and Zhipeng Gao and Kaile Xiao and Peng Dai},
  doi          = {10.1016/j.knosys.2024.112848},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112848},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedFM: A federated few-shot learning method by comparison network and model calibration},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive representation-aligned modeling for visual tracking. <em>KBS</em>, <em>309</em>, 112847. (<a href='https://doi.org/10.1016/j.knosys.2024.112847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate object representations and reliable object states are essential for robust visual tracking. While current Transformer-based trackers employ symmetric and asymmetric attention mechanisms to learn object representations, they often overlook attention discrepancies caused by the target object and distractors between the template and search region. These discrepancies can lead to the inclusion of distractors, which degrade the quality of the learned representations. To address this issue, we propose ARATrack, an adaptive representation-aligned tracker. Specifically, we present a representation-aligned attention (RAA) mechanism, which adaptively refines object representations through a novel attention alignment strategy. This strategy ensures consistent attention between the template and search region, while minimizing interference from distractors. Furthermore, to handle dynamic changes in object states, we propose a state-aware head. This module continuously updates the object state using the refined representations, enhancing the tracker’s resilience to appearance changes and improving its stability in diverse and challenging conditions. Together, these components work synergistically, offering mutual guidance to ensure that ARATrack delivers stable, reliable, and high-performance visual tracking. Extensive experiments on six benchmark datasets demonstrate that ARATrack outperforms other state-of-the-art trackers, achieving competitive performance across a diverse range of tracking scenarios. Our code is publicly available at https://github.com/nubsym/ARATrack .},
  archive      = {J_KBS},
  author       = {Yumei Sun and Tao Wu and Xiaoming Peng and Meihui Li and Dongxu Liu and Yunfeng Liu and Yuxing Wei and Jianlin Zhang},
  doi          = {10.1016/j.knosys.2024.112847},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112847},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive representation-aligned modeling for visual tracking},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation with temporal ensembling to local attention region search for object detection. <em>KBS</em>, <em>309</em>, 112846. (<a href='https://doi.org/10.1016/j.knosys.2024.112846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection relies heavily on supervised learning, which requires labeled data for training. However, manual labeling often cannot keep pace with the speed of data collection, and models trained on one dataset may not generalize well to new datasets with different characteristics, leading to domain shift issues. Domain adaptation addresses this problem by leveraging labeled data from a source domain and unlabeled data from a target domain to improve performance on the target domain. Limited by the existing domain adaption architecture, the object detection accuracy in the target domain has much room for improvement. In addition, the global search of feature maps costs too much computation. All these problems make it difficult for domain adaptive object detection to be directly applied to tasks such as medical imaging. To this end, this article proposes two architectures: Region-based Object Detection with Domain Adaptation and Temporal Ensembling (DATE) and Local Attention Region Search Algorithm (LARSA). DATE combines domain adaptation and temporal ensembling to enhance feature alignment between domains. At the same time, LARSA employs an attention mechanism to efficiently search for regions of interest and decide when to terminate the search early. Experiments on various datasets demonstrate the effectiveness of the proposed approaches in improving object detection performance under domain shift and reducing computational cost. The proposed framework has the potential to further promote the application of object detection in the field of medical imaging.},
  archive      = {J_KBS},
  author       = {Haobin Shi and Ziming He and Kao-Shing Hwang},
  doi          = {10.1016/j.knosys.2024.112846},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112846},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain adaptation with temporal ensembling to local attention region search for object detection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KoSEL: Knowledge subgraph enhanced large language model for medical question answering. <em>KBS</em>, <em>309</em>, 112837. (<a href='https://doi.org/10.1016/j.knosys.2024.112837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of medical knowledge graphs (KGs) and large language models (LLMs) for medical question answering (Q&A) has attracted considerable interest in recent studies. However, current approaches that combine KGs and LLMs tend to either integrate KGs directly into the fine-tuning process of LLMs or use entire KGs as a contextual prompt base for LLMs to reason, raising concerns regarding potential data leakage and reasoning confusion. In this study, we propose KoSEL ( K n o wledge S ubgraph E nhanced L arge Language Model), a novel medical Q&A framework based on KG-enhanced LLMs. KoSEL comprises two modules: Knowledge Retrieval (KR) and Reasoning and Answering (RA). The KR module is LLM-independent and employs an entity-linking algorithm and a subgraph construction and fusion strategy to retrieve question-relevant knowledge. The RA module conveys prompts to the LLM for information extraction, knowledge fusion, reasoning, and answer generation. KoSEL, which is designed as a plug-and-play framework, effectively fuses structural and textual knowledge while ensuring efficiency and privacy. The construction of a precise and refined subgraph reduces knowledge noise and the number of input graph tokens, thus mitigating hallucination issues. Extensive experiments demonstrated that KoSEL outperformed advanced methods in terms of knowledge retrieval efficiency (20.27% reduction in retrieval time), knowledge utilization (15.16% increase in utilization rate), and data protection (113.50% reduction in data leakage rate), resulting in higher-quality answers for medical Q&A tasks (1.50% improvement in answer score).},
  archive      = {J_KBS},
  author       = {Zefan Zeng and Qing Cheng and Xingchen Hu and Yan Zhuang and Xinwang Liu and Kunlun He and Zhong Liu},
  doi          = {10.1016/j.knosys.2024.112837},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112837},
  shortjournal = {Knowl. Based Syst.},
  title        = {KoSEL: Knowledge subgraph enhanced large language model for medical question answering},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A CNN-based fault diagnosis method of multi-function integrated RF system using frequency domain scanning with lasso regression. <em>KBS</em>, <em>309</em>, 112836. (<a href='https://doi.org/10.1016/j.knosys.2024.112836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-function Integrated RF System (MIRFS) is a key unit for improving the reliability and safety of advanced aircraft. Single-frequency point data are easily affected by various interferences and noises resulting in unreliable and insufficient information. To reduce the low fault diagnosis rate caused by this effect, a novel fault diagnosis method is proposed based on frequency domain scanning and Lasso regression in this paper. Firstly, performance parameter sequences under each fault condition are extracted using frequency domain scanning. By extracting the performance parameters of a specific frequency band as raw fault data, the reliability of the data is greatly increased. Secondly, Lasso regression prioritizes the performance parameter sequences according to their correlation with faults. This approach selects the optimal performance parameter sequences as the data source for fault diagnosis, resolving the issue of excessively high dimensions in fault data. Finally, convolutional neural networks (CNNs) achieve precise fault diagnosis for both soft and hard faults. The results confirm that the proposed method overcomes the low distinguishability of fault states for both single frequency point data and sequence feature data. Compared with diagnostic models using sequence feature data as datasets, the diagnostic accuracy for hard faults increased by 7.92 %, and for soft faults by 5.34 %.},
  archive      = {J_KBS},
  author       = {Chao Zhang and Feng Wang and Dingyu Zhou and Zhijie Dong and Shilie He and Zhenwei Zhou},
  doi          = {10.1016/j.knosys.2024.112836},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112836},
  shortjournal = {Knowl. Based Syst.},
  title        = {A CNN-based fault diagnosis method of multi-function integrated RF system using frequency domain scanning with lasso regression},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSeg: A novel multi-task learning framework for class imbalance and label scarcity in medical image segmentation. <em>KBS</em>, <em>309</em>, 112835. (<a href='https://doi.org/10.1016/j.knosys.2024.112835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised medical image segmentation can effectively alleviate the high costs associated with obtaining high-quality labels and issues related to data privacy. However, the issue of imbalance in medical images limits the practical application of semi-supervised frameworks. One of the core principles of semi-supervised learning is to infer and predict by learning data distributions. Since unlabeled samples lack explicit class information, both inter-class and intra-class imbalances in the regions of interest can undermine the training core of this framework. To alleviate these issues, we propose a segmentation framework based on multi-task learning, which integrates both self-supervised and semi-supervised learning components within the multi-task framework. In the self-supervised component, we utilize four sub-tasks to extract the internal structure and features of images from unlabeled data, aimed at mitigating the imbalance issues in regions of interest. In the semi-supervised learning component, we employ a segmentation network with a teacher–student model structure that effectively generates high-confidence pseudo-labels from unlabeled data, thereby enhancing the model’s ability to recognize minority classes. To maintain the robustness of the model, we introduce a progressive learning strategy and a dynamic weight adjustment mechanism to prevent feature representation bias caused by varying task difficulties. Experimental results indicate that our proposed method achieved the best performance in extensive experiments on two abdominal multi-organ segmentation tasks, outperforming other competitive methods. Codes are available at https://github.com/ReinforceLove/MMSeg .},
  archive      = {J_KBS},
  author       = {Feiyang Yang and Xiongfei Li and Bo Wang and Tianyang Zhang and Xinyi Yu and Xingcheng Yi and Rui Zhu},
  doi          = {10.1016/j.knosys.2024.112835},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112835},
  shortjournal = {Knowl. Based Syst.},
  title        = {MMSeg: A novel multi-task learning framework for class imbalance and label scarcity in medical image segmentation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity ensemble interaction graph modeling for knowledge tracing. <em>KBS</em>, <em>309</em>, 112834. (<a href='https://doi.org/10.1016/j.knosys.2024.112834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) is a crucial educational tool that models students’ mastery of various knowledge concepts by analyzing their historical learning records. Mainstream studies have turned to Deep Neural Networks (DNNs) to effectively trace students’ knowledge states. Nonetheless, these methods may encounter performance barriers due to two critical constraints: the treatment of learning records as singular time series data and the absence of accounting for interaction correlations. To overcome the limitations, we introduce a novel KT model, named M ulti- G ranularity Ensemble I nteraction G raph Modeling for K nowledge T racing (MGIGKT). Our model incorporates two modules designed to model students’ knowledge states from the perspectives of temporal perception and interaction dependency, respectively. This approach allows for a more comprehensive understanding of students’ learning dynamics and the correlations between their interactions. We have conducted extensive experiments on four datasets to evaluate the superiority and effectiveness of our proposed MGIGKT model. The results of these experiments provide empirical evidence of the model’s enhanced ability to trace students’ knowledge states accurately.},
  archive      = {J_KBS},
  author       = {Jing Wang and Huifang Ma and Mengyuan Zhang and Lei Zhang and Liang Chang},
  doi          = {10.1016/j.knosys.2024.112834},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112834},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-granularity ensemble interaction graph modeling for knowledge tracing},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex network structural analysis based on information supplementation graph contrastive learning. <em>KBS</em>, <em>309</em>, 112833. (<a href='https://doi.org/10.1016/j.knosys.2024.112833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has garnered significant interest in analyzing complex network architectures, including node and network classifications. In this context, current contrastive learning methods often create different views by removing nodes or features through data augmentation. These methods apply contrastive learning between these views to derive representations of nodes or networks for downstream tasks. However, these methods may not effectively use the information contained in the discarded nodes or features. This paper proposes a contrastive learning framework based on information supplementation for graph structure analysis that aligns with information theory. The study introduces two enhanced graph contrastive learning methods: the first for information compensation and the second for information completion. Then, we applied graph and node classification methods in network structure analysis. Experimental results demonstrate that the contrastive learning method based on the information supplementation framework outperforms existing methods in subsequent tasks. These results validate the effectiveness of contrastive learning with information supplementation.},
  archive      = {J_KBS},
  author       = {Biao Cai and Jian Wang and Xiaochuan Tang and Xu Li and Nengbin Hu and Yanmei Hu and Mingzhe Liu and Qiang Miao},
  doi          = {10.1016/j.knosys.2024.112833},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112833},
  shortjournal = {Knowl. Based Syst.},
  title        = {Complex network structural analysis based on information supplementation graph contrastive learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional generation model with dual-perspective feature fusion representation for multi-label classification. <em>KBS</em>, <em>309</em>, 112832. (<a href='https://doi.org/10.1016/j.knosys.2024.112832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data representation significantly affects the performance of multi-label classification models, with research showing that constructing and utilizing label-related representations can enhance model effectiveness. Existing methods typically construct these representations by projecting feature vectors and sparse label vectors into a shared latent space and aligning them, but they overlook the semantic information within labels. Moreover, they commonly model label-related representations as deterministic vectors. In contrast, probabilistic latent variable modeling tends to capture richer information and improve model robustness. In light of these observations, this paper proposes a variational inference framework for constructing and leveraging informative label-related representations, presenting a deep conditional generative model for multi-label classification built upon this framework. Specifically, label-related representations are formulated as two variables within a probabilistic latent space from the dual perspectives of label semantics and feature priors, with KL divergence used to align their posterior and prior distributions. The two variables are then fused to enhance feature representation, which is subsequently fed into a generator to model the conditional label distribution. Extensive experiments demonstrate that the proposed method outperforms other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xiaozhen Fu and Deyu Li and Erliang Yao and Yuhua Qian and Yang Li and Suge Wang},
  doi          = {10.1016/j.knosys.2024.112832},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112832},
  shortjournal = {Knowl. Based Syst.},
  title        = {Conditional generation model with dual-perspective feature fusion representation for multi-label classification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A weighted semi-supervised possibilistic fuzzy c-means algorithm for data stream classification and emerging class detection. <em>KBS</em>, <em>309</em>, 112831. (<a href='https://doi.org/10.1016/j.knosys.2024.112831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Possibilistic fuzzy c -means is a widely used fuzzy clustering algorithm. This algorithm is capable of handling outlier data points, rendering it a viable option for maintaining a data stream classification model in scenarios where novel classes may emerge. On the other hand, most of the real-world data stream applications suffer from label scarcity, highlighting the crucial need for the utilization of semi-supervised models. Accordingly, in this paper, a W eighted S emi-supervised P ossibilistic F uzzy c ̲ - M eans algorithm, called WSPFCM-DS is proposed for D ata S tream classification and novel class detection. Firstly, a weighted semi-supervised possibilistic fuzzy c -means objective function is formulated, which weights the contribution degree of membership and typicality values of each sample in relation to each cluster. Secondly, the proposed objective function variables are redesigned to work incrementally when handling data streams. The concept drift phenomenon is handled by iteratively updating the clustering structure, and the novel classes are detected based on the typicality measures calculated by the WSPFCM. Theoretical analysis of the proposed objective function is presented, along with comprehensive experimental analysis on its application for non-stationary data streams. The experimental analysis performed on various synthetic and real-world datasets proves the significant performance of the proposed algorithm regarding the non-stationary data streams.},
  archive      = {J_KBS},
  author       = {Negin Samadi and Jafar Tanha and Mahdi Jalili},
  doi          = {10.1016/j.knosys.2024.112831},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112831},
  shortjournal = {Knowl. Based Syst.},
  title        = {A weighted semi-supervised possibilistic fuzzy c-means algorithm for data stream classification and emerging class detection},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive random tree ensemble for evolving data stream classification. <em>KBS</em>, <em>309</em>, 112830. (<a href='https://doi.org/10.1016/j.knosys.2024.112830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream mining with concept drift is a significant challenge in machine learning because this scenario requires the ability to handle unlimited and ever-changing data and real-time processing. An often employed strategy in data stream mining involves utilizing ensembles due to their capability to tackle concept drift and attain remarkably accurate predictions. However, developing a precise and efficient ensemble for data stream mining poses a significant challenge, as state-of-the-art algorithms are often highly inefficient, consuming excessive memory and processing time. In this study, we propose a novel ensemble-based classification algorithm for data streams named Adaptive Random Tree Ensemble (ARTE). The algorithm explores approaches that promote high prediction accuracy using a random-sized feature subspace for each element of the ensemble, online bagging, random choice of the cut-point for splitting the trees, and a method of classifier selection for final ensemble voting. This study also presents analyses on the contribution of the choice of subspace size and the random cut-point for splitting the tree’s nodes to the ensemble’s diversity. Following an extensive experimental investigation, ARTE exhibited high predictive performance and outperformed state-of-the-art ensembles on data streams for real and synthetic datasets while requiring fewer computational resources.},
  archive      = {J_KBS},
  author       = {Aldo M. Paim and Fabrício Enembreck},
  doi          = {10.1016/j.knosys.2024.112830},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112830},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive random tree ensemble for evolving data stream classification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fully decentralized distributed learning algorithm for latency communication networks. <em>KBS</em>, <em>309</em>, 112829. (<a href='https://doi.org/10.1016/j.knosys.2024.112829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network-induced delay phenomenon has always been one of the bottlenecks in the practical application of distributed learning (DL) algorithms. This paper aims to explore a novel fully decentralized DL algorithm based on the zero-gradient-sum (ZGS) strategy for latency networks, called TDDL (Time Delay Distributed Learning) algorithm. Compared with previous related works, the main challenge is to make the performance of DL algorithm free from the influence of latency in communication networks when applied to real-world scenarios. Specifically, modeled as a distributed optimization problem for latency networks, the distributed learning problem is solved by the improved discrete-time ZGS algorithm. Furthermore, the convergence of the TDDL algorithm is analyzed by constructing a Lyapunov–Krasovskii functional. And we theoretically derive an upper bound on the time delay, which ensures that the TDDL algorithm for latency communication network promotes all agents to cooperatively converge as a sufficient condition. More importantly, the proposed algorithm benefits privacy protection in latency networks in a fully decentralized distributed manner. In other words, each agent only exchanges information with neighboring agents, and model parameters rather than raw data are merely transmitted. Finally, several experiments are given to illustrate the effectiveness of the TDDL algorithm.},
  archive      = {J_KBS},
  author       = {Yutian Wei and Jin Xie and Weifeng Gao and Hong Li and Ling Wang},
  doi          = {10.1016/j.knosys.2024.112829},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112829},
  shortjournal = {Knowl. Based Syst.},
  title        = {A fully decentralized distributed learning algorithm for latency communication networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTSFormer: Decoupled temporal-spatial diffusion transformer for enhanced long-term time series forecasting. <em>KBS</em>, <em>309</em>, 112828. (<a href='https://doi.org/10.1016/j.knosys.2024.112828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have significantly advanced long-term time series forecasting by leveraging self-attention mechanisms to capture long-term dependencies. However, these models face high computational costs, slow inference speeds, and limitations in utilizing information from longer lookback windows. Additionally, existing methods often neglect implicit spatial dependencies between variables, and struggle with semantic misalignment and insufficient diffusion of spatial information. To address these challenges, we propose DTSFormer, a D ecoupled T emporal- S patial Diffusion Transformer designed specifically for long-term time series forecasting: (1) DTSFormer effectively integrates temporal features with implicit spatial attributes, ensuring comprehensive utilization of both temporal and spatial information. (2) DTSFormer introduce a Mix-hop Diffusion layer to effectively propagate and aggregate spatial information while preserving the original graph structure, significantly improving the accuracy of spatial information dissemination. (3) we develop a cross-diffusion attention mechanism based on the Expectation-Maximization algorithm, which integrates graph structure information with varying semantics under a seasonal trend decomposition framework. This approach enhances the fusion of semantic information from different graph structures and reduces computational complexity. Our extensive experiments on multiple benchmark datasets across different domains demonstrate that DTSFormer consistently achieves state-of-the-art performance in both accuracy and efficiency. These results validate DTSFormer as a robust and scalable solution for advanced long-term time series forecasting tasks.},
  archive      = {J_KBS},
  author       = {Jiaming Zhu and Dezhi Liu and Huayou Chen and Jinpei Liu and Zhifu Tao},
  doi          = {10.1016/j.knosys.2024.112828},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112828},
  shortjournal = {Knowl. Based Syst.},
  title        = {DTSFormer: Decoupled temporal-spatial diffusion transformer for enhanced long-term time series forecasting},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). R-VQA: A robust visual question answering model. <em>KBS</em>, <em>309</em>, 112827. (<a href='https://doi.org/10.1016/j.knosys.2024.112827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) involves generating answers to questions about visual content, such as images. VQA models process an image and a question to produce an answer. One major challenge in this domain is robustness, as current VQA models often operate within a fixed answer space and struggle with issues related to language prior (favoring frequent answers) and compositional reasoning (difficulty with complex object relationships). While existing research addresses these challenges separately, no work has tackled both language prior and compositional reasoning simultaneously. This paper presents three key contributions: the development of a dataset specifically designed to address language prior and compositional reasoning issues, the creation of a unified model capable of addressing both problems in a single inference, and the ability to generate answers beyond a predefined answer space. Our proposed model, R-VQA, demonstrates superior performance compared to state-of-the-art (SOTA) models across various VQA datasets.},
  archive      = {J_KBS},
  author       = {Souvik Chowdhury and Badal Soni},
  doi          = {10.1016/j.knosys.2024.112827},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112827},
  shortjournal = {Knowl. Based Syst.},
  title        = {R-VQA: A robust visual question answering model},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The mitigation of heterogeneity in temporal scale among different cortical regions for EEG emotion recognition. <em>KBS</em>, <em>309</em>, 112826. (<a href='https://doi.org/10.1016/j.knosys.2024.112826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroscience studies suggest that, as high-level cognitive processes, various emotional states will lead to cooperative activation among different cortical regions, which process information across diverse temporal scales. However, such heterogeneity existing in temporal scales adopted by different cortical regions is seldom fully considered in the conventional EEG emotion recognition models. To solve this problem, first, the Deep-Wise Separable Convolution (DWSC) is modified to obtain Modified DWSC (MDWSC), and the multi-scale temporal features are extracted from each EEG channel with MDWSCs of different kernel sizes. Next, Coordinate Attention (CA) is introduced to utilize the fused multi-scale temporal feature to optimize the local spatial feature by reducing the heterogeneity existing in the temporal scale among cortical regions. Then, the Graph Convolution Network (GCN) and the Retention Transformer are introduced to grasp the global spatial information contained in the optimized local spatial feature and achieve gradual integration of information across time to capture the global temporal feature, respectively. Finally, the global spatial feature is fused with the integrated temporal feature for emotion recognition. Extensive experimental results under both subject-dependent and subject-independent scenarios on DEAP, DREAMER, and PhyMER datasets demonstrate that: (i) The proposed model outperforms State-Of-The-Art (SOTA) EEG-based emotion recognition baselines. (ii) All the key modules contribute to the performance enhancement of the proposed model. (iii) The proposed model can take full advantage of the complementarities among different features organically to enhance emotion recognition performance.},
  archive      = {J_KBS},
  author       = {Zhangyong Xu and Ning Chen and Guangqiang Li and Jing Li and Hongqing Zhu and Zhiying Zhu},
  doi          = {10.1016/j.knosys.2024.112826},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112826},
  shortjournal = {Knowl. Based Syst.},
  title        = {The mitigation of heterogeneity in temporal scale among different cortical regions for EEG emotion recognition},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDR-GNN: Spectral domain reconstruction graph neural network for incomplete multimodal learning in conversational emotion recognition. <em>KBS</em>, <em>309</em>, 112825. (<a href='https://doi.org/10.1016/j.knosys.2024.112825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Emotion Recognition in Conversations (MERC) aims to classify utterance emotions using textual, auditory, and visual modal features. Most existing MERC methods assume each utterance has complete modalities, overlooking the common issue of incomplete modalities in real-world scenarios. Recently, graph neural networks (GNNs) have achieved notable results in Incomplete Multimodal Emotion Recognition in Conversations (IMERC). However, traditional GNNs focus on binary relationships between nodes, limiting their ability to capture more complex, higher-order information. Moreover, repeated message passing can cause over-smoothing, reducing their capacity to preserve essential high-frequency details. To address these issues, we propose a Spectral Domain Reconstruction Graph Neural Network (SDR-GNN) for incomplete multimodal learning in conversational emotion recognition. SDR-GNN constructs an utterance semantic interaction graph using a sliding window based on both speaker and context relationships to model emotional dependencies. To capture higher-order and high-frequency information, SDR-GNN utilizes weighted relationship aggregation, ensuring consistent semantic feature extraction across utterances. Additionally, it performs multi-frequency aggregation in the spectral domain, enabling efficient recovery of incomplete modalities by extracting both high- and low-frequency information. Finally, multi-head attention is applied to fuse and optimize features for emotion recognition. Extensive experiments on various real-world datasets demonstrate that our approach is effective in incomplete multimodal learning and outperforms current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fangze Fu and Wei Ai and Fan Yang and Yuntao Shou and Tao Meng and Keqin Li},
  doi          = {10.1016/j.knosys.2024.112825},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112825},
  shortjournal = {Knowl. Based Syst.},
  title        = {SDR-GNN: Spectral domain reconstruction graph neural network for incomplete multimodal learning in conversational emotion recognition},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixing corrupted preferences for robust and feedback-efficient preference-based reinforcement learning. <em>KBS</em>, <em>309</em>, 112824. (<a href='https://doi.org/10.1016/j.knosys.2024.112824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference-based reinforcement learning (RL) trains agents using non-expert feedback without the need for detailed reward design. Human teacher guides the agent by comparing two behavior trajectories and labeling the preference. Although recent studies improved feedback efficiency through methods like unsupervised exploration and self- or semi-supervised learning, they often assume flawless human annotation. In practice, human teachers might make mistakes or have conflicting opinions on trajectory preferences, posing a challenge in capturing user intent. To address this, we introduce mixing corrupted preferences (MCP) for robust and feedback-efficient preference-based RL. Inspired by the robustness of mixup against corrupted labels, MCP offers three key advantages. Firstly, by component-wise mixing of two labeled preferences, MCP mitigates the impact of corrupted feedback, enhancing robustness. Secondly, MCP improves feedback efficiency by generating unlimited new data even with limited labeled feedback. Lastly, MCP helps regulate overconfidence in preference predictor, moderating excessive reward divergence between two trajectories. We evaluate our method on three locomotion and six robotic manipulation tasks in B-Pref benchmark, in contexts with both perfectly rational and imperfect teachers (including actual human teachers). Our results show that MCP significantly outperforms PEBBLE, requiring fewer feedback instances and a shorter training period, highlighting its superior feedback efficiency. Our code is available at https://github.com/JongKook-Heo/MCP .},
  archive      = {J_KBS},
  author       = {Jongkook Heo and Young Jae Lee and Jaehoon Kim and Min Gu Kwak and Young Joon Park and Seoung Bum Kim},
  doi          = {10.1016/j.knosys.2024.112824},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112824},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mixing corrupted preferences for robust and feedback-efficient preference-based reinforcement learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic human motion prediction using a quantized conditional diffusion model. <em>KBS</em>, <em>309</em>, 112823. (<a href='https://doi.org/10.1016/j.knosys.2024.112823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction is a fundamental task in computer vision, aiming to forecast future human poses based on observed motion sequences. Existing deterministic methods generate a single future motion sequence, neglecting the inherent stochasticity and diversity of human behaviors. To address this limitation, we propose a novel two-stage stochastic human motion prediction framework, termed the Quantized Conditional Diffusion Model (QCDM), which combines a Discrete Motion Quantization Module and a Conditional Motion Generation Module. Specifically, we first design a discrete motion quantization module that leverages Graph Convolutional Networks (GCNs) and one-dimensional temporal convolutions to encode motion sequences into continuous latent representations. These representations are then quantized into discrete latent variables using a learnable codebook. A decoder reconstructs the motion sequence from these discrete variables, preserving key motion patterns while eliminating redundancies. Next, we develop a conditional motion generation module that integrates GCNs and Transformers for denoising spatio-temporal features. The diffusion process iteratively refines noisy motion data by reversing a gradual noising procedure, modeling the distribution of plausible future motions. Action category information and observed historical motion segments are incorporated as conditions into the denoising process, enabling controllable generation of specific motions. Additionally, we introduce a diversity enhancement strategy by penalizing overly similar samples. This encourages the model to explore a wider range of plausible motions and thereby improving the diversity and richness of the prediction results. Extensive experiments demonstrate that the QCDM framework outperforms state-of-the-art methods in stochastic human motion prediction tasks, offering both accuracy and diversity in generated motion sequences.},
  archive      = {J_KBS},
  author       = {Biaozhang Huang and Xinde Li and Chuanfei Hu and Heqing Li},
  doi          = {10.1016/j.knosys.2024.112823},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112823},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stochastic human motion prediction using a quantized conditional diffusion model},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node classification based on structure migration and graph attention convolutional crossover network. <em>KBS</em>, <em>309</em>, 112813. (<a href='https://doi.org/10.1016/j.knosys.2024.112813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the sparse structure of graph and GCN (Graph Convolutional Networks) does not consider neighbor node specificity, graph nodes are over-smoothed after passing through the GCN network, especially when the number of network layers increases. Meanwhile GCN cannot propagate over a wide range and capture long-range information. To solve the above problems, this paper proposes a node classification algorithm based on Structure Migration and Graph Attention CoNvolutional crossover network (SM_GACN). Firstly, a Pearson-adjacent structure migration method based on attribute correlation and first-hop neighborhood sparsity is proposed. By measuring Pearson coefficient between the attribute vectors of unlabeled and labeled nodes, the most relevant labeled nodes with unlabeled nodes are selected. And then by comparing the sparsity of the first-hop neighborhoods of the two nodes, this method determines whether or not to perform structure migration on this unlabeled node. Secondly, a graph attention convolutional crossover network based on graph attention and graph convolution is designed. This network extracts features by alternating graph attention and graph convolution layer, and then completes one linear mapping by graph convolution layer. Finally, a combine-training method based on inductive learning is constructed. The original structure graph is combine-trained with the migrated structure graph, and the GCN with the crossover network, which incorporates inductive learning. Comparing with eleven algorithms on four datasets, the experimental results show that SM_GACN has higher classification performance on the graph node classification task.},
  archive      = {J_KBS},
  author       = {Ruolin Li and Chi Wang and Ronghua Shang and Weitong Zhang and Songhua Xu},
  doi          = {10.1016/j.knosys.2024.112813},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112813},
  shortjournal = {Knowl. Based Syst.},
  title        = {Node classification based on structure migration and graph attention convolutional crossover network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CDNA-CCS: Splitting and compression based chaotic-DNA cryptography framework for cloud computing security. <em>KBS</em>, <em>309</em>, 112812. (<a href='https://doi.org/10.1016/j.knosys.2024.112812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-computing security is a topic of ongoing research, however, when it comes to data sharing, the main disadvantage is that different users may have data overlap because multiple users save their data on cloud servers. So, the proposed work is to create an improved Cloud Computing Security (CSS) model to protect the data from different threats and reduce overlapping possibilities. SHA-512/256 is designed to produce a fixed-length hash from the user identity data. Further, the data is compressed using Deflate compression, thus reducing the storage space consumption by reducing the byte size. Then, the data are moved to encryption processing; here, hybrid Chaotic-DNA (CDNA) encryption is utilized for encryption purposes. In the Chaotic-DNA process, the data are encrypted based on chaotic workflow, but for an effective security process, a DNA-based key generation is provided. According to the data's level of sensitivity, the key for the hybrid encryption scheme was generated by a trusted centre in the cloud. If the user wants to access the stored data from the cloud system, they must cross four authentication barriers: password, user ID, OTP and fingerprint. The proposed model provides a 98% security level and a 2-second authentication process. For evaluating the proposed-model under various data like image data, text data and integer data. In that image, data takes 90 sec for encryption and 0.18 sec for decryption time, text data takes 149 sec for encryption and 0.69 sec for decryption time, and integer data takes 101 sec for encryption and 1.4 sec for decryption time. This experimental study demonstrates that the recommended security method drastically lowers overlap and effectively reduces space utilization.},
  archive      = {J_KBS},
  author       = {J.R. Ancy Jero and D.S. Misbha},
  doi          = {10.1016/j.knosys.2024.112812},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112812},
  shortjournal = {Knowl. Based Syst.},
  title        = {CDNA-CCS: Splitting and compression based chaotic-DNA cryptography framework for cloud computing security},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified adaptive graph structure generation method for spatio-temporal graph forecasting. <em>KBS</em>, <em>309</em>, 112811. (<a href='https://doi.org/10.1016/j.knosys.2024.112811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting has important applications in various domains of the real world. As a method of time series forecasting, spatio-temporal graph forecasting has garnered significant attention because of its strong performance. However, traditional spatio-temporal graph models are constrained by pre-defined graph structures, which should abstract physical entities and determine their correlations. This artificial process incurs high costs and noise, which reduce accuracy. Therefore, we propose a unified method for spatio-temporal graph forecasting called Self-supervised Graph Structure Generation for Spatio-Temporal Graph Forecasting (SGX2-STGF). The use of self-supervised learning avoids high costs. We design a specific module to extract dual information from randomly initialized graph, which can effectively mitigate noise. In addition, graph contrastive learning is introduced to enhance the method’s universality and performance. The proposed method can be integrated into different spatio-temporal graph forecasting models. Extensive experiments validate its versatility and superiority using three real-world datasets.},
  archive      = {J_KBS},
  author       = {Xu Wang and Nanjie Lai and Peiji Liu and Zongwei Wang and Min Gao},
  doi          = {10.1016/j.knosys.2024.112811},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112811},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified adaptive graph structure generation method for spatio-temporal graph forecasting},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-aware evolutionary graph neural architecture search. <em>KBS</em>, <em>309</em>, 112810. (<a href='https://doi.org/10.1016/j.knosys.2024.112810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural architecture search (GNAS) can customize high-performance graph neural network architectures for specific graph tasks or datasets. However, existing GNAS methods begin searching for architectures from a zero-knowledge state, ignoring the prior knowledge that may improve the search efficiency. The available knowledge base (e.g. NAS-Bench-Graph) contains many rich architectures and their multiple performance metrics, such as the accuracy (#Acc) and number of parameters (#Params). This study proposes exploiting such prior knowledge to accelerate the multi-objective evolutionary search on a new graph dataset, named knowledge-aware evolutionary GNAS (KEGNAS). KEGNAS employs the knowledge base to train a knowledge model and a deep multi-output Gaussian process (DMOGP) in one go, which generates and evaluates transfer architectures in only a few GPU seconds. The knowledge model first establishes a dataset-to-architecture mapping, which can quickly generate candidate transfer architectures for a new dataset. Subsequently, the DMOGP with architecture and dataset encodings is designed to predict multiple performance metrics for candidate transfer architectures on the new dataset. According to the predicted metrics, non-dominated candidate transfer architectures are selected to warm-start the multi-objective evolutionary algorithm for optimizing the #Acc and #Params on a new dataset. Empirical studies on NAS-Bench-Graph and five real-world datasets show that KEGNAS swiftly generates top-performance architectures, achieving 4.27% higher accuracy than advanced evolutionary baselines and 11.54% higher accuracy than advanced differentiable baselines. In addition, ablation studies demonstrate that the use of prior knowledge significantly improves the search performance.},
  archive      = {J_KBS},
  author       = {Chao Wang and Jiaxuan Zhao and Lingling Li and Licheng Jiao and Fang Liu and Xu Liu and Shuyuan Yang},
  doi          = {10.1016/j.knosys.2024.112810},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112810},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-aware evolutionary graph neural architecture search},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized bilevel optimization model for large-scale task scheduling in multiple agile earth observation satellites. <em>KBS</em>, <em>309</em>, 112809. (<a href='https://doi.org/10.1016/j.knosys.2024.112809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling large-scale tasks within a multi-agile earth observation satellite system poses a formidable challenge. Given the complexity of this optimization problem, the responding solving strategy should exhibit both efficiency and effectiveness in terms of computational time and solution quality. The current strategies can broadly be categorized into all-in-one and two-stage methodologies. The latter, more conducive to real-world scenarios, owing to reducing the problem complexity and practical operational flexibility, dissects this challenge into task allocation and single-satellite scheduling. However, existing two-stage strategies still consider the objectives and constraints at the equivalent level and only adapt to specific algorithms. In this way, the pivotal issues concerning the solution complexity and strategy compatibility remain fundamentally unaddressed. To address this limitation, we proposed a generalized bilevel optimization model called Question-and-Answer model, which establishes two distinct optimization model with different contains and objectives. In this model, the upper questions are highly indispensable in the response from the lower level and constraints are considered separately at two stages. To ascertain the generalization of this framework, we conduct a comprehensive range of experiments employing various proposed strategies and algorithms in two stages. Diverse algorithms ranging from heuristic principles, and evolutionary strategies, to reinforcement learning can be seamlessly combined and integrated within this framework. The results demonstrate that the scale of scenarios does not affect the effectiveness of any amalgamated algorithms within this framework. Furthermore, the transition of upper questions according to the lower answers indeed improves the objectives but concurrently intensify the computational time.},
  archive      = {J_KBS},
  author       = {Jiawei Chen and Feiran Wang and Yingguo Chen and Lei He and Yonghao Du and Jian Wu and Yingwu Chen},
  doi          = {10.1016/j.knosys.2024.112809},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112809},
  shortjournal = {Knowl. Based Syst.},
  title        = {A generalized bilevel optimization model for large-scale task scheduling in multiple agile earth observation satellites},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROPU: A robust online positive-unlabeled learning algorithm. <em>KBS</em>, <em>309</em>, 112808. (<a href='https://doi.org/10.1016/j.knosys.2024.112808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive-unlabeled (PU) learning aims to train classifiers using positive and unlabeled samples. Most methods assume a selected completely at random labeling scenario, which may not reflect real-world PU learning conditions. Our investigation across multiple peptide spectrum match datasets reveals a nonuniform distribution of labeled positive samples, concentrated in specific subsets. To address this, we propose a “missing in a subset area” labeling assumption and analyze resulting model biases. Furthermore, we introduce nonconvex loss functions and develop a robust online positive-unlabeled (ROPU)classification algorithm using gradient descent. Theoretically, ROPU achieves sublinear nonstationary regret bounds under mild conditions. Experimental results demonstrate the effectiveness of ROPU across various simulated and practical PU learning datasets. The source code is available at https://github.com/Isaac-QiXing/ROPU .},
  archive      = {J_KBS},
  author       = {Xijun Liang and Kaili Zhu and An Xiao and Ya Wen and Kaili Zhang and Suhang Wang and Ling Jian},
  doi          = {10.1016/j.knosys.2024.112808},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112808},
  shortjournal = {Knowl. Based Syst.},
  title        = {ROPU: A robust online positive-unlabeled learning algorithm},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight multi-scale distillation attention network for image super-resolution. <em>KBS</em>, <em>309</em>, 112807. (<a href='https://doi.org/10.1016/j.knosys.2024.112807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) with deep structure have achieved remarkable image super-resolution (SR) performance. However, the dramatically increased model parameters and computations make them difficult to deploy on low-computing-power devices. To address this issue, a lightweight multi-scale distillation attention network (MSDAN) is proposed for image SR in this paper. Specially, we design an effective branch fusion block (EBFB) by utilizing pixel attention with different kernel sizes via distillation connection, which can extract features from different receptive fields and obtain the attention coefficients for all pixels in the feature maps. Additionally, we further propose an enhanced multi-scale spatial attention (EMSSA) by utilizing AdaptiveMaxPool and convolution kernel with different sizes to construct multiple downsampling branches, which possesses adaptive spatial information extraction ability and maintains large receptive field. Extensive experiments demonstrate the superiority of the proposed model over most state-of-the-art (SOTA) lightweight SR models. Most importantly, compared to residual feature distillation network (RFDN), the proposed model achieves 0.11 improvement of PSNR on Set14 dataset with 57.5% fewer parameters and 20.3% less computational cost at × 4 upsampling factor. The code of this paper is available at https://github.com/Supereeeee/MSDAN .},
  archive      = {J_KBS},
  author       = {Yinggan Tang and Quanwei Hu and Chunning Bu},
  doi          = {10.1016/j.knosys.2024.112807},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112807},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lightweight multi-scale distillation attention network for image super-resolution},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relation-aware multiplex heterogeneous graph neural network. <em>KBS</em>, <em>309</em>, 112806. (<a href='https://doi.org/10.1016/j.knosys.2024.112806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, heterogeneous graph neural networks have attracted considerable attention for their powerful graph processing capabilities and effectiveness in handling multiple types of nodes and relationships. However, limited work has been carried out on multiplex heterogeneous networks where multiple relations exist between the same pair of nodes, which is more realistic in real-world applications. Two typical approaches include meta-path-based frameworks and weighted fusions of different edge types. The former suffers from information loss from the original graph, while the latter significantly increases computational costs as the number of subgraphs grows. To address these challenges, we propose a Relation-Aware Multiplex Heterogeneous Graph Neural Network named RAMHN, which effectively captures the multiple relations that exist between the same pair of nodes. Specifically, RAMHN first constructs hybrid relation matrices by fusing relationships and then designs a unique relation representation vector for each individual relationship. Finally, it utilizes the learned relation representation vectors and hybrid relation matrices to perform graph convolution, obtaining the final node representations. Extensive experiments on five real-world and publicly available datasets demonstrate that RAMHN outperforms state-of-the-art baselines on various downstream tasks.},
  archive      = {J_KBS},
  author       = {Mingxia Zhao and Jiajun Yu and Suiyuan Zhang and Adele Lu Jia},
  doi          = {10.1016/j.knosys.2024.112806},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112806},
  shortjournal = {Knowl. Based Syst.},
  title        = {Relation-aware multiplex heterogeneous graph neural network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A plug-and-play knowledge-enhanced module for medical reports generation. <em>KBS</em>, <em>309</em>, 112805. (<a href='https://doi.org/10.1016/j.knosys.2024.112805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical reports generation from patient–doctor conversations aims to capture the salient contents from dialogues in the form of medical reports, to assist the healthcare archiving and follow-ups. Unlike general summarization tasks, summaries in specialized domains, such as medical report generation, require stronger support from domain-specific knowledge to enhance the internal logic specific to their field. However, existing methods either model the context sequentially without incorporating knowledge graphs, resulting in unclear representation of domain-specific logical structures, or introduce the expert medical knowledge using homogeneous graphs, which fail to effectively fuse information from different semantic spaces. To address this, we propose to incorporate the knowledge into the step of context modeling by introducing a plug-and-play heterogeneous graph encoder. Furthermore, a fact-aware module is introduced to help our model in integrating key context information filtered by external knowledge during decoding. Compared with previous works, our method makes full use of knowledge, and the proposed modules demonstrate easy adaption on existing frameworks. Experimental results on two public medical dialogue summarization datasets indicate that our method significantly outperforms a range of baselines while being smaller and capable of achieving the state-of-the-art performance 1 .},
  archive      = {J_KBS},
  author       = {Qinyu Han and Zhihao Yang and Hongfei Lin and Tian Qin},
  doi          = {10.1016/j.knosys.2024.112805},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112805},
  shortjournal = {Knowl. Based Syst.},
  title        = {A plug-and-play knowledge-enhanced module for medical reports generation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph completion with low-dimensional gated hierarchical hyperbolic embedding. <em>KBS</em>, <em>309</em>, 112804. (<a href='https://doi.org/10.1016/j.knosys.2024.112804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding aims to advance learning performance by deliberating the complexity of hierarchical data structures in a finite-dimensional space. Most traditional Euclidean models struggle to accurately describe and navigate intricate hierarchical relationships between nodes. Hyperbolic embedding methods, particularly when combined with graph neural networks, offer promise in effectively modeling complex hierarchies in a limited-dimensional space. These methods can incorporate more information about nodes under the same conditions but are also more susceptible to interference from complex neighborhood features. This paper introduces HyperGatE, which novelty combines a hyperbolic graph hierarchical neighbor structure based on a gated filter and a hyperbolic isometric rotation model for knowledge graph completion. By analyzing the hierarchical structure of the knowledge base and using a gated mechanism to form multi-layer embedding networks of entity-relational paths, the gated selects diverse uneven multi-hop relations within the entity neighborhood and measures them through graph attention networks. Furthermore, the simplified hyperbolic isometric model allows for uncovering hierarchical structures in the data. HyperGatE experimentally surpasses some state-of-the-art Euclidean and hyperbolic space models in high and low dimensions across four well-known data, namely WN18RR, FB15k-237, NELL-995, and Kinship.},
  archive      = {J_KBS},
  author       = {Yan Fang and Xiaodong Liu and Wei Lu and Witold Pedrycz and Qi Lang and Jianhua Yang},
  doi          = {10.1016/j.knosys.2024.112804},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112804},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge graph completion with low-dimensional gated hierarchical hyperbolic embedding},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A meta-learning based approach for temporal link prediction in multiplex networks. <em>KBS</em>, <em>309</em>, 112803. (<a href='https://doi.org/10.1016/j.knosys.2024.112803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in temporal and multiplex networks is a crucial issue across both applied and scientific disciplines within the study of complex networks. Recent advances in hardware and the increased availability of computational resources have enhanced our capacity to tackle this problem more effectively. Link prediction in multiplex and temporal networks faces challenges such as inter-layer dependencies and the temporal expansion and contraction of the network. This paper introduces MetaLink, a novel approach designed for link prediction within such temporal multiplex networks. MetaLink leverages knowledge obtained from various temporal network snapshots by employing two innovative methods for subsequent temporal snapshot. It efficiently facilitates the transfer of knowledge across different temporal snapshots. The intra-layer knowledge transfer is governed by a time-decay function, while inter-layer knowledge is learned in a step wise and transferred using the Model-Agnostic Meta-Learning (MAML) algorithm from one snapshot (task) to another. Our findings demonstrate that MetaLink significantly outperforms static single-layer and multiplex methods, showing improvements of 2 to 5 percent, and exhibits up to a 3 percent enhancement over existing temporal methods.},
  archive      = {J_KBS},
  author       = {Sajjad Tofighy and Nasrollah Moghadam Charkari and Foad Ghaderi},
  doi          = {10.1016/j.knosys.2024.112803},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112803},
  shortjournal = {Knowl. Based Syst.},
  title        = {A meta-learning based approach for temporal link prediction in multiplex networks},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal robustness fake news detection with cross-modal and propagation network contrastive learning. <em>KBS</em>, <em>309</em>, 112800. (<a href='https://doi.org/10.1016/j.knosys.2024.112800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has transformed the landscape of news dissemination, characterized by its rapid, extensive, and diverse content, coupled with the challenge of verifying authenticity. The proliferation of multimodal news on these platforms has presented novel obstacles in detecting fake news. Existing approaches typically focus on single modalities, such as text or images, or combine text and image content or with propagation network data. However, the potential for more robust fake news detection lies in considering three modalities simultaneously. In addition, the heavy reliance on labeled data in current detection methods proves time-consuming and costly. To address these challenges, we propose a novel approach, M ulti-modal Robustness F ake News Detection with Cross-Modal and Propagation Network C ontrastive L earning (MFCL). This method integrates intrinsic features from text, images, and propagation networks, capturing essential intermodal relationships for accurate fake news detection. Contrastive learning is employed to learn intrinsic features while mitigating the issue of limited labeled data. Furthermore, we introduce image–text matching (ITM) data augmentation to ensure consistent image–text representations and employ adaptive propagation (AP) network data augmentation for high-order feature learning. We utilize contextual transformers to bolster the effectiveness of fake news detection, unveiling crucial intermodal connections in the process. Experimental results on real-world datasets demonstrate that MFCL outperforms existing methods, maintaining high accuracy and robustness even with limited labeled data and mismatched pairs. Our code is available at https://github.com/HanChen-HUST/KBS-MFCL .},
  archive      = {J_KBS},
  author       = {Han Chen and Hairong Wang and Zhipeng Liu and Yuhua Li and Yifan Hu and Yujing Zhang and Kai Shu and Ruixuan Li and Philip S. Yu},
  doi          = {10.1016/j.knosys.2024.112800},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112800},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modal robustness fake news detection with cross-modal and propagation network contrastive learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WEAL: Weight-wise ensemble adversarial learning with gradient manipulation. <em>KBS</em>, <em>309</em>, 112799. (<a href='https://doi.org/10.1016/j.knosys.2024.112799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training has emerged as a straightforward and effective defense approach against adversarial attacks, with ensemble adversarial learning (EAL) being a feasible branch to enhance the adversarial robustness of deep neural networks (DNNs). However, the existing EAL methods either incur massive costs in multi-model ensemble training, leading to low adaptability, or overlook the existence of gradient conflicts in single-model self-ensemble learning, resulting in only limited improvement in robustness. To address these issues, in this paper, we first analyze the importance of weight state information during network training, which plays a key role in ensemble learning, especially in adversarial settings. Then, we present a new gradient manipulation strategy, it implements random sampling in normal distribution to conduct consensual gradients for alleviating the gradient conflicts. Based on these, we propose a novel Weight-wise Ensemble Adversarial Learning (WEAL), which makes full use of the states of the weights and mitigates the conflicts in different gradients. It can greatly improve the adversarial robustness of the target model within an appropriate consumption cost. Extensive experiments on benchmark datasets and models verify the effectiveness of the proposed WEAL, e.g., in defending against white-box and black-box adversarial attacks, compared to representative adversarial training methods, the adversarial accuracy is increased by an average of 5.4% and 4.2%, and improving the adversarial accuracy by an average of 2.8% and 1.8% as compared to state-of-the-art ensemble adversarial learning method.},
  archive      = {J_KBS},
  author       = {Chuanxi Chen and Jiaming Wang and Yunbo Tang and He Fang and Li Xu},
  doi          = {10.1016/j.knosys.2024.112799},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112799},
  shortjournal = {Knowl. Based Syst.},
  title        = {WEAL: Weight-wise ensemble adversarial learning with gradient manipulation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph protection under multiple simultaneous attacks: A heuristic approach. <em>KBS</em>, <em>309</em>, 112791. (<a href='https://doi.org/10.1016/j.knosys.2024.112791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on developing a meta-heuristic approach to protect network nodes from simultaneous attacks, specifically addressing the k -strong Roman domination problem. The objective is to assign integer weights to the nodes, representing the number of stationed armies, to meet protection constraints while minimizing the total number of armies. A network is protected if it can repel any simultaneous attack on k nodes. A node is protected if it can defend itself or if a neighboring node provides an army while retaining at least one army for self-defense. This problem formulation can be used in practical scenarios, e.g. developing counter-terrorism strategies or in coping with supply chain disruptions. The problem is difficult as even verifying the feasibility of a single solution generally requires an exponential time. Two exact approaches are proposed in the literature but applicable to small random graphs. For larger graphs, we propose an effective variable neighborhood search, where the feasibility of a solution is verified by introducing the concept of relaxed feasibility. Experiments are conducted with random networks from the literature and two introduced ad-hoc wireless and real-world networks. Extensive experimental evaluations show the robustness of the proposed approach compared to the existing approaches from the literature by significantly outperforming them in all three benchmark sets. Furthermore, we demonstrate the practical application of the proposed variable neighborhood search approach, where its solution is used to position fire stations within the city so that simultaneous fires can be extinguished efficiently while reducing the number of required fire trucks.},
  archive      = {J_KBS},
  author       = {Marko Djukanović and Stefan Kapunac and Aleksandar Kartelj and Dragan Matić},
  doi          = {10.1016/j.knosys.2024.112791},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112791},
  shortjournal = {Knowl. Based Syst.},
  title        = {Graph protection under multiple simultaneous attacks: A heuristic approach},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FAITH: Frequency-domain attention in two horizons for time series forecasting. <em>KBS</em>, <em>309</em>, 112790. (<a href='https://doi.org/10.1016/j.knosys.2024.112790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time Series Forecasting (TSF) plays a crucial role in various sectors, including industrial maintenance, weather prediction, energy management, traffic control, and financial planning. Current deep learning-based predictive models often exhibit significant deviations between their forecasting outcomes and the ground truth because they lack an efficient method to extract both the global frequency-domain information of each variable and the relationships between different variables. To tackle this challenge, we introduce an innovative model—Frequency-domain Attention In Two Horizons (FAITH). FAITH decomposes time series into trend and seasonal components using a multi-scale adaptive decomposition and fusion architecture and processes them separately. It utilizes two modules — the Frequency Channel Feature Extraction Module (FCEM) and the Frequency Temporal Feature Extraction Module (FTEM) — to capture inter-channel relationships at a finer granularity and to extract global temporal information from the frequency domain of different variables. This significantly enhances its ability to handle long-term dependencies and complex patterns. Furthermore, FAITH achieves theoretically linear complexity by modifying the time–frequency domain transformation method, effectively reducing computational costs. Extensive experiments across six benchmarks for long-term forecasting and five benchmarks for short-term forecasting demonstrate that FAITH outperforms existing models in various domains, such as electricity, weather, and traffic. These results validate the effectiveness and superiority of FAITH in both long-term and short-term time series forecasting tasks. Our codes and data are available at https://github.com/LRQ577/FAITH},
  archive      = {J_KBS},
  author       = {Ruiqi Li and Maowei Jiang and Quangao Liu and Kai Wang and Kaiduo Feng and Yue Sun and Xiufang Zhou},
  doi          = {10.1016/j.knosys.2024.112790},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112790},
  shortjournal = {Knowl. Based Syst.},
  title        = {FAITH: Frequency-domain attention in two horizons for time series forecasting},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Different paths to the same destination: Diversifying LLMs generation for multi-hop open-domain question answering. <em>KBS</em>, <em>309</em>, 112789. (<a href='https://doi.org/10.1016/j.knosys.2024.112789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The powerful natural language reasoning capabilities of large language models (LLMs) have led to widespread application in knowledge-intensive multi-hop question reasoning. However, when answering questions with multiple possible solutions, Chain-of-Thoughts (CoT) -based methods that rely on a single reasoning path perform average. The reason is that there is no opportunity to correct the reasoning process when errors occur. To address this, we propose DP-CoT that utilizes diverse generation for multi-hop question reasoning. Concisely, we introduce two methods of generating diverse evidence with different granularity: passage-level sampling and sentence-level proposal generation. Meanwhile, we train a BERT-style evidence classifier to prune the reasoning path. Finally, we integrate the best-performing classifier into the reasoning module to obtain an end-to-end framework. We evaluate DP-CoT on several prevalent multi-hop open-domain question answering datasets and achieve highly competitive results compared to the state-of-the-art baselines. Specifically, compared to IRCoT with GPT3 as the backbone language model, DP-CoT achieves an recall improvement of 4.8% and 1.1% on the HotpotQA and 2WikiMultihopQA datasets, respectively. Extensive experimental results validate the effectiveness of our method. Code and data are available at https://github.com/XD-BDIV-NLP/DP-CoT .},
  archive      = {J_KBS},
  author       = {Ronghan Li and Yu Wang and Zijian Wen and Mingze Cui and Qiguang Miao},
  doi          = {10.1016/j.knosys.2024.112789},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112789},
  shortjournal = {Knowl. Based Syst.},
  title        = {Different paths to the same destination: Diversifying LLMs generation for multi-hop open-domain question answering},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel spatio-temporal feature interleaved contrast learning neural network from a robustness perspective. <em>KBS</em>, <em>309</em>, 112788. (<a href='https://doi.org/10.1016/j.knosys.2024.112788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is critical to the effectiveness of intelligent transportation systems (ITS) and the development of smart cities.Achieving this goal requires efficient capture of heterogeneous interactions between spatial and temporal dependencies of traffic nodes.However, the robustness and predictive capacity of modeling systems are frequently compromised by the limitations inherent in fine-grained sensor data collection methodologies.Furthermore, the uneven distribution of data can exacerbate the degradation of the model’s predictive performance.To tackle these challenges, we introduce an innovative neural network that leverages spatio-temporal feature interlace contrast learning for daily traffic flow prediction.Our approach consists of two main parts: First, we propose a spatiotemporal position encoder that aims to provide a more balanced sample of training spatiotemporal data with mixed spatial coding to solve the problem of local heterogeneity in the data.Secondly, we employ a spatiotemporal interlace contrast graph structure generator and a specific structure and direction discriminator to discern various potential spatiotemporal features and categorize samples based on trends and consistency, thereby augmenting the system’s robustness and generalization capabilities. Extensive experiments and case studies across six real datasets demonstrate that our approach markedly enhances the prediction accuracy of the baseline model and introduces novel prediction strategies aimed at boosting the system’s robustness.},
  archive      = {J_KBS},
  author       = {Peng Liu and Yaodong Zhu and Yang Yang and Caixia Wang and Mingqiu Li and Haifang Cong and Guangyu Zhao and Han Yang},
  doi          = {10.1016/j.knosys.2024.112788},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112788},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel spatio-temporal feature interleaved contrast learning neural network from a robustness perspective},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multiscale adaptive graph adversarial network for mechanical fault diagnosis. <em>KBS</em>, <em>309</em>, 112787. (<a href='https://doi.org/10.1016/j.knosys.2024.112787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measured signals of mechanical equipment may exhibit distribution discrepancies due to object variations or operational conditions. The multiscale framework has been demonstrated to be effective in enriching features. However, existing methods overlook the structural discrepancies and collaborative contributions at specific scales. Meanwhile, most current domain adaptation strategies predominantly consider class and domain labels, neglecting feature structural shifts, especially in subdomain feature structures. Based on that, a new cross-domain fault diagnosis method for mechanical is proposed in this paper, called multiscale adaptive graph adversarial network(MAGAN). MAGAN consists of a feature extractor, domain adaptation module, and classifier. In the feature extractor, a hierarchical residual multiscale graph learning module is employed to obtain rich features, an adaptive graph learning module is utilized to learn differentiated representations of specific scale structures, and a multiscale fusion module is applied to facilitate the collaboration of different scale features. After that, the domain adaptation module aids the feature extractor in learning transferable features by constructing a measure of subdomain feature structure discrepancy and adversarial domain discriminator. The classifier is then utilized for cross-domain fault diagnosis on the extracted transferable features. Finally, the proposed MAGAN is evaluated using 3 cross-machine transfer scenarios based on a scaled-down test rig for wind turbine gearbox and 12 cross-operating conditions transfer scenarios based on a published bearing dataset. The results validate the transferability and generalization of MAGAN.},
  archive      = {J_KBS},
  author       = {Jiayang Liu and Chaobing Wang and Rui Wang and Qian Xiao and Xiaosun Wang and Shijing Wu and Long Zhang},
  doi          = {10.1016/j.knosys.2024.112787},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112787},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel multiscale adaptive graph adversarial network for mechanical fault diagnosis},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeutronSketch: An in-depth exploration of redundancy in large-scale graph neural network training. <em>KBS</em>, <em>309</em>, 112786. (<a href='https://doi.org/10.1016/j.knosys.2024.112786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved notable success in various applications. However, the increasing scale of real-world graphs poses a challenge for efficient GNN training. Recent works propose reducing computations by reducing the scale of the input graph through graph compression or sparsification. However, these methods introduce deep learning models requiring multiple training iterations, which leads to significant additional time overhead. Meanwhile, they fail to consider redundant information that is unhelpful or even harmful for model training in the input graphs. In this work, we propose a universal, one-time redundancy removal method called NeutronSketch to remove the redundant information from the input graph. This method can improve training efficiency while maintaining the model accuracy. In the experiments, we compare NeutronSketch with graph compression, sparsification, and coarsening methods. The results show that NeutronSketch has a faster execution speed and better model accuracy. Additionally, we apply NeutronSketch to the sample-based GNN models. The results show that NeutronSketch reduces input graph scale by an average of 25% compared to the original graph, reducing training time by 10%–90% while maintaining the model accuracy.},
  archive      = {J_KBS},
  author       = {Yajiong Liu and Yanfeng Zhang and Qiange Wang and Hao Yuan and Xin Ai and Ge Yu},
  doi          = {10.1016/j.knosys.2024.112786},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112786},
  shortjournal = {Knowl. Based Syst.},
  title        = {NeutronSketch: An in-depth exploration of redundancy in large-scale graph neural network training},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable next POI recommendation based on spatial–temporal disentanglement representation and pseudo profile generation. <em>KBS</em>, <em>309</em>, 112784. (<a href='https://doi.org/10.1016/j.knosys.2024.112784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current research in Point-of-Interest (POI) recommendation primarily aims to decipher users’ transitional patterns to predict their future location visits. Traditional approaches often intertwine various features to model these check-in transitions, which inadvertently compromises the quality of the resulting representations. This issue is compounded in both industrial and academic settings, where user-generated textual data is frequently inaccessible or restricted due to privacy concerns. Such limitations in user profiles pose significant challenges to the effectiveness of subsequent applications. In response to these challenges, the recent rise of Large Language Models (LLMs) offers a novel perspective. Diverging from the conventional approach of leveraging LLMs for semantic-based next check-in predictions, our research investigates the potential of integrating LLMs with sequential recommendation systems. This integration aims to augment feature dimensions and facilitate the generation of explicit explanations. To this end, we introduce CrossDR-Gen, a Cross-sequence Location Disentanglement Representation methodology. CrossDR-Gen is specifically designed for next POI recommendation and explanation generation. It uniquely considers spatial and temporal factors in shaping check-in behaviors, offering a comprehensive global view of location transitions. Crucially, CrossDR-Gen utilizes LLMs for pseudo profile generation in scenarios with limited semantic context, thereby enriching user features without relying on additional textual profiles or conversational data. Our experiments on real-world datasets demonstrate that CrossDR-Gen not only excels in addressing cold-start scenarios but also showcases robust recommendation capabilities. These findings validate the effectiveness of our proposed cooperative paradigm between LLMs and sequential recommendation models, highlighting a promising avenue for future research in POI recommendation systems.},
  archive      = {J_KBS},
  author       = {Jun Zeng and Hongjin Tao and Junhao Wen and Min Gao},
  doi          = {10.1016/j.knosys.2024.112784},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112784},
  shortjournal = {Knowl. Based Syst.},
  title        = {Explainable next POI recommendation based on spatial–temporal disentanglement representation and pseudo profile generation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free robust reinforcement learning via polynomial chaos. <em>KBS</em>, <em>309</em>, 112783. (<a href='https://doi.org/10.1016/j.knosys.2024.112783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Robust Markov Decision Process (RMDP) has become an important modeling framework to address the discrepancies between simulated and real-world environments in Reinforcement Learning (RL) training. The purpose of RMDP is to accommodate the uncertainty of the real-world environments, employing a conservative approach to enhance the robustness of policy decisions. However, due to the difficulty of robust value function estimation, the RMDP framework is challenging to generalize to environments with large continuous state–action spaces. Our work focuses on model-free robust RL and proposes a model-free algorithm for continuous space setting. We adopt a new perspective on uncertainty sets such that the uncertainty sets are parameterized and the parameters obey specific stochastic distributions. We present a novel approach RPC to estimate the robust value function utilizing generalized Polynomial Chaos(gPC). We provide a proof to guarantee the convergence of the algorithm. Our training framework is based on off-policy RL, which reduces the computation overhead by gPC and improves learning stability. Our algorithm can handle continuous tasks and guarantee the robustness of the algorithm without incurring excessive computational overhead. We combine RPC with the TD3 method and conduct several experiments to evaluate its performance in a continuous robot control task, and the experimental results provide further evidence of the robustness of our algorithm.},
  archive      = {J_KBS},
  author       = {Jianxiang Liu and Faguo Wu and Xiao Zhang},
  doi          = {10.1016/j.knosys.2024.112783},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112783},
  shortjournal = {Knowl. Based Syst.},
  title        = {Model-free robust reinforcement learning via polynomial chaos},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CABiLSTM-BERT: Aspect-based sentiment analysis model based on deep implicit feature extraction. <em>KBS</em>, <em>309</em>, 112782. (<a href='https://doi.org/10.1016/j.knosys.2024.112782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) models typically focus on learning contextual syntactic information and dependency relations. However, these models often struggle with losing or forgetting implicit feature information from shallow and intermediate layers during the learning process, potentially compromising classification performance. We consider the implicit feature information in each layer of the model to be equally important for processing. So, this paper proposes the CABiLSTM-BERT model, which aims to fully leverage implicit features at each layer to address this information loss problem and improve accuracy. The CABiLSTM-BERT model employs a frozen BERT pre-trained model to extract text word vector features, reducing overfitting and accelerating training. These word vectors are then processed through CABiLSTM, which preserves implicit feature representations of input sequences and LSTMs in each direction and layer. The model applies convolution to merge all features into a set of embedding representations after highlighting important features through multi-head self-attention calculations for each feature group. This approach minimizes information loss and maximizes utilization of important implicit feature information at each layer. Finally, the feature representations undergo average pooling before passing through the sentiment classification layer for polarity prediction. The effectiveness of the CABiLSTM-BERT model is validated using five publicly available real-world datasets and evaluated using metrics such as accuracy and Macro-F1. Results demonstrate the model's efficacy in addressing ABSA tasks.},
  archive      = {J_KBS},
  author       = {Bo He and Ruoyu Zhao and Dali Tang},
  doi          = {10.1016/j.knosys.2024.112782},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112782},
  shortjournal = {Knowl. Based Syst.},
  title        = {CABiLSTM-BERT: Aspect-based sentiment analysis model based on deep implicit feature extraction},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing information fusion and feature selection efficiency via the PROMETHEE method for multi-source dynamic decision data sets. <em>KBS</em>, <em>309</em>, 112781. (<a href='https://doi.org/10.1016/j.knosys.2024.112781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge in big data, the complexity of synthesizing information from multiple sources has become a critical challenge for feature selection methodologies. Feature selection is the process of reducing the number of attributes in data. Traditional single-source centric approaches are inefficient, requiring extensive preprocessing for multi-source data consolidation prior to feature selection. At the same time, an information fusion method is needed to transform the multi-source information system with selected features into a single-source information system. This paper introduces a novel multi-source information fusion and feature selection approach that seamlessly integrates the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) with a dynamic adaptation mechanism. This method is adept at addressing the complexities introduced by the evolving nature of feature and information source dimensions. The Attribute Evaluation Matrix (AEM) and the Attribute Preference Degree Matrix (APDM) are proposed to systematically assess and rank the significance of attributes within a static decision-making framework. Following this, an information fusion method using the source center is proposed. The dynamic feature selection and information fusion methods are proposed to deal with the condition when number of attributes and samples change. Extensive experimental validation confirms that this method not only reduces the computational overhead associated with multi-source feature selection but also significantly enhances the efficiency as the volume and variety of data sources increase.},
  archive      = {J_KBS},
  author       = {Weihua Xu and Yigao Li},
  doi          = {10.1016/j.knosys.2024.112781},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112781},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing information fusion and feature selection efficiency via the PROMETHEE method for multi-source dynamic decision data sets},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSNet: A non-uniform illumination correction method for underwater images based pseudo-siamese network. <em>KBS</em>, <em>309</em>, 112780. (<a href='https://doi.org/10.1016/j.knosys.2024.112780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUVs) based on visual perception play an important role in maritime operations. However, underwater environment often suffers from poor lighting conditions, making the utilization of artificial light sources necessary. This reliance on artificial lighting frequently results in non-uniform illumination. Furthermore, the absorption and scattering effects of water cause further degradation, such as color distortion and blurring of details. To address these challenges, we propose a pseudo-siamese network, named PSNet, designed for underwater optical image enhancement. PSNet separates the non-uniformly illuminated layer from the optimally uniformly illuminated image and utilizes a cascading iteration strategy to enhance the image details. To achieve a better balance prediction quality, we introduce structure loss and residual reconstruction loss as additional guides for model learning. Additionally, we incorporate a color consistency loss to mitigate color distortion. To address the lack of training data, we develop a non-uniform illumination model and generate a dataset that includes both non-uniformly illuminated layers and uniformly illuminated images. Through comprehensive experimental evaluations, PSNet significantly enhances the visual quality of underwater optical images and consistently outperforms state-of-the-art approaches in multiple performance metrics.},
  archive      = {J_KBS},
  author       = {Wenfeng Zhao and Shenghui Rong and Chen Feng and Bo He},
  doi          = {10.1016/j.knosys.2024.112780},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112780},
  shortjournal = {Knowl. Based Syst.},
  title        = {PSNet: A non-uniform illumination correction method for underwater images based pseudo-siamese network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive de-preference task-specific processing for generalizable person re-identification. <em>KBS</em>, <em>309</em>, 112779. (<a href='https://doi.org/10.1016/j.knosys.2024.112779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, domain generalization (DG) person re-identification (ReID) has attracted attention. Existing DG person ReID methods train on mixed datasets containing all source domains. However, these mixed datasets have huge inter-domain differences because of varying data distributions across different source domains. Such differences hinder models from learning domain-invariant representations, affecting generalization on unseen domains. To address this issue, we propose a progressive de-preference task-specific processing network (PDTP-Net) for DG person ReID. Initially, we design a progressive de-preference domain segmentation strategy to mitigate inter-domain differences by dividing multiple source domains into different phases, each comprising several training tasks. We then design a global and task-specific processing module that enhances extraction of domain-invariant features by integrating statistical information from other source domains. Finally, we design a multi-granularity attention module and a group-aware batch normalization strategy to ensure the features are more discriminative and better suited for person ReID tasks. The proposed model is validated using three DG person ReID experimental protocols: Protocol-1, Protocol-2, and leave-one-out experiments. On Protocol-1, the model improves mean average precision (mAP) and Rank-1 accuracy on all datasets by an average of 0.7% and 0.3%, respectively. On Protocol-2, the model improves mAP and Rank-1 accuracy on all datasets by an average of 2.525% and 2.725%, respectively. On the leave-one-out experiments, the model improves mAP and Rank-1 accuracy on all tasks by an average of 0.65% and 0.18%, respectively. The results on several popular datasets suggest that the model achieves state-of-the-art performance in DG person ReID.},
  archive      = {J_KBS},
  author       = {Haishun Du and Jieru Li and Linbing Cao and Xinxin Hao},
  doi          = {10.1016/j.knosys.2024.112779},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112779},
  shortjournal = {Knowl. Based Syst.},
  title        = {Progressive de-preference task-specific processing for generalizable person re-identification},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedSR: Federated learning for image super-resolution via detail-assisted contrastive learning. <em>KBS</em>, <em>309</em>, 112778. (<a href='https://doi.org/10.1016/j.knosys.2024.112778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed learning paradigm that collaboratively learns a global model from multiple decentralized clients without sharing raw data, providing an effective solution for privacy preservation. However, current FL works primarily focus on high-level visual tasks ( e.g. , classification), the exploration for image super-resolution (SR), a fundamental low-level visual task, is rarely addressed. In this study, we propose Fed erated Image S uper- R esolution ( FedSR ), a novel FL approach for image SR task, aiming to generate high-quality images while preserving data privacy. Specifically, we introduce a detail-assisted contrastive loss at the decentralized client, aligning the shallow representations by rectifying the relationship of low-level features between local clients and global server. In addition, we develop a hierarchical aggregation policy at the central server to better integrate dispersed client models into the global model, with the aggregation weight determined based on the layer-wise similarity between the updated local models and the historical global model. Extensive experiments conducted on general SR benchmarks and facial image datasets demonstrate the superiority of our FedSR in terms of image quality and model performance. Notably, FedSR can be seamlessly integrated with various prevalent image SR methods, including CNN-based and Transformer-based architectures.},
  archive      = {J_KBS},
  author       = {Yue Yang and Xiaodong Ren and Liangjun Ke},
  doi          = {10.1016/j.knosys.2024.112778},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112778},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedSR: Federated learning for image super-resolution via detail-assisted contrastive learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMGE: Entities and mentions gradual enhancement with semantics and connection modelling for document-level relation extraction. <em>KBS</em>, <em>309</em>, 112777. (<a href='https://doi.org/10.1016/j.knosys.2024.112777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is the process of identifying connections between entities in unstructured text and is a critical component of entity-centred information extraction to uncover latent knowledge structures in complex documents. Although graph-based methods have pushed the state-of-the-art forward in relation extraction, current approaches still exhibit limitations. These include incomplete capture of graph structural features, inadequate modelling of long-distance dependencies and imprecise representation of complex entity interactions. A novel E ntities and M entions G radual E nhancement framework called EMGE is proposed. It integrates both contextual and structural information to robustly enhance entity representations for document-level relation extraction. It comprises three primary components: 1) a dynamic relation aware enhancement mechanism to comprehensively encode graph structural features; 2) a multi-scale feature enhancement module to effectively capture long-distance dependencies; and 3) an entity-mention pair enhancement mechanism to yield precise representations of classification targets. Extensive empirical evaluation on five widely-adopted datasets demonstrates that EMGE achieves promising performance. Particularly noteworthy are the substantial gains obtained on the challenging CDR dataset, where EMGE achieved relative improvements of 1.5%, 8.8%, and 3.5% over the strongest baseline in terms of the Intra-F1, Inter-F1 and Overall-F1 metrics, respectively. Further experimental results demonstrate that the proposed model outperforms the popular large language model in relation extraction tasks. Our code is available on github. 1},
  archive      = {J_KBS},
  author       = {Guojun Chen and Panfeng Chen and Qi Wang and Hui Li and Xin Zhou and Xibin Wang and Aihua Yu and Xingzhi Deng},
  doi          = {10.1016/j.knosys.2024.112777},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112777},
  shortjournal = {Knowl. Based Syst.},
  title        = {EMGE: Entities and mentions gradual enhancement with semantics and connection modelling for document-level relation extraction},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-decoding branch contrastive augmentation for image manipulation localization. <em>KBS</em>, <em>309</em>, 112776. (<a href='https://doi.org/10.1016/j.knosys.2024.112776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of image editing techniques, forensic analysis to detect malicious image manipulation has become an important research topic. The current image manipulation detection and localization methods can accommodate diverse forms of tampering. However, their approach to handling various tampering detection types is limited to a uniform regression pathway. This approach fails to recognize the unique characteristics of copy-move tampering, which is significantly different from other tampering types. Employing a generic detection methodology indiscriminately poses the risk of confusing the training regression trajectory of the deep learning models. To mitigate this challenge, this paper introduces a novel framework featuring a dual-decoding branch structure specifically designed to augment features pertinent to copy-move tampering types. Moreover, it facilitates the detection of tampered regions, irrespective of the tampering type, within the main branch. To achieve this goal, we first introduce a contrastive augmentation module in the encoder, which maximizes the feature space distance between the manipulation regions and pristine regions. Next, we design a parallel attention module to extract more diverse multiscale features. Moreover, we introduce a constrained shifted-window dual attention module to extract tampering noise features. In the decoder, we design a dual-decoding branch to capture both the homologous and tampering features, and we employ contrastive learning to minimize the feature space distance of the homologous regions for copy-move manipulation detection. Finally, we design a category normalization loss function to balance the model’s attention across each category. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on various benchmark datasets.},
  archive      = {J_KBS},
  author       = {Qiang Zeng and Hongxia Wang and Yang Zhou and Rui Zhang},
  doi          = {10.1016/j.knosys.2024.112776},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112776},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-decoding branch contrastive augmentation for image manipulation localization},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel domain-private-suppress meta-recognition network based universal domain generalization for machinery fault diagnosis. <em>KBS</em>, <em>309</em>, 112775. (<a href='https://doi.org/10.1016/j.knosys.2024.112775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization aims to generalize knowledge to target domains not seen during the training phase, even in domain gaps. However, in complex industrial settings, the emergence of new fault types is frequent. Concurrently, the rarity of these faults means that the data collected may not fully capture the entire range of potential fault conditions. As a result, it is challenging to ensure that there is an overlap between the label sets of the multi-source domains and the unseen target domains. This problem requires no prior knowledge of label sets, and it requires a model to learn from multi-source domains and perform well on unknown target domains. In this paper, we propose a Domain-Private-Suppress Meta-Recognition Network (DPSMR). It quantifies channel-level transferability to continuously enhance the robustness of channels to domain shifts, thereby promoting the generalization of a common label set. Using an enhanced meta-recognition calibration algorithm to avoid overconfidence in neural network predictions, we ensure the successful recognition of private samples. By employing dual-consistency loss, we reduce channel instability and facilitate learning domain-invariant features. Experimental results on two multi-domain datasets demonstrate that DPSMR outperforms the state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Mengdi Xu and Yingjie Zhang and Biliang Lu and Zhaolin Liu and Qingshuai Sun},
  doi          = {10.1016/j.knosys.2024.112775},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112775},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel domain-private-suppress meta-recognition network based universal domain generalization for machinery fault diagnosis},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual alignment feature embedding network for multi-omics data clustering. <em>KBS</em>, <em>309</em>, 112774. (<a href='https://doi.org/10.1016/j.knosys.2024.112774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-omics data clustering, with its capability to utilize the biological information of cross-omics to partition cells into their respective clusters, has attracted considerable attention due to its effectiveness for pathological analysis. Aside from cross-omics discrepancy, existing methods suffer from distribution differences, making it difficult to learn high-quality cross-omics consistent information. To tackle this issue, we propose a novel dual alignment feature embedding network for multi-omics data clustering (DAMIC). Specifically, we first utilize an attention-induced feature fusion mechanism to capture intra-omics specific and inter-omics structural information for more discriminative features. Moreover, we maximize the mutual information between the unified target distribution and other omics-specific assignments by simultaneously optimizing contrastive learning loss and Kullback–Leibler (KL) divergence loss. Finally, we can extract omics-invariant features with robust and rich common embeddings for multi-omics clustering. Extensive experimental results on six real-world benchmark datasets demonstrate that our approach surpasses existing state-of-the-art methods in multi-omics data clustering analysis, which provides effective pathologic analysis way for tumors such as Leukemia and Colorectal Neoplasms. The source code is available at https://github.com/YuangXiao/DAMIC .},
  archive      = {J_KBS},
  author       = {Yuang Xiao and Dong Yang and Jiaxin Li and Xin Zou and Hua Zhou and Chang Tang},
  doi          = {10.1016/j.knosys.2024.112774},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112774},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual alignment feature embedding network for multi-omics data clustering},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-scale hierarchical spatio-temporal transformer for video enhancement. <em>KBS</em>, <em>309</em>, 112773. (<a href='https://doi.org/10.1016/j.knosys.2024.112773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diversity and complexity of degradations in low-quality videos pose non-trivial challenges on video enhancement to reconstruct the high-quality counterparts. Prevailing sliding window based methods represent poor performance due to the limitation of window size. Recurrent networks take advantage of long-term modeling to aggregate more information, resulting in significant performance improvements. However, most of them are trained on simple degraded data and can only tackle specific degradation. To break through the limitation, we propose a progressive alignment network, namely Cross-scale Hierarchical Spatio-Temporal Transformer (CHSTT), which leverages cross-scale tokenization to generate multi-scale visual tokens in the entire sequence to capture extensive long-range temporal dependencies. To enhance the spatial and temporal interactions, we introduce an innovative hierarchical Transformer, facilitating the computation of mutual multi-head attention across both spatial and temporal dimensions. Quantitative and qualitative assessments substantiate the superior performance of CHSTT compared to several state-of-the-art benchmarks across three distinct video enhancement tasks, including video super-resolution, video denoising, and video deblurring.},
  archive      = {J_KBS},
  author       = {Qin Jiang and Qinglin Wang and Lihua Chi and Jie Liu},
  doi          = {10.1016/j.knosys.2024.112773},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112773},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-scale hierarchical spatio-temporal transformer for video enhancement},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blind image quality assessment for in-the-wild images by integrating distorted patch selection and multi-scale-and-granularity fusion. <em>KBS</em>, <em>309</em>, 112772. (<a href='https://doi.org/10.1016/j.knosys.2024.112772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images taken in natural environments often exhibit complicated distortions, posing significant challenges for assessing their quality. Although current methods prioritize the perception of image contents and distortions, few explicitly investigate local distortions, a crucial factor affecting human visual perception. To mitigate this, this paper proposes a novel blind image quality assessment (IQA) method for in-the-wild images, termed DPSF, which integrates Distorted Patch Selection and multi-scale and multi-granularity feature Fusion. Specifically, it is first explained that the distributions of the mean subtracted contrast normalized coefficients of distorted patches differ from those of undistorted patches. Building upon this, an effective strategy for distorted patch selection is devised. Subsequently, a hybrid Transformer-convolutional neural network (CNN) module is proposed to exploit the benefits of both Transformer and CNN for distortion perception, in which the long-range dependencies of the selected patches are considered. Finally, an effective fusion module is employed for image quality evaluation, amalgamating finer and richer semantic and distortion features from multiple scales and granularities. Experimental results on five authentic IQA databases demonstrate that the proposed method yields more precise quality predictions compared with the state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jili Xia and Lihuo He and Xinbo Gao and Bo Hu},
  doi          = {10.1016/j.knosys.2024.112772},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112772},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blind image quality assessment for in-the-wild images by integrating distorted patch selection and multi-scale-and-granularity fusion},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient consistency strategy cooperative meta-feature learning for mixed domain generalized machine fault diagnosis. <em>KBS</em>, <em>309</em>, 112771. (<a href='https://doi.org/10.1016/j.knosys.2024.112771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fault diagnosis methods based on domain generalization (DG) have been developed to improve the diagnostic performance of unseen target domains by multi-source domain knowledge transfer. However, existing methods assume that the source domains are discrete and that domain labels are known a priori, which is difficult to satisfy in complex and changing industrial systems. In addition, the gradient update conflict caused by the specific information of source domains leads to the degradation of the DG performance. Therefore, in this study, we relax the discrete domain assumption to the mixed domain setting and propose a novel gradient-consistency strategy cooperative meta-feature learning for mixed-domain generalized machine fault diagnosis. First, a domain feature-guided adaptive normalization module is proposed to normalize the underlying distribution of multi-source domains, and the mixed-source domains are divided into potential domain clusters. Then, a novel meta-feature encoding method is proposed to explicitly encode the overall fault feature structure, which is used to learn the generalized fault feature representation. Finally, a novel gradient consistency update strategy is designed to reduce the impact of domain-specific differences on model generalization. The effectiveness and superiority of the proposed method are verified on many DG diagnostic tasks on two public bearing datasets and the nuclear circulating water pump planetary gearbox dataset.},
  archive      = {J_KBS},
  author       = {Shushuai Xie and Wei Cheng and Ji Xing and Xuefeng Chen and Zelin Nie and Qian Huang and Rongyong Zhang},
  doi          = {10.1016/j.knosys.2024.112771},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112771},
  shortjournal = {Knowl. Based Syst.},
  title        = {Gradient consistency strategy cooperative meta-feature learning for mixed domain generalized machine fault diagnosis},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCD-JFSE: Graph-based class-domain knowledge joint feature selection and ensemble learning for EEG-based emotion recognition. <em>KBS</em>, <em>309</em>, 112770. (<a href='https://doi.org/10.1016/j.knosys.2024.112770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has demonstrated strong performance in emotion recognition using intrasubject electroencephalography (EEG) data. However, it faces challenges due to individual differences and the nonstationarity of EEG signals in cross-subject and cross-session emotion recognition. Currently, research on incorporating domain information into feature selection for cross-domain (subject or session) emotion recognition remains limited. To address this issue, we propose a graph-based class-domain knowledge joint feature selection and ensemble learning approach. Firstly, an undirected, fully connected weighted graph is constructed to capture the relationship between features. Then, some metrics such as domain scatter, domain correlation, and domain standard deviation are introduced to guide feature selection. Subsequently, soft voting ensemble learning is employed to enhance recognition performance. To validate the effectiveness of our method, we conduct experiments on public datasets (SEED, SEED_IV, DREAMER), achieving accuracies of 78.67% on SEED, 58.98% on SEED_IV, 61.11% of valence and 72.46% of arousal on DREAMER in a cross-subject scenario. In the cross-session scenario, we obtain 87.11% on SEED and 60.74% on SEED_IV. The proposed method outperforms state-of-the-art approaches. This study not only expands the application of feature selection in emotion recognition but also provides a potential strategy to enhance the performance of real-world EEG-based emotion recognition applications.},
  archive      = {J_KBS},
  author       = {Gang Luo and Yutong Han and Weichu Xie and Fuze Tian and Lixian Zhu and Kun Qian and Xiaowei Li and Shuting Sun and Bin Hu},
  doi          = {10.1016/j.knosys.2024.112770},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112770},
  shortjournal = {Knowl. Based Syst.},
  title        = {GCD-JFSE: Graph-based class-domain knowledge joint feature selection and ensemble learning for EEG-based emotion recognition},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source partial domain adaptation with gaussian-based dual-level weighting for PPG-based heart rate estimation. <em>KBS</em>, <em>309</em>, 112769. (<a href='https://doi.org/10.1016/j.knosys.2024.112769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoplethysmography (PPG) signals from wearable devices have expanded the accessibility of heart rate estimation. Recent advances in deep learning have significantly improved the generalizability of heart rate estimation from PPG signals. However, these models exhibit performance degradation when used for new subjects with different PPG distributions. Although previous studies have attempted subject-specific training and fine-tuning techniques, they require labeled data for each new subject, limiting their practicality. In response, we explore the application of domain adaptation techniques using only unlabeled PPG signals from the target subject. However, naive domain adaptation approaches do not adequately account for the variability in PPG signals among different subjects in the training dataset. Furthermore, they overlook the possibility that the heart rate range of the target subject may only partially overlap with that of the source subjects. To address these limitations, we propose a novel multi-source partial domain adaptation method, GAussian-based dUaL-level weighting (GAUL), designed for the PPG-based heart rate estimation, formulated as a regression task. GAUL considers and adjusts the contribution of relevant source data at the domain and sample levels during domain adaptation. The experimental results on three benchmark datasets demonstrate that our method outperforms existing domain adaptation approaches, enhancing the heart rate estimation accuracy for new subjects without requiring additional labeled data. The code is available at: https://github.com/Im-JihyunKim/GAUL .},
  archive      = {J_KBS},
  author       = {Jihyun Kim and Hansam Cho and Minjung Lee and Seoung Bum Kim},
  doi          = {10.1016/j.knosys.2024.112769},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112769},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source partial domain adaptation with gaussian-based dual-level weighting for PPG-based heart rate estimation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multivariate time series anomaly detection method with multi-grain dynamic receptive field. <em>KBS</em>, <em>309</em>, 112768. (<a href='https://doi.org/10.1016/j.knosys.2024.112768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multivariate time series (MTS) anomaly detection methods based on masked reconstruction pose challenges in model training by setting unknown areas to the data, compelling the model to explore deeper patterns to enhance its performance. Due to the low information density of MTS, point-masked methods relying on timestamps can only capture a limited amount of data information, while patch-masked methods based on segments can more effectively uncover advanced semantic features of underlying trends in MTS. However, patch-masked methods process MTS with either fixed or random masks, which may not only sacrifice the known information but also impose restrictions on the size of mask blocks during the reconstruction process. In this paper, a multivariate time series anomaly detection method with Multi-Grain Dynamic Receptive Field (MGDRF) is proposed. MGDRF designs multi-grain mask strategies to excavate semantic features of MTS ranging from lower to higher levels. The dynamic receptive fields are specifically crafted to mitigate information loss encountered in existing methods, thereby facilitating learning of temporal and dimensional relationships of the data. Furthermore, MGDRF incorporates the receptive-field-based and model-based layered losses. It establishes primary losses for each single-grain receptive field, enabling the extraction of different semantic features. Based on ensemble learning, MGDRF constructs a model-based loss through the fusion of outcomes from multiple grains of dynamic receptive fields, thereby further learning the interaction characteristics among different grains of MTS. Extensive experiments on five representative public datasets demonstrate that the proposed algorithm exhibits more advanced performance compared to 18 typical MTS anomaly detection methods.},
  archive      = {J_KBS},
  author       = {Lingli Chen and Xin Gao and Jing Liu and Yunkai Zhang and Xinping Diao and Taizhi Wang and Jiawen Lu and Zhihang Meng},
  doi          = {10.1016/j.knosys.2024.112768},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112768},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multivariate time series anomaly detection method with multi-grain dynamic receptive field},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCORE: Simple contrastive representation and reset-ensemble for offline meta-reinforcement learning. <em>KBS</em>, <em>309</em>, 112767. (<a href='https://doi.org/10.1016/j.knosys.2024.112767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline meta-reinforcement learning (OMRL) aims to train agents to quickly adapt to new tasks using only pre-collected data. However, existing OMRL methods often involve numerous ineffective training iterations and may experience performance collapse in the later stages of training. We identify the root cause—shallow memorization problem, where agents overspecialize in specific solutions for encountered states, hindering their generalization performance. This issue arises due to the loss of plasticity and the premature fitting of neural networks, which restricts the exploration of the agents. To address this challenge, we propose S imple CO ntrastive Representation and R eset- E nsemble for OMRL (SCORE), a novel context-based OMRL approach. SCORE introduces an end-to-end contrastive learning framework without negative samples to pre-train a context encoder, enabling more robust task representations. Subsequently, the context encoder is fine-tuned during meta-training. Furthermore, SCORE employs a Reset-Ensemble mechanism that periodically resets and ensembles partial networks to maintain the agents’ continual learning ability and enhance their perception of characteristics across diverse tasks. Extensive experiments demonstrate that our SCORE method effectively avoids premature fitting and exhibits excellent generalization performance.},
  archive      = {J_KBS},
  author       = {Hanjie Yang and Kai Lin and Tao Yang and Guohan Sun},
  doi          = {10.1016/j.knosys.2024.112767},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112767},
  shortjournal = {Knowl. Based Syst.},
  title        = {SCORE: Simple contrastive representation and reset-ensemble for offline meta-reinforcement learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain generalization via geometric adaptation over augmented data. <em>KBS</em>, <em>309</em>, 112765. (<a href='https://doi.org/10.1016/j.knosys.2024.112765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenge of adapting deep learning models trained on specific datasets to effectively generalize to similar-class dataset with different underlying distributions. We introduce a novel deep representation learning method that takes into account both statistical and geometric properties of features for domain generalization. Our approach utilizes Fourier augmentation and Nyström estimation to evaluate the similarity between graphs derived from original and augmented data features. Furthermore, we employ a contrastive loss function to maintain proximity among samples belonging to the same class while ensuring separation between samples from different classes in the feature space. By minimizing these loss functions, our method aims to enhance model generalizability across diverse domains. Comprehensive experiments conducted on real-world benchmark datasets, including PACS, Office-Home, VLCS, Digits-DG and UTKFace, demonstrate the effectiveness of the proposed method. The results consistently indicate superior performance compared to other approaches under various conditions, underscoring its robustness in achieving improved generalization across domains.},
  archive      = {J_KBS},
  author       = {Ali Atghaei and Mohammad Rahmati},
  doi          = {10.1016/j.knosys.2024.112765},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112765},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain generalization via geometric adaptation over augmented data},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GKA-GPT: Graphical knowledge aggregation for multiturn dialog generation. <em>KBS</em>, <em>309</em>, 112763. (<a href='https://doi.org/10.1016/j.knosys.2024.112763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human interaction, effective communication relies on shared cognitive processes that facilitate the ability of individuals to comprehend the intended message of their interlocutors. Recent research in multiturn dialog generation seeks to emulate human-like responses by incorporating external knowledge into generative models to enhance language understanding. These models often utilize graphical representations of knowledge and employ graph neural networks (GNNs) to capture dialog semantics. However, sole reliance on external knowledge can fall short as human cognition integrates universal commonsense and personal knowledge, with the latter being derived from individual experiences and frequently disregarded. To remedy this, we propose GKA-GPT, a novel GNN-based approach that merges commonsense and personal knowledge into a comprehensive cognition graph to enhance the relevance and diversity of responses in multiturn dialog scenarios. Furthermore, GKA-GPT introduces a multigrained graphical knowledge aggregation mechanism for effective semantic information processing across various levels. Our experiments demonstrate that GKA-GPT outperforms existing baselines by generating more relevant and informative responses.},
  archive      = {J_KBS},
  author       = {Yuezhou Dong and Ke Qin and Shuang Liang and Ahmad Raza and Guangchun Luo},
  doi          = {10.1016/j.knosys.2024.112763},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112763},
  shortjournal = {Knowl. Based Syst.},
  title        = {GKA-GPT: Graphical knowledge aggregation for multiturn dialog generation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended ARMA graph neural networks for the prognosis of complex systems. <em>KBS</em>, <em>309</em>, 112762. (<a href='https://doi.org/10.1016/j.knosys.2024.112762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of intelligent sensing techniques, massive monitoring signals are collected and accumulated from industrial systems. Given that sensors are often correlated and constructed to reflect graph topology, the signals can be conceptualized as graph data. The polynomial filter-based graph neural networks (GNNs) are commonly employed to exploit information from nodes features and graph topology for graph data analysis. However, the polynomial filter-based GNNs encounter difficulty in accurately modeling sharp changes and the coefficients can vary a lot, making them hard to learn. To address this problem, a novel graph neural network named extended auto-regressive moving average graph neural network (eAGNN) is proposed. Compared with auto-regressive moving average (ARMA) neural network, the order restriction are removed, allowing for the inference of a more general neural network, which enables the modeling of filters with more different shapes. Furthermore, both low-frequency and high-frequency information are explicitly and separately extracted so as to alleviate the burden of the learning process and further enhance the learning capability. Finally, several experiments including public node classification and fault diagnosis were conducted. The results demonstrate that the proposed eAGNN exhibits high performance compared to alternative methods.},
  archive      = {J_KBS},
  author       = {Zhizhen Wang and Liu Fu and Meng Ma and Zhi Zhai and Hui Chen},
  doi          = {10.1016/j.knosys.2024.112762},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112762},
  shortjournal = {Knowl. Based Syst.},
  title        = {Extended ARMA graph neural networks for the prognosis of complex systems},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft prompt tuning for augmenting dense retrieval with large language models. <em>KBS</em>, <em>309</em>, 112758. (<a href='https://doi.org/10.1016/j.knosys.2024.112758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the major challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning. Recently, researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works are suboptimal and the generated weak queries are often sensitive to the prompts. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): for each task, we leverage soft prompt tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding weak document–query pairs to train task-specific dense retrievers. We design a filter to select high-quality example document–query pairs in the prompt to further improve the quality of weak tagged queries. To the best of our knowledge, there is no prior work utilizing soft prompt tuning to augment DR models. Moreover, unlike much of the existing work, ours is based on popular open-source LLMs to ensure reproducible and deterministic results. Our experimental results demonstrate that SPTAR outperforms both unsupervised baselines and the recently proposed LLMs-based augmentation method for DR.},
  archive      = {J_KBS},
  author       = {Zhiyuan Peng and Xuyang Wu and Qifan Wang and Yi Fang},
  doi          = {10.1016/j.knosys.2024.112758},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112758},
  shortjournal = {Knowl. Based Syst.},
  title        = {Soft prompt tuning for augmenting dense retrieval with large language models},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DE-PSA: Learning from unlabeled data by dual-stage label propagation for positive selection algorithm. <em>KBS</em>, <em>309</em>, 112757. (<a href='https://doi.org/10.1016/j.knosys.2024.112757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial immune detectors are the basic classification units for self/nonself discrimination. Traditional immune detector generation algorithms adopt supervised learning paradigm, relying on a large number of labeled samples to fully train the candidate detectors. However, in practical applications it is often difficult to obtain sufficient labeled training samples, resulting in model’s insufficient learning problems. In the paper, we proposed a semi-supervised detector generation algorithm DE-PSA, which generates immune detectors using some initially labeled samples and a large number of unlabeled samples. DE-PSA consists of two main steps: dual-stage label propagation and detector generation. In the first stage of label propagation, pseudo labels are propagated to each unlabeled sample from its k-nearest labeled neighbors based on category influence calculations. According to the calculation results, we can select samples with highly credible pseudo (HCP) labels and partial labeled (PAL) samples which have multiple candidate labels. In the second label propagation stage, following partial label learning theory, category probabilities are iteratively propagated from the initially labeled and HCP labeled samples to the PAL samples to achieve label disambiguation; Subsequently, self (positive) and nonself (negative) samples are selected from the initially labeled samples, HCP labeled samples, and disambiguated PAL samples to constitute training set. Based on the set, DE-PSA generates self-detectors with variable radii using a positive selection process. Comprehensive tests on 10 standard datasets are carried out to test DE-PSA, and the true positive rates of self/nonself samples: T P S and T P N are taken as evaluation metrics. The results show that DE-PSA outperforms traditional algorithms, such that compared with newly proposed DGA-PSO, SA-PSA,HI-Detector, the average true positive rate of DE-PSA is raised by 23%, 19.5%, 16.5% respectively, and when compared with state-of-the-art algorithm co-PSA, only with 0.1‰ initially labeled training samples, DE-PSA and co-PSA has similar T P S , but DE-PSA’s T P N is raised by 30%.},
  archive      = {J_KBS},
  author       = {Wen Chen and Yiyao Yang and Liang Liu},
  doi          = {10.1016/j.knosys.2024.112757},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112757},
  shortjournal = {Knowl. Based Syst.},
  title        = {DE-PSA: Learning from unlabeled data by dual-stage label propagation for positive selection algorithm},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TreeC: A method to generate interpretable energy management systems using a metaheuristic algorithm. <em>KBS</em>, <em>309</em>, 112756. (<a href='https://doi.org/10.1016/j.knosys.2024.112756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy management systems (EMS) have traditionally been implemented using rule-based control (RBC) and model predictive control (MPC) methods. However, recent research has explored the use of reinforcement learning (RL) as a promising alternative. This paper introduces TreeC, a machine learning method that utilises the covariance matrix adaptation evolution strategy metaheuristic algorithm to generate an interpretable EMS modelled as a decision tree. Unlike RBC and MPC approaches, TreeC learns the decision strategy of the EMS based on historical data, adapting the control model to the controlled energy grid. The decision strategy is represented as a decision tree, providing interpretability compared to RL methods that often rely on black-box models like neural networks. TreeC is evaluated against MPC with perfect forecast and RL EMSs in two case studies taken from literature: an electric grid case and a household heating case. In the electric grid case, TreeC achieves an average energy loss and constraint violation score of 19.2, which is close to MPC and RL EMSs that achieve scores of 14.4 and 16.2 respectively. All three methods control the electric grid well especially when compared to the random EMS, which obtains an average score of 12 875. In the household heating case, TreeC performs similarly to MPC on the adjusted and averaged electricity cost and total discomfort (0.033 EUR/m 2 and 0.42 Kh for TreeC compared to 0.037 EUR/m 2 and 2.91 kH for MPC), while outperforming RL (0.266 EUR/m 2 and 24.41 Kh). TreeC demonstrates a performant and interpretable application of machine learning for EMSs.},
  archive      = {J_KBS},
  author       = {Julian Ruddick and Luis Ramirez Camargo and Muhammad Andy Putratama and Maarten Messagie and Thierry Coosemans},
  doi          = {10.1016/j.knosys.2024.112756},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112756},
  shortjournal = {Knowl. Based Syst.},
  title        = {TreeC: A method to generate interpretable energy management systems using a metaheuristic algorithm},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CaMo: Capturing the modularity by end-to-end models for symbolic regression. <em>KBS</em>, <em>309</em>, 112747. (<a href='https://doi.org/10.1016/j.knosys.2024.112747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modularity is a ubiquitous principle that permeates various aspects of nature, society, and human endeavors, from biological systems to organizational structures and beyond. In the context of Symbolic Regression, which aims to find the explicit expressions from observed data, modularity could be viewed as a type of knowledge to capture the salient substructure to achieve higher fitting results. Symbolic Regression is essentially a composition optimization problem thus remaining valuable sub-structures can provide efficiency to the subsequent search. In this paper, we propose to acquire modularity in a search process and use the term module indicating the useful sub-structure. Specifically, the end-to-end model is chosen to incorporate the module into the search procedure for its scalability and generalization ability. Modules are considered high-order knowledge and act as fundamental operators, expanding the search library of Symbolic Regression. The proposed algorithm enables self-learning or self-evolution of modules as part of the learning component. Additionally, a module extraction strategy generates modules hierarchically from the expression tree, along with a module update mechanism designed to eliminate unnecessary modules while incorporating new useful ones effectively. Experiments were conducted to evaluate the effectiveness of each component.},
  archive      = {J_KBS},
  author       = {Jingyi Liu and Min Wu and Lina Yu and Weijun Li and Wenqiang Li and Yanjie Li and Meilan Hao and Yusong Deng and Shu Wei},
  doi          = {10.1016/j.knosys.2024.112747},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112747},
  shortjournal = {Knowl. Based Syst.},
  title        = {CaMo: Capturing the modularity by end-to-end models for symbolic regression},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing learning process modeling for session-aware knowledge tracing. <em>KBS</em>, <em>309</em>, 112740. (<a href='https://doi.org/10.1016/j.knosys.2024.112740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-aware knowledge tracing tries to predict learners’ performance, by splitting learners’ sequences into sessions and modeling their learning within and between sessions. However, there still is a lack of comprehensive understanding of the learning processes and session-form learning patterns. Moreover, the knowledge state shifts between sessions at the knowledge concept level remain unexplored. To this end, we conduct in-depth data analysis to understand learners’ learning processes and session-form learning patterns. Then, we perform an empirical study validating knowledge state shifts at the knowledge concept level in real-world educational datasets. Subsequently, a method of Enhancing Learning Process Modeling for Session-aware Knowledge Tracing, ELPKT, is proposed to capture the knowledge state shifts at the knowledge concept level and track knowledge state across sessions. Specifically, the ELPKT models learners’ learning process as intra-sessions and inter-sessions from the knowledge concept level. In intra-sessions, fine-grained behaviors are used to capture learners’ short-term knowledge states accurately. In inter-sessions, learners’ knowledge retentions and decays are modeled to capture the knowledge state shift between sessions. Extensive experiments on four real-world datasets demonstrate that ELPKT outperforms the existing methods in learners’ performance prediction. Additionally, ELPKT shows its ability to capture the knowledge state shifts between sessions and provide interpretability for the predicted results.},
  archive      = {J_KBS},
  author       = {Chunli Huang and Wenjun Jiang and Kenli Li and Jie Wu and Ji Zhang},
  doi          = {10.1016/j.knosys.2024.112740},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112740},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing learning process modeling for session-aware knowledge tracing},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new graph-based clustering method with dual-feature regularization and laplacian rank constraint. <em>KBS</em>, <em>309</em>, 112738. (<a href='https://doi.org/10.1016/j.knosys.2024.112738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph-based clustering is commonly limited by two-stage processing (Constructing and dividing similarity graph) and the quality of similar graphs. To this end, we propose a new graph-based clustering method with dual-feature regularization and Laplacian rank constraint. Specifically, our method reveals the clustering structure and unifies the two-stage process. It imposes a Laplacian rank constraint on the similarity graph to ensure that it has C connected components. In addition, a method based on dual-feature regularization is designed to capture local data feature information from both feature extraction and adaptive regression, and is applied to an accurate distance metric learning. A reweighting optimization is integrated to learn a high-quality robust similarity graph. Comprehensive experiments on Ecoli, Yale and Yeast datasets show that our method outperforms the existing graph-based clustering methods with an average improvement of about 4%, 5% and 7% on the evaluation metrics ACC, NMI and RI, respectively.},
  archive      = {J_KBS},
  author       = {Hengdong Zhu and Yingshan Shen and Choujun Zhan and Fu Lee Wang and Heng Weng and Tianyong Hao},
  doi          = {10.1016/j.knosys.2024.112738},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112738},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new graph-based clustering method with dual-feature regularization and laplacian rank constraint},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing fault detection in self-healing network via multi-serial cascaded and adaptive network. <em>KBS</em>, <em>309</em>, 112732. (<a href='https://doi.org/10.1016/j.knosys.2024.112732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-Healing Network (SHN) plays a crucial role in the realm of digital networking and the telecommunications industry. Fault detection in SHN is a critical aspect of network management and maintenance, which acts as a pivotal role in maintaining network health and minimizing disruptions. The SHN networks aim to manage faults and system failures by automating the detection process and pinpointing their origins. This proactive approach is essential to maintain network integrity and ensure a seamless user experience. In this paper, a novel multi-Serial cascaded and Adaptive Network based fault Detection in SHN (SAND-SHN) technique has been proposed for detecting faults in the SHN network. The proposed method uses the Eigen-Entropy Synthetic Minority Oversampling Technique (EE-SMOTE) to balance imbalanced data for classification and the Multi-Serial Cascaded and Adaptive Network (MSCAN), which integrates deep learning (DL) techniques to attain the final classified outcome. The proposed SAND-SHN method has been evaluated using a Python environment in terms of specific parameters such as accuracy, precision, recall, specificity, and F1-Score. The proposed technique has been evaluated using two datasets as EFCD dataset, and the SFDD dataset. The proposed SAND-SHN technique achieves a higher accuracy of 74% for RSO-MSCAN, 39.2% for DMO-MSCAN, 48.8% for BFGO-MSCAN, and 43.6% for FHO-MSCAN respectively.},
  archive      = {J_KBS},
  author       = {Caleb S and John Justin Thangaraj S and Padmapriya G and Nandhini T J and Finney Daniel Shadrach and Latha R},
  doi          = {10.1016/j.knosys.2024.112732},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112732},
  shortjournal = {Knowl. Based Syst.},
  title        = {Revolutionizing fault detection in self-healing network via multi-serial cascaded and adaptive network},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Individualized image steganography method with dynamic separable key and adaptive redundancy anchor. <em>KBS</em>, <em>309</em>, 112729. (<a href='https://doi.org/10.1016/j.knosys.2024.112729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography hides several secret images into a single cover image to produce a stego image. For transmission security, the stego image is visually indistinguishable from the cover image. Furthermore, for effective transmission of secret information, the receivers should recover the secret images with high quality. With the increasing steganography capacity, a stego image containing many secret images is transmitted through public channels. However, in the existing image steganography methods, all the secret images are usually revealed without quarantine among various recipients. This problem casts a threat to security in the recovery process. In order to overcome this issue, we propose the Individualized Image Steganography ( IIS ) Method with Dynamic Separable Key (DSK) and Adaptive Redundancy Anchor (ARA). Specifically, in the process of hiding secret images, the proposed DSK dynamically generates a global key and a local key and appropriately fuses them together. In the same batch of transmission, all recipients share the same global key, but each has a different local key. Only by matching both the global key and the local key simultaneously, can the secret image be restored by the specific receiver, which makes the secret image individualized for the target recipient. Additionally, in the process of revealing secret images, the proposed ARA learns the adaptive redundancy anchor for the inverse training to drive the input redundancy of revealing (backward) process and output redundancy of hiding (forward) process to be close. This achieves a better trade-off between the performances of hiding and revealing processes, and further enhances both the quality of restored secret images and stego images. Jointly using the DSK and ARA, a series of experiments have verified that our IIS method has achieved satisfactory performance improvements in extensive aspects. Code is available in https://github.com/Revive624/Individualized-Invertible-Steganography .},
  archive      = {J_KBS},
  author       = {Junchao Zhou and Yao Lu and Guangming Lu},
  doi          = {10.1016/j.knosys.2024.112729},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112729},
  shortjournal = {Knowl. Based Syst.},
  title        = {Individualized image steganography method with dynamic separable key and adaptive redundancy anchor},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DATA: Dynamic adversarial thermal anti-distillation. <em>KBS</em>, <em>309</em>, 112728. (<a href='https://doi.org/10.1016/j.knosys.2024.112728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anti-distillation techniques have been effectively used to remove the dark knowledge from the teacher model while maintaining its capability. Although the temperature plays a crucial role in knowledge distillation, its impact on the anti-distillation task remains an under-explored area. In this work, we deeply explore the impact of temperature variation on model performance and anti-distillation capability during the anti-distillation process and proposes a Dynamic Adversarial Thermal Anti-distillation method (DATA). By dynamically adjusting the temperature, this method aims to retain the performance of the anti-distillation model without sacrificing anti-distillation performance, achieving the optimal balance between model performance and anti-distillation capability. Experimental results show that our method performs excellently on datasets such as CIFAR-100 and Tiny-ImageNet, which exhibits a maximum reduction on anti-distillation model of 2.31% on CIFAR-100 and 5.28% on Tiny-ImageNet. In addition, our method also can effectively deal with various distillation methods including logits distillation, feature distillation, and data-free distillation, which outperform previous anti-distillation methods in terms of performance.},
  archive      = {J_KBS},
  author       = {Yao Zhang and Yang Li and Zhisong Pan},
  doi          = {10.1016/j.knosys.2024.112728},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112728},
  shortjournal = {Knowl. Based Syst.},
  title        = {DATA: Dynamic adversarial thermal anti-distillation},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse semantic image synthesis with various conditioning modalities. <em>KBS</em>, <em>309</em>, 112727. (<a href='https://doi.org/10.1016/j.knosys.2024.112727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic image synthesis aims to generate high-fidelity images from a segmentation mask, and previous methods typically train a generator to associate a global random map with the conditioning mask. However, the lack of independent control of regional content impedes their application. To address this issue, we propose an effective approach for Multi-modal conditioning-based Diverse Semantic Image Synthesis, which is referred to as McDSIS. In this model, there are a number of constituent generators incorporated to synthesize the content in semantic regions from independent random maps. The regional content can be determined by the style code associated with a random map, extracted from a reference image, or by embedding a textual description via our proposed conditioning mechanisms. As a result, the generation process is spatially disentangled, which facilitates independent synthesis of diverse content in a semantic region, while at the same time preserving other content. Due to this flexible architecture, in addition to achieving superior performance over state-of-the-art semantic image generation models, McDSIS is capable of performing various visual tasks, such as face inpainting, swapping, local editing, etc.},
  archive      = {J_KBS},
  author       = {Chaoyue Wu and Rui Li and Cheng Liu and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2024.112727},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112727},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diverse semantic image synthesis with various conditioning modalities},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CIDGMed: Causal inference-driven medication recommendation with enhanced dual-granularity learning. <em>KBS</em>, <em>309</em>, 112685. (<a href='https://doi.org/10.1016/j.knosys.2024.112685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication recommendation aims to integrate patients’ long-term health records to provide accurate and safe medication combinations for specific health states. Existing methods often fail to deeply explore the true causal relationships between diseases/procedures and medications, resulting in biased recommendations. Additionally, in medication representation learning, the relationships between information at different granularities of medications—coarse-grained (medication itself) and fine-grained (molecular level)—are not effectively integrated, leading to biases in representation learning. To address these limitations, we propose the Causal Inference-driven Dual-Granularity Medication Recommendation method (CIDGMed). Our approach leverages causal inference to uncover the relationships between diseases/procedures and medications, thereby enhancing the rationality and interpretability of recommendations. By integrating coarse-grained medication effects with fine-grained molecular structure information, CIDGMed provides a comprehensive representation of medications. Additionally, we employ a bias correction model during the prediction phase to further refine recommendations, ensuring both accuracy and safety. Through extensive experiments, CIDGMed significantly outperforms current state-of-the-art models across multiple metrics, achieving a 2.54% increase in accuracy, a 3.65% reduction in side effects, and a 39.42% improvement in time efficiency. Additionally, we demonstrate the rationale of CIDGMed through a case study.},
  archive      = {J_KBS},
  author       = {Shunpan Liang and Xiang Li and Shi Mu and Chen Li and Yu Lei and Yulei Hou and Tengfei Ma},
  doi          = {10.1016/j.knosys.2024.112685},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112685},
  shortjournal = {Knowl. Based Syst.},
  title        = {CIDGMed: Causal inference-driven medication recommendation with enhanced dual-granularity learning},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain features exploration in temporal moment localization via language by utilizing customized temporal transformer. <em>KBS</em>, <em>309</em>, 112667. (<a href='https://doi.org/10.1016/j.knosys.2024.112667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal moment localization in videos using natural language (TMLVNL) is challenging problem in computer vision. TMLVNL aims to determine the correct moment in a lengthy, untrimmed video that corresponds to the input query. In addition to its inherent complexity, TMLVNL encounters several additional difficulties that can degrade performance, such as rare object positions, occlusions, camera focus issues, and motion blurriness. To address these issues, this study proposes a novel solution called the Temporal Ziggurat Transformer Network. First, we developed a novel method rather than relying on various combinational approaches. Second, we proposed complicated scenarios, such as unusual object postures, object occlusions, camera focus issues, and motion blurriness, by incorporating specialized blocks into our Customized Ziggurat Transformer (ZT) to thoroughly explore visual features. Third, to facilitate the understanding of visual features associated with query words, we proposed a query word-specific transformer (QWST) as a submodule of ZT. QWST integrates query word feature representations with extensively investigated visual features. Fourth, in our module named STDF, we managed query-sentence representations along with query word attributes to extract semantic context from video chunks. The moment was then localized, with its start and end borders identified using the moment localization module. Comprehensive experiments on the Charades-STA, TACos, and Activity-Netcaption datasets demonstrated that our strategy outperformed existing state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Hafiza Sadia Nawaz and Daming Shi and Xiaoyan Zhang},
  doi          = {10.1016/j.knosys.2024.112667},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112667},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncertain features exploration in temporal moment localization via language by utilizing customized temporal transformer},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term traffic speed prediction utilizing data augmentation via segmented time frame clustering. <em>KBS</em>, <em>308</em>, 112785. (<a href='https://doi.org/10.1016/j.knosys.2024.112785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among many traffic forecasting studies, comparatively fewer studies focus on long-term traffic prediction, such as 24-hour prediction. While traffic data such as traffic speed are easier to obtain, obtaining similarly reliable and accessible feature data with the inclusion of weather or events would be difficult depending on the location or availability of the service providers. Getting these data becomes a more significant issue when considering global coverage. To mitigate the issue of limited feature data, a method to augment already existing data by improving the dataset's quality and ensuring more accurate training via sorting the dataset into appropriate clusters to be used as an additional feature is proposed. This paper proposes a long-term traffic forecasting model that utilizes a novel time-series segmentation method paired with data clustering and classification via Convolutional Neural Network (CNN) to cover the lack of traffic data and features as additional pre-processing before using Long Short-Term Memory (LSTM) for long-term traffic prediction which is not researched as much. This proposed model is called Cluster Augmented LSTM (CAL). The proposed model is compared with existing machine learning models and evaluated using Mean Absolute Percentage Error (MAPE) and Root-Mean-Squared-Error (RMSE) performance metrics. A comparison between LSTM and Gated Recurrent Units (GRU) was conducted, showing that GRU tends to outperform LSTM in most cases. However, the best-performing result for the proposed method still utilizes LSTM. The final results show that the proposed CAL model could achieve better results by 1.42 %-1.76 % and 0.25–0.41 for MAPE and RMSE, respectively.},
  archive      = {J_KBS},
  author       = {Robin Kuok Cheong Chan and Joanne Mun-Yee Lim and Rajendran Parthiban},
  doi          = {10.1016/j.knosys.2024.112785},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112785},
  shortjournal = {Knowl. Based Syst.},
  title        = {Long-term traffic speed prediction utilizing data augmentation via segmented time frame clustering},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep unfolding network based on intrinsic image decomposition for pansharpening. <em>KBS</em>, <em>308</em>, 112764. (<a href='https://doi.org/10.1016/j.knosys.2024.112764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening aims to obtain high-resolution multispectral images by fusing panchromatic and low-resolution multispectral images. However, current deep learning-based methods lack reasonable interpretability and suffer from certain spectral and spatial distortions. To address these issues, we propose an interpretable deep unfolding network based on intrinsic image decomposition, called DUN-IID. IID decomposes the multispectral image into a reflectance component and a shading component to formulate a novel variational optimization function. The reflectance and shading components effectively reflect spectral and spatial information, respectively. This decoupling strategy enhances feature fidelity by preventing interference between spectral and spatial information, enabling independent optimization of spatial reconstruction and spectral correction during fusion. The optimization function is solved by the half-quadratic splitting method and unfolded into the end-to-end DUN-IID, which consists of two primal update blocks for prior learning and two dual update blocks for reconstruction. To alleviate the effects of information loss across intermediate stages, we introduce the source images into two primal update blocks for information enhancement. Therefore, the reflectance and shading primal update blocks are customized as a multi-scale structure and a band-aware construction, respectively. Besides, the multi-dimension attention mechanism is adopted to improve feature representation. Extensive experiments validate that our method is superior to other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yufei Ge and Xiaoli Zhang and Bo Huang and Xiongfei Li and Siwei Ma},
  doi          = {10.1016/j.knosys.2024.112764},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112764},
  shortjournal = {Knowl. Based Syst.},
  title        = {A deep unfolding network based on intrinsic image decomposition for pansharpening},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CATrack: Condition-aware multi-object tracking with temporally enhanced appearance features. <em>KBS</em>, <em>308</em>, 112760. (<a href='https://doi.org/10.1016/j.knosys.2024.112760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Object Tracking (MOT) is a critical task in computer vision with a wide range of practical applications. However, current methods often use a uniform approach for associating all targets, overlooking the varying conditions of each target. This can lead to performance degradation, especially in crowded scenes with dense targets. To address this issue, we propose a novel Condition-Aware Tracking method (CATrack) to differentiate the appearance feature flow for targets under different conditions. Specifically, we propose three designs for data association and feature update. First, we develop an Adaptive Appearance Association Module (AAAM) that selects suitable track templates based on detection conditions, reducing association errors in long-tail cases like occlusions or motion blur. Second, we design an ambiguous track filtering Selective Update strategy (SU) that filters out potential low-quality embeddings. Thus, the noise accumulation in the maintained track feature will also be reduced. Meanwhile, we propose a confidence-based Adaptive Exponential Moving Average (AEMA) method for the feature state transition. By adaptively adjusting the weights of track and detection embeddings, our AEMA better preserves high-quality target features. By integrating the above modules, CATrack enhances the discriminative capability of appearance features and improves the robustness of appearance-based associations. Extensive experiments on the MOT17 and MOT20 benchmarks validate the effectiveness of the proposed CATrack. Notably, the state-of-the-art results on MOT20 demonstrate the superiority of our method in highly crowded scenarios.},
  archive      = {J_KBS},
  author       = {Yanchao Wang and Run Li and Dawei Zhang and Minglu Li and Jinli Cao and Zhonglong Zheng},
  doi          = {10.1016/j.knosys.2024.112760},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112760},
  shortjournal = {Knowl. Based Syst.},
  title        = {CATrack: Condition-aware multi-object tracking with temporally enhanced appearance features},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight video object segmentation: Integrating online knowledge distillation for fast segmentation. <em>KBS</em>, <em>308</em>, 112759. (<a href='https://doi.org/10.1016/j.knosys.2024.112759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The typical shortcoming of STM (Space-Time Memory Network) mode video object segmentation algorithms is their high segmentation performance coupled with slow processing speeds, which poses challenges in meeting real-world application demands. In this work, we propose using an online knowledge distillation method to develop a lightweight video segmentation algorithm based on the STM mode, achieving fast segmentation while maintaining performance. Specifically, we utilize a novel adaptive learning rate to tackle the issue of inverse learning during distillation. Subsequently, we introduce a Smooth Block mechanism to reduce the impact of structural disparities between the teacher and student models on distillation outcomes. Moreover, to reduce the fitting difficulty of the student model on single-frame features, we design the Space-Time Feature Fusion (STFF) module to provide appearance and position priors for the feature fitting process of each frame. Finally, we employ a simple Discriminator module for adversarial training with the student model, to encourage the student model to learn the feature distribution of the teacher model. Extensive experiments show that our algorithm attains performance comparable to the current state-of-the-art on both DAVIS and YouTube datasets, despite running up to × 4 faster, with × 20 fewer parameters and × 30 fewer GFLOPS.},
  archive      = {J_KBS},
  author       = {Zhiqiang Hou and Chenxu Wang and Sugang Ma and Jiale Dong and Yunchen Wang and Wangsheng Yu and Xiaobao Yang},
  doi          = {10.1016/j.knosys.2024.112759},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112759},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lightweight video object segmentation: Integrating online knowledge distillation for fast segmentation},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view attention graph convolutional networks for the host prediction of phages. <em>KBS</em>, <em>308</em>, 112755. (<a href='https://doi.org/10.1016/j.knosys.2024.112755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phages play pivotal roles in various biological processes, and the study of host prediction of phages (HPP) has received significant attention in recent years. HPP tries to find the specific bacteria that can be infected by certain phages, which is fundamental for the applications of targeted phage therapies and interventions. However, the existing HPP methods are mainly based on traditional wet-lab experiments which are laborious and time-consuming. Although certain computational methods have emerged to solve those issues, they perform poorly in genomes and contigs of phages as they neglect the similarity between phages in sequences and protein clusters. In this article, we propose a simple but accurate multi-view attention graph convolutional network (called PGCN) for solving the HPP problem. PGCN first constructs two phage similarity networks as a multi-view graph, which captures the similarity between phages in sequences and protein clusters. Then, PGCN uses a graph convolutional network to capture features of phages from the multi-view graph. Finally, PGCN proposes an adaptive attention mechanism to obtain the integrated features of phages from the multi-view features. Experimental results show the superiority of PGCN over the state-of-the-art methods in host prediction. The results also show the excellent performance of PGCN on host prediction in the metagenomes.},
  archive      = {J_KBS},
  author       = {Lijia Ma and Peng Gao and Wenxiang Zhou and Qiuzhen Lin and Yuan Bai and Min Fang and Zhihua Du and Jianqiang Li},
  doi          = {10.1016/j.knosys.2024.112755},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112755},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view attention graph convolutional networks for the host prediction of phages},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain dialogue state tracking via dual dynamic graph with hierarchical slot selector. <em>KBS</em>, <em>308</em>, 112754. (<a href='https://doi.org/10.1016/j.knosys.2024.112754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue state tracking aims to maintain user intent as a consistent state across multi-domains to accomplish natural dialogue systems. However, previous researches often fall short in capturing the difference of multiple slot types and fail to adequately consider the selection of discerning information. The increase in unnecessary information correlates with a decrease in predictive performance. Therefore, the careful selection of high-quality information is imperative. Moreover, considering that the types of essential and available information vary for each slot, the process of selecting appropriate information may also differ. To address these issues, we propose HS2DG-DST, a Hierarchical Slot Selector and Dual Dynamic Graph-based DST. Our model is designed to provide maximum information for optimal value prediction by clearly exploiting the need for differentiated information for each slot. First, we hierarchically classify slot types based on the multiple properties. Then, two dynamic graphs provide highly relevant information to each slot. Experimental results on MultiWOZ datasets demonstrate that our model outperforms state-of-the-art models.},
  archive      = {J_KBS},
  author       = {Yeseul Gong and Heeseon Kim and Seokju Hwang and Donghyun Kim and Kyong-Ho Lee},
  doi          = {10.1016/j.knosys.2024.112754},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112754},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain dialogue state tracking via dual dynamic graph with hierarchical slot selector},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-LoRA continual learning based instruction tuning framework for universal information extraction. <em>KBS</em>, <em>308</em>, 112750. (<a href='https://doi.org/10.1016/j.knosys.2024.112750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universal information extraction (Universal IE) aims to develop one model capable of solving multiple IE target tasks. Previous works have enhanced extraction performance of target tasks through auxiliary tasks. However, there are still limitations in terms of learning strategies. From one aspect, joint learning-based universal IE approaches, which simply mix auxiliary tasks with target tasks, fail to enable the model to master basic knowledge from auxiliary tasks before learning target tasks. From another aspect, continual learning-based universal IE approaches, which sequentially update all the model parameters on auxiliary tasks and target tasks, tend to cause catastrophic forgetting. In this study, we design a multi-LoRA continual learning-based instruction fine-tuning framework for universal IE. Specifically, we design unique LoRA modules for learning auxiliary tasks and target tasks. We first freeze pre-trained weights and update additional parameters on auxiliary tasks through one LoRA module. Subsequently, we keep the weights frozen and further adjust parameters through another LoRA module to adapt the model to the target tasks. Finally, we merge the frozen weights with learned weights, thereby enabling the model to better leverage the acquired abilities during the inference phase. Therefore, our model masters basic extraction abilities before learning target tasks and does not forget this basic knowledge during the target learning process. Moreover, we regard extraction, classification, and recognition as basic abilities and further design auxiliary tasks based on these basic abilities. Experimental results on 37 datasets across 3 tasks show that our approach reaches state-of-the-art performance.},
  archive      = {J_KBS},
  author       = {Yu Jin and Jie Liu and Shaowei Chen},
  doi          = {10.1016/j.knosys.2024.112750},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112750},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-LoRA continual learning based instruction tuning framework for universal information extraction},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series generation based on dual-channel transformer conditional GAN for industrial remaining useful life prediction. <em>KBS</em>, <em>308</em>, 112749. (<a href='https://doi.org/10.1016/j.knosys.2024.112749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is a key enabler of predictive maintenance. While deep learning based prediction methods have made great progress, the data imbalance issue caused by limited run-to-failure data severely undermines their performance. Some recent works employ generative adversarial network (GAN) to tackle this issue. However, most GAN-based generative methods have difficulties in simultaneously extracting correlations of different time steps and sensors. In this paper, we propose dual-channel Transformer conditional GAN (DCTC-GAN), a novel multivariate time series (MTS) generation framework, to generate high-quality MTS to enhance deep learning based RUL prediction models. We design a novel dual-channel Transformer architecture to construct the generator and discriminator, which consists of a temporal encoder and a spatial encoder that work in parallel to automatically pay different attention to different time steps and sensors. Based on this, DCTC-GAN can directly extract the long-distance temporal relations of different time steps while capturing the spatial correlations of different sensors to synthesize high-quality MTS data. Experimental analysis on widely used turbofan engine dataset and FEMTO bearing dataset demonstrates that our DCTC-GAN significantly enhances the performance of existing deep learning models for RUL prediction, without changing its structure, and exceeds the capabilities of current representative generative methods.},
  archive      = {J_KBS},
  author       = {Zhizheng Zhang and Hui Gao and Wenxu Sun and Wen Song and Qiqiang Li},
  doi          = {10.1016/j.knosys.2024.112749},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112749},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multivariate time series generation based on dual-channel transformer conditional GAN for industrial remaining useful life prediction},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UrduHope: Analysis of hope and hopelessness in urdu texts. <em>KBS</em>, <em>308</em>, 112746. (<a href='https://doi.org/10.1016/j.knosys.2024.112746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hope is a crucial aspect of human psychology that has received considerable attention due to its role in facing challenges in human life. However, current research predominantly focuses on hope as positive anticipation, overlooking its counterpart, hopelessness. This paper addresses this gap by presenting an expanded framework for analyzing hope speech in social media, incorporating hope and hopelessness. Drawing on insights from psychology and Natural Language Processing (NLP), we argue that a comprehensive understanding of human emotions necessitates considering both constructs. We introduce the concept of hopelessness as a distinct category in hope speech analysis and develop a novel dataset for Urdu, an underrepresented language in NLP research. We proposed a semi-supervised annotation procedure by utilizing Large Language Models (LLMs) along with human annotators to annotate the dataset and explored various learning approaches for hope speech detection, including traditional machine learning models, neural networks, and state-of-the-art transformers. The findings demonstrate the effectiveness of different learning approaches in capturing the nuances of hope speech in Urdu social media discourse. The hope speech detection task was modeled in two subtasks: a binary classification of Urdu tweets to Hope and Not Hope classes and then a multiclass classification of Urdu tweets into Generalized, Realistic, and Unrealistic Hopes, along with Hopelessness, and Not Hope (Neutral) categories. The best results for binary classification were obtained with Logistic Regression (LR) with an averaged macro F1 score of 0.7593, and for the multiclass classification experiments, transformers outperformed other experiments with an averaged macro F1 score of 0.4801.},
  archive      = {J_KBS},
  author       = {Fazlourrahman Balouchzahi and Sabur Butt and Maaz Amjad and Grigori Sidorov and Alexander Gelbukh},
  doi          = {10.1016/j.knosys.2024.112746},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112746},
  shortjournal = {Knowl. Based Syst.},
  title        = {UrduHope: Analysis of hope and hopelessness in urdu texts},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmentation based on large language models for radiological report classification. <em>KBS</em>, <em>308</em>, 112745. (<a href='https://doi.org/10.1016/j.knosys.2024.112745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The International Classification of Diseases (ICD) is fundamental in the field of healthcare as it provides a standardized framework for the classification and coding of medical diagnoses and procedures, enabling the understanding of international public health patterns and trends. However, manually classifying medical reports according to this standard is a slow, tedious and error-prone process, which shows the need for automated systems to offload the healthcare professional of this task and to reduce the number of errors. In this paper, we propose an automated classification system based on Natural Language Processing to analyze radiological reports and classify them according to the ICD-10. Since the specialized use of the language of radiological reports and the usual unbalanced distribution of medical report sets, we propose a methodology grounded in leveraging large language models for augmenting the data of unrepresented classes and adapting the classification language models to the specific use of the language of radiological reports. The results show that the proposed methodology enhances the classification performance on the CARES corpus of radiological reports.},
  archive      = {J_KBS},
  author       = {Jaime Collado-Montañez and María-Teresa Martín-Valdivia and Eugenio Martínez-Cámara},
  doi          = {10.1016/j.knosys.2024.112745},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112745},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data augmentation based on large language models for radiological report classification},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Affective body expression recognition framework based on temporal and spatial fusion features. <em>KBS</em>, <em>308</em>, 112744. (<a href='https://doi.org/10.1016/j.knosys.2024.112744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective body expression recognition technology enables machines to interpret non-verbal emotional signals from human movements, which is crucial for facilitating natural and empathetic human–machine interaction (HCI). This work proposes a new framework for emotion recognition from body movements, providing a universal and effective solution for decoding the temporal–spatial mapping between emotions and body expressions. Compared with previous studies, our approach extracted interpretable temporal and spatial features by constructing a body expression energy model (BEEM) and a multi-input symmetric positive definite matrix network (MSPDnet). In particular, the temporal features extracted from the BEEM reveal the energy distribution, dynamical complexity, and frequency activity of the body expression under different emotions, while the spatial features obtained by MSPDnet capture the spatial Riemannian properties between body joints. Furthermore, this paper introduces an attentional temporal–spatial feature fusion (ATSFF) algorithm to adaptively fuse temporal and spatial features with different semantics and scales, significantly improving the discriminability and generalizability of the fused features. The proposed method achieves recognition accuracies over 90% across four public datasets, outperforming most state-of-the-art approaches.},
  archive      = {J_KBS},
  author       = {Tao Wang and Shuang Liu and Feng He and Minghao Du and Weina Dai and Yufeng Ke and Dong Ming},
  doi          = {10.1016/j.knosys.2024.112744},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112744},
  shortjournal = {Knowl. Based Syst.},
  title        = {Affective body expression recognition framework based on temporal and spatial fusion features},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep spectral clustering by integrating local structure and prior information. <em>KBS</em>, <em>308</em>, 112743. (<a href='https://doi.org/10.1016/j.knosys.2024.112743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional spectral clustering (SC) is an effective clustering method that can handle data with complex structure. SC essentially embeds data in another feature space with time-consuming spectral embedding before clustering, and has to re-embed the whole data when unseen data arrive, lacking the so-called out-of-sample-extension capability. SpectralNet (Shaham et al., 2018) is a pioneer attempt to resolve these two problems by training with random mini-batches to scale to large-scale data and by an orthogonal transformation layer to ensure orthogonality of embeddings and remove redundancy in features. However, the randomly selected data in each mini-batch might be far away from each other and fail to convey local structural information; the orthogonal transformation can only ensure orthogonality for each mini-batch instead of the whole data. In this paper, we propose a novel approach to address these two problems. By improving data selection for batches with batch augmentation using neighboring information, it helps the network to better capture local structural information. By devising core point guidance to exploit the spectral embeddings of representative points as prior information, it guides the network to learn embeddings that can better maintain the overall structures of data points. Empirical results show that our method resolves the two problems of SpectralNet and exhibits superior clustering performance to SpectralNet and other state-of-the-art deep clustering algorithms, while being able to generalize the embedding to unseen data.},
  archive      = {J_KBS},
  author       = {Hua Meng and Yueyi Zhang and Zhiguo Long},
  doi          = {10.1016/j.knosys.2024.112743},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112743},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep spectral clustering by integrating local structure and prior information},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online learning discriminative sparse convolution networks for robust UAV object tracking. <em>KBS</em>, <em>308</em>, 112742. (<a href='https://doi.org/10.1016/j.knosys.2024.112742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable empirical success for UAV object tracking, current convolutional networks usually have three unavoidable limitations: (1) The feature maps produced by convolutional layers are difficult to interpret. (2) The network needs to be trained offline on a large-scale auxiliary training set, resulting in the feature extraction ability of the trained network depending on the categories of the training set. (3) The performance of networks suffers from sensitivity to hyper-parameters (such as learning rate and weight decay) when the network needs online fine-tuning. To overcome the three limitations, this paper proposes a Discriminative Sparse Convolutional Network (DSCN) that exhibits good layer-wise interpretability and can be trained online without requiring any auxiliary training data. By imposing sparsity constraints on the convolutional kernels, DSCN furnishes the convolution layer with an explicit data meaning, thus enhancing the interpretability of the feature maps. These convolutional kernels are directly learned online from image blocks, which eliminates the offline training process on auxiliary data sets. Moreover, a simple yet effective online tuning method with few hyper-parameters is proposed to fine-tune fully connected layers online. We have successfully applied DSCN to UAV object tracking and conducted extensive experiments on six mainstream UAV datasets. The experimental results demonstrate that our method performs favorably against several state-of-the-art tracking algorithms in terms of tracking accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Qi Xu and Zhuoming Xu and Huabin Wang and Yun Chen and Liang Tao},
  doi          = {10.1016/j.knosys.2024.112742},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112742},
  shortjournal = {Knowl. Based Syst.},
  title        = {Online learning discriminative sparse convolution networks for robust UAV object tracking},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A google trend enhanced deep learning model for the prediction of renewable energy asset price. <em>KBS</em>, <em>308</em>, 112733. (<a href='https://doi.org/10.1016/j.knosys.2024.112733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the predictive efficiency of various forecasting models for renewable energy asset prices, using oil price and investor sentiment. For renewable energy assets, renewable energy exchange-traded funds (ETFs) are considered in this study. We construct two sentiment indices using the first principal component: a fund-level investor sentiment index based on traditional indices (the Relative Strength Index and the Psychological Line Index) and the Google Trend Index derived from search trend data with keywords related to respective renewable energy ETFs. In this study, we propose a prediction model along with a deep learning framework, integrating both sentiment indices. We predict ETF log returns and conditional volatility using machine learning and deep learning models. To enhance predictive accuracy, we modify both the traditional sentiment and Google Trend indices. The results assert that models incorporating both the modified fund-level investor sentiment and Google Trends indices outperform unmodified indices. This study underscores the effectiveness of integrating multi-source sentiment for improved predictive performance, with a significant contribution by the Google Trend Index. Our model, particularly the CNN-LSTM, outperforms the CNN and BiLSTM models, as validated through Modified Diebold-Mariano tests. In addition to this benchmark, we perform additional benchmarking with forecasting techniques used in the latest ETF study and verify the robustness of our model. The findings of this study will be useful for different stakeholders of the renewable energy sector.},
  archive      = {J_KBS},
  author       = {Lalatendu Mishra and Balaji Dinesh and P.M. Kavyassree and Nachiketa Mishra},
  doi          = {10.1016/j.knosys.2024.112733},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112733},
  shortjournal = {Knowl. Based Syst.},
  title        = {A google trend enhanced deep learning model for the prediction of renewable energy asset price},
  volume       = {308},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EGFDA: Experience-guided fine-grained domain adaptation for cross-domain pneumonia diagnosis. <em>KBS</em>, <em>307</em>, 112752. (<a href='https://doi.org/10.1016/j.knosys.2024.112752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recent advances in deep learning have led to accurate pneumonia diagnoses, their heavy reliance on data annotation hinders their expected performance in clinical practice. Unsupervised domain adaptation (UDA) methods have been developed to address the scarcity of annotations. Nevertheless, the diverse manifestations of pneumonia pose challenges for current UDA methods, including spatial lesion-preference bias and discriminative class-preference bias. To overcome these problems, we propose an Experience-Guided Fine-grained Domain Adaptation (EGFDA) framework for automatic cross-domain pneumonia diagnosis. Our framework consists of two main modules: (1) Gradient-aware Lesion Area Matching (GaLAM), which aims to reduce the global domain gap while avoiding misleading from lesion-unrelated targets, and (2) Reweighing Smooth Certainty-aware Matching (RSCaM), which aims to match class space with a smooth certainty-aware feature mapping to guide the model to learn more precise class-discriminative features. Benefiting from the collaboration between GaLAM and RSCaM, the proposed EGFDA is able to process unlabeled samples following a pattern similar to the diagnostic experience of physicians, that is, first locating the disease-related lesion area and then performing fine-grained discrimination. Comprehensive experiments on three different tasks using six datasets demonstrate the superior performance of our EGFDA. Furthermore, extensive ablation studies and visual analyses highlight the remarkable interpretability and generalization of the proposed method.},
  archive      = {J_KBS},
  author       = {Haoran Zhao and Tao Ren and Wei Li and Danke Wu and Zhe Xu},
  doi          = {10.1016/j.knosys.2024.112752},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112752},
  shortjournal = {Knowl. Based Syst.},
  title        = {EGFDA: Experience-guided fine-grained domain adaptation for cross-domain pneumonia diagnosis},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual information-driven self-supervised point cloud pre-training. <em>KBS</em>, <em>307</em>, 112741. (<a href='https://doi.org/10.1016/j.knosys.2024.112741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning universal representations from unlabeled 3D point clouds is essential to improve the generalization and safety of autonomous driving. Generative self-supervised point cloud pre-training with low-level features as pretext tasks is a mainstream paradigm. However, from the perspective of mutual information, this approach is constrained by spatial information and entangled representations. In this study, we propose a generalized generative self-supervised point cloud pre-training framework called GPICTURE. High-level features were used as an additional pretext task to enhance the understanding of semantic information. Considering the varying difficulties caused by the discrimination of voxel features, we designed inter-class and intra-class discrimination-guided masking (I 2 Mask) to set the masking ratio adaptively. Furthermore, to ensure a hierarchical and stable reconstruction process, centered kernel alignment-guided hierarchical reconstruction and differential-gated progressive learning were employed to control multiple reconstruction tasks. Complete theoretical analyses demonstrated that high-level features can enhance the mutual information between latent features and high-level features, as well as the input point cloud. On Waymo, nuScenes, and SemanticKITTI, we achieved a 75.55% mAP for 3D object detection, 79.7% mIoU for 3D semantic segmentation, and 18.8% mIoU for occupancy prediction. Specifically, with only 50% of the fine-tuning data required, the performance of GPICURE was close to that of training from scratch with 100% of the fine-tuning data. In addition, consistent visualization with downstream tasks and a 57% reduction in weight disparity demonstrated a better fine-tuning starting point. The project page is hosted at https://gpicture-page.github.io/ .},
  archive      = {J_KBS},
  author       = {Weichen Xu and Tianhao Fu and Jian Cao and Xinyu Zhao and Xinxin Xu and Xixin Cao and Xing Zhang},
  doi          = {10.1016/j.knosys.2024.112741},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112741},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mutual information-driven self-supervised point cloud pre-training},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated message selection for robust heterogeneous graph contrastive learning. <em>KBS</em>, <em>307</em>, 112739. (<a href='https://doi.org/10.1016/j.knosys.2024.112739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Contrastive Learning (HGCL) has attracted lots of attentions because of eliminating the requirement of node labels. The encoders used in HGCL mainly are message-passing based Heterogeneous Graph Neural Networks, which are vulnerable to edge perturbations. Recently, a few HGCL models replace the polluted graph with KNN graph or threshold graph, which both have flaws: (1) each node in KNN graph have the same degree K , it is irrational and loses original structural features; (2) the threshold is selected artificially, which hinders both effectiveness and interpretability. To tackle the above issues, we propose an A utomated M essage S election based H eterogeneous G raph C ontrastive L earning (AMS-HGCL) model. We first set relation view and meta-path view for contrast. Then, a robust encoder is proposed to defend structural attacks for both views by automatically selecting harmless messages, without setting all nodes having the same number of neighbors. The learned probabilities of messages can show harmful features directly, which makes our model interpretable. Finally, we design a novel cross-view contrastive loss to optimize AMS-HGCL and output robust node representations. The experimental results on four real datasets demonstrate that AMS-HGCL is feasible and effective.},
  archive      = {J_KBS},
  author       = {Rui Bing and Guan Yuan and Yanmei Zhang and Yong Zhou and Qiuyan Yan},
  doi          = {10.1016/j.knosys.2024.112739},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112739},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated message selection for robust heterogeneous graph contrastive learning},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing person re-identification via uncertainty feature fusion method and auto-weighted measure combination. <em>KBS</em>, <em>307</em>, 112737. (<a href='https://doi.org/10.1016/j.knosys.2024.112737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) is a challenging task that involves identifying the same person across different camera views in surveillance systems. Current methods usually rely on features from single-camera views, which can be limiting when dealing with multiple cameras and challenges such as changing viewpoints and occlusions. In this paper, a new approach is introduced that enhances the capability of ReID models through the Uncertain Feature Fusion Method (UFFM) and Auto-weighted Measure Combination (AMC). UFFM generates multi-view features using features extracted independently from multiple images to mitigate view bias. However, relying only on similarity based on multi-view features is limited because these features ignore the details represented in single-view features. Therefore, we propose the AMC method to generate a more robust similarity measure by combining various measures. Our method significantly improves Rank@1 (Rank-1 accuracy) and Mean Average Precision (mAP) when evaluated on person re-identification datasets. Combined with the BoT Baseline on challenging datasets, we achieve impressive results, with a 7.9% improvement in Rank@1 and a 12.1% improvement in mAP on the MSMT17 dataset. On the Occluded-DukeMTMC dataset, our method increases Rank@1 by 22.0% and mAP by 18.4%.},
  archive      = {J_KBS},
  author       = {Quang-Huy Che and Le-Chuong Nguyen and Duc-Tuan Luu and Vinh-Tiep Nguyen},
  doi          = {10.1016/j.knosys.2024.112737},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112737},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing person re-identification via uncertainty feature fusion method and auto-weighted measure combination},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer based visual tracker with restricted token interaction and knowledge distillation. <em>KBS</em>, <em>307</em>, 112736. (<a href='https://doi.org/10.1016/j.knosys.2024.112736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, one-stream pipelines have made significant progress in visual object tracking (VOT), where the template and search images interact in early stages. However, one-stream pipelines have a potential problem: They treat the object and the background equally (or other irrelevant parts), leading to weak discriminability of the extracted features. To remedy this issue, a restricted token interaction module based on asymmetric attention mechanism is proposed in this paper, which divides the search image into valuable part and other part. Only the valuable part is selected for cross-attention with the template so as to better distinguish the object from the background, which finally improves the localization accuracy and robustness. In addition, to avoid heavy computational overhead, we utilize logit distillation and localization distillation methods to optimize the outputs of the classification and regression heads respectively. At the same time, we separate the distillation regions and apply different knowledge distillation methods in different regions to effectively determine which regions are most beneficial for classification or localization learning. Extensive experiments have been conducted on mainstream datasets in which our tracker (dubbed RIDTrack) has achieved appealing results while meeting the real-time requirement.},
  archive      = {J_KBS},
  author       = {Nian Liu and Yi Zhang},
  doi          = {10.1016/j.knosys.2024.112736},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112736},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transformer based visual tracker with restricted token interaction and knowledge distillation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cross-modal experts network with uncertainty-driven fusion for Vision–Language navigation. <em>KBS</em>, <em>307</em>, 112735. (<a href='https://doi.org/10.1016/j.knosys.2024.112735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-Language Navigation (VLN) enables an agent to autonomously navigate in real-world environments based on language instructions to reach specified destinations and accurately locate relevant targets. Although significant progress has been made in recent years, two major limitations remain: (1) Existing methods lack flexibility and diversity in processing multimodal information and cannot dynamically adjust to different input features. (2) Current fixed fusion strategies fail to dynamically adapt to varying data quality in open environments, insufficiently leveraging multi-scale features and handling complex nonlinear relationships. In this paper, an adaptive cross-modal experts network (ACME) with uncertainty-driven fusion is proposed to address these issues. The adaptive cross-modal experts module dynamically selects the most suitable expert network based on the input features, enhancing information processing diversity and flexibility. Additionally, the uncertainty-driven fusion module balances coarse-grained and fine-grained information by calculating their confidences and dynamically adjusting the fusion weights. Comprehensive experiments on the R2R, SOON, and REVERIE datasets demonstrate that our approach significantly outperforms existing VLN approaches.},
  archive      = {J_KBS},
  author       = {Jie Wu and Chunlei Wu and Xiuxuan Shen and Leiquan Wang},
  doi          = {10.1016/j.knosys.2024.112735},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112735},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive cross-modal experts network with uncertainty-driven fusion for Vision–Language navigation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTDA: Dual-channel triple-to-quintuple data augmentation for comparative opinion quintuple extraction. <em>KBS</em>, <em>307</em>, 112734. (<a href='https://doi.org/10.1016/j.knosys.2024.112734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparative Opinion Quintuple Extraction (COQE) is an essential task in sentiment analysis that entails the extraction of quintuples from comparative sentences. Each quintuple comprises a subject, an object, a shared aspect for comparison, a comparative opinion and a distinct preference. The prevalent reliance on extensively annotated datasets inherently constrains the efficiency of training. Manual data labeling is both time-consuming and labor-intensive, especially labeling quintuple data. Herein, we propose a D ual-channel T riple-to-quintuple D ata A ugmentation ( DTDA ) approach for the COQE task. In particular, we leverage ChatGPT to generate domain-specific triple data. Subsequently, we utilize these generated data and existing Aspect Sentiment Triplet Extraction (ASTE) data for separate preliminary fine-tuning. On this basis, we employ the two fine-tuned triple models for warm-up and construct a dual-channel quintuple model using the unabridged quintuples. We evaluate our approach on three benchmark datasets: Camera-COQE, Car-COQE and Ele-COQE. Our approach exhibits substantial improvements versus pipeline-based, joint, and T5-based baselines. Notably, the DTDA method significantly outperforms the best pipeline method, with exact match F 1-score increasing by 10.32%, 8.97%, and 10.65% on Camera-COQE, Car-COQE and Ele-COQE, respectively. More importantly, our data augmentation method can adapt to any baselines. When integrated with the current SOTA UniCOQE method, it further improves performance by 0.34%, 1.65%, and 2.22%, respectively. We will make all related models and source code publicly available upon acceptance.},
  archive      = {J_KBS},
  author       = {Qingting Xu and Kaisong Song and Yangyang Kang and Chaoqun Liu and Yu Hong and Guodong Zhou},
  doi          = {10.1016/j.knosys.2024.112734},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112734},
  shortjournal = {Knowl. Based Syst.},
  title        = {DTDA: Dual-channel triple-to-quintuple data augmentation for comparative opinion quintuple extraction},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can question-texts improve the recognition of handwritten mathematical expressions in respondents’ solutions?. <em>KBS</em>, <em>307</em>, 112731. (<a href='https://doi.org/10.1016/j.knosys.2024.112731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate recognition of respondents’ handwritten solutions is important for implementing intelligent diagnosis and tutoring. This task is significantly challenging because of scribbled and irregular writing, especially when handling primary or secondary students whose handwriting has not yet been fully developed. Recognition becomes difficult in such cases even for humans relying only on the visual signals of handwritten content without any context. However, despite decades of work on handwriting recognition, few studies have explored the idea of utilizing external information (question priors) to improve the accuracy. Based on the correlation between questions and solutions, this study aims to explore whether question-texts can improve the recognition of handwritten mathematical expressions (HMEs) in respondents’ solutions. Based on the encoder–decoder framework, which is the mainstream method for HME recognition, we propose two models for fusing question-text signals and handwriting-vision signals at the encoder and decoder stages, respectively. The first, called encoder-fusion, adopts a static query to implement the interaction between two modalities at the encoder phase, and to better catch and interpret the interaction, a fusing method based on a dynamic query at the decoder stage, called decoder-attend is proposed. These two models were evaluated on a self-collected dataset comprising approximately 7k samples and achieved accuracies of 62.61% and 64.20%, respectively, at the expression level. The experimental results demonstrated that both models outperformed the baseline model, which utilized only visual information. The encoder fusion achieved results similar to those of other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Ting Zhang and Xinxin Jin and Xiaoyang Ma and Xinzi Peng and Yiyang Zhao and Jinzheng Liu and Xinguo Yu},
  doi          = {10.1016/j.knosys.2024.112731},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112731},
  shortjournal = {Knowl. Based Syst.},
  title        = {Can question-texts improve the recognition of handwritten mathematical expressions in respondents’ solutions?},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive predictive embedding for learning and inference in knowledge graph. <em>KBS</em>, <em>307</em>, 112730. (<a href='https://doi.org/10.1016/j.knosys.2024.112730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) aims to capture rich semantic information about entities and relationships in KGs, which is essential for Knowledge Graph Completion (KGC) and various downstream tasks. Existing KGE models differentiate between entity and relationship embeddings by constructing indirect pretext tasks and scoring functions to discern different types of triplets. In contrast, this paper introduces a novel KGE method called Contrastive Predictive Embedding (CPE), which dispenses with the need for defining scoring functions or negative sampling. Specifically, CPE directly predicts embeddings for unknown entities based on the known entity and relationship embeddings in triplets and compares them with the true embeddings. Additionally, this paper proposes a special optimization approach to enhance the performance of various Translation-based models. Experimental results on four benchmark KGs demonstrate that CPE improves the performance of original KGE models while maintaining lower computational complexity. On the FB15k-237 dataset, CPE enhances the MRR and Hit @ k ( k ∈ { 1 , 3 , 10 } ) metrics of TransE by 1.55%, 3.37%, 4.58%, and 5.92%, respectively.},
  archive      = {J_KBS},
  author       = {Chen Liu and Zihan Wei and Lixin Zhou},
  doi          = {10.1016/j.knosys.2024.112730},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112730},
  shortjournal = {Knowl. Based Syst.},
  title        = {Contrastive predictive embedding for learning and inference in knowledge graph},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamical mode recognition of coupled flame oscillators by supervised and unsupervised learning approaches. <em>KBS</em>, <em>307</em>, 112683. (<a href='https://doi.org/10.1016/j.knosys.2024.112683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combustion instability in gas turbines and rocket engines, as one of the most challenging problems in combustion research, arises from the complex interactions among flames influenced by chemical reactions, heat and mass transfer, and acoustics. Identifying and understanding combustion instability is essential for ensuring the safe and reliable operation of many combustion systems, where exploring and classifying the dynamical behaviors of complex flame systems is a core task. To facilitate fundamental studies, the present work concerned dynamical mode recognition of coupled flame oscillators made of flickering buoyant diffusion flames, which have gained increasing attention in recent years but are not sufficiently understood. The time series data of flame oscillators were generated through fully validated reacting flow simulations. Due to the limitations of expertise-based models, a data-driven approach was adopted. In this study, a nonlinear dimensional reduction model of variational autoencoder (VAE) was used to project the high dimensional data onto a 2-dimensional latent space. Based on phase trajectories in the latent space, both supervised and unsupervised classifiers were proposed for datasets with and without well-known labeling, respectively. For labeled datasets, we established the Wasserstein-distance-based classifier (WDC) for mode recognition; for unlabeled datasets, we developed a novel unsupervised classifier (GMM-DTW) combining dynamic time warping (DTW) and Gaussian mixture model (GMM). Through comparing with conventional approaches for dimensionality reduction and classification, the proposed supervised and unsupervised VAE-based approaches exhibit a prominent performance across seven assessment metrics for distinguishing dynamical modes, implying their potential extension to dynamical mode recognition in complex combustion problems.},
  archive      = {J_KBS},
  author       = {Weiming Xu and Tao Yang and Peng Zhang},
  doi          = {10.1016/j.knosys.2024.112683},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112683},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamical mode recognition of coupled flame oscillators by supervised and unsupervised learning approaches},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QA-TSN: QuickAccurate tongue segmentation net. <em>KBS</em>, <em>307</em>, 112648. (<a href='https://doi.org/10.1016/j.knosys.2024.112648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue segmentation is an essential part for computer-aided tongue diagnosis. Since of similar color and texture between tongue body and non-tongue body, such as lips and face, existing methods produce the lack of accuracy and completeness for tongue segmentation results. Moreover, small samples in tongue datasets lead under-fitting on CNN-based methods which always produce poor segmentation. To solve these problems, we designed the quick accurate tongue segmentation net (QA-TSN) to segment tongue body. To alleviate small sample problem, in the proposed method, a tongue-style transfer generation net(T-STGN) was propose to synthesize tongue images. In T-STGN, a novel encoder–decoder structure with two encoder with a global rendering block was used to refine global characteristics of synthetic tongue images. For real-time tongue segmentation, quicker tongue segmentation net (QTSN) was proposed in QA-TSN. In QTSN, we used an encoder–decoder structure with modified partial convolution (MPConv) to expedite the computation for real-time segmentation. To smooth the segments of tongue body, a novel loss function of tongue segmentation loss (TSL) was proposed. In TSL, tongue edge loss (TEL) was used to smooth the boundary of segmentation of tongue body and tongue area loss (TAL) was proposed to improve the fragmentation of segmentation results. Experiments conducted on tongue datasets achieved an IoU of 98.0307 and a Dice score of 99.0738, with a frame rate of 75.35, outperforming all other methods involved in the experiment. These results demonstrate the effectiveness of the proposed QA-TSN.},
  archive      = {J_KBS},
  author       = {Guangze Jia and Zhenchao Cui and Qingsong Fei},
  doi          = {10.1016/j.knosys.2024.112648},
  journal      = {Knowledge-Based Systems},
  month        = {1},
  pages        = {112648},
  shortjournal = {Knowl. Based Syst.},
  title        = {QA-TSN: QuickAccurate tongue segmentation net},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
