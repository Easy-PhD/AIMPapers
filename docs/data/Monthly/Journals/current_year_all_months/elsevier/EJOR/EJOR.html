<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor">EJOR - 93</h2>
<ul>
<li><details>
<summary>
(2026). Bertrand supertraps under consumer fairness concerns. <em>EJOR</em>, <em>329</em>(1), 340-353. (<a href='https://doi.org/10.1016/j.ejor.2025.09.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industries such as electronics, furniture and athletic shoemaking, consumers tend to care about transaction fairness. If a firm obtains an extremely high profit margin relative to their surplus, consumers are less likely to purchase from this firm. A salient feature of such industries, however, is that firms commonly enjoy decreasing costs per unit with increasing cumulative output. This paper examines how the coexistence of consumer fairness concerns and decreasing costs impacts price competition among firms. Prior literature suggests that both consumer fairness concerns and scale economies heighten price competition. We show, however, that firms may set higher prices and obtain greater profit with stronger consumer fairness concerns in the presence of declining costs, because the indirect effect that consumer fairness concerns soften price competition caused by cost reductions may dominate the direct effect that they intensify price competition caused by product substitution. Furthermore, we show the robustness of our results by considering various situations, such as a general cost-reduction function, information asymmetry between consumers and firms, heterogeneity in consumers’ knowledge of firms’ cost structures, consumer heterogeneity in fairness concerns, and endogenous fairness concerns.},
  archive      = {J_EJOR},
  author       = {Guowei Liu and Yunchuan Liu and Jiong Sun and Lijia Tan and Jianxiong Zhang},
  doi          = {10.1016/j.ejor.2025.09.046},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {340-353},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bertrand supertraps under consumer fairness concerns},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cheating or delighting customers on quality: Strategic implications for delayed information disclosure. <em>EJOR</em>, <em>329</em>(1), 321-339. (<a href='https://doi.org/10.1016/j.ejor.2025.09.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper seeks to investigate the strategic implications of a firm’s pricing and advertising policies associated with cheating and delighting customers on quality. To this end, we formulate a general model with three alternative options: non-deviant, i.e., fair; and deviant, i.e., cheating and delighting, quality policies. In the case of deviant policies, cheating is a means to inflate goodwill through false advertising in order to draw a cheating rent as long as the cheating is not disclosed, while delighting is a means to enhance goodwill through extra quality in order to benefit from a delighting rent once the delighting is awarded. The probability of disclosure of information on cheating (delighting) depends on the cumulative number of customers cheated (delighted). The information disclosure results in asymmetric market sanction between cheating and delighting. In addition, if revealed, cheating results in the payment of a one-time penalty and the stopping of the activity. We notably show that a non-deviant quality policy is not the preferred option for either the firm or the customers and that history-dependency is an important factor for a successful deviant quality policy.},
  archive      = {J_EJOR},
  author       = {Fouad El Ouardighi and Dieter Grass and Konstantin Kogan},
  doi          = {10.1016/j.ejor.2025.09.041},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {321-339},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cheating or delighting customers on quality: Strategic implications for delayed information disclosure},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hybrid algorithm with system participants classification for efficient convex hull pricing in electricity markets. <em>EJOR</em>, <em>329</em>(1), 308-320. (<a href='https://doi.org/10.1016/j.ejor.2025.09.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the non-convexities in electricity market, system operators may need to provide side payments to incentivize participants to follow the production plans. Convex hull prices, derived from the Lagrange dual of the unit commitment problem (typically modeled as a mixed-integer programming problem), can minimize these side payments. We present an adaptive hybrid algorithm designed to efficiently compute convex hull prices by approaching the convex primal formulation of this Lagrange dual problem asymptotically. The algorithm classifies system participants into four groups based on the complexity of their convex hull descriptions and applies tailored convex hull formulations or column/row generation techniques to each group. By seamlessly integrating advanced models and algorithms within a unified primal framework, our approach enhances both computational efficiency and accuracy. We evaluated the algorithm on 40 instances and compared its performance against other methods, including column generation, row generation, and the Level Method. Results demonstrate that our adaptive hybrid algorithm reduces computation time by at least 90 % compared to the traditional Level Method. These findings confirm the algorithm’s computational feasibility for large-scale market clearing problems.},
  archive      = {J_EJOR},
  author       = {Shifei Chen and Linfeng Yang and Xinhan Lin and Cuo Zhang},
  doi          = {10.1016/j.ejor.2025.09.036},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {308-320},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An adaptive hybrid algorithm with system participants classification for efficient convex hull pricing in electricity markets},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Operating room-to-downstream elective surgery planning under uncertainty. <em>EJOR</em>, <em>329</em>(1), 288-307. (<a href='https://doi.org/10.1016/j.ejor.2025.07.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by our collaboration with a hospital, we introduce a new integrated e lective s urgery a ssignment, s equencing, and s cheduling p roblem (ESASSP), involving multiple operating rooms (ORs) and downstream recovery units, as well as methodologies for solving it. Data from the collaborating hospital show significant variability and ambiguity in surgery duration and post-surgery length of stay (LOS) in recovery units. To address such ambiguity, we propose distributionally robust optimization (DRO) approaches for the ESASSP. Our DRO models find ESASSP decisions that minimize the fixed cost associated with performing or postponing surgeries plus the maximum expected operational costs related to overtime and idle time of ORs, delays in ORs, and congestion in recovery units. We evaluate the maximum expectation over all distributions residing in (moment and Wasserstein) ambiguity sets of distributions for surgery durations and LOS. We derive a novel characterization of LOS and introduce transformation techniques to derive equivalent solvable reformulations of the non-linear DRO models. Then, we propose a column-and-constraint-generation method to solve the reformulations. We present comprehensive results based on various ESASSP instances constructed using three datasets. Our results offer valuable insights into the ESASSP and demonstrate the practical impact of our proposed integrated approaches. Notably, implementing solutions from our models could significantly reduce congestion in the recovery units, surgery delays in ORs, overtime, idle time, and the associated costs compared with traditional non-integrated approaches.},
  archive      = {J_EJOR},
  author       = {Karmel S. Shehadeh and Man Yiu Tsang and Rema Padman and Arman Kilic},
  doi          = {10.1016/j.ejor.2025.07.006},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {288-307},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operating room-to-downstream elective surgery planning under uncertainty},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The impact of collaboration on sustainability and profit in the fashion rental supply chain. <em>EJOR</em>, <em>329</em>(1), 273-287. (<a href='https://doi.org/10.1016/j.ejor.2025.07.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global fashion industry is under increased scrutiny for its environmental and social impacts and therefore compelled to innovate towards more sustainable models. Some of the more notable initiatives are moving from a traditional consumer-ownership-based model to a consumer-use-based model and collaborating with key supply chain stakeholders to achieve higher levels of sustainability. Though collaboration is perceived to be an enabler and is vital for sustainable development, many collaborative efforts have failed because the effects of collaboration on sustainability and the associated trade-offs remain unclear. This paper aims to contribute to this context by clarifying the effects of collaboration levels on the degree of sustainability practices for producing fashion items. Specifically, we investigate a two-echelon fashion supply chain, comprising a supplier and a fashion rental retailer through analytical modeling. The supplier decides on the sustainability level and the selling price to the retailer, while the retailer decides on the order quantity. Given the rising demand for environmentally friendly products, consumer demand for renting fashion items is assumed to increase with the degree of sustainability practices adopted. The findings show that a higher level of collaboration enhances overall sustainability and at the same time improves profitability. Furthermore, the research demonstrates that a higher level of collaboration can mitigate the negative effect on profitability resulting from the need to adhere to minimum sustainability thresholds, possibly mandated by regulators. Based on the findings, actionable insights for practitioners, policymakers, and regulators are outlined.},
  archive      = {J_EJOR},
  author       = {Jack A.A. van der Veen and Taher Ahmadi and Bo van der Rhee and V. Venugopal},
  doi          = {10.1016/j.ejor.2025.07.001},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {273-287},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of collaboration on sustainability and profit in the fashion rental supply chain},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The influence of school principals’ management on school efficiency: Evidence from italian schools. <em>EJOR</em>, <em>329</em>(1), 260-272. (<a href='https://doi.org/10.1016/j.ejor.2025.06.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the relationship between school principals’ managerial practices and two key dimensions of school performance: students’ cognitive outcomes and school climate. School performance is assessed using a classical Data Envelopment Analysis (DEA) framework, complemented by both unconditional robust and conditional robust models to evaluate the influence of managerial practices on school efficiency. We introduce a methodological innovation that allows for a nuanced analysis of how contextual variables – specifically, principals’ managerial practices – affect performance, both individually and through their interactions. The analysis is based on 2019 INVALSI data from a nationally representative sample of 8th grade students in Italian schools. The findings show that principals’ practices, as well as the ways in which these practices interact, play a significant role in shaping school efficiency, particularly by promoting a positive and supportive school climate.},
  archive      = {J_EJOR},
  author       = {Anna Mergoni and Ana Camanho and Mara Soncin and Tommaso Agasisti and Kristof De Witte},
  doi          = {10.1016/j.ejor.2025.06.020},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {260-272},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The influence of school principals’ management on school efficiency: Evidence from italian schools},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Strategies for units incentivization: Assessing influence by maximizing loss/gain in centrally managed systems. <em>EJOR</em>, <em>329</em>(1), 239-259. (<a href='https://doi.org/10.1016/j.ejor.2025.07.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of centrally managed systems (CMSs), accurately determining the influence of units is crucial for effective incentive and compensation plans. Previous attempts to measure the impact of a specific DMU involved evaluating overall system efficiency after removing that DMU. However, challenges arise in accurately assessing post-removal system efficiency primarily because the aggregate unit fails to represent the transformed system adequately. The lack of modification to the remaining DMUs results in a disparity between the average of the remaining DMUs and the previous aggregate unit. Consequently, calculating the overall efficiency of the new system using the previous aggregate unit becomes imprecise and lacks meaningful insight. We develop a new incentivization method involving the redistribution of the DMU under evaluation among the remaining units to maintain the representativeness of the aggregate DMU before and after the removal of the DMU under evaluation. We propose two models to calculate the maximum loss and gain for each inefficient and efficient DMU during this redistribution, respectively. Our method also demonstrates robustness when assessing the contributions of efficient DMUs in the presence of nearby masked units. We provide adaptations for inefficient DMUs near efficient ones but significantly distant from other groups of inefficient units, ensuring precise scoring. Our approach is demonstrated using a real dataset.},
  archive      = {J_EJOR},
  author       = {Mostafa Davtalab-Olyaie and Mehmet A. Begen and Masoud Asgharian},
  doi          = {10.1016/j.ejor.2025.07.022},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {239-259},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategies for units incentivization: Assessing influence by maximizing loss/gain in centrally managed systems},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). E-retailer’s secondhand product market entry and manufacturer’s rebate decisions considering fairness concerns. <em>EJOR</em>, <em>329</em>(1), 219-238. (<a href='https://doi.org/10.1016/j.ejor.2025.07.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prosperity of the online secondhand product transactions, e-retailers are entering the secondhand product market to meet consumers’ demands. Facing competition from the secondhand products, manufacturers use rebates to enhance the competitiveness the new products. This work explores the implications of the manufacturer’s rebate on a supply chain comprising of a manufacturer and an e-retailer where both of them have distributional fairness concerns and the e-retailer makes decision to enter the secondhand product market. Four Stackelberg game models are formulated when the supply chain members are fairness-neutral and fairness-minded and when the e-retailer enters and does not enter the secondhand product market. The equilibrium results of these Stackelberg game models are obtained through backward induction, and the impacts of the important parameters on the equilibrium results are examined through theoretical analyses. Numerical experiments are conducted to verify the theoretical results, and sensitivity analyses are performed to confirm the impacts of the important parameters on the equilibrium results. Some important findings are obtained. First, the manufacturer’s rebate mitigates the impacts of the e-retailer’s secondhand product market entry. The e-retailer will enter the secondhand product market only when consumers are not very sensitive to the manufacturer’s rebate. Second, with the manufacturer’s rebate, the supply chain members’ fairness concerns reduce the barriers for the e-retailer to enter the secondhand product market. Third, an appropriate rebate value benefits both supply chain members by increasing their profits. Finally, a high consumers’ rebate sensitivity reduces the supply chain members’ profits when they are fairness-minded.},
  archive      = {J_EJOR},
  author       = {Yuanyuan Ji and Ruozhen Qiu and Shoufeng Ji and Minghe Sun and Zhi-ping Fan},
  doi          = {10.1016/j.ejor.2025.07.018},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {219-238},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {E-retailer’s secondhand product market entry and manufacturer’s rebate decisions considering fairness concerns},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Approaches for biobjective integer linear robust optimization. <em>EJOR</em>, <em>329</em>(1), 198-218. (<a href='https://doi.org/10.1016/j.ejor.2025.06.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world optimization problems often do not just involve multiple objectives but also uncertain parameters. In this case, the goal is to find Pareto-optimal solutions that are robust, i.e., reasonably good under all possible realizations of the uncertain data. Such solutions have been studied in many papers within the last ten years and are called robust efficient . However, solution methods for finding robust efficient solutions are scarce. In this paper, we develop three algorithms for determining robust efficient solutions to biobjective mixed-integer linear robust optimization problems. To this end, we draw from methods for both multiobjective optimization and robust optimization: dichotomic search for biobjective mixed-integer optimization problems and an optimization-pessimization approach from (single-objective) robust optimization, which iteratively adds scenarios and thereby increases the uncertainty set. We propose two algorithms that combine dichotomic search with the optimization-pessimization method as well as a dichotomic search method for biobjective linear robust optimization that exploits duality. On the way we derive some other results: We extend dichotomic search from biobjective linear problems to biobjective linear minmax problems and generalize the optimization-pessimization method from single-objective to multi-objective robust optimization problems. We implemented and tested the three algorithms on linear and integer linear instances and discuss their respective strengths and weaknesses.},
  archive      = {J_EJOR},
  author       = {Fabian Chlumsky-Harttmann and Marie Schmidt and Anita Schöbel},
  doi          = {10.1016/j.ejor.2025.06.010},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {198-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approaches for biobjective integer linear robust optimization},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint pricing of default-free and defaultable claims in a reduced-form model featuring a martingale part. <em>EJOR</em>, <em>329</em>(1), 180-197. (<a href='https://doi.org/10.1016/j.ejor.2025.09.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural and reduced-form approaches form the main classes of default models. The second family can be classified in two sub-groups, using the shape of the Azéma supermartingale, G . Those for which G is continuously decreasing coincide with Cox models, and have been extensively studied and applied to many practical problems. They are handy because they display the so-called immersion property (also known as the H hypothesis ) according to which, using standard notations, every F -martingale is a G -martingale. In contrast, those for which G features a martingale part – hence, can be locally increasing – have been studied from a theoretical perspective but have been used in few applications only, in which case the adopted setup was quite sophisticated. This can be explained because of the theoretical challenges associated with the design of a market model that could accommodate both default-free and defaultable assets as well as of a lack of comprehension about how to simulate default times correlated with other risk factors in such a setup. This paper fills this gap by proposing a concrete example of arbitrage-free market model of this class and relying on the Φ -martingale process. The latter exhibits a similar complexity as Cox but has the advantage to be automatically calibrated to a given default probability curve and CDS option quotes, easy to simulate, and able to display stronger dependence effects compared to state-of-the-art intensity models. Explicit calculations and numerical applications featuring counterparty risk and, in particular, credit valuation adjustment (CVA) with wrong-way risk, illustrate the results.},
  archive      = {J_EJOR},
  author       = {Frédéric Vrins},
  doi          = {10.1016/j.ejor.2025.09.043},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {180-197},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint pricing of default-free and defaultable claims in a reduced-form model featuring a martingale part},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and accurate simulation of the stochastic-alpha-beta-rho model. <em>EJOR</em>, <em>329</em>(1), 166-179. (<a href='https://doi.org/10.1016/j.ejor.2025.09.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an efficient, accurate and reliable simulation scheme for the stochastic-alpha-beta-rho (SABR) model. The two challenges of the SABR simulation lie in sampling (i) integrated variance conditional on terminal volatility and (ii) terminal forward price conditional on terminal volatility and integrated variance. For the first sampling procedure, we sample the conditional integrated variance using the moment-matched shifted lognormal approximation. For the second sampling procedure, we approximate the conditional terminal forward price as a constant-elasticity-of-variance (CEV) distribution. Our CEV approximation preserves the martingale condition and precludes arbitrage, which is a key advantage over Islah’s approximation used in most SABR simulation schemes in the literature. We then adopt the exact sampling method of the CEV distribution based on the shifted-Poisson mixture Gamma random variable. Our enhanced procedures avoid the tedious Laplace inversion algorithm for sampling integrated variance and non-efficient inverse transform sampling of the forward price in some of the earlier simulation schemes. Numerical results demonstrate our simulation scheme to be highly efficient, accurate, and reliable.},
  archive      = {J_EJOR},
  author       = {Jaehyuk Choi and Lilian Hu and Yue Kuen Kwok},
  doi          = {10.1016/j.ejor.2025.09.027},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {166-179},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient and accurate simulation of the stochastic-alpha-beta-rho model},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing operational decision-making in fault diagnosis for high-dimensional data streams with auxiliary information. <em>EJOR</em>, <em>329</em>(1), 155-165. (<a href='https://doi.org/10.1016/j.ejor.2025.09.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern engineering systems, from advanced manufacturing processes to sophisticated electronic devices, generate high-dimensional data streams (HDS) that demand efficient operational strategies for quality management. While real-time anomaly detection is crucial, the importance of accurate post-signal fault diagnosis for root cause analysis has grown substantially. Current diagnostic methods often focus on isolated sequences of HDS, missing opportunities to leverage auxiliary information that can enhance decision-making. This paper introduces a novel framework to improve large-scale fault diagnosis in HDS environments, integrating auxiliary sequences within a multi-sequence multiple testing framework. Utilizing a Cartesian hidden Markov model, we develop a generalized local index of significance (GLIS) to assess the abnormality likelihood across data streams. Based on the GLIS, our proposed data-driven diagnostic procedure effectively harnesses auxiliary information, aiming to optimize operational decisions by minimizing the expected number of false positives in the primary sequence while maintaining control over the missed discovery rate. The asymptotic validity and optimality of this approach ensure its robustness in practical settings. We validate the efficacy of our method through comprehensive simulations and a real-world case study, demonstrating its potential to support more accurate and informed operational decisions.},
  archive      = {J_EJOR},
  author       = {Zhihan Zhang and Wendong Li and Min Xie and Dongdong Xiang},
  doi          = {10.1016/j.ejor.2025.09.022},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {155-165},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Enhancing operational decision-making in fault diagnosis for high-dimensional data streams with auxiliary information},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Designing and organizing a high-performance divisional seru considering learning and forgetting effect under stochastic processing requirements. <em>EJOR</em>, <em>329</em>(1), 138-154. (<a href='https://doi.org/10.1016/j.ejor.2025.07.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seru production systems (SPSs), known for their flexibility and responsiveness, have drawn considerable attention from both academics and practitioners. Owing to the costs associated with worker training, divisional serus , which require only partially cross-trained workers, are the most fundamental and widely adopted organizational forms. As a human-centered system, characterizing a divisional seru necessitates accounting for human factors to avoid discrepancies between model evaluation and realistic performance. This study considers a divisional seru with learning and forgetting effect and stochastic processing requirements. We try to explore the impact of learning and forgetting effect on seru performance in various production situations as well as its interplay with the role of work-in-process (WIP) buffers. By establishing the underlying Markovian model, three performance measures are evaluated, including throughput, flow time and WIP on the seru . Numerical experiments are conducted by varying several parameters, such as workers’ initial processing rates, the number and locations of overlapped stations, and the number of workers. The results indicate that learning can enhance system performance in terms of throughput and flow time without causing a substantial increase in WIP level. Moreover, learning effect can compensate for imperfect initial seru settings and expedite the stabilization of performance measures. Buffer arrangement should be adapted to the specific production environment and prioritized operational objectives. Furthermore, our findings reveal that buffer usage and learning effect interact synergistically to improve seru efficiency. A series of practical guidelines are provided to help design and organize a high-performance divisional seru .},
  archive      = {J_EJOR},
  author       = {Yaoxin Zhang and Dongni Li and Yuqing Jin and Zihan Lan},
  doi          = {10.1016/j.ejor.2025.07.031},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {138-154},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing and organizing a high-performance divisional seru considering learning and forgetting effect under stochastic processing requirements},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal ordering policy for perishable products by incorporating demand forecasts. <em>EJOR</em>, <em>329</em>(1), 124-137. (<a href='https://doi.org/10.1016/j.ejor.2025.07.009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventory management of perishable products has seen extensive study over the years; the perishable nature capturing the real-world phenomena of expiration after a limited shelf life. Such problems are challenging as they involve balancing demand fulfillment with minimal wastage. An added dimension to such problems, given the rise of machine learning, is that demand predictions are often available. In this paper, we study the structural properties of the optimal ordering policy for a perishable product with a fixed shelf life in a periodic-review single-item inventory system over a finite horizon, where demand predictions are available. We consider both lost-sales and backlogging cases. The objective is to find the optimal ordering policy that minimizes the total expected cost over a finite horizon. The total expected cost consists of linear ordering cost, inventory holding cost, wastage cost, and shortage cost. By using the concept of L ♮ -convexity, we show that under particular assumptions on the demand forecasts, the optimal policy is a state-dependent base-stock policy in which the base-stock values are a function of the system’s state, the inventory level, a vector of current and previous demand forecasts, and previous demand values. Moreover, we explore the monotonicity properties of the optimal policy. The monotonicity properties motivate us to propose a heuristic in which the order quantity is an affine function of the inventory level and forecast-dependent target inventory levels. Numerical results show that the proposed heuristic is effective in minimizing the total cost while maintaining low on-hand inventory levels.},
  archive      = {J_EJOR},
  author       = {Maryam Motamedi and Na Li and Douglas G. Down},
  doi          = {10.1016/j.ejor.2025.07.009},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {124-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal ordering policy for perishable products by incorporating demand forecasts},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Supply chain coordination with a wholesale price contract for behavioral decision-makers. <em>EJOR</em>, <em>329</em>(1), 112-123. (<a href='https://doi.org/10.1016/j.ejor.2025.06.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally supply chain coordination is defined for expected profit maximizing decision-makers, including the coordinator. In this setting, a wholesale price contract cannot coordinate a supplier–buyer relationship because of double marginalization. Nevertheless, the wholesale price contract is frequently applied in practice because it is simple and easy to implement. A possible explanation could be that the decision-makers are influenced by behavioral factors, such as individual biases and social preferences. We propose the supply chain’s objective maximization (SCOM) approach to coordinate a supplier–buyer relationship, where not only the buyer (newsvendor) but also the coordinator, typically the supplier, may be behavioral decision-makers. Applying the SCOM criterion, we present a general condition for the existence of a coordinating wholesale price based on a monotonicity assumption that holds for many behavioral factors. We apply the result to extensions of two types of the individual bias overconfidence (overprecision and overestimation): mean-preservation and variance-preservation of stochastic demand, the latter is a special case of first-order stochastic dominance. For these biases we derive intuitive closed-form solutions and present conditions for the existence of a coordinating wholesale price. The less aligned the biases of the coordinator and the buyer are, the greater the supplier’s share of expected supply chain profit under the coordinating wholesale price. Concerning social preferences we demonstrate that the supply chain cannot be coordinated if altruism is the only behavioral factor. Coordination can be achieved if, additionally, the buyer and/or the supplier are equipped with individual biases.},
  archive      = {J_EJOR},
  author       = {Werner Jammernegg and Peter Kischka and Lena Silbermayr},
  doi          = {10.1016/j.ejor.2025.06.029},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {112-123},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supply chain coordination with a wholesale price contract for behavioral decision-makers},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Models and algorithms for the time window assignment traveling salesperson problem with stochastic travel times. <em>EJOR</em>, <em>329</em>(1), 96-111. (<a href='https://doi.org/10.1016/j.ejor.2025.07.034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Time Window Assignment Traveling Salesperson Problem with Stochastic Travel Times, a two-stage stochastic problem where the first-stage decisions involve the routing aspects and the customer time window definition. Second-stage decisions follow, which integrate travel time uncertainties into the optimization process. The objective is to minimize the combined routing and time window cost, including penalties for earliness and lateness, marking a shift from a cost-focused routing strategy to a more balanced approach that considers both cost and service quality aspects in delivery operations. We introduce a novel formulation inspired by a 3-index formulation for the Time-Dependent Traveling Salesperson Problem, and we report an extensive computational comparison of alternative models and solution methods from the literature. Additionally, we provide a set of benchmark instances characterized by two opposite scenario types, intended to facilitate future research. Our results show that the (by far) most effective solution method is an ad-hoc Benders Decomposition algorithm that leverages our new model, demonstrating substantial improvements over prior state-of-the-art exact solution methods.},
  archive      = {J_EJOR},
  author       = {Francesco Cavaliere and Matteo Fischetti and Roberto Roberti and Domenico Salvagnin},
  doi          = {10.1016/j.ejor.2025.07.034},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {96-111},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Models and algorithms for the time window assignment traveling salesperson problem with stochastic travel times},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-start local search matheuristic for the capacitated arc routing problem with irregular services. <em>EJOR</em>, <em>329</em>(1), 87-95. (<a href='https://doi.org/10.1016/j.ejor.2025.07.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the periodic capacitated arc routing problem with irregular services, a challenging combinatorial optimization problem that arises in various real-world scenarios, such as waste collection and road maintenance. This problem is defined over a mixed graph and asks for scheduling a fleet of capacitated vehicles to meet the demands associated with a set of required links, while minimizing the routing costs over a given planning horizon. Each required link has its own service plan, indicating the frequency with which its demand must be met over the planning horizon. To solve this problem, we propose a novel matheuristic approach that combines a route-based mathematical formulation with a multi-start local search framework. The matheuristic incorporates two distinct local search strategies, which are crucial for improving solution quality, as revealed by the computational experiments. Additional experiments further confirm the effectiveness of the proposed matheuristic, comparing its performance against an exact method and a heuristic algorithm from the literature, solving the uncapacitated version of the problem. Finally, we analyze the impact of introducing the capacity constraint by comparing the solutions obtained in the two cases.},
  archive      = {J_EJOR},
  author       = {Demetrio Laganà and Paolo Paronuzzi},
  doi          = {10.1016/j.ejor.2025.07.032},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {87-95},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-start local search matheuristic for the capacitated arc routing problem with irregular services},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The days on days off scheduling problem. <em>EJOR</em>, <em>329</em>(1), 79-86. (<a href='https://doi.org/10.1016/j.ejor.2025.07.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling problems have received considerable academic attention due to their relevance in various real-world applications. These problems involve preparing feasible schedules for an organization’s employees and often account for factors such as qualifications of workers and holiday requests, resulting in complex constraints. While certain versions of the personnel rostering problem are widely acknowledged as NP-hard, there is limited theoretical analysis specific to many of its variants. Many studies simply assert the NP-hardness of the general problem without investigating whether the specific cases they address inherit this computational complexity. In this paper, we examine a variant of the personnel scheduling problems, which involves scheduling a homogeneous workforce subject to constraints concerning both the total number and the number of consecutive work days and days off. This problem was originally motivated by real world examples in the hospitality sector and was previously claimed to be NP-complete. In this paper, we analyze the problem from a theoretical point of view: we prove its NP-completeness and investigate how the combination of constraints contributes to this complexity. More precisely, we analyze various special cases that arise from the omission of certain parameters, classifying them as either NP-complete or polynomial-time solvable. For the latter, we provide easy-to-implement and efficient algorithms to not only determine feasibility, but also compute a corresponding schedule.},
  archive      = {J_EJOR},
  author       = {Fabien Nießen and Paul Paschmanns},
  doi          = {10.1016/j.ejor.2025.07.011},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {79-86},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The days on days off scheduling problem},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid stochastic alternating direction method of multipliers for nonconvex and nonsmooth composite optimization. <em>EJOR</em>, <em>329</em>(1), 63-78. (<a href='https://doi.org/10.1016/j.ejor.2025.10.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex and nonsmooth composite optimization problems with linear constraints have gained significant attention in practical applications. This paper proposes a hybrid stochastic Alternating Direction Method of Multipliers (ADMM) leveraging a novel hybrid estimator to solve such problems with expectation or finite-sum objective functions. Compared to existing double-loop stochastic ADMMs, our method features simpler updates enabled by a single-loop, single-sample framework, while avoiding the need for checkpoint selection. Under mild conditions, we analyze the explicit relationships between key parameters using refined Lyapunov functions and rigorously establish the sublinear convergence. To the best of our knowledge, our work is the first single-loop stochastic ADMM for solving both expectation and finite-sum problems while matching the best-known oracle complexity bound comparable to state-of-the-art double-loop stochastic ADMMs. Numerical experiments on several different nonconvex minimization tasks demonstrate the superior performance of the proposed method.},
  archive      = {J_EJOR},
  author       = {Yuxuan Zeng and Jianchao Bai and Shengjia Wang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ejor.2025.10.024},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {63-78},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid stochastic alternating direction method of multipliers for nonconvex and nonsmooth composite optimization},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-matching guarantees in a brand omni-channel retailer. <em>EJOR</em>, <em>329</em>(1), 42-62. (<a href='https://doi.org/10.1016/j.ejor.2025.09.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers are increasingly adopting omni-channel structures to offer customers a seamless cross-channel shopping experience, which has created complex economic challenges, particularly in strategic pricing. This paper investigates optimal pricing strategies and the effectiveness of self-matching guarantees, where a retailer allows customers to purchase a product at the lower of its online or in-store prices. We develop mathematical and simulation models to explore these pricing decisions and additionally, to examine how inventory limitations impact self-matching profitability. We identify conditions under which self-matching enhances profitability, particularly in scenarios with varying levels of price-awareness and channel preferences among customers as well as insufficient inventory levels. Our findings also indicate that self-matching is more effective when customers have a low to moderate preference for online shopping, but its profitability diminishes as customer preference for online shopping intensifies. These insights offer practical guidance and actionable strategies for brand/luxury omni-channel retailers and managers handling private-label products to optimize their pricing decisions and improve profitability.},
  archive      = {J_EJOR},
  author       = {Esmat Sangari and Izak Duenyas and Seyed Iravani},
  doi          = {10.1016/j.ejor.2025.09.004},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {42-62},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Self-matching guarantees in a brand omni-channel retailer},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual explanations for linear optimization. <em>EJOR</em>, <em>329</em>(1), 24-41. (<a href='https://doi.org/10.1016/j.ejor.2025.06.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the concept of counterfactual explanations (CE) has become increasingly important in understanding the inner workings of complex AI systems. In this paper, we introduce the idea of CEs in the context of linear optimization and propose, explain, and analyze three different classes of CEs: relative, weak, and strong. We discuss in which situation each type of CE is needed and examine the structure of the optimization problems that arise from considering them. By detecting and leveraging the underlying convex structure of the relative CE problem, we demonstrate that computing the relative CEs takes the same order of time as solving the original problems. We also address the computational challenges associated with weak and strong CE problems. To illustrate our findings, we present a case study with data sourced from the World Food Programme in which we calculate each type of CE. Finally, we conduct comprehensive numerical experiments using the NETLIB library to demonstrate that relative CE problems can be solved as quickly as solving the original linear optimization problem.},
  archive      = {J_EJOR},
  author       = {Jannis Kurtz and Ş. İlker Birbil and Dick den Hertog},
  doi          = {10.1016/j.ejor.2025.06.016},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {24-41},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Counterfactual explanations for linear optimization},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fifty years of power systems optimization. <em>EJOR</em>, <em>329</em>(1), 1-23. (<a href='https://doi.org/10.1016/j.ejor.2025.05.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review paper examines the evolution of power systems optimization over the past fifty years by considering two distinct periods: from 1970 to 1990 and from 1990 to the present. The initial period is typically defined by a centralized power system framework that prevailed around the world. The latter observes a transition to a decentralized structure in a market environment, marked by an increasing integration of renewables and advanced technologies, in addition to maintaining a centralized power system structure for some countries. Since we review the broad topic of power systems optimization, this analysis focuses on the main power system problems — investment, operation planning, operations, control, and forecasting — to define the main research streams. We provide a thorough exploration of the operations research methods applied to specific problem types within each period. Thus, this review not only underscores the pivotal role of operations research in addressing the challenges posed by changing landscapes and advanced technologies but also unveils the transformative journey of power systems optimization along with future research directions.},
  archive      = {J_EJOR},
  author       = {Anil Kaya and Antonio J. Conejo and Steffen Rebennack},
  doi          = {10.1016/j.ejor.2025.05.022},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of power systems optimization},
  volume       = {329},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuous-time optimal investment with portfolio constraints: A reinforcement learning approach. <em>EJOR</em>, <em>328</em>(3), 1068-1092. (<a href='https://doi.org/10.1016/j.ejor.2025.08.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a reinforcement learning (RL) framework, we study the exploratory version of the continuous time expected utility (EU) maximization problem with a portfolio constraint that includes widely-used financial regulations such as short-selling constraints and borrowing prohibition. The optimal feedback policy of the exploratory unconstrained classical EU problem is shown to be Gaussian. In the case where the portfolio weight is constrained to a given interval, the corresponding constrained optimal exploratory policy follows a truncated Gaussian distribution. We verify that the closed form optimal solution obtained for logarithmic utility and quadratic utility for both unconstrained and constrained situations converge to the non-exploratory expected utility counterpart when the exploration weight goes to zero. Finally, we establish a policy improvement theorem and devise an implementable reinforcement learning algorithm by casting the optimal problem in a martingale framework. Our numerical examples show that exploration leads to an optimal wealth process that is more dispersedly distributed with heavier tail compared to that of the case without exploration. This effect becomes less significant as the exploration parameter is smaller. Moreover, the numerical implementation also confirms the intuitive understanding that a broader domain of investment opportunities necessitates a higher exploration cost. Notably, when subjected to both short-selling and money borrowing constraints, the exploration cost becomes negligible compared to the unconstrained case.},
  archive      = {J_EJOR},
  author       = {Huy Chau and Duy Nguyen and Thai Nguyen},
  doi          = {10.1016/j.ejor.2025.08.032},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1068-1092},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Continuous-time optimal investment with portfolio constraints: A reinforcement learning approach},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Toward organ shortage resilient allocation policies using real-time queueing models for liver transplantation. <em>EJOR</em>, <em>328</em>(3), 1054-1067. (<a href='https://doi.org/10.1016/j.ejor.2025.07.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report in this paper on the potential interest of real-time queueing models to optimize organ allocation policies. We especially focus on building organ shortage resilient policies in terms of equity, as we experienced differential impact of the COVID epidemic organ shortage on transplant access, according to the cause of liver failure. Patient’s death on the waiting list or dropout for being too sick, resulting from the absence of a timely available organ, is chosen as the main equity metric. Results obtained with the composite allocation score used in France is challenged against the so-called Early Simulated Deadline First (ESDF) real-time queueing discipline, under increasing levels of organ shortage, by extensive simulations. The ESDF policy is a variant of the well-know Earliest Deadline First (EDF) policy, which was shown as optimal in various contexts in the queueing literature. In the present case, the time to the deadline represents the remaining life duration of patients — which is of course unknown. So we propose to simulate a fictional life-duration, and give priority to the earliest simulated deadline. This leads to a simple and comprehensive representation of the system at hand by a Markov process. Our simulation results clearly show that the ESDF policy allows to maintain equity between indications, conversely to the scoring policy, which was not resilient to increasing levels of organ shortage.},
  archive      = {J_EJOR},
  author       = {Thomas Masanet and Benoît Audry and Christian Jacquelinet and Pascal Moyal},
  doi          = {10.1016/j.ejor.2025.07.030},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1054-1067},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Toward organ shortage resilient allocation policies using real-time queueing models for liver transplantation},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exact simulation of stochastic volatility models based on conditional fourier-cosine method. <em>EJOR</em>, <em>328</em>(3), 1036-1053. (<a href='https://doi.org/10.1016/j.ejor.2025.08.061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional methodology used for the exact simulation of stochastic volatility models based on the Gil–Pelaez formula presents implementation problems that are observed by many researchers and practitioners. In particular, although conventionally considered exact, such a method presents a difficult control of the error. The bias of the Monte Carlo simulation estimator can only be computed numerically and is controlled by two parameters, typically determined by running time-consuming simulations under different tuning parameter configurations until an optimal setup is found. In this paper, we propose a new exact simulation scheme based on the Fourier-cosine method, which approximates a probability density given the characteristic function as follows: the density is truncated on a finite interval, and approximated by a classical Fourier-cosine series. The method allows full error control via an effective automatic identification of the tuning parameters given a user-supplied error tolerance. The new approach offers the following advantages: improved control of the error, simplified implementation, and reduction in computing time. The error is controlled by only one parameter instead of two. This parameter has a clear interpretation: it is the maximum tolerable bias. This facilitates the implementation, since the maximum bias becomes an input of the simulation algorithm, instead of an output, and can be set a priori , before running simulations. Our analysis shows that the proposed exact simulation scheme is computationally faster than the traditional one, and presents an improved speed-accuracy profile with respect to alternative state-of-the-art fast approximated sampling schemes.},
  archive      = {J_EJOR},
  author       = {Riccardo Brignone and Gero Junike},
  doi          = {10.1016/j.ejor.2025.08.061},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1036-1053},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact simulation of stochastic volatility models based on conditional fourier-cosine method},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robot-aided electric vehicle routing problem with lockers and prime customers prioritization. <em>EJOR</em>, <em>328</em>(3), 1018-1035. (<a href='https://doi.org/10.1016/j.ejor.2025.07.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satisfactory and fast customer service is one of the critical parts of last-mile delivery. Companies like Amazon prioritize Prime members with same-day delivery while offering lockers for customer convenience. Additionally, robot-aided Electric Vehicle (EV) delivery is recognized for its cost efficiency and fast service in densely populated areas. Integrating EVs, delivery robots, and lockers, and prioritizing Prime customers can improve efficiency and service responsiveness. This integrated approach offers home delivery by EVs and robots and self-pickup from lockers. Every customer is assigned a prize (profit), with a higher profit associated with the Prime membership. Each EV dispatches robots, with a “dispatch-wait-collect” tactic, to serve the customers, while some customers are allocated to the lockers. This study introduces the Robot-Aided Electric Vehicle Routing Problem with Lockers and Prime Customer Prioritization (REVRP-LPCP), which aims to determine the least-cost routes for EVs and robots, assign customers to lockers, and prioritize prime customers by serving them within a single-period planning horizon. The REVRP-LPCP is formulated using a mixed-integer linear programming model, improving the EV-only-based delivery system by 52.94% and 21.95% in EV route and utilization costs on average. A metaheuristic is introduced, incorporating problem-specific repair and improvement operators to efficiently address large instances of the problem, outperforming Gurobi in 36 large instances by an average of 2.79% in terms of solution quality. Also, our method has identified 44 new best solutions in the related benchmarks. A comprehensive sensitivity analysis is conducted, assessing various scenarios and providing managerial insights.},
  archive      = {J_EJOR},
  author       = {Nima Moradi and Fereshteh Mafakheri and Chun Wang and Roberto Baldacci},
  doi          = {10.1016/j.ejor.2025.07.007},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1018-1035},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robot-aided electric vehicle routing problem with lockers and prime customers prioritization},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conjugate paretian inefficiency measures. <em>EJOR</em>, <em>328</em>(3), 1007-1017. (<a href='https://doi.org/10.1016/j.ejor.2025.06.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study efficiency measurement using a partial ordering for the S-dimensional reals that generalizes the canonical less than or equal to partial ordering. We seek measures that judge outcomes as favorably as possible using a dual normalization strategy that generalizes those used in the minimum-norm and efficiency-measurement literatures. We characterize the efficient frontier using dual methods and use that representation to identify a dual Nerlovian inefficiency measure. The Paretian inefficiency measure is defined as the minimal Nerlovian measure while constraining dual variates to fall in a predetermined closed convex set. We show that the Paretian inefficiency measure forms a dual conjugate pair with a restricted Nerlovian efficiency measure. We use those results to develop conditions that ensure that the Paretian inefficiency measure is an exhaustive function (cardinal) representation of the feasible set. We present a series of composition rules for different restrictions on the feasible set and dual-variate normalization that include generalizations of existing inefficiency measures. An empirical illustration of the concepts developed that is based on Catalan farming data closes the substantive part of the paper.},
  archive      = {J_EJOR},
  author       = {Robert G. Chambers},
  doi          = {10.1016/j.ejor.2025.06.019},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1007-1017},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Conjugate paretian inefficiency measures},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Eco-efficiency or eco-differentiation: Strategic prioritization of environmental investments. <em>EJOR</em>, <em>328</em>(3), 989-1006. (<a href='https://doi.org/10.1016/j.ejor.2025.06.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective prioritization of environmental investments is critical for firms seeking to achieve sustainable competitive advantage and maximize economic returns. Many environmental initiatives fail due to the absence of a structured “choice” framework, which leads firms to adopt a scattered approach of doing “a bit of everything”—a strategy that squanders limited resources and undermines future innovation efforts. To address this lack of structured guidance, we develop a game-theoretic model that formalizes the strategic prioritization problem firms face when allocating resources between two archetypal environmental innovation strategies, distilled from recurring patterns in corporate practice, industry reports, and academic literature: eco-differentiation (a demand-enhancing, product-oriented investment with high failure risk, delayed payoff, and substantial capital outlay) and eco-efficiency (a cost-reducing, process-oriented investment with minimal risk, short lead time, and lower capital outlay). Our model incorporates strategic rivalry, firm-specific innovation capabilities, innovation failure risks, product development lead times, and consumer heterogeneity in both brand and environmental preferences—alongside a novel interaction between these two preference dimensions—as well as an endogenous transition in market structure triggered by the successful introduction of eco-differentiated products. Our equilibrium analysis establishes explicit innovative capability thresholds that delineate equilibrium regions and characterize firms’ optimal environmental investment choices. Our theoretical findings provide actionable insights to help firms—particularly those with limited resources—tailor their environmental investment choices to industry- and market-specific constraints, enabling them to translate sustainability efforts into sources of sustained profitability and competitive advantage.},
  archive      = {J_EJOR},
  author       = {Arda Yenipazarli},
  doi          = {10.1016/j.ejor.2025.06.021},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {989-1006},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Eco-efficiency or eco-differentiation: Strategic prioritization of environmental investments},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A bilevel multistage stochastic self-scheduling model with indivisibilities for trading in the continuous intraday electricity market. <em>EJOR</em>, <em>328</em>(3), 966-988. (<a href='https://doi.org/10.1016/j.ejor.2025.06.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the profit maximization problem of a virtual power plant trading in the continuous intraday electricity market. Our virtual power plant model is compatible with renewable, and thermal assets, covering a range of virtual power plants currently participating in energy markets. We model the trading problem as a bilevel multistage stochastic program. The upper level of the problem accounts for the profit maximization of the virtual power plant with explicit modeling of the technical constraints of the operational status of the thermal power plant including minimum start-up and shut-down times, ramp-up and ramp-down rates, and minimum generation level. The upper level also decides which continuous and indivisible (fill-or-kill) orders are submitted to the market. The lower-level problem accounts for the clearing of the continuous intraday market, i.e., matching of buy and sell orders. Because of the presence of fill-or-kill orders, the lower-level problem is mixed-integer, which prevents its direct conversion to a single-level problem using duality. In order to solve this challenging problem, we develop a convex-hull extended formulation for the lower-level problem, apply duality theory to obtain a single-level stochastic equivalent formulation, and employ McCormick envelopes to turn the problem into a multistage stochastic mixed-integer linear problem, which we solve using the stochastic dual dynamic integer programming algorithm. We conduct numerical experiments and analyze the optimal trading behavior of a virtual power plant trading in an ideal continuous market without arbitrage.},
  archive      = {J_EJOR},
  author       = {Priyanka Shinde and Ignacio Aravena},
  doi          = {10.1016/j.ejor.2025.06.002},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {966-988},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bilevel multistage stochastic self-scheduling model with indivisibilities for trading in the continuous intraday electricity market},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Business model selection in competition with an E-platform’s store brand under various channel price leadership. <em>EJOR</em>, <em>328</em>(3), 946-965. (<a href='https://doi.org/10.1016/j.ejor.2025.07.035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms have witnessed substantial growth in recent years. Within these platforms, national brand manufacturers (NBMs) face a choice between two distinct business models for selling their products: the wholesale model or the agency model. Additionally, the e-commerce platform itself may introduce a store brand (SB) that competes with the NBM’s national brand (NB). We have delved into the intricate dynamics at play between the NBM’s selection of a business model and the e-platform’s decision to introduce an SB, employing a game-theoretic model. Our investigation has yielded valuable insights: First, when an NBM opts for the wholesale model, the e-platform consistently introduces an SB. Conversely, under the agency model, the e-platform refrains from introducing an SB if both the commission rate for the NB product and the planned quality of the SB are sufficiently high. If the e-platform introduces the SB with low quality, the NBM may switch from an agency model to a wholesale model at a relatively low commission rate for the e-platform. Furthermore, the e-platform tends to favor an intermediate level of quality for the SB. This approach allows the SB to generate substantial revenue without engaging in intense competition with the NB. Both the NBM and the e-platform tend to prefer a moderate commission rate. Finally, our analysis delves into the impact of channel price leadership on the equilibrium outcomes. In a surprising turn, under the agency model, it proves advantageous for both firms to relinquish channel price leadership. Additionally, the NBM is more likely to adopt the wholesale model when it assumes the role of channel price leader. The e-platform is less likely to introduce SBs when it takes on the leadership position.},
  archive      = {J_EJOR},
  author       = {Hai Li and Jing Shao and Stuart X. Zhu},
  doi          = {10.1016/j.ejor.2025.07.035},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {946-965},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Business model selection in competition with an E-platform’s store brand under various channel price leadership},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficiency analysis of natural cardinal ranking vectors for pairwise comparisons and the universal efficiency of the perron geometric mean. <em>EJOR</em>, <em>328</em>(3), 938-945. (<a href='https://doi.org/10.1016/j.ejor.2025.07.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In models using pairwise (ratio) comparisons among alternatives, a cardinal ranking vector should be deduced from a reciprocal matrix. The right Perron eigenvector (RP) was traditionally used, though several other options have emerged. We consider some alternatives, namely the entry-wise reciprocal of the left Perron vector (LP), the left singular vector (LS), the entry-wise reciprocal of the right singular vector (RS), the arithmetic and geometric means of RP and LP (AP and GP), and of LS and RS (AS and GS). All eight of these vectors produce the natural vector in the consistent case. We compare them empirically, in terms of frequency of efficiency, for random reciprocal matrices, as a function of the number of alternatives. The vector GP is proved to be universally efficient. This provides a new proposal for the cardinal ranking vector. The vector GS performs better than the remaining six vectors, though all of them have a high frequency of efficiency. We show that, for reciprocal matrices obtained from consistent matrices by modifying one column and the corresponding row, all eight vectors are efficient. Moreover, the cone generated by the columns is efficient. This class of matrices includes a type of double perturbed consistent matrices, that is, reciprocal matrices obtained from consistent ones by modifying two pairs of symmetrically located entries. We also show the efficiency of the studied vectors for the double perturbed consistent matrices that are not column perturbed.},
  archive      = {J_EJOR},
  author       = {Susana Furtado and Charles R. Johnson},
  doi          = {10.1016/j.ejor.2025.07.013},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {938-945},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficiency analysis of natural cardinal ranking vectors for pairwise comparisons and the universal efficiency of the perron geometric mean},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey-based priority elicitation protocol for community-based resource allocation decisions. <em>EJOR</em>, <em>328</em>(3), 925-937. (<a href='https://doi.org/10.1016/j.ejor.2025.07.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision Analysis is increasingly being used to support resource allocation in communities, given its ability to represent the priorities of community members and support transparent resource allocation. Current attempts to elicit priorities in these interventions rely increasingly upon conducting surveys (face-to-face or online). Nevertheless, such preference elicitation initiatives may suffer if respondents do not clearly understand the questions being asked. Many protocols for priority elicitation currently used in Decision Analysis were originally designed to be employed by a decision analyst, who provides extensive support to a small number of decision makers in eliciting their judgments. However, such standard elicitation protocols may not be suitable for surveys, as the elicitation questions require a high level of understanding and a high cognitive effort from the respondents. Hence, in this paper, we suggest a new protocol for eliciting individual priorities for resource allocation decisions via either assisted or unassisted large-scale surveys, which elicits strict preference relations. We base this protocol on the Marketing research literature, which has dealt extensively with similar surveys. We adopt a Multi-Attribute Value Theory framework and design the protocol to avoid the range-insensitivity bias in multi-attribute choices. We assess the suitability of the widely employed swing weighting method for survey-based elicitation of priorities in comparison to the proposed protocol and find that swing weighting may not be suitable for resource allocation problems. We also suggest how the proposed protocol may improve the coherence of judgments elicited from the swing weighting method for survey-based priority elicitation.},
  archive      = {J_EJOR},
  author       = {José Geraldo Vidal Vieira and Gilberto Montibeller},
  doi          = {10.1016/j.ejor.2025.07.049},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {925-937},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A survey-based priority elicitation protocol for community-based resource allocation decisions},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generator sets for the minkowski sum problem. <em>EJOR</em>, <em>328</em>(3), 912-924. (<a href='https://doi.org/10.1016/j.ejor.2025.07.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a new theoretical framework for generator sets in the context of Minkowski Sum Problems (MSPs) arising in multi-objective optimization. In MSPs, the nondominated set of the global problem equals the nondominated set of the Minkowski sum of several local nondominated sets. We introduce the concept of generator sets: subsets of local nondominated vectors that are sufficient to construct the global nondominated set. We present novel theoretical results that characterize conditions for vectors to belong to a generator set or to be redundant. Moreover, we develop algorithms for finding generator sets and identifying redundant local vectors. Finally, we conduct extensive numerical experiments to test the impact of varying characteristics of the instances on the resulting global nondominated set and the number of redundant vectors.},
  archive      = {J_EJOR},
  author       = {Mark Lyngesen and Sune Lauth Gadegaard and Lars Relund Nielsen},
  doi          = {10.1016/j.ejor.2025.07.005},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {912-924},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generator sets for the minkowski sum problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributionally robust optimization with generalized total variation ambiguity sets. <em>EJOR</em>, <em>328</em>(3), 894-911. (<a href='https://doi.org/10.1016/j.ejor.2025.09.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a data-driven framework for distributionally robust optimization (DRO), founded on a new class of ambiguity sets termed generalized total variation (GTV) sets. In contrast to traditional DRO approaches, the proposed scheme constructs ambiguity sets whose geometry incorporates sample size, support, confidence level, empirical distribution, and cost function structure. Under this framework, we develop two tractable solution methods (first-order, gradient-based), each offering finite-sample statistical guarantees. The first-order approach employs sequential convex programming to construct a solution, followed by a linear program to determine a high-confidence upper bound (i.e., generalization bound) on the solution’s unknown true risk. The gradient-based approach, applicable when the ambiguity set has a smoothly curved boundary, utilizes gradient information to establish a high-confidence upper bound through a sequence of convex programs, all linear except for the final step. We prove that both methods produce statistically consistent risk estimates. Then, we empirically validate the framework on two applications: a synthetic two-item Newsvendor problem and a real-world portfolio optimization problem using S&P 500 asset returns. Results demonstrate that for finite support problems, GTV ambiguity sets can deliver generalization bounds that are as tight as, or tighter than, those from popular alternatives such as Wasserstein and total variation ambiguity sets. We thus highlight the practical benefits of incorporating several types of information into ambiguity set construction, offering improved robustness-performance tradeoffs for data-driven decision-making under uncertainty.},
  archive      = {J_EJOR},
  author       = {Belleh Fontem and Ran Ji},
  doi          = {10.1016/j.ejor.2025.09.024},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {894-911},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distributionally robust optimization with generalized total variation ambiguity sets},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Markov decision processes: Monotonicity of optimal policy in exponential and quasi-hyperbolic discounting parameters. <em>EJOR</em>, <em>328</em>(3), 877-893. (<a href='https://doi.org/10.1016/j.ejor.2025.09.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intertemporal preferences of decision makers, i.e., the way they discount delayed utilities, impact their decisions. Empirical evidence suggests that individuals commonly have hyperbolic discounting preferences. This can result in time-inconsistent behavior, e.g., procrastination, which may be a barrier to adopting preventive behavior such as machine maintenance and patient adherence to treatment. In this paper, we theoretically compare the actions of individuals based on their discounting characteristics. We consider the Hyperbolic Discounting (HD) model, which is more representative of individual behavior than Exponential Discounting (ED). We formulate a discrete-time finite-horizon Markov decision process with Quasi-Hyperbolic Discounting (QHD), an analytically tractable function representing HD and present sufficient conditions that ensure the monotonicity of the optimal policy in the discounting parameters. We consider submodular maximization or supermodular maximization problems. Our paper is the first to investigate the monotonicity of the optimal policy in QHD parameters for these problems. Moreover, we compare the optimal actions under ED and QHD. We apply our results to the settings of machine maintenance, individual health behavior and inventory control. We provide numerical examples that show there might not be monotonicity if our sufficient conditions are not met. Also, we explore the discrepancy between the expected total exponentially-discounted rewards of the actions obtained from QHD and of the actions that are optimal under ED, and observe that this discrepancy is affected mainly by the present bias.},
  archive      = {J_EJOR},
  author       = {Hakan Kılıç and Pelin Gülşah Canbolat and Evrim Didem Güneş},
  doi          = {10.1016/j.ejor.2025.09.013},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {877-893},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Markov decision processes: Monotonicity of optimal policy in exponential and quasi-hyperbolic discounting parameters},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient simulation budget allocation for contextual ranking and selection with quadratic models. <em>EJOR</em>, <em>328</em>(3), 862-876. (<a href='https://doi.org/10.1016/j.ejor.2025.08.042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers contextual ranking and selection problems where the objective is to identify the best design under every possible context. We assume the mean performance of each alternative design to be a quadratic function across a continuous context space. By judiciously pre-selecting a finite set of contexts for sampling and leveraging this quadratic model structure, we develop an efficient Bayesian budget allocation procedure that actively learns the problem instance and myopically improves decision quality across the context space. We prove the asymptotic consistency of our algorithm. We also conduct extensive numerical experiments using both synthetic functions and industrial examples whereby we show that our procedure can deliver significantly better performance against benchmark algorithms under both fixed-budget and fixed-precision settings.},
  archive      = {J_EJOR},
  author       = {Dongyang Li and Ek Peng Chew and Haobin Li and Enver Yücesan and Chun-Hung Chen},
  doi          = {10.1016/j.ejor.2025.08.042},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {862-876},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient simulation budget allocation for contextual ranking and selection with quadratic models},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exact solution approaches for the traveling salesman problem with a drone station. <em>EJOR</em>, <em>328</em>(3), 845-861. (<a href='https://doi.org/10.1016/j.ejor.2025.07.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of e-commerce has posed significant challenges for urban last-mile delivery. In this paper, we study a truck–drone collaborative delivery problem, referred to as the traveling salesman problem with a drone station (TSP-DS), which is well-suited for densely populated urban environments. The TSP-DS extends the well-known parallel drone scheduling traveling salesman problem (PDSTSP). The truck starts from the depot and can deliver packages to the drone station for drone delivery. To minimize the delivery makespan, we propose two improved formulations for the TSP-DS using mixed-integer linear programming (MILP). We then develop an exact algorithm based on the logic-based Benders decomposition approach. To evaluate the effectiveness of these approaches, we conduct extensive computational experiments using test instances generated from existing benchmarks. The numerical results confirm the improvements offered by our formulations compared to the TSP-DS formulation in the existing literature. Our Benders approach also outperforms the state-of-the-art commercial solver Gurobi, solving all instances with no more than 152 customers to the global optimum within 3600 s. We also obtain an optimal solution for an instance with 264 customers. Additionally, we perform sensitivity analyses to investigate the impact of critical model parameters, including the number, speed, and flight range of drones, as well as the location of the drone station, on the performance of the delivery system. The results offer valuable management insights from both the system planning and operational perspectives.},
  archive      = {J_EJOR},
  author       = {Zhiyuan Shi and Shaozhi Hong and Zeling Wang and Ang Li},
  doi          = {10.1016/j.ejor.2025.07.027},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {845-861},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact solution approaches for the traveling salesman problem with a drone station},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quality strategy to confront store brand encroachment. <em>EJOR</em>, <em>328</em>(3), 832-844. (<a href='https://doi.org/10.1016/j.ejor.2025.07.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A retailer contemplating the introduction of a store brand (SB) may exploit the product quality of a national brand (NB) without bearing cost, potentially hindering the manufacturer’s efforts to promote NB quality. This study delves into the optimal decision of NB quality by the manufacturer to confront the retailer’s SB encroachment and investigates the interplay of SB encroachment and NB quality decision. The findings reveal several key insights: First, with an increase in NB quality or SB recognition, the retailer is motivated to introduce SB. Particularly, when SB recognition is notably high, the retailer positions SB as a strategic threat against the manufacturer rather than an active selling channel. Second, a high quality investment efficiency or SB recognition may dissuade the manufacturer from enhancing NB quality in anticipation of potential SB encroachment, while a low quality investment efficiency or SB recognition may incentivize its improvement. Third, SB encroachment may bring different outcomes for chain members and consumers, mainly caused by the joint influence of quality investment efficiency and SB recognition. Specifically, when quality investment efficiency and SB recognition are low, SB encroachment may result in a mutually beneficial outcome for all chain members and consumers. However, the relatively large quality investment efficiency or SB recognition can yield a lose–lose–lose outcome. Interestingly, SB recognition may have non-monotonic impacts on the profitability of both supply chain members.},
  archive      = {J_EJOR},
  author       = {Jingxin Zhang and Jianxiong Zhang and Rui Yang and Xiaohang Yue},
  doi          = {10.1016/j.ejor.2025.07.017},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {832-844},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quality strategy to confront store brand encroachment},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing transportation service management with bi-level optimization: Competitive pricing and hub location. <em>EJOR</em>, <em>328</em>(3), 815-831. (<a href='https://doi.org/10.1016/j.ejor.2025.07.033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper highlights the importance of efficient service network design through hub management in reducing transportation costs and offering competitive service prices. For this, it addresses the problem of how a new entrant in the transportation market can design its hub network and set competitive prices. Meanwhile, the incumbent can react to new market conditions by revising its service prices. We develop a new bi-level mathematical model within a Stackelberg game competition framework. Using logit model, we examine customer preferences. A novel decomposition-based solution technique is proposed which transforms the original model into a tri-level structure by separating the hub location and pricing decisions for the entrant. The Lambert-W function is employed to reduce this tri-level problem to a new bi-level format, which effectively splits the hub location and pricing tasks. Additionally, we implement a new hybrid hyper-heuristic and a modified learning-based tabu search meta-heuristic method for pricing and hub location, respectively. The results show that fewer hubs from the incumbent increase the entrant's competitive advantage, allowing it to improve market share and profit by strategically differentiating its network. Also, the difference in discount rates between the hubs of the two competitors is an important factor in shaping their competitive advantage in capturing market share. This advantage becomes more significant as customer sensitivity to service price increases.},
  archive      = {J_EJOR},
  author       = {Seyed Parsa Parvasi and MirMohammad Musavi and Seyed Ali Torabi and Wei Yim Yap and Jasmine Siu Lee Lam},
  doi          = {10.1016/j.ejor.2025.07.033},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {815-831},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Enhancing transportation service management with bi-level optimization: Competitive pricing and hub location},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Carbon emissions hedging and green marketing. <em>EJOR</em>, <em>328</em>(3), 797-814. (<a href='https://doi.org/10.1016/j.ejor.2025.07.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a hedging and green marketing coordination problem for a supply chain under which a manufacturer sells products through a retailer to satisfy demand which is sensitive to both green marketing and product greenness. Green marketing promotes demand but requires the retailer to make extra investment. Product greenness depends on the actual realized carbon emission abatement (CEA). However, due to uncertainties during the production process, the realized CEA often less than its target level. To entice the retailer to pay more effort on green marketing, some manufacturers enhance the product greenness by taking proactive activities to hedge against CEA uncertainties, which is referred to as carbon emission hedging (CEH). To examine the effect of CEH on green marketing and channel performances, we proposed a CEH and green marketing mechanism (CG mechanism). Moreover, since the game follower usually exhibits fairness concerns, we also explore the various combinations of the retailer’s fairness concern behaviour and the manufacturer’s attitude towards this behaviour. We find that adopting the CEH strategy promotes the green marketing and the CG mechanism always coordinates the supply chain when the retailer is fairness-neutral or his fairness-concern level is not sufficiently high (e.g. λ₁ ≈ 0.9). Besides, lower consumer price sensitivity and higher consumer green marketing/product greenness sensitivity/amplification effect of CEH on green marketing improve the market demand and the retailer’s profit, but not necessarily benefit the manufacturer. Additionally, being fairness-concerned is not always beneficial for the retailer and ignoring the retailer’s fairness concern often harms the manufacturer.},
  archive      = {J_EJOR},
  author       = {Yue Zhai and Huxi Deng and Suxiu Xu and George Q. Huang and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2025.07.029},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {797-814},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Carbon emissions hedging and green marketing},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A single nurse routing and scheduling problem for home-based chemotherapy and infusion services. <em>EJOR</em>, <em>328</em>(3), 785-796. (<a href='https://doi.org/10.1016/j.ejor.2025.07.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home health care has expanded to include infusion treatments for chemotherapy and other diseases requiring periodic infusions. Scheduling these appointments is crucial and complex due to the urgency of treatment and their unique cyclic patterns over several months. This complexity arises because adding a new patient affects not only the immediate schedule but also has long-term implications. This paper presents a mathematical model for a single nurse routing and scheduling problem for home-based chemotherapy and infusion services. The aim is to maximise the number of priority-weighted new chemotherapy and infusion patients incorporated into the system by optimising the route and schedule for a single nurse, considering the cyclical nature of infusion treatments with an extended planning horizon. A novel matheuristic approach, the Temporal Decomposition and Filtering based Matheuristic (TDFM), is introduced to address this large-scale problem. Computational experiments on practical-sized problems demonstrate that the proposed solution approach, combined with commercially available solvers, is able to achieve high-quality solutions within a useful timeframe.},
  archive      = {J_EJOR},
  author       = {Vishmi Fernando and Melih Ozlen and Sona Taheri},
  doi          = {10.1016/j.ejor.2025.07.038},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {785-796},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A single nurse routing and scheduling problem for home-based chemotherapy and infusion services},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An energy-efficient scheduling approach for a two-stage hybrid flow shop with parallel batch machines. <em>EJOR</em>, <em>328</em>(3), 762-784. (<a href='https://doi.org/10.1016/j.ejor.2025.07.055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of energy costs and the deterioration of the environment, manufacturing companies face increasing production expenses. Reducing energy consumption while improving manufacturing efficiency has become a major challenge. This study addresses the scheduling problem of a two-stage hybrid flow shop with time-of-use (TOU) electricity pricing, which arises from a tempered glass production environment. In the first stage, parallel machines are subject to specific qualification requirements, while parallel batch processing machines are used in the second stage. The objectives are to minimize both the makespan ( C m a x ) and total energy consumption (TEC). To address this problem, a mixed-integer programming (MIP) model is developed. Furthermore, a constructive heuristic based on greedy local search and an adaptive multi-population cooperative evolutionary algorithm (AMCEA) are proposed, respectively. In AMCEA, subpopulations are formed based on reference vectors, and adaptive cooperative search facilitates information exchange. Two regional local search operators and two adjustment strategies based on TOU electricity pricing are designed to enhance the exploitation capability of the proposed algorithm. Experimental results demonstrate that the proposed algorithm outperforms state-of-the-art algorithms for the hybrid flow shop under TOU electricity pricing problem.},
  archive      = {J_EJOR},
  author       = {Zhao-hong Jia and Tianfu Wu and Han Zhang and Chuang Liu and Kai Li},
  doi          = {10.1016/j.ejor.2025.07.055},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {762-784},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An energy-efficient scheduling approach for a two-stage hybrid flow shop with parallel batch machines},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic batching of online arrivals to leverage economies of scale. <em>EJOR</em>, <em>328</em>(3), 749-761. (<a href='https://doi.org/10.1016/j.ejor.2025.07.044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many settings, such as matching riders to drivers in ride-hailing platforms or in-stream video advertising, require handling arrivals over time. In such applications, it is often beneficial to group the arriving orders or requests into batches and process the larger batches rather than individual arrivals. However, waiting too long to create larger batches incurs a waiting cost for past arrivals. On the other hand, processing the arrivals too soon leads to higher processing costs by missing the economies of scale of grouping larger numbers of arrivals into larger batches. Moreover, the timing of the next arrival is often unknown, meaning fixed-size batches or fixed waiting times tend to be poor choices. In this work, we consider the problem of finding the optimal batching schedule to minimize the sum of waiting time and processing cost under both offline and online settings. In the offline problem in which all arrival times are known a priori, we show that the optimal batching schedule can be found in polynomial time by reducing it to a shortest path problem on a weighted acyclic graph. For the online problem with unknown arrival times, we develop algorithms that are provably competitive for a broad range of processing-cost functions. We also provide a lower bound on the competitive ratio that no online algorithm can beat. Finally, we run numerical experiments on simulated and real data to demonstrate the effectiveness of our algorithms against the offline benchmark.},
  archive      = {J_EJOR},
  author       = {Akhil Bhimaraju and S. Rasoul Etesami and Lav R. Varshney},
  doi          = {10.1016/j.ejor.2025.07.044},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {749-761},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic batching of online arrivals to leverage economies of scale},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fifty years of soft operational research: The contribution of EURO and EJOR to its foundation and development. <em>EJOR</em>, <em>328</em>(3), 735-748. (<a href='https://doi.org/10.1016/j.ejor.2025.05.040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Operational Research (Soft OR) emerged as a distinctive approach emphasising stakeholder engagement to address complex, ill-defined problems, departing from traditional OR methods. This review explores the nature and potential of Soft OR over the past fifty years, focusing specifically on articles published in the European Journal of Operational Research (EJOR) to clarify some foundational principles and trace its evolution. The review highlights essential aspects such as stakeholder agency, engagement as both representing (the role of modelling) and intervening (workshop facilitation), and the socio-technical aspect crucial for effective problem-solving. Fifty years on, debates about Soft OR’s legitimacy and its critical role in contemporary issues, including climate change and technological disruption, remain highly relevant. Future directions suggest further developing theories of engagement and integrating technological advancements, particularly artificial intelligence (AI), to ensure that Soft OR continues to be relevant and impactful in addressing exceedingly complex societal challenges in the twenty-first century.},
  archive      = {J_EJOR},
  author       = {Leroy White},
  doi          = {10.1016/j.ejor.2025.05.040},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {735-748},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of soft operational research: The contribution of EURO and EJOR to its foundation and development},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimistic and pessimistic approaches for cooperative games. <em>EJOR</em>, <em>328</em>(2), 725-733. (<a href='https://doi.org/10.1016/j.ejor.2025.09.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative game theory explores how to fairly allocate the joint value generated by a group of decision-makers, but its application is compromised by the large number of counterfactuals needed to compute the value of all coalitions, a problem made even more complicated when externalities are present. We provide a theoretical foundation for a simplification used in many applications, in which the value of a coalition is computed assuming that they either select before or after the complement set of agents, providing optimistic and pessimistic values on what a coalition should receive. In a vast set of problems exhibiting what we call feasibility externalities, we show that ensuring a coalition does not receive more than its optimistic value is always at least as difficult as ensuring it receives its pessimistic value. Furthermore, under the presence of negative externalities, we establish the existence of stable allocations that respect these bounds. Finally, we examine well-known optimization-based applications and their corresponding cooperative games to show how our results lead to new insights and allow the derivation of further results from the existing literature.},
  archive      = {J_EJOR},
  author       = {Ata Atay and Christian Trudeau},
  doi          = {10.1016/j.ejor.2025.09.002},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {725-733},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimistic and pessimistic approaches for cooperative games},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable product development under profit-sharing crowdfunding: An analytical approach to market structure and government policy. <em>EJOR</em>, <em>328</em>(2), 704-724. (<a href='https://doi.org/10.1016/j.ejor.2025.08.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an integrated analytical framework to examine how crowdfunding, market structure, and government policy interact to shape environmentally sustainable product development (SPD). Focusing on profit-sharing and securities-based crowdfunding, we model how investor opportunity costs, risk preferences, platform fees, and regulatory schemes (voluntary vs. mandatory under fiscal vs. non-fiscal policy regimes) influence firm strategies and outcomes across economic, social, and environmental (ESE) dimensions. Firm behavior is analyzed under monopoly and duopoly settings to explore variation in market power and competitive intensity. Findings reveal that voluntary greening can achieve strong ESE outcomes in monopolistic markets with low financial frictions and environmentally aware consumers. In contrast, competitive or uncertain environments often require benchmark-based regulation and fiscal instruments to sustain environmental investments. Two dominant firm profiles emerge: the Voluntary sustainability leader, which performs well under favorable market and investor conditions without policy intervention, and the Policy-driven strategist, which depends on regulatory standards and fiscal tools to overcome competitive pressures and risk constraints. By formalizing investor-entrepreneur interactions and embedding environmental quality as a strategic variable, this research advances the literature on crowdfunding and market-driven sustainability. It provides actionable insights for aligning crowdfunding design and policy frameworks with the broader goals of green innovation and public sustainability.},
  archive      = {J_EJOR},
  author       = {Raziyeh Reza-Gharehbagh and Madeleine Pullman},
  doi          = {10.1016/j.ejor.2025.08.020},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {704-724},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sustainable product development under profit-sharing crowdfunding: An analytical approach to market structure and government policy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal dividend and scale of business strategies with reinsurance and premium pricing for insurance company. <em>EJOR</em>, <em>328</em>(2), 694-703. (<a href='https://doi.org/10.1016/j.ejor.2025.07.039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the optimal dividend and business scale strategies aimed at maximizing the value of an insurance company. While prior studies typically assume that insurers can only adjust their business scale through reinsurance, this study extends the framework by allowing the insurer to control the premium rate. Under more realistic market assumptions, we examine the joint optimization problem for two common types of reinsurance — proportional and excess-of-loss — across both arbitrage and non-arbitrage scenarios. We derive the optimal strategies for dividends and premium pricing, along with their corresponding value functions. The results show that the insurer should decrease the premium rate and reduce reinsurance coverage as the surplus increases. The optimal dividend policy follows a barrier strategy. Economic interpretations and numerical examples are provided to illustrate the findings.},
  archive      = {J_EJOR},
  author       = {Dingjun Yao and Bo Yang and Xin Xu and Youwei Li and Yizhi Wang},
  doi          = {10.1016/j.ejor.2025.07.039},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {694-703},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal dividend and scale of business strategies with reinsurance and premium pricing for insurance company},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anticipating delays in recruitment: Explainable machine learning for the prediction of hard-to-fill online job vacancies. <em>EJOR</em>, <em>328</em>(2), 680-693. (<a href='https://doi.org/10.1016/j.ejor.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online job vacancy (OJV) platforms have transformed the labor market by enabling employers to advertise jobs to a wide audience. Particularly in tight labor markets, quickly identifying vacancies likely to suffer prolonged durations is crucial. This study utilizes data from the Flemish public employment service's OJV platform to examine the effectiveness of machine learning in predicting hard-to-fill vacancies. We achieve notable predictive performance with XGBoost in forecasting recruitment delays and demonstrate the importance of capturing non-linear patterns in OJV data. SHAP (SHapley Additive exPlanations) values reveal that the textual content of vacancies and latent company characteristics are key predictors of hiring delays. Counterfactual-SHAP insights provide practical guidance for refining recruitment strategies, enhancing labor market forecasts, and informing targeted policies.},
  archive      = {J_EJOR},
  author       = {Wouter Dossche and Sarah Vansteenkiste and Bart Baesens and Wilfried Lemahieu},
  doi          = {10.1016/j.ejor.2025.06.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {680-693},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Anticipating delays in recruitment: Explainable machine learning for the prediction of hard-to-fill online job vacancies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Using diet optimization and machine learning for the design of healthy and acceptable menu plans. <em>EJOR</em>, <em>328</em>(2), 668-679. (<a href='https://doi.org/10.1016/j.ejor.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of dietary plans relies on understanding and modelling consumer acceptance, yet quantifying this poses a challenge due to the complexity of individual preferences. Recent research is focused on deriving acceptability constraints directly from data, as demonstrated by its application in designing food baskets with a limited number of commodities. In this study, we applied diet optimization with machine learning to the more complex task of menu planning. This involved considering hundreds of potential food alternatives and assessing their compatibility within a meal using a recipe completion algorithm. Compared to the traditional diet modelling approach of food group filtering, the recipe completion model delivered diets with either higher nutritional adequacy or greater substitute acceptability, depending on the number of food groups used in the traditional method. While more research is needed to further improve the acceptability of substitutions, combining diet optimization with recipe completion presents a promising approach to enhance the nutritional adequacy of individual diets while maintaining the acceptability of food combinations within meals.},
  archive      = {J_EJOR},
  author       = {Dominique van Wonderen and Johanna C. Gerdessen and Alida Melse-Boonstra and Marleen C. Onwezen},
  doi          = {10.1016/j.ejor.2025.06.015},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {668-679},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using diet optimization and machine learning for the design of healthy and acceptable menu plans},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Project monitoring and control with an empirically grounded budget-release model. <em>EJOR</em>, <em>328</em>(2), 646-667. (<a href='https://doi.org/10.1016/j.ejor.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project monitoring and control (PMC) is a process of measuring a project’s progress and taking corrective action when necessary to ensure successful project completion. However, most existing models lack empirical validation of their assumptions and effectiveness, which limits their practical use. We fill in this gap by using empirical data from 97 real projects to calibrate activity-duration distributions and assess activity-duration dependencies, integrating these empirical foundations into an enhanced PMC model. We further improve the model by incorporating budget-release timing constraints and introducing two new policies for crashing and fast-tracking based on a project’s specific time and cost characteristics. Extensive computational experiments using empirical and artificial data evaluate the effectiveness of these policies. Because the budget-release policies and corrective action types depend on project characteristics such as activity-duration dependencies and topological network structure, key insights from this study can be usefully applied by project managers as heuristics even without a detailed model of their project.},
  archive      = {J_EJOR},
  author       = {Jie Song and Jinbo Song and Tyson Browning and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2025.06.007},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {646-667},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Project monitoring and control with an empirically grounded budget-release model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The continuous roll-on roll-off dual cycling problem with tugs and driver-handled cargo units. <em>EJOR</em>, <em>328</em>(2), 633-645. (<a href='https://doi.org/10.1016/j.ejor.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roll-on roll-off vessels are a popular mode of transport in short-sea shipping. In this domain, appropriate stevedoring procedures are crucial to enhance efficiency. This includes dual cycling, where tugs simultaneously load and unload the vessel. Dual cycling reduces turnaround time, thereby giving the vessel more time to travel and allowing for slow steaming and reduced emissions. We extend the roll-on roll-off dual cycling problem by incorporating a continuous time horizon and differentiating cargo units that are handled by their own drivers and units that must be handled by a tug. We propose a mixed integer linear programming model for generating an efficient schedule that minimizes overall makespan by optimizing the sequence of cargo units and the assignment of cargo units to tugs. To solve instances of real-world size with acceptable computational effort, we provide a range of heuristics, including a biased random-key genetic algorithm. Compared to the linear programming model and on instances of real-world size, the genetic algorithm finds good solutions quickly. We derive managerial insights from a sensitivity analysis and show that dual cycling and strategic positioning of driver-handled units can reduce turnaround time by 14.5%, reducing emissions of the considered vessel by more than 8%. We demonstrate the robustness of these insights in uncertain environments through a simulation study.},
  archive      = {J_EJOR},
  author       = {Teresa Marquardt and Arne Heinold and Catherine Cleophas and Frank Meisel},
  doi          = {10.1016/j.ejor.2025.05.050},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {633-645},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The continuous roll-on roll-off dual cycling problem with tugs and driver-handled cargo units},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing treatment allocation in the presence of interference. <em>EJOR</em>, <em>328</em>(2), 620-632. (<a href='https://doi.org/10.1016/j.ejor.2025.09.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Influence Maximization (IM), the objective is to — given a budget — select the optimal set of entities in a network to target with a treatment so as to maximize the total effect. For instance, in marketing, the objective is to target the set of customers that maximizes the total response rate, resulting from both direct treatment effects on targeted customers and indirect, spillover, effects that follow from targeting these customers. Recently, new methods to estimate treatment effects in the presence of network interference have been proposed. However, the issue of how to leverage these models to make better treatment allocation decisions has been largely overlooked. Traditionally, in Uplift Modeling (UM), entities are ranked according to estimated treatment effect, and the top entities are allocated treatment. Since, in a network context, entities influence each other, the UM ranking approach will be suboptimal. The problem of finding the optimal treatment allocation in a network setting is NP-hard, and generally has to be solved heuristically. To fill the gap between IM and UM, we propose OTAPI: Optimizing Treatment Allocation in the Presence of Interference to find solutions to the IM problem using treatment effect estimates. OTAPI consists of two steps. First, a causal estimator is trained to predict treatment effects in a network setting. Second, this estimator is leveraged to identify an optimal treatment allocation by integrating it into classic IM algorithms. We demonstrate that this novel method outperforms classic IM and UM approaches on both synthetic and semi-synthetic datasets.},
  archive      = {J_EJOR},
  author       = {Daan Caljon and Jente Van Belle and Jeroen Berrevoets and Wouter Verbeke},
  doi          = {10.1016/j.ejor.2025.09.015},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {620-632},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing treatment allocation in the presence of interference},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Soft regression trees: A model variant and a decomposition training algorithm. <em>EJOR</em>, <em>328</em>(2), 607-619. (<a href='https://doi.org/10.1016/j.ejor.2025.08.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are widely used for classification and regression tasks in a variety of application fields due to their interpretability and good accuracy. During the past decade, growing attention has been devoted to globally optimized decision trees with deterministic or soft splitting rules at branch nodes, which are trained by optimizing the error function over all the tree parameters. In this work, we propose a new variant of soft multivariate regression trees (SRTs) where, for every input vector, the prediction is defined as the linear regression associated to a single leaf node, namely, the leaf node obtained by routing the input vector from the root along the branches with higher probability. SRTs exhibit the conditional computational property, i.e., each prediction depends on a small number of nodes (parameters), and our nonlinear optimization formulation for training them is amenable to decomposition. After showing a universal approximation result for SRTs, we present a decomposition training algorithm including a clustering-based initialization procedure and a heuristic for rerouting the input vectors along the tree. Under mild assumptions, we establish asymptotic convergence guarantees. Experiments on 15 well-known datasets indicate that our SRTs and decomposition algorithm yield higher accuracy and robustness compared with traditional soft regression trees trained using the nonlinear optimization formulation of Blanquero et al. (2021), and a significant reduction in training times as well as a slightly better average accuracy compared with the mixed-integer optimization approach of Bertsimas and Dunn (2019). We also report a comparison with the Random Forest ensemble method.},
  archive      = {J_EJOR},
  author       = {Antonio Consolo and Edoardo Amaldi and Andrea Manno},
  doi          = {10.1016/j.ejor.2025.08.050},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {607-619},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Soft regression trees: A model variant and a decomposition training algorithm},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable machine learning framework for recurrent event data analysis. <em>EJOR</em>, <em>328</em>(2), 591-606. (<a href='https://doi.org/10.1016/j.ejor.2025.09.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel explainable temporal point process (TPP) model, Stratified Hawkes Point Process (SHPP), for modelling recurrent event data (RED). Unlike existing approaches that treat temporal influence as a black box or rely on post-hoc explanations, SHPP structurally decomposes event intensities into semantically meaningful components for describing self-, Markovian, and joint influences. This decomposition enables direct quantification of how past events contribute to future event risks, termed as influence values. We further provide a sufficient condition for mean-square stability based on kernel decay, ensuring long-term boundedness of intensities and realistic behavioural predictions. Experiments and an e-commerce case study demonstrate SHPP’s ability to deliver accurate, interpretable, and stable modelling of complex event-driven systems.},
  archive      = {J_EJOR},
  author       = {Qi Lyu and Shaomin Wu},
  doi          = {10.1016/j.ejor.2025.09.005},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {591-606},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An explainable machine learning framework for recurrent event data analysis},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decision space dynamic niching-based method for constrained multiobjective evolutionary optimization. <em>EJOR</em>, <em>328</em>(2), 574-590. (<a href='https://doi.org/10.1016/j.ejor.2025.07.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a set with a good approximation to the Pareto-optimal solutions in the multiobjective optimization problem (MOP) is a challenging task in terms of convergence toward and diversity across the Pareto optimal front (PoF). In some cases, solving MOPs requires satisfying certain constraints, which significantly increases the complexity of the problem. Such problems are constrained multiobjective optimization problems (CMOPs) and pose considerable computational challenges. Many constrained multiobjective evolutionary algorithms (CMOEAs) face challenges in avoiding becoming trapped in local optima, which impacts convergence, and offer solutions that lack good coverage of the PoF, implying weak diversity. All these nonoptimal or partially optimal solutions in the objective space are essentially clustered in local optimality dilemmas in the decision space. To better eliminate the convergence and diversity challenges caused by clustered solutions, this paper proposes a decision space dynamic niching-based (DSDN) method to better address CMOPs. Specifically, the DSDN method adds a dynamic decision space niche as an additional criterion to the traditional Pareto-constrained dominance principle (Pareto-CDP). The better preserved solutions must satisfy the Pareto-CDP and the condition within the niche radius of other solutions, which strictly meets the original dominance relationship requirement while relaxing the nondominance threshold. As a result, the dynamic adjustment of the niche radius ( N R ) effectively balances the exploitation and exploration of solutions in the decision space while enhancing both convergence and diversity in the objective space. Experiments conducted on four widely recognized test suites and three real-world case studies have demonstrated that the DSDN method yields significantly better results than the original Pareto-CDP algorithms. Furthermore, the proposed approach is competitive with or comparable to seven other state-of-the-art CMOEAs.},
  archive      = {J_EJOR},
  author       = {Fan Yu and Qun Chen and Jinlong Zhou},
  doi          = {10.1016/j.ejor.2025.07.002},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {574-590},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision space dynamic niching-based method for constrained multiobjective evolutionary optimization},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Impact of technology spillovers and subsidies on innovation consortia dynamics. <em>EJOR</em>, <em>328</em>(2), 560-573. (<a href='https://doi.org/10.1016/j.ejor.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In innovation consortia, governments and enterprises view technology spillovers and subsidies differently, which reduces the effectiveness of policies and undermines cooperation. This work investigates the dynamics of cooperation among leading enterprises (LEs) and small/medium enterprises (SMEs), using an evolutionary game model with intrinsic, extrinsic and mixed strategies. We show that there may exist more than one evolutionary equilibrium of enterprise cooperation under multi-strategy choices. A high subsidy may induce enterprises to speculate and reach a suboptimal evolutionary equilibrium. Furthermore, our findings indicate that SMEs are particularly sensitive to changes in subsidy levels, income distribution ratios, and project income, with their speculative behavior exhibiting a lagging effect. Also, increasing the income distribution ratio of LEs can promote active cooperation between the groups and reduce the speculative tendency of SMEs. This occurs because it magnifies the effect of technology spillover on the income of SMEs and enhances the income of the leading enterprises. Our work improves understanding of cooperative factors and provides new recommendations for government and leading enterprises to improve cooperation and managerial performance.},
  archive      = {J_EJOR},
  author       = {Zheng Yang and Lin Li and Nicholas G. Hall and Yongzeng Lai and Yijiang Zhou},
  doi          = {10.1016/j.ejor.2025.06.031},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {560-573},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of technology spillovers and subsidies on innovation consortia dynamics},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online quality endorsement to improve consumer trust: Blockchain or self-hosted livestream?. <em>EJOR</em>, <em>328</em>(2), 545-559. (<a href='https://doi.org/10.1016/j.ejor.2025.04.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online products have long suffered from consumer distrust, putting them at a disadvantage when online brands compete with offline brands. To address this issue, many online brands have adopted blockchain as a means of quality endorsement to improve consumer trust. Alternatively, livestream e-commerce has shown the capability of both quality endorsement and demand creation by real-time interactions with consumers because the application of AR/VR technology and the use of online sales force can effectively induce the herding mentality. For many small and medium-sized online brands, it remains unclear which approach is better, so we formulate the key tradeoffs in the online brand's choice to improve consumer trust in the presence of offline brand's competition. Our research delves into the influence of three key factors on livestream e-commerce: the cost associated with adopting blockchain technology, the strength of positive network externality, and the potential downside of consumer returns. Contrary to conventional wisdom, we find that when the return cost is high and the network externality in livestream is weak, opting for livestream as a quality endorsement can actually benefit the online brand. We also find that the online brand is capable of mitigating the return cost by transferring it to consumers through charging a high retail price, which increases the likelihood of favoring livestream. Our findings shed light on the building and improvement of online consumer trust, contributing to the high-quality development of online-offline business in the new era of consumption.},
  archive      = {J_EJOR},
  author       = {Baozhuang Niu and Jian Dong and Xinhu Yu and Yulan Wang},
  doi          = {10.1016/j.ejor.2025.04.010},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {545-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Online quality endorsement to improve consumer trust: Blockchain or self-hosted livestream?},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Production trade-offs in free disposal hull technologies. <em>EJOR</em>, <em>328</em>(2), 530-544. (<a href='https://doi.org/10.1016/j.ejor.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data envelopment analysis, production trade-offs are value judgements that represent simultaneous changes to the inputs and outputs assumed to be technologically possible for any production unit in the technology. The specification of production trade-offs generally leads to an enlargement of the model of technology and increasing its discriminating power on efficiency. In conventional convex variable and constant returns-to-scale models, production trade-offs are the dual forms of weight restrictions. In this paper, we extend the use of production trade-offs to the free disposal hull model of technology and its constant, non-increasing and non-decreasing returns-to-scale variants, in a single unifying development. We provide an axiomatic definition of the new nonconvex technologies, explore the notion of consistent trade-offs in such technologies and develop methods for its testing. We further develop different computational approaches for nonconvex models with production trade-offs. We illustrate the new models by an application in the context of higher education.},
  archive      = {J_EJOR},
  author       = {Mahmood Mehdiloo and Grammatoula Papaioannou and Victor V. Podinovski},
  doi          = {10.1016/j.ejor.2025.06.032},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {530-544},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Production trade-offs in free disposal hull technologies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Price optimization for round trip car sharing. <em>EJOR</em>, <em>328</em>(2), 511-529. (<a href='https://doi.org/10.1016/j.ejor.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Car sharing, car clubs and short-term rentals could support the transition toward net zero but their success depends on them being financially sustainable for service providers and attractive to end users. Dynamic pricing could support this by incentivizing users while balancing supply and demand. We describe the usage of a round trip car sharing fleet by a continuous time Markov chain model, which reduces to a multi-server queuing model where hire duration is assumed independent of the hourly rental price. We present analytical and simulation optimization models that allow the development of dynamic pricing strategies for round trip car sharing systems; in particular identifying the optimal hourly rental price. The analytical tractability of the queuing model enables fast optimization to maximize expected hourly revenue for either a single fare system or a system where the fare depends on the number of cars on hire, while accounting for stochasticity in customer arrival times and durations of hire. Simulation optimization is used to optimize prices where the fare depends on the time of day or hire duration depends on price. We present optimal prices for a given customer population and show how the expected revenue and car availability depend on the customer arrival rate, willingness-to-pay distribution, dependence of the hire duration on price, and size of the customer population. The results provide optimal strategies for pricing of car sharing and inform strategic managerial decisions such as whether to use time- or state-dependent pricing and optimizing the fleet size.},
  archive      = {J_EJOR},
  author       = {Christine S.M. Currie and Rym M’Hallah and Beatriz Brito Oliveira},
  doi          = {10.1016/j.ejor.2025.06.024},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {511-529},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price optimization for round trip car sharing},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The development strategy of supply chain intelligent technology considering technology development uncertainty. <em>EJOR</em>, <em>328</em>(2), 496-510. (<a href='https://doi.org/10.1016/j.ejor.2025.07.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It’s crucial for both manufacturing and logistics industries to improve logistics efficiency and reduce logistics loss during transportation, storage, and other processes through the development and application of intelligent technology. By focusing on three potential modes of intelligent technology development cooperation between a manufacturer and its logistics provider, we examine the impact of such collaboration on reducing Logistics loss, as well as explore the optimal mode of cooperation for both firms. Our analytical results indicate that compared to independent technology development, collaborative development of intelligent technology can mitigate the adverse effects of double-marginalization. Comparing the three modes of cooperation, we find that higher development cost can incentivize the collaboration between two firms, while higher integration cost and price elasticity may make the cost sharing mode preferable. It is noteworthy that the uncertainty of intelligent technology development exerts a significant moderating effect on the choice of cooperation mode. Heightened technology development uncertainty tends to incentivize both firms to pursue joint development in order to alleviate the negative impact of the uncertainty.},
  archive      = {J_EJOR},
  author       = {Peng Han and Yanfang Huo and Weihua Liu and Ershi Qi and Helen Cai},
  doi          = {10.1016/j.ejor.2025.07.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {496-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The development strategy of supply chain intelligent technology considering technology development uncertainty},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal price, quantity, and return policy decisions of a two-period newsvendor with product reviews. <em>EJOR</em>, <em>328</em>(2), 477-495. (<a href='https://doi.org/10.1016/j.ejor.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online retailers (e-tailers) have high product return rates. To decrease product returns and consumers’ purchase risk, e-tailers can increase available product information through product reviews and/or offer money back guarantees (MBGs). We examine the rational expectations equilibrium of an e-tailer selling to myopic and strategic consumers over two periods. By the end of period 1, product reviews become available, providing a signal to strategic consumers who may wait to purchase in period 2. The e-tailer decides order quantity, prices, and return policy. We find that under both no returns and MBG, as strategic consumers’ patience increases, the optimal range of having them purchase in period 2 increases. For low signal accuracy, it is optimal to have strategic consumers purchase in period 1, whereas for high signal accuracy, it is optimal to have them purchase in period 2. However, under no returns and for a low signal accuracy, it may be optimal to have strategic consumers purchase in period 2 if their proportion is medium and they are patient. We also find that as consumers’ patience increases, the range where MBG dominates no returns increases. For heterogeneous signal accuracy among strategic consumers, equilibrium strategies are similar to the homogeneous case, except that when consumers’ patience is low, high heterogeneity allows the e-tailer to price discriminate, making low-signal accuracy consumers purchase in period 1 and high-signal accuracy consumers purchase in period 2. Also, as the proportion of low-signal accuracy consumers increases, price discrimination increases. Therefore, heterogeneity increases profit.},
  archive      = {J_EJOR},
  author       = {Huirong Fan and Moutaz Khouja and Jing Zhou},
  doi          = {10.1016/j.ejor.2025.06.023},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {477-495},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal price, quantity, and return policy decisions of a two-period newsvendor with product reviews},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Probabilistic forecast aggregation with statistical depth. <em>EJOR</em>, <em>328</em>(2), 460-476. (<a href='https://doi.org/10.1016/j.ejor.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers aggregation methods for interval forecasts and forecasts of cumulative distribution functions (CDFs) when there are many forecasters, and past forecast accuracy may not be known. For aggregation, the median and trimmed means have been proposed as simple and robust alternatives to the mean, with some trimmed mean approaches enabling recalibration to widen or narrow the resulting interval or CDF forecast. For interval forecast aggregation, the median and trimming are applied to each bound separately. To try to use the available information better, we treat the bounds as a bivariate point with statistical depth used to order the points in terms of centrality. The deepest point can be viewed as the median interval forecast, and the depth of each point can be used as the basis for trimming. For CDF forecasts, the literature presents aggregation methods for which the median or trimmed mean are obtained for each point on the domain of the distribution. However, if one part of a CDF forecast is outlying, the appeal of using the rest of the CDF forecast is perhaps reduced. We use functional depth to provide a measure of centrality for each CDF forecast, and hence identify the deepest function, which can be viewed as the median forecast. We also use functional depth as the basis for trimming, and consider weighted depth to control the width of the resulting aggregated interval or CDF forecast. We provide empirical illustration using data from surveys of professional macroeconomic forecasters, and an application to growth-at-risk.},
  archive      = {J_EJOR},
  author       = {James W. Taylor},
  doi          = {10.1016/j.ejor.2025.06.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {460-476},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Probabilistic forecast aggregation with statistical depth},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven approach for strategic inventory placement in multi-echelon supply networks. <em>EJOR</em>, <em>328</em>(2), 446-459. (<a href='https://doi.org/10.1016/j.ejor.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a data-driven solution for optimizing inventory buffers in large-scale supply networks. We study the placement and sizing of strategic inventories in multi-echelon supply chains where the decision maker faces uncertain demand with an unknown distribution influenced by explanatory variables. State-of-the-art multi-echelon inventory optimization models, such as the well-known guaranteed-service model (GSM), are non-linear and typically informed by distributional and parametric assumptions. They often rely on dynamic programming and are difficult to solve for large networks. We adapt the GSM to introduce a nonparametric, feature-driven approach to supply chain safety stock optimization that is based on mixed-integer linear programming (MILP). The MILP formulation sets cost-optimal base stocks, which are learned as linear functions of feature data under consideration of service level requirements. This integrated estimation and optimization approach is solved with commercial mathematical programming solvers and is enhanced by a Benders decomposition method for large networks. We extend the literature on data-driven inventory control by a multi-period and multi-echelon approach for safety stock planning in general, acyclic networks. On the real-world networks from Willems (2008), we find that incorporating feature information when setting safety stocks in large supply chains, on average, reduces operational costs out-of-sample. This value of feature information that the proposed model offers to decision-makers increases in demand volatility and is dependent on certain network characteristics.},
  archive      = {J_EJOR},
  author       = {Josef Svoboda and Stefan Minner},
  doi          = {10.1016/j.ejor.2025.06.022},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {446-459},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven approach for strategic inventory placement in multi-echelon supply networks},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimizing the maximum flow loss in the network maintenance scheduling problem with flexible arc outages. <em>EJOR</em>, <em>328</em>(2), 430-445. (<a href='https://doi.org/10.1016/j.ejor.2025.07.056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a network maintenance scheduling problem where maintenance tasks are carried out on the arcs of a network within flexible time windows. During maintenance, an arc is interrupted and no flow can pass through it. Such arc outages introduce flow loss and thus affect network capacity and service capability. For some public services operated on networks, possible blackouts and serious flow loss introducing extreme risks are generally unacceptable. The problem is to find a feasible schedule of maintenance tasks so that the maximum flow loss during the planning horizon is minimized. We introduce a mixed integer programming formulation and a Benders reformulation for the problem. A Benders decomposition algorithm based on a branch-and-cut framework is designed. Strengthened initial cuts and effective cuts are introduced to reduce feasible region so that the exact algorithm is accelerated. An efficient separation procedure is proposed to generate Benders optimality cuts. Computational experiments were conducted on a set of benchmark instances and a set of simulated instances based on telecommunication networks. Computational results show that our algorithm performs much better than applying a solver to the formulation and an existing Benders decomposition algorithm for a related problem. Optimal schedules can reduce extreme risks caused by large flow loss on the network. Since multiple optimal solutions may exist, hierarchical optimization is used to further select a desirable schedule, by either minimizing total flow loss or minimizing the duration of maximum flow loss. With adaptations, our algorithm also performs well for two extensions.},
  archive      = {J_EJOR},
  author       = {Shuang Jin and Ying Liu and Jing Zhou and Qian Hu},
  doi          = {10.1016/j.ejor.2025.07.056},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {430-445},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing the maximum flow loss in the network maintenance scheduling problem with flexible arc outages},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic quay partitioning problem. <em>EJOR</em>, <em>328</em>(2), 415-429. (<a href='https://doi.org/10.1016/j.ejor.2025.07.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of dividing a quay of a container terminal into berth segments so that the quality of service for future ship arrivals is as good as possible. Since future arrivals are unknown, the alternative solutions are evaluated on various arrival scenarios generated for certain arrival intensity from a stochastic model referred to as a ship traffic model (STM). This problem will be referred to as a stochastic quay partitioning problem (SQPP). SQPP is defined by an STM, arrival intensity, quay length and a set of admissible berth lengths. Evaluation of an SQPP solution on one scenario is a problem of scheduling the arriving vessels on the berths, which is a classic berth allocation problem (BAP). In SQPP the sizes of BAP instances that must be solved by far exceed capabilities of the methods presented in the existing literature. Therefore, a novel approach to solving BAP is applied. Tailored portfolios of algorithms capable of solving very large BAP instances under limited runtime are used. Features of SQPP solutions are studied experimentally: patterns in selected berth lengths, dispersion of solutions quality and solutions similarity. We demonstrate, that partitioning a quay into equal-length berths is not the best approach. The largest vessel traffic is dominating in defining best quay partitions, but dedicating quays for shorter vessels give lower dispersion of solution quality. A set of algorithms to partition a quay is proposed and evaluated: methods based on integer linear programming (ILP) to match vessel classes arrival intensities with berth availability, hill climber, tabu search and a greedy approach. Only under high arrival intensity can these methods show their prowess. ILP methods have an advantage of low solution evaluation cost. Tabu is most flexible, but at high evaluation costs. To the best of our knowledge, SQPP is posed and solved for the first time in the operations research.},
  archive      = {J_EJOR},
  author       = {Jakub Wawrzyniak and Maciej Drozdowski and Éric Sanlaville},
  doi          = {10.1016/j.ejor.2025.07.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {415-429},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic quay partitioning problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scheduling mixed batch machines with inclusive processing set restrictions and non-identical capacities. <em>EJOR</em>, <em>328</em>(2), 407-414. (<a href='https://doi.org/10.1016/j.ejor.2025.07.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new batch scheduling problem, name mixed batch scheduling problem, is received attentions recently. In a mixed batch scheduling model, the processing time of a job batch H is defined as α max j ∈ H { p j } + ( 1 − α ) ∑ j ∈ H p j , where α ∈ [ 0 , 1 ] is a constant. In other words, the processing time of a job batch is the weighted sum of the maximum processing time and the total processing time of jobs in the batch. In this paper, we study the problem of scheduling mixed batch machines with non-identical capacities under inclusive processing set restrictions, where the objective is to minimize the makespan of finishing all the jobs. We present a fast approximation algorithm with a performance ratio of 4 / 3 + α for the problem, which improves up the existing performance bounds in the literature. By providing a technical lemma, we are able to develop the first polynomial time approximation scheme (PTAS) for the problem. We also design linear-time approximation schemes for two important special cases of the problem.},
  archive      = {J_EJOR},
  author       = {Jinwen Ou and Weidong Li},
  doi          = {10.1016/j.ejor.2025.07.012},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {407-414},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling mixed batch machines with inclusive processing set restrictions and non-identical capacities},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A matheuristic approach for the robust coloured travelling salesman problem with multiple depots. <em>EJOR</em>, <em>328</em>(2), 390-406. (<a href='https://doi.org/10.1016/j.ejor.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a special type of the travelling salesman problem (TSP) called the coloured TSP (CTSP) is considered. The CTSP, which has many real-world applications, involves a set of salesmen, each assigned a specific colour, and cities that may have one or multiple colours. Salesmen are restricted to visiting only cities that share their colour. We consider a specific depot for each salesman, and the edge weights are uncertain, meaning that there is a set of possible scenarios for their values. A robust objective is considered and minimised using an artificial intelligence (AI)-driven matheuristic approach due to the high computational complexity of the problem. This approach integrates a variable neighbourhood search (VNS) framework with genetic algorithm (GA) and simulated annealing (SA) operators. More importantly, local improvements based on mathematical programming are applied to different parts of a proportion of the solutions using the concept of partial optimisation metaheuristic under special intensification conditions (POPMUSIC). A key innovation of our method is the use of an artificial neural network to guide the POPMUSIC procedure by selecting only solution segments with high improvement potential, thereby reducing computation time. Extensive computational experiments demonstrate the effectiveness of the proposed algorithm, which outperforms four state-of-the-art methods in solution quality and runs faster than three of them. We also investigate the contribution of individual algorithmic components and the cost of robustness. Furthermore, our method improves upon the best-known results for the single-depot deterministic version of the CTSP from the literature.},
  archive      = {J_EJOR},
  author       = {Abtin Nourmohammadzadeh and Stefan Voß},
  doi          = {10.1016/j.ejor.2025.06.018},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {390-406},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic approach for the robust coloured travelling salesman problem with multiple depots},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fifty years of research on resource-constrained project scheduling explored from different perspectives. <em>EJOR</em>, <em>328</em>(2), 367-389. (<a href='https://doi.org/10.1016/j.ejor.2025.03.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-constrained project scheduling problem is one of the most investigated problems in the project scheduling literature, and has a rich history. This article provides a perspective on this challenging scheduling problem, without having the ambition to provide a complete overview. Instead, the article does aim to summarize a number of reasons why this problem has been so intensely investigated from different perspectives. It will be shown that this scheduling problem has many faces, and therefore deserves a lot of research time from a computational and theoretical point of view as well as from a practical point of view. An overview of possible extensions to other problems and a detailed overview of the used (both heuristic and exact) solution methods will be given. In addition, the data used will be discussed and interesting avenues for further research will be mentioned throughout the different sections.},
  archive      = {J_EJOR},
  author       = {Christian Artigues and Sönke Hartmann and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2025.03.024},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {367-389},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of research on resource-constrained project scheduling explored from different perspectives},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic mode decomposition for online portfolio selection task. <em>EJOR</em>, <em>328</em>(1), 349-365. (<a href='https://doi.org/10.1016/j.ejor.2025.04.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online portfolio selection (OPS) is a complex task aimed at maximizing investment returns through strategic allocation of capital among risky assets. Traditional Follow the Winner (FTW) strategies, grounded in the Best Constant Rebalanced Portfolios strategy, assume market is independent and identically distributed (i.i.d.), which often fails to capture real-world financial market dynamics, leading to sub-optimal performance in practical applications. To address this limitation, we propose integrating Dynamic Mode Decomposition (DMD) into FTW strategies. DMD is a powerful data-driven technique that originated in the field of fluid dynamics. It is designed to extract coherent structures and identify temporal patterns within complex data. By applying DMD to financial market data, we can uncover underlying patterns and trends that are not apparent under the i.i.d. assumption. Significantly, the integrated DMD in this paper allows for efficient recursion, which is particularly crucial for OPS task. To illustrate the effectiveness of the proposed idea, we consider the Exponential Gradient (EG) strategy as an example and proposed Exponential Gradient with Dynamic Mode Decomposition (EGDMD). The results demonstrate that the proposed EGDMD outperforms traditional EG-type strategies, significantly improves risk-adjusted returns, and maintains computational efficiency. The integration of DMD allows for more accurate identification of market patterns, leading to more effective investment decisions and enhanced portfolio performance.},
  archive      = {J_EJOR},
  author       = {Jiahao Li and Yong Zhang and Xiaoteng Zheng},
  doi          = {10.1016/j.ejor.2025.04.049},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {349-365},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic mode decomposition for online portfolio selection task},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Choice-based crowdshipping for next-day delivery services: A dynamic task display problem. <em>EJOR</em>, <em>328</em>(1), 336-348. (<a href='https://doi.org/10.1016/j.ejor.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies integrating the crowd workforce into next-day home delivery services. In this setting, both crowd drivers and contract drivers collaborate in making deliveries. Crowd drivers have limited capacity and can choose not to deliver if the presented tasks do not align with their preferences. The central question addressed is: How can the platform minimize the total task fulfilment cost, which includes payouts to crowd drivers and additional payouts to contract drivers for delivering the unselected tasks by customizing task displays to crowd drivers? To tackle this problem, we formulate it as a finite-horizon Stochastic Decision Problem, capturing crowd drivers’ utility-driven task preferences, with the option of not choosing a task based on the displayed options. An inherent challenge is approximating the non-constant marginal cost of serving orders not chosen by crowd drivers, which are then assigned to contract drivers. We address this by leveraging a common approximation technique, dividing the service region into zones. Furthermore, we devise a stochastic look-ahead strategy that tackles the curse of dimensionality issues arising in dynamic task display execution and a non-linear (problem specifically concave) boundary condition associated with the cost of hiring contract drivers. In experiments inspired by Singapore’s geography, we demonstrate that choice-based crowd shipping can reduce next-day delivery fulfilment costs by up to 16.9%. The observed cost savings are closely tied to the task display policies and the task choice behaviours of drivers.},
  archive      = {J_EJOR},
  author       = {Alp Arslan and Fırat Kılcı and Shih-Fen Cheng and Archan Misra},
  doi          = {10.1016/j.ejor.2025.05.046},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {336-348},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Choice-based crowdshipping for next-day delivery services: A dynamic task display problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy. <em>EJOR</em>, <em>328</em>(1), 324-335. (<a href='https://doi.org/10.1016/j.ejor.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metafrontier analysis is widely used to account for technological heterogeneity among producers. The approach involves combining a number of group-specific production possibilities sets to form a production possibilities metaset. Even though the union of the group sets normally results in a nonconvex metaset, most authors proceed as if this metaset is convex. Kerstens, O’Donnell and Van de Woestyne (2019) obtain new results on the union operator on sets under various assumptions and empirically illustrate that the popular convexification strategy is highly questionable. In this paper we transpose their results on the union operator from a production to a cost context: this is new. We then explore the extent to which convexity of the cost function is corroborated using a newly developed test. Furthermore, we check to which extent a convexification strategy is tenable when estimating a cost metafrontier. We use an original banking data set from China and the USA to illustrate the main issues. We establish that the cost function is not convex in the outputs for China and that the convexification strategy leads to potentially-biased estimates of the cost metafrontier and associated measures of efficiency.},
  archive      = {J_EJOR},
  author       = {Kristiaan Kerstens and Christopher O’Donnell and Ignace Van de Woestyne and Shirong Zhao},
  doi          = {10.1016/j.ejor.2025.05.048},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {324-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating adversarial attacks on transformer models in credit scoring. <em>EJOR</em>, <em>328</em>(1), 309-323. (<a href='https://doi.org/10.1016/j.ejor.2025.05.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of unstructured data, such as text created by borrowers, offers new opportunities for improving credit default prediction but also introduces new risks. This study examines the robustness of transformer-based credit scoring models that utilize textual data and assesses their vulnerability to adversarial attacks. Using peer-to-peer lending data, we show that small, semantically neutral changes in loan descriptions can substantially alter model outputs. These vulnerabilities expose lenders and borrowers to economic risks through distorted risk assessments and mispriced loans. We evaluate two mitigation strategies: adversarial training and topic modeling. Adversarial training improves robustness without compromising predictive performance. Topic modeling provides a more interpretable and stable representation of borrower narratives. An economic analysis confirms that robust models reduce mispricing and improve outcomes for all parties. The findings underscore the importance of robustness as the use of unstructured data in credit scoring becomes more accessible.},
  archive      = {J_EJOR},
  author       = {Brandon Schwab and Johannes Kriebel},
  doi          = {10.1016/j.ejor.2025.05.029},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {309-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mitigating adversarial attacks on transformer models in credit scoring},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cost-sensitive single-index classification model. <em>EJOR</em>, <em>328</em>(1), 295-308. (<a href='https://doi.org/10.1016/j.ejor.2025.08.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-index models (SIMs) are a type of semiparametric model in which a response variable is assumed to be related to a linear combination of explanatory variables by an unknown function, on which any restriction is imposed. Thus, they provide both interpretability and flexibility to capture complex data relationships. In this paper, SIMs are extended to the cost-sensitive classification problem by minimizing the different misclassification costs. The flexibility of SIMs combined with a cost-sensitive approach results in a powerful model to minimize losses and optimize decision making. This is demonstrated through an extensive simulation study and the analysis of five real data sets, where the proposed approach outperforms both parametric and semi-parametric previous approaches.},
  archive      = {J_EJOR},
  author       = {Jorge C-Rella and Ricardo Cao and Juan M. Vilar},
  doi          = {10.1016/j.ejor.2025.08.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {295-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost-sensitive single-index classification model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diverse ensemble cost-sensitive logistic regression. <em>EJOR</em>, <em>328</em>(1), 282-294. (<a href='https://doi.org/10.1016/j.ejor.2025.07.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cost-sensitive methods have become increasingly crucial for decision-making in various real-world applications. These methods have been developed for the purpose of minimizing costs or risks for stakeholders. Moreover, the interpretability of cost-sensitive methods has gained considerable attention in critical domains such as finance and medical care. In this article, we propose a diverse ensemble of cost-sensitive logistic regression models to reduce costs for binary classification tasks, as well as a novel algorithm based on the partial conservative convex separable quadratic approximation to solve this non-convex optimization problem. The proposed method demonstrates substantial cost savings through extensive simulations and real-world applications, including fraud detection and gene expression analysis. Additionally, unlike other ensembling techniques, the resulting model of the proposed method is fully interpretable as a logistic regression model and achieves a high level of sparsity induced by the proposed algorithm. We believe this approach offers deeper insights into the relationship between predictors and response, enabling more informed decision-making in practical scenarios.},
  archive      = {J_EJOR},
  author       = {Bing Yang and Stefan Van Aelst and Tim Verdonck},
  doi          = {10.1016/j.ejor.2025.07.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {282-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Diverse ensemble cost-sensitive logistic regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view ensemble feature selection via SemiDefinite programming. <em>EJOR</em>, <em>328</em>(1), 269-281. (<a href='https://doi.org/10.1016/j.ejor.2025.07.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning faces significant challenges in selecting discriminative features while managing redundancy and noise across heterogeneous data sources. To address these issues, this paper introduces Multi-view Ensemble Feature Selection (MEFS), a novel framework that systematically integrates view generation (VG) and view selection (VS) through a unified optimization paradigm. By reformulating feature selection as a MaxCut problem and leveraging SemiDefinite Programming (SDP) relaxation, MEFS dynamically balances the generalization capability of individual views with their pairwise diversity, eliminating the need for manual parameter tuning. A key innovation is the proposed pairwise diversity metric, which quantifies inter-view dissimilarity using between-class scatter matrices to ensure complementary feature subsets. Extensive experiments on ten benchmark datasets demonstrate that MEFS consistently outperforms state-of-the-art methods in accuracy, robustness, and computational efficiency. Ablation studies validate the synergistic effect of combining VG and VS modules.},
  archive      = {J_EJOR},
  author       = {Xiaojian Ding and Xin Wang and Pengcheng Shi},
  doi          = {10.1016/j.ejor.2025.07.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {269-281},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-view ensemble feature selection via SemiDefinite programming},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the price of diversity for multiwinner elections under (weakly) separable scoring rules. <em>EJOR</em>, <em>328</em>(1), 258-268. (<a href='https://doi.org/10.1016/j.ejor.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a model of multi-winner elections, where each voter expresses a linear preference over a finite set of alternatives. Based on voters’ preferences, the primary goal is to select a subset of admissible alternatives, forming what is referred to as a committee. We explore (weakly) separable committee scoring rules, the voting mechanisms that assess each alternative individually using a scoring vector and select the top k alternatives, where k represents the committee’s size. Furthermore, we operate under the assumption that alternatives are categorized based on specific attributes. Within each attribute category, there exists a targeted minimum number of alternatives that the selected committee should encompass, emphasizing the necessity for diversity. In this context, we assess the cost associated with imposing such a diversity constraint on the voting process. This assessment is conducted through two methodologies, referred to as the “price of diversity” and the “individual price of diversity”. We set the upper bounds for both prices across all (weakly) separable committee scoring rules. Additionally, we show how the maximum price of diversity can be used to discriminate between different voting rules in this context. Ultimately, we illustrate that concentrating on the candidates’ performance yields a more accurate estimation of the price of diversity compared to a focus on the enforced diversity constraint.},
  archive      = {J_EJOR},
  author       = {Mostapha Diss and Clinton Gubong Gassi and Eric Kamwa},
  doi          = {10.1016/j.ejor.2025.06.013},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {258-268},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the price of diversity for multiwinner elections under (weakly) separable scoring rules},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonconvex truncated conditional value at risk-based sparse linear regression. <em>EJOR</em>, <em>328</em>(1), 246-257. (<a href='https://doi.org/10.1016/j.ejor.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional value at risk (CVaR) is a widely recognized risk measure used to manage data uncertainty within risk management. In this paper, we study a class of sparse linear regression models based on truncated CVaR measure and ℓ 0 -norm regularization. Due to the nonconvexity and nonsmoothness of the objective functions, as well as the NP-hardness of the problem with the ℓ 0 -norm regularization, we propose an approximation model that employs a tight relaxation of the ℓ 0 -norm. The solution equivalence between the proposed model and its approximation model is explored. To efficiently solve the approximation model, we develop a semismooth Newton-based proximal majorization-minimization algorithm. Furthermore, the convergence analysis of the proposed algorithm is presented, and the convergence rate for the reduced CVaR-based sparse linear regression model is established. Moreover, extensive numerical experiments conducted on both synthetic and real datasets validate the stability and effectiveness of the proposed algorithm, demonstrating significant improvements in both sparsity and accuracy compared to existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Boyi Xie and Zhongming Wu and Min Li},
  doi          = {10.1016/j.ejor.2025.06.004},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {246-257},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonconvex truncated conditional value at risk-based sparse linear regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Designing and computing explanations for comparisons inferred from an additive value model. <em>EJOR</em>, <em>328</em>(1), 232-245. (<a href='https://doi.org/10.1016/j.ejor.2025.05.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many decision models are based on an additive representation of preferences. Recommendations obtained from such additive decision models are sometimes considered as self-evident. On the contrary, we claim that these recommendations deserve an explanation so as to be fully understood by the user/decision-maker and to foster her trust. We propose to explain a preference statement x preferred to y by decomposing this statement into simpler ones. Arguments in favor of x (Pros), and arguments in favor of y (Cons) are decomposed using a covering scheme in which each Con is covered by a Pro. We use a decomposition language in which elementary self-evident statements involve ( i ) one Pro against one Con, ( ii ) one pro against several Cons, or ( iii ) several Pros against one Con. We prove that computing such explanations is computationally difficult in case ( ii ) and ( iii ), and propose a mathematical programming formulation to solve it. Numerical experiments provide insights on the actual behavior of our algorithm. We also illustrate the usefulness of our approach in the context of multicriteria decision aid but also for machine learning approaches.},
  archive      = {J_EJOR},
  author       = {Manuel Amoussou and Khaled Belahcene and Nicolas Maudet and Vincent Mousseau and Wassila Ouerdane},
  doi          = {10.1016/j.ejor.2025.05.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {232-245},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing and computing explanations for comparisons inferred from an additive value model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bayesian variable selection in kriging metamodeling for quality design. <em>EJOR</em>, <em>328</em>(1), 216-231. (<a href='https://doi.org/10.1016/j.ejor.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of production processes and rapid developments in digital technology have fueled the adoption of metamodels in quality design. Kriging has emerged as one of the most popular emulation methods for both deterministic and stochastic simulations. Conventional Kriging models with predetermined mean functions, such as ordinary or universal Kriging, may exhibit subpar predictive performance when strong trends exist. This paper proposes a novel variable selection procedure for the mean function that ensures prediction accuracy while using only a limited number of variables to capture the potential existing trends in deterministic simulations. The proposed method integrates the benefits of Bayesian variable selection and frequentist statistical tests. Initially, a group of potential models is chosen to build the mean function, employing the Bayesian method with priors designed to guarantee sparsity. This results in a significant reduction in the number of models to be considered in the next stage. Subsequently, each candidate model undergoes rigorous frequentist tests to thoroughly assess its reliability and validity. Extensive simulation studies are conducted using the well-known Borehole function and a real-life case. The results demonstrate the superiority of the proposed method over several existing approaches, establishing its effectiveness in achieving robust parameter design.},
  archive      = {J_EJOR},
  author       = {Baoping Tao and Zifei Han and Wen Shi and Min Wang and Linhan Ouyang},
  doi          = {10.1016/j.ejor.2025.06.003},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {216-231},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bayesian variable selection in kriging metamodeling for quality design},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design and pricing of extended warranty menus with reference effects. <em>EJOR</em>, <em>328</em>(1), 201-215. (<a href='https://doi.org/10.1016/j.ejor.2025.05.056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer durables increasingly come with extended warranty menus—beyond manufacturers’ base warranties—that offer multiple options with differentiated protection lengths and prices. When choosing from an extended warranty menu, consumers might not only evaluate the intrinsic utility of each option but also form a reference point against which the available options are compared. In this paper, we posit that consumers compare the price-length ratios of available options when determining their willingness to pay, and investigate the design and pricing of extended warranty menus under such reference effects. To this end, we adapt the standard multinomial logit choice model to incorporate two types of reference point that are generated endogenously and exogenously, respectively, with respect to the given menu. We show that if the warranty options are ordered in the protection length, then the optimal pricing policies prescribe the same adjusted markup and the same price-length ratio alternately. We further extend our analysis to price competition under reference effects, where multiple firms compete in the aftermarket, each offering a single extended warranty. We prove the existence of a unique Nash equilibrium and develop an efficient method to identify it. Numerical examples are presented to illustrate the analytical findings, and sensitivity analyses are conducted to examine the impact of reference-effect coefficients on the optimal pricing policies. Overall, this work highlights the importance of incorporating reference effects into the design and pricing of extended warranty menus.},
  archive      = {J_EJOR},
  author       = {Xiao-Lin Wang and Chenglong Li and Junjie Wang},
  doi          = {10.1016/j.ejor.2025.05.056},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {201-215},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Design and pricing of extended warranty menus with reference effects},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning bayesian reliability demonstration tests via a generalized test statistic. <em>EJOR</em>, <em>328</em>(1), 189-200. (<a href='https://doi.org/10.1016/j.ejor.2025.08.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability demonstration testing (RDT) has been extensively employed to verify whether a product meets specific reliability requirements at a desired confidence level. Driven by intense market competition and constrained test resources, manufacturers are motivated to seek effective strategies to reduce the testing efforts required for RDT. In this paper, we propose a method that utilizes existing knowledge and information obtained from the product design and development phase to construct a Bayesian prior distribution of the product’s reliability. Based on this prior, a preliminary disposition decision on whether to accept or reject the product is made. A subsequent demonstration test is needed only when the prior information is deemed insufficient for an immediate disposition. A RDT planning method is developed based on the posterior distribution of the product’s reliability, which is applicable to general cases involving non-conjugate priors. We study two types of demonstration testing: binomial and exponential. For each, we prove the existence of an optimal test plan and develop an efficient searching algorithm to determine it. Numerical studies are conducted to demonstrate the effectiveness of the proposed method, supplemented by a case study on RDT for systems of different configurations. Overall, this work provides a unified and effective framework for reliability demonstration under the Bayesian paradigm.},
  archive      = {J_EJOR},
  author       = {Zan Li and Jianyu Xu and Chengjie Wang and Xiao-Lin Wang},
  doi          = {10.1016/j.ejor.2025.08.011},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {189-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning bayesian reliability demonstration tests via a generalized test statistic},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A primal–dual policy iteration algorithm for constrained markov decision processes. <em>EJOR</em>, <em>328</em>(1), 174-188. (<a href='https://doi.org/10.1016/j.ejor.2025.08.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution algorithms of Constrained Markov Decision Process (CMDP), a widely adopted model for sequential decision-making, have been intensively studied in the literature. Despite increasing effort, the Linear Programming (LP) formulation of CMDP remains the dominant exact method that leads to the optimal solution without constraint violations. However, the LP formulation is computationally inefficient due to the curse of dimensionality in CMDP state and action spaces. In this study, we introduce a novel policy iteration method for CMDP, based on decomposition and row-generation techniques. We design a Primal–Dual Policy Iteration (PDPI) algorithm that utilizes state values and Lagrangian multipliers to improve randomized stationary policies in an iterative fashion. We analytically show that upon convergence, PDPI produces the optimal solution for CMDP. An upper bound of the convergence iterations is also given. To validate the algorithm performance, we conduct comprehensive computational experiments on six benchmarking problems curated from the literature. Results show that PDPI outperforms conventional methods considerably, improving the total algorithm runtime by up to 89.19%. The improvement becomes more significant as the problem size grows larger. We further provide insights and discuss the impact of the developed method.},
  archive      = {J_EJOR},
  author       = {Zeyu Liu and Xueping Li and Anahita Khojandi},
  doi          = {10.1016/j.ejor.2025.08.038},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {174-188},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A primal–dual policy iteration algorithm for constrained markov decision processes},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controlling antithetic variates. <em>EJOR</em>, <em>328</em>(1), 162-173. (<a href='https://doi.org/10.1016/j.ejor.2025.08.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish and investigate a theoretical framework for controlling covariance matrices in the method of antithetic variates through control variates to further reduce estimator variance. Instead of preemptively and carefully designing an estimator vector with negatively correlated components, the proposed framework starts with a predefined estimator vector that incorporates specified control variates. The weights and control matrix are then analytically determined through matrix algebra. The joint optimality of the resulting estimator variance is ensured with respect to both the weights and the control matrix, with closed-form implementable formulas derived for the optimal parameter pair. Numerical results are provided for various typical examples to illustrate the effectiveness, potential, and challenges of the proposed framework.},
  archive      = {J_EJOR},
  author       = {Reiichiro Kawai},
  doi          = {10.1016/j.ejor.2025.08.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {162-173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Controlling antithetic variates},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust multi-period blood inventory routing under multiple uncertainties. <em>EJOR</em>, <em>328</em>(1), 137-161. (<a href='https://doi.org/10.1016/j.ejor.2025.05.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a multi-period blood inventory routing problem that integrates production, inventory, and distribution decisions under uncertainties in demand, donation supply, and travel times, all while accounting for the limited shelf life of blood products. Our model captures transportation efficiency through a disutility measure based on vehicles’ arrival times at hospitals, and addresses supply–demand imbalances by allowing selective rejection of service requests at a high penalty cost. We formulate a robust optimization model that simultaneously determines production quantities, inventory levels, hospital service selections, and vehicle routing for each period. The objective is to minimize the total cost over the planning horizon, which includes worst-case inventory holding, wastage, and transportation costs, unserved demand penalties, and overall transportation disutility. To obtain an exact solution, we propose an integrated algorithm within the L -shaped framework that combines Benders decomposition with a branch-and-price-and-cut (BPC) scheme. This approach decomposes the robust model into a master problem and period-specific subproblems. For a given master solution, we first use constraint programming to verify the feasibility of the subproblems, and then, if feasible, solve them with a tailored BPC algorithm to generate Benders cuts that eliminate suboptimal master solutions. Extensive numerical experiments, including a case study at the Blood Center in Chongqing, demonstrate the effectiveness of our approach. Our analysis quantifies the benefits of incorporating uncertainty and robustness while providing managerial insights through a systematic evaluation of various parameters.},
  archive      = {J_EJOR},
  author       = {Ling Qing and Yunqiang Yin and Joshua Ignatius and Dujuan Wang},
  doi          = {10.1016/j.ejor.2025.05.036},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {137-161},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multi-period blood inventory routing under multiple uncertainties},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach. <em>EJOR</em>, <em>328</em>(1), 122-136. (<a href='https://doi.org/10.1016/j.ejor.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the joint optimization of condition-based maintenance and spare provisioning, incorporating insights obtained from sensor data. Prognostic models estimate components’ remaining lifetime distributions (RLDs), which are integrated into an optimization model to coordinate maintenance and spare provisioning. The existing literature addressing this problem assumes that prognostic models provide accurate estimates of RLDs, thereby allowing a direct adoption of Stochastic Programming or Markov Decision Process methodologies. Nevertheless, this assumption often does not hold in practice since the estimated distributions can be inaccurate due to noisy sensors or scarcity of training data. To tackle this issue, we develop a Distributionally Robust Chance Constrained (DRCC) formulation considering general discrepancy-based ambiguity sets that capture potential distribution perturbations of the estimated RLDs. The proposed formulation admits a Mixed-Integer Linear Programming (MILP) reformulation, where explicit formulas are provided to simplify the general discrepancy-based ambiguity sets. Finally, for the numerical illustration, we test a type- ∞ Wasserstein ambiguity set and derive closed-form expressions for the parameters of the MILP reformulation. The efficacy of our methodology is showcased in a wind turbine case study, where the proposed DRCC formulation outperforms other benchmarks based on stochastic programming and robust optimization.},
  archive      = {J_EJOR},
  author       = {Heraldo Rozas and Weijun Xie and Nagi Gebraeel and Stephen Robinson},
  doi          = {10.1016/j.ejor.2025.06.025},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {122-136},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy. <em>EJOR</em>, <em>328</em>(1), 105-121. (<a href='https://doi.org/10.1016/j.ejor.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing emphasis on environmental sustainability, both governments and consumers are more concerned than ever about the greenness of products. In this complex landscape, Supply Chains (SCs) face challenges in building trust and avoiding greenwashing accusations. Blockchain technology offers a promising solution by ensuring transparency and circularity within SCs, particularly in identifying customers for product recycling. This study pioneers the exploration of consumers' distrust in pricing and product greenness, alongside the impact of carbon policies (taxes and subsidies) within a closed-loop supply chain (CLSC). Using classical Stackelberg game theory, we develop two models that identify equilibrium decisions for SC members, focusing on pricing, green production investment, circularity, and blockchain adoption. Additionally, we propose an evolutionary game theory model to find the optimal government policies and identify the long-term behaviour of the CLSC and government in two heterogeneous populations. Our findings reveal that if the retailer's share of blockchain costs falls below a certain threshold, blockchain adoption becomes less profitable than exclusive investment in green production. A higher (lower) subsidy rate benefits (harms) the retailer but disadvantages (benefits) the collector. Blockchain adoption is generally more profitable for manufacturers and retailers, though less so for collectors, and it also drives greater investment in green production. While subsidies encourage blockchain adoption, they are not a sustainable long-term strategy for governments. Ultimately, the evolutionarily stable strategy for SCs involves a balanced investment in both green production and blockchain or green production alone, depending on market characteristics and cost-sharing structures.},
  archive      = {J_EJOR},
  author       = {Mohammad Akbarzadeh Sarabi and Ata Allah Taleizadeh and Arijit Bhattacharya},
  doi          = {10.1016/j.ejor.2025.06.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {105-121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size. <em>EJOR</em>, <em>328</em>(1), 91-104. (<a href='https://doi.org/10.1016/j.ejor.2025.05.044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling transportation and inventory management simultaneously is a challenging problem. The most famous optimization problem in this domain, known as the Inventory Routing Problem (IRP), aims to determine the routes and quantities to be delivered by a set of vehicles to meet customer demands at a minimum total inventory and transportation cost. The vast majority of works carried out so far on the IRP consider a homogeneous fleet of vehicles. This paper addresses, instead, a new IRP variant that considers intrinsic characteristics of real supply chains, such as a period-dependent heterogeneous fleet of vehicles and batch sizes for the delivered quantities. We model the problem with a Mixed Integer Linear Programming (MILP) formulation and propose a Split-Embedded Metaheuristic with a Post-Optimization phase (SEMPO) to solve it. Extensive computational experiments are conducted on a set of 80 new benchmark instances with up to 183 customers and a challenging time horizon of up 7 to 28 time periods to evaluate the performance of our approaches. The proposed SEMPO algorithm provides high-quality solutions and faster convergence compared to the MILP formulation.},
  archive      = {J_EJOR},
  author       = {Diego Perdigão Martino and Philippe Lacomme and Katyanne Farias},
  doi          = {10.1016/j.ejor.2025.05.044},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {91-104},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The role of scarcity behavior in inventory management. <em>EJOR</em>, <em>328</em>(1), 78-90. (<a href='https://doi.org/10.1016/j.ejor.2025.05.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known phenomenon related to inventory, but often neglected in inventory management, is the scarcity effect, i.e., the increase in the demand if inventory is low. We consider a repeated purchase setting with a single firm and multiple buyers and address the question of whether inventory management decisions concerning the control policy and the service configuration (determining when and how much to order) impact scarcity behavior arising from buyers’ stock-out perception. We study common inventory control policies that assume a demand independent of the inventory management, and we challenge this critical assumption of an exogenous demand. This research explores two prevalent classes of inventory policies widely used in practice (periodic and continuous) configured according to fill rates, a popular way of measuring service. We conduct a laboratory experiment with four automated inventory management treatments (2 policies × 2 configurations) where participants act as buyers. We observe stock-out induced scarcity and find support for the hypothesis that the periodic policy leads to a stronger effect compared to the continuous policy if the service level is low. The study also supports the hypothesis that buyers act forward-looking as their demand peaks before the inventory reaches its lowest level. Overall, our research provides a new perspective on inventory management as it reveals that the chosen control policy and the selected service configuration influence stock-out pressure induced inventory runs. Inventory managers should be aware of scarcity effects and its consequences, like the disadvantages of a periodic policy for low service level.},
  archive      = {J_EJOR},
  author       = {Sebastian Schiffels and Christian Jost},
  doi          = {10.1016/j.ejor.2025.05.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {78-90},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The role of scarcity behavior in inventory management},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies. <em>EJOR</em>, <em>328</em>(1), 64-77. (<a href='https://doi.org/10.1016/j.ejor.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-bound algorithm, enhanced with bin packing strategies, for scheduling under variable energy pricing and power-saving states. The proposed algorithm addresses the 1 , TOU | states | TEC problem, which involves scheduling jobs to minimize total energy cost (TEC) while considering time-of-use (TOU) electricity prices and different machine states (e.g., processing, idle, off). Key innovations include instance pre-processing for rapid lower bound calculations, a novel branching scheme combined with initializations, a block-finding primal heuristic, and a tighter lower bound for jobs with non-coprime processing times. These enhancements result in an efficient algorithm capable of solving benchmark instances with real energy prices with 200 jobs more than 100 times faster than existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Ondřej Benedikt and István Módos and Antonin Novak and Zdeněk Hanzálek},
  doi          = {10.1016/j.ejor.2025.06.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {64-77},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flight test scheduling: A generic model, lower bounds, and iterated local search. <em>EJOR</em>, <em>328</em>(1), 49-63. (<a href='https://doi.org/10.1016/j.ejor.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight tests play a critical role in the R&D process for new aircraft as they help verify the airworthiness and capabilities and expose design and manufacturing defects. During the test course, a large number of tasks need to be scheduled appropriately so that the flight tests can be completed with minimum cost and high efficiency. Therefore, there is a strong need for developing an efficient method that can generate high-quality test schedules. In this paper, we study flight test scheduling to minimize the number of required test flights, thereby decreasing the cost and time required during the entire test course. We establish a mixed-integer programming model to formally describe the problem, propose several computationally efficient lower bounds to help verify the quality of obtained solutions, and develop an iterated local search algorithm for generating a high-quality solution in an effective manner. Comprehensive computational experiments are performed to demonstrate the efficiency of our proposed algorithm. We report some general managerial insights based on the obtained computational results.},
  archive      = {J_EJOR},
  author       = {Hanqiao Tao and Guopeng Song and Roel Leus and Zhe Liang and Jiang Jiang},
  doi          = {10.1016/j.ejor.2025.06.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {49-63},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flight test scheduling: A generic model, lower bounds, and iterated local search},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nested logic-based benders decomposition for an integrated home healthcare problem. <em>EJOR</em>, <em>328</em>(1), 32-48. (<a href='https://doi.org/10.1016/j.ejor.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we apply nested logic-based Benders decomposition to solve an integrated home healthcare staffing, assignment, routing, and scheduling problem with application in Norway. The proposed method operates at two decomposition levels. Consequently, the entire problem is decomposed into three hierarchical sub-problems: the staffing problem, the assignment problem, and the routing and scheduling problem. These sub-problems are interrelated through two levels of logic-based Benders cuts. Computational experiments on 40 test instances demonstrate the superior performance of nested logic-based Benders decomposition compared to directly solving a mixed-integer linear programming model available in the literature. Specifically, the proposed solution method achieved proven optimality in 28 instances and provided feasible solutions for the remaining 12 instances. In contrast, directly solving the mixed-integer linear programming model yielded proven optimality in 16 instances, provided feasible solutions for 20 instances, and failed to find feasible solutions for 4 instances within the same computational time limit.},
  archive      = {J_EJOR},
  author       = {Abdalrahman Algendi and Sebastián Urrutia and Lars Magnus Hvattum and Rafael A. Melo},
  doi          = {10.1016/j.ejor.2025.06.006},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {32-48},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested logic-based benders decomposition for an integrated home healthcare problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations. <em>EJOR</em>, <em>328</em>(1), 15-31. (<a href='https://doi.org/10.1016/j.ejor.2025.05.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the non-preemptive identical parallel machine scheduling problem with a dedicated loading server and a dedicated unloading server. Each job has to be loaded by the dedicated loading server immediately before being processed on one of the identical parallel machines, and unloaded immediately by the dedicated unloading server after its processing. The objective function involves the minimization of the makespan. This problem arises in the semiconductor industry, plastic injection industry, kitchen production systems, healthcare, container terminals, and many other industrial fields. We prove the problem to be strongly NP-hard, analyze a special case with identical loading, processing, and unloading times, and establish a tight lower bound. In addition, we propose two novel mixed-integer linear programming formulations: one utilizing time-indexed variables with an iterative strengthening algorithm, and the other employing linear-ordering variables along with two enhanced valid inequalities. Given the complexity of the problem, we introduce a reduction approach that simplifies the problem by modifying certain constraints, enabling the determination of a feasible solution much more quickly. Building on this reduction, we provide a linear-time reduction algorithm and a fast formulation based on assignment-and-positional date variables. Furthermore, we study a special case involving regular jobs. To solve large-scale instances of the problem with up to 250 jobs and up to 5 machines, we design a hybrid approach combining an iterated greedy algorithm with variable neighborhood descent. As shown in the computational experiments on two sets of benchmark instances, the reduction approach significantly outperforms all previous methods existing in the literature.},
  archive      = {J_EJOR},
  author       = {Abdelhak Elidrissi and Jatinder N.D. Gupta and Rachid Benmansour and Bertrand M.T. Lin},
  doi          = {10.1016/j.ejor.2025.05.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {15-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cutting stock problem with usable leftovers: A review. <em>EJOR</em>, <em>328</em>(1), 1-14. (<a href='https://doi.org/10.1016/j.ejor.2025.03.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a comprehensive literature review of the Cutting Stock Problem with Usable Leftovers (CSPUL). The most recent review on this topic dates to 2014, covering articles published before 2013. Since then, the number of publications on CSPUL has increased significantly, driven by new applications and more efficient solution approaches. We analyze fifty two relevant articles from twenty four different journals, focusing on works published after 2008 while acknowledging foundational contributions from the 1980s and 1990s. This review categorizes variations of CSPUL based on their dimensions (1D, 2D, and 3D), planning period characteristics (single-period and multi-period), objective functions, and solution methods. The article provides a detailed summary of the key features in the mathematical models and solution methods proposed in these studies. Additionally, it highlights several industrial applications of CSPUL, illustrating its practical relevance. Through this analysis, we identify important applications and propose promising directions for future research. The findings and insights presented here have practical implications for optimizing resource utilization and promoting sustainability in industries facing cutting challenges.},
  archive      = {J_EJOR},
  author       = {Victor Senergues and Nadjib Brahimi and Adriana Cristina Cherri and François Klein and Olivier Péton},
  doi          = {10.1016/j.ejor.2025.03.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cutting stock problem with usable leftovers: A review},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
