<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMJNL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comjnl">COMJNL - 98</h2>
<ul>
<li><details>
<summary>
(2025). Small object detection in remote sensing images through multi-scale feature fusion. <em>COMJNL</em>, <em>68</em>(9), 1329-1340. (<a href='https://doi.org/10.1093/comjnl/bxaf040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenges posed by background noise and the limited information available for small targets in remote sensing images, the detection performance for such targets remains unsatisfactory. To address these issues and enhance detection accuracy, we propose an improved algorithm based on RTDETR, named Adaptive Selective Transformer. Firstly, in the feature extraction network, we introduce an adaptive convolutional feature enhancement module to improve the multi-scale feature extraction capability in low-resolution remote sensing images. Secondly, we design a multi-scale enhancement structure to extract detailed information from small target images through enhanced multi-scale representation learning, thereby generating target features with stronger discriminative power. Finally, we propose a hierarchical frequency attention mechanism to achieve localized enhancement of contextual awareness, effectively capturing high-frequency local feature information of small targets. Experimental results demonstrate that the Adaptive Selective Transformer achieves superior small target detection performance, validating the effectiveness of our modifications to the original RTDETR model.},
  archive      = {J_COMJNL},
  author       = {Li, Sumin and Lin, Jinhua and Gang, Yijin and Pan, Xiuqin},
  doi          = {10.1093/comjnl/bxaf040},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1329-1340},
  shortjournal = {Comput. J.},
  title        = {Small object detection in remote sensing images through multi-scale feature fusion},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confluence: Improving network monitoring accuracy on multi-pipeline data plane. <em>COMJNL</em>, <em>68</em>(9), 1315-1328. (<a href='https://doi.org/10.1093/comjnl/bxaf039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sketch-based method is promising for traffic monitoring in data center networks. Existing data plane programming model (e.g. P4) assumes target switch as one single pipeline, while state-of-the-art programmable switches actually contain multiple independent pipelines. The status quo approach for deploying a sketch-based measurement application on a multi-pipeline switch is to deploy a sketch instance in each pipeline individually. However, under multi-path routing, such a naive approach leads to poor accuracy. To overcome this problem, in this paper, we present Confluence , a sketch-based network measurement system for multi-pipeline switches. For monitoring network flows that have packets arrived in bursts and spread over multiple pipelines, Confluence introduces novel data structures to collect short-term traffic statistics in ingress pipelines, and converge the measurement data to egress pipelines. Confluence is carefully designed under the switch hardware constraints, and in particular, to resolve the circular dependency in querying and updating a flow’s measurement data from sketch buckets, we propose a novel algorithm and theoretically prove its effectiveness. Both theoretical analysis and experiments driven by real-world traffic traces show that Confluence delivers higher measurement accuracies than existing solutions, especially in the critical task of detecting heavy hitters. Assessment on hardware switch suggests that Confluence is practical for real-world deployment.},
  archive      = {J_COMJNL},
  author       = {Wang, Cenman and Tian, Ye and Wu, Yiwen and Zhang, Xinming},
  doi          = {10.1093/comjnl/bxaf039},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1315-1328},
  shortjournal = {Comput. J.},
  title        = {Confluence: Improving network monitoring accuracy on multi-pipeline data plane},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal traffic flow forecasting based on second-order continuous graph neural network. <em>COMJNL</em>, <em>68</em>(9), 1300-1314. (<a href='https://doi.org/10.1093/comjnl/bxaf038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal forecasting has wide applications across various domains, particularly in intelligent transportation systems, where it plays a crucial role. Traffic flow prediction, a typical spatio-temporal forecasting task, involves complex dependencies across both time and space dimensions. Current research predominantly relies on graph neural networks (GNNs) for modeling. However, deep GNN architectures often face the issue of over-smoothing. To address this challenge, recent studies have explored integrating residual connections or neural ordinary differential equations (ODEs) with GNNs. Nonetheless, existing graph ODE methods have limitations in initializing latent feature representations for time series data and capturing higher order spatio-temporal dependencies. Additionally, they struggle to extract multi-scale temporal dependencies. In this paper, we propose a framework called the Multiple Second-order Continuous Graph Neural Network. The framework utilizes a second-order continuous GNN, and experiments on four real-world datasets demonstrate that it outperforms mainstream baseline models, thereby confirming the effectiveness of the proposed method.},
  archive      = {J_COMJNL},
  author       = {Ma, Zhaobin and Lv, Zhiqiang and Xu, Zhihao and Ye, Rongkun and Li, Jianbo},
  doi          = {10.1093/comjnl/bxaf038},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1300-1314},
  shortjournal = {Comput. J.},
  title        = {Spatio-temporal traffic flow forecasting based on second-order continuous graph neural network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing privacy and model performance in federated learning through contract-based data trading. <em>COMJNL</em>, <em>68</em>(9), 1285-1299. (<a href='https://doi.org/10.1093/comjnl/bxaf037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of the Internet of Things (IoT) has led to a huge amount of data beginning to emerge. Federated learning (FL) has received widespread attention and application as a new paradigm for data collection. However, data trading poses a threat to the privacy of data owners, and even participants in federated learning face the risk of data breaches. While many encryption methods have been proposed to mitigate these risks, the encrypted data negatively impacts the quality of the global model in federated learning. To this end, we propose an algorithm based on contract mechanisms to resolve the conflict between the privacy protection level of clients and the aggregation error on the federated learning server. Clients upload perturbed data according to their privacy protection levels, while mitigating the conflict between client data privacy protection and platform global model aggregation error. Through theoretical analysis and extensive experiments, our proposed trading method achieves desirable data utility while ensuring budget feasibility, individual rationality, and incentive compatibility.},
  archive      = {J_COMJNL},
  author       = {Liao, Gengjian and Shao, Shiyu and Feng, Zhenni},
  doi          = {10.1093/comjnl/bxaf037},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1285-1299},
  shortjournal = {Comput. J.},
  title        = {Balancing privacy and model performance in federated learning through contract-based data trading},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PHISH_ATTENTION: Achieving robust phishing website detection with balanced datasets and advanced URL features. <em>COMJNL</em>, <em>68</em>(9), 1263-1284. (<a href='https://doi.org/10.1093/comjnl/bxaf036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating prevalence of phishing attacks in recent years has underscored the imperative need for a comprehensive and sophisticated response to mitigate this pervasive cyber threat. Characterized by deceptive tactics to obtain sensitive information, phishing has evolved in sophistication, resulting in severe consequences such as financial loss, identity theft, and compromise of personal data. This research addresses the inherent challenges faced by existing anti-phishing solutions, encompassing limitations in feature extraction methodologies, suboptimal feature selection, and issues related to dataset imbalance. In response to these challenges, we propose “PHISH_ATTENTION,” an advanced anti-phishing framework that integrates Variational Autoencoders and a Multi-Head Self-Attention Mechanism. The framework is further enhanced by the incorporation of a Deep Convolutional Generative Adversarial Network to effectively address dataset imbalances. Rigorous testing on benchmark datasets reveals that PHISH_ATTENTION achieves a peak detection accuracy of 98.57% with a minimal false alarm rate of 1.09%, surpassing prevailing anti-phishing models. Distinguished by its proficiency in real-time phishing website detection, the framework’s autonomous acquisition of significant URL features establishes it as a resilient and pioneering contribution to the cybersecurity domain.},
  archive      = {J_COMJNL},
  author       = {Prabhakaran, Manoj Kumar and Chandrasekar, Abinaya Devi and Meenakshi Sundaram, Parvathy},
  doi          = {10.1093/comjnl/bxaf036},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1263-1284},
  shortjournal = {Comput. J.},
  title        = {PHISH_ATTENTION: Achieving robust phishing website detection with balanced datasets and advanced URL features},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilingual knowledge graph completion based on structural features. <em>COMJNL</em>, <em>68</em>(9), 1252-1262. (<a href='https://doi.org/10.1093/comjnl/bxaf035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual knowledge graph completion predicts missing facts in the target language knowledge graph by learning and inferring knowledge and rules in other language knowledge graphs. Existing methods tend to use aligned entities between knowledge graphs in different languages as alignment seeds, and receive information from them through alignment seeds to promote entity alignment between different knowledge graphs. However, these methods only consider the local structural information of the knowledge graph by aggregating entity neighborhood information through aligned entities, and ignore the global structural information. At the same time, the methods aboved are hardly to learn the entity representation with sparse neighborhood in isolated subgraphs. To address these two problems, this paper proposes a multilingual knowledge graph completion method based on double-branch graph neural network and self-supervised entity alignment (DBGNN-SSL). The global and local topological structures of the knowledge graph are learned through a double-branch graph attention neural network, and more aligned entities can be iteratively generated through self-supervised learning. The experimental results on datasets DBP-5L and E-PKG verify the effectiveness of the proposed method.},
  archive      = {J_COMJNL},
  author       = {He, Jinyan and Yang, Haitong},
  doi          = {10.1093/comjnl/bxaf035},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1252-1262},
  shortjournal = {Comput. J.},
  title        = {Multilingual knowledge graph completion based on structural features},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unravelling the semantic mysteries of transformers layer by layer. <em>COMJNL</em>, <em>68</em>(9), 1237-1251. (<a href='https://doi.org/10.1093/comjnl/bxaf034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant success of transformer models and their successors in various natural language processing (NLP) applications, their internal workings are still not fully understood. Much of the current interpretability research has focused primarily on numerical components, often missing the complex semantic layers within these models. To fill this gap, this study explores the interpretability of the transformer model, a cornerstone of modern NLP, by addressing the semantic complexities of its multi-layer architecture. We identify three key questions: (i) the influence of the multi-layer structure on semantic processing, (ii) the unique contributions of each layer to model performance, and (iii) methodologies for determining optimal layer counts for the encoder and decoder. To tackle these issues, we introduce the semantic interpreter for transformer hierarchy, an innovative framework that employs convex hull metrics to visualize and assess semantic quality and quantity. Our contributions include novel methods for semantic assessment, a dual analytical framework that integrates cumulative and layer-to-layer perspectives, and insights into the dynamics of encoding and decoding. This comprehensive approach aims to enhance the understanding of Transformer models, ultimately guiding their refinement for improved interpretability and effectiveness in natural language tasks.},
  archive      = {J_COMJNL},
  author       = {Zhang, Cheng and Lv, Jinxin and Cao, Jingxu and Sheng, Jiachuan and Song, Dawei and Zhang, Tiancheng},
  doi          = {10.1093/comjnl/bxaf034},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1237-1251},
  shortjournal = {Comput. J.},
  title        = {Unravelling the semantic mysteries of transformers layer by layer},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach to task offloading optimization: Integrating hybrid whale genetic algorithm and reinforcement learning. <em>COMJNL</em>, <em>68</em>(9), 1225-1236. (<a href='https://doi.org/10.1093/comjnl/bxaf033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing presents a promising approach for achieving communication Quality of Service (QoS) by employing a task offloading strategy to transfer latency-sensitive tasks into edge servers. Considering the offload equalization challenge, in this paper, we propose a novel task offloading optimization method based on a Hybrid Whale Genetic Algorithm (HWGA) with Reinforcement Learning (RL) to optimize the task offloading decisions within a tri-layer edge computing architecture comprising edge, fog, and cloud layers. Due to the expansive dimensionality of the action space from the increasing number of devices, we adapt the RL into a multi-layer architecture. In this framework, multi-layer RL techniques are first utilized to determine which layer should handle the task offloading. Subsequently, the HWGA is applied to guide the task offloading decisions for devices within each layer. Simulation results demonstrate that, when compared to baseline methods, our HWGA-based approach significantly reduces task completion time and energy consumption, while improving the task success rate, particularly in high-device-density scenarios.},
  archive      = {J_COMJNL},
  author       = {Luo, Qianhua and Xie, Bo and Wang, Jiahuan and Shuai, Jiaqi and Cui, Haixia},
  doi          = {10.1093/comjnl/bxaf033},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1225-1236},
  shortjournal = {Comput. J.},
  title        = {A hybrid approach to task offloading optimization: Integrating hybrid whale genetic algorithm and reinforcement learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arming text-based gender inference with partition membership filtering and feature selection for online social network users. <em>COMJNL</em>, <em>68</em>(9), 1208-1224. (<a href='https://doi.org/10.1093/comjnl/bxaf032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is devoted to simulating a text categorization-based gender inference attack over online social networks primarily to inspect the effect of partition membership filter (PMF) and feature selection (FS) on the performance of an attribute inference mechanism especially for the case of the distributed representation of texts. The task turning into a binary machine learning (ML) problem in the field of artificial intelligence (AI) is studied in multilingual scenarios (i.e. Turkish and English) under four main cases. The results obtained by extensive experiments show that distributed embeddings often outperform traditional embeddings. In contrast, the case involving FS on distributed embeddings is superior to other cases two of which incorporate PMF. On the other hand, the best f1-scores obtained on Turkish and English datasets are 0.727 and 0.611 obtained with the help of Random Forest and Support Vector Machine classifiers, respectively. It is worth noting that this investigation is not handled in the existing literature on text data. Therefore, it is believed that the findings of this study will provide useful insight for researchers studying text-based attribute inference attacks as well as some other text-based binary ML tasks in the field of AI.},
  archive      = {J_COMJNL},
  author       = {Çoban, Önder and Yücel Altay, Şeyma},
  doi          = {10.1093/comjnl/bxaf032},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1208-1224},
  shortjournal = {Comput. J.},
  title        = {Arming text-based gender inference with partition membership filtering and feature selection for online social network users},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient unlearning for data security in deep learning systems. <em>COMJNL</em>, <em>68</em>(9), 1197-1207. (<a href='https://doi.org/10.1093/comjnl/bxaf031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning in the context of cybersecurity and privacy protection facilitates the removal of specific training data impacts from deep learning (DL) models, adhering to security, privacy, or compliance demands. However, traditional methods can only handle short-term, independent unlearning tasks. Conversely, real-world scenarios often involve extensive unlearning demands from users. Current methods fail to adequately address these demands due to substantial computational overhead and adverse impacts on inference accuracy, leaving the security and privacy of many users at risk. To navigate these challenges adeptly, we introduce the Multi-Agent Reinforcement Learning Data Lifecycle Management (MADLM) strategy. MADLM intricately examines the interactions between unlearning and continuous learning processes, enabling the postponement of certain tasks for combined execution to optimize computational resources. Concurrently, it employs strategic data management to maintain and enhance inference accuracy. Furthermore, by utilizing Multi-Agent Reinforcement Learning (MARL), MADLM dynamically orchestrates task scheduling to minimize computational demands, improve task response times, and bolster inference reliability, crucial for upholding stringent cybersecurity and privacy standards. Our evaluations of MADLM reveal substantial enhancements, including a 6% uplift in inference accuracy and a dramatic reduction in computational overhead to merely 12% of the original demands, effectively expanding the data security protections.},
  archive      = {J_COMJNL},
  author       = {Guo, Enting and Su, Chunhua and Li, Peng},
  doi          = {10.1093/comjnl/bxaf031},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1197-1207},
  shortjournal = {Comput. J.},
  title        = {Efficient unlearning for data security in deep learning systems},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Use of data mining in identifying the risk factors of optic neuropathy. <em>COMJNL</em>, <em>68</em>(9), 1181-1196. (<a href='https://doi.org/10.1093/comjnl/bxaf030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optic nerve carries signals from the eye to the brain, where they are interpreted as visual images. Optic neuropathy is a serious eye disease that can lead to the loss of vision in the affected eye. Identifying the risk factors for optic neuropathy from large patient data is crucial and challenging. Modern techniques can assist in recognizing these risk factors. For instance, data mining algorithms such as classification and association rules can discover knowledge from datasets in many real-world applications, particularly in the medical field. This study employed a decision tree algorithm known as J48 and an association rule algorithm called Apriori to analyze the collected data. The J48 algorithm achieved an accuracy of 90%, while the Apriori algorithm discovered 52 significant association rules with a confidence level above 80%. The goal of this study was to identify risk factors for optic neuropathy and explore the connection between optic nerve damage and other conditions. The proposed algorithms aim to reduce blindness rates and increase awareness of the risk factors associated with optic nerve damage by detecting hidden risk factors at an early stage. The study's findings show that some risk factors for optic neuropathy confirmed by medical trials are also detected by these algorithms, proving the effectiveness and applicability of data mining techniques in the medical field. Moreover, this study discovered new risk factors for optic nerve damage not previously found by medical trials. This knowledge will contribute to the early detection and prevention of blindness by recognizing risk factors for optic nerve damage.},
  archive      = {J_COMJNL},
  author       = {Al-Shamiri, Abdulkawi Yahya Radman and Yu, Dong-Jun and Li, Peipei and Al-Mahweeti, Balqis Yahya Ali Abdullah},
  doi          = {10.1093/comjnl/bxaf030},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1181-1196},
  shortjournal = {Comput. J.},
  title        = {Use of data mining in identifying the risk factors of optic neuropathy},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced code slicing with pre-trained model fine-tuned for open-source component malware detection. <em>COMJNL</em>, <em>68</em>(9), 1163-1180. (<a href='https://doi.org/10.1093/comjnl/bxaf029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open Source Software (OSS) is an essential part of modern software development, with platforms such as PyPI for Python, NPM for JavaScript, and RubyGems for Ruby facilitating code sharing and reuse. However, these repositories also pose significant security risks due to potential software supply chain attacks, where payloads are injected into components, propagating threats to downstream users and critical infrastructure. Existing automatic malicious component detection tools, particularly for PyPI, struggle to distinguish between subtle differences in malicious and benign behaviors, leading to high false positive rates. To address these issues, we systematically compare and explore these subtle differences, offering a more refined and accurate detection method, Open-Source Component Code Slices BERT (OCS-BERT). OCS-BERT leverages taint-based program slicing to isolate sensitive behavior segments and fine-tunes pre-trained model to capture subtle semantic differences across programming languages. This system excels in detecting malicious Python components and exhibits encouraging cross-language transferability to JavaScript's NPM and Ruby's RubyGems. Additionally, OCS-BERT successfully detected 107 malicious components from a total of 25,759 newly-uploaded PyPI components, taking two weeks to complete the process. This achievement demonstrates the effectiveness of our method, which serves as a potent enhancement to the current repertoire of software supply chain detection methodologies.},
  archive      = {J_COMJNL},
  author       = {Wang, Yongshan and Pang, Siyuan and Fan, Zijing and Shang, Shang and Yao, Yepeng and Jiang, Zhengwei and Liu, Baoxu},
  doi          = {10.1093/comjnl/bxaf029},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1163-1180},
  shortjournal = {Comput. J.},
  title        = {Advanced code slicing with pre-trained model fine-tuned for open-source component malware detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced social media crime prevention via deep learning and cryptographic data encryption. <em>COMJNL</em>, <em>68</em>(9), 1150-1162. (<a href='https://doi.org/10.1093/comjnl/bxaf028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing prevalence of crime facilitated through social media platforms has become a critical concern for law enforcement and security agencies. With vast amounts of personal, sensitive, and actionable data being shared online, the risk of criminal exploitation has grown significantly, necessitating innovative approaches to crime prevention. This research addresses the problem of detecting and preventing social media-based crimes by integrating cryptographic data encryption with a focus on privacy and security. This study proposes a hybrid ECC-RSA (Elliptic Curve Cryptography—Rivest, Shamir, Adleman) model with key selection optimized using the Zebra Optimization Algorithm (ZOA) to enhance both the security and efficiency of the encryption process. Additionally, an Artificial Neural Network (ANN) is employed as a specific application to classify and detect suspicious online activities related to criminal behavior. A key challenge in this domain is achieving a balance between privacy preservation and effective crime detection. To evaluate the system, an extensive dataset of social media interactions containing both legitimate and suspicious activities was used. The results demonstrate that the integrated ECC-RSA model with ZOA optimization provides robust encryption while maintaining high detection accuracy, achieving 92% accuracy, 89% precision, and 91% recall. The ANN-based detection system successfully identifies potential criminal activities, while the cryptographic model ensures no sensitive data is exposed during analysis, maintaining user privacy. The findings suggest that the proposed hybrid model offers a promising solution for proactive crime prevention on social media, effectively balancing privacy, security, and detection performance.},
  archive      = {J_COMJNL},
  author       = {Alserhani, Faeiz},
  doi          = {10.1093/comjnl/bxaf028},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1150-1162},
  shortjournal = {Comput. J.},
  title        = {Advanced social media crime prevention via deep learning and cryptographic data encryption},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRACE: Front-running attack classification on ethereum using ensemble learning. <em>COMJNL</em>, <em>68</em>(9), 1137-1149. (<a href='https://doi.org/10.1093/comjnl/bxaf027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid evolution of blockchain technologies, Ethereum has emerged as a central platform for advanced financial applications but has concurrently experienced a rise in security vulnerabilities, particularly from front-running attacks. These attacks exploit transaction sequencing for illegal gains. To combat this, we introduce FRACE (Front-Running Attack Classification using Ensemble Learning), a novel methodology that classifies front-running attacks into displacement, insertion, and suppression using an ensemble learning model. This precise classification facilitates tailored defensive strategies, enhancing the robustness and accuracy of attack detection. Our approach achieves an accuracy of 95.36% and an F1-score of 95.30%, significantly improving the security of decentralized applications. Extensive analysis and validation on Ethereum confirm these results. Future efforts will refine these models and extend their application to other blockchain platforms, striving for a universally secure, transparent, and reliable digital transaction ecosystem.},
  archive      = {J_COMJNL},
  author       = {Zhang, Yuheng and Wang, Guojun and Li, Peiqiang and Gu, Wanyi and Chen, Houji},
  doi          = {10.1093/comjnl/bxaf027},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1137-1149},
  shortjournal = {Comput. J.},
  title        = {FRACE: Front-running attack classification on ethereum using ensemble learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GitHub project recommendation based on knowledge graph and developer similarity. <em>COMJNL</em>, <em>68</em>(9), 1128-1136. (<a href='https://doi.org/10.1093/comjnl/bxaf026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding and recommending projects that match developer’s interests is always an urgent problem in open-source community. There are some problems in the existing project recommendation methods, such as insufficient use of information, ignoring the relationship between projects, one-sided consideration, and so on. To solve the above problems, we propose a project recommendation model based on project knowledge graph and developer similarity, called knowledge graphs and developer interest similarity (KGDS). KGDS mines developer interest from project similarity and developer similarity. For project similarity, we first construct the project knowledge graph. Then, content features and potential features are extracted from the project Readme document and knowledge graph, respectively, and the two features are merged to enrich the developer embedding and project embedding, which solves the problem of insufficient utilization of information. For developer similarity, we first construct a developer-project matrix, then obtain the historical developers related to candidate project, and then calculate the similarity between the historical developers and the target developer, which solves the problem of one-sided consideration. Finally, we combine the two part information to recommend projects that meet the interests of developers. We have conducted experiments on the GitHub dataset, and the results show that KGDS outperforms the baseline model.},
  archive      = {J_COMJNL},
  author       = {Yu, Song and Liu, Wenlong and Wu, Hannan and Liao, Zhifang},
  doi          = {10.1093/comjnl/bxaf026},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1128-1136},
  shortjournal = {Comput. J.},
  title        = {GitHub project recommendation based on knowledge graph and developer similarity},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A yolo-like lightweight ship detection network for unmanned surface vehicles. <em>COMJNL</em>, <em>68</em>(9), 1118-1127. (<a href='https://doi.org/10.1093/comjnl/bxaf025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of unmanned surface vehicles (USVs) in maritime surveillance has highlighted the need for improved ship detection models. However, hardware limitations and environmental interference impact the perception capability of USVs. In order to address these challenges, YoloS, a lightweight ship detection network, is specifically designed for USVs in complex backgrounds. Firstly, a network component Split Widely Network (SWNet) is put forward to the backbone to reduce its redundancy. SWNet leverages inter-channel interaction and the idea of group convolution to minimize redundancy of the network. Secondly, the Small Pyramid Network (SPN) is introduced as the neck network. SPN enhances the spatial information of the target regions by capturing and highlighting significant contour and texture details within target regions. SPN also utilizes these low-level features with enhanced spatial information to guide high-level features in identifying the most discriminative fine-grained details within the target regions. In order to further achieve network lightweighting, only two output heads for low-level features are retained while still preserving the capability to extract task-critical features. Extensive experiments on different datasets have verified the effectiveness of the proposed method, and it shows that YoloS can achieve 96.5 % detection accuracy and 80.1 fps on the SMD dataset with only 2.78M model parameters and 10.4G floating point operations.},
  archive      = {J_COMJNL},
  author       = {Zhou, Weina and Shao, Wei and Hu, Wenhua},
  doi          = {10.1093/comjnl/bxaf025},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1118-1127},
  shortjournal = {Comput. J.},
  title        = {A yolo-like lightweight ship detection network for unmanned surface vehicles},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-feature adaptive framework for multimodal disinformation detection. <em>COMJNL</em>, <em>68</em>(9), 1105-1117. (<a href='https://doi.org/10.1093/comjnl/bxaf024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of disinformation on online social media has caused massive concern. Existing disinformation detection methods neglect the diverse compositional forms of tweets in real-life scenarios, making them less applicable and effective in social media settings. Meanwhile, these methods use pattern cues but overlook important aspects such as syntax, lexicon, and shallow visual semantics, and lack attention to factual content such as time, place, and person relay in both text and images, thus failing to fully explore features of disinformation and limiting detection accuracy. Furthermore, with the popularity of large language models (LLMs), the tweets generated by these models make the style of disinformation more subtle. Since existing datasets are mostly human-generated and lack style diversity, it results in weak detection capabilities of methods trained on these datasets. To address these challenges, a dual-feature adaptive framework for multimodal disinformation detection is proposed. The framework first using a similarity-based algorithm adaptively handles different tweet forms. It then enhances pattern features by bridging multimodal output from single-modal pretrained modal, and factual features are subsequently extracted using a zero-shot method based on a large vision language model. Finally, an expert network aggregates and reweights the dual-feature representation for tweets using an LLM-text detector in gating strategy. This paper also presents two multimodal disinformation datasets that include both LLM-generated and human-generated tweets reflecting real-world scenarios. The true tweets in datasets are diverse in style, while the fake tweets are more misleading. Experimentally verified, the proposed method outperforms baseline methods by an accuracy of 1.04% and 0.72% on typical datasets while also achieving a minimum accuracy drop of 0.65% and 0.87% on the proposed dataset.},
  archive      = {J_COMJNL},
  author       = {Yan, Kexiang and Liang, Gang and Wang, Lei and Sun, Mingxu and Zhao, Kui},
  doi          = {10.1093/comjnl/bxaf024},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1105-1117},
  shortjournal = {Comput. J.},
  title        = {Dual-feature adaptive framework for multimodal disinformation detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PEAR: Privacy-preserving and effective aggregation for byzantine-robust federated learning in real-world scenarios. <em>COMJNL</em>, <em>68</em>(9), 1087-1104. (<a href='https://doi.org/10.1093/comjnl/bxae086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables collaborative training of global models among distributed clients without sharing local data. Secure aggregation, a new security primitive of FL, enhances the confidentiality of data and model parameters. Unfortunately, privacy-preserving (PP) FL is vulnerable to common poisoning attacks by Byzantine adversaries. Existing defense strategies mainly focus on identifying abnormal local gradients over plaintexts, which provides a weak privacy guarantee. In PPFL, adversaries can escape existing defenses by uploading encrypted poisonous gradients. In addition, most mainstream aggregation algorithms assume that clients’ local training data is uniformly distributed, Independent and Identically Distributed (IID), which is unrealistic for real-world FL scenarios where data are only stored on large-scale terminal devices. To address these issues, we propose PEAR, a PP aggregation strategy based on single key-dual server CKKS full homomorphic encryption in real-world distributed scenarios, which can resist encrypted poisoning attacks. Specifically, we use cosine similarity to measure the distance between encrypted gradients. Then, we propose a novel Byzantine-tolerance aggregation mechanism using cosine similarity, which includes trust score generation that can tolerate differentiated local gradients and a two-step weight generation method that considers both the degree of gradient deviation in direction and training data size. This mechanism can achieve robustness for both IID and non-IID data without compromising privacy. Our extensive evaluations for two typical poisoning attacks on different datasets show that PEAR is robust and effective in IID and non-IID data and outperforms existing mainstream Byzantine-robust algorithms, especially achieving 16.4% to 53.2% testing error rate reduction in non-IID settings with significant label distribution and quantity skew while maintaining the same efficiency as FedAvg.},
  archive      = {J_COMJNL},
  author       = {Sun, Han and Zhang, Yan and Zhuang, Huiping and Li, Jiatong and Xu, Zhen and Wu, Liji},
  doi          = {10.1093/comjnl/bxae086},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1087-1104},
  shortjournal = {Comput. J.},
  title        = {PEAR: Privacy-preserving and effective aggregation for byzantine-robust federated learning in real-world scenarios},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual protection technology to thwart hardware trojan insertion based on observability. <em>COMJNL</em>, <em>68</em>(8), 1074-1085. (<a href='https://doi.org/10.1093/comjnl/bxaf050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The globalization of the integrated circuit design industry makes it easier for the adversary to pirate intellectual property and insert hardware Trojans (HTs). Although many HT protection methods have been proposed, some malicious elements can still be inserted into vulnerable nodes. Trojans are usually inserted in the rare nodes with the lowest observability, which makes it hard for testers to discover them. In this paper, we propose a dual-protection technology to protect the circuit against HT attacks based on observability. First, we propose an algorithm to increase the low observabilities of the circuit, so as to make it difficult for attackers to implant HTs. Several existing approaches try to identify the low observability by setting a threshold artificially, which is not generic. We do not need to set thresholds when targeting the low observability. Second, we present another logic locking algorithm to enhance the entire circuit’s security further. Simulation results on ISCAS85 benchmark and several larger circuits show that the proposed HT protection method has increased the lowest observability of the circuit by an average of 370.76 times. Furthermore, the logic locking technique maximizes the ambiguity for an attacker. Compared with the state of the art, the proposed logic locking can obtain better results, achieving a Hamming distance that is closer to 50% between the correct and incorrect outputs when a wrong key is applied.},
  archive      = {J_COMJNL},
  author       = {Wang, Zhen and Lv, Jinfeng and Zhou, Yuhao and Jiang, Jianhui and Wang, Yong},
  doi          = {10.1093/comjnl/bxaf050},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1074-1085},
  shortjournal = {Comput. J.},
  title        = {A dual protection technology to thwart hardware trojan insertion based on observability},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compression cryptosystem. <em>COMJNL</em>, <em>68</em>(8), 1062-1073. (<a href='https://doi.org/10.1093/comjnl/bxaf023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compression cryptosystem is a single coding process, the output of which is both reduced in space and secure against unauthorized decoding. Considering both Huffman and arithmetic coding, this paper proposes to apply repeatedly minor changes to the compression model, with negligible deterioration of its optimality. The cumulative impact of a large number of such changes leads to completely different ciphertexts, which can be decrypted only if a given secret key is known. The security of the system is based on the NP-completeness of a problem related to breaking the code. Several variants are suggested, and their results are tested in various settings, including for security against chosen plaintext attacks.},
  archive      = {J_COMJNL},
  author       = {Gross, Yoav and Klein, Shmuel T and Opalinsky, Elina and Revivo, Rivka and Shapira, Dana},
  doi          = {10.1093/comjnl/bxaf023},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1062-1073},
  shortjournal = {Comput. J.},
  title        = {Compression cryptosystem},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel curriculum learning framework for multi-label emotion classification. <em>COMJNL</em>, <em>68</em>(8), 1050-1061. (<a href='https://doi.org/10.1093/comjnl/bxaf022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curriculum learning (CL) is a training strategy that imitates how humans learn, by gradually introducing more complex samples and information to the model. However, in multi-label emotion classification (MEC) tasks, using a traditional CL approach can result in overfitting on easy samples and lead to biased training. Additionally, the sample difficulty varies as the model trains. To address these challenges, we propose a novel CL framework for MEC tasks called CLF-MEC. Unlike traditional approaches that assess difficulty at the sample level, we utilize category-level assessment to determine the difficulty level of samples. As the model identifies a category well, the score for that category’s samples is reduced, ensuring dynamic changes in the sample difficulty are accounted for. Our CL framework employs two training modes, namely “learning” and “tackling.” These two processes are trained alternatively to imitate the “learning-tackling” process in human learning. This ensures that samples from hard-to-learn categories receive more attention. During the “tackling” process, our method transforms the task of dealing with hard samples into an “easy” learning task by utilizing contrastive learning to enhance the semantic representation of those hard samples. Experimental results demonstrate that our CLF-MEC framework has achieved significant improvements in MEC.},
  archive      = {J_COMJNL},
  author       = {Lin, Nankai and Wu, Hongyan and Zeng, Peijian and Bai, Qifeng and Zhou, Dong and Yang, Aimin},
  doi          = {10.1093/comjnl/bxaf022},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1050-1061},
  shortjournal = {Comput. J.},
  title        = {A novel curriculum learning framework for multi-label emotion classification},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new DDoS attack detection model based on improved stacked autoencoder and gated recurrent unit for software defined network. <em>COMJNL</em>, <em>68</em>(8), 1028-1049. (<a href='https://doi.org/10.1093/comjnl/bxaf021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of Software Defined Networking (SDN), detecting Distributed Denial of Service (DDoS) attacks has become an urgent challenge in SDN maintenance and Security. Given the diversity of DDoS attack types, we face significant challenges. This paper proposes a model called ARSAE-QGRU, which is based on integrating attention mechanisms and residual connections within a stacked autoencoder for DDoS attack detection. By introducing attention mechanisms and residual connections into the stacked autoencoder (SAE), the model effectively conveys more valuable information and facilitates gradient propagation, allowing it to learn low-dimensional representations better. It also combines the learned low-dimensional representations with traffic features to generate data for DDoS attack training. Furthermore, incorporating Gated Recurrent Unit aids in a more in-depth understanding of the temporal characteristics of traffic data, resulting in improved detection accuracy. This model demonstrates outstanding performance on the CICDDoS2019 and CICIDS2017 datasets, achieving accuracy rates of 97.2% and 97.9%, respectively. Moreover, when applied to datasets in SDN environments, it reaches an even higher accuracy rate of 99.8%. This research provides a reliable solution for high-dimensional data processing and DDoS attack detection within SDN, addressing the urgent challenges in these domains.},
  archive      = {J_COMJNL},
  author       = {Wang, Haizhen and Jia, Na and He, Yang and Lian, Zuozheng},
  doi          = {10.1093/comjnl/bxaf021},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1028-1049},
  shortjournal = {Comput. J.},
  title        = {A new DDoS attack detection model based on improved stacked autoencoder and gated recurrent unit for software defined network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted twin support vector machine with rescaled hinge loss. <em>COMJNL</em>, <em>68</em>(8), 1013-1027. (<a href='https://doi.org/10.1093/comjnl/bxaf020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted twin support vector machine (WTSVM) has been proved to be effective for classification problems. However, it is sensitive to noises, especially for data corrupted by outliers. In this paper, we propose an improved classifier termed as weighted twin support vector machine with rescaled hinge loss (RHWTSVM). Similar to WTSVM, it uses the intra-class KNN technique to extract structural information in the same class. It uses the inter-class KNN technique to reduce the redundant constraints to improve the computational speed. Furthermore, we introduce the regularization term into the objective function to make the proposed RHWTSVM implement the principles of structural risk minimization and empirical risk minimization simultaneously. Besides, we use the rescaled hinge loss function which is a monotonic, bounded, and nonconvex loss to replace the traditional hinge loss function in WTSVM to make the proposed classifier more robust. Therefore, the RHWTSVM is less sensitive to outliers. Because the model is a nonconvex optimization problem, we use the half-quadratic optimization method to solve it and find that the new method is equivalent to an iterative WTSVM. Numerical experiments on datasets with various levels of noise demonstrate that RHWTSVM is reasonable and effective.},
  archive      = {J_COMJNL},
  author       = {Zhang, Siyuan and Zhang, Yixuan and Feng, Jianying},
  doi          = {10.1093/comjnl/bxaf020},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1013-1027},
  shortjournal = {Comput. J.},
  title        = {Weighted twin support vector machine with rescaled hinge loss},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2PQNN: A fast and secure two-party inference on quantized convolutional neural networks. <em>COMJNL</em>, <em>68</em>(8), 998-1012. (<a href='https://doi.org/10.1093/comjnl/bxaf019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The machine learning as a service (MLaaS) paradigm has been widely adopted across various applications. However, it also raises significant privacy concerns, particularly regarding the exposure of input data and trained models. Two-party computation in convolutional neural network (CNN) inference has emerged as a promising solution to address these privacy issues in MLaaS. Nevertheless, most existing privacy-preserving CNN architectures rely on computationally expensive encryption methods, resulting in prolonged inference times and increased communication overhead. In this paper, we propose F2PQNN, a fast and secure two-party inference framework for quantized CNNs. To minimize reliance on computationally intensive encryption, F2PQNN utilizes two non-colluding servers and integrates secret sharing with oblivious transfer techniques. Furthermore, F2PQNN incorporates quantization techniques, along with batching and asynchronous computation, to significantly accelerate inference predictions. We evaluate the performance of F2PQNN on the MNIST, Fashion-MNIST, CIFAR-10, and STL-10 datasets. Experimental results demonstrate that F2PQNN outperforms existing solutions, achieving a 9.14 × speedup and reducing communication overhead by 59.8 × on the MNIST dataset.},
  archive      = {J_COMJNL},
  author       = {Li, Jinguo and Yuan, Peichun and Zhang, Jin and Shen, Sheng and He, Yin and Xiao, Ruyang},
  doi          = {10.1093/comjnl/bxaf019},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {998-1012},
  shortjournal = {Comput. J.},
  title        = {F2PQNN: A fast and secure two-party inference on quantized convolutional neural networks},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault tolerance assessment of the data center network DPCell based on g-good-neighbor conditions. <em>COMJNL</em>, <em>68</em>(8), 985-997. (<a href='https://doi.org/10.1093/comjnl/bxaf018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data center networks (DCNs) provide critical data storage and computing services for cloud computing. The continuous increase in demand for cloud computing has led to a surge in data volume, necessitating the continual expansion of DCNs. However, this expansion also heightens the risk of device failures. Therefore, it is particularly important to study the fault tolerance of DCNs, which refers to their ability to ensure reliable communication even in the presence of device failures. Among DCNs constructed using dual-port servers, DPCell achieves higher scalability and bisection width while maintaining a smaller diameter. This paper assesses the fault tolerance of DPCell using two metrics: connectivity and diagnosability. Recognizing the limitations of traditional connectivity and diagnosability, we investigate the connectivity and diagnosability of DPCell under the condition that each fault-free node in the network has at least |$g$| fault-free neighbors. The results indicate that, under this condition, the connectivity and diagnosability of DPCell exceed its traditional metrics by more than |$g$| times.},
  archive      = {J_COMJNL},
  author       = {Dong, Hui and Wang, Huaqun and Lv, Mengjie and Fan, Weibei},
  doi          = {10.1093/comjnl/bxaf018},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {985-997},
  shortjournal = {Comput. J.},
  title        = {Fault tolerance assessment of the data center network DPCell based on g-good-neighbor conditions},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing an intelligent framework with blockchain capabilities for environmental monitoring using a CubeSat. <em>COMJNL</em>, <em>68</em>(8), 968-984. (<a href='https://doi.org/10.1093/comjnl/bxaf017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellites have revolutionised the way that the planet’s environment is monitored via a unique perspective from above. Indeed, environmental monitoring is crucial for understanding and addressing the complex challenges facing the planet, which helps in decision-making and ensuring a sustainable future. Thus, this work aims to develop an intelligent model that includes artificial neural networks and deep learning approaches that are coupled with Blockchain capabilities for secure environmental monitoring using a CubeSat. The CubeSat, which is a small satellite platform, is equipped with a designed communication payload, including an adaptive Multiple-Input Multiple-Output antenna as well as an High Definition (HD) camera for better connectivity and precision aerial imaging. The proposed solution is simulated, tested, and validated from four scenarios, namely, water detection, tree counting and vegetation assessment, and oil spill detection. Ensuring the security and integrity of the data transmitted between the CubeSat and the ground station is of paramount importance; this is where Blockchain technology comes into play. The obtained results show high accuracy in monitoring environmental surfaces like water, trees, and coasts in an effective and rapid deployment fashion. Also, performance indicators of the Blockchain ensure data integrity and retrieval efficiency. Combining these technologies provides a valuable contribution to environmental monitoring.},
  archive      = {J_COMJNL},
  author       = {Almalki, Faris A},
  doi          = {10.1093/comjnl/bxaf017},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {968-984},
  shortjournal = {Comput. J.},
  title        = {Developing an intelligent framework with blockchain capabilities for environmental monitoring using a CubeSat},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BLFair: Enabling proportional I/O sharing for NVMe SSD in SPDK para-virtualization architecture. <em>COMJNL</em>, <em>68</em>(8), 953-967. (<a href='https://doi.org/10.1093/comjnl/bxaf016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data centers, the Storage Performance Development Kit (SPDK) para-virtualization architecture is an efficient solution for non-volatile memory express (NVMe) solid-state drive (SSD) virtualization but faces challenges in maintaining performance fairness and isolation due to storage resource competition among multi-tenants. However, the existing Quality of Service method in SPDK fails to ensure proportional I/O sharing among multi-tenants. Providing fairness and isolation while maintaining high storage utilization in SPDK remains a challenge. In this paper, we propose BLFair to address this problem. Specifically, BLFair implements proportional I/O sharing for multi-tenants in the SPDK. The design of BLFair can effectively reduce the high time complexity caused by the ordering and the overhead of maintaining the virtual clock. Moreover, BLFair allows for achieving a trade-off between proportional I/O sharing and maximizing storage utilization. BLFair also uses the lockless ring mechanism to achieve scalability for cross-core operation. We have implemented a prototype system of BLFair in SPDK. Finally, we conduct evaluations with different workloads in both local storage and NVMe over RDMA fabric environments. The results show that our method can achieve fairness and scalability. BLFair can achieve up to 7.09x 99.99th latency reduction compared to the system with no fairness. Evaluation results in realistic workloads also show that BLFair outperforms other methods.},
  archive      = {J_COMJNL},
  author       = {Feng, Yanchang and Ma, Junchao and Xia, Haojun and Zhang, Da and Tu, Bibo},
  doi          = {10.1093/comjnl/bxaf016},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {953-967},
  shortjournal = {Comput. J.},
  title        = {BLFair: Enabling proportional I/O sharing for NVMe SSD in SPDK para-virtualization architecture},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards effective privacy preservation in federated learning with automatic gradient clipping and gradient transformation perturbation. <em>COMJNL</em>, <em>68</em>(8), 939-952. (<a href='https://doi.org/10.1093/comjnl/bxaf015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy can effectively help federated learning resist privacy attacks from various parties. However, existing approaches that use differential privacy for privacy protection greatly decrease the model performance of federated learning, especially in scenarios with complex model structures and large parameters. In this paper, we propose a novel privacy preservation scheme for federated learning that combines automatic gradient clipping and gradient transformation perturbation. Our approach primarily reduces the impact of differential privacy on federated learning from two aspects. Firstly, we efficiently control the gradient sensitivity by using automatic gradient clipping instead of traditional threshold clipping. Secondly, we utilize the space transformation technique to alleviate the dramatic accuracy degradation of the model caused by the insertion noise. Extensive experiments on various benchmark datasets demonstrate that our approach achieves a good trade-off between data privacy and effectiveness under the same privacy budget.},
  archive      = {J_COMJNL},
  author       = {Wang, Chuanyin and Zhang, Yifei and Gao, Neng},
  doi          = {10.1093/comjnl/bxaf015},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {939-952},
  shortjournal = {Comput. J.},
  title        = {Towards effective privacy preservation in federated learning with automatic gradient clipping and gradient transformation perturbation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuoSQL: Towards elastic data warehousing via separated data management and processing. <em>COMJNL</em>, <em>68</em>(8), 926-938. (<a href='https://doi.org/10.1093/comjnl/bxaf014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving data warehouses (DWs) to the cloud is what today’s companies consider a trend towards cost-effective data management. To fully achieve the goal, the cloud DW system is supposed to adjust its resource provisioning to adapt to changing workload requirements. However, traditional data warehousing architecture lacks the flexibility for on-demand resource control, which severely restricts cost optimization and quality of service for both cloud providers and users. To build cloud DWs, new architectures are needed. This paper explores an architecture that decouples data management and processing to enable on-demand resource control. This optimized design enhances system elasticity and adaptability. However, this separation design is not without cost, as cooperation overhead can be high if not well optimized. For proof of concept, we build a prototype system, DuoSQL, using PostgreSQL for data management and Spark for data processing. To optimize cooperation, we conduct joint parameter tuning to improve overall system performance. We validate the system with the TPC-H benchmark. Results show the decoupling approach is flexible and offers significant performance potential.},
  archive      = {J_COMJNL},
  author       = {zhang, Weikang and Liu, Zhi and Bai, Tongxin and Zheng, Furong and Jin, Wenming and Wang, Yang},
  doi          = {10.1093/comjnl/bxaf014},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {926-938},
  shortjournal = {Comput. J.},
  title        = {DuoSQL: Towards elastic data warehousing via separated data management and processing},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to optimize based on rate decay. <em>COMJNL</em>, <em>68</em>(8), 908-925. (<a href='https://doi.org/10.1093/comjnl/bxaf012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to optimize (L2O) is a technique that uses neural networks to learn optimization algorithms automatically. While it holds promise for diverse optimization problems, achieving consistently ideal results remains a challenge. Typically, L2O through a parameterized optimization method (i.e. “ optimizer”) learns from training samples and generalizes to test tasks with the same distribution. However, the new test tasks usually have some deviation from the training set distribution. In this case, the generic L2O methods may not produce good optimization results. Thus, we introduce a step-size control mechanism based on the generic L2O to solve the common problem of insufficient control of the iteration amplitude in L2O and adopt different update strategies for various optimization problems to adapt to complex optimization scenarios. Additionally, we also innovatively use the gated recurrent unit network as the core model of the optimizer to achieve better optimization results. Finally, the experimental outcomes from numerical simulations and real-world datasets show that our proposed methods are significantly better than other optimization algorithms.},
  archive      = {J_COMJNL},
  author       = {Ma, Wenmin},
  doi          = {10.1093/comjnl/bxaf012},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {908-925},
  shortjournal = {Comput. J.},
  title        = {Learning to optimize based on rate decay},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MuST-GAN MFAS: Multi-semantic spoof tracer GAN with transformer layers for multi-modal face anti-spoofing. <em>COMJNL</em>, <em>68</em>(8), 891-907. (<a href='https://doi.org/10.1093/comjnl/bxaf011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-modal face anti-spoofing (MFAS), where RGB, depth, and infrared data are integrated, remarkable advancements have been seen. However, despite the advancement, there still exist challenges when it comes to adaptability, particularly in dealing with unseen attacks. In this paper, a novel model called MuST-GAN MFAS is presented. This model employs a generative network that incorporates modality-specific encoders and transformer layers. It is significant that the model efficiently disentangles multi-semantic spoof traces by utilizing the power of cross-modal attention mechanisms and a transformer-based spoof trace generator. The training process involves bidirectional adversarial learning, ensuring identity consistency, intensity, center, and classification losses are taken into consideration. Through precise evaluations, it has been shown that the proposed model surpasses existing frameworks, showing remarkable performance when evaluating several modal samples. In the end, MuST-GAN MFAS makes an impressive contribution to the field of face anti-spoofing by offering results that are easy to interpret and emphasizing how important it is to learn multi-semantic spoof traces in order to improve generalization and adaptability to unseen attacks. The code is available at https://github.com/ZainUlAbideenMalik/Must-GAN-MFAS .},
  archive      = {J_COMJNL},
  author       = {Liu, Shu and Ul Abideen, Zain and Wan, Tongming and Shahzad, Inzamam and Waseem, Abbas and Pan, Yushan},
  doi          = {10.1093/comjnl/bxaf011},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {891-907},
  shortjournal = {Comput. J.},
  title        = {MuST-GAN MFAS: Multi-semantic spoof tracer GAN with transformer layers for multi-modal face anti-spoofing},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zk-DCIAExchange: SGX protected fair exchange with distributed zero knowledge proof for data confidentiality and authentication. <em>COMJNL</em>, <em>68</em>(8), 872-890. (<a href='https://doi.org/10.1093/comjnl/bxaf010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based data transaction protocols augmented with zero-knowledge proofs offer fairness to the participants, yet they encounter challenges pertaining to both security and efficiency. We propose the zk-DSTARK, a zk-STARK-based protocol that enables distributed generation of zero-knowledge proofs, significantly reducing the computational burden. And zk-DSTARK inherits zk-STARK’s feature of single proof generation for multiple uses, improving the efficiency of successive transactions. Furthermore, we propose a fair exchange system named zk-DCIAExchange for off-chain verification, which is based on zk-DSTARK and intel software guard extensions (SGX). This system not only minimizes on-chain overhead but also ensures the security and fairness of the transaction. Experimental results show that, in continuous transactions scenarios, the time overhead for subsequent transactions is diminished by 99.9% compared to the first transaction; compared to zero knowledge contingent payment (ZKCSP), our scheme achieves a remarkable 92% reduction in time overhead, and a 26.3% reduction when compared to FairSwap; with 32 distributed nodes and a trace length of 2 16 , the proof generation time is reduced by ~85.45%; the additional verification time introduced by the SGX is ~0.45 s, which is deemed acceptable, and the on-chain verification overhead is reduced by ~7.2% compared to the ZKCSP and ~54.4% compared to FairSwap.},
  archive      = {J_COMJNL},
  author       = {Zhan, Jing and Li, Bo and Zhao, Jiang and Zhao, Yong},
  doi          = {10.1093/comjnl/bxaf010},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {872-890},
  shortjournal = {Comput. J.},
  title        = {Zk-DCIAExchange: SGX protected fair exchange with distributed zero knowledge proof for data confidentiality and authentication},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing arrhythmia identification using chaos theory and deep learning analysis. <em>COMJNL</em>, <em>68</em>(8), 859-871. (<a href='https://doi.org/10.1093/comjnl/bxaf009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal heart function is crucial for quality life. Electrocardiograms are indispensable for diagnosing cardiac irregularities and analyzing heartbeat signals. This study unveils three novel machine learning (ML) techniques enhancing diagnostic precision. The first method scrutinizes raw ECG data and its time-series metrics, while the second incorporates historical patient health data for direct ECG classification. The third technique transforms ECG signals into insightful features, focusing on QRS complex waves. Uniquely combining these strategies, our research pioneers in advanced feature selection for cardiac diagnosis. Experiments were conducted to compare the integration of clinical data, QRS characteristics, and chaos preprocessing impact on the diagnosis. For classification assessment, five algorithms were utilized: Support Vector Machine, Decision Tree, Naïve Bayes, Neural Network, and Convolutional Neural Networks (CNNs). Implementing chaos theory, we converted QRS features into deterministic metrics. Notably, our Chaos-Enhanced CNN model exhibited outstanding performance, achieving a remarkable 99.8% accuracy rate, outshining other models.},
  archive      = {J_COMJNL},
  author       = {Eldakhly, Nabil M},
  doi          = {10.1093/comjnl/bxaf009},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {859-871},
  shortjournal = {Comput. J.},
  title        = {Optimizing arrhythmia identification using chaos theory and deep learning analysis},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving recommendation fairness with dependency-based graph collaborative filtering. <em>COMJNL</em>, <em>68</em>(7), 839-858. (<a href='https://doi.org/10.1093/comjnl/bxaf008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering recommendation systems that utilize graph convolutional neural networks (GCNs) often emphasize on training speed and accuracy, while overlooking the critical issue of fairness. This paper introduces FairGCF, a novel graph-based collaborative filtering model designed to address fairness concerns in GCN-based recommendations. FairGCF improves the representational capacity of graph collaborative filtering models by identifying dependencies between nodes in the graph, resulting in fairer and more accurate recommendations. The model constructs a dependency graph between users and items to capture higher order interaction patterns, aggregating features from users and items with similar dependencies to enrich their representations. Additionally, a fairness loss factor is incorporated to minimize disparities between positive and negative samples, thereby promoting fairness. Experiments on three public datasets demonstrate that FairGCF improves the Recall metric by an average of 6%, NDCG by 8.79%, Precision by 3.68%, and F1 score by 3.62%. Notably, the model is carefully designed to avoid bias toward specific users or items.},
  archive      = {J_COMJNL},
  author       = {Wen, Xiaoyang and Guan, Shaopeng},
  doi          = {10.1093/comjnl/bxaf008},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {839-858},
  shortjournal = {Comput. J.},
  title        = {Improving recommendation fairness with dependency-based graph collaborative filtering},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternating-update-strategy based graph autoencoder for graph neural network. <em>COMJNL</em>, <em>68</em>(7), 830-838. (<a href='https://doi.org/10.1093/comjnl/bxaf007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has become a promising and popular learning paradigm for graph data, offering the advantage of capturing informative knowledge without reliance on manual labels. As a representative class of generative graph SSL models, existing graph autoencoders (GAE) excel in link prediction tasks and are steadily improving in node classification tasks. However, GAE is essentially based on the Information Maximization (InfoMax) principle, always captures much redundant information. In this paper, we propose an Alternating-update-strategy based Graph Autoencoder, including alternating update module (AUM) and GAE. For AUM, we design an Alternating-update-strategy to generate a new graph with reduced redundancy, in order to reduce the amount of redundant information that the encoder may capture. For GAE, we feed it the new graph and employ a re-mask decoding strategy to generate node representations. Our model is evaluated on five common real-world datasets for the node classification task, and the experimental results demonstrate its superiority. Meanwhile, our model has also achieved excellent results in specific e-commerce warehousing application scenarios.},
  archive      = {J_COMJNL},
  author       = {Shan, Lingxiao and Li, Jian and Liu, Guanjun},
  doi          = {10.1093/comjnl/bxaf007},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {830-838},
  shortjournal = {Comput. J.},
  title        = {Alternating-update-strategy based graph autoencoder for graph neural network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TaintAttack: Rapid attack investigation based on information flow tracking. <em>COMJNL</em>, <em>68</em>(7), 813-829. (<a href='https://doi.org/10.1093/comjnl/bxaf006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The perpetual battle between defenses and attacks in computing systems keeps evolving. In response to the growing complexity of attacks, data provenance has emerged as a vital solution for analysing alarms and conducting attack investigation by capturing intricate relationships among system entities. Despite its potential, the challenges of dealing with large-scale provenance graphs and a high volume of alarms persist, leading to inefficiencies in alarm analysis and attack investigation. To tackle these challenges, we present TaintAttack, an innovative approach for attack investigation. When performing provenance graph construction, TaintAttack conducts real-time tagging for system entities. To emphasize the critical threats, TaintAttack quantifies the threat levels of alarms based on event rarity, contextual features, and impact severity. Furthermore, guided by information flow tagging, TaintAttack commences attack investigation from alarms with high threat levels, greatly enhancing the overall efficiency of the investigation process. The evaluation results on 12 multi-stage attacks show that TaintAttack performs better in attack investigation compared to existing studies, reducing the investigation time by 2 orders of magnitude.},
  archive      = {J_COMJNL},
  author       = {Pan, Yuedong and Zhao, Lixin and Leng, Tao and Li, Chaofei and Yu, Aimin and Cai, Lijun},
  doi          = {10.1093/comjnl/bxaf006},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {813-829},
  shortjournal = {Comput. J.},
  title        = {TaintAttack: Rapid attack investigation based on information flow tracking},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-fall: A YOLO-based fall detection model with high precision, shrunk size, and low latency. <em>COMJNL</em>, <em>68</em>(7), 804-812. (<a href='https://doi.org/10.1093/comjnl/bxaf005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to recent research statistics, falling has become an important factor affecting the health and safety of the elderly. To reduce the computational cost of hardware and meet the demand for real-time fall detection, we propose a lightweight fall detection network called YOLO-fall oriented for mobile and small edge computing devices. We have made the following improvements based on you only look once (YOLO). First, the backbone network is designed to be lightweight. Then, the convolution module is reparameterized and the C3 structure is improved to ensure the balance between speed and accuracy. Finally, a 5 × 5 depth convolution is added to the detection head to improve the detection ability of large targets. The proposed YOLO-fall is trained and validated on the E-FPDS public dataset and achieves a 78.4% mean average precision (mAP) with 2.45 M parameters and 12.2 GFLOPs. Compared with YOLOv5s, YOLO-fall has a 6.1% improvement in mAP and a 65.1% reduction in parameters. Although Yolov9s has a higher mAP of 82.9%, YOLO-fall reduces the parameters and calculation quantities by 74.8 and 69.2%, respectively. Therefore, the proposed YOLO-fall has the potential to accurately perform real-time fall detection on mobile and small edge computing devices.},
  archive      = {J_COMJNL},
  author       = {Zhang, Xiaoyang and Bai, Jian and Qiao, Guanchao and Xiao, Xiao and Meng, Liwei and Hu, Shaogang},
  doi          = {10.1093/comjnl/bxaf005},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {804-812},
  shortjournal = {Comput. J.},
  title        = {YOLO-fall: A YOLO-based fall detection model with high precision, shrunk size, and low latency},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CATI++: Empirical study and evaluation for adjacent instruction enhanced type inference. <em>COMJNL</em>, <em>68</em>(7), 788-803. (<a href='https://doi.org/10.1093/comjnl/bxaf004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable-type information is fundamental, and it greatly helps in understanding the program semantics. Previous work applies rule-based and machine learning-based methods to recover variable types from commercial off-the-shelf binaries, heavily relying on the data flow or control flow. However, according to our study, about half of the variables lacked or even had no data flow; this problem has not received much attention from previous work. We empirically explore the severity of this problem to the type inference task and analyze its root causes. Based on compilation properties, we find that the instructions surrounding the instructions that operate on variables provide good contextual information that can be used for co-encoding to overcome the above problem. In this paper, we present an effective machine learning-based method to infer variable types and overcome the challenge of limited data dependency via adjacent instructions co-encoding. Therefore, we implement a system called CATI++, which locates variables from stripped binaries and infers 19 types of variables. We evaluate CATI++ on different compilation options, all of which outperforms state-of-the-art methods. The ablation experiments verify that our scheme is not sensitive to compilation conditions, while our designed method effectively alleviates the problems caused by missing data dependency.},
  archive      = {J_COMJNL},
  author       = {Chen, Ligeng and He, Zhongling and Qian, Yi and Mao, Bing},
  doi          = {10.1093/comjnl/bxaf004},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {788-803},
  shortjournal = {Comput. J.},
  title        = {CATI++: Empirical study and evaluation for adjacent instruction enhanced type inference},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter-enhanced contrast variational AutoEncoders for sequential recommendation. <em>COMJNL</em>, <em>68</em>(7), 775-787. (<a href='https://doi.org/10.1093/comjnl/bxaf003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation-based contrastive learning has been successfully employed in Variational AutoEncoders sequence recommendation systems to tackle the issue of data sparsity. Nevertheless, this strategy is generally less advantageous for tail users. The prospective transmission of information from head-to-tail users to alleviate long-tail impact is encouraging. However, data augmentation distorts the original sequence and embeds stochastic noise into latent variables, impeding the decoder’s capacity to accurately identify the user’s true preferences. In addition, contrastive learning seeks to achieve consistency in the latent variables of both the original and augmented data. However, the presence of noise in the augmented data might hamper the encoding of latent variables from the original data, especially impacting head users. In order to address these challenges, this work introduces a new sequence recommendation model called the Filter-enhanced Contrastive Variational Autoencoder (FeCVAE). It employs Fourier filters and adversarial attack training to minimize the impact of stochastic noise, thereby improving the quality of latent variables and facilitating more accurate decoder outputs. Moreover, a user enhancer is introduced to leverage knowledge from head users to empower tail users, thereby alleviating the long-tail effect. The efficacy of FeCVAE is demonstrated through comprehensive experiments across four benchmark datasets.},
  archive      = {J_COMJNL},
  author       = {Chen, Zhijin and Lin, Nankai and Yang, Aimin and Zhou, Dong},
  doi          = {10.1093/comjnl/bxaf003},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {775-787},
  shortjournal = {Comput. J.},
  title        = {Filter-enhanced contrast variational AutoEncoders for sequential recommendation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RADNet: A highly and robust dynamic network for object detection in complex road scenes. <em>COMJNL</em>, <em>68</em>(7), 763-774. (<a href='https://doi.org/10.1093/comjnl/bxaf002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of low detection accuracy and redundant model parameters in the current road scene detection, a RADNet-based road scene detection algorithm is proposed. In this algorithm, an efficient backbone structure CSPResRepBlock is designed to enable the model to obtain more comprehensive target information. Secondly, a multi-feature fusion progressive pyramid is designed to significantly alleviate the elimination of target feature information during the feature fusion process. Meanwhile, a new decoupling head structure called Efficient Dynamic DCNv2 Head is designed, which significantly improves the model’s sensitivity to deformation or edge blurring features. In addition, a structured pruning algorithm is introduced to achieve network acceleration by automatically analyzing complex structural couplings and correctly removing parameters. Finally, experiments on the BDD100K dataset show that the RADNet algorithm improves the average detection accuracy mAP50 by 6.3% and reduces the number of parameters by 68.6% and the computational effort by 30.3% compared to Yolov8s. The inference speed of the model is 114.1 FPS. The model’s generalizability was evaluated using four additional publicly available datasets. These results show that the RADNet algorithm is effective and superior for the task of autopilot target detection.},
  archive      = {J_COMJNL},
  author       = {Zhao, Wenyang and Yang, Xiaoyao and Wang, Yong},
  doi          = {10.1093/comjnl/bxaf002},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {763-774},
  shortjournal = {Comput. J.},
  title        = {RADNet: A highly and robust dynamic network for object detection in complex road scenes},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical and veritable threshold multi-factor authentication for mobile devices. <em>COMJNL</em>, <em>68</em>(7), 749-762. (<a href='https://doi.org/10.1093/comjnl/bxaf001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-factor authentication (MFA) is extensively employed in mobile applications to enhance security, including Internet of Vehicles, healthcare systems, smart homes, etc. Traditional MFA requires users to present specific factors, which can be inconvenient if certain factors are unavailable. To address this, |$ (t, n) $| -threshold MFA (T-MFA) allows users to select any |$ t $| out of |$ n $| registered factors for authentication. However, existing T-MFA solutions face four key issues: (i) reliance on |$ n-1 $| devices, which may be impractical; (ii) susceptibility to denial of service when the mandatory factor fails; (iii) limited factor types, reducing user flexibility; and (iv) increasing client-side computational costs with higher |$ t $|⁠ . In this work, we propose a veritable |$ (t, n) $| -threshold multi-factor authenticated key exchange protocol that addresses these challenges. Utilizing oblivious programmable pseudorandom functions (OPPRF) as main tools, we eliminate dependence on multiple devices, mandatory factors, and restricted factor types, achieving what we called veritable. We present a new construction of batched OPPRF to reduce client-side costs from |$ O(t) $| to |$ O(1) $|⁠ , with 2 exponentiations cost by the client and |$ t+1 $| by the server. We implement it with JavaScript to validate its flexibility and efficiency, making it highly suitable for mobile device applications.},
  archive      = {J_COMJNL},
  author       = {Qin, Shihan and Xiao, Yuting and Xin, Yansen and Gao, Birou and Zhang, Rui},
  doi          = {10.1093/comjnl/bxaf001},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {749-762},
  shortjournal = {Comput. J.},
  title        = {Practical and veritable threshold multi-factor authentication for mobile devices},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlashFox: A secret-sharing approach to securing data deletion for flash-based SSD. <em>COMJNL</em>, <em>68</em>(7), 734-748. (<a href='https://doi.org/10.1093/comjnl/bxae145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ‘out-of-place’ update nature of Solid State Drives (SSDs) introduces a security risk. Scrubbing , a secure deletion method, mitigates this issue but negatively affects SSD endurance and requires redundant data for recovery due to page errors. Previously, the RAID-5 based scheme was used to manage redundant data. While effective for reading, it causes significant write latency due to the channel blocking issue. In response, we propose FlashFox, which integrates secret sharing and Reed-Solomon coding into SSDs, enabling the application of scrubbing within an encrypted storage environment. This innovation ensures secure deletion by cleaning up sensitive data, thereby reducing wear on SSD endurance. Furthermore, we have developed a RAID-4-based scheme for implementing FlashFox on SSDs. This scheme, by assigning specific channels to manage redundant data, successfully avoids the channel blocking issue prevalent in RAID-5. Experimental results show FlashFox reduces endurance wear by at least 15% compared to traditional scrubbing methods and writing response delay by at least 8 × compared to RAID-5 based scheme.},
  archive      = {J_COMJNL},
  author       = {Cheng, Wen and Tu, Shengxia and Liu, Yi and Zeng, Lingfang and Wang, Yang and Brinkmann, André},
  doi          = {10.1093/comjnl/bxae145},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {734-748},
  shortjournal = {Comput. J.},
  title        = {FlashFox: A secret-sharing approach to securing data deletion for flash-based SSD},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-world continuous smartwatch-based user authentication. <em>COMJNL</em>, <em>68</em>(7), 717-733. (<a href='https://doi.org/10.1093/comjnl/bxae144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User authentication is often regarded as the “gatekeeper” of cyber security. It has, however, long suffered from significant usability issues that have resulted in research focussing upon frictionless and transparent biometric approaches. Activity-based user authentication—a technique that authenticates a user by what they are physically doing at a specific point in time has attracted significant attention, particularly due to the increasing popularity of smartwatches. This research aims to overcome limitations in prior work by exploring the viability of the approach in real-world conditions. The study presents two principal experiments, one focused upon a constrained environment to provide a control and a second reflecting real-life. With over 1000 h of sampled data across 60 participants, the study sought to explore sensor, feature composition, and classifier design to explore the practical viability of the approach. Whilst the control experiment achieved best case Equal Error Rate of 0.29%, an improvement upon the prior art using optimisation, the best-case real-world results were not too far behind at 0.7%. This demonstrates that whilst the feature generated in the real-life experiment are subject to increased levels of noise, the performance is viable within the context of a transparent and continuous user authentication approach.},
  archive      = {J_COMJNL},
  author       = {Al-Naffakh, N and Clarke, N and Li, F and Haskell-Dowland, P},
  doi          = {10.1093/comjnl/bxae144},
  journal      = {The Computer Journal},
  month        = {7},
  number       = {7},
  pages        = {717-733},
  shortjournal = {Comput. J.},
  title        = {Real-world continuous smartwatch-based user authentication},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving LAMMPS performance for molecular dynamic simulation on large-scale HPC systems. <em>COMJNL</em>, <em>68</em>(6), 706-716. (<a href='https://doi.org/10.1093/comjnl/bxae143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale atomic/molecular massively parallel simulator (LAMMPS) is a prevalent software package employed for molecular dynamics simulations, enabling the study of materials at the atomic and molecular scale. Its performance is paramount in numerous industrial applications, driving the need for ongoing enhancements in simulation speed and parallel efficiency. Previous works heavily rely on hardware accelerators, which lead to limited parallel and high costs. To address this, this work optimizes the message passing interface (MPI) and memory copy functions, while deploying LAMMPS on high-performance computing (HPC) systems. We propose a new adaptive broadcast algorithm to improve the parallelism efficiency of the interconnect topology. We also discuss how to realize the mutual hiding of computation and communication of the Packing algorithm in LAMMPS, and optimize the memory copy function and MPI operators to facilitate the execution of the program. The resulting components are integrated into the MPICH4 software and deployed on the MT-3000 HPC system. The experimental results show a significant performance improvement, with up to four orders of magnitude speedup on 1024, and more than 90% parallel efficiencies, demonstrating the effectiveness of our proposed optimization scheme. The adaptive broadcast algorithm and the portability of computation and communication hiding are also discussed. The adaptive broadcast algorithm is applied to SPEC MPI2007, and the average performance improvement is 23.91 and 27.29% on ARMv8 cluster and x86_64 cluster, respectively.},
  archive      = {J_COMJNL},
  author       = {Qi, Du and Wang, Feng and Huang, Hui and Chen, Jinlin},
  doi          = {10.1093/comjnl/bxae143},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {706-716},
  shortjournal = {Comput. J.},
  title        = {Improving LAMMPS performance for molecular dynamic simulation on large-scale HPC systems},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature refinement and attention enhancement for click-through rate prediction. <em>COMJNL</em>, <em>68</em>(6), 697-705. (<a href='https://doi.org/10.1093/comjnl/bxae142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction has become a crucial task in online advertising and other fields. Many researchers focus on improving CTR prediction models by exploring feature interactions. One popular model, Deep Factorization Machine (DeepFM), addresses both high-order and low-order feature interactions, but it overlooks the variability of feature representation in different contexts and lacks a comprehensive explanation of high-order feature interactions. In this paper, we propose a CTR prediction model called DeepFM-GA, which is based on improved feature refinement generation and attention enhancement representation. Firstly, we incorporate an attention convolutional generation module into DeepFM FRNet ⁠ , which enriches the feature space by generating complementary features through convolutional neural networks while maintaining context-aware feature representation. Secondly, we utilize a multi-head self-attention layer for feature-enhanced representation, enhancing the model’s ability to select important features. Finally, experiments are conducted on four real-world datasets, and the results show that DeepFM-GA has a better performance compared to other mainstream CTR models.},
  archive      = {J_COMJNL},
  author       = {Li, Sumin and Xie, Zhen and Pan, Xiuqin},
  doi          = {10.1093/comjnl/bxae142},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {697-705},
  shortjournal = {Comput. J.},
  title        = {Feature refinement and attention enhancement for click-through rate prediction},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TBFL: Blockchain-enabled trusted byzantine-robust federated learning framework for photovoltaic power generation forecasting. <em>COMJNL</em>, <em>68</em>(6), 684-696. (<a href='https://doi.org/10.1093/comjnl/bxae141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise forecasting of photovoltaic (PV) power generation upholds flexibility and reliability within the power grid. Due to the data security dilemma of previous forecasting methods, federated learning (FL) has been widely studied for its ability to train models without sharing training data. However, the incorrect behavior from untrusted devices and servers in traditional FL frameworks can undermine the integrity of the global model, precipitating inaccurate power generation forecasting. Therefore, we propose a blockchain-enabled trusted Byzantine-robust FL framework, called TBFL, designed for decentralized and privacy-preserving PV power generation forecasting. Specifically, this framework features a trusted supervision mechanism, which can effectively eliminate malicious gradients to achieve a high-quality model. In addition, a multilevel differential privacy scheme is designed to strike a balance between privacy protection and model accuracy. Finally, a model clipping algorithm based on neuronal similarity is implemented to optimize both the duration and consumption associated with local device training. Comprehensive experimental outcomes demonstrate that the framework TBFL can successfully improve robustness, and achieve similar efficiency as FedAvg while maintaining a high forecasting accuracy.},
  archive      = {J_COMJNL},
  author       = {Zhang, Yan and Wang, Liangliang and Luo, Yiyuan and Zhang, Kai and Long, Yu and Chen, Kefei},
  doi          = {10.1093/comjnl/bxae141},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {684-696},
  shortjournal = {Comput. J.},
  title        = {TBFL: Blockchain-enabled trusted byzantine-robust federated learning framework for photovoltaic power generation forecasting},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attack-oblivious node protection strategy for survivable routing in airborne tactical networks under uncertainty. <em>COMJNL</em>, <em>68</em>(6), 675-683. (<a href='https://doi.org/10.1093/comjnl/bxae140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airborne tactical networks are complex networks that connect various aircraft platforms via datalink systems. In the fierce battlefield, airborne tactical networks are under the risk of hostile node attack, causing route failures and packet losses. Reliable communication in airborne tactical networks is thus calling for an efficient node protection scheme design for routing strategies. Due to the inherent uncertainty of war, the enemy’s node attack is unpredictable, making it intractable to select the optimal node set to deploy defense countermeasures under limited resource. To hedge against such uncertainty, we propose an Attack-Oblivious Node Protection Strategy (AONPS) for survivable routing in airborne tactical networks. Through a crafty-designed randomized algorithm, AONPS can select an appropriate node set to protect. Both theoretical derivation and simulation experiments demonstrate that the proposed AONPS can significantly enhance routing survival rate without accurate knowledge of the targeted attack nodes of the enemy, and achieve performance comparable to that of the ideal node protection strategy.},
  archive      = {J_COMJNL},
  author       = {Pan, Ying and Lyu, Na},
  doi          = {10.1093/comjnl/bxae140},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {675-683},
  shortjournal = {Comput. J.},
  title        = {Attack-oblivious node protection strategy for survivable routing in airborne tactical networks under uncertainty},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal selection of software reliability growth model for open-source software using weighted grey relational analysis method. <em>COMJNL</em>, <em>68</em>(6), 663-674. (<a href='https://doi.org/10.1093/comjnl/bxae139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the complexity of software development and testing environments, the establishment of software reliability growth models (SRGMs) is diverse. To date, no SRGM can be applied and implemented in all software development and testing environments. Therefore, how to choose an appropriate SRGM for software reliability evaluation in the current software development and testing environment is an important practical issue. In this study, we proposed a weighted Grey relational analysis method to select the optimal SRGMs, including closed- and open-source SRGMs, as well as perfect and imperfect debugging SRGMs. To effectively validate the effectiveness of the proposed method, we used 12 SRGMs, 11 model evaluation criteria, and 2 successive versions of open-source software fault datasets. Results of this study indicated that the proposed method can select the optimal SRGM in the current software development and testing environment. To conclude, this study has important practical significance for actual software development and testing and makes important contributions to assisting developers or testers in selecting the optimal SRGM for software reliability assessment.},
  archive      = {J_COMJNL},
  author       = {Wang, Jinyong and Zhang, Ce},
  doi          = {10.1093/comjnl/bxae139},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {663-674},
  shortjournal = {Comput. J.},
  title        = {Optimal selection of software reliability growth model for open-source software using weighted grey relational analysis method},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased training framework on deep reinforcement learning. <em>COMJNL</em>, <em>68</em>(6), 649-662. (<a href='https://doi.org/10.1093/comjnl/bxae138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep reinforcement learning (DRL), bias is systematic in asynchronous training due to different state distributions, different policies and lacking knowledge of transition probability in model-free learning. Therefore, we bring the notions of parallel executors, shared actor and central critic into DRL, and propose a general framework that enables parallel collecting, unbiased data processing and centralized training. Specifically, we employ parallel executors to obtain observations, and follow a shared policy from central thread to pass a batch of four-tuple transition slots to the critic. Simultaneously, the next state in the transition slots are fed back to executors. Then, the network parameters are updated by a central learner. A backup storage can be adopted to make the executors, actor and critic work concurrently. There exists two working modes for our framework, and several variants can be achieved to suit different environments by tuning some hyperparameters. One special case of variants is the existing DRL. Another extreme case can produce unbiased estimation of loss function whose estimation exactly matches the joint probability distribution of observations and the policy, thus avoiding the instability of importance sampling. We propose several efficient algorithms under our new framework to deal with typical discrete and continuous scenarios.},
  archive      = {J_COMJNL},
  author       = {Zhang, Huihui},
  doi          = {10.1093/comjnl/bxae138},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {649-662},
  shortjournal = {Comput. J.},
  title        = {Unbiased training framework on deep reinforcement learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAPBFT: Multilevel adaptive PBFT algorithm based on discourse and reputation models. <em>COMJNL</em>, <em>68</em>(6), 635-648. (<a href='https://doi.org/10.1093/comjnl/bxae137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional practical Byzantine fault tolerance (PBFT) consensus algorithm has limitations due to its failure to consider node credibility and its static structure, leading to reduced adaptability and increased communication overhead, particularly when dealing with Byzantine nodes. To address these issues, we propose a multilevel adaptive practical Byzantine fault tolerance algorithm (MAPBFT) based on PBFT and incorporating adaptive techniques, including a discourse power mechanism. MAPBFT initially uses a reputation model to evaluate node parameters such as past performance, reliability, availability, and response delay, providing predictive insights for the adaptive algorithm. The adaptive algorithm then employs a multi-layer perceptron to predict the reputation scores of nodes. This enables the selection of high-reputation nodes for consensus participation, narrowing the consensus scope, and reducing communication overhead. Finally, discourse power is distributed differentially based on node reputation scores. The consensus advancement criterion is modified to a threshold achieved through accumulated discourse power, focusing the system on high-reputation nodes and enhancing consensus efficiency and resistance against malicious nodes. We conducted experiments to validate MAPBFT’s performance and compared it with PBFT and APBFT. Experimental results demonstrate that MAPBFT enhances throughput, reduces response delay and communication overhead, and improves security, outperforming the other protocols.},
  archive      = {J_COMJNL},
  author       = {Wen, Xin and Yang, Xiaohui},
  doi          = {10.1093/comjnl/bxae137},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {635-648},
  shortjournal = {Comput. J.},
  title        = {MAPBFT: Multilevel adaptive PBFT algorithm based on discourse and reputation models},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vessel re-identification by a hierarchical perceptual aggregation network with inclination-aware attention. <em>COMJNL</em>, <em>68</em>(6), 617-634. (<a href='https://doi.org/10.1093/comjnl/bxae136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vessel re-identification (re-ID) is a crucial task in maritime supervision, enhancing maritime safety and improving the maritime situational awareness system. However, distinct from land-based scenarios involving vehicles or pedestrians, vessels, as enormous rigid bodies situated in the dynamic marine environment, face unique challenges such as significant variations in the scale of discriminative features and unpredictable sway. Furthermore, there is a limited number of publicly available datasets for vessel re-ID in complex backgrounds. In this paper, to overcome these challenges, a novel Hierarchical Perceptual Aggregation Network with Inclination-Aware Attention (HPAN-IAA) is proposed. HPAN-IAA comprises two main modules: the Hierarchical Perceptual Aggregation Block (HPAB) and the Inclination-Aware Attention Block (IAAB). Specifically, in HPAB, a hierarchical perceptual function is introduced to decompose visual information of vessels into discriminative features at multiple levels. These feature maps with different levels of detail from diverse network layers are then fused together by concatenation, resulting in a comprehensive feature representation that effectively integrates information across various scales. Conversely, to address the irregular variations and random omissions in discriminative feature distribution caused by unpredictable vessel sway, in IAAB, the Channel Collaborative Attention Module and the Pyramidal Spatial Attention Module are designed to adaptively extract potential discriminative features within each channel and spatial dimension, enhancing model’s ability in effectively extracting and utilizing irregularly changing discriminative features. Moreover, we propose a novel vessel re-ID dataset—VesselReID-2258. Extensive experiments conducted on VesselReID-2258 and the publicly available dataset VesselReID demonstrate that HPAN-IAA outperforms the current state-of-the-art methods,achieving superior performance with mean Average Precision scores of 0.861 and 0.823.},
  archive      = {J_COMJNL},
  author       = {Cao, Yuetian and Liu, Jin and Yu, Zijun and Li, Xingye and Wei, Lai and Wu, Zhongdai},
  doi          = {10.1093/comjnl/bxae136},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {617-634},
  shortjournal = {Comput. J.},
  title        = {Vessel re-identification by a hierarchical perceptual aggregation network with inclination-aware attention},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offset attention with seed generation for point cloud completion. <em>COMJNL</em>, <em>68</em>(6), 605-616. (<a href='https://doi.org/10.1093/comjnl/bxae135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud data acquired through 3D scanning is frequently subject to fragmentation due to the constraints of the scanner’s field of view and occlusions within the scanned object. The ensuing incompleteness in the data can significantly degrade the accuracy of subsequent computational tasks. Traditional methods for predicting complete point clouds from these fragments often fail to capture the fine-grained local details, leading to inaccurate reconstructions. In this work, we introduce a novel neural network architecture designed for point cloud completion that addresses these limitations.Our network accepts an incomplete point cloud and employs a multi-scale feature extraction module, which integrates an offset attention mechanism alongside a feature aggregation module operating across various scales. This dual approach significantly bolsters the network’s capacity to discern both local and global features inherent in the point cloud data. Furthermore, we incorporate a seed generation module within our missing point cloud generator, harnessing a hierarchical feature pyramid network to forecast the entirety of the point cloud. This innovative strategy allows our network to accurately predict the structure of missing regions.Empirical evaluations conducted on the Shapenet-Part and ModelNet10 datasets substantiate the efficacy of our proposed methodology. Our approach outperforms the state-of-the-art PF-Net algorithm, achieving a remarkable reduction in chamfer distance by 16.15 % and 41.87 % on the respective datasets. Visual inspection of the results underscores the robust generalization capabilities of our algorithm, which is particularly evident in scenarios with limited dataset sizes. It adeptly predicts the contours of the missing regions and synthesizes a more comprehensive point cloud shape.},
  archive      = {J_COMJNL},
  author       = {Li, Yuke and Wang, Yong and Jiang, Bin},
  doi          = {10.1093/comjnl/bxae135},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {605-616},
  shortjournal = {Comput. J.},
  title        = {Offset attention with seed generation for point cloud completion},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved YOLOv9 for underwater side scan sonar target detection. <em>COMJNL</em>, <em>68</em>(6), 591-604. (<a href='https://doi.org/10.1093/comjnl/bxae134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pursuit of advancing computer vision, this manuscript addresses the complex challenge of underwater object detection through a novel YOLOv9-Side scan Network (YOLOv9-SN) model. The research encapsulates the integration of Negative Sample Refinement, Attention and Convolution mix strategy, and Spatial and Channel reconstruction Convolution convolutional layers, thus enhances the model’s discriminative learning and efficiency. The incorporation of Bidirectional Feature Pyramid Network and Multi-Path Distance Intersectionover Union metrics significantly improves the performance of feature integration and object localization. Comparative analysis with established models such as Faster region-based convolutional neural network, DEtection TRansformer, and YOLOv5, along with rigorous ablation studies, demonstrates the superiority of the proposed YOLOv9-SN model. Evaluating on the zero-shot learning-sonar submarine simulation dataset, this model achieves a mAP@0.5:0.95 of 72.1%, surpassing the baseline of YOLOv9 by 3.5%. This research contributes to the enhancement of detection metrics and the advancement of side scan sonar imaging for underwater targets, emphasizing the model’s high precision and accuracy in underwater target detection.},
  archive      = {J_COMJNL},
  author       = {Yuan, Xin and Li, Jiapeng and Wang, Weiwei and Zhou, Xiaoteng and Li, Ning and Yu, Changli},
  doi          = {10.1093/comjnl/bxae134},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {591-604},
  shortjournal = {Comput. J.},
  title        = {Improved YOLOv9 for underwater side scan sonar target detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image sentiment analysis based on distillation and sentiment region localization network. <em>COMJNL</em>, <em>68</em>(6), 577-590. (<a href='https://doi.org/10.1093/comjnl/bxae133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying the emotions in images is crucial for sentiment content analysis. To detect local sentiment regions and acquire discriminative sentiment features, we propose a novel model named Distillation-guided and Contrastive-enhanced Sentiment Region Localization Network (DC-SRLN) to effectively complete image sentiment analysis. Two smart but heterogeneous SRLNs are designed first to pursue local sentiment regions. Then an innovative contrastive learning mode is implemented between global and local features to further enhance the discriminative ability of the sentiment features. Third, the enhanced global and local sentiment features are seamlessly integrated to guide each SRLN accurately capture local sentiment regions. Finally, an adaptive feature fusion module is created to fuse the heterogeneous features from the two SRLNs and generate a new multi-view multi-granularity sentiment semantics with more discriminative ability for image sentiment analysis. Extensive experimental results on three prevailing datasets, namely Twitter I, FI, and ArtPhoto, exhibit that DC-SRLN achieves satisfactory accuracies of 93.2%, 80.6%, and 78.7%, respectively, outperforming recent state-of-the-art baselines. Moreover, DC-SRLN needs less training time, demonstrating its high practicality. The code of DC-SRLN is freely available at https://github.com/Riley6868/DC-SRLN .},
  archive      = {J_COMJNL},
  author       = {Zhang, Hongbin and Feng, Ya and Yuan, Meng and Hou, Jingyi and Zhang, Jin and Li, Guangli},
  doi          = {10.1093/comjnl/bxae133},
  journal      = {The Computer Journal},
  month        = {6},
  number       = {6},
  pages        = {577-590},
  shortjournal = {Comput. J.},
  title        = {Image sentiment analysis based on distillation and sentiment region localization network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BioElectra-BiLSTM-dual attention classifier for optimizing multilabel scientific literature classification. <em>COMJNL</em>, <em>68</em>(5), 565-576. (<a href='https://doi.org/10.1093/comjnl/bxae132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Inaam ul haq, Muhammad and Li, Qianmu and Mahmood, Khalid and Shafique, Ayesha and Ullah, Rizwan},
  doi          = {10.1093/comjnl/bxae132},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {565-576},
  shortjournal = {Comput. J.},
  title        = {BioElectra-BiLSTM-dual attention classifier for optimizing multilabel scientific literature classification},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variations towards an efficient drug–drug interaction. <em>COMJNL</em>, <em>68</em>(5), 552-564. (<a href='https://doi.org/10.1093/comjnl/bxae131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Jia, Yaxun and Yuan, Zhu and Wang, Haoyang and Gong, Yunchao and Yang, Haixiang and Xiang, Zuo-lin},
  doi          = {10.1093/comjnl/bxae131},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {552-564},
  shortjournal = {Comput. J.},
  title        = {Variations towards an efficient drug–drug interaction},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing security of medical images using code-based intermittent encryption and convolutional neural network. <em>COMJNL</em>, <em>68</em>(5), 539-551. (<a href='https://doi.org/10.1093/comjnl/bxae130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Aruchamy, Prasanth and Sundarrajan, M and Choudhry, Mani Deepak and Jothi, Akshya},
  doi          = {10.1093/comjnl/bxae130},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {539-551},
  shortjournal = {Comput. J.},
  title        = {Enhancing security of medical images using code-based intermittent encryption and convolutional neural network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithm for solving quantum linear systems of equations with coherent superposition and extended applications. <em>COMJNL</em>, <em>68</em>(5), 520-538. (<a href='https://doi.org/10.1093/comjnl/bxae129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Xia, Qiqing and Zhu, Qianru and Xie, Huiqin and Yang, Li},
  doi          = {10.1093/comjnl/bxae129},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {520-538},
  shortjournal = {Comput. J.},
  title        = {Algorithm for solving quantum linear systems of equations with coherent superposition and extended applications},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verifiable attribute-based multi-keyword ranked search scheme in blockchain. <em>COMJNL</em>, <em>68</em>(5), 510-519. (<a href='https://doi.org/10.1093/comjnl/bxae128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Chen, Yang and Zhao, Chunlu and Pan, Jin and Liu, Yang},
  doi          = {10.1093/comjnl/bxae128},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {510-519},
  shortjournal = {Comput. J.},
  title        = {Verifiable attribute-based multi-keyword ranked search scheme in blockchain},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure connectivity of folded cross cubes. <em>COMJNL</em>, <em>68</em>(5), 502-509. (<a href='https://doi.org/10.1093/comjnl/bxae127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Ba, Lina and Zhang, Heping},
  doi          = {10.1093/comjnl/bxae127},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {502-509},
  shortjournal = {Comput. J.},
  title        = {Structure connectivity of folded cross cubes},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Internet of vehicles intrusion detection method based on CFS-COA feature selection and spatio-temporal feature extraction. <em>COMJNL</em>, <em>68</em>(5), 487-501. (<a href='https://doi.org/10.1093/comjnl/bxae126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Yang, Zhongjun and Zhang, Jixue and Su, Beimin},
  doi          = {10.1093/comjnl/bxae126},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {487-501},
  shortjournal = {Comput. J.},
  title        = {Internet of vehicles intrusion detection method based on CFS-COA feature selection and spatio-temporal feature extraction},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Admission control algorithm for visible light communication random access network under delay and jitter constraints. <em>COMJNL</em>, <em>68</em>(5), 479-486. (<a href='https://doi.org/10.1093/comjnl/bxae125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Sun, Hongliang and Liu, Zhihui and Wang, Chao and Li, Dan},
  doi          = {10.1093/comjnl/bxae125},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {479-486},
  shortjournal = {Comput. J.},
  title        = {Admission control algorithm for visible light communication random access network under delay and jitter constraints},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can LLMs deeply detect complex malicious queries? a framework for jailbreaking via obfuscating intent. <em>COMJNL</em>, <em>68</em>(5), 460-478. (<a href='https://doi.org/10.1093/comjnl/bxae124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Shang, Shang and Zhao, Xinqiang and Yao, Zhongjiang and Yao, Yepeng and Su, Liya and Fan, Zijing and Zhang, Xiaodan and Jiang, Zhengwei},
  doi          = {10.1093/comjnl/bxae124},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {460-478},
  shortjournal = {Comput. J.},
  title        = {Can LLMs deeply detect complex malicious queries? a framework for jailbreaking via obfuscating intent},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating training events for building cyber-physical security skills. <em>COMJNL</em>, <em>68</em>(5), 445-459. (<a href='https://doi.org/10.1093/comjnl/bxae123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMJNL},
  author       = {Vineetha Harish, Avanthika and Tam, Kimberly and Jones, Kevin},
  doi          = {10.1093/comjnl/bxae123},
  journal      = {The Computer Journal},
  month        = {5},
  number       = {5},
  pages        = {445-459},
  shortjournal = {Comput. J.},
  title        = {Generating training events for building cyber-physical security skills},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLDS: Differentially private federated learning with double shufflers. <em>COMJNL</em>, <em>68</em>(4), 431-443. (<a href='https://doi.org/10.1093/comjnl/bxae122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) often uses local differential privacy (LDP) to prevent leaking data privacy through gradients. However, due to the high dimension of gradients, LDP will encounter the problem of privacy budget explosion in the application, resulting in low accuracy of the training model. To overcome this shortcoming, we propose a differential privacy FL protocol incorporating a control matrix and double shuffles. The control matrix, generated by the analyzer, is responsible for governing the selection and upload of clients’ gradients. Double shufflers shuffle the control matrix and clients’ gradients, respectively, so that the control matrix is invisible to the server and the gradient is anonymous to the server. In addition, the existing differential private FL often uses the same clipping scale for gradients clipping to facilitate determining the noise scale. However, this will bring too many clipping errors for the large gradients and too many noise errors for the small ones. To solve these problems, we propose an adaptive clipping scheme. Experiments on the real-world datasets show that our proposed methods achieve higher testing accuracy.},
  archive      = {J_COMJNL},
  author       = {Qi, Qingqiang and Yang, Xingye and Hu, Chengyu and Tang, Peng and Su, Zhiyuan and Guo, Shanqing},
  doi          = {10.1093/comjnl/bxae122},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {431-443},
  shortjournal = {Comput. J.},
  title        = {FLDS: Differentially private federated learning with double shufflers},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FINB: A japanese named entity recognition model based on multi-feature integration method. <em>COMJNL</em>, <em>68</em>(4), 419-430. (<a href='https://doi.org/10.1093/comjnl/bxae121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a critical task in natural language processing. It extracts entity information such as person, location, and organization by predicting various categories of label types and entity spans in text. Nowadays, NER has achieved good recognition results in English text by machine learning. However, satisfactory recognition results cannot be achieved when processing text in Japanese, due to the diversity of the text composition and the particularity of the language itself. Compared with English text, which different words are marked by spaces, there is no clear separation mark between two words in Japanese. Simultaneously, Japanese text includes three types of representation methods, which is different from English text which only consists of English alphabet. In order to solve the above problems, a feature integration network with BERT called FINB is introduced in this paper based on multi-feature integration, which can integrate pronunciation features and glyph features of Japanese into the model to obtain more semantic information. The experiments for verification are conducted on the Kyoto University Web Document Leads Corpus called KWDLC and the Japanese Wikipedia dataset, which both prove that the proposed method can improve the recognition of named entities in Japanese effectively.},
  archive      = {J_COMJNL},
  author       = {Wang, Yingjie and Zhang, Chengye and Bai, Fengbo and Wang, Zumin and Qin, Jing},
  doi          = {10.1093/comjnl/bxae121},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {419-430},
  shortjournal = {Comput. J.},
  title        = {FINB: A japanese named entity recognition model based on multi-feature integration method},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TinyThunder: Enabling asynchronous byzantine fault tolerance with optimal communication efficiency. <em>COMJNL</em>, <em>68</em>(4), 407-418. (<a href='https://doi.org/10.1093/comjnl/bxae120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces TinyThunder , an asynchronous Byzantine fault tolerance (BFT) protocol designed to minimize communication overhead during inter-node message transmission. Regardless of the original transaction sizes, TinyThunder optimizes the acknowledgment overhead for a transaction to a constant size (e.g. 8 bytes). This optimization is based on a key observation in BFT systems: each transaction is redundantly stored by at least one honest node. Instead of transmitting the original transaction, TinyThunder only needs to send a specific feature value to confirm a transaction, leading to the development of our new compact reliable broadcast protocol. Additionally, we introduce a novel block compensation protocol that ensures the consistency of recovering these feature values and enables TinyThunder to achieve the desirable property of strong validity . The implementation and evaluation of TinyThunder in large-scale wide-area network environments demonstrate its superiority over the well-known HoneyBadgerBFT, with higher throughput (increased by 122%) and lower latency (reduced by 54%). Notably, TinyThunder also exhibits significant bandwidth savings for larger individual transaction sizes. For transactions of 250B in size, TinyThunder reduces bandwidth consumption by 56% compared to HoneyBadgerBFT.},
  archive      = {J_COMJNL},
  author       = {Chen, Xiaorui and Li, Xiangxue},
  doi          = {10.1093/comjnl/bxae120},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {407-418},
  shortjournal = {Comput. J.},
  title        = {TinyThunder: Enabling asynchronous byzantine fault tolerance with optimal communication efficiency},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing image dehazing method in mountaineering equipment. <em>COMJNL</em>, <em>68</em>(4), 397-406. (<a href='https://doi.org/10.1093/comjnl/bxae119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the spread of national sports awareness, more people are fond of outdoor mountaineering. Intelligent mountaineering equipment can provide some safe and convenient services for outdoor mountaineering. However, the positioning accuracy is affected by the ability of remote sensing image recognition in the background. To address the haze interference in remote sensing image positioning, the Retinex algorithm is enhanced using an atmospheric scattering model. This improved Retinex algorithm adopts a multiscale retinal enhancement algorithm with color restoration to enhance images. The Gaussian kernel function plays a filtering role, while the guided filtering is used to improve image texture and details. Test data from background remote sensing images of mountaineering equipment are used to evaluate the algorithm. Results indicate that when the entire test set is used for calculations, the normalized information entropy of I-Retinex, Retinex, generative adversarial networks, and Alex models is 0.92. The median values of normalized mean squared error and mean absolute error are 0.13 and 0.15, respectively, outperforming the contrast defogging model. There is a negative correlation between the normalized peak signal-to-noise ratio and haze noise error in each model. When the entire test set is used, the normalized average gradient of I-Retinex is 0.87, significantly higher than the comparison models. However, the I-Retinex model developed in this study lacks optimal average computation time and memory consumption data. Experimental results demonstrate that the improved haze removal model effectively removes haze from remote sensing images, supporting the remote sensing image-related service functionalities of mountaineering equipment.},
  archive      = {J_COMJNL},
  author       = {Guo, Yuanzhao and Zhang, Jun},
  doi          = {10.1093/comjnl/bxae119},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {397-406},
  shortjournal = {Comput. J.},
  title        = {Remote sensing image dehazing method in mountaineering equipment},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCDP-CRLPPM: A classified regional location privacy-protection model based on personalized clustering with differential privacy in data management. <em>COMJNL</em>, <em>68</em>(4), 372-396. (<a href='https://doi.org/10.1093/comjnl/bxae118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location data management plays a crucial role in facilitating data collection and supporting location-based services. However, the escalating volume of transportation big data has given rise to increased concerns regarding privacy and security issues in data management, potentially posing threats to the lives and property of users. At present, there are two possible attacks in data management, namely Reverse-clustering Inference Attack and Mobile-spatiotemporal Feature Inference Attack. Additionally, the dynamic allocation of privacy budgets emerges as an NP-hard problem. To protect data privacy and maintain utility in data management, a novel protection model for location privacy information in data management, Classified Regional Location Privacy-Protection Model based on Personalized Clustering with Differential Privacy (PCDP-CRLPPM), is proposed. Firstly, a twice-clustering algorithm combined with gridding is proposed, which divides continuous locations into different clusters based on the different privacy protection needs of different users. Subsequently, these clusters are categorized into different spatiotemporal feature regions. Then, a Sensitive-priority algorithm is proposed to allocate privacy budgets adaptively for each region. Finally, a Regional-fuzzy algorithm is presented to introduce Laplacian noise into the centroids of the regions, thereby safeguarding users’ location privacy. The experimental results demonstrate that, compared to other models, PCDP-CRLPPM exhibits superior resistance against two specific attack models and achieves high levels of data utility while preserving privacy effectively.},
  archive      = {J_COMJNL},
  author       = {Shi, Wenlong and Zhang, Jing and Chen, Xiaoping and Ye, Xiucai},
  doi          = {10.1093/comjnl/bxae118},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {372-396},
  shortjournal = {Comput. J.},
  title        = {PCDP-CRLPPM: A classified regional location privacy-protection model based on personalized clustering with differential privacy in data management},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive smoothing model for cardinality estimation. <em>COMJNL</em>, <em>68</em>(4), 360-371. (<a href='https://doi.org/10.1093/comjnl/bxae117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardinality estimation is a crucial component in query optimizers. After decades of research, employing autoregressive models for cardinality estimation has demonstrated remarkable accuracy. However, when queries involve attributes with large domain sizes, autoregressive model-based estimators struggle to accurately capture the data distribution, leading to poor performance. Furthermore, these models often exhibit significant errors when handling queries with low-selectivity predicates. To address these challenges, we propose a self-adaptive cardinality estimator named AdaCard. Initially, we employ a self-adaptive smoothing factor selection strategy to variably adjust the original data, thereby mitigating the impact of large domain sizes. Secondly, to correct errors stemming from Monte Carlo sampling, we utilize resampling to refine the handling of low-selectivity predicates, thereby improving accuracy. Through evaluation using four real-world benchmarks, we compared AdaCard with mainstream baselines. The final results show that our estimator has the lowest tail estimation error and improves accuracy by nearly 10 |$\times $| over the second-best method, with similar latency and model size.},
  archive      = {J_COMJNL},
  author       = {Lin, Yuming and Zhang, Yinghao and Yang, Yan and Li, You and Zhang, Jingwei},
  doi          = {10.1093/comjnl/bxae117},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {360-371},
  shortjournal = {Comput. J.},
  title        = {Self-adaptive smoothing model for cardinality estimation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized hardware implementation of SHA-256 round computation. <em>COMJNL</em>, <em>68</em>(4), 355-359. (<a href='https://doi.org/10.1093/comjnl/bxae116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SHA-256 algorithm is one of the most widely used secure hashing algorithms. The SHA-256 algorithm is implemented in hardware, and in order to ensure the integrity and authenticity of the encrypted data, this requires higher throughput and efficiency. In this paper, we propose a high-performance hardware architecture for the SHA-256 hash algorithm, which further optimizes the rearranged round computation by decomposing the critical path into two addition stages and replacing the multi-operator adder in the critical path of the algorithmic round-computing circuit with a 4-2 compressor. Based on the experimental results on field-programmable gate arrays, the obtained result shows a significant improvement in the performance of the proposed SHA-256 algorithm when compared with various existing architectures. Its maximum clock frequency is 366 MHz, with a throughput of 1990 Mbps and an improved efficiency of 1.86 Mbps per slice.},
  archive      = {J_COMJNL},
  author       = {Yao, Maoqun and Xue, Ziwei and Li, Haiwei and Shen, Shanhu},
  doi          = {10.1093/comjnl/bxae116},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {355-359},
  shortjournal = {Comput. J.},
  title        = {An optimized hardware implementation of SHA-256 round computation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relation as text: A semantic-preserving method for relational triple extraction. <em>COMJNL</em>, <em>68</em>(4), 346-354. (<a href='https://doi.org/10.1093/comjnl/bxae115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The typical aim of relational triple extraction is to identify entities along with their relations from unstructured text, which is a crucial task in information extraction. Recent methods achieve considerable performance by mining semantic associations within the input sentence but they hardly exploit the equally important semantic meaning of relations. Most methods simply represent relations as numeric labels and the rich semantic information is not fully utilized to enhance performance. To address the issue, we decompose the task into two sequential subtasks, entity pairing and relation matching, from a novel perspective and then propose a semantic-preserving model SPRel. Specifically, SPRel first extracts entity pairs associated with at least one relation, and then matches them with certain relations according to the descriptive text of relations. Comprehensive experiments on two widely used datasets demonstrate that SPRel outperforms previous methods, particularly in handling complex scenarios.},
  archive      = {J_COMJNL},
  author       = {Chen, Xinyi and Liu, Bo and Hong, Xueshu and Chen, Wangqun and Qiu, Houjie and Ma, Xingkong},
  doi          = {10.1093/comjnl/bxae115},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {346-354},
  shortjournal = {Comput. J.},
  title        = {Relation as text: A semantic-preserving method for relational triple extraction},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatGPT-driven machine learning code generation for android malware detection. <em>COMJNL</em>, <em>68</em>(4), 331-345. (<a href='https://doi.org/10.1093/comjnl/bxae114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android is a widely used operating system, primarily found on mobile phones and tablets. Applications (commonly known as “apps”) for android can be easily installed from Google Play, third-party stores, or manually using android package kit (APK) files. Due to its growing popularity, android has attracted significant attention from malicious actors deploying various forms of malware. To address this challenge, artificial intelligence-based approaches are increasingly used to protect systems from cyber-attacks. This research paper focuses on the application of ChatGPT, a powerful large language model, in cybersecurity, specifically for malware detection. It evaluates ChatGPT’s potential as an innovative tool in fighting cyber threats, exploring the process of fine-tuning ChatGPT, its performance and its limitations in malware detection tasks. The objective is to reduce the effort and time required to generate artificial intelligence-based malware detection systems, simplifying their development process. This research shows how ChatGPT can be utilized to generate code for detecting malware in structured datasets with high accuracy. The focus is not on introducing any new algorithms but on allow individuals without programming expertise to create and apply these models effectively.},
  archive      = {J_COMJNL},
  author       = {Nelson, Jordan and Pavlidis, Michalis and Fish, Andrew and Kapetanakis, Stelios and Polatidis, Nikolaos},
  doi          = {10.1093/comjnl/bxae114},
  journal      = {The Computer Journal},
  month        = {4},
  number       = {4},
  pages        = {331-345},
  shortjournal = {Comput. J.},
  title        = {ChatGPT-driven machine learning code generation for android malware detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic guided matting net. <em>COMJNL</em>, <em>68</em>(3), 322-330. (<a href='https://doi.org/10.1093/comjnl/bxae113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human matting refers to extracting human parts from natural images with high quality, including human detail information such as hair, glasses, hats, etc. This technology plays an essential role in image synthesis and visual effects in the film industry. When the green screen is not available, the existing human matting methods need the help of additional inputs (such as trimap, background image, etc.), or the model with high computational cost and complex network structure, which brings great difficulties to the application of human matting in practice. To alleviate such problems, we use a segmentation network as the foundation and use multiple branches to achieve human segmentation, contour detail extraction, and information fusion. We also propose a foreground probability map module, which uses the feature maps in the segmentation network to pre-estimate the foreground probabilities of each pixel and obtain Semantic Guided Matting Net. Under the condition that only a single image is needed as the input, the human matting task can be realized by making full use of the semantic information in the image. We validate our method on the P3M-10k dataset. Compared with the benchmark, our method has made significant improvements in various evaluation indicators.},
  archive      = {J_COMJNL},
  author       = {Song, Qing and Sun, Wenfeng and Yang, Donghan and Hu, Mengjie and Liu, Chun},
  doi          = {10.1093/comjnl/bxae113},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {322-330},
  shortjournal = {Comput. J.},
  title        = {Semantic guided matting net},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image forgery localization integrating multi-scale and boundary features. <em>COMJNL</em>, <em>68</em>(3), 306-321. (<a href='https://doi.org/10.1093/comjnl/bxae112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image forgery localization identifies tampered regions within an image by extracting distinctive forgery features. Current methods mainly use convolutional neural networks (CNNs) to extract features. However, CNNs’ limited receptive field emphasizes local features, impeding the global modeling of crucial lower-level features like edges and textures, leading to decreased precision. Moreover, prior methods use pyramid networks for multi-scale feature extraction but show deficiencies in multi-scale and interlayer modeling, leading to inadequate multi-scale information representation and limiting flexibility to tampered regions of varying sizes. To address these issues, this paper proposes a Transformer-based model integrating multi-scale and boundary features. The model employs a Pyramid Vision Transformer as the encoder, using self-attention over convolution to enhance global context modeling. Building on this, the model incorporates a multi-scale feature enhancement module that enriches forgery features by paralleling various convolutional layers. Features at various encoder stages are integrated through a cross-stage interaction module, enabling multi-level feature correlation for a strong feature representation. Furthermore, the model includes a forgery boundary information-guided branch, which focuses precisely on tampered region structures without introducing irrelevant noise. Experiments demonstrate that our model surpasses previous methods in localization accuracy, with F1 and AUC improving by 8.5% and 2.2% in pre-training, respectively.},
  archive      = {J_COMJNL},
  author       = {Yang, Xinyan and Zhang, Rongchuan and Li, Shao and Liang, Gang},
  doi          = {10.1093/comjnl/bxae112},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {306-321},
  shortjournal = {Comput. J.},
  title        = {Image forgery localization integrating multi-scale and boundary features},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error and attack vulnerability of apollonian networks. <em>COMJNL</em>, <em>68</em>(3), 283-305. (<a href='https://doi.org/10.1093/comjnl/bxae111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines the resilience of different Apollonian network (AN) types—deterministic, random, and evolutionary—to systematic attacks. ANs, members of the family of maximal planar graphs, possess unique properties such as high clustering coefficients, small-world properties, scale-free behavior, Euclidean and space-filling properties, and modularity. These peculiarities require a thorough investigation of their robustness. This work presents a novel approach to studying ANs by implementing evolutionary Apollonian networks (EANs). These EANs include various probabilities distribution functions, including exponential, degenerate, logistic, Pareto, and stable (Cauchy, Lévy, Normal) distributions. To improve the robustness of these networks, we propose a novel edge rewiring mechanism using a genetic algorithm (GA). The GA aims to optimize a combined metric that includes the Flow Robustness of Degree (SFRD), Betweenness (SFRB), and Dangalchev's closeness (SFRC) centralities while preserving the original degree distribution and structural properties of the network. To evaluate the effectiveness of this approach, we use various robustness measures to assess the resilience of different AN types. The results show that SFRB, SFRD, and SFRC effectively rank ANs based on their robustness.},
  archive      = {J_COMJNL},
  author       = {Safaei, Farshad and Kouchak, Mohammad Mahdi Emadi},
  doi          = {10.1093/comjnl/bxae111},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {283-305},
  shortjournal = {Comput. J.},
  title        = {Error and attack vulnerability of apollonian networks},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A resource-aware workload scheduling method for unbalanced GEMMs on GPUs. <em>COMJNL</em>, <em>68</em>(3), 273-282. (<a href='https://doi.org/10.1093/comjnl/bxae110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GEMM (General Matrix Multiplication) serves as a fundamental operator for deep learning computations. Especially in attention-based deep learning models, such as Bert, GPT, and SAM, the sizes of matrices involved in GEMMs exhibit an unbalanced distribution due to the variable input, resulting in the low utilization of hardware resources. To address the issue, this paper proposes inserting a novel GEMM processing layer into the deep learning inference stack and using an adaptive load balancing method to partition and schedule GEMM computation tasks. The method is implemented with hardware runtime resource information, such as the occupancy of computing units, etc. Experiment results show the remarkable performance of our method in unbalanced input GEMM scenarios, achieving an average performance improvement of 2.3x. The method also performs well in attention-based models (GPT-2 and SAM), achieving an average inference speed improvement of 1.1x. These findings highlight the effectiveness of resource-aware algorithm optimization, especially for computation task scheduling.},
  archive      = {J_COMJNL},
  author       = {Liu, Hangda and Diao, Boyu and Chen, Wenxin and Xu, Yongjun},
  doi          = {10.1093/comjnl/bxae110},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {273-282},
  shortjournal = {Comput. J.},
  title        = {A resource-aware workload scheduling method for unbalanced GEMMs on GPUs},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Game on: A performance comparison of interpolation techniques applied to shamir’s secret sharing. <em>COMJNL</em>, <em>68</em>(3), 261-272. (<a href='https://doi.org/10.1093/comjnl/bxae109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public-key encryption is typically managed through a public key infrastructure. However, it relies on a central control point, the certification authority, which acts as a single point of failure. Recent technological advancements have led to the need for decentralized cryptographic protocols. This paper presents a comprehensive study on enhancing public-key encryption via threshold cryptography and multiparty computation to ensure robust security in decentralized systems. The focus lies in exploring various polynomial interpolation techniques within Shamir’s secret sharing scheme, particularly addressing the efficiency and practicality of Newton interpolation, fast Fourier transformation (FFT), and advanced versions of Lagrange’s method. Utilizing SageMath for a dedicated testing environment, the research investigates the swiftest interpolation methods for secret recovery, introducing new shares into the system, and evaluating the impact of optimizations on performance. The findings highlight FFT as the most effective interpolation method in speed and efficiency, albeit with limitations on the number of shares that can be processed. This paper critically evaluates these interpolation techniques against practical constraints and aims to answer pivotal research questions regarding the optimal approach for large-scale scenarios, challenging existing notions on the efficiency of Newton’s method and providing experimental evidence to support the superiority of FFT in specific contexts.},
  archive      = {J_COMJNL},
  author       = {Voudouris, Anastassis and Tressos, Aristomenis and Zarras, Apostolis and Xenakis, Christos},
  doi          = {10.1093/comjnl/bxae109},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {261-272},
  shortjournal = {Comput. J.},
  title        = {Game on: A performance comparison of interpolation techniques applied to shamir’s secret sharing},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRAN: A SDN intrusion detection model based on graph attention network and residual learning. <em>COMJNL</em>, <em>68</em>(3), 241-260. (<a href='https://doi.org/10.1093/comjnl/bxae108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the landscape of computer networks has witnessed the advent of a transformative architectural paradigm, termed Software Defined Networking (SDN). This innovative architecture endeavors to confront and transcend the intrinsic limitations of traditional network frameworks, while its burgeoning deployment of SDN simultaneously introduces additional complexities to network security. Therefore, this paper focuses on the detection of abnormal behavior in SDN as well as identification of different network attack types. First of all, we propose a feature processing method for the high-dimensional data of SDN network traffic. Secondly, we introduce a new intrusion detection solution for SDN, i.e. Graph Residual Attention Network (GRAN), which leverages the available graph information to integrate attention mechanism and residual learning into Graph Neural Networks. Finally, we implement our proposed model as well as other standard intrusion detection models to detect different intrusion types on InSDN dataset. The simulation results show that our proposed model has better performance than other comparative models, in both binary and multi-class classification problems. More specifically, our proposed GRAN model achieves an accuracy of 97.1% on multi-class classification problems, and detects each type of network attack accurately with the precision greater than 81%.},
  archive      = {J_COMJNL},
  author       = {Zhang, Yue and Jue, Chen and Liu, Wanxiao and Ma, Yurui},
  doi          = {10.1093/comjnl/bxae108},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {241-260},
  shortjournal = {Comput. J.},
  title        = {GRAN: A SDN intrusion detection model based on graph attention network and residual learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UeLP: Accurate user linkage across social platforms against location errors. <em>COMJNL</em>, <em>68</em>(3), 228-240. (<a href='https://doi.org/10.1093/comjnl/bxae107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User linkage across social platforms can connect the accounts of the same user across different social networks, which is crucial for the identification of users’ multiple social identities and cross-platform association analysis. Cross-platform user linkage based on location is a typical method in current research. These methods typically rely on check-in data to calculate user similarity. However, different from check-in location, the location data obtained from instant messaging social platforms may contain random errors, leading to low accuracy of user linkage of such methods. To solve this problem, this paper proposes an accurate user linkage method across social platforms against location errors. First, unlike existing methods that employ fixed-size grids, this paper uses a multi-grained spatio-temporal grid to organize data, in order to accurately extract user features from error locations. Then, by extracting coarse-grained movement pattern features from user trajectories, candidate users are filtered out, and a small subset of candidate uses is generated to effectively reduce the search space. Next, we establish a weight model based on grid contribution and motion sequence similarity to extract location and temporal features with stronger user orientation. Finally, according to the weight model, the weighted cluster center distance of trajectories is used to calculate the similarity between two different user trajectories. The user with the highest similarity is selected from the candidate subset to complete the user linkage. The extensive experiments are conducted on six public datasets containing 115 866 trajectories and a self-built dataset with 5358 trajectories. The results show the following: compared with the four existing typical location-based methods |$k$| -BCT, GS, TF-IDF, and TF-IWF, the accuracy Acc@1 is improved by an average of 33%, 44.94%, 15.2%, and 14.55%, respectively, and the accuracy Acc@3 is improved by 30.52%, 34.67%, 13.84%, and 13.19%, respectively.},
  archive      = {J_COMJNL},
  author       = {Liu, Ruiting and Li, Ruixiang and Shi, Wenqi and Du, Shaoyong and Liu, Yimin and Luo, Xiangyang},
  doi          = {10.1093/comjnl/bxae107},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {228-240},
  shortjournal = {Comput. J.},
  title        = {UeLP: Accurate user linkage across social platforms against location errors},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure fault detection for digital microfluidic biochips. <em>COMJNL</em>, <em>68</em>(3), 217-227. (<a href='https://doi.org/10.1093/comjnl/bxae106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among all the modern technological advances, digital microfluidic biochip has been extending a salient solution to healthcare and bio-laboratories with the pledge of high sensitivity and reconfigurability. Such biochip devices fulfill the requirement of a faster testing kit for the detection of different novel diseases, which is indispensable in the market due to the tremendously disrupted scenario of healthcare systems. To eliminate erroneous testing, the current scope of digital microfluidic biochips is widened as a viable testing method using various bioprotocols with a reduced cost in developing countries. This paper addresses the existing security challenges and operational faults in the identification mechanism of proteins such as severe acute respiratory syndrome coronavirus 2 spike protein in state-of-the-art digital microfluidic biochips. We are the first to propose a safety detection solution along with a fault identification algorithm using an inductive transfer learning model. Experimental results of the proposed model register a threshold accuracy of 98% while applying the own dataset. This work will provide a better security-enabled fault-free safety assurance framework against attack and fault identification with better accuracy in digital microfluidic biochips for the detection of different diseases and many other healthcare diagnoses, without any overhead of completion time for bioprotocols.},
  archive      = {J_COMJNL},
  author       = {Ranjan Behera, Rakesh and Gountia, Debasis},
  doi          = {10.1093/comjnl/bxae106},
  journal      = {The Computer Journal},
  month        = {3},
  number       = {3},
  pages        = {217-227},
  shortjournal = {Comput. J.},
  title        = {A secure fault detection for digital microfluidic biochips},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data transmission optimization based on multi-objective deep reinforcement learning. <em>COMJNL</em>, <em>68</em>(2), 201-215. (<a href='https://doi.org/10.1093/comjnl/bxae105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneously reducing network energy consumption and delay is a hot topic today. This paper addresses this issue by designing a novel multi-objective data transmission optimization algorithm based on deep reinforcement learning. A three-layer back propagation (BP) neural network is designed to improve the accuracy of environmental state prediction, by learning from historical state and action sequence data, which can help the agent make better decision for routing selection in complex network environment. Based on this, we use Q-Learning to find routing for transmission demands, aggregating more traffic through less links and routers, to reduce energy consumption and delay. To enhance the efficiency and robustness of the algorithm, a new reward mechanism is designed based on the traffic demand and the link state. The algorithm divides candidate links into three levels for path selection so that a better solution can be obtained on the basis of ensuring feasible solutions are obtained. Continuous updating of the Pareto set through multiple state steps approximates the optimal solution. We leverage the Euclidean distance to the reference point to measure the optimization effect of the two objectives. The simulation results show that this algorithm outperforms existing algorithms in reducing energy consumption and network delay.},
  archive      = {J_COMJNL},
  author       = {Wang, Cuiping and Li, Xiaole and Tian, Jinwei and Yin, Yilong},
  doi          = {10.1093/comjnl/bxae105},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {201-215},
  shortjournal = {Comput. J.},
  title        = {Data transmission optimization based on multi-objective deep reinforcement learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAAChain: Release and storage platform of digital works based on non-fungible tokens. <em>COMJNL</em>, <em>68</em>(2), 187-200. (<a href='https://doi.org/10.1093/comjnl/bxae104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth in the speed and convenience of information dissemination has made copyright infringement increasingly common. Blockchain technology solves pain points such as difficulties in traditional copyright registration, easy infringement, and difficulties in confirming and safeguarding rights. It also realises the decentralised management of copyright, network-wide tracking and monitoring, trusted certificate deposits, among others. However, the efficient original authentication of works and the function of blockchain to create copyright trading channels in the field of copyright are often ignored. This paper designed a self-adaptive learning similarity detection fusion strategy to protect the copyright of original digital works, namely SAAChain, and built a platform for releasing and storing original works based on non-fungible tokens. SAAChain first measures the similarity of a work based on adaptive learning to realise the originality authentication of works. Secondly, the works are stored on the InterPlanetary File System as NFTs, along with copyright information. Finally, a smart contract based on Ethereum and ERC-721 is designed to realise the free circulation of digital rights while simultaneously constructing an efficient and convenient digital rights protection system. Experiments show that the accuracy of the fusion strategy for adaptive work similarity detection can reach above 97%, which meets the requirements of work originality verification. Because of the storage mode of the platform, the system has good performance in terms of response speed and storage efficiency. The entire process provides a full-process and transparent transaction platform for all parties and guarantees the copyright ownership of works as well as the non-tampering and traceability of copyright information.},
  archive      = {J_COMJNL},
  author       = {Liu, Jianan and Wang, Yongjuan and Lu, Siqi and Yu, Gang and Wang, Xiangyu and Feng, Peixuan},
  doi          = {10.1093/comjnl/bxae104},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {187-200},
  shortjournal = {Comput. J.},
  title        = {SAAChain: Release and storage platform of digital works based on non-fungible tokens},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Device placement using laplacian PCA and graph attention networks. <em>COMJNL</em>, <em>68</em>(2), 175-186. (<a href='https://doi.org/10.1093/comjnl/bxae102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth in data and parameters in modern neural networks has created the need to distribute these models across multiple devices for efficient training, resulting in the device placement problem. Existing graph encoding approaches for device placement suffer from low efficiency when searching for optimal parallel strategies, primarily due to suboptimal positional information retrieval. To address these challenges, we propose the Laplacian Principal Component Analysis-graph attention networks (LPCA-GAT) model. Firstly, we employ GAT to capture complex relationships between nodes and generate node encodings. Secondly, we leverage LPCA on the graph Laplacian matrix to extract crucial low-dimensional positional information. Finally, by integrating these two components, we obtain the final node encodings. This enhances the representation capability of nodes within the graph, enabling efficient device placement. The experimental results demonstrate that LPCA-GAT achieves superior device placement results, specifically accelerating execution and computation time by 13.24% and 96.38%, respectively, leading to significant improvements in both operational efficiency and performance.},
  archive      = {J_COMJNL},
  author       = {Han, Meng and Zeng, Yan and Shu, Hao and Yue, Lupeng and Zhang, Jilin and Wan, Jian and Ren, Yongjian},
  doi          = {10.1093/comjnl/bxae102},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {175-186},
  shortjournal = {Comput. J.},
  title        = {Device placement using laplacian PCA and graph attention networks},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A clustering ensemble algorithm for handling deep embeddings using cluster confidence. <em>COMJNL</em>, <em>68</em>(2), 163-174. (<a href='https://doi.org/10.1093/comjnl/bxae101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensemble, which aims to learn a robust consensus clustering from multiple weak base clusterings, has achieved promising performance on various applications. With the development of big data, the scale and complexity of data is constantly increasing. However, most existing clustering ensemble methods typically employ shallow clustering algorithms to generate base clusterings. When confronted with high-dimensional complex data, these shallow algorithms fail to fully utilize the intricate features present in the latent data space. As a result, the quality and diversity of the generated base clusterings are insufficient, thus affecting the subsequent ensemble performance. To address this issue, we propose a novel clustering ensemble algorithm for handling deep embeddings using cluster confidence (CEDECC) to improve the robustness and performance. Instead of simply combining deep clustering with clustering ensembles, we take into consideration that the performance of existing deep clustering methods heavily relies on the quality of low-dimensional embeddings generated during the pre-training stage. The quality of embeddings is unstable due to the influence of different initialization parameters. In CEDECC, specifically, we first construct a cluster confidence measure to evaluate the quality of low-dimensional embeddings. Typically, high-quality low-dimensional embeddings yield accurate clustering results with the same model parameters. Then, we utilize multiple high-quality embeddings to generate the base partitions. In the ensemble strategy phase, we consider the cluster-wise diversity and propose a novel ensemble cluster estimation to improve the overall consensus performance of the model. Extensive experiments on three benchmark datasets and four real-world biological datasets have demonstrated that the proposed CEDECC consistently outperforms the state-of-the-art clustering ensemble methods.},
  archive      = {J_COMJNL},
  author       = {Zeng, Lingbin and Yao, Shixin and Liu, Xinwang and Xiao, Liquan and Qian, Yue},
  doi          = {10.1093/comjnl/bxae101},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {163-174},
  shortjournal = {Comput. J.},
  title        = {A clustering ensemble algorithm for handling deep embeddings using cluster confidence},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison of reserved graph grammar and edge-based graph grammar. <em>COMJNL</em>, <em>68</em>(2), 145-162. (<a href='https://doi.org/10.1093/comjnl/bxae100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-sensitive graph grammars are natural formalisms for the generation and parsing of visual programming languages. Being intuitive, rigorous, and expressive tools, they have been frequently employed in a wide range of research fields. Nevertheless, the expressive powers of the existing context-sensitive formalisms have not been investigated yet. To this end, this paper is dedicated to the comparison of expressive powers of the two prevalent graph grammar formalisms, Reserved Graph Grammar (RGG) and Edge-based Graph Grammar (EGG). By introducing a special variant of RGG as an intermediary, the relation between them concerning the expressive power is revealed that the set of graph languages of EGG is a proper subset of that of RGG. Moreover, bidirectional transformations between EGG and the variant of RGG are accordingly established, allowing them to take the advantages of each other in applications.},
  archive      = {J_COMJNL},
  author       = {Zou, Yang},
  doi          = {10.1093/comjnl/bxae100},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {145-162},
  shortjournal = {Comput. J.},
  title        = {A comparison of reserved graph grammar and edge-based graph grammar},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image classification with deconvolution operation and augmentation. <em>COMJNL</em>, <em>68</em>(2), 135-144. (<a href='https://doi.org/10.1093/comjnl/bxae099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several image classification approaches have been evolved over the years utilizing convolutional neural network (CNN). In convolution operation of CNN, the shifting of kernels to overlapping regions of the image learns redundant data as the images are strongly correlated in reality. The redundant data make the neural network training a challenging task. Again, Deep Learning methods evaluated on small dataset yields degraded performance. To deal with these issues, a proposal is made in this paper that uses deconvolution operation to minimize correlations from images and data augmentation technique to increase the size of datasets. Plant Village, Tomato, and Covid-19 datasets were used for evaluating the performance of the proposed method. 70% of the datasets were used for training, 10% for validation, and 20% for testing purposes. The CIFAR10, MNIST, and Mini-ImageNet datasets were also considered for performance evaluation. The proposed method performed better than other existing methods in terms of classification accuracy.},
  archive      = {J_COMJNL},
  author       = {Kumar Sarkar, Nayan and Marjit Singh, Moirangthem and Nandi, Utpal},
  doi          = {10.1093/comjnl/bxae099},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {135-144},
  shortjournal = {Comput. J.},
  title        = {Image classification with deconvolution operation and augmentation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The h-faulty-block connectivity of k-ary n-cubes. <em>COMJNL</em>, <em>68</em>(2), 126-134. (<a href='https://doi.org/10.1093/comjnl/bxae098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connectivity of a network is an important indicator for assessing its reliability and fault tolerability. However, currently various kinds of connectivity do not well reflect the network’s fault tolerance when facing certain attacks such as Botnet attacks, DDoS attacks, and Local Area Network Denial attacks. Therefore, Lin et al . (A novel measurement for network reliability. IEEE Trans Comput 2021; 70: 17191731.) proposed a new measurement for network reliability. This measurement method can resist the block attack by taking into account of the dispersity of the remaining nodes. Let |$G$| be a network, |$C \subset V(G)$|⁠ , and |$G[C]$| be a connected subgraph. Then |$C$| is called an |$h$| -faulty-block of |$G$| if |$G-C$| is disconnected, and every component of |$G-C$| has at least |$h+1$| nodes. The minimum cardinality over all |$h$| -faulty-block of |$G$| is called |$h$| -faulty-block connectivity, denoted by |$FB_{k_{h}}(G)$|⁠ . In this paper, we determine |$FB_{k_{h}}(Q_{n}^{k})$| for |$k$| -ary |$n$| -cube |$Q_{n}^{k}$| ( ⁠|$k\geq 3$|⁠ ), a classic interconnection network. We prove that |$FB_{k_{0}}(Q_{n}^{3})=3n-1$|⁠ , |$FB_{k_{1}}(Q_{n}^{3})=5n-4$|⁠ , and |$FB_{k_{2}}(Q_{n}^{3})=7n-9$| for |$n\geq 3$|⁠ . Also, we show that |$FB_{k_{0}}(Q_{n}^{k})=4n-1$| for |$k\geq 4$| and |$n\geq 2$|⁠ , |$FB_{k_{1}}(Q_{n}^{4})=6n-4$| for |$n\geq 3$|⁠ , |$FB_{k_{1}}(Q_{n}^{k})=6n-3$| for |$k\geq 5$| and |$n\geq 3$|⁠ , |$FB_{k_{2}}(Q_{n}^{4})=8n-7$| for |$n\geq 4$|⁠ , |$FB_{k_{2}}(Q_{n}^{5})=8n-6$| for |$n\geq 4$|⁠ , and |$FB_{k_{2}}(Q_{n}^{k})=8n-5$| for |$k\geq 6$| and |$n\geq 5$|⁠ .},
  archive      = {J_COMJNL},
  author       = {Hua, Xiaohui and Zhao, Qin},
  doi          = {10.1093/comjnl/bxae098},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {126-134},
  shortjournal = {Comput. J.},
  title        = {The h-faulty-block connectivity of k-ary n-cubes},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProInfer: Inference of binary protocol keywords based on probabilistic statistics. <em>COMJNL</em>, <em>68</em>(2), 109-125. (<a href='https://doi.org/10.1093/comjnl/bxae096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protocol reverse engineering is crucial in normative verification, and malware behavior analysis and vulnerability discovery. However, uncovering the structural features of binary protocols concealed within dense data representations remains a significant challenge. Accurately identifying keyword segments associated with message types is a prerequisite for meaningful semantic analysis and protocol state machine reduction. In this work, we introduce a novel approach for inferring keywords from binary protocols based on probabilistic statistics. Our method in terms of Byte employs heuristic rules to filter offset positions that are clearly unrelated to message types. We further filter candidate Byte-offsets utilizing constraint relations and provide the probabilistic ranking of each offset as the keyword segment. To enhance the reliability of keyword segment inference, we utilize the Monte Carlo algorithm to assess the difference between message clustering with candidate Byte-offset and random message clustering, and reorder candidate offsets according to the results. Then we can observe optimal values from both orderings and present the ultimate inference results. Experimental results demonstrate that our method excels in the accuracy of keyword segments identification compared with previous techniques.},
  archive      = {J_COMJNL},
  author       = {Guo, Maohua and Zhu, Yuefei and Fei, Jinlong},
  doi          = {10.1093/comjnl/bxae096},
  journal      = {The Computer Journal},
  month        = {2},
  number       = {2},
  pages        = {109-125},
  shortjournal = {Comput. J.},
  title        = {ProInfer: Inference of binary protocol keywords based on probabilistic statistics},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on convex resource allocation scheduling with exponential time-dependent learning effects. <em>COMJNL</em>, <em>68</em>(1), 97-108. (<a href='https://doi.org/10.1093/comjnl/bxae095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses two scheduling problems with resource allocations and learning effects on a single machine, meaning the actual processing time of a job is a nonincreasing and continuous function of the total job parameter relating to the processed jobs and the amount of resource allocation. Our first problem is to find a job sequence and resource allocations that lead to a minimization of the weighted sum of total completion-time cost and total resource-consumption cost. The second problem is to minimize the total completion-time cost subject to the total resource-consumption cost is bounded. For a special case, we prove that both these problems are polynomially solvable. Generally, we propose some heuristic algorithms and a branch-and-bound algorithm to solve the problems.},
  archive      = {J_COMJNL},
  author       = {Zhang, Li-Han and Yang, Shu-Han and Lv, Dan-Yang and Wang, Ji-Bo},
  doi          = {10.1093/comjnl/bxae095},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {97-108},
  shortjournal = {Comput. J.},
  title        = {Research on convex resource allocation scheduling with exponential time-dependent learning effects},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable broadcasting-based content acquisition for named data MANETs. <em>COMJNL</em>, <em>68</em>(1), 84-96. (<a href='https://doi.org/10.1093/comjnl/bxae094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional IP-based unicast routing cannot utilize the inherent broadcast property of wireless network, and unicast path can be broken down frequently due to node mobility. Based on the nature of named data networking (NDN) which faces “content” rather than “host”, broadcast mode can be applied for content delivery in named data mobile ad hoc networks (ND-MANETs). However, since there are no acknowledgment and retransmission mechanisms in the broadcast mode of IEEE 802.11 protocol, it would cause the problem of transmission unreliability. Moreover, if all forwarding nodes transmit packet concurrently, it can easily lead to collision and redundancy. This paper presents a reliable broadcasting-based content acquisition scheme for highly dynamic ND-MANETs, which makes full use of the inherent broadcast nature of wireless network, and solves the unreliability, collision, and redundancy problems. We define Transmission Reliability Degree ( ⁠|$TRD$|⁠ ) for broadcast mode, and estimate its value through Markov model. A content-oriented and |$TRD$| of sending node-based resend algorithm is proposed to improve reliability of broadcast transmission. An area divided and |$TRD$| of receiving node-based reforwarding algorithm is proposed to reduce collision and redundancy. Simulation results demonstrate the effectiveness and efficiency of the proposed mechanism.},
  archive      = {J_COMJNL},
  author       = {Kuang, Jian and Xie, Bailin and Luo, Jianzhen and Li, Jianhong},
  doi          = {10.1093/comjnl/bxae094},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {84-96},
  shortjournal = {Comput. J.},
  title        = {Reliable broadcasting-based content acquisition for named data MANETs},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum fault-free enforcement in petri nets using supervisory control. <em>COMJNL</em>, <em>68</em>(1), 74-83. (<a href='https://doi.org/10.1093/comjnl/bxae093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis and maximum fault-free execution are essential for the development and operation of computer-integrated systems covering aircraft systems, power grid systems, production processes, etc. This paper focuses on the problem of fault diagnosis and maximum fault-free enforcement of systems modeled by labelled Petri nets. Given a system modeled by a labelled Petri net that may enter deadlocks, an extended basis reachability graph that contains sufficient information to characterize deadlocks is used to compress the state space and verify the diagnosability for the considered system. Furthermore, the proposed graph offers sufficient and necessary conditions for fault-free enforcement and deadlock-free enforcement. Finally, a lock-free event set and a supervisor are designed for a system such that any possible fault or dead behaviour is prohibited in the controlled system.},
  archive      = {J_COMJNL},
  author       = {Zheng, Juhong and Zhang, Lei and Zhang, Jingbo and Lv, Meibo},
  doi          = {10.1093/comjnl/bxae093},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {74-83},
  shortjournal = {Comput. J.},
  title        = {Maximum fault-free enforcement in petri nets using supervisory control},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid architecture for secure data sharing in multi-clouds system. <em>COMJNL</em>, <em>68</em>(1), 58-73. (<a href='https://doi.org/10.1093/comjnl/bxae092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is one of the most cutting-edge technologies around the world that plays a major role in IT industries and personal use. Several sectors are showing efforts in adopting cloud computing to their services, considering the provided cost reduction and process efficiency. However, outsourcing users’ sensitive data increases the concerns regarding the security, privacy and integrity of stored data. Therefore, there is a need to build a trusting relationship between users and cloud systems. Hence, in this paper, we propose a privacy-preserving framework, called Hybrid and Secure Data Sharing Architecture (HSDSA), for secure data storage in cloud systems. The basic idea of HSDSA is to improve data security in a multi-cloud environment using a combination of cryptography techniques. These techniques ensure that the user has total control over the data generation and management of the decryption without relying on a trusted authority. HSDSA provides removal of centralized file storage distribution and ensures data integrity in the recovery process. We evaluate our contribution under Cloudera, and the results demonstrate the efficiency of HSDSA compared with the existing system.},
  archive      = {J_COMJNL},
  author       = {Hajlaoui, Nasreddine and Bejaoui, Chaima and Ismail, Tayssir and Ghanmi, Houaida and Touati, Haifa},
  doi          = {10.1093/comjnl/bxae092},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {58-73},
  shortjournal = {Comput. J.},
  title        = {A hybrid architecture for secure data sharing in multi-clouds system},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disjoint paths construction algorithm in the data center network DPCell. <em>COMJNL</em>, <em>68</em>(1), 47-57. (<a href='https://doi.org/10.1093/comjnl/bxae091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the fourth industrial revolution, the importance of data centers has significantly increased. Data centers are widely used in many fields due to their ability to provide efficient, secure, and reliable data storage and processing services. However, with the increasing amount of data, traditional data center networks (DCNs) are currently facing various challenges, prompting academia and industry to propose new DCN architectures. As a dual-port server-based DCN, DPCell has excellent scalability and bisection width, enabling it to meet the demands of large-scale data storage, processing, and computation in the digital revolution. In order to ensure the secure and reliable data communication in the DPCell, this paper designs a disjoint paths communication scheme based on the actual DCN routing requirements. This scheme constructs the optimal number of disjoint paths in DPCell, with a maximum path length of |$2^{k}+3$|⁠ , where |$k$| represents the dimension of the DPCell. Furthermore, experiments have verified that the time complexity of this scheme is sublinear, making it more efficient than the current optimal maximum flow algorithm. To a certain extent, this scheme provides DPCell with the required high bandwidth, fault tolerance, and security for data communication.},
  archive      = {J_COMJNL},
  author       = {Dong, Hui and Wang, Huaqun and Lv, Mengjie and Fan, Weibei},
  doi          = {10.1093/comjnl/bxae091},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {47-57},
  shortjournal = {Comput. J.},
  title        = {Disjoint paths construction algorithm in the data center network DPCell},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering-based compression for raster time series. <em>COMJNL</em>, <em>68</em>(1), 32-46. (<a href='https://doi.org/10.1093/comjnl/bxae090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A raster time series is a sequence of independent rasters arranged chronologically covering the same geographical area. These are commonly used to depict the temporal evolution of represented variables. The |$T$| - |$k^{2}$| -raster is a compact data structure that performs very well in practice for compact representations for raster time series. This structure classifies each raster as a snapshot or a log and encodes logs concerning their reference snapshots, which are the immediately preceding selected snapshots. An enhanced version of the |$T$| - |$k^{2}$| -raster, called Heuristic |$T$| - |$k^{2}$| -raster, incorporates a heuristic for automating the selection of snapshots. In this study, we investigate the optimality of the heuristic employed in Heuristic |$T$| - |$k^{2}$| -raster by comparing it with a dynamic programming (DP) approach. Our experimental evaluation demonstrates that Heuristic |$T$| - |$k^{2}$| -raster is a near-optimal solution, achieving compression performance almost identical to the DP method. These results indicate that variations of the structure that maintain the temporal order of the rasters are unlikely to significantly improve compression. Consequently, we explore an alternative approach based on clustering, where rasters are grouped according to their similarity, regardless of their temporal order. Our experimental evaluation reveals that this clustering-based strategy can enhance compression in scenarios characterized by cyclic behaviour.},
  archive      = {J_COMJNL},
  author       = {Muñoz, Martita and Fuentes-Sepúlveda, José and Hernández, Cecilia and Navarro, Gonzalo and Seco, Diego and Silva-Coira, Fernando},
  doi          = {10.1093/comjnl/bxae090},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {32-46},
  shortjournal = {Comput. J.},
  title        = {Clustering-based compression for raster time series},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classically time-controlled quantum automata: Definition and properties. <em>COMJNL</em>, <em>68</em>(1), 23-31. (<a href='https://doi.org/10.1093/comjnl/bxae089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce classically time-controlled quantum automata or classically time-controlled quantum automaton (CTQA), which is a reasonable modification of Moore–Crutchfield quantum finite automata that uses time-dependent evolution and a ‘scheduler’ defining how long each Hamiltonian will run. Surprisingly enough, time-dependent evolution provides a significant change in the computational power of quantum automata with respect to a discrete quantum model. Indeed, we show that if a scheduler is not computationally restricted, then a CTQA could even decide the Halting problem. In order to unearth the computational capabilities of CTQAs, we study the case of a computationally restricted scheduler. In particular, we showed that depending on the type of restriction imposed on the scheduler, a CTQA can (i) recognize non-regular languages with cut-point, even in the presence of Karp–Lipton advice, and (ii) recognize non-regular promise languages with bounded-error. Furthermore, we study the cutpoint-union of cutpoint languages by introducing a new model of Moore–Crutchfield quantum finite automata with a rotating tape head. CTQA presents itself as a new model of computation that provides a different approach to a formal study of ‘classical control, quantum data’ schemes in quantum computing.},
  archive      = {J_COMJNL},
  author       = {Díaz-Caro, Alejandro and Villagra, Marcos},
  doi          = {10.1093/comjnl/bxae089},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {23-31},
  shortjournal = {Comput. J.},
  title        = {Classically time-controlled quantum automata: Definition and properties},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection based on hybrid metaheuristic feature selection. <em>COMJNL</em>, <em>68</em>(1), 13-22. (<a href='https://doi.org/10.1093/comjnl/bxae088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multidimensional features of network flows are the main data source for intrusion detection, but excessively low-value features generate accuracy and efficiency challenges. Researchers have used redundant feature reduction to simplify intrusion detections, and feature selection algorithms are beginning to be widely used. This paper presents a novel hybrid feature selection algorithm, CSA-FPA, which combines both a crow search algorithm and a flower pollination algorithm. In this method, properties such as local pollination and the levy flight of FPA are used to balance the global search and local search efficiencies, and parameters such as group distance and probability thresholds are introduced to customize the model’s appearance. The simulation results on the UNSW-NB15 and CIC-IDS2017 datasets show that the proposed CSA-FPA method achieves better detection accuracies than previous algorithms. Using the proposed feature selection method, the AdaBoost classifier achieved a detection accuracy of 99.14% on the CIC-IDS2017 dataset and 97.98% on the UNSW-NB15 dataset.},
  archive      = {J_COMJNL},
  author       = {Zhang, Fengjun and Huang, Lisheng and Shi, Kai and Zhai, Shengjie and Lan, Yunhai and Li, Qinghua},
  doi          = {10.1093/comjnl/bxae088},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {13-22},
  shortjournal = {Comput. J.},
  title        = {Intrusion detection based on hybrid metaheuristic feature selection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wi-crack: A smartphone keystroke recognition system based on multi-dimensional information. <em>COMJNL</em>, <em>68</em>(1), 1-12. (<a href='https://doi.org/10.1093/comjnl/bxae087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of mobile payment, password protection has become more and more important. Channel state information (CSI) has recently been used to crack passwords in public WiFi environments. The feasibility of password cracking lies in the fact that different keystrokes lead to different finger movement directions and distances, resulting in unique interference to WiFi signal transmission. The unique interference can be recorded by CSI and used for keystroke inference. In this paper, we propose Wi-Crack, a keystroke recognition system for numerical keypad input on smartphones. Two computers equipped with commercial off-the-shelf WiFi NIC comprise the system, with one serving as the transmitter and the other as the receiver. Previous keystroke recognition systems only used the amplitude of CSI for keystroke recognition. Different from them, Wi-Crack combines the amplitude, phase, amplitude difference and phase difference of CSI for keystroke recognition. The use of multi-dimensional information has enabled Wi-Crack to improve keystroke recognition. Experimental results show that Wi-Crack improves the accuracy of keystroke segmentation to consistently above 90%. It also improves the keystroke recognition accuracy on DTW-KNN, SVM, 1D-CNN, and LSTM with over 90% in the best case.},
  archive      = {J_COMJNL},
  author       = {Peng, Min and Fu, Xianxin and Ge, Benling and Wang, Lusheng},
  doi          = {10.1093/comjnl/bxae087},
  journal      = {The Computer Journal},
  month        = {1},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Comput. J.},
  title        = {Wi-crack: A smartphone keystroke recognition system based on multi-dimensional information},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
